id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/su2code/SU2/issues/417#issuecomment-318056745:205,Modifiability,config,config,205,"Dear Edwin,. Thanks for your quick response. I thoroughly verified my config file, AoA option was given only once. I am not getting any clue about this error. In-fact, I made only two modifications to the config file, which I have sent to Dr. Giuilo, yesterday. Those two are: 1. MARKER_ZONE_INTERFACE option from MARKER_FSI_INTERFACE 2. SST Turbulence model from SA. Then I arrived at new config file for the today downloaded code from develop branch. Hence I suspected minor mistake in any one of newly updated files to develop branch. Thanks & Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318056745
https://github.com/su2code/SU2/issues/417#issuecomment-318056745:390,Modifiability,config,config,390,"Dear Edwin,. Thanks for your quick response. I thoroughly verified my config file, AoA option was given only once. I am not getting any clue about this error. In-fact, I made only two modifications to the config file, which I have sent to Dr. Giuilo, yesterday. Those two are: 1. MARKER_ZONE_INTERFACE option from MARKER_FSI_INTERFACE 2. SST Turbulence model from SA. Then I arrived at new config file for the today downloaded code from develop branch. Hence I suspected minor mistake in any one of newly updated files to develop branch. Thanks & Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318056745
https://github.com/su2code/SU2/issues/417#issuecomment-318060333:25,Modifiability,config,config,25,"Hi Jyothi,. I tried your config file and I cannot reproduce this issue here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318060333
https://github.com/su2code/SU2/issues/417#issuecomment-318069676:76,Availability,down,downloaded,76,"Dear Tim,. Thanks for your response. I would like to inform you that I have downloaded the develop branch code nearly 9hrs ago from git and installed. May I know, are you using the fresh code available from develop branch. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318069676
https://github.com/su2code/SU2/issues/417#issuecomment-318069676:192,Availability,avail,available,192,"Dear Tim,. Thanks for your response. I would like to inform you that I have downloaded the develop branch code nearly 9hrs ago from git and installed. May I know, are you using the fresh code available from develop branch. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318069676
https://github.com/su2code/SU2/issues/417#issuecomment-318069676:140,Deployability,install,installed,140,"Dear Tim,. Thanks for your response. I would like to inform you that I have downloaded the develop branch code nearly 9hrs ago from git and installed. May I know, are you using the fresh code available from develop branch. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318069676
https://github.com/su2code/SU2/issues/417#issuecomment-318158198:28,Availability,error,error,28,"Dear Jyothi,; regarding the error with the option AOA given twice. the problem is related to the fact that in your config file you are giving the option with the ""o"" lower case. If you update the option from ; ""AoA"" --> ""AOA"" it will work. regards. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318158198
https://github.com/su2code/SU2/issues/417#issuecomment-318158198:185,Deployability,update,update,185,"Dear Jyothi,; regarding the error with the option AOA given twice. the problem is related to the fact that in your config file you are giving the option with the ""o"" lower case. If you update the option from ; ""AoA"" --> ""AOA"" it will work. regards. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318158198
https://github.com/su2code/SU2/issues/417#issuecomment-318158198:115,Modifiability,config,config,115,"Dear Jyothi,; regarding the error with the option AOA given twice. the problem is related to the fact that in your config file you are giving the option with the ""o"" lower case. If you update the option from ; ""AoA"" --> ""AOA"" it will work. regards. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318158198
https://github.com/su2code/SU2/issues/417#issuecomment-318276357:111,Modifiability,config,config,111,"Dear Salvo,. Thanks a lot. I appreciate your observation in tracing out the cause of ""lower case o"" used in my config file. My AoA problem is solved. Just I replaced AoA with AOA, then the run took-off. But in earlier versions AoA option was working and never used AOA upto now. This is the first time I am using AOA in my config file. Anyway thanks once again. Regrads,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318276357
https://github.com/su2code/SU2/issues/417#issuecomment-318276357:323,Modifiability,config,config,323,"Dear Salvo,. Thanks a lot. I appreciate your observation in tracing out the cause of ""lower case o"" used in my config file. My AoA problem is solved. Just I replaced AoA with AOA, then the run took-off. But in earlier versions AoA option was working and never used AOA upto now. This is the first time I am using AOA in my config file. Anyway thanks once again. Regrads,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318276357
https://github.com/su2code/SU2/issues/417#issuecomment-318352388:56,Availability,down,download,56,"Dear Giuilo,. I am able to simulate the case with fresh download from develop branch and got post processed data for Tecplot without any error. Thanks a lot for your assistance in this regard. But surprisingly I also faced problem with SA turbulence model, whereas SST is going smooth. SA turbulence model is working fine with develop branch code, which was downloaded may be 2 months ago. I would like to request you to please explain the option MACH_MOTION in detail in the context of sliding interface capability. Thank you so much Giulio once again!. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318352388
https://github.com/su2code/SU2/issues/417#issuecomment-318352388:137,Availability,error,error,137,"Dear Giuilo,. I am able to simulate the case with fresh download from develop branch and got post processed data for Tecplot without any error. Thanks a lot for your assistance in this regard. But surprisingly I also faced problem with SA turbulence model, whereas SST is going smooth. SA turbulence model is working fine with develop branch code, which was downloaded may be 2 months ago. I would like to request you to please explain the option MACH_MOTION in detail in the context of sliding interface capability. Thank you so much Giulio once again!. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318352388
https://github.com/su2code/SU2/issues/417#issuecomment-318352388:358,Availability,down,downloaded,358,"Dear Giuilo,. I am able to simulate the case with fresh download from develop branch and got post processed data for Tecplot without any error. Thanks a lot for your assistance in this regard. But surprisingly I also faced problem with SA turbulence model, whereas SST is going smooth. SA turbulence model is working fine with develop branch code, which was downloaded may be 2 months ago. I would like to request you to please explain the option MACH_MOTION in detail in the context of sliding interface capability. Thank you so much Giulio once again!. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318352388
https://github.com/su2code/SU2/issues/417#issuecomment-318352388:495,Integrability,interface,interface,495,"Dear Giuilo,. I am able to simulate the case with fresh download from develop branch and got post processed data for Tecplot without any error. Thanks a lot for your assistance in this regard. But surprisingly I also faced problem with SA turbulence model, whereas SST is going smooth. SA turbulence model is working fine with develop branch code, which was downloaded may be 2 months ago. I would like to request you to please explain the option MACH_MOTION in detail in the context of sliding interface capability. Thank you so much Giulio once again!. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318352388
https://github.com/su2code/SU2/issues/417#issuecomment-318359073:446,Availability,avail,available,446,"Hi Jyothi, . yes, I am indeed aware that there is something to fix with the SA turbulence model and I am already working to solve it, so that I can push a fix as soon as possible. Regarding the MACH_MOTION option, that is a non-dimensional value you can set to initialize a viscous flow and for computing force coefficients when using dynamic meshes.; Within the SU2 folder you can find the config_template.cfg file that lists all of the options available in SU2. ; There, all options are briefly described and an example of their usage is also provided. By the way, I am happy that you are now able to run your simulation correctly (using the SST model), and thanks to all the SU2 developers that also contributed to help you having your computations running. I am closing this issue, feel free to re-open it if there is something more you (or someone else) want to discuss.; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/417#issuecomment-318359073
https://github.com/su2code/SU2/pull/419#issuecomment-318925936:28,Availability,failure,failure,28,"No worries about the Travis failure, it is because of the changes in the metadata structure in restart files. We can merge this implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/419#issuecomment-318925936
https://github.com/su2code/SU2/pull/422#issuecomment-320694792:920,Performance,perform,performing,920,"In reply to:; > What is the subroutine ""FinishResidualCalc"" is it a new name to call ""ComputeResidual"" if that is the case, for consistency with the rest of the code we should probably use ""ComputeResidual"". I would have liked to have named it the way you suggested. But unfortunately, it's not possible. There's two reasons for this: one is more philosophical, the other is due to a programming restriction. 1. The real residual calculation is a larger method in the parent class (i.e. `CAvgGrad_Abstract::ComputeResidual`). The method currently called `FinishResidualCalc` is just a step in that larger process.; 2. Since the real residual calculation is in the parent class, we need to be able to call it from derived classes (i.e. `CAvgGrad_TurbSA::ComputeResidual`). If we also name a separate method in the derived class `ComputeResidual`, then that method now overrides the method in the parent class. Instead of performing the whole calculation, callers would only get the final step in the calculation. I'm not fixed on the name. Honestly, I picked it somewhat arbitrarily. I just know that ""ComputeResidual"" isn't an option. What do you suggest as a better name?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/422#issuecomment-320694792
https://github.com/su2code/SU2/pull/422#issuecomment-320700900:888,Modifiability,refactor,refactoring,888,"In reply to:; > You are adding the prefix ""_Abstract"" to the new parent classes. For the time being, as we are applying this only for the turbulence model, would it be possible to add also the key word ""Turb"". And... are you completely sure about using the word ""Abstract"" does it makes sense to use something like for example CAvgGrad_TurbBaseline instead of CAvgGrad_Abstract. What do you think?. I'm not fixed on ""Abstract"". In fact, I wanted to use the suffix ""Template"" instead, and only decided on ""Abstract"" as a less satisfactory second choice. As the code currently stands, I totally agree with you. ""Turb"" would be a better suffix. But I was also thinking about possible changes in the future. I can see these classes (`CAvgGrad_Abstract` and `CUpwSca_Abstract`) being used for the transition model (in `numerics_direct_transition.cpp`) as well. Do you agree? Do you think this refactoring should be applied to the transition model?. I didn't picture the transition model as part of this pull request's scope. I wanted to include the transition model as a separate pull request. If we do want to refactor the transition model to eliminate the duplicate code there, then I don't think ""Turb"" or ""TurbBaseline"" are good suffixes. If you do want the duplicate code in the transition model eliminated, then which would you prefer: ""Baseline"", ""Abstract"", ""Outline"", or ""Scalar""? Or do you have another idea?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/422#issuecomment-320700900
https://github.com/su2code/SU2/pull/422#issuecomment-320700900:1106,Modifiability,refactor,refactor,1106,"In reply to:; > You are adding the prefix ""_Abstract"" to the new parent classes. For the time being, as we are applying this only for the turbulence model, would it be possible to add also the key word ""Turb"". And... are you completely sure about using the word ""Abstract"" does it makes sense to use something like for example CAvgGrad_TurbBaseline instead of CAvgGrad_Abstract. What do you think?. I'm not fixed on ""Abstract"". In fact, I wanted to use the suffix ""Template"" instead, and only decided on ""Abstract"" as a less satisfactory second choice. As the code currently stands, I totally agree with you. ""Turb"" would be a better suffix. But I was also thinking about possible changes in the future. I can see these classes (`CAvgGrad_Abstract` and `CUpwSca_Abstract`) being used for the transition model (in `numerics_direct_transition.cpp`) as well. Do you agree? Do you think this refactoring should be applied to the transition model?. I didn't picture the transition model as part of this pull request's scope. I wanted to include the transition model as a separate pull request. If we do want to refactor the transition model to eliminate the duplicate code there, then I don't think ""Turb"" or ""TurbBaseline"" are good suffixes. If you do want the duplicate code in the transition model eliminated, then which would you prefer: ""Baseline"", ""Abstract"", ""Outline"", or ""Scalar""? Or do you have another idea?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/422#issuecomment-320700900
https://github.com/su2code/SU2/issues/423#issuecomment-322124810:284,Modifiability,variab,variables,284,"The dimensional inconsistency comes from the multiplicity of the normal velocity eigenvalue and the manipulation Hirsch does with the corresponding eigenvectors in order to obtain a formulation that is valid for any normal vector. When you use the P matrix to form the characteristic variables, the dimensional inconsistency disappears again, as it should. Never looked at it this way. Thanks for clearing this up Francisco.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/423#issuecomment-322124810
https://github.com/su2code/SU2/issues/423#issuecomment-322124810:397,Usability,clear,clearing,397,"The dimensional inconsistency comes from the multiplicity of the normal velocity eigenvalue and the manipulation Hirsch does with the corresponding eigenvectors in order to obtain a formulation that is valid for any normal vector. When you use the P matrix to form the characteristic variables, the dimensional inconsistency disappears again, as it should. Never looked at it this way. Thanks for clearing this up Francisco.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/423#issuecomment-322124810
https://github.com/su2code/SU2/pull/424#issuecomment-321431468:37,Deployability,update,updated,37,"The Travis config should probably be updated to use Miniconda, running tests with both a Python 2 and Python 3 environment. Could take some influence from https://github.com/mwaskom/seaborn/blob/master/.travis.yml",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321431468
https://github.com/su2code/SU2/pull/424#issuecomment-321431468:11,Modifiability,config,config,11,"The Travis config should probably be updated to use Miniconda, running tests with both a Python 2 and Python 3 environment. Could take some influence from https://github.com/mwaskom/seaborn/blob/master/.travis.yml",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321431468
https://github.com/su2code/SU2/pull/424#issuecomment-321431468:71,Testability,test,tests,71,"The Travis config should probably be updated to use Miniconda, running tests with both a Python 2 and Python 3 environment. Could take some influence from https://github.com/mwaskom/seaborn/blob/master/.travis.yml",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321431468
https://github.com/su2code/SU2/pull/424#issuecomment-321530610:26,Testability,test,test,26,"Fixed at least one failed test, but there are still many print statements left to fix:. ![image](https://user-images.githubusercontent.com/4604869/29169275-3be68e88-7da1-11e7-9d78-4f9a39727257.png). Hopefully this can be fixed up and merged before a bunch of new Python 3 incompatible code is added!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321530610
https://github.com/su2code/SU2/pull/424#issuecomment-321731944:241,Deployability,install,installed,241,"Thanks for spending the time on this, @petebachant. I just fixed a couple of bugs in the python scripts in another PR, but I don't think they will affect this too much. Btw, do you have access to a sizable distributed machine with Python 3+ installed for testing? It would be great to know if this is working in a production environment, while keeping backward compatibility with Python 2+, since it can sometimes be hard to get new Python installations on clusters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321731944
https://github.com/su2code/SU2/pull/424#issuecomment-321731944:440,Deployability,install,installations,440,"Thanks for spending the time on this, @petebachant. I just fixed a couple of bugs in the python scripts in another PR, but I don't think they will affect this too much. Btw, do you have access to a sizable distributed machine with Python 3+ installed for testing? It would be great to know if this is working in a production environment, while keeping backward compatibility with Python 2+, since it can sometimes be hard to get new Python installations on clusters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321731944
https://github.com/su2code/SU2/pull/424#issuecomment-321731944:186,Security,access,access,186,"Thanks for spending the time on this, @petebachant. I just fixed a couple of bugs in the python scripts in another PR, but I don't think they will affect this too much. Btw, do you have access to a sizable distributed machine with Python 3+ installed for testing? It would be great to know if this is working in a production environment, while keeping backward compatibility with Python 2+, since it can sometimes be hard to get new Python installations on clusters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321731944
https://github.com/su2code/SU2/pull/424#issuecomment-321731944:255,Testability,test,testing,255,"Thanks for spending the time on this, @petebachant. I just fixed a couple of bugs in the python scripts in another PR, but I don't think they will affect this too much. Btw, do you have access to a sizable distributed machine with Python 3+ installed for testing? It would be great to know if this is working in a production environment, while keeping backward compatibility with Python 2+, since it can sometimes be hard to get new Python installations on clusters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321731944
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:579,Availability,ERROR,ERROR,579,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:641,Availability,ERROR,ERROR,641,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:754,Availability,Error,Error,754,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:74,Deployability,install,install,74,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:13,Security,access,access,13,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:36,Testability,test,test,36,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:373,Testability,test,tests,373,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:429,Testability,Test,TestCases,429,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:574,Testability,log,log,574,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321769609:729,Testability,Test,TestCases,729,"I don't have access to a cluster to test this on. However, I usually will install Anaconda Python (3) in my home directory when I do run on clusters just to have complete control over the entire Python environment. I think for scientific/engineering computing this is generally a better strategy than relying on the system Python. . On another note, any hints on why these tests are failing?. ```; /home/travis/build/su2code/SU2/TestCases/optimization_euler/steady_naca0012; naca0012_geo: FAILED; ```. ```; execution command: SU2_GEO inv_NACA0012_adv.cfg > inv_NACA0012_adv.log; ERROR: The code was not able to get to the ""OBJFUN"" section.; ERROR: The SU2_GEO values could not be found.; ```. ```; /home/travis/build/su2code/SU2/TestCases/rans/naca0012; Error in test_vals!; turb_naca0012_sst_restart_mg: FAILED; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321769609
https://github.com/su2code/SU2/pull/424#issuecomment-321771383:62,Testability,test,test,62,"I don't know if this is related, but the output of the stored test vals looks a little bit strange now:. ```; ==================== Start Test: contadj_fixedcl_naca0012 ====================; /home/travis/build/su2code/SU2/TestCases/fixed_cl/naca0012; contadj_fixedcl_naca0012: PASSED; execution command: parallel_computation.py -f inv_NACA0012_ContAdj.cfg.autotest > inv_NACA0012_ContAdj.cfg.log; test_iter=500 ; test_vals (stored): -2.093175,; -6.967350,; 0.249870,; -0.000019,; sim_vals (computed): -2.093175, -6.967350, 0.249870, -0.000019, ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000000, ; test duration: 0.62 min; ==================== End Test: contadj_fixedcl_naca0012 ====================; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321771383
https://github.com/su2code/SU2/pull/424#issuecomment-321771383:137,Testability,Test,Test,137,"I don't know if this is related, but the output of the stored test vals looks a little bit strange now:. ```; ==================== Start Test: contadj_fixedcl_naca0012 ====================; /home/travis/build/su2code/SU2/TestCases/fixed_cl/naca0012; contadj_fixedcl_naca0012: PASSED; execution command: parallel_computation.py -f inv_NACA0012_ContAdj.cfg.autotest > inv_NACA0012_ContAdj.cfg.log; test_iter=500 ; test_vals (stored): -2.093175,; -6.967350,; 0.249870,; -0.000019,; sim_vals (computed): -2.093175, -6.967350, 0.249870, -0.000019, ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000000, ; test duration: 0.62 min; ==================== End Test: contadj_fixedcl_naca0012 ====================; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321771383
https://github.com/su2code/SU2/pull/424#issuecomment-321771383:221,Testability,Test,TestCases,221,"I don't know if this is related, but the output of the stored test vals looks a little bit strange now:. ```; ==================== Start Test: contadj_fixedcl_naca0012 ====================; /home/travis/build/su2code/SU2/TestCases/fixed_cl/naca0012; contadj_fixedcl_naca0012: PASSED; execution command: parallel_computation.py -f inv_NACA0012_ContAdj.cfg.autotest > inv_NACA0012_ContAdj.cfg.log; test_iter=500 ; test_vals (stored): -2.093175,; -6.967350,; 0.249870,; -0.000019,; sim_vals (computed): -2.093175, -6.967350, 0.249870, -0.000019, ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000000, ; test duration: 0.62 min; ==================== End Test: contadj_fixedcl_naca0012 ====================; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321771383
https://github.com/su2code/SU2/pull/424#issuecomment-321771383:391,Testability,log,log,391,"I don't know if this is related, but the output of the stored test vals looks a little bit strange now:. ```; ==================== Start Test: contadj_fixedcl_naca0012 ====================; /home/travis/build/su2code/SU2/TestCases/fixed_cl/naca0012; contadj_fixedcl_naca0012: PASSED; execution command: parallel_computation.py -f inv_NACA0012_ContAdj.cfg.autotest > inv_NACA0012_ContAdj.cfg.log; test_iter=500 ; test_vals (stored): -2.093175,; -6.967350,; 0.249870,; -0.000019,; sim_vals (computed): -2.093175, -6.967350, 0.249870, -0.000019, ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000000, ; test duration: 0.62 min; ==================== End Test: contadj_fixedcl_naca0012 ====================; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321771383
https://github.com/su2code/SU2/pull/424#issuecomment-321771383:599,Testability,test,test,599,"I don't know if this is related, but the output of the stored test vals looks a little bit strange now:. ```; ==================== Start Test: contadj_fixedcl_naca0012 ====================; /home/travis/build/su2code/SU2/TestCases/fixed_cl/naca0012; contadj_fixedcl_naca0012: PASSED; execution command: parallel_computation.py -f inv_NACA0012_ContAdj.cfg.autotest > inv_NACA0012_ContAdj.cfg.log; test_iter=500 ; test_vals (stored): -2.093175,; -6.967350,; 0.249870,; -0.000019,; sim_vals (computed): -2.093175, -6.967350, 0.249870, -0.000019, ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000000, ; test duration: 0.62 min; ==================== End Test: contadj_fixedcl_naca0012 ====================; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321771383
https://github.com/su2code/SU2/pull/424#issuecomment-321771383:649,Testability,Test,Test,649,"I don't know if this is related, but the output of the stored test vals looks a little bit strange now:. ```; ==================== Start Test: contadj_fixedcl_naca0012 ====================; /home/travis/build/su2code/SU2/TestCases/fixed_cl/naca0012; contadj_fixedcl_naca0012: PASSED; execution command: parallel_computation.py -f inv_NACA0012_ContAdj.cfg.autotest > inv_NACA0012_ContAdj.cfg.log; test_iter=500 ; test_vals (stored): -2.093175,; -6.967350,; 0.249870,; -0.000019,; sim_vals (computed): -2.093175, -6.967350, 0.249870, -0.000019, ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000000, ; test duration: 0.62 min; ==================== End Test: contadj_fixedcl_naca0012 ====================; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321771383
https://github.com/su2code/SU2/pull/424#issuecomment-321867755:277,Availability,avail,available,277,"On the topic of Python distributions: I agree.. I typically build up a local Enthought Canopy Python (command line only) on clusters to have control too. Although, it seems that their new versions (canopy 2+) deprecate the command line interface somewhat, even though Py 3+ is available. Perhaps I'll give Anaconda a try then soon, thanks for that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321867755
https://github.com/su2code/SU2/pull/424#issuecomment-321867755:236,Integrability,interface,interface,236,"On the topic of Python distributions: I agree.. I typically build up a local Enthought Canopy Python (command line only) on clusters to have control too. Although, it seems that their new versions (canopy 2+) deprecate the command line interface somewhat, even though Py 3+ is available. Perhaps I'll give Anaconda a try then soon, thanks for that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-321867755
https://github.com/su2code/SU2/pull/424#issuecomment-323047764:26,Testability,test,test,26,"So I have setup Travis to test both Python versions, but I need to learn a little bit more about automake to setup the `pySU2` Makefile properly to build against the active Python environment. Hopefully getting closer...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-323047764
https://github.com/su2code/SU2/pull/424#issuecomment-323047764:67,Usability,learn,learn,67,"So I have setup Travis to test both Python versions, but I need to learn a little bit more about automake to setup the `pySU2` Makefile properly to build against the active Python environment. Hopefully getting closer...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-323047764
https://github.com/su2code/SU2/pull/424#issuecomment-323252317:131,Integrability,wrap,wrapper,131,"@petebachant thanks for the effort to keep this PR going. I think that @tobadavid would be the best contact for updating the pySU2 wrapper build, as he is the original author. David, if you have a moment, could you please give this a look? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-323252317
https://github.com/su2code/SU2/pull/424#issuecomment-326741839:112,Integrability,wrap,wrapper,112,"Made some progress on this. The build system now automatically finds the Python directories and library, so the wrapper is now built against both Python 2.7 and 3.6 in the test suite. However, some tests are still failing. Any ideas what might be going wrong?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-326741839
https://github.com/su2code/SU2/pull/424#issuecomment-326741839:172,Testability,test,test,172,"Made some progress on this. The build system now automatically finds the Python directories and library, so the wrapper is now built against both Python 2.7 and 3.6 in the test suite. However, some tests are still failing. Any ideas what might be going wrong?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-326741839
https://github.com/su2code/SU2/pull/424#issuecomment-326741839:198,Testability,test,tests,198,"Made some progress on this. The build system now automatically finds the Python directories and library, so the wrapper is now built against both Python 2.7 and 3.6 in the test suite. However, some tests are still failing. Any ideas what might be going wrong?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-326741839
https://github.com/su2code/SU2/pull/424#issuecomment-339951861:91,Modifiability,variab,variables,91,"It looks like all the tests are finally working. However, the `directdiff_euler_py` output variables are written in the wrong order. It looks like this comes from `SU2/eval/gradients.py`:. ```python; # initialize gradients; func_keys = list(su2io.grad_names_map.keys()); func_keys = ['VARIABLE'] + func_keys; ```. My guess is that there was some assumption that dictionary keys have an inherent order. Now, should the test be doing a diff of the text output, or should it really be checking the numerical values?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-339951861
https://github.com/su2code/SU2/pull/424#issuecomment-339951861:285,Modifiability,VARIAB,VARIABLE,285,"It looks like all the tests are finally working. However, the `directdiff_euler_py` output variables are written in the wrong order. It looks like this comes from `SU2/eval/gradients.py`:. ```python; # initialize gradients; func_keys = list(su2io.grad_names_map.keys()); func_keys = ['VARIABLE'] + func_keys; ```. My guess is that there was some assumption that dictionary keys have an inherent order. Now, should the test be doing a diff of the text output, or should it really be checking the numerical values?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-339951861
https://github.com/su2code/SU2/pull/424#issuecomment-339951861:22,Testability,test,tests,22,"It looks like all the tests are finally working. However, the `directdiff_euler_py` output variables are written in the wrong order. It looks like this comes from `SU2/eval/gradients.py`:. ```python; # initialize gradients; func_keys = list(su2io.grad_names_map.keys()); func_keys = ['VARIABLE'] + func_keys; ```. My guess is that there was some assumption that dictionary keys have an inherent order. Now, should the test be doing a diff of the text output, or should it really be checking the numerical values?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-339951861
https://github.com/su2code/SU2/pull/424#issuecomment-339951861:418,Testability,test,test,418,"It looks like all the tests are finally working. However, the `directdiff_euler_py` output variables are written in the wrong order. It looks like this comes from `SU2/eval/gradients.py`:. ```python; # initialize gradients; func_keys = list(su2io.grad_names_map.keys()); func_keys = ['VARIABLE'] + func_keys; ```. My guess is that there was some assumption that dictionary keys have an inherent order. Now, should the test be doing a diff of the text output, or should it really be checking the numerical values?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-339951861
https://github.com/su2code/SU2/pull/424#issuecomment-340193114:271,Integrability,wrap,wrapper,271,"Alright, so my above hunch was correct: that there was an assumption of dictionary key order. I switched that variable over to an ordered bunch and I believe all the tests are passing, despite one of them timing out. After addressing that, the entire repo (including the wrapper) should now be compatible with both Python 2 and Python 3, and is setup to be tested with both.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-340193114
https://github.com/su2code/SU2/pull/424#issuecomment-340193114:110,Modifiability,variab,variable,110,"Alright, so my above hunch was correct: that there was an assumption of dictionary key order. I switched that variable over to an ordered bunch and I believe all the tests are passing, despite one of them timing out. After addressing that, the entire repo (including the wrapper) should now be compatible with both Python 2 and Python 3, and is setup to be tested with both.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-340193114
https://github.com/su2code/SU2/pull/424#issuecomment-340193114:166,Testability,test,tests,166,"Alright, so my above hunch was correct: that there was an assumption of dictionary key order. I switched that variable over to an ordered bunch and I believe all the tests are passing, despite one of them timing out. After addressing that, the entire repo (including the wrapper) should now be compatible with both Python 2 and Python 3, and is setup to be tested with both.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-340193114
https://github.com/su2code/SU2/pull/424#issuecomment-340193114:357,Testability,test,tested,357,"Alright, so my above hunch was correct: that there was an assumption of dictionary key order. I switched that variable over to an ordered bunch and I believe all the tests are passing, despite one of them timing out. After addressing that, the entire repo (including the wrapper) should now be compatible with both Python 2 and Python 3, and is setup to be tested with both.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-340193114
https://github.com/su2code/SU2/pull/424#issuecomment-343013631:27,Testability,test,tests,27,This PR finally passed the tests! Can I get some review feedback @economon and/or @talbring? It would be great to have this merged ASAP so no one adds any new code incompatible with Python 3.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-343013631
https://github.com/su2code/SU2/pull/424#issuecomment-343013631:56,Usability,feedback,feedback,56,This PR finally passed the tests! Can I get some review feedback @economon and/or @talbring? It would be great to have this merged ASAP so no one adds any new code incompatible with Python 3.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-343013631
https://github.com/su2code/SU2/pull/424#issuecomment-347509883:67,Integrability,wrap,wrapper,67,Unfortunately it looks like the serial regression test with Python wrapper is timing out for both versions. Any ideas to speed this up or perhaps request another minute or two?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-347509883
https://github.com/su2code/SU2/pull/424#issuecomment-347509883:50,Testability,test,test,50,Unfortunately it looks like the serial regression test with Python wrapper is timing out for both versions. Any ideas to speed this up or perhaps request another minute or two?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-347509883
https://github.com/su2code/SU2/pull/424#issuecomment-347515641:15,Energy Efficiency,reduce,reduce,15,I think we can reduce the iterations of some of the test cases. That should already save a lot time ... . I'll create a branch for that which we should merge in asap.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-347515641
https://github.com/su2code/SU2/pull/424#issuecomment-347515641:52,Testability,test,test,52,I think we can reduce the iterations of some of the test cases. That should already save a lot time ... . I'll create a branch for that which we should merge in asap.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-347515641
https://github.com/su2code/SU2/pull/424#issuecomment-476708929:137,Availability,error,error,137,"Hi, I was having a few issues installing the Python wrapper (which strangely happened to work for some of my systems) and I followed the error back to SU2_PY/pySU2/Makefile.am, where a Python 2.7 path is still hardcoded. Is this an intentional remainder?. I tried to use the [fix documented back in V5](https://github.com/su2code/SU2/issues/447) but I've not had any success yet. I'm still troubleshooting (and may have a few incorrect paths still) but just to hear the official word here before I have another go. Thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-476708929
https://github.com/su2code/SU2/pull/424#issuecomment-476708929:30,Deployability,install,installing,30,"Hi, I was having a few issues installing the Python wrapper (which strangely happened to work for some of my systems) and I followed the error back to SU2_PY/pySU2/Makefile.am, where a Python 2.7 path is still hardcoded. Is this an intentional remainder?. I tried to use the [fix documented back in V5](https://github.com/su2code/SU2/issues/447) but I've not had any success yet. I'm still troubleshooting (and may have a few incorrect paths still) but just to hear the official word here before I have another go. Thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-476708929
https://github.com/su2code/SU2/pull/424#issuecomment-476708929:52,Integrability,wrap,wrapper,52,"Hi, I was having a few issues installing the Python wrapper (which strangely happened to work for some of my systems) and I followed the error back to SU2_PY/pySU2/Makefile.am, where a Python 2.7 path is still hardcoded. Is this an intentional remainder?. I tried to use the [fix documented back in V5](https://github.com/su2code/SU2/issues/447) but I've not had any success yet. I'm still troubleshooting (and may have a few incorrect paths still) but just to hear the official word here before I have another go. Thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-476708929
https://github.com/su2code/SU2/pull/424#issuecomment-477524398:110,Availability,error,error,110,"@timjim333 you should probably open a new issue for this, specifying your system, Python environment, and the error messages you get. It may be possible to remove those hardcoded paths, changing. ```make; MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; -I${PYTHON_SITE_PACKAGES}/mpi4py/include \; -I/Library/Python/2.7/site-packages/mpi4py/include; ```. to. ```make; MPI4PY_INCLUDE = ${PYTHON_SITE_PACKAGES}/mpi4py/include; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-477524398
https://github.com/su2code/SU2/pull/424#issuecomment-477524398:116,Integrability,message,messages,116,"@timjim333 you should probably open a new issue for this, specifying your system, Python environment, and the error messages you get. It may be possible to remove those hardcoded paths, changing. ```make; MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; -I${PYTHON_SITE_PACKAGES}/mpi4py/include \; -I/Library/Python/2.7/site-packages/mpi4py/include; ```. to. ```make; MPI4PY_INCLUDE = ${PYTHON_SITE_PACKAGES}/mpi4py/include; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/424#issuecomment-477524398
https://github.com/su2code/SU2/pull/426#issuecomment-323580700:127,Deployability,integrat,integrated,127,"By the way, there's also this cool tool called vera++ that allows you to check the style of the entire codebase. This could be integrated with Travis so make sure PRs are consistent with the coding style guide.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323580700
https://github.com/su2code/SU2/pull/426#issuecomment-323580700:127,Integrability,integrat,integrated,127,"By the way, there's also this cool tool called vera++ that allows you to check the style of the entire codebase. This could be integrated with Travis so make sure PRs are consistent with the coding style guide.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323580700
https://github.com/su2code/SU2/pull/426#issuecomment-323580700:204,Usability,guid,guide,204,"By the way, there's also this cool tool called vera++ that allows you to check the style of the entire codebase. This could be integrated with Travis so make sure PRs are consistent with the coding style guide.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323580700
https://github.com/su2code/SU2/pull/426#issuecomment-323636235:103,Deployability,integrat,integrated,103,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235
https://github.com/su2code/SU2/pull/426#issuecomment-323636235:103,Integrability,integrat,integrated,103,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235
https://github.com/su2code/SU2/pull/426#issuecomment-323636235:133,Testability,test,test,133,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235
https://github.com/su2code/SU2/pull/426#issuecomment-323636235:188,Usability,guid,guide,188,"Agreed that the style needs some attention. I am open to ideas about this. You may have noticed that I integrated Codacy recently to test it out: https://www.codacy.com. We have the style guide, but honestly, it's not getting much attention. We should automate checks or have scripts that automatically enforce style constraints. Vera++ sounds interesting in this regard. A little while back, @rsanfer and I had been working on indentation issues with the uncrustify tool. Should we open this as an issue and get some input? Find volunteers to look into these things?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/426#issuecomment-323636235
https://github.com/su2code/SU2/issues/429#issuecomment-324472719:92,Availability,avail,available,92,"Dear Tim,. I think it is good one. But we should keep in mind that we already have OpenFoam available which is a very good open-source solver for this type of flows, but I do not think it has an Adjoint solver. Please correct me if I am wrong. Best,. Eduardo. > On 22 Aug 2017, at 16:44, Tim Albring <notifications@github.com> wrote:; > ; > Dear all,; > ; > I recently had a lot of discussions with people that are interested in developing a pressure-based incompressible solver (like SIMPLE etc.) in SU2. I just wanted to get the discussion started.; > ; > Who is willing to contribute ? What applications do you have in mind ?; > ; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/issues/429>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AJVmCTZqPArJr99aBEoGoiAmQsKOLQmBks5say-JgaJpZM4O_GCF>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-324472719
https://github.com/su2code/SU2/issues/429#issuecomment-324472719:485,Usability,SIMPL,SIMPLE,485,"Dear Tim,. I think it is good one. But we should keep in mind that we already have OpenFoam available which is a very good open-source solver for this type of flows, but I do not think it has an Adjoint solver. Please correct me if I am wrong. Best,. Eduardo. > On 22 Aug 2017, at 16:44, Tim Albring <notifications@github.com> wrote:; > ; > Dear all,; > ; > I recently had a lot of discussions with people that are interested in developing a pressure-based incompressible solver (like SIMPLE etc.) in SU2. I just wanted to get the discussion started.; > ; > Who is willing to contribute ? What applications do you have in mind ?; > ; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/issues/429>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AJVmCTZqPArJr99aBEoGoiAmQsKOLQmBks5say-JgaJpZM4O_GCF>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-324472719
https://github.com/su2code/SU2/issues/429#issuecomment-326904729:429,Availability,avail,availability,429,"Hi Tim,. In collaboration with the Energy Centre Netherlands (ECN) we are interested in participating in the development of a pressure-based incompressible solver. The applications we have in mind are all related to wind turbines, for which compressible solvers perform relatively poorly. We realize that OpenFOAM is very much capable of carrying out such simulations, but the motivation for developing this in SU2 is indeed the availability of the (discrete) adjoint. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-326904729
https://github.com/su2code/SU2/issues/429#issuecomment-326904729:35,Energy Efficiency,Energy,Energy,35,"Hi Tim,. In collaboration with the Energy Centre Netherlands (ECN) we are interested in participating in the development of a pressure-based incompressible solver. The applications we have in mind are all related to wind turbines, for which compressible solvers perform relatively poorly. We realize that OpenFOAM is very much capable of carrying out such simulations, but the motivation for developing this in SU2 is indeed the availability of the (discrete) adjoint. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-326904729
https://github.com/su2code/SU2/issues/429#issuecomment-326904729:262,Performance,perform,perform,262,"Hi Tim,. In collaboration with the Energy Centre Netherlands (ECN) we are interested in participating in the development of a pressure-based incompressible solver. The applications we have in mind are all related to wind turbines, for which compressible solvers perform relatively poorly. We realize that OpenFOAM is very much capable of carrying out such simulations, but the motivation for developing this in SU2 is indeed the availability of the (discrete) adjoint. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-326904729
https://github.com/su2code/SU2/issues/429#issuecomment-345704308:300,Testability,test,test,300,"Hello all,. As a first step towards developing the pressure based system, I was looking at the Poisson solver currently in the code. Is there any active development going on in Poisson problem. From what I understand it was developed for electric potential problems. ; Is there some documentation or test case?. Cheers,; Akshay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-345704308
https://github.com/su2code/SU2/issues/429#issuecomment-370767656:487,Deployability,integrat,integration,487,"Hello,. I have now added a basic FVM implementation to solve a general Poisson problem. The existing Poisson solver used a FEM based discretization but we needed a FVM based discretization to maintain numerical consistency when the momentum equations and Poisson equation for pressure are coupled. The FVM based solver is now working but some work still remains (like output formatting, history files.. etc). I used a pseudo-time approach and Euler explicit and implicit schemes fortime integration. The source term and the boundary conditions (Dirichlet and Neumann) are all hard coded for now. The next step would be to use the multigrid methods to solve the Poisson problem directly instead of the pseudo-time approach. . Cheers,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-370767656
https://github.com/su2code/SU2/issues/429#issuecomment-370767656:487,Integrability,integrat,integration,487,"Hello,. I have now added a basic FVM implementation to solve a general Poisson problem. The existing Poisson solver used a FEM based discretization but we needed a FVM based discretization to maintain numerical consistency when the momentum equations and Poisson equation for pressure are coupled. The FVM based solver is now working but some work still remains (like output formatting, history files.. etc). I used a pseudo-time approach and Euler explicit and implicit schemes fortime integration. The source term and the boundary conditions (Dirichlet and Neumann) are all hard coded for now. The next step would be to use the multigrid methods to solve the Poisson problem directly instead of the pseudo-time approach. . Cheers,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-370767656
https://github.com/su2code/SU2/issues/429#issuecomment-371167335:66,Deployability,integrat,integrate,66,"Hi there,. maybe I should mention that as a part of my commits to integrate a CHT functionality to SU2 (see the pull request I opened up a month ago, if you like), I also had to implement a heat solver that can be coupled to a flow equation system. We even chose similar namings (mine is called CHeatSolverFVM). It might be interesting for you that it also can be run ""stand-alone"" for pure heat conduction problems (for solids..) in which case it is nothing else but a Poisson solver.; It's just that my naming is unnecessarily specific, I should rather rename the CHeatSolverFVM to CAdvectionDiffusionSolver and generalize the coefficients (""diffusivity"" instead of ""thermal_difffusivity"", for example). Sounds to be a good idea... :D. Anyway, feel informed :-). Ole",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-371167335
https://github.com/su2code/SU2/issues/429#issuecomment-371167335:66,Integrability,integrat,integrate,66,"Hi there,. maybe I should mention that as a part of my commits to integrate a CHT functionality to SU2 (see the pull request I opened up a month ago, if you like), I also had to implement a heat solver that can be coupled to a flow equation system. We even chose similar namings (mine is called CHeatSolverFVM). It might be interesting for you that it also can be run ""stand-alone"" for pure heat conduction problems (for solids..) in which case it is nothing else but a Poisson solver.; It's just that my naming is unnecessarily specific, I should rather rename the CHeatSolverFVM to CAdvectionDiffusionSolver and generalize the coefficients (""diffusivity"" instead of ""thermal_difffusivity"", for example). Sounds to be a good idea... :D. Anyway, feel informed :-). Ole",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/429#issuecomment-371167335
https://github.com/su2code/SU2/issues/431#issuecomment-337056131:390,Integrability,rout,routine,390,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
https://github.com/su2code/SU2/issues/431#issuecomment-337056131:831,Modifiability,variab,variables,831,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
https://github.com/su2code/SU2/issues/431#issuecomment-337056131:859,Security,access,access,859,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
https://github.com/su2code/SU2/issues/431#issuecomment-337056131:680,Testability,test,test,680,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
https://github.com/su2code/SU2/issues/431#issuecomment-337056131:498,Usability,simpl,simple,498,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
https://github.com/su2code/SU2/issues/431#issuecomment-337056131:544,Usability,simpl,simple,544,"This bug pops up because the periodic mesh reconstruction (in `SU2_MSH`) doesn't always create a valid mesh in 3D. Some points disappear, and some points are duplicated. When `SU2_CFD` (specifically, `CPhysicalGeometry`) tries to get the number of points in the domain, it calculates the wrong number because some of those points are duplicated. That leads to segfaults, because the output routine thinks the extra (missing) points belong to another processor. I've got a little toy problem with a simple periodic cube. It's easy to see on the simple 4x4x4 (+ periodic) problem that 3 nodes disappear, and 3 nodes are duplicated. I've never observed this problem in any of the 2D test cases I ran. As to why `SU2_MSH` is missing some points and duplicating others, I'm not sure. I tried running Valgrind to check for uninitialized variables or illegal memory access, but nothing there. I'll have to look more into the problem. The `su2_periodic.f90` script mentioned in #416 seems to be a workaround. I don't run into any problems when I use that script.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-337056131
https://github.com/su2code/SU2/issues/431#issuecomment-358340153:13,Availability,down,down,13,"I've tracked down the source of the bug, and I'll submit a pull request later today. During the output of the periodic mesh in `SU2_MSH`, `CPeriodicGeometry::SetMeshFile` sorts the nodes into the order normal, receive, send. This can be found in [lines 18798-18819 of Common/src/geometry_structure](https://github.com/su2code/SU2/blob/68991cd1005cf118e1ff21b8952bb366bb299cf3/Common/src/geometry_structure.cpp#L18798). I've copied down the lines here for reference:. ```cpp; /*--- Change the numbering to guarantee that the all the receive; points are at the end of the file ---*/; unsigned long OldnPoint = geometry->GetnPoint();; unsigned long *NewSort = new unsigned long[nPoint];; for (iPoint = 0; iPoint < nPoint; iPoint++) {; NewSort[iPoint] = iPoint;; }; ; unsigned long Index = OldnPoint-1;; for (iMarker = 0; iMarker < nMarker; iMarker++) {; if (bound[iMarker][0]->GetVTK_Type() == VERTEX) {; if (config->GetMarker_All_SendRecv(iMarker) < 0) {; for (iElem_Bound = 0; iElem_Bound < nElem_Bound[iMarker]; iElem_Bound++) {; if (bound[iMarker][iElem_Bound]->GetNode(0) < geometry->GetnPoint()) {; NewSort[bound[iMarker][iElem_Bound]->GetNode(0)] = Index;; NewSort[Index] = bound[iMarker][iElem_Bound]->GetNode(0);; Index--;; }; }; }; }; }; ```. In order to sort the points, a list mapping the old points to the new points (`NewSort`) is created. The problem is that this list is sorted by switching nodes. But it doesn't switch around the _contents_ of the list (i.e. two node numbers from the list). Instead it switched an index from the list and an actual node number pulled from the geometry. This presents two problems:. 1. If any of the receive nodes actually are at the end of the list, they will get switched away from the end of the list.; 2. If any node is switched twice, data is lost. That's because the sorting assumes that the elements being switched have not already been switched. This is how the three points went missing from the cube problem I previously referenced. If my write",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358340153
https://github.com/su2code/SU2/issues/431#issuecomment-358340153:431,Availability,down,down,431,"I've tracked down the source of the bug, and I'll submit a pull request later today. During the output of the periodic mesh in `SU2_MSH`, `CPeriodicGeometry::SetMeshFile` sorts the nodes into the order normal, receive, send. This can be found in [lines 18798-18819 of Common/src/geometry_structure](https://github.com/su2code/SU2/blob/68991cd1005cf118e1ff21b8952bb366bb299cf3/Common/src/geometry_structure.cpp#L18798). I've copied down the lines here for reference:. ```cpp; /*--- Change the numbering to guarantee that the all the receive; points are at the end of the file ---*/; unsigned long OldnPoint = geometry->GetnPoint();; unsigned long *NewSort = new unsigned long[nPoint];; for (iPoint = 0; iPoint < nPoint; iPoint++) {; NewSort[iPoint] = iPoint;; }; ; unsigned long Index = OldnPoint-1;; for (iMarker = 0; iMarker < nMarker; iMarker++) {; if (bound[iMarker][0]->GetVTK_Type() == VERTEX) {; if (config->GetMarker_All_SendRecv(iMarker) < 0) {; for (iElem_Bound = 0; iElem_Bound < nElem_Bound[iMarker]; iElem_Bound++) {; if (bound[iMarker][iElem_Bound]->GetNode(0) < geometry->GetnPoint()) {; NewSort[bound[iMarker][iElem_Bound]->GetNode(0)] = Index;; NewSort[Index] = bound[iMarker][iElem_Bound]->GetNode(0);; Index--;; }; }; }; }; }; ```. In order to sort the points, a list mapping the old points to the new points (`NewSort`) is created. The problem is that this list is sorted by switching nodes. But it doesn't switch around the _contents_ of the list (i.e. two node numbers from the list). Instead it switched an index from the list and an actual node number pulled from the geometry. This presents two problems:. 1. If any of the receive nodes actually are at the end of the list, they will get switched away from the end of the list.; 2. If any node is switched twice, data is lost. That's because the sorting assumes that the elements being switched have not already been switched. This is how the three points went missing from the cube problem I previously referenced. If my write",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358340153
https://github.com/su2code/SU2/issues/431#issuecomment-358340153:2063,Availability,error,error,2063,"r today. During the output of the periodic mesh in `SU2_MSH`, `CPeriodicGeometry::SetMeshFile` sorts the nodes into the order normal, receive, send. This can be found in [lines 18798-18819 of Common/src/geometry_structure](https://github.com/su2code/SU2/blob/68991cd1005cf118e1ff21b8952bb366bb299cf3/Common/src/geometry_structure.cpp#L18798). I've copied down the lines here for reference:. ```cpp; /*--- Change the numbering to guarantee that the all the receive; points are at the end of the file ---*/; unsigned long OldnPoint = geometry->GetnPoint();; unsigned long *NewSort = new unsigned long[nPoint];; for (iPoint = 0; iPoint < nPoint; iPoint++) {; NewSort[iPoint] = iPoint;; }; ; unsigned long Index = OldnPoint-1;; for (iMarker = 0; iMarker < nMarker; iMarker++) {; if (bound[iMarker][0]->GetVTK_Type() == VERTEX) {; if (config->GetMarker_All_SendRecv(iMarker) < 0) {; for (iElem_Bound = 0; iElem_Bound < nElem_Bound[iMarker]; iElem_Bound++) {; if (bound[iMarker][iElem_Bound]->GetNode(0) < geometry->GetnPoint()) {; NewSort[bound[iMarker][iElem_Bound]->GetNode(0)] = Index;; NewSort[Index] = bound[iMarker][iElem_Bound]->GetNode(0);; Index--;; }; }; }; }; }; ```. In order to sort the points, a list mapping the old points to the new points (`NewSort`) is created. The problem is that this list is sorted by switching nodes. But it doesn't switch around the _contents_ of the list (i.e. two node numbers from the list). Instead it switched an index from the list and an actual node number pulled from the geometry. This presents two problems:. 1. If any of the receive nodes actually are at the end of the list, they will get switched away from the end of the list.; 2. If any node is switched twice, data is lost. That's because the sorting assumes that the elements being switched have not already been switched. This is how the three points went missing from the cube problem I previously referenced. If my write-up is too confusing, I can provide a play-by-play of how the error occurs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358340153
https://github.com/su2code/SU2/issues/431#issuecomment-358340153:906,Modifiability,config,config,906,"I've tracked down the source of the bug, and I'll submit a pull request later today. During the output of the periodic mesh in `SU2_MSH`, `CPeriodicGeometry::SetMeshFile` sorts the nodes into the order normal, receive, send. This can be found in [lines 18798-18819 of Common/src/geometry_structure](https://github.com/su2code/SU2/blob/68991cd1005cf118e1ff21b8952bb366bb299cf3/Common/src/geometry_structure.cpp#L18798). I've copied down the lines here for reference:. ```cpp; /*--- Change the numbering to guarantee that the all the receive; points are at the end of the file ---*/; unsigned long OldnPoint = geometry->GetnPoint();; unsigned long *NewSort = new unsigned long[nPoint];; for (iPoint = 0; iPoint < nPoint; iPoint++) {; NewSort[iPoint] = iPoint;; }; ; unsigned long Index = OldnPoint-1;; for (iMarker = 0; iMarker < nMarker; iMarker++) {; if (bound[iMarker][0]->GetVTK_Type() == VERTEX) {; if (config->GetMarker_All_SendRecv(iMarker) < 0) {; for (iElem_Bound = 0; iElem_Bound < nElem_Bound[iMarker]; iElem_Bound++) {; if (bound[iMarker][iElem_Bound]->GetNode(0) < geometry->GetnPoint()) {; NewSort[bound[iMarker][iElem_Bound]->GetNode(0)] = Index;; NewSort[Index] = bound[iMarker][iElem_Bound]->GetNode(0);; Index--;; }; }; }; }; }; ```. In order to sort the points, a list mapping the old points to the new points (`NewSort`) is created. The problem is that this list is sorted by switching nodes. But it doesn't switch around the _contents_ of the list (i.e. two node numbers from the list). Instead it switched an index from the list and an actual node number pulled from the geometry. This presents two problems:. 1. If any of the receive nodes actually are at the end of the list, they will get switched away from the end of the list.; 2. If any node is switched twice, data is lost. That's because the sorting assumes that the elements being switched have not already been switched. This is how the three points went missing from the cube problem I previously referenced. If my write",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358340153
https://github.com/su2code/SU2/issues/431#issuecomment-358423989:343,Availability,down,down,343,"Hi clarkpede,. Have you looked into the enhancement_periodicbc"" branch? I recall fixing many of these bugs there but not merging it to master because there are still a few more things that have to be taken care of. David. On Jan 17, 2018, at 7:30 AM, clarkpede <notifications@github.com<mailto:notifications@github.com>> wrote:. I've tracked down the source of the bug, and I'll submit a pull request later today. During the output of the periodic mesh in SU2_MSH, CPeriodicGeometry::SetMeshFile sorts the nodes into the order normal, receive, send. This can be found in lines 18798-18819 of Common/src/geometry_structure<https://github.com/su2code/SU2/blob/68991cd1005cf118e1ff21b8952bb366bb299cf3/Common/src/geometry_structure.cpp#L18798>. I've copied down the lines here for reference:. /*--- Change the numbering to guarantee that the all the receive; points are at the end of the file ---*/; unsigned long OldnPoint = geometry->GetnPoint();; unsigned long *NewSort = new unsigned long[nPoint];; for (iPoint = 0; iPoint < nPoint; iPoint++) {; NewSort[iPoint] = iPoint;; }. unsigned long Index = OldnPoint-1;; for (iMarker = 0; iMarker < nMarker; iMarker++) {; if (bound[iMarker][0]->GetVTK_Type() == VERTEX) {; if (config->GetMarker_All_SendRecv(iMarker) < 0) {; for (iElem_Bound = 0; iElem_Bound < nElem_Bound[iMarker]; iElem_Bound++) {; if (bound[iMarker][iElem_Bound]->GetNode(0) < geometry->GetnPoint()) {; NewSort[bound[iMarker][iElem_Bound]->GetNode(0)] = Index;; NewSort[Index] = bound[iMarker][iElem_Bound]->GetNode(0);; Index--;; }; }; }; }; }. In order to sort the points, a list mapping the old points to the new points (NewSort) is created. The problem is that this list is sorted by switching nodes. But it doesn't switch around the contents of the list (i.e. two node numbers from the list). Instead it switched an index from the list and an actual node number pulled from the geometry. This presents two problems:. 1. If any of the receive nodes actually are at the end of the list",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358423989
https://github.com/su2code/SU2/issues/431#issuecomment-358423989:755,Availability,down,down,755,"Hi clarkpede,. Have you looked into the enhancement_periodicbc"" branch? I recall fixing many of these bugs there but not merging it to master because there are still a few more things that have to be taken care of. David. On Jan 17, 2018, at 7:30 AM, clarkpede <notifications@github.com<mailto:notifications@github.com>> wrote:. I've tracked down the source of the bug, and I'll submit a pull request later today. During the output of the periodic mesh in SU2_MSH, CPeriodicGeometry::SetMeshFile sorts the nodes into the order normal, receive, send. This can be found in lines 18798-18819 of Common/src/geometry_structure<https://github.com/su2code/SU2/blob/68991cd1005cf118e1ff21b8952bb366bb299cf3/Common/src/geometry_structure.cpp#L18798>. I've copied down the lines here for reference:. /*--- Change the numbering to guarantee that the all the receive; points are at the end of the file ---*/; unsigned long OldnPoint = geometry->GetnPoint();; unsigned long *NewSort = new unsigned long[nPoint];; for (iPoint = 0; iPoint < nPoint; iPoint++) {; NewSort[iPoint] = iPoint;; }. unsigned long Index = OldnPoint-1;; for (iMarker = 0; iMarker < nMarker; iMarker++) {; if (bound[iMarker][0]->GetVTK_Type() == VERTEX) {; if (config->GetMarker_All_SendRecv(iMarker) < 0) {; for (iElem_Bound = 0; iElem_Bound < nElem_Bound[iMarker]; iElem_Bound++) {; if (bound[iMarker][iElem_Bound]->GetNode(0) < geometry->GetnPoint()) {; NewSort[bound[iMarker][iElem_Bound]->GetNode(0)] = Index;; NewSort[Index] = bound[iMarker][iElem_Bound]->GetNode(0);; Index--;; }; }; }; }; }. In order to sort the points, a list mapping the old points to the new points (NewSort) is created. The problem is that this list is sorted by switching nodes. But it doesn't switch around the contents of the list (i.e. two node numbers from the list). Instead it switched an index from the list and an actual node number pulled from the geometry. This presents two problems:. 1. If any of the receive nodes actually are at the end of the list",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358423989
https://github.com/su2code/SU2/issues/431#issuecomment-358423989:2368,Availability,error,error,2368,"6bb299cf3/Common/src/geometry_structure.cpp#L18798>. I've copied down the lines here for reference:. /*--- Change the numbering to guarantee that the all the receive; points are at the end of the file ---*/; unsigned long OldnPoint = geometry->GetnPoint();; unsigned long *NewSort = new unsigned long[nPoint];; for (iPoint = 0; iPoint < nPoint; iPoint++) {; NewSort[iPoint] = iPoint;; }. unsigned long Index = OldnPoint-1;; for (iMarker = 0; iMarker < nMarker; iMarker++) {; if (bound[iMarker][0]->GetVTK_Type() == VERTEX) {; if (config->GetMarker_All_SendRecv(iMarker) < 0) {; for (iElem_Bound = 0; iElem_Bound < nElem_Bound[iMarker]; iElem_Bound++) {; if (bound[iMarker][iElem_Bound]->GetNode(0) < geometry->GetnPoint()) {; NewSort[bound[iMarker][iElem_Bound]->GetNode(0)] = Index;; NewSort[Index] = bound[iMarker][iElem_Bound]->GetNode(0);; Index--;; }; }; }; }; }. In order to sort the points, a list mapping the old points to the new points (NewSort) is created. The problem is that this list is sorted by switching nodes. But it doesn't switch around the contents of the list (i.e. two node numbers from the list). Instead it switched an index from the list and an actual node number pulled from the geometry. This presents two problems:. 1. If any of the receive nodes actually are at the end of the list, they will get switched away from the end of the list.; 2. If any node is switched twice, data is lost. That's because the sorting assumes that the elements being switched have not already been switched. This is how the three points went missing from the cube problem I previously referenced. If my write-up is too confusing, I can provide a play-by-play of how the error occurs. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/431#issuecomment-358340153>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AE_4SuB5X60MCplLjmFeVUIgSigM7xbrks5tLhH_gaJpZM4PE7sn>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358423989
https://github.com/su2code/SU2/issues/431#issuecomment-358423989:1220,Modifiability,config,config,1220,"om>> wrote:. I've tracked down the source of the bug, and I'll submit a pull request later today. During the output of the periodic mesh in SU2_MSH, CPeriodicGeometry::SetMeshFile sorts the nodes into the order normal, receive, send. This can be found in lines 18798-18819 of Common/src/geometry_structure<https://github.com/su2code/SU2/blob/68991cd1005cf118e1ff21b8952bb366bb299cf3/Common/src/geometry_structure.cpp#L18798>. I've copied down the lines here for reference:. /*--- Change the numbering to guarantee that the all the receive; points are at the end of the file ---*/; unsigned long OldnPoint = geometry->GetnPoint();; unsigned long *NewSort = new unsigned long[nPoint];; for (iPoint = 0; iPoint < nPoint; iPoint++) {; NewSort[iPoint] = iPoint;; }. unsigned long Index = OldnPoint-1;; for (iMarker = 0; iMarker < nMarker; iMarker++) {; if (bound[iMarker][0]->GetVTK_Type() == VERTEX) {; if (config->GetMarker_All_SendRecv(iMarker) < 0) {; for (iElem_Bound = 0; iElem_Bound < nElem_Bound[iMarker]; iElem_Bound++) {; if (bound[iMarker][iElem_Bound]->GetNode(0) < geometry->GetnPoint()) {; NewSort[bound[iMarker][iElem_Bound]->GetNode(0)] = Index;; NewSort[Index] = bound[iMarker][iElem_Bound]->GetNode(0);; Index--;; }; }; }; }; }. In order to sort the points, a list mapping the old points to the new points (NewSort) is created. The problem is that this list is sorted by switching nodes. But it doesn't switch around the contents of the list (i.e. two node numbers from the list). Instead it switched an index from the list and an actual node number pulled from the geometry. This presents two problems:. 1. If any of the receive nodes actually are at the end of the list, they will get switched away from the end of the list.; 2. If any node is switched twice, data is lost. That's because the sorting assumes that the elements being switched have not already been switched. This is how the three points went missing from the cube problem I previously referenced. If my write-up is too c",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358423989
https://github.com/su2code/SU2/issues/431#issuecomment-358538787:404,Integrability,rout,routines,404,"After realizing that SU2_MSH was only able to generate halo cells when the periodic BCs didn't share a common edge, @sravya91 and I went through the code that performs this task and fixed a few things to add this capability back. After fixing this we realized that there was an issue within the SU2_CFD when trying to run periodic BCs that touch each other. The issue was traced to the mpi communication routines, and since @economon was working on a revamp of this part of the code, we decided to wait until this was done. I am not sure what has been done here since, but I thought I should mention what has already been done in case you find it useful and can save you some time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358538787
https://github.com/su2code/SU2/issues/431#issuecomment-358538787:159,Performance,perform,performs,159,"After realizing that SU2_MSH was only able to generate halo cells when the periodic BCs didn't share a common edge, @sravya91 and I went through the code that performs this task and fixed a few things to add this capability back. After fixing this we realized that there was an issue within the SU2_CFD when trying to run periodic BCs that touch each other. The issue was traced to the mpi communication routines, and since @economon was working on a revamp of this part of the code, we decided to wait until this was done. I am not sure what has been done here since, but I thought I should mention what has already been done in case you find it useful and can save you some time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358538787
https://github.com/su2code/SU2/issues/431#issuecomment-358555075:747,Safety,avoid,avoid,747,"Ah. Well, pull request #500 should fix this bug, regardless. It's a single-purpose pull request that's ready to be merged in with the develop branch. That being said, it looks like the changes implemented in `enhancement_periodicbc` and `enhancement_periodicbc_paralleldraft` seem to encompass a lot of the other changes needed to fix periodic boundary conditions. Unfortunately, both branches are based off of v4.3 and seem to be a little rough (there's a lot of cout statements, commented out code, etc.). @demanosalvas, @sravya91, or @hlkline: Do you anticipate updating these branches in the next few months? Our group wants to run a few periodic problems, and we're currently trying to fix the bugs in the periodic implementation. We want to avoid duplicating effort if at all possible.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358555075
https://github.com/su2code/SU2/issues/431#issuecomment-358744678:656,Deployability,integrat,integrate,656,"@clarkpede: thanks for organizing - it would be great to have your help on this topic. I'll let the others comment on the status of those branches, but in general, we have 2 major issues:. 1. Numerous bugs in the creation of the initial periodic BCs and new mesh file generated by SU2_MSH (ordering, inability to treat adjacent periodic markers, e.g., triply-periodic cube, and others). The branches above contain some fixes, and we should also merge in your #500 too. 2. Runtime issues in SU2_CFD, especially in parallel. Some of these issues may be fixed by the branches above, but the second step is to create the periodic BCs on the fly in SU2_CFD and integrate properly with the parallel partitioning, removing the need to call SU2_MSH as a pre-processing. Once the clean up in 1 is finished (a lot of this searching and matching can be reused), and after the fix_partitioning branch is merged, we can start on this task. I am planning to work on this part.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358744678
https://github.com/su2code/SU2/issues/431#issuecomment-358744678:656,Integrability,integrat,integrate,656,"@clarkpede: thanks for organizing - it would be great to have your help on this topic. I'll let the others comment on the status of those branches, but in general, we have 2 major issues:. 1. Numerous bugs in the creation of the initial periodic BCs and new mesh file generated by SU2_MSH (ordering, inability to treat adjacent periodic markers, e.g., triply-periodic cube, and others). The branches above contain some fixes, and we should also merge in your #500 too. 2. Runtime issues in SU2_CFD, especially in parallel. Some of these issues may be fixed by the branches above, but the second step is to create the periodic BCs on the fly in SU2_CFD and integrate properly with the parallel partitioning, removing the need to call SU2_MSH as a pre-processing. Once the clean up in 1 is finished (a lot of this searching and matching can be reused), and after the fix_partitioning branch is merged, we can start on this task. I am planning to work on this part.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/431#issuecomment-358744678
https://github.com/su2code/SU2/pull/432#issuecomment-326204080:96,Usability,clear,clear,96,"Hi, this sounds very interesting!; I'll take the chance to raise a point: we still don't have a clear strategy to manage the output of multi-zone simulations. Indeed, earlier we used to have the residuals plotted for each zone (so we used to have a line for each zone), currently we just get the residuals corresponding to ZONE_0 (this was probably changed in one of the latest pull request, I think it could be the one from @salvovitale ). We should decide if to restore the previous ""multi-residual"" output or if to sum up residuals from each zone and print out the results.; Cause right now we can't know how the residuals are behaving in the rest of the domain.; We could perhaps create an additional ""special"" output to manage multi-zone computations. cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/432#issuecomment-326204080
https://github.com/su2code/SU2/pull/435#issuecomment-329400246:171,Modifiability,config,config,171,Maybe it makes more sense to have this changes in a separate branch for now ? This way we avoid potential problems for others in case there are some modifications of this config option necessary during the final implementation of the wall functions.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/435#issuecomment-329400246
https://github.com/su2code/SU2/pull/435#issuecomment-329400246:90,Safety,avoid,avoid,90,Maybe it makes more sense to have this changes in a separate branch for now ? This way we avoid potential problems for others in case there are some modifications of this config option necessary during the final implementation of the wall functions.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/435#issuecomment-329400246
https://github.com/su2code/SU2/pull/436#issuecomment-329063810:15,Usability,feedback,feedback,15,"Thanks for the feedback. The GitHub pages site is now the official project page, and the redirect has been put in place. Please let me know asap if any problems arise. @vdweide: yes, let's keep with our normal development process for the website, including PRs and code reviews, etc., in order to maintain quality and keep everyone informed. Lastly, if anyone is very interested in working on a website overhaul, please let us know.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/436#issuecomment-329063810
https://github.com/su2code/SU2/issues/437#issuecomment-328274125:855,Deployability,integrat,integrate,855,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125
https://github.com/su2code/SU2/issues/437#issuecomment-328274125:657,Integrability,interface,interface,657,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125
https://github.com/su2code/SU2/issues/437#issuecomment-328274125:855,Integrability,integrat,integrate,855,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125
https://github.com/su2code/SU2/issues/437#issuecomment-328274125:18,Usability,clear,clearly,18,"Dear @vdweide,. I clearly see your point. However, this can be quite a big structural change of the code and I think we should plan very well how to address this issue. The reason of having a driver class was to facilitate the extension of SU2 to multi-physics applications both for analysis (direct solver) and design (adjoint). Thanks to the high level of abstraction of the CInterpolator, CTransfer and the CIteration classes, it was kind of natural to treat fluid-fluid problems similarly to multi-physics problem (i.e. fluid-structure and fluid-heat). As a matter of fact, the multi-stage turbomachinery approach , its adjoint counterpart, the sliding interface they all rely on this driver structure in which we loop among all the zones. If i understood correctly, you suggest to move only the fluid-fluid multi-zone loop at lower level in order to integrate in time only after having coupled all the fluid zones. Right? If so, we need to design the code in such a way that the fluid zones loop is separated from the multi-physics one.; To solve this issue, I think, we just need to find a smart way to differentiate fluid-zones from the rest. Perhaps we can do that by instantiating one Iteration per physical problem instead than per zone. So that inside the iteration we can couple all the fluid zones, and in the driver we can couple the different physics (Iteration). Indeed, this is just a preliminary idea. In general I think we should aim to a structure that can flexibly accommodate multi-physics problems with multi-zones for different physics. A good example is solving fluid-structure in multi-stage turbomachinery, in which we have multiple fluid-zones and multiple structure-zones. ; ; I would like to hear on this matter also from @fpalacios @talbring , @economon , @rsanfer @oleburghardt ,@LaSerpe and @arubino. Thanks @vdweide againg for raising this issue. cheers. Salvo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328274125
https://github.com/su2code/SU2/issues/437#issuecomment-328302068:108,Usability,clear,clear,108,"Dear @salvovitale,. I realize that it requires significant changes in the code structure and I don't have a clear answer how to do this, also because I don't know all the details of the implementation of the multi-physics simulations. . The only thing I do know is that the loop over the zones must be inside the loop over the RK stages, at least for the fluid zones. Whether this is also the case for e.g. fluid-structure problems, I don't know. As you mentioned, the opinion of the other developers is greatly appreciated on this matter. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328302068
https://github.com/su2code/SU2/issues/437#issuecomment-328341372:213,Availability,down,down,213,"Dear @vdweide,. I do see your point as well, in fact I remember that I raised my concerns about this when the multi-physics driver started to be used for multi-zone, single physics problems. Unfortunately, moving down the loop in the zones would break the FSI solver, and also the FSI coupled adjoint solver that we have put together, so I have to advise otherwise. . When we first put together the Driver structure, the objective was to be able to fully converge different physical problems independently from each other. Then, the level of abstraction of the classes we implemented permitted for the structure to be used in fluid-fluid problems. CFD is not my top expertise, so the details escape to me, but it always seemed to me more natural to have an upper loop on the physics (the driver loop), and then have an internal loop over fluid zones. . That is pretty much the same idea as @salvovitale is proposing: keeping the Driver as is, for different physics, and incorporate inside the Iteration the loop over different zones in the fluid domain. This structure would address problems like Salvatore's example of multi-stage turbomachinery. Let's see what others think of this, happy to have a chat or a telecom over this. Kind regards,. Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328341372
https://github.com/su2code/SU2/issues/437#issuecomment-328368371:740,Deployability,integrat,integration,740,"Dear @rsanfer,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The ge",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
https://github.com/su2code/SU2/issues/437#issuecomment-328368371:1049,Deployability,Update,Update,1049,"be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
https://github.com/su2code/SU2/issues/437#issuecomment-328368371:1516,Deployability,integrat,integration,1516,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
https://github.com/su2code/SU2/issues/437#issuecomment-328368371:1751,Deployability,integrat,integration,1751,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
https://github.com/su2code/SU2/issues/437#issuecomment-328368371:740,Integrability,integrat,integration,740,"Dear @rsanfer,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The ge",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
https://github.com/su2code/SU2/issues/437#issuecomment-328368371:1516,Integrability,integrat,integration,1516,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
https://github.com/su2code/SU2/issues/437#issuecomment-328368371:1751,Integrability,integrat,integration,1751,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
https://github.com/su2code/SU2/issues/437#issuecomment-328368371:1666,Usability,simpl,simply,1666,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
https://github.com/su2code/SU2/issues/437#issuecomment-328368371:2226,Usability,clear,clearer,2226,"uch lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. - Loop over the number of iterations, or time steps for unsteady problems.; - Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; - Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate: ; - Loop over the (Runge-Kutta) stages; - Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; - End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; - End loop over the (Runge-Kutta) stages ; - End loop over the disciplines; - End loop over the pseudo time steps.; - End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. . Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328368371
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:680,Deployability,integrat,integrated,680,"All,. For whatever it is worth, here are some thoughts. It is clear that we need to strike the right level and hierarchy of abstraction: at the highest level one really ought to be describing the physical problem, not the number of zones or the specific time-stepping algorithm that would be used. But preventing future multi-zone calculations from reaching the (time) order of accuracy desired is also an important issue that SU2 must support (and that I think would be very important for those doing unsteady turbomachinery calculations). Just as important: even for multi-physics problems (say fluid-structure interaction, when the fluid and structural solvers are not closely integrated into the same source) we need to ensure that the time accuracy of the full multi-physics calculation is as high as those of the component physics solvers. This is a very valid and useful discussion and some proposals are on the table. Given that we are planning a developers meeting sometime before the end of the year, this may actually be one of the items in the agenda for discussion, so some decisions can be reached that both make sense and minimize the pain of changes for any part of the existing code. I would suggest that the conversation continue and that other proposals are put forward so the discussion can be finalized at the developers meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whethe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:2251,Deployability,integrat,integration,2251," and that other proposals are put forward so the discussion can be finalized at the developers meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the diff",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:2559,Deployability,Update,Update,2559," be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be define",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3025,Deployability,integrat,integration,3025,"uctures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3260,Deployability,integrat,integration,3260,"eps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxHiNAbZtzVEvIm0XDsNvQmZ6lrwwks5shEHjgaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:680,Integrability,integrat,integrated,680,"All,. For whatever it is worth, here are some thoughts. It is clear that we need to strike the right level and hierarchy of abstraction: at the highest level one really ought to be describing the physical problem, not the number of zones or the specific time-stepping algorithm that would be used. But preventing future multi-zone calculations from reaching the (time) order of accuracy desired is also an important issue that SU2 must support (and that I think would be very important for those doing unsteady turbomachinery calculations). Just as important: even for multi-physics problems (say fluid-structure interaction, when the fluid and structural solvers are not closely integrated into the same source) we need to ensure that the time accuracy of the full multi-physics calculation is as high as those of the component physics solvers. This is a very valid and useful discussion and some proposals are on the table. Given that we are planning a developers meeting sometime before the end of the year, this may actually be one of the items in the agenda for discussion, so some decisions can be reached that both make sense and minimize the pain of changes for any part of the existing code. I would suggest that the conversation continue and that other proposals are put forward so the discussion can be finalized at the developers meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whethe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:2251,Integrability,integrat,integration,2251," and that other proposals are put forward so the discussion can be finalized at the developers meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whether this is also the case for other disciplines, like structures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the diff",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3025,Integrability,integrat,integration,3025,"uctures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3260,Integrability,integrat,integration,3260,"eps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxHiNAbZtzVEvIm0XDsNvQmZ6lrwwks5shEHjgaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:62,Usability,clear,clear,62,"All,. For whatever it is worth, here are some thoughts. It is clear that we need to strike the right level and hierarchy of abstraction: at the highest level one really ought to be describing the physical problem, not the number of zones or the specific time-stepping algorithm that would be used. But preventing future multi-zone calculations from reaching the (time) order of accuracy desired is also an important issue that SU2 must support (and that I think would be very important for those doing unsteady turbomachinery calculations). Just as important: even for multi-physics problems (say fluid-structure interaction, when the fluid and structural solvers are not closely integrated into the same source) we need to ensure that the time accuracy of the full multi-physics calculation is as high as those of the component physics solvers. This is a very valid and useful discussion and some proposals are on the table. Given that we are planning a developers meeting sometime before the end of the year, this may actually be one of the items in the agenda for discussion, so some decisions can be reached that both make sense and minimize the pain of changes for any part of the existing code. I would suggest that the conversation continue and that other proposals are put forward so the discussion can be finalized at the developers meeting. Best,. Juan. On Sep 10, 2017, at 1:09 PM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Dear @rsanfer<https://github.com/rsanfer>,. I agree with you that the outer loop should be the loop over the number of physical disciplines involved in the problem and not the zones. Whether the individual disciplines contain one or multiple zones is irrelevant at this level, in my opinion. The loop over the multiple zones of a single discipline should take place at a much lower level, namely where the spatial residual is computed. At least, this should be the case for the fluid dynamics part. I don't know whethe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3175,Usability,simpl,simply,3175,"uctures. What about the following high level structure?. * Loop over the number of iterations, or time steps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328403160:3735,Usability,clear,clearer,3735,"eps for unsteady problems.; * Loop over the number of pseudo-time steps for implicit time integration schemes; (DT_STEPPING_1ST and DT_STEPPING_2ND). For other cases this loop is 1.; * Loop over the number of disciplines involved; Call iterate for each of the disciplines.; In iterate:; * Loop over the (Runge-Kutta) stages; * Loop over the zones of a single discipline; Compute spatial residual.; Update the state vector.; * End loop over the zones of a single discipline.; Exchange halo data. This includes the halo data between zones of a single discipline.; * End loop over the (Runge-Kutta) stages; * End loop over the disciplines; * End loop over the pseudo time steps.; * End loop over the number of iterations, or time steps for unsteady problems. The weakness of this approach is that it still does not work when one would like to employ multi-stage time integration schemes for an unsteady, multi-disciplinary problem (does not work for the current implementation either), but maybe this is something we simply have to accept. The alternative is that all the details of the different time integration schemes have to be moved to the driver classes, which is highly undesirable, I think. The structure above implies that the iteration_container and the integration_container should be defined per discipline and not per zone anymore. The geometry_container and solver_container should still be defined per zone. Well, I suppose this leaves plenty of room for discussion, so I would say to continue the online discussion a bit further, such that things become a bit clearer how to tackle this issue. After that having a telecon would be good to iron out the details. Regards,. Edwin. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-328368371>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxHiNAbZtzVEvIm0XDsNvQmZ6lrwwks5shEHjgaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328403160
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1925,Availability,avail,available,1925," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:81,Deployability,integrat,integration,81,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:281,Deployability,integrat,integration,281,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:356,Deployability,integrat,integration,356,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:631,Deployability,integrat,integration,631,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:744,Deployability,integrat,integration,744,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1599,Deployability,integrat,integration,1599," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1712,Deployability,integrat,integration,1712," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1893,Deployability,integrat,integration,1893," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:2205,Deployability,integrat,integration,2205," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:2293,Deployability,integrat,integration,2293," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:81,Integrability,integrat,integration,81,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:281,Integrability,integrat,integration,281,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:356,Integrability,integrat,integration,356,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:631,Integrability,integrat,integration,631,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:744,Integrability,integrat,integration,744,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1599,Integrability,integrat,integration,1599," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1712,Integrability,integrat,integration,1712," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1893,Integrability,integrat,integration,1893," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:2205,Integrability,integrat,integration,2205," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:2293,Integrability,integrat,integration,2293," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1012,Safety,predict,predictor,1012,"Juan,. Indeed, it is desirable that at the highest level the details of the time integration scheme and number of zones per discipline should not be visible. The question is whether that is achievable for all combinations you can think of. This is especially the case for the time integration schemes. E.g. suppose you would like to use a multi-stage time integration scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:1780,Usability,simpl,simply,1780," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-328441926:2136,Usability,clear,clear,2136," scheme for a multi-physics problem. To obtain the design accuracy in time, this implies that the loop over the number of time stages is outside the loop over the number of physical disciplines. Hence at a very high level in the hierarchy, the details of the time integration should then be known. The situation becomes even more complicated when one would like to employ time integration schemes that allow for time accurate local time stepping, e.g. the ones we are currently working on for the DG solver. I won't bore you with all the details here, but those schemes basically require the loop over the multiple disciplines to be between the predictor and corrector step, while both these steps consist of multiple stages. Although it is probably possible to come up with a data structure that supports all this, the question is whether this is desirable. Apart from the fact that it would require a major overhaul in the high level design of SU2, the implementation will be less readable, especially for people that will be starting with the code. Also the parallelization may become significantly more complicated. The alternative is that for unsteady multi-physics problems, we put the restriction that only single stage time integration schemes can be used, e.g. DT_STEPPING_1ST and DT_STEPPING_2ND. In that case, the details of the time integration scheme can be hidden at the driver level, where we then simply have a loop over the number of physical disciplines. The consequence of course is that more advanced time integration schemes will not be available for multi-physics problems. In the above I just tried to picture what, in my opinion, the consequences are for either option. I don't have a preference for one of them. The only thing I wanted to make clear is that it is not possible to hide all the details of the time integration scheme at the driver level, while also having support for all possible time integration schemes for an unsteady multi-physics problem. Regards,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-328441926
https://github.com/su2code/SU2/issues/437#issuecomment-329078418:145,Deployability,integrat,integration,145,"BTW, all of the above also applies for the grid motion parameters. This should also happen inside the loop over the number of stages of the time integration scheme and currently this is done outside this loop. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078418
https://github.com/su2code/SU2/issues/437#issuecomment-329078418:145,Integrability,integrat,integration,145,"BTW, all of the above also applies for the grid motion parameters. This should also happen inside the loop over the number of stages of the time integration scheme and currently this is done outside this loop. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078418
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:1680,Availability,down,down,1680,"s nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CIntegration classes could help here, and they are due for some updates anyway. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:256,Deployability,integrat,integration,256,"Hi all,. This is definitely good discussion... everything goes toward multi-physics nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CI",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:332,Deployability,release,released,332,"Hi all,. This is definitely good discussion... everything goes toward multi-physics nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CI",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:1438,Deployability,integrat,integration,1438,"s nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CIntegration classes could help here, and they are due for some updates anyway. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:1497,Deployability,release,release,1497,"s nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CIntegration classes could help here, and they are due for some updates anyway. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:1553,Deployability,update,update,1553,"s nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CIntegration classes could help here, and they are due for some updates anyway. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:2063,Deployability,update,updates,2063,"s nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CIntegration classes could help here, and they are due for some updates anyway. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:256,Integrability,integrat,integration,256,"Hi all,. This is definitely good discussion... everything goes toward multi-physics nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CI",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:1438,Integrability,integrat,integration,1438,"s nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CIntegration classes could help here, and they are due for some updates anyway. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329078585:1749,Modifiability,inherit,inheritance,1749,"s nowadays, so we should always be improving the class design accordingly. I suppose this will just get more important with adding more physics, zones, and more complex time integration schemes. I would like to highlight that when the code was first released, we did not have ""zones"" at all (not until some early sliding mesh work after a couple of versions), and the CDriver and CIteration classes didn't even exist until we dreamed them up a couple of years ago. My point is that, with some proper planning, we have the creativity and the right team to develop the solution we need, and we shouldn't be afraid to make big changes when necessary. Moving quickly while leveraging the team's broad skillset is one of our biggest advantages in this project. As you all know, over the years, we continue to move toward a *_structure.cpp and *_physics.cpp mindset for how we do our abstractions/data encapsulations, with ""structure"" components reused and ""physics"" components being specialized to a certain set of governing equations. This has happened in many places, including recently with the CTransfer class, for instance, and it is likely to happen with the COutput class(es) before long. However, one area where there hasn't been much evolution is within the CIntegration classes. Apart from a couple of additions for structural problems and now the DG integration, it is largely the same as it was in the first release. Perhaps this is our opportunity to rethink and update these classes for future expansion, just as we've done for others over the years. We could rework them, move them up or down in the hierarchy, change where they're instantiated, change the inheritance, and so on. Even if they get a little more complicated (like usual), as long as they're properly abstracted, it isn't likely to bother the developers working in other areas of the code too much. In short, I think some effort spent on the CIntegration classes could help here, and they are due for some updates anyway. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329078585
https://github.com/su2code/SU2/issues/437#issuecomment-329096830:109,Deployability,integrat,integration,109,"Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329096830
https://github.com/su2code/SU2/issues/437#issuecomment-329096830:109,Integrability,integrat,integration,109,"Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329096830
https://github.com/su2code/SU2/issues/437#issuecomment-329096830:233,Usability,simpl,simply,233,"Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329096830
https://github.com/su2code/SU2/issues/437#issuecomment-329146567:1347,Deployability,integrat,integration,1347,"output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqPPMuaDziLuDRzWCJfYwrks5sh5KagaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
https://github.com/su2code/SU2/issues/437#issuecomment-329146567:735,Energy Efficiency,charge,charge,735,"Hi all,. as with the restructuring of the output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqP",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
https://github.com/su2code/SU2/issues/437#issuecomment-329146567:1347,Integrability,integrat,integration,1347,"output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqPPMuaDziLuDRzWCJfYwrks5sh5KagaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
https://github.com/su2code/SU2/issues/437#issuecomment-329146567:306,Modifiability,coupling,coupling,306,"Hi all,. as with the restructuring of the output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqP",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
https://github.com/su2code/SU2/issues/437#issuecomment-329146567:1471,Usability,simpl,simply,1471,"output classes, we should find a common level of abstraction for all the different physical problems we might want to have. Right now there isn't even a unified way of specifying the kind of problem for each zone (what is fluid, what is solid etc) and the kind of coupling. This might also affect the actual implementation/restructuring since we somehow have to decide what driver we have to instantiate and so on. Hopefully we can gather all the people involved to have a discussion on that. Since we have a lot of people working in their branches on multizone problems we should tackle that better sooner than later. As Edwin already suggested, maybe it is a good idea to put some people in charge of organizing some of the bigger structural changes. Furthermore in case some people don't know, we have a slack channel for the dev team. I think that makes it easier to communicate, arrange meetings, discuss problems and ask questions. In case you need an invite, let me know, everybody who wants to contribute is welcome. Thanks for the discussion, I still think that communication is the key of success !. Tim. On Sep 13, 2017 10:30 AM, Edwin van der Weide <notifications@github.com> wrote:. Hi Tom,. Sounds like a plan then to have a look at CIntegration to see what we can do to generalize the time integration. I definitely want to help with this, but I don't think I am the appropriate person to take the lead, because I simply don't have a good overview of all the multi-physics options. Tom, are you willing to take the lead for this?. Furthermore, it is good to have other people involved as well, preferably with detailed knowledge of the different disciplines. Any volunteers?. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/437#issuecomment-329096830>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5MkXdqhqPPMuaDziLuDRzWCJfYwrks5sh5KagaJpZM4PQ90s>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/437#issuecomment-329146567
https://github.com/su2code/SU2/pull/441#issuecomment-329835608:50,Safety,avoid,avoided,50,"Yes, there are some warnings there. I have mostly avoided the Tecplot ones with ""-Wno-unused-parameter."" We could also contact the developers of those two packages directly (CGNS is now on GitHub).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/441#issuecomment-329835608
https://github.com/su2code/SU2/pull/443#issuecomment-331645981:221,Deployability,update,update,221,"Hi, thanks a lot for contributing, this is a very interesting and useful implementation. . Unfortunately something strange has happened with the git diff tool and the merging is not possible... it seems that is trying to update the driver subroutine with an old version of SU2. I'm very sorry about this but, would you be so kind to reimplement the changes in a clean copy of the developer's branch? so... only the relevant changes of your implementation will be added to SU2?. Just to check that nobody if going to break your implementation. In this case, I think it is also important to add a regression test. Could you please add one example that travis can control?. Thanks a lot for your hard work!. Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/443#issuecomment-331645981
https://github.com/su2code/SU2/pull/443#issuecomment-331645981:606,Testability,test,test,606,"Hi, thanks a lot for contributing, this is a very interesting and useful implementation. . Unfortunately something strange has happened with the git diff tool and the merging is not possible... it seems that is trying to update the driver subroutine with an old version of SU2. I'm very sorry about this but, would you be so kind to reimplement the changes in a clean copy of the developer's branch? so... only the relevant changes of your implementation will be added to SU2?. Just to check that nobody if going to break your implementation. In this case, I think it is also important to add a regression test. Could you please add one example that travis can control?. Thanks a lot for your hard work!. Best,; Francisco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/443#issuecomment-331645981
https://github.com/su2code/SU2/pull/443#issuecomment-331681951:23,Deployability,update,updated,23,"I will try to get that updated in the next few days. I think I am pulling from develop branch, but the build keeps failing. I originally was modifying an older version of SU2 on my computer then pasting changes into development branch so I will make sure the changes work with the current develop branch and retry. I am new to github. I will work on regression test after that. I had been testing the NACA 64a010 test case currently used for harmonic balance. The method improves max CFL from about 1.0 to at least 4.0. I have not checked higher numbers. Is it better to add a different case for regression, pitching NACA 0012 for example? . Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/443#issuecomment-331681951
https://github.com/su2code/SU2/pull/443#issuecomment-331681951:361,Testability,test,test,361,"I will try to get that updated in the next few days. I think I am pulling from develop branch, but the build keeps failing. I originally was modifying an older version of SU2 on my computer then pasting changes into development branch so I will make sure the changes work with the current develop branch and retry. I am new to github. I will work on regression test after that. I had been testing the NACA 64a010 test case currently used for harmonic balance. The method improves max CFL from about 1.0 to at least 4.0. I have not checked higher numbers. Is it better to add a different case for regression, pitching NACA 0012 for example? . Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/443#issuecomment-331681951
https://github.com/su2code/SU2/pull/443#issuecomment-331681951:389,Testability,test,testing,389,"I will try to get that updated in the next few days. I think I am pulling from develop branch, but the build keeps failing. I originally was modifying an older version of SU2 on my computer then pasting changes into development branch so I will make sure the changes work with the current develop branch and retry. I am new to github. I will work on regression test after that. I had been testing the NACA 64a010 test case currently used for harmonic balance. The method improves max CFL from about 1.0 to at least 4.0. I have not checked higher numbers. Is it better to add a different case for regression, pitching NACA 0012 for example? . Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/443#issuecomment-331681951
https://github.com/su2code/SU2/pull/443#issuecomment-331681951:413,Testability,test,test,413,"I will try to get that updated in the next few days. I think I am pulling from develop branch, but the build keeps failing. I originally was modifying an older version of SU2 on my computer then pasting changes into development branch so I will make sure the changes work with the current develop branch and retry. I am new to github. I will work on regression test after that. I had been testing the NACA 64a010 test case currently used for harmonic balance. The method improves max CFL from about 1.0 to at least 4.0. I have not checked higher numbers. Is it better to add a different case for regression, pitching NACA 0012 for example? . Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/443#issuecomment-331681951
https://github.com/su2code/SU2/pull/444#issuecomment-331841826:115,Availability,avail,available,115,Thanks for the improvements! Just a quick suggestion: maybe we should use for the distance computation the already available ADT structure ? Just have a look at CPhysicalGeometry::ComputeWall_Distance on how to use it. Should be more or less a simple copy/paste.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-331841826
https://github.com/su2code/SU2/pull/444#issuecomment-331841826:244,Usability,simpl,simple,244,Thanks for the improvements! Just a quick suggestion: maybe we should use for the distance computation the already available ADT structure ? Just have a look at CPhysicalGeometry::ComputeWall_Distance on how to use it. Should be more or less a simple copy/paste.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-331841826
https://github.com/su2code/SU2/pull/444#issuecomment-332825983:17,Deployability,update,update,17,You just have to update the files in the TestCases repository (`TestCases/cont_adj_euler/naca0012/of_grad_directdiff.dat.ref` and `TestCases/cont_adj_euler/naca0012/of_grad_cd_disc.dat.ref`),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-332825983
https://github.com/su2code/SU2/pull/444#issuecomment-332825983:41,Testability,Test,TestCases,41,You just have to update the files in the TestCases repository (`TestCases/cont_adj_euler/naca0012/of_grad_directdiff.dat.ref` and `TestCases/cont_adj_euler/naca0012/of_grad_cd_disc.dat.ref`),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-332825983
https://github.com/su2code/SU2/pull/444#issuecomment-332825983:64,Testability,Test,TestCases,64,You just have to update the files in the TestCases repository (`TestCases/cont_adj_euler/naca0012/of_grad_directdiff.dat.ref` and `TestCases/cont_adj_euler/naca0012/of_grad_cd_disc.dat.ref`),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-332825983
https://github.com/su2code/SU2/pull/444#issuecomment-332825983:131,Testability,Test,TestCases,131,You just have to update the files in the TestCases repository (`TestCases/cont_adj_euler/naca0012/of_grad_directdiff.dat.ref` and `TestCases/cont_adj_euler/naca0012/of_grad_cd_disc.dat.ref`),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/444#issuecomment-332825983
https://github.com/su2code/SU2/pull/445#issuecomment-332057827:328,Testability,test,test,328,It looks like changes have gone through for driver_structure.hpp and driver_structure.cpp. I am not sure how to remove the previous commits that failed. It also appears a .hpp got placed in the src directory that needs to be removed. Preconditioning is called automatically for HB cases in this setup. The current HB regression test may therefore be sufficient. If preconditioning should be an option in the cfg file instead I will leave open to discussion.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-332057827
https://github.com/su2code/SU2/pull/445#issuecomment-335467032:137,Testability,test,test,137,I believe this request is fixed with requested changes and white space removed. I have added a grid file and .cfg file to the respective test case repositories. I am not sure where to add a solution file if this is to become a regression test. Jason,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-335467032
https://github.com/su2code/SU2/pull/445#issuecomment-335467032:238,Testability,test,test,238,I believe this request is fixed with requested changes and white space removed. I have added a grid file and .cfg file to the respective test case repositories. I am not sure where to add a solution file if this is to become a regression test. Jason,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-335467032
https://github.com/su2code/SU2/pull/445#issuecomment-335889541:38,Testability,test,test-case,38,"Thanks, Jason! Can you please add the test-case in the python scripts for the regression test? You can find them in the TestCases folder.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-335889541
https://github.com/su2code/SU2/pull/445#issuecomment-335889541:89,Testability,test,test,89,"Thanks, Jason! Can you please add the test-case in the python scripts for the regression test? You can find them in the TestCases folder.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-335889541
https://github.com/su2code/SU2/pull/445#issuecomment-335889541:120,Testability,Test,TestCases,120,"Thanks, Jason! Can you please add the test-case in the python scripts for the regression test? You can find them in the TestCases folder.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-335889541
https://github.com/su2code/SU2/pull/445#issuecomment-335937240:396,Testability,test,test,396,I think I see how the regressions work now. I was thinking the cases were restarted from a converged solution. It looks as though the regression works by comparing the results after a set number of iterations from a non-restart case? That means the values I need to enter into the python script are the residuals and lift/drag coefficients after that number of iterations I set in the regression test?. Jason,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-335937240
https://github.com/su2code/SU2/pull/445#issuecomment-336911792:47,Availability,error,error,47,"Hi Jason, Travis is failing with the following error:. ``` ; File ""serial_regression.py"", line 1116, in <module>; main(); File ""serial_regression.py"", line 508, in main; test_list.append(turbulent_hb); NameError: global name 'turbulent_hb' is not defined; ```. are you addressing this?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-336911792
https://github.com/su2code/SU2/pull/445#issuecomment-336948272:43,Availability,error,error,43,"Antonio,. I have been trying to figure the error message out, but I have been unsuccessful. I've only modified serial_regression.py and parallel_regression.py. Is there a file where turbulent_hb needs to be defined or does the code read the names from the test case repository?. We may want to change structure of HB test case folder since there are now two cases. The turbulent case has a sub-directory in there but the inviscid does not. Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-336948272
https://github.com/su2code/SU2/pull/445#issuecomment-336948272:49,Integrability,message,message,49,"Antonio,. I have been trying to figure the error message out, but I have been unsuccessful. I've only modified serial_regression.py and parallel_regression.py. Is there a file where turbulent_hb needs to be defined or does the code read the names from the test case repository?. We may want to change structure of HB test case folder since there are now two cases. The turbulent case has a sub-directory in there but the inviscid does not. Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-336948272
https://github.com/su2code/SU2/pull/445#issuecomment-336948272:256,Testability,test,test,256,"Antonio,. I have been trying to figure the error message out, but I have been unsuccessful. I've only modified serial_regression.py and parallel_regression.py. Is there a file where turbulent_hb needs to be defined or does the code read the names from the test case repository?. We may want to change structure of HB test case folder since there are now two cases. The turbulent case has a sub-directory in there but the inviscid does not. Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-336948272
https://github.com/su2code/SU2/pull/445#issuecomment-336948272:317,Testability,test,test,317,"Antonio,. I have been trying to figure the error message out, but I have been unsuccessful. I've only modified serial_regression.py and parallel_regression.py. Is there a file where turbulent_hb needs to be defined or does the code read the names from the test case repository?. We may want to change structure of HB test case folder since there are now two cases. The turbulent case has a sub-directory in there but the inviscid does not. Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-336948272
https://github.com/su2code/SU2/pull/445#issuecomment-337577313:274,Security,access,access,274,"Antonio,. We will see if this check passes with corrections to .py files, but the mesh file is sitting in a pull request in TestCases repository. I could not add to that repository as part of this pull request. I have a feeling both checks are going to fail unless they can access each other. Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-337577313
https://github.com/su2code/SU2/pull/445#issuecomment-337577313:124,Testability,Test,TestCases,124,"Antonio,. We will see if this check passes with corrections to .py files, but the mesh file is sitting in a pull request in TestCases repository. I could not add to that repository as part of this pull request. I have a feeling both checks are going to fail unless they can access each other. Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-337577313
https://github.com/su2code/SU2/pull/445#issuecomment-339132520:29,Testability,test,test,29,"@economon for the regression test of this PR travis in failing in the TestCases repository, I guess for time limit. Do they have different time limits?. I would propose to merge that PR https://github.com/su2code/TestCases/pull/17) so that we can close this one once the reg test is passing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-339132520
https://github.com/su2code/SU2/pull/445#issuecomment-339132520:70,Testability,Test,TestCases,70,"@economon for the regression test of this PR travis in failing in the TestCases repository, I guess for time limit. Do they have different time limits?. I would propose to merge that PR https://github.com/su2code/TestCases/pull/17) so that we can close this one once the reg test is passing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-339132520
https://github.com/su2code/SU2/pull/445#issuecomment-339132520:213,Testability,Test,TestCases,213,"@economon for the regression test of this PR travis in failing in the TestCases repository, I guess for time limit. Do they have different time limits?. I would propose to merge that PR https://github.com/su2code/TestCases/pull/17) so that we can close this one once the reg test is passing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-339132520
https://github.com/su2code/SU2/pull/445#issuecomment-339132520:275,Testability,test,test,275,"@economon for the regression test of this PR travis in failing in the TestCases repository, I guess for time limit. Do they have different time limits?. I would propose to merge that PR https://github.com/su2code/TestCases/pull/17) so that we can close this one once the reg test is passing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-339132520
https://github.com/su2code/SU2/pull/445#issuecomment-339155498:35,Testability,test,test,35,"I will caution that the regression test that I added related to this pull has yet to actually run. I don't know why it is running out of time, but it would be good to see it actually pass before merging. I don't know how to force a retry. Jason",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-339155498
https://github.com/su2code/SU2/pull/445#issuecomment-341049765:4,Deployability,update,update,4,Any update or help needed here to close this PR?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-341049765
https://github.com/su2code/SU2/pull/445#issuecomment-342591090:224,Testability,test,tests,224,"@jhowison : thanks for the extra effort to clean things up. It is very important to have community involvement, and it's a very nice contribution! Nice to see you and @arubino work together on this too. We'll merge once the tests pass.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/445#issuecomment-342591090
https://github.com/su2code/SU2/issues/447#issuecomment-332762075:251,Availability,error,error,251,"Indeed thats a bug when you enable the python wrapper... I am gonna solve this soon. For the time being just compile the normal and AD binaries separately by going to SU2_BASE and SU2_AD and `run make install` in each of them. You should see the same error again in SU2_AD, but you can ignore it, everything should have been compiled fine. Best,; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332762075
https://github.com/su2code/SU2/issues/447#issuecomment-332762075:201,Deployability,install,install,201,"Indeed thats a bug when you enable the python wrapper... I am gonna solve this soon. For the time being just compile the normal and AD binaries separately by going to SU2_BASE and SU2_AD and `run make install` in each of them. You should see the same error again in SU2_AD, but you can ignore it, everything should have been compiled fine. Best,; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332762075
https://github.com/su2code/SU2/issues/447#issuecomment-332762075:46,Integrability,wrap,wrapper,46,"Indeed thats a bug when you enable the python wrapper... I am gonna solve this soon. For the time being just compile the normal and AD binaries separately by going to SU2_BASE and SU2_AD and `run make install` in each of them. You should see the same error again in SU2_AD, but you can ignore it, everything should have been compiled fine. Best,; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332762075
https://github.com/su2code/SU2/issues/447#issuecomment-332764044:15,Deployability,update,update,15,"Thanks for the update - I'll give it a go and get back to you. Are there any tests I can run to check functionality once complete? . Kind regards,; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332764044
https://github.com/su2code/SU2/issues/447#issuecomment-332764044:77,Testability,test,tests,77,"Thanks for the update - I'll give it a go and get back to you. Are there any tests I can run to check functionality once complete? . Kind regards,; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332764044
https://github.com/su2code/SU2/issues/447#issuecomment-332766903:17,Deployability,install,install,17,"For the SU2 make install, I did not manage to successfully complete the installation, I've attached the output in the text file. Meanwhile, I'll the give AD build a go. Thanks again.; [BASE_make_install_error.txt](https://github.com/su2code/SU2/files/1340083/BASE_make_install_error.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332766903
https://github.com/su2code/SU2/issues/447#issuecomment-332766903:72,Deployability,install,installation,72,"For the SU2 make install, I did not manage to successfully complete the installation, I've attached the output in the text file. Meanwhile, I'll the give AD build a go. Thanks again.; [BASE_make_install_error.txt](https://github.com/su2code/SU2/files/1340083/BASE_make_install_error.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332766903
https://github.com/su2code/SU2/issues/447#issuecomment-332767525:7,Deployability,install,install,7,The AD install also seems to have failed - did both actually 'successfully' install? . [AD_make_install_error.txt](https://github.com/su2code/SU2/files/1340097/AD_make_install_error.txt),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332767525
https://github.com/su2code/SU2/issues/447#issuecomment-332767525:76,Deployability,install,install,76,The AD install also seems to have failed - did both actually 'successfully' install? . [AD_make_install_error.txt](https://github.com/su2code/SU2/files/1340097/AD_make_install_error.txt),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332767525
https://github.com/su2code/SU2/issues/447#issuecomment-332771355:19,Availability,error,error,19,If you look at the error in SU2_BASE it says `Error: Unable to find 'mpi4py/mpi4py.i'`. It seems like mpi4py is not properly installed on your machine. The error in SU2_AD can be ignored.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332771355
https://github.com/su2code/SU2/issues/447#issuecomment-332771355:46,Availability,Error,Error,46,If you look at the error in SU2_BASE it says `Error: Unable to find 'mpi4py/mpi4py.i'`. It seems like mpi4py is not properly installed on your machine. The error in SU2_AD can be ignored.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332771355
https://github.com/su2code/SU2/issues/447#issuecomment-332771355:156,Availability,error,error,156,If you look at the error in SU2_BASE it says `Error: Unable to find 'mpi4py/mpi4py.i'`. It seems like mpi4py is not properly installed on your machine. The error in SU2_AD can be ignored.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332771355
https://github.com/su2code/SU2/issues/447#issuecomment-332771355:125,Deployability,install,installed,125,If you look at the error in SU2_BASE it says `Error: Unable to find 'mpi4py/mpi4py.i'`. It seems like mpi4py is not properly installed on your machine. The error in SU2_AD can be ignored.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332771355
https://github.com/su2code/SU2/issues/447#issuecomment-332791823:294,Deployability,install,installed,294,"Indeed, the compilation with AD support is not compatible with the Python wrapper yet. If you are not interested in using the wrapper, just remove the --enable-PY_WRAPPER option and it should be OK. In general, if you want to compile SU2 with the wrapper in parallel, mpi4py has to be properly installed on your system. As the wiki says, the easiest way to install it is by using python-pip (example for Linux).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332791823
https://github.com/su2code/SU2/issues/447#issuecomment-332791823:357,Deployability,install,install,357,"Indeed, the compilation with AD support is not compatible with the Python wrapper yet. If you are not interested in using the wrapper, just remove the --enable-PY_WRAPPER option and it should be OK. In general, if you want to compile SU2 with the wrapper in parallel, mpi4py has to be properly installed on your system. As the wiki says, the easiest way to install it is by using python-pip (example for Linux).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332791823
https://github.com/su2code/SU2/issues/447#issuecomment-332791823:74,Integrability,wrap,wrapper,74,"Indeed, the compilation with AD support is not compatible with the Python wrapper yet. If you are not interested in using the wrapper, just remove the --enable-PY_WRAPPER option and it should be OK. In general, if you want to compile SU2 with the wrapper in parallel, mpi4py has to be properly installed on your system. As the wiki says, the easiest way to install it is by using python-pip (example for Linux).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332791823
https://github.com/su2code/SU2/issues/447#issuecomment-332791823:126,Integrability,wrap,wrapper,126,"Indeed, the compilation with AD support is not compatible with the Python wrapper yet. If you are not interested in using the wrapper, just remove the --enable-PY_WRAPPER option and it should be OK. In general, if you want to compile SU2 with the wrapper in parallel, mpi4py has to be properly installed on your system. As the wiki says, the easiest way to install it is by using python-pip (example for Linux).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332791823
https://github.com/su2code/SU2/issues/447#issuecomment-332791823:247,Integrability,wrap,wrapper,247,"Indeed, the compilation with AD support is not compatible with the Python wrapper yet. If you are not interested in using the wrapper, just remove the --enable-PY_WRAPPER option and it should be OK. In general, if you want to compile SU2 with the wrapper in parallel, mpi4py has to be properly installed on your system. As the wiki says, the easiest way to install it is by using python-pip (example for Linux).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-332791823
https://github.com/su2code/SU2/issues/447#issuecomment-333029447:151,Availability,error,error,151,Thanks for your thoughts. I've been working on the mpi4py install [here](https://bitbucket.org/mpi4py/mpi4py/issues/78/openmpi-based-mpi4py-runtestspy-error) and I thought I had finally installed mpi4py correctly. I can see the missing file located in `~/anaconda3/lib/python3.6/site-packages/mpi4py/include/mpi4py/mpi4py.i` - is there a flag I can set in the install script to direct the installer there? Thanks.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333029447
https://github.com/su2code/SU2/issues/447#issuecomment-333029447:58,Deployability,install,install,58,Thanks for your thoughts. I've been working on the mpi4py install [here](https://bitbucket.org/mpi4py/mpi4py/issues/78/openmpi-based-mpi4py-runtestspy-error) and I thought I had finally installed mpi4py correctly. I can see the missing file located in `~/anaconda3/lib/python3.6/site-packages/mpi4py/include/mpi4py/mpi4py.i` - is there a flag I can set in the install script to direct the installer there? Thanks.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333029447
https://github.com/su2code/SU2/issues/447#issuecomment-333029447:186,Deployability,install,installed,186,Thanks for your thoughts. I've been working on the mpi4py install [here](https://bitbucket.org/mpi4py/mpi4py/issues/78/openmpi-based-mpi4py-runtestspy-error) and I thought I had finally installed mpi4py correctly. I can see the missing file located in `~/anaconda3/lib/python3.6/site-packages/mpi4py/include/mpi4py/mpi4py.i` - is there a flag I can set in the install script to direct the installer there? Thanks.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333029447
https://github.com/su2code/SU2/issues/447#issuecomment-333029447:360,Deployability,install,install,360,Thanks for your thoughts. I've been working on the mpi4py install [here](https://bitbucket.org/mpi4py/mpi4py/issues/78/openmpi-based-mpi4py-runtestspy-error) and I thought I had finally installed mpi4py correctly. I can see the missing file located in `~/anaconda3/lib/python3.6/site-packages/mpi4py/include/mpi4py/mpi4py.i` - is there a flag I can set in the install script to direct the installer there? Thanks.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333029447
https://github.com/su2code/SU2/issues/447#issuecomment-333029447:389,Deployability,install,installer,389,Thanks for your thoughts. I've been working on the mpi4py install [here](https://bitbucket.org/mpi4py/mpi4py/issues/78/openmpi-based-mpi4py-runtestspy-error) and I thought I had finally installed mpi4py correctly. I can see the missing file located in `~/anaconda3/lib/python3.6/site-packages/mpi4py/include/mpi4py/mpi4py.i` - is there a flag I can set in the install script to direct the installer there? Thanks.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333029447
https://github.com/su2code/SU2/issues/447#issuecomment-333042668:49,Deployability,install,installation,49,"I've realised that it might be because my mpi4py installation is within python 3.6.; preconfigure.py seemed to be written python 2.7 but now I think of it, I had not installed mpi4py for my python 2.7 install. Can I use the python2to3 tool and run preconfigure.py using python 3? Or would it be better to set up a separate python 2.7 environment?. Eventually, I want to couple SU2 and I was planning on doing so in a python 3 environment. Thanks for the suggestions!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333042668
https://github.com/su2code/SU2/issues/447#issuecomment-333042668:166,Deployability,install,installed,166,"I've realised that it might be because my mpi4py installation is within python 3.6.; preconfigure.py seemed to be written python 2.7 but now I think of it, I had not installed mpi4py for my python 2.7 install. Can I use the python2to3 tool and run preconfigure.py using python 3? Or would it be better to set up a separate python 2.7 environment?. Eventually, I want to couple SU2 and I was planning on doing so in a python 3 environment. Thanks for the suggestions!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333042668
https://github.com/su2code/SU2/issues/447#issuecomment-333042668:201,Deployability,install,install,201,"I've realised that it might be because my mpi4py installation is within python 3.6.; preconfigure.py seemed to be written python 2.7 but now I think of it, I had not installed mpi4py for my python 2.7 install. Can I use the python2to3 tool and run preconfigure.py using python 3? Or would it be better to set up a separate python 2.7 environment?. Eventually, I want to couple SU2 and I was planning on doing so in a python 3 environment. Thanks for the suggestions!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333042668
https://github.com/su2code/SU2/issues/447#issuecomment-333100920:229,Modifiability,variab,variable,229,The problem is that the path where automake looks for mpi4py is hardcoded at the moment. This will also eventually be changed soon. . A workaround is to add the path manually in `SU2_PY/pySU2/Makefile.am` to the `MPI4PY_INCLUDE` variable. Then run `automake` in the main folder and then the preconfigure script again.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333100920
https://github.com/su2code/SU2/issues/447#issuecomment-333103775:22,Integrability,wrap,wrapper,22,"Concerning the Python wrapper, everything is currently hardcoded for python2.7 which was my Python environment when I originally introduced the wrapper. PR #424 is fixing this. In the meantime, the workaround proposed by @talbring should work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333103775
https://github.com/su2code/SU2/issues/447#issuecomment-333103775:144,Integrability,wrap,wrapper,144,"Concerning the Python wrapper, everything is currently hardcoded for python2.7 which was my Python environment when I originally introduced the wrapper. PR #424 is fixing this. In the meantime, the workaround proposed by @talbring should work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333103775
https://github.com/su2code/SU2/issues/447#issuecomment-333444892:139,Deployability,install,install,139,"Hello, thanks for the comments. Can I just clarify that the workaround steps are:; 1. Add the path to `SU2_PY/pySU2/Makefile.am`; 2. `make install` (not sure which you mean by `automake`); 3. `make distclean`; 4. `export CXXFLAGS=""-O3"" && python2.7 ./preconfigure.py --enable-autodiff ...` with all options; 5. Navigate to `SU_BASE` and `SU_AD` and `make install` in each. Is that correct? Many thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333444892
https://github.com/su2code/SU2/issues/447#issuecomment-333444892:355,Deployability,install,install,355,"Hello, thanks for the comments. Can I just clarify that the workaround steps are:; 1. Add the path to `SU2_PY/pySU2/Makefile.am`; 2. `make install` (not sure which you mean by `automake`); 3. `make distclean`; 4. `export CXXFLAGS=""-O3"" && python2.7 ./preconfigure.py --enable-autodiff ...` with all options; 5. Navigate to `SU_BASE` and `SU_AD` and `make install` in each. Is that correct? Many thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333444892
https://github.com/su2code/SU2/issues/447#issuecomment-333460280:277,Deployability,install,install,277,"I looked up automake, compiled and ran automake-1.12.5 in the place of step 2:; `cd /opt/SU2/SU2v5.0.0_src && /opt/automake/automake-1.12.5/bin/automake-1.12`. It didn't give any confirmation but I assumed it worked as I can see the path was added when attempting to run `make install` in `SU_BASE`. However, it still does not seem to find the file, although I can see the file in that location. I've attached the final part of the output:; [BASE_make_install_error2.txt](https://github.com/su2code/SU2/files/1348152/BASE_make_install_error2.txt). Although when I run ` ls ~/anaconda3/envs/su2/lib/python2.7/site-packages/mpi4py/include/mpi4py/`, I see: `mpi4py.h mpi4py.i mpi4py.MPI_api.h mpi4py.MPI.h mpi.pxi`. Is there anything else which may be causing this issue? Many thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333460280
https://github.com/su2code/SU2/issues/447#issuecomment-333473465:41,Deployability,install,install,41,"Sorry - in my haste, I missed that...the install now finds mpi4py just fine. Thanks for the help. On another note, the `make install` fails when searching for what looks a tecplot-related file (output attached [BASE_make_install_error3.txt](https://github.com/su2code/SU2/files/1348289/BASE_make_install_error3.txt) ). This isn't surprising as I don't have Techplot installed but I also did not set the `--enable-tecio` flag with `preconfigure.py`. Is there a way I can turn this off? Thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333473465
https://github.com/su2code/SU2/issues/447#issuecomment-333473465:125,Deployability,install,install,125,"Sorry - in my haste, I missed that...the install now finds mpi4py just fine. Thanks for the help. On another note, the `make install` fails when searching for what looks a tecplot-related file (output attached [BASE_make_install_error3.txt](https://github.com/su2code/SU2/files/1348289/BASE_make_install_error3.txt) ). This isn't surprising as I don't have Techplot installed but I also did not set the `--enable-tecio` flag with `preconfigure.py`. Is there a way I can turn this off? Thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333473465
https://github.com/su2code/SU2/issues/447#issuecomment-333473465:366,Deployability,install,installed,366,"Sorry - in my haste, I missed that...the install now finds mpi4py just fine. Thanks for the help. On another note, the `make install` fails when searching for what looks a tecplot-related file (output attached [BASE_make_install_error3.txt](https://github.com/su2code/SU2/files/1348289/BASE_make_install_error3.txt) ). This isn't surprising as I don't have Techplot installed but I also did not set the `--enable-tecio` flag with `preconfigure.py`. Is there a way I can turn this off? Thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333473465
https://github.com/su2code/SU2/issues/447#issuecomment-333753697:212,Availability,error,error,212,Thanks for that - I didn't realise that my copy of emacs was doing the replace on saving. I made the edit then reran the above steps. It seems that SU2_BASE now installs fine and SU2_AD only presents the initial error. I assume this means SU2 is up and running? I'll try some test cases to confirm. Thanks for the support!,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333753697
https://github.com/su2code/SU2/issues/447#issuecomment-333753697:161,Deployability,install,installs,161,Thanks for that - I didn't realise that my copy of emacs was doing the replace on saving. I made the edit then reran the above steps. It seems that SU2_BASE now installs fine and SU2_AD only presents the initial error. I assume this means SU2 is up and running? I'll try some test cases to confirm. Thanks for the support!,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333753697
https://github.com/su2code/SU2/issues/447#issuecomment-333753697:276,Testability,test,test,276,Thanks for that - I didn't realise that my copy of emacs was doing the replace on saving. I made the edit then reran the above steps. It seems that SU2_BASE now installs fine and SU2_AD only presents the initial error. I assume this means SU2 is up and running? I'll try some test cases to confirm. Thanks for the support!,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-333753697
https://github.com/su2code/SU2/issues/447#issuecomment-349530941:221,Availability,error,error,221,"Sorry, not sure if this is the best place to ask this but after closing this, I am now trying to do the same AD build on my local supercomputer. During the part where I do a `make install` in SU_BASE, I get the following error: [make_error.txt](https://github.com/su2code/SU2/files/1533904/make_error.txt). Can you give a pointer as to what might be up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349530941
https://github.com/su2code/SU2/issues/447#issuecomment-349530941:180,Deployability,install,install,180,"Sorry, not sure if this is the best place to ask this but after closing this, I am now trying to do the same AD build on my local supercomputer. During the part where I do a `make install` in SU_BASE, I get the following error: [make_error.txt](https://github.com/su2code/SU2/files/1533904/make_error.txt). Can you give a pointer as to what might be up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349530941
https://github.com/su2code/SU2/issues/447#issuecomment-349590138:7,Availability,error,error,7,"As the error message says, it cannot find ""Python.h"". This is again related to the Python wrapper compilation. If you really don't need it, I suggest you to just disable it when configuring your build (remove --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is not located in a standard location on your supercomputer, you will have to manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for the Python include and Python libs (I think similarly to what you did for mpi4py, see above)... Again, everything should be improved after #424 is merged.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349590138
https://github.com/su2code/SU2/issues/447#issuecomment-349590138:13,Integrability,message,message,13,"As the error message says, it cannot find ""Python.h"". This is again related to the Python wrapper compilation. If you really don't need it, I suggest you to just disable it when configuring your build (remove --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is not located in a standard location on your supercomputer, you will have to manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for the Python include and Python libs (I think similarly to what you did for mpi4py, see above)... Again, everything should be improved after #424 is merged.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349590138
https://github.com/su2code/SU2/issues/447#issuecomment-349590138:90,Integrability,wrap,wrapper,90,"As the error message says, it cannot find ""Python.h"". This is again related to the Python wrapper compilation. If you really don't need it, I suggest you to just disable it when configuring your build (remove --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is not located in a standard location on your supercomputer, you will have to manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for the Python include and Python libs (I think similarly to what you did for mpi4py, see above)... Again, everything should be improved after #424 is merged.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349590138
https://github.com/su2code/SU2/issues/447#issuecomment-349590138:254,Integrability,wrap,wrapper,254,"As the error message says, it cannot find ""Python.h"". This is again related to the Python wrapper compilation. If you really don't need it, I suggest you to just disable it when configuring your build (remove --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is not located in a standard location on your supercomputer, you will have to manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for the Python include and Python libs (I think similarly to what you did for mpi4py, see above)... Again, everything should be improved after #424 is merged.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349590138
https://github.com/su2code/SU2/issues/447#issuecomment-349590138:178,Modifiability,config,configuring,178,"As the error message says, it cannot find ""Python.h"". This is again related to the Python wrapper compilation. If you really don't need it, I suggest you to just disable it when configuring your build (remove --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is not located in a standard location on your supercomputer, you will have to manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for the Python include and Python libs (I think similarly to what you did for mpi4py, see above)... Again, everything should be improved after #424 is merged.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349590138
https://github.com/su2code/SU2/issues/447#issuecomment-349967348:80,Availability,down,download,80,"Thanks for the heads up - I just noticed you merged today! Does that mean; if I download the fresh-out-of-the oven master, these problems will go; away? Cheers!. On 6 Dec 2017 18:55, ""David Thomas"" <notifications@github.com> wrote:. > As the error message says, it cannot find ""Python.h"". This is again; > related to the Python wrapper compilation. If you really don't need it, I; > suggest you to just disable it when configuring your build (remove; > --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is; > not located in a standard location on your supercomputer, you will have to; > manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for; > the Python include and Python libs (I think similarly to what you did for; > mpi4py, see above)... Again, everything should be improved after #424; > <https://github.com/su2code/SU2/pull/424> is merged.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/447#issuecomment-349590138>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AQD-Esbg6axZxZB3ZUnHir1iqvyU8CUSks5s9mSrgaJpZM4Pm0yA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349967348
https://github.com/su2code/SU2/issues/447#issuecomment-349967348:242,Availability,error,error,242,"Thanks for the heads up - I just noticed you merged today! Does that mean; if I download the fresh-out-of-the oven master, these problems will go; away? Cheers!. On 6 Dec 2017 18:55, ""David Thomas"" <notifications@github.com> wrote:. > As the error message says, it cannot find ""Python.h"". This is again; > related to the Python wrapper compilation. If you really don't need it, I; > suggest you to just disable it when configuring your build (remove; > --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is; > not located in a standard location on your supercomputer, you will have to; > manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for; > the Python include and Python libs (I think similarly to what you did for; > mpi4py, see above)... Again, everything should be improved after #424; > <https://github.com/su2code/SU2/pull/424> is merged.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/447#issuecomment-349590138>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AQD-Esbg6axZxZB3ZUnHir1iqvyU8CUSks5s9mSrgaJpZM4Pm0yA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349967348
https://github.com/su2code/SU2/issues/447#issuecomment-349967348:248,Integrability,message,message,248,"Thanks for the heads up - I just noticed you merged today! Does that mean; if I download the fresh-out-of-the oven master, these problems will go; away? Cheers!. On 6 Dec 2017 18:55, ""David Thomas"" <notifications@github.com> wrote:. > As the error message says, it cannot find ""Python.h"". This is again; > related to the Python wrapper compilation. If you really don't need it, I; > suggest you to just disable it when configuring your build (remove; > --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is; > not located in a standard location on your supercomputer, you will have to; > manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for; > the Python include and Python libs (I think similarly to what you did for; > mpi4py, see above)... Again, everything should be improved after #424; > <https://github.com/su2code/SU2/pull/424> is merged.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/447#issuecomment-349590138>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AQD-Esbg6axZxZB3ZUnHir1iqvyU8CUSks5s9mSrgaJpZM4Pm0yA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349967348
https://github.com/su2code/SU2/issues/447#issuecomment-349967348:328,Integrability,wrap,wrapper,328,"Thanks for the heads up - I just noticed you merged today! Does that mean; if I download the fresh-out-of-the oven master, these problems will go; away? Cheers!. On 6 Dec 2017 18:55, ""David Thomas"" <notifications@github.com> wrote:. > As the error message says, it cannot find ""Python.h"". This is again; > related to the Python wrapper compilation. If you really don't need it, I; > suggest you to just disable it when configuring your build (remove; > --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is; > not located in a standard location on your supercomputer, you will have to; > manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for; > the Python include and Python libs (I think similarly to what you did for; > mpi4py, see above)... Again, everything should be improved after #424; > <https://github.com/su2code/SU2/pull/424> is merged.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/447#issuecomment-349590138>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AQD-Esbg6axZxZB3ZUnHir1iqvyU8CUSks5s9mSrgaJpZM4Pm0yA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349967348
https://github.com/su2code/SU2/issues/447#issuecomment-349967348:498,Integrability,wrap,wrapper,498,"Thanks for the heads up - I just noticed you merged today! Does that mean; if I download the fresh-out-of-the oven master, these problems will go; away? Cheers!. On 6 Dec 2017 18:55, ""David Thomas"" <notifications@github.com> wrote:. > As the error message says, it cannot find ""Python.h"". This is again; > related to the Python wrapper compilation. If you really don't need it, I; > suggest you to just disable it when configuring your build (remove; > --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is; > not located in a standard location on your supercomputer, you will have to; > manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for; > the Python include and Python libs (I think similarly to what you did for; > mpi4py, see above)... Again, everything should be improved after #424; > <https://github.com/su2code/SU2/pull/424> is merged.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/447#issuecomment-349590138>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AQD-Esbg6axZxZB3ZUnHir1iqvyU8CUSks5s9mSrgaJpZM4Pm0yA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349967348
https://github.com/su2code/SU2/issues/447#issuecomment-349967348:419,Modifiability,config,configuring,419,"Thanks for the heads up - I just noticed you merged today! Does that mean; if I download the fresh-out-of-the oven master, these problems will go; away? Cheers!. On 6 Dec 2017 18:55, ""David Thomas"" <notifications@github.com> wrote:. > As the error message says, it cannot find ""Python.h"". This is again; > related to the Python wrapper compilation. If you really don't need it, I; > suggest you to just disable it when configuring your build (remove; > --enable-PY_WRAPPER). If you need the Python wrapper and if your Python is; > not located in a standard location on your supercomputer, you will have to; > manually modify the SU2_PY/pySU2/Makefile.am and put the right paths for; > the Python include and Python libs (I think similarly to what you did for; > mpi4py, see above)... Again, everything should be improved after #424; > <https://github.com/su2code/SU2/pull/424> is merged.; >; > ; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/447#issuecomment-349590138>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AQD-Esbg6axZxZB3ZUnHir1iqvyU8CUSks5s9mSrgaJpZM4Pm0yA>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349967348
https://github.com/su2code/SU2/issues/447#issuecomment-349972232:86,Testability,test,test,86,"It is now merged indeed. I dit not work in that branch and I did not have the time to test it on several machines...so I suggest you to checkout the develop branch (not the master) and make a clean build. If things are not improved, I'm afraid that you will have to set the paths manually again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/447#issuecomment-349972232
https://github.com/su2code/SU2/pull/448#issuecomment-334163260:204,Availability,error,error,204,That sounds very nice! Thanks for this update. . Btw: I fixed the failing regression test in the TestCases repo. There was a whitespace missing in the reference file. That's why the file diff returned an error.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/448#issuecomment-334163260
https://github.com/su2code/SU2/pull/448#issuecomment-334163260:39,Deployability,update,update,39,That sounds very nice! Thanks for this update. . Btw: I fixed the failing regression test in the TestCases repo. There was a whitespace missing in the reference file. That's why the file diff returned an error.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/448#issuecomment-334163260
https://github.com/su2code/SU2/pull/448#issuecomment-334163260:85,Testability,test,test,85,That sounds very nice! Thanks for this update. . Btw: I fixed the failing regression test in the TestCases repo. There was a whitespace missing in the reference file. That's why the file diff returned an error.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/448#issuecomment-334163260
https://github.com/su2code/SU2/pull/448#issuecomment-334163260:97,Testability,Test,TestCases,97,That sounds very nice! Thanks for this update. . Btw: I fixed the failing regression test in the TestCases repo. There was a whitespace missing in the reference file. That's why the file diff returned an error.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/448#issuecomment-334163260
https://github.com/su2code/SU2/pull/448#issuecomment-334288538:144,Testability,test,test,144,"Dear @IndianaStokes,. First of all, I would like to thank you for the many contributions you are giving to SU2. I have just a question? Did you test this improvement in convergence rate with both JST and Roe 2nd order limiter?. regards . sv",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/448#issuecomment-334288538
https://github.com/su2code/SU2/pull/448#issuecomment-334358362:353,Energy Efficiency,reduce,reduced,353,"Thanks @salvovitale and @talbring. As you know, the main consequence of a better linear solver is that it is possible to increase the CFL number (independently of the spatial discretization). In other words... the benefits are for JST and Roe. By the way, I have found that a fill-in level of 1 is too expensive for 3D problems (great for 2D)... I have reduced the default value from 1 to 0... but feel free to increase the number if you are looking for very large CFL numbers. I think that regression tests are taking too much time and they don't finish on the assigned time... hopefully the change from 1 to 0 fill-in level will resolve the problem, otherwise I'll reduce the time on some of the tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/448#issuecomment-334358362
https://github.com/su2code/SU2/pull/448#issuecomment-334358362:667,Energy Efficiency,reduce,reduce,667,"Thanks @salvovitale and @talbring. As you know, the main consequence of a better linear solver is that it is possible to increase the CFL number (independently of the spatial discretization). In other words... the benefits are for JST and Roe. By the way, I have found that a fill-in level of 1 is too expensive for 3D problems (great for 2D)... I have reduced the default value from 1 to 0... but feel free to increase the number if you are looking for very large CFL numbers. I think that regression tests are taking too much time and they don't finish on the assigned time... hopefully the change from 1 to 0 fill-in level will resolve the problem, otherwise I'll reduce the time on some of the tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/448#issuecomment-334358362
https://github.com/su2code/SU2/pull/448#issuecomment-334358362:502,Testability,test,tests,502,"Thanks @salvovitale and @talbring. As you know, the main consequence of a better linear solver is that it is possible to increase the CFL number (independently of the spatial discretization). In other words... the benefits are for JST and Roe. By the way, I have found that a fill-in level of 1 is too expensive for 3D problems (great for 2D)... I have reduced the default value from 1 to 0... but feel free to increase the number if you are looking for very large CFL numbers. I think that regression tests are taking too much time and they don't finish on the assigned time... hopefully the change from 1 to 0 fill-in level will resolve the problem, otherwise I'll reduce the time on some of the tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/448#issuecomment-334358362
https://github.com/su2code/SU2/pull/448#issuecomment-334358362:698,Testability,test,tests,698,"Thanks @salvovitale and @talbring. As you know, the main consequence of a better linear solver is that it is possible to increase the CFL number (independently of the spatial discretization). In other words... the benefits are for JST and Roe. By the way, I have found that a fill-in level of 1 is too expensive for 3D problems (great for 2D)... I have reduced the default value from 1 to 0... but feel free to increase the number if you are looking for very large CFL numbers. I think that regression tests are taking too much time and they don't finish on the assigned time... hopefully the change from 1 to 0 fill-in level will resolve the problem, otherwise I'll reduce the time on some of the tests.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/448#issuecomment-334358362
https://github.com/su2code/SU2/issues/449#issuecomment-333879558:382,Integrability,wrap,wrapper,382,"Hello,. May I ask which version of the code do you use and on which branch ? In fact, this bug (and it was not the only one) was already fixed a few days ago on the branch feature_pyWrapper. You may pull those new changes just to be sure to have a clean version. Otherwise, I would not trust the results. The reason why the FSI Python tool (note the distinction with the SU2 Python wrapper, which is maintained and up-to-date) accumulates some bugs is that, normally, it is not really maintained anymore in prevision of a new coupling framework. I recently introduced some fixes to make it work again (I mean the coupling SU2 + pitch-plunge structural solver) in the meantime, but you may want to double-check each result you get. Best,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/449#issuecomment-333879558
https://github.com/su2code/SU2/issues/449#issuecomment-333879558:526,Modifiability,coupling,coupling,526,"Hello,. May I ask which version of the code do you use and on which branch ? In fact, this bug (and it was not the only one) was already fixed a few days ago on the branch feature_pyWrapper. You may pull those new changes just to be sure to have a clean version. Otherwise, I would not trust the results. The reason why the FSI Python tool (note the distinction with the SU2 Python wrapper, which is maintained and up-to-date) accumulates some bugs is that, normally, it is not really maintained anymore in prevision of a new coupling framework. I recently introduced some fixes to make it work again (I mean the coupling SU2 + pitch-plunge structural solver) in the meantime, but you may want to double-check each result you get. Best,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/449#issuecomment-333879558
https://github.com/su2code/SU2/issues/449#issuecomment-333879558:613,Modifiability,coupling,coupling,613,"Hello,. May I ask which version of the code do you use and on which branch ? In fact, this bug (and it was not the only one) was already fixed a few days ago on the branch feature_pyWrapper. You may pull those new changes just to be sure to have a clean version. Otherwise, I would not trust the results. The reason why the FSI Python tool (note the distinction with the SU2 Python wrapper, which is maintained and up-to-date) accumulates some bugs is that, normally, it is not really maintained anymore in prevision of a new coupling framework. I recently introduced some fixes to make it work again (I mean the coupling SU2 + pitch-plunge structural solver) in the meantime, but you may want to double-check each result you get. Best,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/449#issuecomment-333879558
https://github.com/su2code/SU2/issues/449#issuecomment-334158112:51,Deployability,release,release,51,"Hi David,. Actually I was using the first official release of the Raven version of SU2 (I think released at the end of this February). I'm mainly interested in the python tools of the package as I'm dealing with fluid structure interaction. Thank you so much for the advice, hope the branch you suggested me is ok for my purposes!!. Best,. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/449#issuecomment-334158112
https://github.com/su2code/SU2/issues/449#issuecomment-334158112:96,Deployability,release,released,96,"Hi David,. Actually I was using the first official release of the Raven version of SU2 (I think released at the end of this February). I'm mainly interested in the python tools of the package as I'm dealing with fluid structure interaction. Thank you so much for the advice, hope the branch you suggested me is ok for my purposes!!. Best,. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/449#issuecomment-334158112
https://github.com/su2code/SU2/issues/449#issuecomment-358638245:272,Deployability,release,release,272,"Hi David,. I am sorry to bring up this topic again, but I am experiencing the same bug from Rocco and I found this Issue discussion. However, I can not find the branch ""feature_pyWrapper"" that you mentioned. Is it still somewhere?; I am presently using the official 5.0.0 release cloned from the main branch. Thanks; Best Regards; Gabriele",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/449#issuecomment-358638245
https://github.com/su2code/SU2/pull/451#issuecomment-335205189:373,Availability,error,error,373,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189
https://github.com/su2code/SU2/pull/451#issuecomment-335205189:379,Integrability,message,messages,379,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189
https://github.com/su2code/SU2/pull/451#issuecomment-335205189:225,Usability,clear,clear,225,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189
https://github.com/su2code/SU2/pull/451#issuecomment-335205189:632,Usability,clear,clear,632,"I agree with the proposed changes, but I also think this could go farther. Some of the most common issues for users involve misuse of the *_ORDER options, dissipation coefficients, and limiters. Overall, it is still not very clear for a user how the centered schemes work. For instance, Lax is always first order and JST is always second order, but sometimes there are not error messages when trying to change the ""ORDER"" option when using these schemes. Also, if we rename the coefficients for JST as proposed, shouldn't we also separate the first coefficient that is only used for Lax? It would make treating the dissipation more clear.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-335205189
https://github.com/su2code/SU2/pull/451#issuecomment-336345293:96,Availability,error,error,96,This is a big change that will affect all the config files... could you please add a meaningful error message if somebody uses the old options? Thanks!,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-336345293
https://github.com/su2code/SU2/pull/451#issuecomment-336345293:102,Integrability,message,message,102,This is a big change that will affect all the config files... could you please add a meaningful error message if somebody uses the old options? Thanks!,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-336345293
https://github.com/su2code/SU2/pull/451#issuecomment-336345293:46,Modifiability,config,config,46,This is a big change that will affect all the config files... could you please add a meaningful error message if somebody uses the old options? Thanks!,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/451#issuecomment-336345293
https://github.com/su2code/SU2/pull/452#issuecomment-337575805:122,Deployability,update,updates,122,"Thanks Tom for the comments! ; I think I have covered them all but let me know if you still have comments. I will do some updates tomorrow morning. I agree this is a very large pull request, it's the result of over a year of work, so I would really appreciate any more feedback from the community! ; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/452#issuecomment-337575805
https://github.com/su2code/SU2/pull/452#issuecomment-337575805:269,Usability,feedback,feedback,269,"Thanks Tom for the comments! ; I think I have covered them all but let me know if you still have comments. I will do some updates tomorrow morning. I agree this is a very large pull request, it's the result of over a year of work, so I would really appreciate any more feedback from the community! ; Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/452#issuecomment-337575805
https://github.com/su2code/SU2/issues/454#issuecomment-338776498:134,Deployability,update,update,134,"@vdweide: yep, definitely a bug. Only the mean flow solver uses that routine. Please feel free to clean this up. I would also like to update the version for the incompressible solver (I think it needs a fix or two)... but we'll get to that after your changes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/454#issuecomment-338776498
https://github.com/su2code/SU2/issues/454#issuecomment-338776498:69,Integrability,rout,routine,69,"@vdweide: yep, definitely a bug. Only the mean flow solver uses that routine. Please feel free to clean this up. I would also like to update the version for the incompressible solver (I think it needs a fix or two)... but we'll get to that after your changes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/454#issuecomment-338776498
https://github.com/su2code/SU2/issues/457#issuecomment-339026305:601,Deployability,configurat,configuration,601,"Hi,. The structure of fsi_computation.py is completely different from the one of parallel_computation(_fsi).py, this one is just a script that, if I am right, will set for you the commands in order to launch SU2_CFD in parallel and SU2_SOL right after. It is based on system calls ( it is like calling mpirun -np xx SU2_CFD SU2conf.cfg and mpirun -np xx SU2_SOL SU2conf.cfg). The fsi_computation.py has to be considered as an executable, and thus has to be launched with the mpirun command for parallel run:. $ mpirun -np XX fsi_computation.py -f FSIConfig.cfg --parallel. You have to specify the FSI configuration file (see examples in TestCase) with -f, and the --parallel option is mandatory (only if SU2 has been built in parallel). XX is the number of procs. Hope this helps,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/457#issuecomment-339026305
https://github.com/su2code/SU2/issues/457#issuecomment-339026305:601,Modifiability,config,configuration,601,"Hi,. The structure of fsi_computation.py is completely different from the one of parallel_computation(_fsi).py, this one is just a script that, if I am right, will set for you the commands in order to launch SU2_CFD in parallel and SU2_SOL right after. It is based on system calls ( it is like calling mpirun -np xx SU2_CFD SU2conf.cfg and mpirun -np xx SU2_SOL SU2conf.cfg). The fsi_computation.py has to be considered as an executable, and thus has to be launched with the mpirun command for parallel run:. $ mpirun -np XX fsi_computation.py -f FSIConfig.cfg --parallel. You have to specify the FSI configuration file (see examples in TestCase) with -f, and the --parallel option is mandatory (only if SU2 has been built in parallel). XX is the number of procs. Hope this helps,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/457#issuecomment-339026305
https://github.com/su2code/SU2/issues/457#issuecomment-339026305:637,Testability,Test,TestCase,637,"Hi,. The structure of fsi_computation.py is completely different from the one of parallel_computation(_fsi).py, this one is just a script that, if I am right, will set for you the commands in order to launch SU2_CFD in parallel and SU2_SOL right after. It is based on system calls ( it is like calling mpirun -np xx SU2_CFD SU2conf.cfg and mpirun -np xx SU2_SOL SU2conf.cfg). The fsi_computation.py has to be considered as an executable, and thus has to be launched with the mpirun command for parallel run:. $ mpirun -np XX fsi_computation.py -f FSIConfig.cfg --parallel. You have to specify the FSI configuration file (see examples in TestCase) with -f, and the --parallel option is mandatory (only if SU2 has been built in parallel). XX is the number of procs. Hope this helps,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/457#issuecomment-339026305
https://github.com/su2code/SU2/issues/459#issuecomment-339748432:500,Availability,down,down,500,"As a second note: we are aware that even the 70 min. time limit is causing problems for new PRs and other branches that are using Travis CI individually. . One option is to ""parallelize"" the builds by decomposing the current regression scripts into more scripts with fewer tests each. However, this only addresses part of the problem, as the compilation step is taking the most time and is currently done within each script. We could consider compiling with lower optimization, etc., to get the cost down, but I am open to ideas on this front too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/459#issuecomment-339748432
https://github.com/su2code/SU2/issues/459#issuecomment-339748432:464,Performance,optimiz,optimization,464,"As a second note: we are aware that even the 70 min. time limit is causing problems for new PRs and other branches that are using Travis CI individually. . One option is to ""parallelize"" the builds by decomposing the current regression scripts into more scripts with fewer tests each. However, this only addresses part of the problem, as the compilation step is taking the most time and is currently done within each script. We could consider compiling with lower optimization, etc., to get the cost down, but I am open to ideas on this front too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/459#issuecomment-339748432
https://github.com/su2code/SU2/issues/459#issuecomment-339748432:273,Testability,test,tests,273,"As a second note: we are aware that even the 70 min. time limit is causing problems for new PRs and other branches that are using Travis CI individually. . One option is to ""parallelize"" the builds by decomposing the current regression scripts into more scripts with fewer tests each. However, this only addresses part of the problem, as the compilation step is taking the most time and is currently done within each script. We could consider compiling with lower optimization, etc., to get the cost down, but I am open to ideas on this front too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/459#issuecomment-339748432
https://github.com/su2code/SU2/issues/459#issuecomment-339751327:89,Deployability,update,updated,89,"How about making the test cases repo a submodule of SU2, such that when the submodule is updated Travis will be triggered?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/459#issuecomment-339751327
https://github.com/su2code/SU2/issues/459#issuecomment-339751327:21,Testability,test,test,21,"How about making the test cases repo a submodule of SU2, such that when the submodule is updated Travis will be triggered?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/459#issuecomment-339751327
https://github.com/su2code/SU2/issues/459#issuecomment-339799097:466,Availability,down,download,466,"@petebachant: interesting idea.. do you know if this is possible? I thought that submodules were mostly static links to particular tags of a repo, but this could be a good way. @vdweide: yes, the machines that Travis CI uses for running open-source projects are fairly small linux boxes with 2-4 cores. Going higher than 'make -j4' won't do much (this is what we do). More ideas along these lines would be great though. By the way, you can see the details of how we download the code, packages, and compile/install in the .travis.yml file here:. https://github.com/su2code/SU2/blob/develop/.travis.yml",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/459#issuecomment-339799097
https://github.com/su2code/SU2/issues/459#issuecomment-339799097:507,Deployability,install,install,507,"@petebachant: interesting idea.. do you know if this is possible? I thought that submodules were mostly static links to particular tags of a repo, but this could be a good way. @vdweide: yes, the machines that Travis CI uses for running open-source projects are fairly small linux boxes with 2-4 cores. Going higher than 'make -j4' won't do much (this is what we do). More ideas along these lines would be great though. By the way, you can see the details of how we download the code, packages, and compile/install in the .travis.yml file here:. https://github.com/su2code/SU2/blob/develop/.travis.yml",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/459#issuecomment-339799097
https://github.com/su2code/SU2/issues/459#issuecomment-339800670:109,Testability,Test,TestCases,109,"I think it is possible, but there may need to be some renaming to deal with the fact that there's already a `TestCases` directory. One benefit of using a submodule is that an exact commit of the test cases repo can be tied to each SU2 commit. Also, I think Travis by default recurses submodules when cloning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/459#issuecomment-339800670
https://github.com/su2code/SU2/issues/459#issuecomment-339800670:195,Testability,test,test,195,"I think it is possible, but there may need to be some renaming to deal with the fact that there's already a `TestCases` directory. One benefit of using a submodule is that an exact commit of the test cases repo can be tied to each SU2 commit. Also, I think Travis by default recurses submodules when cloning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/459#issuecomment-339800670
https://github.com/su2code/SU2/issues/462#issuecomment-342593274:220,Integrability,wrap,wrapping,220,"This is very interesting, since I often find that I am commenting out most of the python regression script when debugging only a couple of tests locally. Can you estimate how much work this would be? Is it just a simple wrapping of what we already have? We would also have to make sure that Travis CI can handle it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342593274
https://github.com/su2code/SU2/issues/462#issuecomment-342593274:139,Testability,test,tests,139,"This is very interesting, since I often find that I am commenting out most of the python regression script when debugging only a couple of tests locally. Can you estimate how much work this would be? Is it just a simple wrapping of what we already have? We would also have to make sure that Travis CI can handle it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342593274
https://github.com/su2code/SU2/issues/462#issuecomment-342593274:213,Usability,simpl,simple,213,"This is very interesting, since I often find that I am commenting out most of the python regression script when debugging only a couple of tests locally. Can you estimate how much work this would be? Is it just a simple wrapping of what we already have? We would also have to make sure that Travis CI can handle it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342593274
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:46,Testability,test,test,46,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:113,Testability,Test,TestCase,113,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:201,Testability,test,tests,201,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:356,Testability,Test,TestCases,356,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:486,Testability,test,test,486,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:626,Testability,Test,TestCases,626,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:775,Testability,Test,TestCase,775,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:800,Testability,test,test,800,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:812,Testability,Test,TestCase,812,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/462#issuecomment-342677051:9,Usability,simpl,simply,9,"It would simply take some reorganizing of the test scripts to make one function per case and maybe renaming the `TestCase` class to `RegressionTestCase` or something. For example, I rewrote one of the tests in `serial_regression.py` here: https://github.com/petebachant/SU2/commit/fe0ee432c67540067046fbebf9889660331a6592. Then I could run this with. $ cd TestCases; $ pytest serial_regression.py. the output from which was:. ```; $ pytest serial_regression.py; ======================= test session starts =======================; platform linux -- Python 3.6.3, pytest-3.2.1, py-1.4.34, pluggy-0.4.0; rootdir: /home/pete/SU2/TestCases, inifile:; collected 1 item. serial_regression.py . ====================== warnings summary =======================; serial_regression.py::TestCase; cannot collect test class 'TestCase' because it has a __init__ constructor. -- Docs: http://doc.pytest.org/en/latest/warnings.html; =============== 1 passed, 1 warnings in 92.18 seconds ==================; ```. `pytest` has a bunch of features to control the print output as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/462#issuecomment-342677051
https://github.com/su2code/SU2/issues/466#issuecomment-341623660:205,Availability,avail,available,205,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660
https://github.com/su2code/SU2/issues/466#issuecomment-341623660:424,Availability,avail,available,424,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660
https://github.com/su2code/SU2/issues/466#issuecomment-341623660:252,Integrability,rout,routines,252,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660
https://github.com/su2code/SU2/issues/466#issuecomment-341623660:370,Usability,simpl,simple,370,"Hi Soumen: yes, this is something that the developers are actively working on at the moment (in particular, @sravya91 has been taking the lead on this). It is true that most of the ingredients are already available in SU2 (fast searches, interpolation routines, etc.), but the trick is combining them all and making it general. Do you have any other requirements beyond simple probes? I am guessing we should have something available in the next few months, but it's not set yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-341623660
https://github.com/su2code/SU2/issues/466#issuecomment-342266341:410,Availability,avail,available,410,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
https://github.com/su2code/SU2/issues/466#issuecomment-342266341:900,Availability,avail,available,900,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
https://github.com/su2code/SU2/issues/466#issuecomment-342266341:1131,Availability,avail,available,1131,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
https://github.com/su2code/SU2/issues/466#issuecomment-342266341:345,Deployability,configurat,configuration,345,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
https://github.com/su2code/SU2/issues/466#issuecomment-342266341:29,Integrability,rout,routines,29,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
https://github.com/su2code/SU2/issues/466#issuecomment-342266341:947,Integrability,rout,routines,947,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
https://github.com/su2code/SU2/issues/466#issuecomment-342266341:345,Modifiability,config,configuration,345,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
https://github.com/su2code/SU2/issues/466#issuecomment-342266341:382,Modifiability,extend,extended,382,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
https://github.com/su2code/SU2/issues/466#issuecomment-342266341:1074,Usability,simpl,simple,1074,"Hi Soumen,. As Tom said, the routines are all in place and I have been putting them; together for solution interpolation from one mesh to another for unsteady; simulation as post-processing step. So probing at a particular location for; unsteady solution can be also done with this framework. The probe search; implementation is in place for 2D configuration currently. It will be; extended to 3D and probably available in the main branch in the next 2; months.; The implementation so far is in feature_MeshInterpolation branch if you; want to take a look. Sravya. On Thu, Nov 2, 2017 at 10:09 PM, Thomas D. Economon <; notifications@github.com> wrote:. > Hi Soumen: yes, this is something that the developers are actively working; > on at the moment (in particular, @sravya91 <https://github.com/sravya91>; > has been taking the lead on this). It is true that most of the ingredients; > are already available in SU2 (fast searches, interpolation routines, etc.),; > but the trick is combining them all and making it general.; >; > Do you have any other requirements beyond simple probes? I am guessing we; > should have something available in the next few months, but it's not set; > yet.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/466#issuecomment-341623660>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AHenII5B0Xtb2U_hj2vbBesf5Oc51uvzks5syqAEgaJpZM4QPYh8>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-342266341
https://github.com/su2code/SU2/issues/466#issuecomment-480186725:103,Deployability,update,updated,103,"Hello,. Is there someone still working on this topic? I saw that feature_MeshInterpolation hasn't been updated in a year and I was wondering whether there are other active branches where something similar is being developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-480186725
https://github.com/su2code/SU2/issues/466#issuecomment-502780046:606,Performance,perform,perform,606,"I'm going to jump on this too. Is anyone working on solution interpolation (from one mesh to another)? @sravya91, are you still working on this? Did PR #672 introduce any capabilities to address interpolation? This seems to be a common request from SU2 users: [\[1\]](https://www.cfd-online.com/Forums/su2/213321-su2-solution-interpolation.html) [\[2\]](https://www.cfd-online.com/Forums/su2/215920-use-coarse-grid-flow-solution-initial-solution-fine-grid.html). I've used some pretty rough python scripts to do solution interpolation in the past, and it would be nice to have some SU2 C++ code that could perform the same task.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-502780046
https://github.com/su2code/SU2/issues/466#issuecomment-502783107:211,Availability,error,error,211,"Folks,. This is indeed a very important capability for many different applications: from interpolation of solutions from coarser grids to finer grids, to querying an unsteady solution, to implementing numerical error estimatesand many others. It is important that the search / interpolation routines work when interpolating between grids where some points in the target grid may fall outside of the source grid and, therefore some notion of distance to the wall is needed. Fortunately, Edwin van der Weide had worked on an interpolation library that @sravya91 (who received her PhD yesterday at our graduation ceremony and is now working at NVIDIA) used in her work. Jayant Mukhopadhaya and Brian Munguia have also been testing/improving the library. Perhaps everyone can comment on current status and we can create a small task force to see what still needs to be done and who can do what?. Best,. Juan. On Jun 17, 2019, at 10:36 AM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I'm going to jump on this too. Is anyone working on solution interpolation (from one mesh to another)? @sravya91<https://github.com/sravya91>, are you still working on this? Did PR #672<https://github.com/su2code/SU2/pull/672> introduce any capabilities to address interpolation? This seems to be a common request from SU2 users: [1]<https://www.cfd-online.com/Forums/su2/213321-su2-solution-interpolation.html> [2]<https://www.cfd-online.com/Forums/su2/215920-use-coarse-grid-flow-solution-initial-solution-fine-grid.html>. I've used some pretty rough python scripts to do solution interpolation in the past, and it would be nice to have some SU2 C++ code that could perform the same task. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/466?email_source=notifications&email_token=AA5FFRGCPYI5KNVQZ7GB5F3P27DQZA5CNFSM4EB5RB6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-502783107
https://github.com/su2code/SU2/issues/466#issuecomment-502783107:292,Integrability,rout,routines,292,"Folks,. This is indeed a very important capability for many different applications: from interpolation of solutions from coarser grids to finer grids, to querying an unsteady solution, to implementing numerical error estimatesand many others. It is important that the search / interpolation routines work when interpolating between grids where some points in the target grid may fall outside of the source grid and, therefore some notion of distance to the wall is needed. Fortunately, Edwin van der Weide had worked on an interpolation library that @sravya91 (who received her PhD yesterday at our graduation ceremony and is now working at NVIDIA) used in her work. Jayant Mukhopadhaya and Brian Munguia have also been testing/improving the library. Perhaps everyone can comment on current status and we can create a small task force to see what still needs to be done and who can do what?. Best,. Juan. On Jun 17, 2019, at 10:36 AM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I'm going to jump on this too. Is anyone working on solution interpolation (from one mesh to another)? @sravya91<https://github.com/sravya91>, are you still working on this? Did PR #672<https://github.com/su2code/SU2/pull/672> introduce any capabilities to address interpolation? This seems to be a common request from SU2 users: [1]<https://www.cfd-online.com/Forums/su2/213321-su2-solution-interpolation.html> [2]<https://www.cfd-online.com/Forums/su2/215920-use-coarse-grid-flow-solution-initial-solution-fine-grid.html>. I've used some pretty rough python scripts to do solution interpolation in the past, and it would be nice to have some SU2 C++ code that could perform the same task. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/466?email_source=notifications&email_token=AA5FFRGCPYI5KNVQZ7GB5F3P27DQZA5CNFSM4EB5RB6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-502783107
https://github.com/su2code/SU2/issues/466#issuecomment-502783107:1687,Performance,perform,perform,1687,"g an unsteady solution, to implementing numerical error estimatesand many others. It is important that the search / interpolation routines work when interpolating between grids where some points in the target grid may fall outside of the source grid and, therefore some notion of distance to the wall is needed. Fortunately, Edwin van der Weide had worked on an interpolation library that @sravya91 (who received her PhD yesterday at our graduation ceremony and is now working at NVIDIA) used in her work. Jayant Mukhopadhaya and Brian Munguia have also been testing/improving the library. Perhaps everyone can comment on current status and we can create a small task force to see what still needs to be done and who can do what?. Best,. Juan. On Jun 17, 2019, at 10:36 AM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I'm going to jump on this too. Is anyone working on solution interpolation (from one mesh to another)? @sravya91<https://github.com/sravya91>, are you still working on this? Did PR #672<https://github.com/su2code/SU2/pull/672> introduce any capabilities to address interpolation? This seems to be a common request from SU2 users: [1]<https://www.cfd-online.com/Forums/su2/213321-su2-solution-interpolation.html> [2]<https://www.cfd-online.com/Forums/su2/215920-use-coarse-grid-flow-solution-initial-solution-fine-grid.html>. I've used some pretty rough python scripts to do solution interpolation in the past, and it would be nice to have some SU2 C++ code that could perform the same task. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/466?email_source=notifications&email_token=AA5FFRGCPYI5KNVQZ7GB5F3P27DQZA5CNFSM4EB5RB6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODX35BDQ#issuecomment-502780046>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRA2PYIJFUNP7AHIS3DP27DQZANCNFSM4EB5RB6A>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-502783107
https://github.com/su2code/SU2/issues/466#issuecomment-502783107:721,Testability,test,testing,721,"Folks,. This is indeed a very important capability for many different applications: from interpolation of solutions from coarser grids to finer grids, to querying an unsteady solution, to implementing numerical error estimatesand many others. It is important that the search / interpolation routines work when interpolating between grids where some points in the target grid may fall outside of the source grid and, therefore some notion of distance to the wall is needed. Fortunately, Edwin van der Weide had worked on an interpolation library that @sravya91 (who received her PhD yesterday at our graduation ceremony and is now working at NVIDIA) used in her work. Jayant Mukhopadhaya and Brian Munguia have also been testing/improving the library. Perhaps everyone can comment on current status and we can create a small task force to see what still needs to be done and who can do what?. Best,. Juan. On Jun 17, 2019, at 10:36 AM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I'm going to jump on this too. Is anyone working on solution interpolation (from one mesh to another)? @sravya91<https://github.com/sravya91>, are you still working on this? Did PR #672<https://github.com/su2code/SU2/pull/672> introduce any capabilities to address interpolation? This seems to be a common request from SU2 users: [1]<https://www.cfd-online.com/Forums/su2/213321-su2-solution-interpolation.html> [2]<https://www.cfd-online.com/Forums/su2/215920-use-coarse-grid-flow-solution-initial-solution-fine-grid.html>. I've used some pretty rough python scripts to do solution interpolation in the past, and it would be nice to have some SU2 C++ code that could perform the same task. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/466?email_source=notifications&email_token=AA5FFRGCPYI5KNVQZ7GB5F3P27DQZA5CNFSM4EB5RB6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-502783107
https://github.com/su2code/SU2/issues/466#issuecomment-505741019:61,Deployability,integrat,integrated,61,"The interpolation tool I use is a standalone program and not integrated into SU2. However, it is possible that @bmunguia and @jayantmukho have integrated it into SU2. Is that the case?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-505741019
https://github.com/su2code/SU2/issues/466#issuecomment-505741019:143,Deployability,integrat,integrated,143,"The interpolation tool I use is a standalone program and not integrated into SU2. However, it is possible that @bmunguia and @jayantmukho have integrated it into SU2. Is that the case?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-505741019
https://github.com/su2code/SU2/issues/466#issuecomment-505741019:61,Integrability,integrat,integrated,61,"The interpolation tool I use is a standalone program and not integrated into SU2. However, it is possible that @bmunguia and @jayantmukho have integrated it into SU2. Is that the case?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-505741019
https://github.com/su2code/SU2/issues/466#issuecomment-505741019:143,Integrability,integrat,integrated,143,"The interpolation tool I use is a standalone program and not integrated into SU2. However, it is possible that @bmunguia and @jayantmukho have integrated it into SU2. Is that the case?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/466#issuecomment-505741019
https://github.com/su2code/SU2/issues/467#issuecomment-342353441:781,Availability,down,down,781,"Great progress, thanks @clarkpede !. As for your notes, some thoughts:; - I think you are already doing this but just in case... manually specifying the info at each node can be made a little easier by automatically generating the files for the first time if they don't exist at runtime. We had code that would do this for the grid motion case, and perhaps you can reuse it to generate inlet profile files with the correct global ID and dummy free-stream state to save the trouble of finding the global IDs by hand (that is what we wanted to avoid as well). Then you can at least use excel or another text editor to swap out the data.; - I wouldn't worry about interpolation to start. This can be added later.; - MG is a little tough, but I think we should be able to do a mapping down to the coarse levels in a similar way that we do the restarts in the volume mesh. Can you please check the code in LoadRestart() in solver_direct_mean.cpp where we restrict the solution down onto the coarse levels?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-342353441
https://github.com/su2code/SU2/issues/467#issuecomment-342353441:972,Availability,down,down,972,"Great progress, thanks @clarkpede !. As for your notes, some thoughts:; - I think you are already doing this but just in case... manually specifying the info at each node can be made a little easier by automatically generating the files for the first time if they don't exist at runtime. We had code that would do this for the grid motion case, and perhaps you can reuse it to generate inlet profile files with the correct global ID and dummy free-stream state to save the trouble of finding the global IDs by hand (that is what we wanted to avoid as well). Then you can at least use excel or another text editor to swap out the data.; - I wouldn't worry about interpolation to start. This can be added later.; - MG is a little tough, but I think we should be able to do a mapping down to the coarse levels in a similar way that we do the restarts in the volume mesh. Can you please check the code in LoadRestart() in solver_direct_mean.cpp where we restrict the solution down onto the coarse levels?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-342353441
https://github.com/su2code/SU2/issues/467#issuecomment-342353441:901,Performance,Load,LoadRestart,901,"Great progress, thanks @clarkpede !. As for your notes, some thoughts:; - I think you are already doing this but just in case... manually specifying the info at each node can be made a little easier by automatically generating the files for the first time if they don't exist at runtime. We had code that would do this for the grid motion case, and perhaps you can reuse it to generate inlet profile files with the correct global ID and dummy free-stream state to save the trouble of finding the global IDs by hand (that is what we wanted to avoid as well). Then you can at least use excel or another text editor to swap out the data.; - I wouldn't worry about interpolation to start. This can be added later.; - MG is a little tough, but I think we should be able to do a mapping down to the coarse levels in a similar way that we do the restarts in the volume mesh. Can you please check the code in LoadRestart() in solver_direct_mean.cpp where we restrict the solution down onto the coarse levels?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-342353441
https://github.com/su2code/SU2/issues/467#issuecomment-342353441:542,Safety,avoid,avoid,542,"Great progress, thanks @clarkpede !. As for your notes, some thoughts:; - I think you are already doing this but just in case... manually specifying the info at each node can be made a little easier by automatically generating the files for the first time if they don't exist at runtime. We had code that would do this for the grid motion case, and perhaps you can reuse it to generate inlet profile files with the correct global ID and dummy free-stream state to save the trouble of finding the global IDs by hand (that is what we wanted to avoid as well). Then you can at least use excel or another text editor to swap out the data.; - I wouldn't worry about interpolation to start. This can be added later.; - MG is a little tough, but I think we should be able to do a mapping down to the coarse levels in a similar way that we do the restarts in the volume mesh. Can you please check the code in LoadRestart() in solver_direct_mean.cpp where we restrict the solution down onto the coarse levels?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-342353441
https://github.com/su2code/SU2/issues/467#issuecomment-366410742:53,Integrability,wrap,wrap,53,"@clarkpede : I would like to collaborate with you to wrap up the C++ implementation of this feature (I know you have already completed the Python version). If you have some time, can you please push your version to an internal branch of the SU2 repository?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-366410742
https://github.com/su2code/SU2/issues/467#issuecomment-366493237:28,Testability,test,test,28,"@economon I need to fix and test a few things before I push the branch to an internal branch. But I should be able to finish by the end of the next week. If you're looking to improve the C++ inlet profile specification I started, then I'd like to get some feedback on the overall design. There are several different ways to handle this, and I chose what I thought was most logical. I want to make sure that my design choices match your use cases and SU2's design. Should I post a summary here, or would you prefer that I email you?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-366493237
https://github.com/su2code/SU2/issues/467#issuecomment-366493237:373,Testability,log,logical,373,"@economon I need to fix and test a few things before I push the branch to an internal branch. But I should be able to finish by the end of the next week. If you're looking to improve the C++ inlet profile specification I started, then I'd like to get some feedback on the overall design. There are several different ways to handle this, and I chose what I thought was most logical. I want to make sure that my design choices match your use cases and SU2's design. Should I post a summary here, or would you prefer that I email you?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-366493237
https://github.com/su2code/SU2/issues/467#issuecomment-366493237:256,Usability,feedback,feedback,256,"@economon I need to fix and test a few things before I push the branch to an internal branch. But I should be able to finish by the end of the next week. If you're looking to improve the C++ inlet profile specification I started, then I'd like to get some feedback on the overall design. There are several different ways to handle this, and I chose what I thought was most logical. I want to make sure that my design choices match your use cases and SU2's design. Should I post a summary here, or would you prefer that I email you?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-366493237
https://github.com/su2code/SU2/issues/467#issuecomment-368990059:379,Availability,error,error,379,"Alright. I've copied over my changes, with a few improvements. They're on the branch `feature_fileprofile`. One important change is that the user no longer needs to specify the node numbers. For each inlet node on the mesh, the code looks for the closest point from the inlet file. If that closest point is within a specified distance, it deems it a match. If not, it returns an error. Some points:. + The code will generate an example inlet file if the inlet file is missing / is invalid.; + I have not added interpolation. Since python makes interpolation easy, I didn't view this as a high priority.; + I have not added support for multigrid. I'm unsure of how to do this, since I'm not familiar with the multigrid code. It's not as simple as copying what's done for the restarts in the volume mesh. That's a volume based agglomeration, whereas the boundaries are faces. Feel free to modify my implementation however you want.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-368990059
https://github.com/su2code/SU2/issues/467#issuecomment-368990059:736,Usability,simpl,simple,736,"Alright. I've copied over my changes, with a few improvements. They're on the branch `feature_fileprofile`. One important change is that the user no longer needs to specify the node numbers. For each inlet node on the mesh, the code looks for the closest point from the inlet file. If that closest point is within a specified distance, it deems it a match. If not, it returns an error. Some points:. + The code will generate an example inlet file if the inlet file is missing / is invalid.; + I have not added interpolation. Since python makes interpolation easy, I didn't view this as a high priority.; + I have not added support for multigrid. I'm unsure of how to do this, since I'm not familiar with the multigrid code. It's not as simple as copying what's done for the restarts in the volume mesh. That's a volume based agglomeration, whereas the boundaries are faces. Feel free to modify my implementation however you want.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-368990059
https://github.com/su2code/SU2/issues/467#issuecomment-371716916:1068,Availability,toler,tolerance,1068,"I just pushed a new version of your inlet profile branch. I really like the solver class abstractions. I can tell you have a good grip on the classes and where data should live - nice job. Here are the changes I have made:; * everything is generalized in parallel for an arbitrary number of inlets in the file. The file format changed slightly.; * I moved around some routines and data to take more advantage of inheritance and encapsulation: it is now more like the restart routines where the reading and data live in the parent CSolver class, the specific load functions are found in the solvers (I overloaded SetInletAtVertex), and the template file is written by COutput. It is written such that any solver could eventually use it for any marker type by adding the appropriate SetInletAtVertex routine for solver-specific data (might need to rename for different marker types rather than inlet) and writing an appropriate template file writer in the output.; * for now, it is still requiring a essentially a matching profile point (nearest neighbor within a tight tolerance) by default, but you can have an arbitrary number of points in the file for each marker, and we can eventually add interpolation easily. We already have some of these routines.; * the turbulent solvers now all use the Inlet_TurbVars data structure even for uniform inlets. Can you please check this with Python?; * multigrid is now working. I put in a boundary face area-averaged restriction operator for the inlet profiles. Any decent approximation on the coarse levels should work ok. I left all of your original routines there, but deactivated them for the moment. Can you please give it a look and let me know what you think (and whether it is working for you)? Feedback most welcome. If we are happy with it, we can clean it up and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-371716916
https://github.com/su2code/SU2/issues/467#issuecomment-371716916:368,Integrability,rout,routines,368,"I just pushed a new version of your inlet profile branch. I really like the solver class abstractions. I can tell you have a good grip on the classes and where data should live - nice job. Here are the changes I have made:; * everything is generalized in parallel for an arbitrary number of inlets in the file. The file format changed slightly.; * I moved around some routines and data to take more advantage of inheritance and encapsulation: it is now more like the restart routines where the reading and data live in the parent CSolver class, the specific load functions are found in the solvers (I overloaded SetInletAtVertex), and the template file is written by COutput. It is written such that any solver could eventually use it for any marker type by adding the appropriate SetInletAtVertex routine for solver-specific data (might need to rename for different marker types rather than inlet) and writing an appropriate template file writer in the output.; * for now, it is still requiring a essentially a matching profile point (nearest neighbor within a tight tolerance) by default, but you can have an arbitrary number of points in the file for each marker, and we can eventually add interpolation easily. We already have some of these routines.; * the turbulent solvers now all use the Inlet_TurbVars data structure even for uniform inlets. Can you please check this with Python?; * multigrid is now working. I put in a boundary face area-averaged restriction operator for the inlet profiles. Any decent approximation on the coarse levels should work ok. I left all of your original routines there, but deactivated them for the moment. Can you please give it a look and let me know what you think (and whether it is working for you)? Feedback most welcome. If we are happy with it, we can clean it up and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-371716916
https://github.com/su2code/SU2/issues/467#issuecomment-371716916:475,Integrability,rout,routines,475,"I just pushed a new version of your inlet profile branch. I really like the solver class abstractions. I can tell you have a good grip on the classes and where data should live - nice job. Here are the changes I have made:; * everything is generalized in parallel for an arbitrary number of inlets in the file. The file format changed slightly.; * I moved around some routines and data to take more advantage of inheritance and encapsulation: it is now more like the restart routines where the reading and data live in the parent CSolver class, the specific load functions are found in the solvers (I overloaded SetInletAtVertex), and the template file is written by COutput. It is written such that any solver could eventually use it for any marker type by adding the appropriate SetInletAtVertex routine for solver-specific data (might need to rename for different marker types rather than inlet) and writing an appropriate template file writer in the output.; * for now, it is still requiring a essentially a matching profile point (nearest neighbor within a tight tolerance) by default, but you can have an arbitrary number of points in the file for each marker, and we can eventually add interpolation easily. We already have some of these routines.; * the turbulent solvers now all use the Inlet_TurbVars data structure even for uniform inlets. Can you please check this with Python?; * multigrid is now working. I put in a boundary face area-averaged restriction operator for the inlet profiles. Any decent approximation on the coarse levels should work ok. I left all of your original routines there, but deactivated them for the moment. Can you please give it a look and let me know what you think (and whether it is working for you)? Feedback most welcome. If we are happy with it, we can clean it up and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-371716916
https://github.com/su2code/SU2/issues/467#issuecomment-371716916:798,Integrability,rout,routine,798,"I just pushed a new version of your inlet profile branch. I really like the solver class abstractions. I can tell you have a good grip on the classes and where data should live - nice job. Here are the changes I have made:; * everything is generalized in parallel for an arbitrary number of inlets in the file. The file format changed slightly.; * I moved around some routines and data to take more advantage of inheritance and encapsulation: it is now more like the restart routines where the reading and data live in the parent CSolver class, the specific load functions are found in the solvers (I overloaded SetInletAtVertex), and the template file is written by COutput. It is written such that any solver could eventually use it for any marker type by adding the appropriate SetInletAtVertex routine for solver-specific data (might need to rename for different marker types rather than inlet) and writing an appropriate template file writer in the output.; * for now, it is still requiring a essentially a matching profile point (nearest neighbor within a tight tolerance) by default, but you can have an arbitrary number of points in the file for each marker, and we can eventually add interpolation easily. We already have some of these routines.; * the turbulent solvers now all use the Inlet_TurbVars data structure even for uniform inlets. Can you please check this with Python?; * multigrid is now working. I put in a boundary face area-averaged restriction operator for the inlet profiles. Any decent approximation on the coarse levels should work ok. I left all of your original routines there, but deactivated them for the moment. Can you please give it a look and let me know what you think (and whether it is working for you)? Feedback most welcome. If we are happy with it, we can clean it up and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-371716916
https://github.com/su2code/SU2/issues/467#issuecomment-371716916:1245,Integrability,rout,routines,1245,"I just pushed a new version of your inlet profile branch. I really like the solver class abstractions. I can tell you have a good grip on the classes and where data should live - nice job. Here are the changes I have made:; * everything is generalized in parallel for an arbitrary number of inlets in the file. The file format changed slightly.; * I moved around some routines and data to take more advantage of inheritance and encapsulation: it is now more like the restart routines where the reading and data live in the parent CSolver class, the specific load functions are found in the solvers (I overloaded SetInletAtVertex), and the template file is written by COutput. It is written such that any solver could eventually use it for any marker type by adding the appropriate SetInletAtVertex routine for solver-specific data (might need to rename for different marker types rather than inlet) and writing an appropriate template file writer in the output.; * for now, it is still requiring a essentially a matching profile point (nearest neighbor within a tight tolerance) by default, but you can have an arbitrary number of points in the file for each marker, and we can eventually add interpolation easily. We already have some of these routines.; * the turbulent solvers now all use the Inlet_TurbVars data structure even for uniform inlets. Can you please check this with Python?; * multigrid is now working. I put in a boundary face area-averaged restriction operator for the inlet profiles. Any decent approximation on the coarse levels should work ok. I left all of your original routines there, but deactivated them for the moment. Can you please give it a look and let me know what you think (and whether it is working for you)? Feedback most welcome. If we are happy with it, we can clean it up and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-371716916
https://github.com/su2code/SU2/issues/467#issuecomment-371716916:1593,Integrability,rout,routines,1593,"I just pushed a new version of your inlet profile branch. I really like the solver class abstractions. I can tell you have a good grip on the classes and where data should live - nice job. Here are the changes I have made:; * everything is generalized in parallel for an arbitrary number of inlets in the file. The file format changed slightly.; * I moved around some routines and data to take more advantage of inheritance and encapsulation: it is now more like the restart routines where the reading and data live in the parent CSolver class, the specific load functions are found in the solvers (I overloaded SetInletAtVertex), and the template file is written by COutput. It is written such that any solver could eventually use it for any marker type by adding the appropriate SetInletAtVertex routine for solver-specific data (might need to rename for different marker types rather than inlet) and writing an appropriate template file writer in the output.; * for now, it is still requiring a essentially a matching profile point (nearest neighbor within a tight tolerance) by default, but you can have an arbitrary number of points in the file for each marker, and we can eventually add interpolation easily. We already have some of these routines.; * the turbulent solvers now all use the Inlet_TurbVars data structure even for uniform inlets. Can you please check this with Python?; * multigrid is now working. I put in a boundary face area-averaged restriction operator for the inlet profiles. Any decent approximation on the coarse levels should work ok. I left all of your original routines there, but deactivated them for the moment. Can you please give it a look and let me know what you think (and whether it is working for you)? Feedback most welcome. If we are happy with it, we can clean it up and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-371716916
https://github.com/su2code/SU2/issues/467#issuecomment-371716916:412,Modifiability,inherit,inheritance,412,"I just pushed a new version of your inlet profile branch. I really like the solver class abstractions. I can tell you have a good grip on the classes and where data should live - nice job. Here are the changes I have made:; * everything is generalized in parallel for an arbitrary number of inlets in the file. The file format changed slightly.; * I moved around some routines and data to take more advantage of inheritance and encapsulation: it is now more like the restart routines where the reading and data live in the parent CSolver class, the specific load functions are found in the solvers (I overloaded SetInletAtVertex), and the template file is written by COutput. It is written such that any solver could eventually use it for any marker type by adding the appropriate SetInletAtVertex routine for solver-specific data (might need to rename for different marker types rather than inlet) and writing an appropriate template file writer in the output.; * for now, it is still requiring a essentially a matching profile point (nearest neighbor within a tight tolerance) by default, but you can have an arbitrary number of points in the file for each marker, and we can eventually add interpolation easily. We already have some of these routines.; * the turbulent solvers now all use the Inlet_TurbVars data structure even for uniform inlets. Can you please check this with Python?; * multigrid is now working. I put in a boundary face area-averaged restriction operator for the inlet profiles. Any decent approximation on the coarse levels should work ok. I left all of your original routines there, but deactivated them for the moment. Can you please give it a look and let me know what you think (and whether it is working for you)? Feedback most welcome. If we are happy with it, we can clean it up and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-371716916
https://github.com/su2code/SU2/issues/467#issuecomment-371716916:558,Performance,load,load,558,"I just pushed a new version of your inlet profile branch. I really like the solver class abstractions. I can tell you have a good grip on the classes and where data should live - nice job. Here are the changes I have made:; * everything is generalized in parallel for an arbitrary number of inlets in the file. The file format changed slightly.; * I moved around some routines and data to take more advantage of inheritance and encapsulation: it is now more like the restart routines where the reading and data live in the parent CSolver class, the specific load functions are found in the solvers (I overloaded SetInletAtVertex), and the template file is written by COutput. It is written such that any solver could eventually use it for any marker type by adding the appropriate SetInletAtVertex routine for solver-specific data (might need to rename for different marker types rather than inlet) and writing an appropriate template file writer in the output.; * for now, it is still requiring a essentially a matching profile point (nearest neighbor within a tight tolerance) by default, but you can have an arbitrary number of points in the file for each marker, and we can eventually add interpolation easily. We already have some of these routines.; * the turbulent solvers now all use the Inlet_TurbVars data structure even for uniform inlets. Can you please check this with Python?; * multigrid is now working. I put in a boundary face area-averaged restriction operator for the inlet profiles. Any decent approximation on the coarse levels should work ok. I left all of your original routines there, but deactivated them for the moment. Can you please give it a look and let me know what you think (and whether it is working for you)? Feedback most welcome. If we are happy with it, we can clean it up and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-371716916
https://github.com/su2code/SU2/issues/467#issuecomment-371716916:1744,Usability,Feedback,Feedback,1744,"I just pushed a new version of your inlet profile branch. I really like the solver class abstractions. I can tell you have a good grip on the classes and where data should live - nice job. Here are the changes I have made:; * everything is generalized in parallel for an arbitrary number of inlets in the file. The file format changed slightly.; * I moved around some routines and data to take more advantage of inheritance and encapsulation: it is now more like the restart routines where the reading and data live in the parent CSolver class, the specific load functions are found in the solvers (I overloaded SetInletAtVertex), and the template file is written by COutput. It is written such that any solver could eventually use it for any marker type by adding the appropriate SetInletAtVertex routine for solver-specific data (might need to rename for different marker types rather than inlet) and writing an appropriate template file writer in the output.; * for now, it is still requiring a essentially a matching profile point (nearest neighbor within a tight tolerance) by default, but you can have an arbitrary number of points in the file for each marker, and we can eventually add interpolation easily. We already have some of these routines.; * the turbulent solvers now all use the Inlet_TurbVars data structure even for uniform inlets. Can you please check this with Python?; * multigrid is now working. I put in a boundary face area-averaged restriction operator for the inlet profiles. Any decent approximation on the coarse levels should work ok. I left all of your original routines there, but deactivated them for the moment. Can you please give it a look and let me know what you think (and whether it is working for you)? Feedback most welcome. If we are happy with it, we can clean it up and submit a PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/467#issuecomment-371716916
https://github.com/su2code/SU2/issues/468#issuecomment-342348565:305,Deployability,update,update,305,"Hi Akshay: . Both issues are certainly true, plus there are even more problems :). At the moment, the incompressible solver does not have an implementation of the ALE terms needed for grid motion cases, and it is likely that the rotating source term should be double-checked. We are in the midst of a big update to the incompressible solver as we speak though, and this is on the list. First, can you get by with the compressible code at low (but reasonable) Mach numbers for now, say 0.1? Second, are you interested in developing some of these capabilities (ALE, rotating frame) once we finish the incompressible solver upgrade?. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/468#issuecomment-342348565
https://github.com/su2code/SU2/issues/468#issuecomment-342348565:621,Deployability,upgrade,upgrade,621,"Hi Akshay: . Both issues are certainly true, plus there are even more problems :). At the moment, the incompressible solver does not have an implementation of the ALE terms needed for grid motion cases, and it is likely that the rotating source term should be double-checked. We are in the midst of a big update to the incompressible solver as we speak though, and this is on the list. First, can you get by with the compressible code at low (but reasonable) Mach numbers for now, say 0.1? Second, are you interested in developing some of these capabilities (ALE, rotating frame) once we finish the incompressible solver upgrade?. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/468#issuecomment-342348565
https://github.com/su2code/SU2/issues/468#issuecomment-343086793:119,Usability,guid,guidance,119,"Hi Tom,; ; I would like to work on the ALE and rotating frame implementations for incompressible solver. Under Edwin's guidance I have been looking at SU2 closely over the past few months and, as you might have heard from him, we are looking to implement a pressure based scheme. . Also, could you tell me more about what are the changes you are planning for the incompressible solver? . Thanks a lot.; Regards,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/468#issuecomment-343086793
https://github.com/su2code/SU2/issues/469#issuecomment-345215874:93,Modifiability,variab,variable,93,"You can override the command that is used to launch parallel jobs by setting the environment variable `SU2_MPI_COMMAND`. For example on our cluster I had to force it to use the usual mpi command with `export SU2_MPI_COMMAND=""mpirun -n %i %s""`, otherwise it tried to use `srun` which didn't work with our setup.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/469#issuecomment-345215874
https://github.com/su2code/SU2/issues/469#issuecomment-707290679:106,Usability,clear,clear,106,I have the same problem but I don't understand the solutions you suggested. Could you explain to me a bit clear?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/469#issuecomment-707290679
https://github.com/su2code/SU2/issues/470#issuecomment-351961812:381,Energy Efficiency,schedul,scheduled,381,"Hi @economon ,. I would like to take a quick glance on the presented slides in advance. I always find it easier to follow when I already know whats coming my way. I know that slides are often finished the exact second before the presentation but maybe I am lucky. Also considering that it is quite late here in Germany and the concentration level might drop a little, although you scheduled the Conference quite ""Europe-friendly"" :) . Thanks already,; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/470#issuecomment-351961812
https://github.com/su2code/SU2/issues/470#issuecomment-352088919:857,Energy Efficiency,schedul,scheduled,857,"Tobi,. We have asked all presenters for slides on Sunday. We will link them to the agenda in the SU2 main web pages shortly after we receive them and you should be able to see them on Monday morning (your morning) and have a few hours to review them before the actual meeting starts at 8 am Pacific / 5pm in Germany. Best wishes,. Juan. On Dec 15, 2017, at 1:48 AM, TobiKattmann <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @economon<https://github.com/economon> ,. I would like to take a quick glance on the presented slides in advance. I always find it easier to follow when I already know whats coming my way. I know that slides are often finished the exact second before the presentation but maybe I am lucky. Also considering that it is quite late here in Germany and the concentration level might drop a little, although you scheduled the Conference quite ""Europe-friendly"" :). Thanks already,; Tobi. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/470#issuecomment-351961812>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxFNRIn3cnh34ZYSaHSuUE72mZK7fks5tAkBngaJpZM4QVjsL>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/470#issuecomment-352088919
https://github.com/su2code/SU2/pull/472#issuecomment-346165153:119,Integrability,rout,routine,119,Can we set Velocity_Ref to 1.0 and Alpha and Beta to 0.0 in case ModVel_Freestream is zero in SetNondinemsionalisation routine? There might some cases of pure rotation with zero free stream velocity which makes many variables in Pressure_Forces/Momentum_Forces/Friction_Forces undefined because Velocity_Ref goes to zero.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/472#issuecomment-346165153
https://github.com/su2code/SU2/pull/472#issuecomment-346165153:216,Modifiability,variab,variables,216,Can we set Velocity_Ref to 1.0 and Alpha and Beta to 0.0 in case ModVel_Freestream is zero in SetNondinemsionalisation routine? There might some cases of pure rotation with zero free stream velocity which makes many variables in Pressure_Forces/Momentum_Forces/Friction_Forces undefined because Velocity_Ref goes to zero.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/472#issuecomment-346165153
https://github.com/su2code/SU2/pull/473#issuecomment-346190604:85,Availability,error,errors,85,"I am also having some trouble building this with GCC 4.7.2 + OpenMPI 1.10.1. Lots of errors like:. CXX ../src/libSU2_AD_a-config_structure.o; In file included from ../../../Common/lib/../src/../include/./mpi_structure.hpp:58:0,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/medi/include/medi/codiMediPackTypes.hpp: In instantiation of void CoDiPackToolBase<CoDiType, primalRestore, Impl>::addToolAction(medi::HandleBase*) [with CoDiType = codi::ActiveReal<codi::JacobiTape<codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> > > >; bool primalRestore = false; Impl = CoDiPackTool<codi::ActiveReal<codi::JacobiTape<codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> > > > >]:; ../../../externals/medi/include/medi/../../generated/medi/ampiFunctions.hpp:874:9: required from int medi::AMPI_Isend(const typename DATATYPE::Type*, int, DATATYPE*, int, int, MPI_Comm, medi::AMPI_Request*) [with DATATYPE = medi::MpiTypeDefault<CoDiPackTool<codi::ActiveReal<codi::JacobiTape<codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> > > > > >; typename DATATYPE::Type = codi::ActiveReal<codi::JacobiTape<codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> > > >; MPI_Comm = ompi_communicator_t*]; ../../../Common/lib/../src/../include/./mpi_structure.inl:216:85: required from here; ../../../externals/medi/include/medi/codiMediPackTypes.hpp:255:7: error: invalid conversion from void (*)(void*, void*) to codi::ExternalFunction::CallFunction {aka void (*)(void*)} [-fpermissive]; In file included from ../../../externals/codi/include/tapes/jacobiTape.hpp:195:0,; from ../../../externals/codi/include/codi.hpp:35,; from ../../../Common/lib/../src/../include/././datatypes/codi_reverse_structure.hpp:35,; from ../../../Common/lib/../src/../include/././datatype_structure.hpp:47,; from ../../../Common/lib/../src/../include/./mpi_structure.hpp:42,; from ../../../Common/lib/../s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346190604
https://github.com/su2code/SU2/pull/473#issuecomment-346190604:1470,Availability,error,error,1470,"i::ActiveReal<codi::JacobiTape<codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> > > >; bool primalRestore = false; Impl = CoDiPackTool<codi::ActiveReal<codi::JacobiTape<codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> > > > >]:; ../../../externals/medi/include/medi/../../generated/medi/ampiFunctions.hpp:874:9: required from int medi::AMPI_Isend(const typename DATATYPE::Type*, int, DATATYPE*, int, int, MPI_Comm, medi::AMPI_Request*) [with DATATYPE = medi::MpiTypeDefault<CoDiPackTool<codi::ActiveReal<codi::JacobiTape<codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> > > > > >; typename DATATYPE::Type = codi::ActiveReal<codi::JacobiTape<codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> > > >; MPI_Comm = ompi_communicator_t*]; ../../../Common/lib/../src/../include/./mpi_structure.inl:216:85: required from here; ../../../externals/medi/include/medi/codiMediPackTypes.hpp:255:7: error: invalid conversion from void (*)(void*, void*) to codi::ExternalFunction::CallFunction {aka void (*)(void*)} [-fpermissive]; In file included from ../../../externals/codi/include/tapes/jacobiTape.hpp:195:0,; from ../../../externals/codi/include/codi.hpp:35,; from ../../../Common/lib/../src/../include/././datatypes/codi_reverse_structure.hpp:35,; from ../../../Common/lib/../src/../include/././datatype_structure.hpp:47,; from ../../../Common/lib/../src/../include/./mpi_structure.hpp:42,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/codi/include/tapes/modules/externalFunctionsModule.tpp:245:10: error: initializing argument 1 of void codi::JacobiTape<TapeTypes>::pushExternalFunctionHandle(codi::ExternalFunction::CallFunction, void*, codi::ExternalFunction::DeleteFunction) [with TapeTypes = codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> >; codi::ExternalFunction::CallFunction = void (*)(void*); codi::ExternalFunction::DeleteFunction = void ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346190604
https://github.com/su2code/SU2/pull/473#issuecomment-346190604:2181,Availability,error,error,2181,": required from here; ../../../externals/medi/include/medi/codiMediPackTypes.hpp:255:7: error: invalid conversion from void (*)(void*, void*) to codi::ExternalFunction::CallFunction {aka void (*)(void*)} [-fpermissive]; In file included from ../../../externals/codi/include/tapes/jacobiTape.hpp:195:0,; from ../../../externals/codi/include/codi.hpp:35,; from ../../../Common/lib/../src/../include/././datatypes/codi_reverse_structure.hpp:35,; from ../../../Common/lib/../src/../include/././datatype_structure.hpp:47,; from ../../../Common/lib/../src/../include/./mpi_structure.hpp:42,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/codi/include/tapes/modules/externalFunctionsModule.tpp:245:10: error: initializing argument 1 of void codi::JacobiTape<TapeTypes>::pushExternalFunctionHandle(codi::ExternalFunction::CallFunction, void*, codi::ExternalFunction::DeleteFunction) [with TapeTypes = codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> >; codi::ExternalFunction::CallFunction = void (*)(void*); codi::ExternalFunction::DeleteFunction = void (*)(void*)] [-fpermissive]; In file included from ../../../Common/lib/../src/../include/./mpi_structure.hpp:58:0,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/medi/include/medi/codiMediPackTypes.hpp:255:7: error: invalid conversion from void (*)(void*, void*) to codi::ExternalFunction::DeleteFunction {aka void (*)(void*)} [-fpermissive]; In file included from ../../../externals/codi/include/tapes/jacobiTape.hpp:195:0,; from ../../../externals/codi/include/codi.hpp:35,; from ../../../Common/lib/../src/../include/././datatypes/codi_reverse_structure.hpp:35,; from ../../../Common/lib/../src/../include/././datatype_structure.hpp:47,; from ../../../Common/lib/../src/../include/./mpi_structure.hpp:42,; from ../../../Common/lib/.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346190604
https://github.com/su2code/SU2/pull/473#issuecomment-346190604:2853,Availability,error,error,2853,"/../src/../include/./mpi_structure.hpp:42,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/codi/include/tapes/modules/externalFunctionsModule.tpp:245:10: error: initializing argument 1 of void codi::JacobiTape<TapeTypes>::pushExternalFunctionHandle(codi::ExternalFunction::CallFunction, void*, codi::ExternalFunction::DeleteFunction) [with TapeTypes = codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> >; codi::ExternalFunction::CallFunction = void (*)(void*); codi::ExternalFunction::DeleteFunction = void (*)(void*)] [-fpermissive]; In file included from ../../../Common/lib/../src/../include/./mpi_structure.hpp:58:0,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/medi/include/medi/codiMediPackTypes.hpp:255:7: error: invalid conversion from void (*)(void*, void*) to codi::ExternalFunction::DeleteFunction {aka void (*)(void*)} [-fpermissive]; In file included from ../../../externals/codi/include/tapes/jacobiTape.hpp:195:0,; from ../../../externals/codi/include/codi.hpp:35,; from ../../../Common/lib/../src/../include/././datatypes/codi_reverse_structure.hpp:35,; from ../../../Common/lib/../src/../include/././datatype_structure.hpp:47,; from ../../../Common/lib/../src/../include/./mpi_structure.hpp:42,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/codi/include/tapes/modules/externalFunctionsModule.tpp:245:10: error: initializing argument 3 of void codi::JacobiTape<TapeTypes>::pushExternalFunctionHandle(codi::ExternalFunction::CallFunction, void*, codi::ExternalFunction::DeleteFunction) [with TapeTypes = codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> >; codi::ExternalFunction::CallFunction = void (*)(void*); codi::ExternalFunction::DeleteFunction = void",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346190604
https://github.com/su2code/SU2/pull/473#issuecomment-346190604:3566,Availability,error,error,3566,"fig_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/codi/include/tapes/modules/externalFunctionsModule.tpp:245:10: error: initializing argument 1 of void codi::JacobiTape<TapeTypes>::pushExternalFunctionHandle(codi::ExternalFunction::CallFunction, void*, codi::ExternalFunction::DeleteFunction) [with TapeTypes = codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> >; codi::ExternalFunction::CallFunction = void (*)(void*); codi::ExternalFunction::DeleteFunction = void (*)(void*)] [-fpermissive]; In file included from ../../../Common/lib/../src/../include/./mpi_structure.hpp:58:0,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/medi/include/medi/codiMediPackTypes.hpp:255:7: error: invalid conversion from void (*)(void*, void*) to codi::ExternalFunction::DeleteFunction {aka void (*)(void*)} [-fpermissive]; In file included from ../../../externals/codi/include/tapes/jacobiTape.hpp:195:0,; from ../../../externals/codi/include/codi.hpp:35,; from ../../../Common/lib/../src/../include/././datatypes/codi_reverse_structure.hpp:35,; from ../../../Common/lib/../src/../include/././datatype_structure.hpp:47,; from ../../../Common/lib/../src/../include/./mpi_structure.hpp:42,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/codi/include/tapes/modules/externalFunctionsModule.tpp:245:10: error: initializing argument 3 of void codi::JacobiTape<TapeTypes>::pushExternalFunctionHandle(codi::ExternalFunction::CallFunction, void*, codi::ExternalFunction::DeleteFunction) [with TapeTypes = codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> >; codi::ExternalFunction::CallFunction = void (*)(void*); codi::ExternalFunction::DeleteFunction = void (*)(void*)] [-fpermissive]; make[2]: *** [../src/libSU2_AD_a-config_structure.o] Error 1",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346190604
https://github.com/su2code/SU2/pull/473#issuecomment-346190604:4011,Availability,Error,Error,4011,"fig_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/codi/include/tapes/modules/externalFunctionsModule.tpp:245:10: error: initializing argument 1 of void codi::JacobiTape<TapeTypes>::pushExternalFunctionHandle(codi::ExternalFunction::CallFunction, void*, codi::ExternalFunction::DeleteFunction) [with TapeTypes = codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> >; codi::ExternalFunction::CallFunction = void (*)(void*); codi::ExternalFunction::DeleteFunction = void (*)(void*)] [-fpermissive]; In file included from ../../../Common/lib/../src/../include/./mpi_structure.hpp:58:0,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/medi/include/medi/codiMediPackTypes.hpp:255:7: error: invalid conversion from void (*)(void*, void*) to codi::ExternalFunction::DeleteFunction {aka void (*)(void*)} [-fpermissive]; In file included from ../../../externals/codi/include/tapes/jacobiTape.hpp:195:0,; from ../../../externals/codi/include/codi.hpp:35,; from ../../../Common/lib/../src/../include/././datatypes/codi_reverse_structure.hpp:35,; from ../../../Common/lib/../src/../include/././datatype_structure.hpp:47,; from ../../../Common/lib/../src/../include/./mpi_structure.hpp:42,; from ../../../Common/lib/../src/../include/config_structure.hpp:37,; from ../../../Common/lib/../src/config_structure.cpp:34:; ../../../externals/codi/include/tapes/modules/externalFunctionsModule.tpp:245:10: error: initializing argument 3 of void codi::JacobiTape<TapeTypes>::pushExternalFunctionHandle(codi::ExternalFunction::CallFunction, void*, codi::ExternalFunction::DeleteFunction) [with TapeTypes = codi::ChunkTapeTypes<double, codi::LinearIndexHandler<int> >; codi::ExternalFunction::CallFunction = void (*)(void*); codi::ExternalFunction::DeleteFunction = void (*)(void*)] [-fpermissive]; make[2]: *** [../src/libSU2_AD_a-config_structure.o] Error 1",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346190604
https://github.com/su2code/SU2/pull/473#issuecomment-346272157:41,Deployability,update,updated,41,"It looks like the codi submodule was not updated properly. Can you try to run the preconfigure command with the additional option ""-u"" ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346272157
https://github.com/su2code/SU2/pull/473#issuecomment-346273506:1061,Availability,error,error,1061,"Maybe we could define the NO_OPTINAL_CONST based on the MPI Version. https://stackoverflow.com/questions/17772906/why-does-mpi-send-accept-void-source. Gives a hint as to when the transition was made. On Tue, 2017-11-21 at 19:53 +0000, Tim Albring wrote:. @talbring commented on this pull request. ________________________________. In .travis.yml<https://github.com/su2code/SU2/pull/473#discussion_r152384146>:. > @@ -20,7 +20,7 @@ branches:. env:; global:; - CXXFLAGS=""-O3 -Wall -Wextra -Wno-unused-parameter -Wno-empty-body -Wno-format-security""; + CXXFLAGS=""-O3 -Wall -Wextra -Wno-unused-parameter -Wno-empty-body -Wno-format-security -DMEDI_NO_OPTIONAL_CONST"". The problem is that depending on the actual MPI implementation (so for example MPICH, openmpi etc.) send buffer arguments might be declared as const or not. Unfortunately, there is no (easy) way to get that information automatically. It might be even different between versions of openmpi (on travis it is v1.6.5 and its necessary, locally I have v3.x, and its not)... so for now it is trial and error whether this is necessary or not. Maybe I can find that information somewhere, then I will provide it in the wiki. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/473#discussion_r152384146>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AMWwAeCRxzq9FO4-6pkSHTDnihbtByhvks5s4yoygaJpZM4QmNie>. --. Max Sagebaum Chair for Scientific Computing, TU Kaiserslautern, Bldg/Geb 34, Paul-Ehrlich-Strasse, 67663 Kaiserslautern, Germany Phone: +49 (0)631 205 5638 Fax: +49 (0)631 205 3056 Email: max.sagebaum@scicomp.uni-kl.de URL: www.scicomp.uni-kl.de",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346273506
https://github.com/su2code/SU2/pull/473#issuecomment-346273506:685,Integrability,depend,depending,685,"Maybe we could define the NO_OPTINAL_CONST based on the MPI Version. https://stackoverflow.com/questions/17772906/why-does-mpi-send-accept-void-source. Gives a hint as to when the transition was made. On Tue, 2017-11-21 at 19:53 +0000, Tim Albring wrote:. @talbring commented on this pull request. ________________________________. In .travis.yml<https://github.com/su2code/SU2/pull/473#discussion_r152384146>:. > @@ -20,7 +20,7 @@ branches:. env:; global:; - CXXFLAGS=""-O3 -Wall -Wextra -Wno-unused-parameter -Wno-empty-body -Wno-format-security""; + CXXFLAGS=""-O3 -Wall -Wextra -Wno-unused-parameter -Wno-empty-body -Wno-format-security -DMEDI_NO_OPTIONAL_CONST"". The problem is that depending on the actual MPI implementation (so for example MPICH, openmpi etc.) send buffer arguments might be declared as const or not. Unfortunately, there is no (easy) way to get that information automatically. It might be even different between versions of openmpi (on travis it is v1.6.5 and its necessary, locally I have v3.x, and its not)... so for now it is trial and error whether this is necessary or not. Maybe I can find that information somewhere, then I will provide it in the wiki. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/473#discussion_r152384146>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AMWwAeCRxzq9FO4-6pkSHTDnihbtByhvks5s4yoygaJpZM4QmNie>. --. Max Sagebaum Chair for Scientific Computing, TU Kaiserslautern, Bldg/Geb 34, Paul-Ehrlich-Strasse, 67663 Kaiserslautern, Germany Phone: +49 (0)631 205 5638 Fax: +49 (0)631 205 3056 Email: max.sagebaum@scicomp.uni-kl.de URL: www.scicomp.uni-kl.de",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346273506
https://github.com/su2code/SU2/pull/473#issuecomment-346273506:538,Security,secur,security,538,"Maybe we could define the NO_OPTINAL_CONST based on the MPI Version. https://stackoverflow.com/questions/17772906/why-does-mpi-send-accept-void-source. Gives a hint as to when the transition was made. On Tue, 2017-11-21 at 19:53 +0000, Tim Albring wrote:. @talbring commented on this pull request. ________________________________. In .travis.yml<https://github.com/su2code/SU2/pull/473#discussion_r152384146>:. > @@ -20,7 +20,7 @@ branches:. env:; global:; - CXXFLAGS=""-O3 -Wall -Wextra -Wno-unused-parameter -Wno-empty-body -Wno-format-security""; + CXXFLAGS=""-O3 -Wall -Wextra -Wno-unused-parameter -Wno-empty-body -Wno-format-security -DMEDI_NO_OPTIONAL_CONST"". The problem is that depending on the actual MPI implementation (so for example MPICH, openmpi etc.) send buffer arguments might be declared as const or not. Unfortunately, there is no (easy) way to get that information automatically. It might be even different between versions of openmpi (on travis it is v1.6.5 and its necessary, locally I have v3.x, and its not)... so for now it is trial and error whether this is necessary or not. Maybe I can find that information somewhere, then I will provide it in the wiki. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/473#discussion_r152384146>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AMWwAeCRxzq9FO4-6pkSHTDnihbtByhvks5s4yoygaJpZM4QmNie>. --. Max Sagebaum Chair for Scientific Computing, TU Kaiserslautern, Bldg/Geb 34, Paul-Ehrlich-Strasse, 67663 Kaiserslautern, Germany Phone: +49 (0)631 205 5638 Fax: +49 (0)631 205 3056 Email: max.sagebaum@scicomp.uni-kl.de URL: www.scicomp.uni-kl.de",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346273506
https://github.com/su2code/SU2/pull/473#issuecomment-346273506:629,Security,secur,security,629,"Maybe we could define the NO_OPTINAL_CONST based on the MPI Version. https://stackoverflow.com/questions/17772906/why-does-mpi-send-accept-void-source. Gives a hint as to when the transition was made. On Tue, 2017-11-21 at 19:53 +0000, Tim Albring wrote:. @talbring commented on this pull request. ________________________________. In .travis.yml<https://github.com/su2code/SU2/pull/473#discussion_r152384146>:. > @@ -20,7 +20,7 @@ branches:. env:; global:; - CXXFLAGS=""-O3 -Wall -Wextra -Wno-unused-parameter -Wno-empty-body -Wno-format-security""; + CXXFLAGS=""-O3 -Wall -Wextra -Wno-unused-parameter -Wno-empty-body -Wno-format-security -DMEDI_NO_OPTIONAL_CONST"". The problem is that depending on the actual MPI implementation (so for example MPICH, openmpi etc.) send buffer arguments might be declared as const or not. Unfortunately, there is no (easy) way to get that information automatically. It might be even different between versions of openmpi (on travis it is v1.6.5 and its necessary, locally I have v3.x, and its not)... so for now it is trial and error whether this is necessary or not. Maybe I can find that information somewhere, then I will provide it in the wiki. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/473#discussion_r152384146>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AMWwAeCRxzq9FO4-6pkSHTDnihbtByhvks5s4yoygaJpZM4QmNie>. --. Max Sagebaum Chair for Scientific Computing, TU Kaiserslautern, Bldg/Geb 34, Paul-Ehrlich-Strasse, 67663 Kaiserslautern, Germany Phone: +49 (0)631 205 5638 Fax: +49 (0)631 205 3056 Email: max.sagebaum@scicomp.uni-kl.de URL: www.scicomp.uni-kl.de",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-346273506
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:87,Availability,error,error,87,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:185,Availability,error,error,185,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:248,Availability,Error,Error,248,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:688,Availability,Error,Error,688,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1077,Availability,error,error,1077,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1127,Availability,Error,Error,1127,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1134,Availability,Error,Error,1134,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1304,Availability,error,error,1304,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:452,Deployability,configurat,configuration,452,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1140,Integrability,Message,Message,1140,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1249,Integrability,rout,routine,1249,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1310,Integrability,message,messages,1310,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1377,Integrability,Wrap,Wrapper,1377,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1562,Integrability,rout,routine,1562,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:452,Modifiability,config,configuration,452,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-347663941:1092,Usability,simpl,simply,1092,"A short summary of the things I did in the additional commits:. - I added a consistent error handling that can be used throughout the code. For example if a marker is not specified the error looks like that: ; ```; -------------------------------- Error ---------------------------------; In ""short unsigned int CConfig::GetMarker_CfgFile_TagBound(std::__cxx11::string)"": ; ------------------------------------------------------------------------; The configuration file doesn't have any definition for marker airfoil; ------------------------------------------------------------------------; Exiting now ...; ```; or if a solution cannot be found:. ```; -------------------------------- Error ---------------------------------; In ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; ------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------------------------------------------------; Exiting now ...; ```; In case you want to throw an error, you can simply call the function `SU2_MPI::Error(""Error Message"", CURRENT_FUNCTION)` where `CURRENT_FUNCTION` is a predefined macro which expands to the name of the routine at compile time. I already replaced almost all error messages in the code. - More MPI functions are included in the MPI Wrapper. - The rank/size is now stored in most of the bigger classes and initialized in the constructor. That means there are no calls to MPI_Comm_rank / MPI_Comm_size anymore in every routine ... For convenience there is also a SU2_MPI::GetRank() / SU2_MPI::GetSize(), in case you need it outside of the main classes. Let me know what you think. Not everything I did has to stay the way I implemented it :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-347663941
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:53,Availability,error,error,53,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:278,Availability,error,error,278,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:480,Availability,error,error,480,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:548,Availability,Error,Error,548,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:954,Availability,error,error,954,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:1112,Availability,error,errors,1112,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:1302,Availability,error,error,1302,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:1457,Availability,Error,Error,1457,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:960,Integrability,rout,routine,960,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350111995:1308,Integrability,message,message,1308,"Looking ok for me now on ubuntu, but I am getting an error on OS X w/ Apple LLVM:. In file included from ../../../Common/lib/../src/mpi_structure.cpp:43:; In file included from ../../../externals/medi/src/medi/medi.cpp:29:; ../../../externals/medi/src/medi/ampi/ampi.cpp:39:28: error: default initialization of an object of const type 'const medi::AMPI_IN_PLACE_IMPL' without a user-provided default constructor; const AMPI_IN_PLACE_IMPL AMPI_IN_PLACE;; ^; {}; 296 warnings and 1 error generated.; make[2]: *** [../src/libSU2_AD_a-mpi_structure.o] Error 1. Also, lots of overloaded virtual warnings for multiple functions in the passive type header, such as:. ../../../externals/medi/include/medi/ampi/../../../generated/medi/../../include/medi/ampi/typePassive.hpp:159:19: warning: 'medi::MpiTypePassive<medi::PairWithInt<long double> >::createModifiedTypeBuffer' hides overloaded virtual; function [-Woverloaded-virtual]. Lastly, I really like the new error routine. Nice work. My only (picky) comments are on the formatting: could you please add a couple of empty lines of white space after the exit? The SU2 errors are getting lost with some other MPI clean up output and are not easy for the user to see immediately. One more personal preference: I would go without the line btwn the function and error message for clarity and, for consistency with the successful exit, remove the ""Exiting now..."" in favor of something like. ------------------------- Error Exit (SU2_CFD) ------------------------. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350111995
https://github.com/su2code/SU2/pull/473#issuecomment-350366632:14,Availability,error,error,14,"@economon the error will be fixed in the next commit. About the error message: I added the additional dashed line in order to immediately see the error message. . What about the following ?; ```; ...; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ----------------------------- Exit Failure ------------------------------. ```. Unfortunately I cannot get the kind of SU2 module in the interface ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350366632
https://github.com/su2code/SU2/pull/473#issuecomment-350366632:64,Availability,error,error,64,"@economon the error will be fixed in the next commit. About the error message: I added the additional dashed line in order to immediately see the error message. . What about the following ?; ```; ...; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ----------------------------- Exit Failure ------------------------------. ```. Unfortunately I cannot get the kind of SU2 module in the interface ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350366632
https://github.com/su2code/SU2/pull/473#issuecomment-350366632:146,Availability,error,error,146,"@economon the error will be fixed in the next commit. About the error message: I added the additional dashed line in order to immediately see the error message. . What about the following ?; ```; ...; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ----------------------------- Exit Failure ------------------------------. ```. Unfortunately I cannot get the kind of SU2 module in the interface ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350366632
https://github.com/su2code/SU2/pull/473#issuecomment-350366632:401,Availability,Error,Error,401,"@economon the error will be fixed in the next commit. About the error message: I added the additional dashed line in order to immediately see the error message. . What about the following ?; ```; ...; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ----------------------------- Exit Failure ------------------------------. ```. Unfortunately I cannot get the kind of SU2 module in the interface ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350366632
https://github.com/su2code/SU2/pull/473#issuecomment-350366632:666,Availability,Failure,Failure,666,"@economon the error will be fixed in the next commit. About the error message: I added the additional dashed line in order to immediately see the error message. . What about the following ?; ```; ...; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ----------------------------- Exit Failure ------------------------------. ```. Unfortunately I cannot get the kind of SU2 module in the interface ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350366632
https://github.com/su2code/SU2/pull/473#issuecomment-350366632:70,Integrability,message,message,70,"@economon the error will be fixed in the next commit. About the error message: I added the additional dashed line in order to immediately see the error message. . What about the following ?; ```; ...; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ----------------------------- Exit Failure ------------------------------. ```. Unfortunately I cannot get the kind of SU2 module in the interface ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350366632
https://github.com/su2code/SU2/pull/473#issuecomment-350366632:152,Integrability,message,message,152,"@economon the error will be fixed in the next commit. About the error message: I added the additional dashed line in order to immediately see the error message. . What about the following ?; ```; ...; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ----------------------------- Exit Failure ------------------------------. ```. Unfortunately I cannot get the kind of SU2 module in the interface ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350366632
https://github.com/su2code/SU2/pull/473#issuecomment-350366632:768,Integrability,interface,interface,768,"@economon the error will be fixed in the next commit. About the error message: I added the additional dashed line in order to immediately see the error message. . What about the following ?; ```; ...; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ----------------------------- Exit Failure ------------------------------. ```. Unfortunately I cannot get the kind of SU2 module in the interface ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350366632
https://github.com/su2code/SU2/pull/473#issuecomment-350737144:157,Availability,error,error,157,"What about the others ? If you have any doubts, comments or suggestions, please let me know. . I am pretty sure that everybody will at least come across the error message sooner or later, so know is your chance to influence its style :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350737144
https://github.com/su2code/SU2/pull/473#issuecomment-350737144:163,Integrability,message,message,163,"What about the others ? If you have any doubts, comments or suggestions, please let me know. . I am pretty sure that everybody will at least come across the error message sooner or later, so know is your chance to influence its style :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-350737144
https://github.com/su2code/SU2/pull/473#issuecomment-353216435:12,Availability,error,error,12,"The compile error is fixed on Apple LLVM for me now, thanks. I am happy with the output format for the error now, with one small comment: I think that ""Exit Failure"" in the final line might be unclear to the user, in that, one might think that the code actually failed to exit correctly rather than exiting due to a runtime error. That's why I originally proposed ""Error Exit,"" but I'm open to something else. No problem on not having the executable name (not critical at all).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-353216435
https://github.com/su2code/SU2/pull/473#issuecomment-353216435:103,Availability,error,error,103,"The compile error is fixed on Apple LLVM for me now, thanks. I am happy with the output format for the error now, with one small comment: I think that ""Exit Failure"" in the final line might be unclear to the user, in that, one might think that the code actually failed to exit correctly rather than exiting due to a runtime error. That's why I originally proposed ""Error Exit,"" but I'm open to something else. No problem on not having the executable name (not critical at all).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-353216435
https://github.com/su2code/SU2/pull/473#issuecomment-353216435:157,Availability,Failure,Failure,157,"The compile error is fixed on Apple LLVM for me now, thanks. I am happy with the output format for the error now, with one small comment: I think that ""Exit Failure"" in the final line might be unclear to the user, in that, one might think that the code actually failed to exit correctly rather than exiting due to a runtime error. That's why I originally proposed ""Error Exit,"" but I'm open to something else. No problem on not having the executable name (not critical at all).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-353216435
https://github.com/su2code/SU2/pull/473#issuecomment-353216435:324,Availability,error,error,324,"The compile error is fixed on Apple LLVM for me now, thanks. I am happy with the output format for the error now, with one small comment: I think that ""Exit Failure"" in the final line might be unclear to the user, in that, one might think that the code actually failed to exit correctly rather than exiting due to a runtime error. That's why I originally proposed ""Error Exit,"" but I'm open to something else. No problem on not having the executable name (not critical at all).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-353216435
https://github.com/su2code/SU2/pull/473#issuecomment-353216435:365,Availability,Error,Error,365,"The compile error is fixed on Apple LLVM for me now, thanks. I am happy with the output format for the error now, with one small comment: I think that ""Exit Failure"" in the final line might be unclear to the user, in that, one might think that the code actually failed to exit correctly rather than exiting due to a runtime error. That's why I originally proposed ""Error Exit,"" but I'm open to something else. No problem on not having the executable name (not critical at all).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-353216435
https://github.com/su2code/SU2/pull/473#issuecomment-354017856:287,Availability,Error,Error,287,"Tom, I see your point with the exit message. The current style is the following;. ```; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354017856
https://github.com/su2code/SU2/pull/473#issuecomment-354017856:544,Availability,Error,Error,544,"Tom, I see your point with the exit message. The current style is the following;. ```; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354017856
https://github.com/su2code/SU2/pull/473#issuecomment-354017856:36,Integrability,message,message,36,"Tom, I see your point with the exit message. The current style is the following;. ```; ------------------------ Iteration Preprocessing ------------------------; Zone 1: Euler/Navier-Stokes/RANS fluid iteration. ------------------------- Solver Preprocessing --------------------------. Error in ""void CSolver::Read_SU2_Restart_Metadata(CGeometry*, CConfig*, bool, std::__cxx11::string)"": ; -------------------------------------------------------------------------; Unable to open restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354017856
https://github.com/su2code/SU2/pull/473#issuecomment-354360988:103,Availability,error,errors,103,"Thanks, Tim. This PR looks good to me now. Do you need any additional help finishing this one? Are the errors replaced everywhere and changes w.r.t. rank/size all sorted as you like?. @rsanfer: when you have time, could you please revisit your review?. All: I recommend that everyone tries to build this on your systems with your favorite compiler and flavor of MPI. Any comments/reviews from others are most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354360988
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:480,Energy Efficiency,Energy,Energy,480,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:577,Energy Efficiency,Energy,Energy,577,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:246,Modifiability,variab,variable,246,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:301,Modifiability,variab,variable,301,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:470,Modifiability,variab,variable,470,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:523,Modifiability,variab,variable,523,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:693,Modifiability,variab,variable,693,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:730,Modifiability,variab,variable,730,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:837,Modifiability,variab,variable,837,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354407661:863,Modifiability,variab,variable,863,"I built it with OpenMPI v2.1.1 in combination with gnu compilers, version 7.0.1, and all debug flags enabled. Apart from a lot of warnings in ParMETIS and CGNS, I also get the following warnings. ../src/geometry_structure.cpp:16468:103: warning: variable SemiSpan set but not used [-Wunused-but-set-variable]; su2double Angle, MinAngle, MaxAngle, dAngle, *Area, *MaxThickness, *ToC, *Chord, *LERadius, *Twist, SemiSpan;. ../src/output_structure.cpp:16249:46: warning: variable Energy set but not used [-Wunused-but-set-variable]; Velocity[3], Velocity2, MassFlow, Density, Energy, Area, AxiFactor = 1.0, SoundSpeed, Vn, Weight = 1.0;. ../src/output_structure.cpp:16253:13: warning: unused variable Gamma_Minus_One [-Wunused-variable]; su2double Gamma_Minus_One = Gamma - 1.0;. ../src/output_structure.cpp:16256:18: warning: unused variable nVar [-Wunused-variable]; unsigned short nVar = solver->GetnVar();. However, these are from an earlier merge. I already took care of them in feature_hom, so I suppose it can wait until we merge that branch into develop. So it is good to go as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354407661
https://github.com/su2code/SU2/pull/473#issuecomment-354459150:27,Testability,test,tests,27,"All good from my side. The tests are passing and I managed to compile (and cross check) the regression test cases for the discrete adjoint FEA and FSI both in my workstation at Imperial and even running in WSL (which I find amazing that SU2 runs in there). In this latest case, I used the openSUSE Leap 42.3 app for windows and the (pretty old) gcc 4.8.5 compilers shipped along. It worked. From my side, this is ready to go. I'll remove the block straight away. . Thanks, Tim and Max, for the efforts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354459150
https://github.com/su2code/SU2/pull/473#issuecomment-354459150:103,Testability,test,test,103,"All good from my side. The tests are passing and I managed to compile (and cross check) the regression test cases for the discrete adjoint FEA and FSI both in my workstation at Imperial and even running in WSL (which I find amazing that SU2 runs in there). In this latest case, I used the openSUSE Leap 42.3 app for windows and the (pretty old) gcc 4.8.5 compilers shipped along. It worked. From my side, this is ready to go. I'll remove the block straight away. . Thanks, Tim and Max, for the efforts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-354459150
https://github.com/su2code/SU2/pull/473#issuecomment-355150444:19,Availability,error,error,19,I checked for last error messages and MPI functions. Everything seems to be fine. From my side it is ready to be merged :+1:,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-355150444
https://github.com/su2code/SU2/pull/473#issuecomment-355150444:25,Integrability,message,messages,25,I checked for last error messages and MPI functions. Everything seems to be fine. From my side it is ready to be merged :+1:,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/473#issuecomment-355150444
https://github.com/su2code/SU2/issues/477#issuecomment-347066655:532,Modifiability,config,config,532,"@yukaiweng: no problem on the repost. A couple comments... 1. I am not able to reproduce the problem on my mac, but I have a suspicion that the line endings in the text files could be causing an issue. Are you working on Windows? There may be a problem with the line endings that can resolved by using the ""dos2unix"" or ""unix2dos"" utility on linux that can format the file in the correct direction. Check this out any time you move files between Linux/Mac <-> Windows. 2. You can always convert between the two file types using the config options and restarting for one iteration, e.g. if you have a binary restart file and you restart with. WRT_BINARY_RESTART= NO; READ_BINARY_RESTART= YES; EXT_ITER= 1. you will get an ASCII restart upon completion. You can do also do this in the other direction to get a binary restart from ASCII. Hope this helps,; Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-347066655
https://github.com/su2code/SU2/issues/477#issuecomment-347244204:354,Deployability,install,installation,354,"@economon Hello Dr. Economon, thank you very much for the replying. 1. I tried using unix2dos to convert the file attached to the previous post, but the problem remains as picture shown (attached and highlighted) and these non-binary files cannot be read in SU2 when running restart simulation. Is it possible I did not configure it correctly during the installation? ; My configure command is: ""./configure --prefix=user-dir --enable-mpi --with-cc=mpicc --with-cxx=mpicxx"". 2. Thanks for the suggestion. And since I am using MATLAB to post-process the data and trying to import the binary restart data directly into MATLAB, could you please advise me the precision and other information of the binary restart file?. Again thank you very much for your helping with this issue.; Sincerely; ![picture1](https://user-images.githubusercontent.com/33880907/33277349-40eaa6d8-d366-11e7-970f-1ae712fb449b.jpg); ![picture2](https://user-images.githubusercontent.com/33880907/33277354-4374751e-d366-11e7-8f8e-4b6a81c5b78f.jpg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-347244204
https://github.com/su2code/SU2/issues/477#issuecomment-347244204:320,Modifiability,config,configure,320,"@economon Hello Dr. Economon, thank you very much for the replying. 1. I tried using unix2dos to convert the file attached to the previous post, but the problem remains as picture shown (attached and highlighted) and these non-binary files cannot be read in SU2 when running restart simulation. Is it possible I did not configure it correctly during the installation? ; My configure command is: ""./configure --prefix=user-dir --enable-mpi --with-cc=mpicc --with-cxx=mpicxx"". 2. Thanks for the suggestion. And since I am using MATLAB to post-process the data and trying to import the binary restart data directly into MATLAB, could you please advise me the precision and other information of the binary restart file?. Again thank you very much for your helping with this issue.; Sincerely; ![picture1](https://user-images.githubusercontent.com/33880907/33277349-40eaa6d8-d366-11e7-970f-1ae712fb449b.jpg); ![picture2](https://user-images.githubusercontent.com/33880907/33277354-4374751e-d366-11e7-8f8e-4b6a81c5b78f.jpg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-347244204
https://github.com/su2code/SU2/issues/477#issuecomment-347244204:373,Modifiability,config,configure,373,"@economon Hello Dr. Economon, thank you very much for the replying. 1. I tried using unix2dos to convert the file attached to the previous post, but the problem remains as picture shown (attached and highlighted) and these non-binary files cannot be read in SU2 when running restart simulation. Is it possible I did not configure it correctly during the installation? ; My configure command is: ""./configure --prefix=user-dir --enable-mpi --with-cc=mpicc --with-cxx=mpicxx"". 2. Thanks for the suggestion. And since I am using MATLAB to post-process the data and trying to import the binary restart data directly into MATLAB, could you please advise me the precision and other information of the binary restart file?. Again thank you very much for your helping with this issue.; Sincerely; ![picture1](https://user-images.githubusercontent.com/33880907/33277349-40eaa6d8-d366-11e7-970f-1ae712fb449b.jpg); ![picture2](https://user-images.githubusercontent.com/33880907/33277354-4374751e-d366-11e7-8f8e-4b6a81c5b78f.jpg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-347244204
https://github.com/su2code/SU2/issues/477#issuecomment-347244204:398,Modifiability,config,configure,398,"@economon Hello Dr. Economon, thank you very much for the replying. 1. I tried using unix2dos to convert the file attached to the previous post, but the problem remains as picture shown (attached and highlighted) and these non-binary files cannot be read in SU2 when running restart simulation. Is it possible I did not configure it correctly during the installation? ; My configure command is: ""./configure --prefix=user-dir --enable-mpi --with-cc=mpicc --with-cxx=mpicxx"". 2. Thanks for the suggestion. And since I am using MATLAB to post-process the data and trying to import the binary restart data directly into MATLAB, could you please advise me the precision and other information of the binary restart file?. Again thank you very much for your helping with this issue.; Sincerely; ![picture1](https://user-images.githubusercontent.com/33880907/33277349-40eaa6d8-d366-11e7-970f-1ae712fb449b.jpg); ![picture2](https://user-images.githubusercontent.com/33880907/33277354-4374751e-d366-11e7-8f8e-4b6a81c5b78f.jpg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-347244204
https://github.com/su2code/SU2/issues/477#issuecomment-360050851:89,Testability,test,test,89,"Unfortunately, I have not been able to recreate this issue on my systems with the simple test case that you shared @yukaiweng. . @talbring or @EduardoMolina, if you have some time, could you give the attached toy problem a try on your machines? I ran for a couple of unsteady iterations and then restarted on the third iteration (successfully for me). I think we're just missing something simple... [ascii_restart_test.zip](https://github.com/su2code/SU2/files/1659029/ascii_restart_test.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-360050851
https://github.com/su2code/SU2/issues/477#issuecomment-360050851:82,Usability,simpl,simple,82,"Unfortunately, I have not been able to recreate this issue on my systems with the simple test case that you shared @yukaiweng. . @talbring or @EduardoMolina, if you have some time, could you give the attached toy problem a try on your machines? I ran for a couple of unsteady iterations and then restarted on the third iteration (successfully for me). I think we're just missing something simple... [ascii_restart_test.zip](https://github.com/su2code/SU2/files/1659029/ascii_restart_test.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-360050851
https://github.com/su2code/SU2/issues/477#issuecomment-360050851:389,Usability,simpl,simple,389,"Unfortunately, I have not been able to recreate this issue on my systems with the simple test case that you shared @yukaiweng. . @talbring or @EduardoMolina, if you have some time, could you give the attached toy problem a try on your machines? I ran for a couple of unsteady iterations and then restarted on the third iteration (successfully for me). I think we're just missing something simple... [ascii_restart_test.zip](https://github.com/su2code/SU2/files/1659029/ascii_restart_test.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-360050851
https://github.com/su2code/SU2/issues/477#issuecomment-361351607:191,Deployability,Update,Update,191,"We have resolved this issue: the problem was with the particular combination of MPI implementation and compiler. The problem appeared with Intel MPI (mpigcc for the Intel(R) MPI Library 2017 Update 2 for Linux*) and GCC 6.3.0. Switching to an OpenMPI implementation fixed the issue. As this may be a machine-specific problem, we will close the issue, but please be advised of possible problems with this combination.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-361351607
https://github.com/su2code/SU2/issues/477#issuecomment-634412128:291,Modifiability,config,configure,291,"Hi. I am using SU2-6.2.0 with PYAMG library to solve RANS equations. l have similar ascii write problem. For initial runs with SU2, i used binary format. Unfortunately, now PYAMG requires only ascii output and l have to sort it out. I compiled with SU2 with openmpi/1.8.8-gcc-4.8.5 using. ./configure --prefix=/truba/home/mesahin/LIB_ALL/SU2-6.2.0+PYAMG -enable-mpi -enable-metis --with-cxx=mpicxx --enable-PY_WRAPPER CXXFLOGS='O3'. Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/477#issuecomment-634412128
https://github.com/su2code/SU2/issues/478#issuecomment-347913899:73,Modifiability,config,configure,73,LAPACK is currently not used at all ... we probably need to clean up the configure script at some point.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/478#issuecomment-347913899
https://github.com/su2code/SU2/issues/478#issuecomment-347944491:83,Modifiability,config,configure,83,"In our case, he added the libraries himself and I believe he did some stuff in the configure file in his fork, so I wouldn't be sure whether the `--with-LAPACK-lib` option works as is.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/478#issuecomment-347944491
https://github.com/su2code/SU2/issues/479#issuecomment-347944502:242,Performance,perform,performance,242,"Hi @gmandrews: we have been working hard on issues related to the partitioning / memory, and we have a branch that is under testing and nearly complete. Can you please try your case with the branch here, when you have a moment, to see if the performance is any better?. https://github.com/su2code/SU2/tree/fix_partitioning",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/479#issuecomment-347944502
https://github.com/su2code/SU2/issues/479#issuecomment-347944502:124,Testability,test,testing,124,"Hi @gmandrews: we have been working hard on issues related to the partitioning / memory, and we have a branch that is under testing and nearly complete. Can you please try your case with the branch here, when you have a moment, to see if the performance is any better?. https://github.com/su2code/SU2/tree/fix_partitioning",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/479#issuecomment-347944502
https://github.com/su2code/SU2/issues/479#issuecomment-349131148:31,Deployability,install,installation,31,@gmandrews did you try a clean installation of SU2 and ParMETIS yet?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/479#issuecomment-349131148
https://github.com/su2code/SU2/pull/480#issuecomment-347835808:178,Availability,down,down,178,"Hi Tim,; thanks, this is really useful. Let's wait until the test cases finish, but I agree, we should get this in sooner than later. The regression test issue is slowing us all down, definitely something to get fixed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/480#issuecomment-347835808
https://github.com/su2code/SU2/pull/480#issuecomment-347835808:61,Testability,test,test,61,"Hi Tim,; thanks, this is really useful. Let's wait until the test cases finish, but I agree, we should get this in sooner than later. The regression test issue is slowing us all down, definitely something to get fixed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/480#issuecomment-347835808
https://github.com/su2code/SU2/pull/480#issuecomment-347835808:149,Testability,test,test,149,"Hi Tim,; thanks, this is really useful. Let's wait until the test cases finish, but I agree, we should get this in sooner than later. The regression test issue is slowing us all down, definitely something to get fixed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/480#issuecomment-347835808
https://github.com/su2code/SU2/issues/481#issuecomment-355588717:257,Deployability,integrat,integrations,257,"What is your goal in including LAPACK?. You might want to see the issue I raised ( #478 ). I asked what the LAPACK compile option does, and the short answer is that it doesn't do anything for the master and develop branches. The long answer is that several integrations, such as the higher-order finite element branch, use LAPACK but in different ways.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/481#issuecomment-355588717
https://github.com/su2code/SU2/issues/481#issuecomment-355588717:257,Integrability,integrat,integrations,257,"What is your goal in including LAPACK?. You might want to see the issue I raised ( #478 ). I asked what the LAPACK compile option does, and the short answer is that it doesn't do anything for the master and develop branches. The long answer is that several integrations, such as the higher-order finite element branch, use LAPACK but in different ways.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/481#issuecomment-355588717
https://github.com/su2code/SU2/issues/483#issuecomment-536824982:53,Deployability,release,release,53,This is now out of date. With v7.0.0 on the verge of release,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/483#issuecomment-536824982
https://github.com/su2code/SU2/pull/485#issuecomment-353223445:135,Availability,redundant,redundant,135,Are there any duplicate files here? Perhaps the regression tests could copy in the files from tutorials before running to avoid having redundant information.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-353223445
https://github.com/su2code/SU2/pull/485#issuecomment-353223445:122,Safety,avoid,avoid,122,Are there any duplicate files here? Perhaps the regression tests could copy in the files from tutorials before running to avoid having redundant information.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-353223445
https://github.com/su2code/SU2/pull/485#issuecomment-353223445:135,Safety,redund,redundant,135,Are there any duplicate files here? Perhaps the regression tests could copy in the files from tutorials before running to avoid having redundant information.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-353223445
https://github.com/su2code/SU2/pull/485#issuecomment-353223445:59,Testability,test,tests,59,Are there any duplicate files here? Perhaps the regression tests could copy in the files from tutorials before running to avoid having redundant information.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-353223445
https://github.com/su2code/SU2/pull/485#issuecomment-354358512:298,Deployability,update,updated,298,"@talbring: Tutorials repo should be ready. Once you have it sorted out, could you please share the expected workflow for users/Travis CI (i.e., where do the files need to be placed, etc.)? There is a README in the Tutorials repo that we can fill with this information, and the wiki will need to be updated too so we can explain how it will work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354358512
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1159,Performance,perform,perform,1159,"p team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1306,Safety,avoid,avoiding,1306,"some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aaf6b411fd30a0aab80; > 29ebe325d8/Tutorials/Inviscid_Bump/Inviscid_Bump.md; >; > ; > You are receiving this because you are sub",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:321,Security,validat,validation,321,"Good Morning,. I'm from Chair of Thermal Engineering of Pozna University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:513,Testability,Test,Test,513,"Good Morning,. I'm from Chair of Thermal Engineering of Pozna University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:654,Testability,Test,Test,654,"Good Morning,. I'm from Chair of Thermal Engineering of Pozna University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:727,Testability,Test,TestCases,727,"Good Morning,. I'm from Chair of Thermal Engineering of Pozna University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:800,Testability,test,test,800,"Good Morning,. I'm from Chair of Thermal Engineering of Pozna University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:858,Testability,Test,TestCases,858,"Good Morning,. I'm from Chair of Thermal Engineering of Pozna University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:916,Testability,Test,Test,916,"Good Morning,. I'm from Chair of Thermal Engineering of Pozna University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1014,Testability,test,test,1014,"iversity of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > thi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1169,Testability,test,test,1169,"p team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1471,Testability,Test,TestCases,1471,"rding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aaf6b411fd30a0aab80; > 29ebe325d8/Tutorials/Inviscid_Bump/Inviscid_Bump.md; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/485#issuecomment-354572803>, or mute; > the thread; > <https://github.co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:453,Usability,simpl,simple,453,"Good Morning,. I'm from Chair of Thermal Engineering of Pozna University of Technology.; In August 2017 my colleague and I attended SU2 Summer School in; Kaiserslautern and met the Sci-Comp team developing the SU2. I think moving the main tutorials to the main repository is a good idea. We; declared to contribute some validation cases and written tutorials and; having this in main repository will ease the process of adding/modifying; the docs to a simple pull request. I also have a suggestion regarding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-354736415:1591,Usability,clear,clear,1591,"rding the Test Cases and Tutorial files. I; apologize if this is the wrong place or this has been discussed already,; but still will give it a try:; - Test cases folder from SU2/su2code repository shall be moved to the; SU2/TestCases repository. Rationale: this makes one repository to store the; test case *.cfg files and mesh files.; - There shall be a TestCases/Mesh folder to store all the meshes needed for; Test Cases files, without subdivisions for RANS, Euler etc subfolders.; Considering that multiple test cases use the same mesh and all the mesh; files are distinct, this solution generates one place to store all the mesh; files. Should a user perform a test case, he/she will find the mesh by name; referenced in the *.cfg file instead searching thru multiple folders. This; will also help avoiding unnecessary copies of mesh files.; - The same should be done for Tutorial files: Tutorial/Mesh folder for; storing meshes (duplicating these few files from TestCases/Mesh should not; be a problem IMO, but will really help a new user to get up to speed with; SU2); - I have no clear opinion on where the Tutorial files folder should be; stored. But considering moving written tutorials to main repository i think; that tutorial files should also be stored in main SU2/su2code repository. Best regards and Happy New Year; Jdrzej. 2017-12-30 23:45 GMT+01:00 Tim Albring <notifications@github.com>:. > What do you think of moving the written tutorials also to the main; > repository ? Then we can have links in the wiki to the markdown files like; > this (the link will be much shorter if the files are in the master branch):; > https://github.com/su2code/SU2/blob/0e36facc031aaf6b411fd30a0aab80; > 29ebe325d8/Tutorials/Inviscid_Bump/Inviscid_Bump.md; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/485#issuecomment-354572803>, or mute; > the thread; > <https://github.co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-354736415
https://github.com/su2code/SU2/pull/485#issuecomment-355152833:47,Modifiability,config,config,47,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jdrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
https://github.com/su2code/SU2/pull/485#issuecomment-355152833:207,Modifiability,config,config,207,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jdrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
https://github.com/su2code/SU2/pull/485#issuecomment-355152833:408,Modifiability,config,config,408,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jdrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
https://github.com/su2code/SU2/pull/485#issuecomment-355152833:613,Modifiability,config,config,613,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jdrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
https://github.com/su2code/SU2/pull/485#issuecomment-355152833:671,Safety,avoid,avoid,671,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jdrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
https://github.com/su2code/SU2/pull/485#issuecomment-355152833:136,Testability,test,test,136,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jdrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
https://github.com/su2code/SU2/pull/485#issuecomment-355152833:551,Testability,Test,Test-Cases,551,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jdrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
https://github.com/su2code/SU2/pull/485#issuecomment-355152833:275,Usability,simpl,simply,275,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jdrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
https://github.com/su2code/SU2/pull/485#issuecomment-355152833:578,Usability,clear,clear,578,"@JedrzejMosiezny . The reason why the mesh and config files are split into separate repos is the following: ideally we want to have the test cases being closely coupled to the current version of the code as config options change quite frequently. However, the mesh files are simply too big to have them in the main repo (it takes too much time to check them out etc.). So a compromise was to still leave the config files in the main repo in order for them to stay up-to-date. We thought that the information [here](https://github.com/su2code/SU2/wiki/Test-Cases) would be quite clear for the user on how to merge config and mesh files. Following this instructions should avoid having to search for the mesh files manually. Let us know if you think different. @economon could you add Jdrzej to the dev team here on github ? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355152833
https://github.com/su2code/SU2/pull/485#issuecomment-355153943:107,Modifiability,config,config,107,"I added the tutorial cases to the regression tests. They only do **one** iteration, just to check that the config options are correct. Everything else should be covered by the other regression tests already.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355153943
https://github.com/su2code/SU2/pull/485#issuecomment-355153943:45,Testability,test,tests,45,"I added the tutorial cases to the regression tests. They only do **one** iteration, just to check that the config options are correct. Everything else should be covered by the other regression tests already.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355153943
https://github.com/su2code/SU2/pull/485#issuecomment-355153943:193,Testability,test,tests,193,"I added the tutorial cases to the regression tests. They only do **one** iteration, just to check that the config options are correct. Everything else should be covered by the other regression tests already.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355153943
https://github.com/su2code/SU2/pull/485#issuecomment-355216605:610,Deployability,update,update,610,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
https://github.com/su2code/SU2/pull/485#issuecomment-355216605:1043,Deployability,update,update,1043,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
https://github.com/su2code/SU2/pull/485#issuecomment-355216605:141,Testability,test,tested,141,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
https://github.com/su2code/SU2/pull/485#issuecomment-355216605:155,Testability,Test,TestCases,155,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
https://github.com/su2code/SU2/pull/485#issuecomment-355216605:237,Testability,test,test,237,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
https://github.com/su2code/SU2/pull/485#issuecomment-355216605:412,Testability,test,test,412,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
https://github.com/su2code/SU2/pull/485#issuecomment-355216605:1236,Usability,user-friendly,user-friendly,1236,"@talbring: thanks for adding the regressions. One iteration is perfect just to check they're running, if they have the originals still being tested in the TestCases. I think the idea of having the written tutorials/documentation for the test cases in the main repository is a very good one, for several reasons. In particular, it will make it easier for people to add documentation, and we could eventually even test for its existence in Travis or make it a strict requirement for PRs in the future. My only concern at the moment is making sure that they look ""nice"" when viewed and that the links are easy to update/follow. We should probably add a title at the top of each tutorial markdown file now (above the first image), since the titles from the wiki page are missing. The image files should be moved from the website repo (su2code.github.io/github_wiki/) to these Tutorials folders. Another idea is to put a top-level ""Tutorials"" markdown file that will be linked from the wiki at the root Tutorials/ directory so that one only has to update the links to new tutorials in that file in the main repo, rather than always updating both the main repo and manually updating the wiki too. Any other ideas for making this seamless and user-friendly are most welcome! Let me know if you need any help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355216605
https://github.com/su2code/SU2/pull/485#issuecomment-355262713:92,Usability,clear,clear,92,"@talbring Thanks for getting this sorted, Tim! I also think it's the best way to maintain a clear difference between regressions and Tutorials. I do have a suggestion though. Although I think it's very nice to have the written tutorials directly in git, so people can contribute directly, I wonder if it's the best idea to have them in the main repo. As the number of tutorials grows, we will have the same problems as for the meshes, with too many files to check out (images, md files, etc). Given that there is a new ""Tutorials"" repository, would it be a good idea to incorporate them there? I think it makes sense in terms of clarity, and we could make use of github pages, which allows to create a website per repository. That way we could have a site for the tutorials - and eventually this could be incorporated seamlessly into the SU2 website. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/485#issuecomment-355262713
https://github.com/su2code/SU2/issues/487#issuecomment-355796302:111,Energy Efficiency,adapt,adaptation,111,"As for the question I raised, Dr. Alonso mentioned the problem in an email he sent me. He said, ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."". That matches my experience with a few tests I ran. After playing around a little, it seems like adaptivity for hexahedra was only partially finished. Many sections of the are implemented, but there seem to be both bugs and unfinished implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/487#issuecomment-355796302
https://github.com/su2code/SU2/issues/487#issuecomment-355796302:195,Energy Efficiency,adapt,adaptation,195,"As for the question I raised, Dr. Alonso mentioned the problem in an email he sent me. He said, ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."". That matches my experience with a few tests I ran. After playing around a little, it seems like adaptivity for hexahedra was only partially finished. Many sections of the are implemented, but there seem to be both bugs and unfinished implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/487#issuecomment-355796302
https://github.com/su2code/SU2/issues/487#issuecomment-355796302:331,Energy Efficiency,adapt,adaptivity,331,"As for the question I raised, Dr. Alonso mentioned the problem in an email he sent me. He said, ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."". That matches my experience with a few tests I ran. After playing around a little, it seems like adaptivity for hexahedra was only partially finished. Many sections of the are implemented, but there seem to be both bugs and unfinished implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/487#issuecomment-355796302
https://github.com/su2code/SU2/issues/487#issuecomment-355796302:111,Modifiability,adapt,adaptation,111,"As for the question I raised, Dr. Alonso mentioned the problem in an email he sent me. He said, ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."". That matches my experience with a few tests I ran. After playing around a little, it seems like adaptivity for hexahedra was only partially finished. Many sections of the are implemented, but there seem to be both bugs and unfinished implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/487#issuecomment-355796302
https://github.com/su2code/SU2/issues/487#issuecomment-355796302:195,Modifiability,adapt,adaptation,195,"As for the question I raised, Dr. Alonso mentioned the problem in an email he sent me. He said, ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."". That matches my experience with a few tests I ran. After playing around a little, it seems like adaptivity for hexahedra was only partially finished. Many sections of the are implemented, but there seem to be both bugs and unfinished implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/487#issuecomment-355796302
https://github.com/su2code/SU2/issues/487#issuecomment-355796302:331,Modifiability,adapt,adaptivity,331,"As for the question I raised, Dr. Alonso mentioned the problem in an email he sent me. He said, ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."". That matches my experience with a few tests I ran. After playing around a little, it seems like adaptivity for hexahedra was only partially finished. Many sections of the are implemented, but there seem to be both bugs and unfinished implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/487#issuecomment-355796302
https://github.com/su2code/SU2/issues/487#issuecomment-355796302:273,Testability,test,tests,273,"As for the question I raised, Dr. Alonso mentioned the problem in an email he sent me. He said, ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."". That matches my experience with a few tests I ran. After playing around a little, it seems like adaptivity for hexahedra was only partially finished. Many sections of the are implemented, but there seem to be both bugs and unfinished implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/487#issuecomment-355796302
https://github.com/su2code/SU2/pull/488#issuecomment-352001425:142,Integrability,wrap,wrapper,142,"Hey David,. to define custom BCs inside python is an amazing feature! I can see a lot of potential there. Thanks for that! . Since the python wrapper functionality is growing, what do you think about moving all of these wrapper routines to a separate file cpp file? ; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352001425
https://github.com/su2code/SU2/pull/488#issuecomment-352001425:220,Integrability,wrap,wrapper,220,"Hey David,. to define custom BCs inside python is an amazing feature! I can see a lot of potential there. Thanks for that! . Since the python wrapper functionality is growing, what do you think about moving all of these wrapper routines to a separate file cpp file? ; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352001425
https://github.com/su2code/SU2/pull/488#issuecomment-352001425:228,Integrability,rout,routines,228,"Hey David,. to define custom BCs inside python is an amazing feature! I can see a lot of potential there. Thanks for that! . Since the python wrapper functionality is growing, what do you think about moving all of these wrapper routines to a separate file cpp file? ; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352001425
https://github.com/su2code/SU2/pull/488#issuecomment-352045091:421,Integrability,wrap,wrapper,421,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
https://github.com/su2code/SU2/pull/488#issuecomment-352045091:536,Integrability,wrap,wrapper,536,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
https://github.com/su2code/SU2/pull/488#issuecomment-352045091:1005,Integrability,wrap,wrapper,1005,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
https://github.com/su2code/SU2/pull/488#issuecomment-352045091:632,Modifiability,config,config,632,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
https://github.com/su2code/SU2/pull/488#issuecomment-352045091:594,Security,access,access,594,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
https://github.com/su2code/SU2/pull/488#issuecomment-352045091:880,Security,access,accessors,880,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
https://github.com/su2code/SU2/pull/488#issuecomment-352045091:1284,Testability,test,tests,1284,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
https://github.com/su2code/SU2/pull/488#issuecomment-352045091:1336,Usability,user-friendly,user-friendly,1336,"Hi Tim,. Thanks!. I totally agree on the fact that Python-related functionalities could be in a separate file for code clarity. Anyway, considering only the C++ structure, those functionalities are still members of the CDriver (and all child classes). So if you are OK with the fact that having members of the same C++ class in different cpp files, I am OK too. . However, if you mean creating a new class for the Python wrapper (like CPyWrapper or whatever), and leave the CDriver ""clean"", this might be more tricky. Indeed, since the wrapper has to be a top-level class, it is better to have access to all the other main classes (config, geometry, solver, ...) and the CDriver was the perfect candidate (it instanciates all of them). So now if we create a new top-level class next to the CDriver, the direct link with all those classes is lost. Basically we will have to create accessors like CDriver::GetConfig(), CDriver::GetGeometry(), ... that will return the different containers to be used by the wrapper. Obviously this is possible but not in a short time, besides this might be a significant change in the top-level code structure. We could also think about exposing thoses CConfig, CGeometry, ... classes to Python in addition to just the driver, I already made some local tests and it worked great but this approach is less user-friendly. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-352045091
https://github.com/su2code/SU2/pull/488#issuecomment-354105984:16,Integrability,wrap,wrapper,16,"We can keep the wrapper routines as part of the CDriver class, but moving them to a separate file could already improve readability in my opinion.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-354105984
https://github.com/su2code/SU2/pull/488#issuecomment-354105984:24,Integrability,rout,routines,24,"We can keep the wrapper routines as part of the CDriver class, but moving them to a separate file could already improve readability in my opinion.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-354105984
https://github.com/su2code/SU2/pull/488#issuecomment-355928565:5,Deployability,update,updates,5,"Some updates:. - Python wrapper functionalities have been moved into a dedicated python_wrapper_structure.cpp file for code clarity.; - The data structures for the customized values at boundaries have been removed from the CPoint class. Data structures are stored in the geometry class, they are initialized only when customization is set ON and only for involved vertices. There was no restriction to put the data structures in the solver class, except that when multi-grids needs to be updated (required for non uniform field), the geometry class needed an access to the solver class, which is not the case since everything that is in the Common structure seems to be independent of what it is in SU2_CFD, and I wanted to keep that. Those data structures should not be seen as true PDE-related variables, they should be seen as a generic support for boundary customization.; - CHT related labels have been removed and replaced by ""Python customizable"" in order to not introduce any confusion with the native CHT development. The basic purpose of this work is to enable existing boudary conditions to be customized from Python and not to develop a CHT interface. CHT is just an example of application (since only the HEAT_FLUX and ISOTHERMAL walls are customizable for now).; - Based on the previous point, no new specific boundary condition was introduced. For now, I keep the idea to just modify (one single line) the existing boundary conditions to take into account the customization. New dedicated boundary conditions (for example BC_HEAT_FLUX_CUSTOM or BC_ISOTHERMAL_CUSTOM) would be a 99% copy of the originals... Dedicated boundary conditions for native CHT development can still be defined independently (no condlfict). Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-355928565
https://github.com/su2code/SU2/pull/488#issuecomment-355928565:488,Deployability,update,updated,488,"Some updates:. - Python wrapper functionalities have been moved into a dedicated python_wrapper_structure.cpp file for code clarity.; - The data structures for the customized values at boundaries have been removed from the CPoint class. Data structures are stored in the geometry class, they are initialized only when customization is set ON and only for involved vertices. There was no restriction to put the data structures in the solver class, except that when multi-grids needs to be updated (required for non uniform field), the geometry class needed an access to the solver class, which is not the case since everything that is in the Common structure seems to be independent of what it is in SU2_CFD, and I wanted to keep that. Those data structures should not be seen as true PDE-related variables, they should be seen as a generic support for boundary customization.; - CHT related labels have been removed and replaced by ""Python customizable"" in order to not introduce any confusion with the native CHT development. The basic purpose of this work is to enable existing boudary conditions to be customized from Python and not to develop a CHT interface. CHT is just an example of application (since only the HEAT_FLUX and ISOTHERMAL walls are customizable for now).; - Based on the previous point, no new specific boundary condition was introduced. For now, I keep the idea to just modify (one single line) the existing boundary conditions to take into account the customization. New dedicated boundary conditions (for example BC_HEAT_FLUX_CUSTOM or BC_ISOTHERMAL_CUSTOM) would be a 99% copy of the originals... Dedicated boundary conditions for native CHT development can still be defined independently (no condlfict). Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-355928565
https://github.com/su2code/SU2/pull/488#issuecomment-355928565:24,Integrability,wrap,wrapper,24,"Some updates:. - Python wrapper functionalities have been moved into a dedicated python_wrapper_structure.cpp file for code clarity.; - The data structures for the customized values at boundaries have been removed from the CPoint class. Data structures are stored in the geometry class, they are initialized only when customization is set ON and only for involved vertices. There was no restriction to put the data structures in the solver class, except that when multi-grids needs to be updated (required for non uniform field), the geometry class needed an access to the solver class, which is not the case since everything that is in the Common structure seems to be independent of what it is in SU2_CFD, and I wanted to keep that. Those data structures should not be seen as true PDE-related variables, they should be seen as a generic support for boundary customization.; - CHT related labels have been removed and replaced by ""Python customizable"" in order to not introduce any confusion with the native CHT development. The basic purpose of this work is to enable existing boudary conditions to be customized from Python and not to develop a CHT interface. CHT is just an example of application (since only the HEAT_FLUX and ISOTHERMAL walls are customizable for now).; - Based on the previous point, no new specific boundary condition was introduced. For now, I keep the idea to just modify (one single line) the existing boundary conditions to take into account the customization. New dedicated boundary conditions (for example BC_HEAT_FLUX_CUSTOM or BC_ISOTHERMAL_CUSTOM) would be a 99% copy of the originals... Dedicated boundary conditions for native CHT development can still be defined independently (no condlfict). Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-355928565
https://github.com/su2code/SU2/pull/488#issuecomment-355928565:1153,Integrability,interface,interface,1153,"Some updates:. - Python wrapper functionalities have been moved into a dedicated python_wrapper_structure.cpp file for code clarity.; - The data structures for the customized values at boundaries have been removed from the CPoint class. Data structures are stored in the geometry class, they are initialized only when customization is set ON and only for involved vertices. There was no restriction to put the data structures in the solver class, except that when multi-grids needs to be updated (required for non uniform field), the geometry class needed an access to the solver class, which is not the case since everything that is in the Common structure seems to be independent of what it is in SU2_CFD, and I wanted to keep that. Those data structures should not be seen as true PDE-related variables, they should be seen as a generic support for boundary customization.; - CHT related labels have been removed and replaced by ""Python customizable"" in order to not introduce any confusion with the native CHT development. The basic purpose of this work is to enable existing boudary conditions to be customized from Python and not to develop a CHT interface. CHT is just an example of application (since only the HEAT_FLUX and ISOTHERMAL walls are customizable for now).; - Based on the previous point, no new specific boundary condition was introduced. For now, I keep the idea to just modify (one single line) the existing boundary conditions to take into account the customization. New dedicated boundary conditions (for example BC_HEAT_FLUX_CUSTOM or BC_ISOTHERMAL_CUSTOM) would be a 99% copy of the originals... Dedicated boundary conditions for native CHT development can still be defined independently (no condlfict). Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-355928565
https://github.com/su2code/SU2/pull/488#issuecomment-355928565:796,Modifiability,variab,variables,796,"Some updates:. - Python wrapper functionalities have been moved into a dedicated python_wrapper_structure.cpp file for code clarity.; - The data structures for the customized values at boundaries have been removed from the CPoint class. Data structures are stored in the geometry class, they are initialized only when customization is set ON and only for involved vertices. There was no restriction to put the data structures in the solver class, except that when multi-grids needs to be updated (required for non uniform field), the geometry class needed an access to the solver class, which is not the case since everything that is in the Common structure seems to be independent of what it is in SU2_CFD, and I wanted to keep that. Those data structures should not be seen as true PDE-related variables, they should be seen as a generic support for boundary customization.; - CHT related labels have been removed and replaced by ""Python customizable"" in order to not introduce any confusion with the native CHT development. The basic purpose of this work is to enable existing boudary conditions to be customized from Python and not to develop a CHT interface. CHT is just an example of application (since only the HEAT_FLUX and ISOTHERMAL walls are customizable for now).; - Based on the previous point, no new specific boundary condition was introduced. For now, I keep the idea to just modify (one single line) the existing boundary conditions to take into account the customization. New dedicated boundary conditions (for example BC_HEAT_FLUX_CUSTOM or BC_ISOTHERMAL_CUSTOM) would be a 99% copy of the originals... Dedicated boundary conditions for native CHT development can still be defined independently (no condlfict). Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-355928565
https://github.com/su2code/SU2/pull/488#issuecomment-355928565:559,Security,access,access,559,"Some updates:. - Python wrapper functionalities have been moved into a dedicated python_wrapper_structure.cpp file for code clarity.; - The data structures for the customized values at boundaries have been removed from the CPoint class. Data structures are stored in the geometry class, they are initialized only when customization is set ON and only for involved vertices. There was no restriction to put the data structures in the solver class, except that when multi-grids needs to be updated (required for non uniform field), the geometry class needed an access to the solver class, which is not the case since everything that is in the Common structure seems to be independent of what it is in SU2_CFD, and I wanted to keep that. Those data structures should not be seen as true PDE-related variables, they should be seen as a generic support for boundary customization.; - CHT related labels have been removed and replaced by ""Python customizable"" in order to not introduce any confusion with the native CHT development. The basic purpose of this work is to enable existing boudary conditions to be customized from Python and not to develop a CHT interface. CHT is just an example of application (since only the HEAT_FLUX and ISOTHERMAL walls are customizable for now).; - Based on the previous point, no new specific boundary condition was introduced. For now, I keep the idea to just modify (one single line) the existing boundary conditions to take into account the customization. New dedicated boundary conditions (for example BC_HEAT_FLUX_CUSTOM or BC_ISOTHERMAL_CUSTOM) would be a 99% copy of the originals... Dedicated boundary conditions for native CHT development can still be defined independently (no condlfict). Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-355928565
https://github.com/su2code/SU2/pull/488#issuecomment-356044234:188,Integrability,wrap,wrapper,188,It looks like the regression tests fail because there is an additional `------------------------------ Begin Solver -----------------------------; ` at the end of the output of the python wrapper test cases.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-356044234
https://github.com/su2code/SU2/pull/488#issuecomment-356044234:29,Testability,test,tests,29,It looks like the regression tests fail because there is an additional `------------------------------ Begin Solver -----------------------------; ` at the end of the output of the python wrapper test cases.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-356044234
https://github.com/su2code/SU2/pull/488#issuecomment-356044234:196,Testability,test,test,196,It looks like the regression tests fail because there is an additional `------------------------------ Begin Solver -----------------------------; ` at the end of the output of the python wrapper test cases.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/488#issuecomment-356044234
https://github.com/su2code/SU2/issues/489#issuecomment-355968201:169,Deployability,configurat,configurations,169,"Dear SU2 Team Members,. Greetings! We are very happy to inform you that we are exploring the aerodynamic shape optimization script of SU2 R 5.0.0 (Raven) with different configurations. And we would also like to seek your assistance in connection with the following two issues:. We are not getting any clue on restarting procedure of the optimization process from previously finished cycles. Is there any way for exporting the intermediate / final optimized geometry as 3D CAD model. Thanking you in advance. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/489#issuecomment-355968201
https://github.com/su2code/SU2/issues/489#issuecomment-355968201:169,Modifiability,config,configurations,169,"Dear SU2 Team Members,. Greetings! We are very happy to inform you that we are exploring the aerodynamic shape optimization script of SU2 R 5.0.0 (Raven) with different configurations. And we would also like to seek your assistance in connection with the following two issues:. We are not getting any clue on restarting procedure of the optimization process from previously finished cycles. Is there any way for exporting the intermediate / final optimized geometry as 3D CAD model. Thanking you in advance. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/489#issuecomment-355968201
https://github.com/su2code/SU2/issues/489#issuecomment-355968201:111,Performance,optimiz,optimization,111,"Dear SU2 Team Members,. Greetings! We are very happy to inform you that we are exploring the aerodynamic shape optimization script of SU2 R 5.0.0 (Raven) with different configurations. And we would also like to seek your assistance in connection with the following two issues:. We are not getting any clue on restarting procedure of the optimization process from previously finished cycles. Is there any way for exporting the intermediate / final optimized geometry as 3D CAD model. Thanking you in advance. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/489#issuecomment-355968201
https://github.com/su2code/SU2/issues/489#issuecomment-355968201:337,Performance,optimiz,optimization,337,"Dear SU2 Team Members,. Greetings! We are very happy to inform you that we are exploring the aerodynamic shape optimization script of SU2 R 5.0.0 (Raven) with different configurations. And we would also like to seek your assistance in connection with the following two issues:. We are not getting any clue on restarting procedure of the optimization process from previously finished cycles. Is there any way for exporting the intermediate / final optimized geometry as 3D CAD model. Thanking you in advance. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/489#issuecomment-355968201
https://github.com/su2code/SU2/issues/489#issuecomment-355968201:447,Performance,optimiz,optimized,447,"Dear SU2 Team Members,. Greetings! We are very happy to inform you that we are exploring the aerodynamic shape optimization script of SU2 R 5.0.0 (Raven) with different configurations. And we would also like to seek your assistance in connection with the following two issues:. We are not getting any clue on restarting procedure of the optimization process from previously finished cycles. Is there any way for exporting the intermediate / final optimized geometry as 3D CAD model. Thanking you in advance. Regards,; Jyothi Kumar Puttam.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/489#issuecomment-355968201
https://github.com/su2code/SU2/pull/490#issuecomment-355911820:26,Testability,test,tests,26,Hm why are the regression tests failing ? It looks like is has something to do with the changes in the limiter in a recent commit.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/490#issuecomment-355911820
https://github.com/su2code/SU2/pull/491#issuecomment-355613118:278,Availability,ERROR,ERROR,278,"The change in the numerics of the Jacobian calculation changed the results of the regression tests. That was expected, since improvements to the linear solve will change the residuals at each time step. If you look at the values from the tests, you'll see something like:. ```; ERROR: Difference between computed input and test_vals exceeded tolerance. TOL=0.000001; test_iter=50; test_vals (stored): -6.459421, -4.595755, 1.201830, -0.007146, 0.080516; sim_vals (computed): -6.459444, -4.595710, 1.201844, -0.007146, 0.080517; ```. The values using the new numerics are very close, but not within tolerance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-355613118
https://github.com/su2code/SU2/pull/491#issuecomment-355613118:342,Availability,toler,tolerance,342,"The change in the numerics of the Jacobian calculation changed the results of the regression tests. That was expected, since improvements to the linear solve will change the residuals at each time step. If you look at the values from the tests, you'll see something like:. ```; ERROR: Difference between computed input and test_vals exceeded tolerance. TOL=0.000001; test_iter=50; test_vals (stored): -6.459421, -4.595755, 1.201830, -0.007146, 0.080516; sim_vals (computed): -6.459444, -4.595710, 1.201844, -0.007146, 0.080517; ```. The values using the new numerics are very close, but not within tolerance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-355613118
https://github.com/su2code/SU2/pull/491#issuecomment-355613118:598,Availability,toler,tolerance,598,"The change in the numerics of the Jacobian calculation changed the results of the regression tests. That was expected, since improvements to the linear solve will change the residuals at each time step. If you look at the values from the tests, you'll see something like:. ```; ERROR: Difference between computed input and test_vals exceeded tolerance. TOL=0.000001; test_iter=50; test_vals (stored): -6.459421, -4.595755, 1.201830, -0.007146, 0.080516; sim_vals (computed): -6.459444, -4.595710, 1.201844, -0.007146, 0.080517; ```. The values using the new numerics are very close, but not within tolerance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-355613118
https://github.com/su2code/SU2/pull/491#issuecomment-355613118:93,Testability,test,tests,93,"The change in the numerics of the Jacobian calculation changed the results of the regression tests. That was expected, since improvements to the linear solve will change the residuals at each time step. If you look at the values from the tests, you'll see something like:. ```; ERROR: Difference between computed input and test_vals exceeded tolerance. TOL=0.000001; test_iter=50; test_vals (stored): -6.459421, -4.595755, 1.201830, -0.007146, 0.080516; sim_vals (computed): -6.459444, -4.595710, 1.201844, -0.007146, 0.080517; ```. The values using the new numerics are very close, but not within tolerance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-355613118
https://github.com/su2code/SU2/pull/491#issuecomment-355613118:238,Testability,test,tests,238,"The change in the numerics of the Jacobian calculation changed the results of the regression tests. That was expected, since improvements to the linear solve will change the residuals at each time step. If you look at the values from the tests, you'll see something like:. ```; ERROR: Difference between computed input and test_vals exceeded tolerance. TOL=0.000001; test_iter=50; test_vals (stored): -6.459421, -4.595755, 1.201830, -0.007146, 0.080516; sim_vals (computed): -6.459444, -4.595710, 1.201844, -0.007146, 0.080517; ```. The values using the new numerics are very close, but not within tolerance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-355613118
https://github.com/su2code/SU2/pull/491#issuecomment-355732699:344,Integrability,depend,depend,344,"Thanks for looking into this.. it could be an important change. Regression changes are expected, of course, but does the convergence of the code improve with this change, in your experience? . Since it is an off-diagonal term, it may be hurting diagonal dominance and thus possibly convergence of the linear system. The final solution does not depend on the Jacobian approximation at convergence, but if this noticeably helps overall convergence rate, we should make the change.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-355732699
https://github.com/su2code/SU2/pull/491#issuecomment-358401929:466,Energy Efficiency,adapt,adaptive,466,"So I tested the convergence on a couple of test cases, to see its behavior. I used the following three different preconditioner/linear solver combinations:. + LU SGS with FGMRES; + ILU with FGMRES; + ILU with BCGSTAB. I looked at three different test cases from the repo: the zero-pressure gradient flat-plate turbulent boundary layer, the NACA 0012 airfoil, and the RAE 2822. In each case, I ran without a restart file. For the flat plate and the NACA 0012, I used adaptive CFL and no multigrid. For the RAE 2822, I used constant CFL and multigrid. I looked at both the number of iterations of the linear solver (the inner iterations) and the overall convergence over time (the outer iterations). Here's some sample results and discussion:. For the flat-plate boundary layer, there was no noticeable difference between the develop branch and the fix:; ![flat_plate_ilu](https://user-images.githubusercontent.com/13340225/35281464-92d4da84-0018-11e8-9460-ae4672be6f44.png). For the NACA 0012, the linear solver converged in a similar number of iterations. Its hard to tell which outperformed the other due to different CFL numbers. The residual in turbulent kinetic energy did lag in the middle, but both cases converged in a similar number of outer iterations.; ![naca0012_ilu](https://user-images.githubusercontent.com/13340225/35281471-9aa05a40-0018-11e8-8abe-e31ddd058679.png). For the RAE 2822, the overall convergence was identical (same number of outer iterations). The linear solvers also converged in a similar number of iterations.; ![rae2822_ilu](https://user-images.githubusercontent.com/13340225/35281495-addf0d7c-0018-11e8-96c0-6599e3cfa5e5.png). ### Conclusion; There doesn't seem to be any large difference in the convergence with or without the fix.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358401929
https://github.com/su2code/SU2/pull/491#issuecomment-358401929:1166,Energy Efficiency,energy,energy,1166,"So I tested the convergence on a couple of test cases, to see its behavior. I used the following three different preconditioner/linear solver combinations:. + LU SGS with FGMRES; + ILU with FGMRES; + ILU with BCGSTAB. I looked at three different test cases from the repo: the zero-pressure gradient flat-plate turbulent boundary layer, the NACA 0012 airfoil, and the RAE 2822. In each case, I ran without a restart file. For the flat plate and the NACA 0012, I used adaptive CFL and no multigrid. For the RAE 2822, I used constant CFL and multigrid. I looked at both the number of iterations of the linear solver (the inner iterations) and the overall convergence over time (the outer iterations). Here's some sample results and discussion:. For the flat-plate boundary layer, there was no noticeable difference between the develop branch and the fix:; ![flat_plate_ilu](https://user-images.githubusercontent.com/13340225/35281464-92d4da84-0018-11e8-9460-ae4672be6f44.png). For the NACA 0012, the linear solver converged in a similar number of iterations. Its hard to tell which outperformed the other due to different CFL numbers. The residual in turbulent kinetic energy did lag in the middle, but both cases converged in a similar number of outer iterations.; ![naca0012_ilu](https://user-images.githubusercontent.com/13340225/35281471-9aa05a40-0018-11e8-8abe-e31ddd058679.png). For the RAE 2822, the overall convergence was identical (same number of outer iterations). The linear solvers also converged in a similar number of iterations.; ![rae2822_ilu](https://user-images.githubusercontent.com/13340225/35281495-addf0d7c-0018-11e8-96c0-6599e3cfa5e5.png). ### Conclusion; There doesn't seem to be any large difference in the convergence with or without the fix.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358401929
https://github.com/su2code/SU2/pull/491#issuecomment-358401929:466,Modifiability,adapt,adaptive,466,"So I tested the convergence on a couple of test cases, to see its behavior. I used the following three different preconditioner/linear solver combinations:. + LU SGS with FGMRES; + ILU with FGMRES; + ILU with BCGSTAB. I looked at three different test cases from the repo: the zero-pressure gradient flat-plate turbulent boundary layer, the NACA 0012 airfoil, and the RAE 2822. In each case, I ran without a restart file. For the flat plate and the NACA 0012, I used adaptive CFL and no multigrid. For the RAE 2822, I used constant CFL and multigrid. I looked at both the number of iterations of the linear solver (the inner iterations) and the overall convergence over time (the outer iterations). Here's some sample results and discussion:. For the flat-plate boundary layer, there was no noticeable difference between the develop branch and the fix:; ![flat_plate_ilu](https://user-images.githubusercontent.com/13340225/35281464-92d4da84-0018-11e8-9460-ae4672be6f44.png). For the NACA 0012, the linear solver converged in a similar number of iterations. Its hard to tell which outperformed the other due to different CFL numbers. The residual in turbulent kinetic energy did lag in the middle, but both cases converged in a similar number of outer iterations.; ![naca0012_ilu](https://user-images.githubusercontent.com/13340225/35281471-9aa05a40-0018-11e8-8abe-e31ddd058679.png). For the RAE 2822, the overall convergence was identical (same number of outer iterations). The linear solvers also converged in a similar number of iterations.; ![rae2822_ilu](https://user-images.githubusercontent.com/13340225/35281495-addf0d7c-0018-11e8-96c0-6599e3cfa5e5.png). ### Conclusion; There doesn't seem to be any large difference in the convergence with or without the fix.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358401929
https://github.com/su2code/SU2/pull/491#issuecomment-358401929:5,Testability,test,tested,5,"So I tested the convergence on a couple of test cases, to see its behavior. I used the following three different preconditioner/linear solver combinations:. + LU SGS with FGMRES; + ILU with FGMRES; + ILU with BCGSTAB. I looked at three different test cases from the repo: the zero-pressure gradient flat-plate turbulent boundary layer, the NACA 0012 airfoil, and the RAE 2822. In each case, I ran without a restart file. For the flat plate and the NACA 0012, I used adaptive CFL and no multigrid. For the RAE 2822, I used constant CFL and multigrid. I looked at both the number of iterations of the linear solver (the inner iterations) and the overall convergence over time (the outer iterations). Here's some sample results and discussion:. For the flat-plate boundary layer, there was no noticeable difference between the develop branch and the fix:; ![flat_plate_ilu](https://user-images.githubusercontent.com/13340225/35281464-92d4da84-0018-11e8-9460-ae4672be6f44.png). For the NACA 0012, the linear solver converged in a similar number of iterations. Its hard to tell which outperformed the other due to different CFL numbers. The residual in turbulent kinetic energy did lag in the middle, but both cases converged in a similar number of outer iterations.; ![naca0012_ilu](https://user-images.githubusercontent.com/13340225/35281471-9aa05a40-0018-11e8-8abe-e31ddd058679.png). For the RAE 2822, the overall convergence was identical (same number of outer iterations). The linear solvers also converged in a similar number of iterations.; ![rae2822_ilu](https://user-images.githubusercontent.com/13340225/35281495-addf0d7c-0018-11e8-96c0-6599e3cfa5e5.png). ### Conclusion; There doesn't seem to be any large difference in the convergence with or without the fix.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358401929
https://github.com/su2code/SU2/pull/491#issuecomment-358401929:43,Testability,test,test,43,"So I tested the convergence on a couple of test cases, to see its behavior. I used the following three different preconditioner/linear solver combinations:. + LU SGS with FGMRES; + ILU with FGMRES; + ILU with BCGSTAB. I looked at three different test cases from the repo: the zero-pressure gradient flat-plate turbulent boundary layer, the NACA 0012 airfoil, and the RAE 2822. In each case, I ran without a restart file. For the flat plate and the NACA 0012, I used adaptive CFL and no multigrid. For the RAE 2822, I used constant CFL and multigrid. I looked at both the number of iterations of the linear solver (the inner iterations) and the overall convergence over time (the outer iterations). Here's some sample results and discussion:. For the flat-plate boundary layer, there was no noticeable difference between the develop branch and the fix:; ![flat_plate_ilu](https://user-images.githubusercontent.com/13340225/35281464-92d4da84-0018-11e8-9460-ae4672be6f44.png). For the NACA 0012, the linear solver converged in a similar number of iterations. Its hard to tell which outperformed the other due to different CFL numbers. The residual in turbulent kinetic energy did lag in the middle, but both cases converged in a similar number of outer iterations.; ![naca0012_ilu](https://user-images.githubusercontent.com/13340225/35281471-9aa05a40-0018-11e8-8abe-e31ddd058679.png). For the RAE 2822, the overall convergence was identical (same number of outer iterations). The linear solvers also converged in a similar number of iterations.; ![rae2822_ilu](https://user-images.githubusercontent.com/13340225/35281495-addf0d7c-0018-11e8-96c0-6599e3cfa5e5.png). ### Conclusion; There doesn't seem to be any large difference in the convergence with or without the fix.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358401929
https://github.com/su2code/SU2/pull/491#issuecomment-358401929:246,Testability,test,test,246,"So I tested the convergence on a couple of test cases, to see its behavior. I used the following three different preconditioner/linear solver combinations:. + LU SGS with FGMRES; + ILU with FGMRES; + ILU with BCGSTAB. I looked at three different test cases from the repo: the zero-pressure gradient flat-plate turbulent boundary layer, the NACA 0012 airfoil, and the RAE 2822. In each case, I ran without a restart file. For the flat plate and the NACA 0012, I used adaptive CFL and no multigrid. For the RAE 2822, I used constant CFL and multigrid. I looked at both the number of iterations of the linear solver (the inner iterations) and the overall convergence over time (the outer iterations). Here's some sample results and discussion:. For the flat-plate boundary layer, there was no noticeable difference between the develop branch and the fix:; ![flat_plate_ilu](https://user-images.githubusercontent.com/13340225/35281464-92d4da84-0018-11e8-9460-ae4672be6f44.png). For the NACA 0012, the linear solver converged in a similar number of iterations. Its hard to tell which outperformed the other due to different CFL numbers. The residual in turbulent kinetic energy did lag in the middle, but both cases converged in a similar number of outer iterations.; ![naca0012_ilu](https://user-images.githubusercontent.com/13340225/35281471-9aa05a40-0018-11e8-8abe-e31ddd058679.png). For the RAE 2822, the overall convergence was identical (same number of outer iterations). The linear solvers also converged in a similar number of iterations.; ![rae2822_ilu](https://user-images.githubusercontent.com/13340225/35281495-addf0d7c-0018-11e8-96c0-6599e3cfa5e5.png). ### Conclusion; There doesn't seem to be any large difference in the convergence with or without the fix.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358401929
https://github.com/su2code/SU2/pull/491#issuecomment-358747316:247,Availability,toler,tolerance,247,"Thanks for the detailed analysis... out of curiosity, how tightly did you converge the linear solve with each nonlinear iteration? . Lately, we have seen that the ILU preconditioner performs best, and, when solving the linear systems to a smaller tolerance, one can often use a higher CFL number. It could be interesting to look at the convergence of the linear solve for a single nonlinear iteration (at different points of the calculation) for GMRES+ILU to a near machine precision tolerance both with and without the term in the Jacobian. That might best show the impact of this term. All of that being said, I think we can add this term, as performance is the same or better, and it is technically correct.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358747316
https://github.com/su2code/SU2/pull/491#issuecomment-358747316:484,Availability,toler,tolerance,484,"Thanks for the detailed analysis... out of curiosity, how tightly did you converge the linear solve with each nonlinear iteration? . Lately, we have seen that the ILU preconditioner performs best, and, when solving the linear systems to a smaller tolerance, one can often use a higher CFL number. It could be interesting to look at the convergence of the linear solve for a single nonlinear iteration (at different points of the calculation) for GMRES+ILU to a near machine precision tolerance both with and without the term in the Jacobian. That might best show the impact of this term. All of that being said, I think we can add this term, as performance is the same or better, and it is technically correct.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358747316
https://github.com/su2code/SU2/pull/491#issuecomment-358747316:182,Performance,perform,performs,182,"Thanks for the detailed analysis... out of curiosity, how tightly did you converge the linear solve with each nonlinear iteration? . Lately, we have seen that the ILU preconditioner performs best, and, when solving the linear systems to a smaller tolerance, one can often use a higher CFL number. It could be interesting to look at the convergence of the linear solve for a single nonlinear iteration (at different points of the calculation) for GMRES+ILU to a near machine precision tolerance both with and without the term in the Jacobian. That might best show the impact of this term. All of that being said, I think we can add this term, as performance is the same or better, and it is technically correct.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358747316
https://github.com/su2code/SU2/pull/491#issuecomment-358747316:645,Performance,perform,performance,645,"Thanks for the detailed analysis... out of curiosity, how tightly did you converge the linear solve with each nonlinear iteration? . Lately, we have seen that the ILU preconditioner performs best, and, when solving the linear systems to a smaller tolerance, one can often use a higher CFL number. It could be interesting to look at the convergence of the linear solve for a single nonlinear iteration (at different points of the calculation) for GMRES+ILU to a near machine precision tolerance both with and without the term in the Jacobian. That might best show the impact of this term. All of that being said, I think we can add this term, as performance is the same or better, and it is technically correct.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-358747316
https://github.com/su2code/SU2/pull/491#issuecomment-359811020:182,Deployability,update,updated,182,So I realized I made a mistake with my previous post. The plots previously showed the iterations of the linear solver for the Navier-Stokes equations. I apologize for the mistake. I updated them with the iterations of the linear solver for the turbulence solver. The results aren't very different.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-359811020
https://github.com/su2code/SU2/pull/491#issuecomment-359811658:129,Availability,toler,tolerance,129,"My previous post used a linear solver precision of 1E-6. I ran a couple of test cases at near machine precision (a linear solver tolerance of 1E-14) and higher CFL number (CFL=150), with no CFL adaptation. As suggested, I used ILU+FGMRES. I capped the maximum number of linear solver iterations at 200, and did not raise any errors if the linear solver stopped at 200 iterations with less than 1E-14. The linear solver didn't exceed 200 iterations for the RANS equations, but it did for the Navier-Stokes equations. Once again, there doesn't appear to be a huge difference. For the flat-plate, the results were almost identical:. ![flat_plate_improved](https://user-images.githubusercontent.com/13340225/35233993-595fe2d4-ff65-11e7-9fd6-4b98f30b4d75.png). For the NACA 0012 airfoil, the current `develop` branch of the code outperformed this pull request:. ![naca0012_improved](https://user-images.githubusercontent.com/13340225/35233983-4f79b380-ff65-11e7-81f4-4b65964acecc.png). I believe overall convergence was similar because the Navier-Stokes solver, not the turbulence-solver, is the limiting factor when it comes to precision. The linear solver always converged on a turbulence solution with high precision in under 50 linear solver iterations. Meanwhile, the linear solver sometimes failed to find a Navier-Stokes solution within 1E-14 even after 200 iterations. The only way to make the Navier-Stokes solver converge to 1E-14 was to use small time steps (CFL ~= 1) at difficult points in the overall convergence.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-359811658
https://github.com/su2code/SU2/pull/491#issuecomment-359811658:325,Availability,error,errors,325,"My previous post used a linear solver precision of 1E-6. I ran a couple of test cases at near machine precision (a linear solver tolerance of 1E-14) and higher CFL number (CFL=150), with no CFL adaptation. As suggested, I used ILU+FGMRES. I capped the maximum number of linear solver iterations at 200, and did not raise any errors if the linear solver stopped at 200 iterations with less than 1E-14. The linear solver didn't exceed 200 iterations for the RANS equations, but it did for the Navier-Stokes equations. Once again, there doesn't appear to be a huge difference. For the flat-plate, the results were almost identical:. ![flat_plate_improved](https://user-images.githubusercontent.com/13340225/35233993-595fe2d4-ff65-11e7-9fd6-4b98f30b4d75.png). For the NACA 0012 airfoil, the current `develop` branch of the code outperformed this pull request:. ![naca0012_improved](https://user-images.githubusercontent.com/13340225/35233983-4f79b380-ff65-11e7-81f4-4b65964acecc.png). I believe overall convergence was similar because the Navier-Stokes solver, not the turbulence-solver, is the limiting factor when it comes to precision. The linear solver always converged on a turbulence solution with high precision in under 50 linear solver iterations. Meanwhile, the linear solver sometimes failed to find a Navier-Stokes solution within 1E-14 even after 200 iterations. The only way to make the Navier-Stokes solver converge to 1E-14 was to use small time steps (CFL ~= 1) at difficult points in the overall convergence.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-359811658
https://github.com/su2code/SU2/pull/491#issuecomment-359811658:194,Energy Efficiency,adapt,adaptation,194,"My previous post used a linear solver precision of 1E-6. I ran a couple of test cases at near machine precision (a linear solver tolerance of 1E-14) and higher CFL number (CFL=150), with no CFL adaptation. As suggested, I used ILU+FGMRES. I capped the maximum number of linear solver iterations at 200, and did not raise any errors if the linear solver stopped at 200 iterations with less than 1E-14. The linear solver didn't exceed 200 iterations for the RANS equations, but it did for the Navier-Stokes equations. Once again, there doesn't appear to be a huge difference. For the flat-plate, the results were almost identical:. ![flat_plate_improved](https://user-images.githubusercontent.com/13340225/35233993-595fe2d4-ff65-11e7-9fd6-4b98f30b4d75.png). For the NACA 0012 airfoil, the current `develop` branch of the code outperformed this pull request:. ![naca0012_improved](https://user-images.githubusercontent.com/13340225/35233983-4f79b380-ff65-11e7-81f4-4b65964acecc.png). I believe overall convergence was similar because the Navier-Stokes solver, not the turbulence-solver, is the limiting factor when it comes to precision. The linear solver always converged on a turbulence solution with high precision in under 50 linear solver iterations. Meanwhile, the linear solver sometimes failed to find a Navier-Stokes solution within 1E-14 even after 200 iterations. The only way to make the Navier-Stokes solver converge to 1E-14 was to use small time steps (CFL ~= 1) at difficult points in the overall convergence.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-359811658
https://github.com/su2code/SU2/pull/491#issuecomment-359811658:194,Modifiability,adapt,adaptation,194,"My previous post used a linear solver precision of 1E-6. I ran a couple of test cases at near machine precision (a linear solver tolerance of 1E-14) and higher CFL number (CFL=150), with no CFL adaptation. As suggested, I used ILU+FGMRES. I capped the maximum number of linear solver iterations at 200, and did not raise any errors if the linear solver stopped at 200 iterations with less than 1E-14. The linear solver didn't exceed 200 iterations for the RANS equations, but it did for the Navier-Stokes equations. Once again, there doesn't appear to be a huge difference. For the flat-plate, the results were almost identical:. ![flat_plate_improved](https://user-images.githubusercontent.com/13340225/35233993-595fe2d4-ff65-11e7-9fd6-4b98f30b4d75.png). For the NACA 0012 airfoil, the current `develop` branch of the code outperformed this pull request:. ![naca0012_improved](https://user-images.githubusercontent.com/13340225/35233983-4f79b380-ff65-11e7-81f4-4b65964acecc.png). I believe overall convergence was similar because the Navier-Stokes solver, not the turbulence-solver, is the limiting factor when it comes to precision. The linear solver always converged on a turbulence solution with high precision in under 50 linear solver iterations. Meanwhile, the linear solver sometimes failed to find a Navier-Stokes solution within 1E-14 even after 200 iterations. The only way to make the Navier-Stokes solver converge to 1E-14 was to use small time steps (CFL ~= 1) at difficult points in the overall convergence.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-359811658
https://github.com/su2code/SU2/pull/491#issuecomment-359811658:75,Testability,test,test,75,"My previous post used a linear solver precision of 1E-6. I ran a couple of test cases at near machine precision (a linear solver tolerance of 1E-14) and higher CFL number (CFL=150), with no CFL adaptation. As suggested, I used ILU+FGMRES. I capped the maximum number of linear solver iterations at 200, and did not raise any errors if the linear solver stopped at 200 iterations with less than 1E-14. The linear solver didn't exceed 200 iterations for the RANS equations, but it did for the Navier-Stokes equations. Once again, there doesn't appear to be a huge difference. For the flat-plate, the results were almost identical:. ![flat_plate_improved](https://user-images.githubusercontent.com/13340225/35233993-595fe2d4-ff65-11e7-9fd6-4b98f30b4d75.png). For the NACA 0012 airfoil, the current `develop` branch of the code outperformed this pull request:. ![naca0012_improved](https://user-images.githubusercontent.com/13340225/35233983-4f79b380-ff65-11e7-81f4-4b65964acecc.png). I believe overall convergence was similar because the Navier-Stokes solver, not the turbulence-solver, is the limiting factor when it comes to precision. The linear solver always converged on a turbulence solution with high precision in under 50 linear solver iterations. Meanwhile, the linear solver sometimes failed to find a Navier-Stokes solution within 1E-14 even after 200 iterations. The only way to make the Navier-Stokes solver converge to 1E-14 was to use small time steps (CFL ~= 1) at difficult points in the overall convergence.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/491#issuecomment-359811658
https://github.com/su2code/SU2/pull/492#issuecomment-355796132:59,Energy Efficiency,adapt,adaptation,59,"@economon Dr. Alonso emailed me saying that ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."" That matches my experience with a few tests I ran.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/492#issuecomment-355796132
https://github.com/su2code/SU2/pull/492#issuecomment-355796132:143,Energy Efficiency,adapt,adaptation,143,"@economon Dr. Alonso emailed me saying that ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."" That matches my experience with a few tests I ran.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/492#issuecomment-355796132
https://github.com/su2code/SU2/pull/492#issuecomment-355796132:59,Modifiability,adapt,adaptation,59,"@economon Dr. Alonso emailed me saying that ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."" That matches my experience with a few tests I ran.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/492#issuecomment-355796132
https://github.com/su2code/SU2/pull/492#issuecomment-355796132:143,Modifiability,adapt,adaptation,143,"@economon Dr. Alonso emailed me saying that ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."" That matches my experience with a few tests I ran.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/492#issuecomment-355796132
https://github.com/su2code/SU2/pull/492#issuecomment-355796132:220,Testability,test,tests,220,"@economon Dr. Alonso emailed me saying that ""We used [grid adaptation] successfully in tetrahedral meshes, but I do not believe the hexahedral adaptation was ever fully functional."" That matches my experience with a few tests I ran.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/492#issuecomment-355796132
https://github.com/su2code/SU2/pull/492#issuecomment-356504525:49,Modifiability,extend,extended,49,"Thanks, @clarkpede, merging now. We can keep the extended convo going with issue #487.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/492#issuecomment-356504525
https://github.com/su2code/SU2/pull/494#issuecomment-357367522:409,Performance,Optimiz,Optimization,409,"Why don't I add additional regression cases of multiple objective on a single surface and a single objective on multiple surfaces, I think otherwise the situations you mention are covered (both of those should already work, but may not be covered by regressions, and they can easily be covered by single-iteration tests). ; There is a tutorial page here: ; https://github.com/su2code/SU2/wiki/Multi-Objective-Optimization; Although that's from a while ago I don't think much needs to be changed, except for broken links including images.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-357367522
https://github.com/su2code/SU2/pull/494#issuecomment-357367522:314,Testability,test,tests,314,"Why don't I add additional regression cases of multiple objective on a single surface and a single objective on multiple surfaces, I think otherwise the situations you mention are covered (both of those should already work, but may not be covered by regressions, and they can easily be covered by single-iteration tests). ; There is a tutorial page here: ; https://github.com/su2code/SU2/wiki/Multi-Objective-Optimization; Although that's from a while ago I don't think much needs to be changed, except for broken links including images.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-357367522
https://github.com/su2code/SU2/pull/494#issuecomment-357458143:506,Modifiability,config,config,506,"Ah, that tutorial page is very important.. I don't think it was ever linked in the main wiki menu, but it is critical for making the options clear to the user (especially the surface handling). We need to make the design features as easy to use as possible - it is already hard enough for experts to use adjoints :). This is a good opportunity to move it over to the new repo where we are placing the tutorials here: https://su2code.github.io/Tutorials/docs/home/. The files, including the markdown, mesh, config, and images, can be moved to that repo. The markdown portion goes into the _docs directory, and we should make sure it's linked under the shape design tutorials. Do you have some time for this? Let me know if you need some help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-357458143
https://github.com/su2code/SU2/pull/494#issuecomment-357458143:141,Usability,clear,clear,141,"Ah, that tutorial page is very important.. I don't think it was ever linked in the main wiki menu, but it is critical for making the options clear to the user (especially the surface handling). We need to make the design features as easy to use as possible - it is already hard enough for experts to use adjoints :). This is a good opportunity to move it over to the new repo where we are placing the tutorials here: https://su2code.github.io/Tutorials/docs/home/. The files, including the markdown, mesh, config, and images, can be moved to that repo. The markdown portion goes into the _docs directory, and we should make sure it's linked under the shape design tutorials. Do you have some time for this? Let me know if you need some help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-357458143
https://github.com/su2code/SU2/pull/494#issuecomment-357820044:16,Deployability,update,update,16,"In theory I can update the tutorial, but most likely I won't be able to get to completing that for a couple of weeks. If you have the time to work on it, that would be based on the files in optimization_euler/multiobjective_wedge/; since that's a separate that would be in a different pull request. ; There may be an issue with the single objective/multi-surface case: I'm going to comment that out from the regression script but leave the files in to make that easy to add back in in the future - it looks like someone in another pull request was working on similar things (https://github.com/su2code/SU2/pull/497) so that should probably wait until their changes are merged in as well. Otherwise this is ready.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-357820044
https://github.com/su2code/SU2/pull/494#issuecomment-362947809:384,Deployability,update,update,384,"The single objective/multi surface case was added back in along with a regression test by these previous commits; I do still think it is reasonable to wait until after #497 is merged in so that I can be sure to pass their tests as well, and I will be working on updating the tutorial separately. ; In short, this can be reviewed at any time, and reviewers should expect an additional update if #497 is merged in first.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-362947809
https://github.com/su2code/SU2/pull/494#issuecomment-362947809:82,Testability,test,test,82,"The single objective/multi surface case was added back in along with a regression test by these previous commits; I do still think it is reasonable to wait until after #497 is merged in so that I can be sure to pass their tests as well, and I will be working on updating the tutorial separately. ; In short, this can be reviewed at any time, and reviewers should expect an additional update if #497 is merged in first.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-362947809
https://github.com/su2code/SU2/pull/494#issuecomment-362947809:222,Testability,test,tests,222,"The single objective/multi surface case was added back in along with a regression test by these previous commits; I do still think it is reasonable to wait until after #497 is merged in so that I can be sure to pass their tests as well, and I will be working on updating the tutorial separately. ; In short, this can be reviewed at any time, and reviewers should expect an additional update if #497 is merged in first.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-362947809
https://github.com/su2code/SU2/pull/494#issuecomment-364602321:125,Safety,avoid,avoiding,125,closing temporarily for finishing tutorial/anticipating merging with the previously mentioned pull request/bug fix/generally avoiding confusion. Will reopen when those are complete.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/494#issuecomment-364602321
https://github.com/su2code/SU2/issues/499#issuecomment-357418220:12,Deployability,update,update,12,"I forgot to update the Xcode project when I moved some Python related functionalities into a new cpp file, my bad (see #488 ). Seems like #497 may fix this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/499#issuecomment-357418220
https://github.com/su2code/SU2/pull/500#issuecomment-363126952:93,Deployability,patch,patch,93,"@LaSerpe thanks for catching that! Yeah, that definitely seems like a problem. I'll submit a patch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/500#issuecomment-363126952
https://github.com/su2code/SU2/issues/502#issuecomment-428584455:75,Availability,avail,available,75,So I am closing this for now. It will be announced when this model becomes available.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-428584455
https://github.com/su2code/SU2/issues/502#issuecomment-446515213:77,Availability,avail,available,77,"> So I am closing this for now. It will be announced when this model becomes available. Hello, vdweide. Thank you for your attention and this contribution. Did you ever try some testcases? I am a beginner SU2 user. Can you maybe give us a configure file about S-K transition flat plate using LM model? Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446515213
https://github.com/su2code/SU2/issues/502#issuecomment-446515213:239,Modifiability,config,configure,239,"> So I am closing this for now. It will be announced when this model becomes available. Hello, vdweide. Thank you for your attention and this contribution. Did you ever try some testcases? I am a beginner SU2 user. Can you maybe give us a configure file about S-K transition flat plate using LM model? Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446515213
https://github.com/su2code/SU2/issues/502#issuecomment-446515213:178,Testability,test,testcases,178,"> So I am closing this for now. It will be announced when this model becomes available. Hello, vdweide. Thank you for your attention and this contribution. Did you ever try some testcases? I am a beginner SU2 user. Can you maybe give us a configure file about S-K transition flat plate using LM model? Thank you!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446515213
https://github.com/su2code/SU2/issues/502#issuecomment-446518663:34,Testability,test,test,34,Below you can find a transitional test case using B-C model implemented in SU2:; https://su2code.github.io/tutorials/Transitional_Flat_Plate/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446518663
https://github.com/su2code/SU2/issues/502#issuecomment-446631804:36,Testability,test,test,36,"> Below you can find a transitional test case using B-C model implemented in SU2:; > https://su2code.github.io/tutorials/Transitional_Flat_Plate/. Samet, nice to meet you! Thank you for your suggestion! I have learned this model in current SU2 version. B-C model can provide quite good results in many teatcases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446631804
https://github.com/su2code/SU2/issues/502#issuecomment-446631804:210,Usability,learn,learned,210,"> Below you can find a transitional test case using B-C model implemented in SU2:; > https://su2code.github.io/tutorials/Transitional_Flat_Plate/. Samet, nice to meet you! Thank you for your suggestion! I have learned this model in current SU2 version. B-C model can provide quite good results in many teatcases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/502#issuecomment-446631804
https://github.com/su2code/SU2/pull/505#issuecomment-372674121:403,Testability,test,test,403,"@talbring @economon Thanks to you both!!. I could realise most of your remarks. To summarize the leftovers:. 1. Concerning the intersecting code with your heat extension to the incompressible solver - should we already find common function names or do we align them once they will be merged?; 1. Concerning the numerics class CSourceHeating: I think I will remove it for now, as I don't have any use or test case for it anyway.; 1. I will wait for your agreement on the FEM solver, if that's alright.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/505#issuecomment-372674121
https://github.com/su2code/SU2/pull/506#issuecomment-364848312:196,Usability,clear,clear,196,"@fpalacios, you misunderstood me. What I meant was that the CrossProduct part should be uncommented in order to remove the compiler warnings, not removed. When I read this back, this was not very clear from my side. In any case there are still two compiler warnings in geometry_structure.cpp due to this issue in the develop branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/506#issuecomment-364848312
https://github.com/su2code/SU2/pull/507#issuecomment-365301931:156,Testability,test,tests,156,"I noticed that the `release_v6.0.0` branch isn't set up with Travis CI. Are there plans to have Travis CI track this branch (v6.0.0), or are the regression tests only happening on other branches?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/507#issuecomment-365301931
https://github.com/su2code/SU2/pull/508#issuecomment-365829775:104,Deployability,release,releases,104,"Were carrying on as usual: please submit PRs to the develop branch when ready. Well have more regular releases going forward, and these fixes can be in a maintanence release before long.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/508#issuecomment-365829775
https://github.com/su2code/SU2/pull/508#issuecomment-365829775:168,Deployability,release,release,168,"Were carrying on as usual: please submit PRs to the develop branch when ready. Well have more regular releases going forward, and these fixes can be in a maintanence release before long.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/508#issuecomment-365829775
https://github.com/su2code/SU2/pull/508#issuecomment-365976110:120,Deployability,release,release-week,120,"Ok. I've sumbitted a new PR to the develop branch. I apologize about any headache I caused. I didn't mean to add to the release-week stress. I should have done a better job of checking my code and submitted the pull request earlier, and for that I'm sorry.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/508#issuecomment-365976110
https://github.com/su2code/SU2/pull/513#issuecomment-387257646:101,Integrability,rout,routines,101,Time to merge this one. Please just let me know if you run into any issues with the new partitioning routines.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/513#issuecomment-387257646
https://github.com/su2code/SU2/pull/514#issuecomment-383495897:26,Availability,error,error,26,"Hey @oleburghardt , ; the error I got can be fixed (using the same setup as described above) via enforcing the C++11 standard (CXXFLAGS=-std=c++11) as I am an older standard (not sure which though). C++11 explicitly introduces constructors that are allowed to call other constructors of the same class.; (see here: https://en.wikipedia.org/wiki/C%2B%2B11#Object_construction_improvement). For now I commited changes in the constructor as you suggested, after having talked to @economon . If compatibility with older C++ standards is desired I think this is a viable solution.; Sorry for not noticing that right away (Tom suggested to try C++11),; Regards, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/514#issuecomment-383495897
https://github.com/su2code/SU2/pull/514#issuecomment-384324818:37,Testability,test,test,37,@economon ; I had a look at the only test case that was still failing - looks that everything is alright. This is the pressure delta after 200 iterations:. ![schubauer](https://user-images.githubusercontent.com/22639394/39260962-411efb7a-48bb-11e8-89ed-7a5e0df3ca42.png). So it seems that it's still a transition model regression test and didn't turn into something else :smiley: I will change the values in a minute.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/514#issuecomment-384324818
https://github.com/su2code/SU2/pull/514#issuecomment-384324818:330,Testability,test,test,330,@economon ; I had a look at the only test case that was still failing - looks that everything is alright. This is the pressure delta after 200 iterations:. ![schubauer](https://user-images.githubusercontent.com/22639394/39260962-411efb7a-48bb-11e8-89ed-7a5e0df3ca42.png). So it seems that it's still a transition model regression test and didn't turn into something else :smiley: I will change the values in a minute.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/514#issuecomment-384324818
https://github.com/su2code/SU2/issues/515#issuecomment-459228891:15,Usability,feedback,feedback,15,Thanks for the feedback.. this is resolved in #600,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/515#issuecomment-459228891
https://github.com/su2code/SU2/pull/516#issuecomment-390755340:17,Deployability,update,updated,17,"This PR has been updated to include the inlet profile capability for the incompressible solver now too with the latest updates. There were a few bugs earlier, but this PR is now ready to go. If folks can take a look soon, I would appreciate it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/516#issuecomment-390755340
https://github.com/su2code/SU2/pull/516#issuecomment-390755340:119,Deployability,update,updates,119,"This PR has been updated to include the inlet profile capability for the incompressible solver now too with the latest updates. There were a few bugs earlier, but this PR is now ready to go. If folks can take a look soon, I would appreciate it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/516#issuecomment-390755340
https://github.com/su2code/SU2/pull/517#issuecomment-377863784:54,Testability,test,tests,54,"Merging. FYI: the time out issues with the regression tests were solved by forcing a flush of the print buffer after each test case result. Python 3 was buffering too long in some cases, leading to time outs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/517#issuecomment-377863784
https://github.com/su2code/SU2/pull/517#issuecomment-377863784:122,Testability,test,test,122,"Merging. FYI: the time out issues with the regression tests were solved by forcing a flush of the print buffer after each test case result. Python 3 was buffering too long in some cases, leading to time outs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/517#issuecomment-377863784
https://github.com/su2code/SU2/pull/518#issuecomment-375160507:125,Testability,test,test,125,"I'm glad to see the doxygen being used again, thanks for setting this up! Was this something needing review, or is it just a test that won't be merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/518#issuecomment-375160507
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:985,Deployability,update,updated,985,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:1249,Energy Efficiency,monitor,monitored,1249,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:857,Modifiability,config,config,857,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:1093,Modifiability,config,config,1093,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:1166,Modifiability,config,config,1166,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:1270,Modifiability,extend,extended,1270,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:1312,Modifiability,config,config,1312,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:317,Performance,optimiz,optimization,317,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:196,Testability,test,test,196,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:1401,Testability,test,test,1401,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376016690:1502,Testability,test,test,1502,"Thanks Heather,. Could you please take a look at the log_Adjoint.out file generated in the folder DESIGNS/DSN_001/ADJOINT_DRAG/ when you run the single objective-with-multiple-surfaces regression test (in the part whereSU2 specifies the Surface(s) where the force coefficients are evaluated). It seems that the shape optimization python script only copied the first surface to config_CFD.cfg. I found the ""if (n_obj>1): solution but, you know better the multi objective implementation. Just let me know if there is another more elegant fix that we can implement. Thanks!; Francisco. > On Mar 25, 2018, at 1:55 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176953697>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > I think that the array of monitored markers is extended to accommodate this situation in config.py (~line 514), and there is a single objective-with-multiple-surfaces regression test; do you have a case you can send me where this wasn't working? Or if you see an issue with that test that I previously missed I wouldn't mind looking into it.; > ; > ; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#pullrequestreview-106743204>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRva3VNHDjv7H11VnmorjY5pCNlpkks5tiARDgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376016690
https://github.com/su2code/SU2/pull/519#issuecomment-376023020:1523,Availability,error,error,1523," PR. And do not worry too much (or at all)... we are doing this for free and for fun! As you know, after a major release we always find this kind of small bugs. The big picture is that thanks to you we all enjoy an awesome multipoint optimization capability! Thanks!. Best,; Francisco. > On Mar 25, 2018, at 6:04 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176962282>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > @fpalacios <https://github.com/fpalacios> yes, I commented a bit too quickly; I do see the behavior that you mention. I think the line previously mentioned helps with getting the value of the objective but not the gradient.; > While I was testing this on my end I also noticed that there is an issue if you list the same objective multiple times (for example, if you wanted to weight the drag contribution from one surface more than another), where since it has the same key the previous dict entry is overwritten. Do you mind if I add an error catching that to your PR?; > ; > I am taking a look back through it but so far I think your solution will be good - and better to fix the performance in master now and worry about elegant improvements in the develop branch.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#discussion_r176962282>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRlzQ3wEuDogzT35DALgoNbrSv32Xks5tiD64gaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376023020
https://github.com/su2code/SU2/pull/519#issuecomment-376023020:173,Deployability,release,release,173,"Thanks! Please feel free to add anything you consider to my PR. And do not worry too much (or at all)... we are doing this for free and for fun! As you know, after a major release we always find this kind of small bugs. The big picture is that thanks to you we all enjoy an awesome multipoint optimization capability! Thanks!. Best,; Francisco. > On Mar 25, 2018, at 6:04 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176962282>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > @fpalacios <https://github.com/fpalacios> yes, I commented a bit too quickly; I do see the behavior that you mention. I think the line previously mentioned helps with getting the value of the objective but not the gradient.; > While I was testing this on my end I also noticed that there is an issue if you list the same objective multiple times (for example, if you wanted to weight the drag contribution from one surface more than another), where since it has the same key the previous dict entry is overwritten. Do you mind if I add an error catching that to your PR?; > ; > I am taking a look back through it but so far I think your solution will be good - and better to fix the performance in master now and worry about elegant improvements in the develop branch.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#discussion_r176962282>, or mute the thread <https://github.com/notifications/unsubscribe-auth",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376023020
https://github.com/su2code/SU2/pull/519#issuecomment-376023020:746,Deployability,update,updated,746,"Thanks! Please feel free to add anything you consider to my PR. And do not worry too much (or at all)... we are doing this for free and for fun! As you know, after a major release we always find this kind of small bugs. The big picture is that thanks to you we all enjoy an awesome multipoint optimization capability! Thanks!. Best,; Francisco. > On Mar 25, 2018, at 6:04 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176962282>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > @fpalacios <https://github.com/fpalacios> yes, I commented a bit too quickly; I do see the behavior that you mention. I think the line previously mentioned helps with getting the value of the objective but not the gradient.; > While I was testing this on my end I also noticed that there is an issue if you list the same objective multiple times (for example, if you wanted to weight the drag contribution from one surface more than another), where since it has the same key the previous dict entry is overwritten. Do you mind if I add an error catching that to your PR?; > ; > I am taking a look back through it but so far I think your solution will be good - and better to fix the performance in master now and worry about elegant improvements in the develop branch.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#discussion_r176962282>, or mute the thread <https://github.com/notifications/unsubscribe-auth",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376023020
https://github.com/su2code/SU2/pull/519#issuecomment-376023020:618,Modifiability,config,config,618,"Thanks! Please feel free to add anything you consider to my PR. And do not worry too much (or at all)... we are doing this for free and for fun! As you know, after a major release we always find this kind of small bugs. The big picture is that thanks to you we all enjoy an awesome multipoint optimization capability! Thanks!. Best,; Francisco. > On Mar 25, 2018, at 6:04 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176962282>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > @fpalacios <https://github.com/fpalacios> yes, I commented a bit too quickly; I do see the behavior that you mention. I think the line previously mentioned helps with getting the value of the objective but not the gradient.; > While I was testing this on my end I also noticed that there is an issue if you list the same objective multiple times (for example, if you wanted to weight the drag contribution from one surface more than another), where since it has the same key the previous dict entry is overwritten. Do you mind if I add an error catching that to your PR?; > ; > I am taking a look back through it but so far I think your solution will be good - and better to fix the performance in master now and worry about elegant improvements in the develop branch.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#discussion_r176962282>, or mute the thread <https://github.com/notifications/unsubscribe-auth",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376023020
https://github.com/su2code/SU2/pull/519#issuecomment-376023020:854,Modifiability,config,config,854,"Thanks! Please feel free to add anything you consider to my PR. And do not worry too much (or at all)... we are doing this for free and for fun! As you know, after a major release we always find this kind of small bugs. The big picture is that thanks to you we all enjoy an awesome multipoint optimization capability! Thanks!. Best,; Francisco. > On Mar 25, 2018, at 6:04 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176962282>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > @fpalacios <https://github.com/fpalacios> yes, I commented a bit too quickly; I do see the behavior that you mention. I think the line previously mentioned helps with getting the value of the objective but not the gradient.; > While I was testing this on my end I also noticed that there is an issue if you list the same objective multiple times (for example, if you wanted to weight the drag contribution from one surface more than another), where since it has the same key the previous dict entry is overwritten. Do you mind if I add an error catching that to your PR?; > ; > I am taking a look back through it but so far I think your solution will be good - and better to fix the performance in master now and worry about elegant improvements in the develop branch.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#discussion_r176962282>, or mute the thread <https://github.com/notifications/unsubscribe-auth",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376023020
https://github.com/su2code/SU2/pull/519#issuecomment-376023020:927,Modifiability,config,config,927,"Thanks! Please feel free to add anything you consider to my PR. And do not worry too much (or at all)... we are doing this for free and for fun! As you know, after a major release we always find this kind of small bugs. The big picture is that thanks to you we all enjoy an awesome multipoint optimization capability! Thanks!. Best,; Francisco. > On Mar 25, 2018, at 6:04 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176962282>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > @fpalacios <https://github.com/fpalacios> yes, I commented a bit too quickly; I do see the behavior that you mention. I think the line previously mentioned helps with getting the value of the objective but not the gradient.; > While I was testing this on my end I also noticed that there is an issue if you list the same objective multiple times (for example, if you wanted to weight the drag contribution from one surface more than another), where since it has the same key the previous dict entry is overwritten. Do you mind if I add an error catching that to your PR?; > ; > I am taking a look back through it but so far I think your solution will be good - and better to fix the performance in master now and worry about elegant improvements in the develop branch.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#discussion_r176962282>, or mute the thread <https://github.com/notifications/unsubscribe-auth",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376023020
https://github.com/su2code/SU2/pull/519#issuecomment-376023020:294,Performance,optimiz,optimization,294,"Thanks! Please feel free to add anything you consider to my PR. And do not worry too much (or at all)... we are doing this for free and for fun! As you know, after a major release we always find this kind of small bugs. The big picture is that thanks to you we all enjoy an awesome multipoint optimization capability! Thanks!. Best,; Francisco. > On Mar 25, 2018, at 6:04 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176962282>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > @fpalacios <https://github.com/fpalacios> yes, I commented a bit too quickly; I do see the behavior that you mention. I think the line previously mentioned helps with getting the value of the objective but not the gradient.; > While I was testing this on my end I also noticed that there is an issue if you list the same objective multiple times (for example, if you wanted to weight the drag contribution from one surface more than another), where since it has the same key the previous dict entry is overwritten. Do you mind if I add an error catching that to your PR?; > ; > I am taking a look back through it but so far I think your solution will be good - and better to fix the performance in master now and worry about elegant improvements in the develop branch.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#discussion_r176962282>, or mute the thread <https://github.com/notifications/unsubscribe-auth",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376023020
https://github.com/su2code/SU2/pull/519#issuecomment-376023020:1667,Performance,perform,performance,1667," PR. And do not worry too much (or at all)... we are doing this for free and for fun! As you know, after a major release we always find this kind of small bugs. The big picture is that thanks to you we all enjoy an awesome multipoint optimization capability! Thanks!. Best,; Francisco. > On Mar 25, 2018, at 6:04 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176962282>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > @fpalacios <https://github.com/fpalacios> yes, I commented a bit too quickly; I do see the behavior that you mention. I think the line previously mentioned helps with getting the value of the objective but not the gradient.; > While I was testing this on my end I also noticed that there is an issue if you list the same objective multiple times (for example, if you wanted to weight the drag contribution from one surface more than another), where since it has the same key the previous dict entry is overwritten. Do you mind if I add an error catching that to your PR?; > ; > I am taking a look back through it but so far I think your solution will be good - and better to fix the performance in master now and worry about elegant improvements in the develop branch.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#discussion_r176962282>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRlzQ3wEuDogzT35DALgoNbrSv32Xks5tiD64gaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376023020
https://github.com/su2code/SU2/pull/519#issuecomment-376023020:1223,Testability,test,testing,1223," PR. And do not worry too much (or at all)... we are doing this for free and for fun! As you know, after a major release we always find this kind of small bugs. The big picture is that thanks to you we all enjoy an awesome multipoint optimization capability! Thanks!. Best,; Francisco. > On Mar 25, 2018, at 6:04 PM, Heather Kline <notifications@github.com> wrote:; > ; > @hlkline commented on this pull request.; > ; > In SU2_PY/SU2/eval/design.py <https://github.com/su2code/SU2/pull/519#discussion_r176962282>:; > ; > > @@ -364,7 +364,7 @@ def obj_df(dvs,config,state=None):; > # For multiple objectives are evaluated one-by-one rather than combined; > # MARKER_MONITORING should be updated to only include the marker for i_obj; > # For single objectives, multiple markers can be used ; > - config['MARKER_MONITORING'] = marker_monitored[i_obj]; > + if (n_obj>1): config['MARKER_MONITORING'] = marker_monitored[i_obj]; > @fpalacios <https://github.com/fpalacios> yes, I commented a bit too quickly; I do see the behavior that you mention. I think the line previously mentioned helps with getting the value of the objective but not the gradient.; > While I was testing this on my end I also noticed that there is an issue if you list the same objective multiple times (for example, if you wanted to weight the drag contribution from one surface more than another), where since it has the same key the previous dict entry is overwritten. Do you mind if I add an error catching that to your PR?; > ; > I am taking a look back through it but so far I think your solution will be good - and better to fix the performance in master now and worry about elegant improvements in the develop branch.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#discussion_r176962282>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRlzQ3wEuDogzT35DALgoNbrSv32Xks5tiD64gaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376023020
https://github.com/su2code/SU2/pull/519#issuecomment-376260268:167,Availability,mainten,maintenance,167,"Thanks for sorting this out @hlkline and @fpalacios. Once this and the other PR that I have open for ""memory fixes"" are ready and merged, why don't we put out a small maintenance release, v6.0.1?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376260268
https://github.com/su2code/SU2/pull/519#issuecomment-376260268:179,Deployability,release,release,179,"Thanks for sorting this out @hlkline and @fpalacios. Once this and the other PR that I have open for ""memory fixes"" are ready and merged, why don't we put out a small maintenance release, v6.0.1?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376260268
https://github.com/su2code/SU2/pull/519#issuecomment-376544604:400,Availability,mainten,maintenance,400,"Do you understand why two regressions test are failing with a exclamation mark?. > On Mar 26, 2018, at 11:11 AM, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks for sorting this out @hlkline <https://github.com/hlkline> and @fpalacios <https://github.com/fpalacios>. Once this and the other PR that I have open for ""memory fixes"" are ready and merged, why don't we put out a small maintenance release, v6.0.1?; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#issuecomment-376260268>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRkIhOxa7Zm6t9u5OxUuquRym_1gZks5tiS9mgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376544604
https://github.com/su2code/SU2/pull/519#issuecomment-376544604:412,Deployability,release,release,412,"Do you understand why two regressions test are failing with a exclamation mark?. > On Mar 26, 2018, at 11:11 AM, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks for sorting this out @hlkline <https://github.com/hlkline> and @fpalacios <https://github.com/fpalacios>. Once this and the other PR that I have open for ""memory fixes"" are ready and merged, why don't we put out a small maintenance release, v6.0.1?; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#issuecomment-376260268>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRkIhOxa7Zm6t9u5OxUuquRym_1gZks5tiS9mgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376544604
https://github.com/su2code/SU2/pull/519#issuecomment-376544604:38,Testability,test,test,38,"Do you understand why two regressions test are failing with a exclamation mark?. > On Mar 26, 2018, at 11:11 AM, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks for sorting this out @hlkline <https://github.com/hlkline> and @fpalacios <https://github.com/fpalacios>. Once this and the other PR that I have open for ""memory fixes"" are ready and merged, why don't we put out a small maintenance release, v6.0.1?; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/519#issuecomment-376260268>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AccuRkIhOxa7Zm6t9u5OxUuquRym_1gZks5tiS9mgaJpZM4S4O1W>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-376544604
https://github.com/su2code/SU2/pull/519#issuecomment-378134342:8,Testability,test,tests,8,"Ok, the tests are passing for this one now after the fix from the other PR. Anything else you would like to add? Otherwise, let's review and merge this next.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-378134342
https://github.com/su2code/SU2/pull/519#issuecomment-379600546:53,Testability,test,test,53,"Thanks Tom, what was the problem with the regression test? I'm going to add some other small fixes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-379600546
https://github.com/su2code/SU2/pull/519#issuecomment-381217217:355,Availability,down,download,355,"@fpalacios : there were two main issues with the regressions. Both are time out problems if Travis waits for over 10 minutes without any console output. The first was that we need to flush the output for Python 3 for each regression test, otherwise there is too long between cases and sometimes it fails. The second is that sometimes it takes too long to download the test cases, so I have added the keywords 'travis_wait 90' in the call to the entire python script in .travis.yml in order to extend the 10 minute restriction to 90 min. We still need to reduce the time for the tests overall, but it seems to be stable for the time being.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-381217217
https://github.com/su2code/SU2/pull/519#issuecomment-381217217:554,Energy Efficiency,reduce,reduce,554,"@fpalacios : there were two main issues with the regressions. Both are time out problems if Travis waits for over 10 minutes without any console output. The first was that we need to flush the output for Python 3 for each regression test, otherwise there is too long between cases and sometimes it fails. The second is that sometimes it takes too long to download the test cases, so I have added the keywords 'travis_wait 90' in the call to the entire python script in .travis.yml in order to extend the 10 minute restriction to 90 min. We still need to reduce the time for the tests overall, but it seems to be stable for the time being.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-381217217
https://github.com/su2code/SU2/pull/519#issuecomment-381217217:493,Modifiability,extend,extend,493,"@fpalacios : there were two main issues with the regressions. Both are time out problems if Travis waits for over 10 minutes without any console output. The first was that we need to flush the output for Python 3 for each regression test, otherwise there is too long between cases and sometimes it fails. The second is that sometimes it takes too long to download the test cases, so I have added the keywords 'travis_wait 90' in the call to the entire python script in .travis.yml in order to extend the 10 minute restriction to 90 min. We still need to reduce the time for the tests overall, but it seems to be stable for the time being.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-381217217
https://github.com/su2code/SU2/pull/519#issuecomment-381217217:233,Testability,test,test,233,"@fpalacios : there were two main issues with the regressions. Both are time out problems if Travis waits for over 10 minutes without any console output. The first was that we need to flush the output for Python 3 for each regression test, otherwise there is too long between cases and sometimes it fails. The second is that sometimes it takes too long to download the test cases, so I have added the keywords 'travis_wait 90' in the call to the entire python script in .travis.yml in order to extend the 10 minute restriction to 90 min. We still need to reduce the time for the tests overall, but it seems to be stable for the time being.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-381217217
https://github.com/su2code/SU2/pull/519#issuecomment-381217217:368,Testability,test,test,368,"@fpalacios : there were two main issues with the regressions. Both are time out problems if Travis waits for over 10 minutes without any console output. The first was that we need to flush the output for Python 3 for each regression test, otherwise there is too long between cases and sometimes it fails. The second is that sometimes it takes too long to download the test cases, so I have added the keywords 'travis_wait 90' in the call to the entire python script in .travis.yml in order to extend the 10 minute restriction to 90 min. We still need to reduce the time for the tests overall, but it seems to be stable for the time being.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-381217217
https://github.com/su2code/SU2/pull/519#issuecomment-381217217:578,Testability,test,tests,578,"@fpalacios : there were two main issues with the regressions. Both are time out problems if Travis waits for over 10 minutes without any console output. The first was that we need to flush the output for Python 3 for each regression test, otherwise there is too long between cases and sometimes it fails. The second is that sometimes it takes too long to download the test cases, so I have added the keywords 'travis_wait 90' in the call to the entire python script in .travis.yml in order to extend the 10 minute restriction to 90 min. We still need to reduce the time for the tests overall, but it seems to be stable for the time being.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-381217217
https://github.com/su2code/SU2/pull/519#issuecomment-381333649:193,Deployability,release,release,193,"Thanks @economon, it was not an easy fix. . There are still some problems with the memory deallocation. As soon as we fix those issues we should accept this pull request and create a new minor release because some of the changes in this branch are really important.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-381333649
https://github.com/su2code/SU2/pull/519#issuecomment-381434706:29,Deployability,release,release,29,Couldnt agree more. We will release v6.0.1 right after this merge. Is it complete now? Or is there still a memory issue? I can help - please let me know.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/519#issuecomment-381434706
https://github.com/su2code/SU2/pull/520#issuecomment-376225263:65,Performance,perform,performed,65,"Hi; Kind of strange that Travis tests failed. Modifications were performed only in the script; compute_polar.py and the pull request was set following git pull from develop branch.; Could it be that there is a problem with the online develop branch?; How can I check what caused Travis to fail?; Thanks,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376225263
https://github.com/su2code/SU2/pull/520#issuecomment-376225263:32,Testability,test,tests,32,"Hi; Kind of strange that Travis tests failed. Modifications were performed only in the script; compute_polar.py and the pull request was set following git pull from develop branch.; Could it be that there is a problem with the online develop branch?; How can I check what caused Travis to fail?; Thanks,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376225263
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:448,Security,access,access,448,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:36,Testability,test,test,36,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:93,Testability,test,test,93,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:164,Testability,test,tests,164,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:246,Testability,test,test,246,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:328,Testability,test,test,328,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:430,Testability,test,tests,430,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:459,Testability,test,test,459,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:464,Testability,log,logs,464,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:476,Testability,test,tests,476,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376704607:634,Testability,test,test,634,"There are two causes for the failed test: your branch is currently failing the compute_polar test case, and an unrelated issue involving time-outs that is effected tests for everyone. . You can click the 'details' link to the right of the failed test in section just below the comments, or click on the red x next to any failed test. This takes you to the travis page, where through following through the links you can find which tests failed, and access the test logs. . The tests with exclamation points on the travis page are the ones that are failing due to other issues, and for now I would suggest focusing on the compute_polar test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376704607
https://github.com/su2code/SU2/pull/520#issuecomment-376941826:89,Deployability,configurat,configuration,89,"The problem that caused Travis to fail is related to a broader issue:; There are several configuration parameters that have a default value (like REYNOLDS_LENGTH =1.0 by default). This means that it is legitimate not to include these parameters in the cfg file.; However, the Python environment is oblivious to these defaults values: if a parameter is missing in the cfg file, then it is not a member of the Python list config. I think it is more consistent to set the default values also in the Python environment. I shall be happy to create such a pull request. However, before I do that I'd like to check if this has not been set intentionally, for a logic that escapes me. ; I shall appreciate a comment about that.; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376941826
https://github.com/su2code/SU2/pull/520#issuecomment-376941826:89,Modifiability,config,configuration,89,"The problem that caused Travis to fail is related to a broader issue:; There are several configuration parameters that have a default value (like REYNOLDS_LENGTH =1.0 by default). This means that it is legitimate not to include these parameters in the cfg file.; However, the Python environment is oblivious to these defaults values: if a parameter is missing in the cfg file, then it is not a member of the Python list config. I think it is more consistent to set the default values also in the Python environment. I shall be happy to create such a pull request. However, before I do that I'd like to check if this has not been set intentionally, for a logic that escapes me. ; I shall appreciate a comment about that.; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376941826
https://github.com/su2code/SU2/pull/520#issuecomment-376941826:420,Modifiability,config,config,420,"The problem that caused Travis to fail is related to a broader issue:; There are several configuration parameters that have a default value (like REYNOLDS_LENGTH =1.0 by default). This means that it is legitimate not to include these parameters in the cfg file.; However, the Python environment is oblivious to these defaults values: if a parameter is missing in the cfg file, then it is not a member of the Python list config. I think it is more consistent to set the default values also in the Python environment. I shall be happy to create such a pull request. However, before I do that I'd like to check if this has not been set intentionally, for a logic that escapes me. ; I shall appreciate a comment about that.; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376941826
https://github.com/su2code/SU2/pull/520#issuecomment-376941826:654,Testability,log,logic,654,"The problem that caused Travis to fail is related to a broader issue:; There are several configuration parameters that have a default value (like REYNOLDS_LENGTH =1.0 by default). This means that it is legitimate not to include these parameters in the cfg file.; However, the Python environment is oblivious to these defaults values: if a parameter is missing in the cfg file, then it is not a member of the Python list config. I think it is more consistent to set the default values also in the Python environment. I shall be happy to create such a pull request. However, before I do that I'd like to check if this has not been set intentionally, for a logic that escapes me. ; I shall appreciate a comment about that.; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-376941826
https://github.com/su2code/SU2/pull/520#issuecomment-377072314:578,Availability,error,errors,578,"Please see the end of the SU2_PY/SU2/io/config.py file - this is where defaults for python are currently defined. If you see any additional ones that are needed for the python scripts to operate, or any that have the incorrect default values, please do update those. ; I would recommend against adding an exhaustive list of defaults, and only adding those that are actually used by the python scripts. The reason is that the default values are not automatically synced between the c++ and python codes, and so this would add unneeded overhead for developers and room for future errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377072314
https://github.com/su2code/SU2/pull/520#issuecomment-377072314:253,Deployability,update,update,253,"Please see the end of the SU2_PY/SU2/io/config.py file - this is where defaults for python are currently defined. If you see any additional ones that are needed for the python scripts to operate, or any that have the incorrect default values, please do update those. ; I would recommend against adding an exhaustive list of defaults, and only adding those that are actually used by the python scripts. The reason is that the default values are not automatically synced between the c++ and python codes, and so this would add unneeded overhead for developers and room for future errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377072314
https://github.com/su2code/SU2/pull/520#issuecomment-377072314:40,Modifiability,config,config,40,"Please see the end of the SU2_PY/SU2/io/config.py file - this is where defaults for python are currently defined. If you see any additional ones that are needed for the python scripts to operate, or any that have the incorrect default values, please do update those. ; I would recommend against adding an exhaustive list of defaults, and only adding those that are actually used by the python scripts. The reason is that the default values are not automatically synced between the c++ and python codes, and so this would add unneeded overhead for developers and room for future errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377072314
https://github.com/su2code/SU2/pull/520#issuecomment-377178756:312,Modifiability,config,config,312,"Heather, thanks for your response.; I do agree that it is preferable to avoid an exhaustive list of defaults. However, currently SU2 runs double booking: For the C++ code, defaults are set in SetRunTime_Options (part of config_structures.cpp) and for the Python scripts, a partial list of defaults is defined in config.py. If we can automatically sync between the c++ and python codes, it will make developers life much easier. ; I suggest creating a single ASCII file that contains all the defaults values. This file can be read both by the c++ code and by the Python scripts, before overwitting parameters, reading from the case cfg file. ; Such a file can be part of the distribution. Whenever a new parameter is defined in SetRunTime_Options, its default value should be written in the defaults' file. Actually, we can prepare a rendering script that would read through SetRunTime_Options and prepares the defaults in the ASCII file, synced with the c++, for the Python. What do you think?; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377178756
https://github.com/su2code/SU2/pull/520#issuecomment-377178756:72,Safety,avoid,avoid,72,"Heather, thanks for your response.; I do agree that it is preferable to avoid an exhaustive list of defaults. However, currently SU2 runs double booking: For the C++ code, defaults are set in SetRunTime_Options (part of config_structures.cpp) and for the Python scripts, a partial list of defaults is defined in config.py. If we can automatically sync between the c++ and python codes, it will make developers life much easier. ; I suggest creating a single ASCII file that contains all the defaults values. This file can be read both by the c++ code and by the Python scripts, before overwitting parameters, reading from the case cfg file. ; Such a file can be part of the distribution. Whenever a new parameter is defined in SetRunTime_Options, its default value should be written in the defaults' file. Actually, we can prepare a rendering script that would read through SetRunTime_Options and prepares the defaults in the ASCII file, synced with the c++, for the Python. What do you think?; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377178756
https://github.com/su2code/SU2/pull/520#issuecomment-377420170:172,Deployability,update,update,172,"You've reminded me that there is an old python script (parse_config.py) which parses the c++ config structure code - I couldn't get it to run right away, but maybe you can update that script to generate your list automatically from the c++ code, and so not require much change (and also not require you to manually write out all the defaults). . Personally I think that we should keep the default definitions in the C++ as it is now, as this keeps the executables self-contained among other things. ; By the way, I think you meant SetConfig_Options().",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377420170
https://github.com/su2code/SU2/pull/520#issuecomment-377420170:93,Modifiability,config,config,93,"You've reminded me that there is an old python script (parse_config.py) which parses the c++ config structure code - I couldn't get it to run right away, but maybe you can update that script to generate your list automatically from the c++ code, and so not require much change (and also not require you to manually write out all the defaults). . Personally I think that we should keep the default definitions in the C++ as it is now, as this keeps the executables self-contained among other things. ; By the way, I think you meant SetConfig_Options().",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377420170
https://github.com/su2code/SU2/pull/520#issuecomment-377499319:286,Availability,failure,failures,286,"Reviving the parsing script can be a simple and effective solution for syncing the defaults.; I shall be out of the country for the next three weeks. I shall try my hand at your suggestion once I return. Meanwhile, I hope the current PR will complete its approval cycle. Current Travis failures are marked by ! only.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377499319
https://github.com/su2code/SU2/pull/520#issuecomment-377499319:37,Usability,simpl,simple,37,"Reviving the parsing script can be a simple and effective solution for syncing the defaults.; I shall be out of the country for the next three weeks. I shall try my hand at your suggestion once I return. Meanwhile, I hope the current PR will complete its approval cycle. Current Travis failures are marked by ! only.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-377499319
https://github.com/su2code/SU2/pull/520#issuecomment-381411950:543,Deployability,update,update,543,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950
https://github.com/su2code/SU2/pull/520#issuecomment-381411950:779,Deployability,update,update,779,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950
https://github.com/su2code/SU2/pull/520#issuecomment-381411950:379,Modifiability,config,config,379,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950
https://github.com/su2code/SU2/pull/520#issuecomment-381411950:310,Usability,clear,clear,310,"Hi, thanks for this interesting discussion. Just a reminder... there is a third place where the default values are stored! the config_template.cfg file. I have had similar problems to what @erangit is describing with the multiple definition of the default values in different places, in fact, sometimes is not clear what is the minimum number of parameters that you can use in a config file. I think that the ideal scenario would be to use the config_template.cfg file as the default value keeper and create subroutines in C++ and python that update the defaults with the existing information in that file. Remember that config_template.cfg is always required otherwise the user doesn't know that are the existing options. By the way... this discussion reminds me that we should update SetRunTime_Options(void). This is an incredible useful small subroutine to modify the software parameters during runtime. EXT_ITER is the only parameters currently accepted but in the near future we should add all or most of them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/520#issuecomment-381411950
https://github.com/su2code/SU2/issues/521#issuecomment-377870818:38,Modifiability,variab,variable,38,"It looks like the SU2_RUN environment variable was not set as described here<https://su2code.github.io/docs/Build-from-Source/>. Scroll to near the bottom for more details. Best,. Juan. On Apr 2, 2018, at 12:00 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. From the picture it looks like you use the python script, but that is about all I could see. Could you therefore give some more details? What operating system do you use? How did you compile the code? What version of MPI do you use?. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/521#issuecomment-377870148>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJgeJsbnZC4ituvS1SoETz-iCeWfks5tkcxxgaJpZM4TDNbe>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-377870818
https://github.com/su2code/SU2/issues/521#issuecomment-378116873:328,Availability,error,errors,328,"Thanks for Edwin van der Weide, I am using a Windows 7 system and compile SU2 with cygwin. The MPI version is 9.0.1247497.11. I am a newcomer to SU2 and following the tutorial now , but there is a problem with ONERAM6 parallel computing.; The following figure shows the contents of the tutorial; The following figure shows the errors in the calculation; Serial computing can run normally; Thanks again, I hope you can help me !. At 2018-04-02 15:00:05, ""Edwin van der Weide"" <notifications@github.com> wrote:. From the picture it looks like you use the python script, but that is about all I could see. Could you therefore give some more details? What operating system do you use? How did you compile the code? What version of MPI do you use?. ; You are receiving this because you authored the thread.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378116873
https://github.com/su2code/SU2/issues/521#issuecomment-378119992:304,Availability,error,error,304,"Seems like your figures are not attached. Please upload them again. Also, please double check whether your ""SU2_RUN"" environment variable is set correctly as Juan mentioned. If serial computation worked fine only with ""$ SU2_CFD inv_ONERAM6.cfg"" command, I guess you set it correctly. However, from your error message, python script says it can't find a path to ""SU2_RUN""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378119992
https://github.com/su2code/SU2/issues/521#issuecomment-378119992:310,Integrability,message,message,310,"Seems like your figures are not attached. Please upload them again. Also, please double check whether your ""SU2_RUN"" environment variable is set correctly as Juan mentioned. If serial computation worked fine only with ""$ SU2_CFD inv_ONERAM6.cfg"" command, I guess you set it correctly. However, from your error message, python script says it can't find a path to ""SU2_RUN""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378119992
https://github.com/su2code/SU2/issues/521#issuecomment-378119992:129,Modifiability,variab,variable,129,"Seems like your figures are not attached. Please upload them again. Also, please double check whether your ""SU2_RUN"" environment variable is set correctly as Juan mentioned. If serial computation worked fine only with ""$ SU2_CFD inv_ONERAM6.cfg"" command, I guess you set it correctly. However, from your error message, python script says it can't find a path to ""SU2_RUN""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378119992
https://github.com/su2code/SU2/issues/521#issuecomment-378164049:380,Integrability,depend,depends,380,"I am not entirely sure, but as far as I know SU2 has not been tested on cygwin. So if the setting of the SU2_RUN environment variable does not solve the problem, could you test it without python? You do this using the following command. mpirun -np <# of ranks> <path to SU2 bin directory>/SU2_CFD.exe inv_ONERAM6.cfg. It could be that instead of mpirun you must use mpiexec. That depends on your MPI implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378164049
https://github.com/su2code/SU2/issues/521#issuecomment-378164049:125,Modifiability,variab,variable,125,"I am not entirely sure, but as far as I know SU2 has not been tested on cygwin. So if the setting of the SU2_RUN environment variable does not solve the problem, could you test it without python? You do this using the following command. mpirun -np <# of ranks> <path to SU2 bin directory>/SU2_CFD.exe inv_ONERAM6.cfg. It could be that instead of mpirun you must use mpiexec. That depends on your MPI implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378164049
https://github.com/su2code/SU2/issues/521#issuecomment-378164049:62,Testability,test,tested,62,"I am not entirely sure, but as far as I know SU2 has not been tested on cygwin. So if the setting of the SU2_RUN environment variable does not solve the problem, could you test it without python? You do this using the following command. mpirun -np <# of ranks> <path to SU2 bin directory>/SU2_CFD.exe inv_ONERAM6.cfg. It could be that instead of mpirun you must use mpiexec. That depends on your MPI implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378164049
https://github.com/su2code/SU2/issues/521#issuecomment-378164049:172,Testability,test,test,172,"I am not entirely sure, but as far as I know SU2 has not been tested on cygwin. So if the setting of the SU2_RUN environment variable does not solve the problem, could you test it without python? You do this using the following command. mpirun -np <# of ranks> <path to SU2 bin directory>/SU2_CFD.exe inv_ONERAM6.cfg. It could be that instead of mpirun you must use mpiexec. That depends on your MPI implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378164049
https://github.com/su2code/SU2/issues/521#issuecomment-378291150:83,Modifiability,config,configure,83,"Using Cygwin's OpenMPI you can compile SU2 using the following command:. $SU2_HOME/configure --prefix=$SU2_EXEC --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --enable-metis --with-metis-cppflags=""-D_FILE_OFFSET_BITS=64 -DNDEBUG -DNDEBUG2 -DHAVE_GETLINE -DMETIS_USE_LONGINDEX=1"" --enable-parmetis --with-parmetis-cppflags=""-DMETIS_USE_LONGINDEX=1"" --enable-cgns. Ok, you will not have the same performance as a linux distribution but you will be able to run SU2. I hope it can help. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378291150
https://github.com/su2code/SU2/issues/521#issuecomment-378291150:412,Performance,perform,performance,412,"Using Cygwin's OpenMPI you can compile SU2 using the following command:. $SU2_HOME/configure --prefix=$SU2_EXEC --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --enable-metis --with-metis-cppflags=""-D_FILE_OFFSET_BITS=64 -DNDEBUG -DNDEBUG2 -DHAVE_GETLINE -DMETIS_USE_LONGINDEX=1"" --enable-parmetis --with-parmetis-cppflags=""-DMETIS_USE_LONGINDEX=1"" --enable-cgns. Ok, you will not have the same performance as a linux distribution but you will be able to run SU2. I hope it can help. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/521#issuecomment-378291150
https://github.com/su2code/SU2/pull/522#issuecomment-382362207:160,Deployability,release,released,160,"About the output: most, if not all, of the changes affect only structural and FSI problems. They are not yet perfect, but the output is improved respect to the released version of the code. I believe it does not affect anybody else's output. . On the other hand - again, the output needs to be rethought. Together with the input, it's the bottleneck in terms of abstraction, the rest of the code is nice and abstract and the input/output is still full of ifs/else. Working on that at the moment... But it's a much bigger change, so that's why I decided to put this through now, as a minor release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/522#issuecomment-382362207
https://github.com/su2code/SU2/pull/522#issuecomment-382362207:589,Deployability,release,release,589,"About the output: most, if not all, of the changes affect only structural and FSI problems. They are not yet perfect, but the output is improved respect to the released version of the code. I believe it does not affect anybody else's output. . On the other hand - again, the output needs to be rethought. Together with the input, it's the bottleneck in terms of abstraction, the rest of the code is nice and abstract and the input/output is still full of ifs/else. Working on that at the moment... But it's a much bigger change, so that's why I decided to put this through now, as a minor release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/522#issuecomment-382362207
https://github.com/su2code/SU2/pull/522#issuecomment-382362207:339,Performance,bottleneck,bottleneck,339,"About the output: most, if not all, of the changes affect only structural and FSI problems. They are not yet perfect, but the output is improved respect to the released version of the code. I believe it does not affect anybody else's output. . On the other hand - again, the output needs to be rethought. Together with the input, it's the bottleneck in terms of abstraction, the rest of the code is nice and abstract and the input/output is still full of ifs/else. Working on that at the moment... But it's a much bigger change, so that's why I decided to put this through now, as a minor release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/522#issuecomment-382362207
https://github.com/su2code/SU2/issues/523#issuecomment-381731261:61,Modifiability,config,config,61,Yes I know about the ONERAM examples. But the mesh files and config files do not match as their boundary conditions are different. Could you share your config file and meshed file to me regarding ONERAM ? ; Thank you.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381731261
https://github.com/su2code/SU2/issues/523#issuecomment-381731261:152,Modifiability,config,config,152,Yes I know about the ONERAM examples. But the mesh files and config files do not match as their boundary conditions are different. Could you share your config file and meshed file to me regarding ONERAM ? ; Thank you.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381731261
https://github.com/su2code/SU2/issues/523#issuecomment-381741128:153,Availability,down,download,153,I just pulled the master branch of SU2 and it worked fine with configuration file and mesh file. Which files did you use for your 3D simulation? You may download files from following links. Inviscid : https://github.com/su2code/su2code.github.io/tree/master/Inviscid_ONERAM6; Turbulent : https://github.com/su2code/su2code.github.io/tree/master/Turbulent_ONERAM6,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381741128
https://github.com/su2code/SU2/issues/523#issuecomment-381741128:63,Deployability,configurat,configuration,63,I just pulled the master branch of SU2 and it worked fine with configuration file and mesh file. Which files did you use for your 3D simulation? You may download files from following links. Inviscid : https://github.com/su2code/su2code.github.io/tree/master/Inviscid_ONERAM6; Turbulent : https://github.com/su2code/su2code.github.io/tree/master/Turbulent_ONERAM6,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381741128
https://github.com/su2code/SU2/issues/523#issuecomment-381741128:63,Modifiability,config,configuration,63,I just pulled the master branch of SU2 and it worked fine with configuration file and mesh file. Which files did you use for your 3D simulation? You may download files from following links. Inviscid : https://github.com/su2code/su2code.github.io/tree/master/Inviscid_ONERAM6; Turbulent : https://github.com/su2code/su2code.github.io/tree/master/Turbulent_ONERAM6,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381741128
https://github.com/su2code/SU2/issues/523#issuecomment-381744025:28,Modifiability,config,configure,28,@chamsolli ; I am trying to configure my own 3D Euler case for this mesh.; ![capture](https://user-images.githubusercontent.com/31462793/38834251-7f1740ca-418d-11e8-962c-8e778331955e.JPG),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381744025
https://github.com/su2code/SU2/issues/523#issuecomment-381747291:310,Modifiability,config,config,310,"Please do run tutorial cases for 3D Euler and NS(Inviscid and Turbulent ONERAM6) first before running your own implementation. Tutorial pages are self-explanatory so I expect that you can easily grab which boundary markers to use in your implementation. ; As I said in previous comment, boundary conditions in config file and mesh file do match at least inviscid case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381747291
https://github.com/su2code/SU2/issues/523#issuecomment-381751040:127,Modifiability,config,config,127,"Thank you @chamsolli ; However, it says that some of the options like coefficients and binary restart are not analogous to the config file of SU2.; ![screenshot from 2018-04-16 16-03-29](https://user-images.githubusercontent.com/31462793/38835288-c18a81e4-4190-11e8-8aae-d28eabbbc0d1.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381751040
https://github.com/su2code/SU2/issues/523#issuecomment-381752554:198,Availability,error,error,198,"Seems like you're using older version of SU2 master branch. We didn't have several config options such as ""WRT_BINARY_RESTART"" in older version. That's the reason why your SU2_CFD executable throws error message regarding it.; Please clean your SU2 directory, pull fresh copy of master branch of SU2, compile it and then run it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381752554
https://github.com/su2code/SU2/issues/523#issuecomment-381752554:204,Integrability,message,message,204,"Seems like you're using older version of SU2 master branch. We didn't have several config options such as ""WRT_BINARY_RESTART"" in older version. That's the reason why your SU2_CFD executable throws error message regarding it.; Please clean your SU2 directory, pull fresh copy of master branch of SU2, compile it and then run it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381752554
https://github.com/su2code/SU2/issues/523#issuecomment-381752554:83,Modifiability,config,config,83,"Seems like you're using older version of SU2 master branch. We didn't have several config options such as ""WRT_BINARY_RESTART"" in older version. That's the reason why your SU2_CFD executable throws error message regarding it.; Please clean your SU2 directory, pull fresh copy of master branch of SU2, compile it and then run it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/523#issuecomment-381752554
https://github.com/su2code/SU2/issues/524#issuecomment-381737174:212,Availability,failure,failure,212,"Ruben,. That's related to the same time out issues that have been mentioned. One is for the total time (70 min. at the moment) and the other is a ""silence"" time out of 10 min with no console output that causes a failure. I am in contact with Travis CI and will report back here asap when we have a solution. Tom",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-381737174
https://github.com/su2code/SU2/issues/524#issuecomment-382152114:59,Safety,timeout,timeout,59,"The folks at Travis CI have kindly doubled both our ""hard"" timeout and ""silence"" timeout limits up to 140 min. and 20 min., respectively. We should be safely within limits for some time to come. . That being said, rather than relying on the increases, I would really encourage that we find some better approaches for reducing total test time, as we will continue to add more cases. It is not good for our pace of development that we have to wait over an hour to get the results of the tests. I think that a test time of approx. 10-20 min. would be more ideal so that we can iterate much more quickly. I suspect that attacking our compile time would be most helpful. Any ideas and discussion most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382152114
https://github.com/su2code/SU2/issues/524#issuecomment-382152114:81,Safety,timeout,timeout,81,"The folks at Travis CI have kindly doubled both our ""hard"" timeout and ""silence"" timeout limits up to 140 min. and 20 min., respectively. We should be safely within limits for some time to come. . That being said, rather than relying on the increases, I would really encourage that we find some better approaches for reducing total test time, as we will continue to add more cases. It is not good for our pace of development that we have to wait over an hour to get the results of the tests. I think that a test time of approx. 10-20 min. would be more ideal so that we can iterate much more quickly. I suspect that attacking our compile time would be most helpful. Any ideas and discussion most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382152114
https://github.com/su2code/SU2/issues/524#issuecomment-382152114:151,Safety,safe,safely,151,"The folks at Travis CI have kindly doubled both our ""hard"" timeout and ""silence"" timeout limits up to 140 min. and 20 min., respectively. We should be safely within limits for some time to come. . That being said, rather than relying on the increases, I would really encourage that we find some better approaches for reducing total test time, as we will continue to add more cases. It is not good for our pace of development that we have to wait over an hour to get the results of the tests. I think that a test time of approx. 10-20 min. would be more ideal so that we can iterate much more quickly. I suspect that attacking our compile time would be most helpful. Any ideas and discussion most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382152114
https://github.com/su2code/SU2/issues/524#issuecomment-382152114:616,Security,attack,attacking,616,"The folks at Travis CI have kindly doubled both our ""hard"" timeout and ""silence"" timeout limits up to 140 min. and 20 min., respectively. We should be safely within limits for some time to come. . That being said, rather than relying on the increases, I would really encourage that we find some better approaches for reducing total test time, as we will continue to add more cases. It is not good for our pace of development that we have to wait over an hour to get the results of the tests. I think that a test time of approx. 10-20 min. would be more ideal so that we can iterate much more quickly. I suspect that attacking our compile time would be most helpful. Any ideas and discussion most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382152114
https://github.com/su2code/SU2/issues/524#issuecomment-382152114:332,Testability,test,test,332,"The folks at Travis CI have kindly doubled both our ""hard"" timeout and ""silence"" timeout limits up to 140 min. and 20 min., respectively. We should be safely within limits for some time to come. . That being said, rather than relying on the increases, I would really encourage that we find some better approaches for reducing total test time, as we will continue to add more cases. It is not good for our pace of development that we have to wait over an hour to get the results of the tests. I think that a test time of approx. 10-20 min. would be more ideal so that we can iterate much more quickly. I suspect that attacking our compile time would be most helpful. Any ideas and discussion most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382152114
https://github.com/su2code/SU2/issues/524#issuecomment-382152114:485,Testability,test,tests,485,"The folks at Travis CI have kindly doubled both our ""hard"" timeout and ""silence"" timeout limits up to 140 min. and 20 min., respectively. We should be safely within limits for some time to come. . That being said, rather than relying on the increases, I would really encourage that we find some better approaches for reducing total test time, as we will continue to add more cases. It is not good for our pace of development that we have to wait over an hour to get the results of the tests. I think that a test time of approx. 10-20 min. would be more ideal so that we can iterate much more quickly. I suspect that attacking our compile time would be most helpful. Any ideas and discussion most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382152114
https://github.com/su2code/SU2/issues/524#issuecomment-382152114:507,Testability,test,test,507,"The folks at Travis CI have kindly doubled both our ""hard"" timeout and ""silence"" timeout limits up to 140 min. and 20 min., respectively. We should be safely within limits for some time to come. . That being said, rather than relying on the increases, I would really encourage that we find some better approaches for reducing total test time, as we will continue to add more cases. It is not good for our pace of development that we have to wait over an hour to get the results of the tests. I think that a test time of approx. 10-20 min. would be more ideal so that we can iterate much more quickly. I suspect that attacking our compile time would be most helpful. Any ideas and discussion most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382152114
https://github.com/su2code/SU2/issues/524#issuecomment-382299662:98,Energy Efficiency,reduce,reduce,98,"That's great! At least it gives us some margin to solve this issue. I agree that we should try to reduce the time of the tests. I think that @talbring approach a few months ago of reducing the number of iterations was the correct one; the tests don't need to be physically meaningful, but rather technically representative of the features. The compile time is also something that we should look into - we might need to have a telecom on this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382299662
https://github.com/su2code/SU2/issues/524#issuecomment-382299662:121,Testability,test,tests,121,"That's great! At least it gives us some margin to solve this issue. I agree that we should try to reduce the time of the tests. I think that @talbring approach a few months ago of reducing the number of iterations was the correct one; the tests don't need to be physically meaningful, but rather technically representative of the features. The compile time is also something that we should look into - we might need to have a telecom on this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382299662
https://github.com/su2code/SU2/issues/524#issuecomment-382299662:239,Testability,test,tests,239,"That's great! At least it gives us some margin to solve this issue. I agree that we should try to reduce the time of the tests. I think that @talbring approach a few months ago of reducing the number of iterations was the correct one; the tests don't need to be physically meaningful, but rather technically representative of the features. The compile time is also something that we should look into - we might need to have a telecom on this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/524#issuecomment-382299662
https://github.com/su2code/SU2/pull/525#issuecomment-382302222:56,Availability,mainten,maintenance,56,"Thanks, @economon! It's great to start again doing some maintenance releases, that should ease the development and release process. There is a small pull request I have recently put through and that I think it would fit in this release. Could you have a look? Maybe it's worthy to add it to 6.0.1.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/525#issuecomment-382302222
https://github.com/su2code/SU2/pull/525#issuecomment-382302222:68,Deployability,release,releases,68,"Thanks, @economon! It's great to start again doing some maintenance releases, that should ease the development and release process. There is a small pull request I have recently put through and that I think it would fit in this release. Could you have a look? Maybe it's worthy to add it to 6.0.1.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/525#issuecomment-382302222
https://github.com/su2code/SU2/pull/525#issuecomment-382302222:115,Deployability,release,release,115,"Thanks, @economon! It's great to start again doing some maintenance releases, that should ease the development and release process. There is a small pull request I have recently put through and that I think it would fit in this release. Could you have a look? Maybe it's worthy to add it to 6.0.1.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/525#issuecomment-382302222
https://github.com/su2code/SU2/pull/525#issuecomment-382302222:228,Deployability,release,release,228,"Thanks, @economon! It's great to start again doing some maintenance releases, that should ease the development and release process. There is a small pull request I have recently put through and that I think it would fit in this release. Could you have a look? Maybe it's worthy to add it to 6.0.1.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/525#issuecomment-382302222
https://github.com/su2code/SU2/issues/526#issuecomment-383032449:156,Integrability,interface,interface,156,"Hi @timjim333 ,. you can try to set an environmental variable 'SU2_MPI_COMMAND' which contains your specific mpirun command. Take a look at /SU2_PY/SU2/run/interface.py (line 66) in the source code, that might help. There the command which is called by parallel_computation.py is build. For your case it should be:; export SU2_MPI_COMMAND=""mpirun --use-hwthread-cpus -np %i %s"". I hope that helps :) Regards,; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-383032449
https://github.com/su2code/SU2/issues/526#issuecomment-383032449:53,Modifiability,variab,variable,53,"Hi @timjim333 ,. you can try to set an environmental variable 'SU2_MPI_COMMAND' which contains your specific mpirun command. Take a look at /SU2_PY/SU2/run/interface.py (line 66) in the source code, that might help. There the command which is called by parallel_computation.py is build. For your case it should be:; export SU2_MPI_COMMAND=""mpirun --use-hwthread-cpus -np %i %s"". I hope that helps :) Regards,; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-383032449
https://github.com/su2code/SU2/issues/526#issuecomment-395712721:430,Integrability,rout,routine,430,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721
https://github.com/su2code/SU2/issues/526#issuecomment-395712721:511,Integrability,interface,interface,511,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721
https://github.com/su2code/SU2/issues/526#issuecomment-395712721:258,Modifiability,config,configure,258,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721
https://github.com/su2code/SU2/issues/526#issuecomment-395712721:197,Usability,simpl,simply,197,"Hi @timjim333 ,. Exactly (concerning your first question). . For the %s : In your initial post you stated that `mpirun --use-hwthread-cpus -np 12 SU2_CFD turb_ONERAM6.cfg` worked for you. So %s is simply the place-holder for the SU2 module together with the configure script. Which in your case would be `SU2_CFD turb_ONERAM6.cfg` . But `parallel_computation.py` will also call `SU2_SOL turb_ONERAM6.cfg` for you after the solver routine to create output files for visualization. ; If you take a look into the `interface.py` (as in my previous post) and the `parallel_computation.py` you'll find exactly how its done. Cheers, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-395712721
https://github.com/su2code/SU2/issues/526#issuecomment-428829621:352,Integrability,interface,interface,352,"Hi @TobiKattmann ,. Apologies for the huge gap in communication - I had to attend to other matters before I could try this out. I just wanted to follow up and thank you for your suggestions. Doing `export SU2_MPI_COMMAND=""mpirun --use-hwthread-cpus -n %i %s""` before calling 'parallel_computation.py' did the job!. Is it safe for me to edit line 70 in interface.py from `mpi_Command = 'mpirun -n %i %s'` to `mpi_Command = 'mpirun --use-hwthread-cpus -n %i %s'` so that it is set permanently? Or is it better to put `export SU2_MPI_COMMAND=""mpirun --use-hwthread-cpus -n %i %s""` in my .bashrc?. Many thanks and kind regards,; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-428829621
https://github.com/su2code/SU2/issues/526#issuecomment-428829621:321,Safety,safe,safe,321,"Hi @TobiKattmann ,. Apologies for the huge gap in communication - I had to attend to other matters before I could try this out. I just wanted to follow up and thank you for your suggestions. Doing `export SU2_MPI_COMMAND=""mpirun --use-hwthread-cpus -n %i %s""` before calling 'parallel_computation.py' did the job!. Is it safe for me to edit line 70 in interface.py from `mpi_Command = 'mpirun -n %i %s'` to `mpi_Command = 'mpirun --use-hwthread-cpus -n %i %s'` so that it is set permanently? Or is it better to put `export SU2_MPI_COMMAND=""mpirun --use-hwthread-cpus -n %i %s""` in my .bashrc?. Many thanks and kind regards,; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-428829621
https://github.com/su2code/SU2/issues/526#issuecomment-429668015:268,Deployability,install,installed,268,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015
https://github.com/su2code/SU2/issues/526#issuecomment-429668015:308,Deployability,patch,patch,308,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015
https://github.com/su2code/SU2/issues/526#issuecomment-429668015:381,Integrability,interface,interface,381,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015
https://github.com/su2code/SU2/issues/526#issuecomment-429668015:181,Usability,clear,clear,181,"Hey @timjim333 that's nice to hear,. I would put it in the .bashrc if you consistently call SU2 with your command, like that you can always switch the SU2-build and still have your clear settings already in place. Image having the master, develop and feature_whatever installed, you don't need to apply your patch to all of these versions if you put it in the bashrc.; But editing interface.py has the same effect, so its up to you what you prefer. Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/526#issuecomment-429668015
https://github.com/su2code/SU2/pull/528#issuecomment-388799884:160,Energy Efficiency,sustainab,sustainability,160,"Thanks for the comments, Tom! I understand it's a big change, so I would welcome some more feedback! . I am working in other ways to improve the generalization/sustainability of the code, so any comments would also be considered for that stage :D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-388799884
https://github.com/su2code/SU2/pull/528#issuecomment-388799884:91,Usability,feedback,feedback,91,"Thanks for the comments, Tom! I understand it's a big change, so I would welcome some more feedback! . I am working in other ways to improve the generalization/sustainability of the code, so any comments would also be considered for that stage :D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-388799884
https://github.com/su2code/SU2/pull/528#issuecomment-392047648:1081,Deployability,update,updated,1081,"Hi Antonio, thanks for the review! . Precisely, the point of this PR is to ease generalization of multi-zone, multi-instance problems. For this reason, I am currently working on a branch putting together a CMultizoneDriver, which should be generic enough to accommodate problems involving complex multiphysics. The situation is now that there are a lot of hard-coded constraints, in order for specific features to work. FSI is an example itself; it requires a very strict way of setting up the problem. The same happens with other features such as Multizone HB. While this is ok for showcasing the features, I don't think it's a sustainable approach. For example, if we were to do Turbomachinery FSI, with the current structure it wouldn't be feasible. It would require a ""CTurbomachineryFSIDriver"" class, and more hard coded assumptions. My goal is to get rid of these bottlenecks, by leveraging on the class structure of SU2. Of course, this will require work, but I think it will pay off in the long run. This PR is just a starting point: SU2_DEF, SU2_DOT, etc, will need to be updated accordingly in next stages, together with other changes that are also necessary in the optimization framework and the core code to get rid of a lot of hacks here and there. I will reply to your specific questions separately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392047648
https://github.com/su2code/SU2/pull/528#issuecomment-392047648:629,Energy Efficiency,sustainab,sustainable,629,"Hi Antonio, thanks for the review! . Precisely, the point of this PR is to ease generalization of multi-zone, multi-instance problems. For this reason, I am currently working on a branch putting together a CMultizoneDriver, which should be generic enough to accommodate problems involving complex multiphysics. The situation is now that there are a lot of hard-coded constraints, in order for specific features to work. FSI is an example itself; it requires a very strict way of setting up the problem. The same happens with other features such as Multizone HB. While this is ok for showcasing the features, I don't think it's a sustainable approach. For example, if we were to do Turbomachinery FSI, with the current structure it wouldn't be feasible. It would require a ""CTurbomachineryFSIDriver"" class, and more hard coded assumptions. My goal is to get rid of these bottlenecks, by leveraging on the class structure of SU2. Of course, this will require work, but I think it will pay off in the long run. This PR is just a starting point: SU2_DEF, SU2_DOT, etc, will need to be updated accordingly in next stages, together with other changes that are also necessary in the optimization framework and the core code to get rid of a lot of hacks here and there. I will reply to your specific questions separately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392047648
https://github.com/su2code/SU2/pull/528#issuecomment-392047648:870,Performance,bottleneck,bottlenecks,870,"Hi Antonio, thanks for the review! . Precisely, the point of this PR is to ease generalization of multi-zone, multi-instance problems. For this reason, I am currently working on a branch putting together a CMultizoneDriver, which should be generic enough to accommodate problems involving complex multiphysics. The situation is now that there are a lot of hard-coded constraints, in order for specific features to work. FSI is an example itself; it requires a very strict way of setting up the problem. The same happens with other features such as Multizone HB. While this is ok for showcasing the features, I don't think it's a sustainable approach. For example, if we were to do Turbomachinery FSI, with the current structure it wouldn't be feasible. It would require a ""CTurbomachineryFSIDriver"" class, and more hard coded assumptions. My goal is to get rid of these bottlenecks, by leveraging on the class structure of SU2. Of course, this will require work, but I think it will pay off in the long run. This PR is just a starting point: SU2_DEF, SU2_DOT, etc, will need to be updated accordingly in next stages, together with other changes that are also necessary in the optimization framework and the core code to get rid of a lot of hacks here and there. I will reply to your specific questions separately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392047648
https://github.com/su2code/SU2/pull/528#issuecomment-392047648:1176,Performance,optimiz,optimization,1176,"Hi Antonio, thanks for the review! . Precisely, the point of this PR is to ease generalization of multi-zone, multi-instance problems. For this reason, I am currently working on a branch putting together a CMultizoneDriver, which should be generic enough to accommodate problems involving complex multiphysics. The situation is now that there are a lot of hard-coded constraints, in order for specific features to work. FSI is an example itself; it requires a very strict way of setting up the problem. The same happens with other features such as Multizone HB. While this is ok for showcasing the features, I don't think it's a sustainable approach. For example, if we were to do Turbomachinery FSI, with the current structure it wouldn't be feasible. It would require a ""CTurbomachineryFSIDriver"" class, and more hard coded assumptions. My goal is to get rid of these bottlenecks, by leveraging on the class structure of SU2. Of course, this will require work, but I think it will pay off in the long run. This PR is just a starting point: SU2_DEF, SU2_DOT, etc, will need to be updated accordingly in next stages, together with other changes that are also necessary in the optimization framework and the core code to get rid of a lot of hacks here and there. I will reply to your specific questions separately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392047648
https://github.com/su2code/SU2/pull/528#issuecomment-392061901:312,Modifiability,config,config,312,Sounds good to me. I have been prototyping the multizone driver in the last couple of weeks. It's still in the early stages but it's slowly taking shape. You can find it here:; https://github.com/su2code/SU2/tree/feature_reformat_config. I also outlined some of the changes (particularly in what respects to the config file) in the Dev-society forum: https://su2devsociety.org/forum/?view=thread&id=5 . We could keep the conversation there if you want. Happy to set up a meeting to explain a bit what I have been doing and receive some feedback (and helping hands would also be welcome!) from the different groups.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392061901
https://github.com/su2code/SU2/pull/528#issuecomment-392061901:536,Usability,feedback,feedback,536,Sounds good to me. I have been prototyping the multizone driver in the last couple of weeks. It's still in the early stages but it's slowly taking shape. You can find it here:; https://github.com/su2code/SU2/tree/feature_reformat_config. I also outlined some of the changes (particularly in what respects to the config file) in the Dev-society forum: https://su2devsociety.org/forum/?view=thread&id=5 . We could keep the conversation there if you want. Happy to set up a meeting to explain a bit what I have been doing and receive some feedback (and helping hands would also be welcome!) from the different groups.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392061901
https://github.com/su2code/SU2/pull/528#issuecomment-392065213:324,Security,access,accessible,324,"Thanks Ruben! Sorry, but I did not even know there was a forum (and also with these topics) by the Dev-society. I would suggest better a meeting and maybe posting on github projects the next steps so that all developers can get information about it. I would keep the conversation on github projects (if possible) so that is accessible to everybody. I'll shortly contact you in private to organize a meeting thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392065213
https://github.com/su2code/SU2/pull/528#issuecomment-392070338:214,Security,access,access,214,"Hi Antonio,; the forum is a brand new feature, so it's normal you hadn't heard about it! :) In fact, mine was one of the very first posts. So that's precisely why we are putting it together, so all developers have access to the discussion there. I think moving this discussion there would be a good starting point (and a good way to encourage its use :D).; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-392070338
https://github.com/su2code/SU2/pull/528#issuecomment-396174581:74,Modifiability,refactor,refactorization,74,"Guys, we really want to merge this in soon to go on with the output/input refactorization. Someone else has some comments ? Otherwise, we need some approvals :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-396174581
https://github.com/su2code/SU2/pull/528#issuecomment-398427777:96,Testability,test,tests,96,"Thanks @fpalacios , that would be great. I've merged with develop and fixed some conflicts, the tests are running right now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/528#issuecomment-398427777
https://github.com/su2code/SU2/pull/530#issuecomment-387719885:48,Deployability,update,updated,48,"Thanks for this pull request! LGTM. I have just updated the branch with develop and the tests are passing, however I will wait for @economon to give his opinion as it was originally his implementation. Only a minor comment: there are some files in which white spaces are introduced in blank lines, probably done automatically by the editor (e.g., numerics_direct_mean.cpp and solver_direct_mean.cpp). This is not a problem in itself, but I have experienced this can generate problems with future merges.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/530#issuecomment-387719885
https://github.com/su2code/SU2/pull/530#issuecomment-387719885:88,Testability,test,tests,88,"Thanks for this pull request! LGTM. I have just updated the branch with develop and the tests are passing, however I will wait for @economon to give his opinion as it was originally his implementation. Only a minor comment: there are some files in which white spaces are introduced in blank lines, probably done automatically by the editor (e.g., numerics_direct_mean.cpp and solver_direct_mean.cpp). This is not a problem in itself, but I have experienced this can generate problems with future merges.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/530#issuecomment-387719885
https://github.com/su2code/SU2/pull/530#issuecomment-387921905:123,Testability,test,test,123,"Thanks for finishing up the implementation, @VivaanKhatri! I am looking forward to reviewing this very soon. Do you have a test case to verify things are working? Even just a simple flat plate like in the paper so that we can put it under regression control?. @rsanfer: your comment reminded me about our earlier attempts to fix up the indentation issues on the fix_indentation branch. Do you think this is something we can revive to provide scripts for automatically fixing this issue once and for all? Or do we need to find a different approach?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/530#issuecomment-387921905
https://github.com/su2code/SU2/pull/530#issuecomment-387921905:175,Usability,simpl,simple,175,"Thanks for finishing up the implementation, @VivaanKhatri! I am looking forward to reviewing this very soon. Do you have a test case to verify things are working? Even just a simple flat plate like in the paper so that we can put it under regression control?. @rsanfer: your comment reminded me about our earlier attempts to fix up the indentation issues on the fix_indentation branch. Do you think this is something we can revive to provide scripts for automatically fixing this issue once and for all? Or do we need to find a different approach?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/530#issuecomment-387921905
https://github.com/su2code/SU2/issues/531#issuecomment-388288297:10,Availability,error,error,10,"Hi,. This error simply occurs because the prototype of the CDriver (and child classes) has changed. There is an additional `bool val_periodic` argument that have to be passed. The current fsi_computation.py is not up-to-date. Here are solutions to fix that:. - Change the fsi_computation.py and pass an extra `False` argument between the number of dimensions and the communicator. or. - Do you need the very last develop branch ? Because it seems like in the master branch the constructor of the CDriver is still the compatible one. So you could use this branch without modifying anything. I hope this will help. Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388288297
https://github.com/su2code/SU2/issues/531#issuecomment-388288297:16,Usability,simpl,simply,16,"Hi,. This error simply occurs because the prototype of the CDriver (and child classes) has changed. There is an additional `bool val_periodic` argument that have to be passed. The current fsi_computation.py is not up-to-date. Here are solutions to fix that:. - Change the fsi_computation.py and pass an extra `False` argument between the number of dimensions and the communicator. or. - Do you need the very last develop branch ? Because it seems like in the master branch the constructor of the CDriver is still the compatible one. So you could use this branch without modifying anything. I hope this will help. Cheers,. David",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388288297
https://github.com/su2code/SU2/issues/531#issuecomment-388316476:131,Availability,error,error,131,"Hi David,; Yes, I was able to figure out that and I went ahead in trying to make fsi_computation.py work with this branch. Another error (which may be a bug actually ) occurs when the wrapped function **SetInitialMesh()** is run. This directly involves the core of SU2 as I found out the error is given during the run of the function **CILUPreconditioner** (inside **matrix_structure.cpp**) which, as much I understood, builds the preconditioning matrix for the solution of the linear system at the base of the mesh deforming procedure. . SU2 uses by default **ILU** precoditioner whose relative function (see above) has remarkable differences from the Raven release (I didn't go too much into details). Same error I get if using **Jacobi** preconditioner. ; At contrary, everything seems fine if using **LU_SGS** preconditioner and the fsi_computation.py finally works. Maybe it's the case to point it out to the developers inveloved in this part of the code. About your last point, I'm developing at the moment some FSI features and I very much relied on fsi_computation.py in defining the interface with the SU2 core. I'm trying to keep it updated with the current version of SU2 for reliability reasons; I hope there won't be drastic changes in the python wrapping of the code! :). Thanks for the reply!. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388316476
https://github.com/su2code/SU2/issues/531#issuecomment-388316476:288,Availability,error,error,288,"Hi David,; Yes, I was able to figure out that and I went ahead in trying to make fsi_computation.py work with this branch. Another error (which may be a bug actually ) occurs when the wrapped function **SetInitialMesh()** is run. This directly involves the core of SU2 as I found out the error is given during the run of the function **CILUPreconditioner** (inside **matrix_structure.cpp**) which, as much I understood, builds the preconditioning matrix for the solution of the linear system at the base of the mesh deforming procedure. . SU2 uses by default **ILU** precoditioner whose relative function (see above) has remarkable differences from the Raven release (I didn't go too much into details). Same error I get if using **Jacobi** preconditioner. ; At contrary, everything seems fine if using **LU_SGS** preconditioner and the fsi_computation.py finally works. Maybe it's the case to point it out to the developers inveloved in this part of the code. About your last point, I'm developing at the moment some FSI features and I very much relied on fsi_computation.py in defining the interface with the SU2 core. I'm trying to keep it updated with the current version of SU2 for reliability reasons; I hope there won't be drastic changes in the python wrapping of the code! :). Thanks for the reply!. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388316476
https://github.com/su2code/SU2/issues/531#issuecomment-388316476:709,Availability,error,error,709,"Hi David,; Yes, I was able to figure out that and I went ahead in trying to make fsi_computation.py work with this branch. Another error (which may be a bug actually ) occurs when the wrapped function **SetInitialMesh()** is run. This directly involves the core of SU2 as I found out the error is given during the run of the function **CILUPreconditioner** (inside **matrix_structure.cpp**) which, as much I understood, builds the preconditioning matrix for the solution of the linear system at the base of the mesh deforming procedure. . SU2 uses by default **ILU** precoditioner whose relative function (see above) has remarkable differences from the Raven release (I didn't go too much into details). Same error I get if using **Jacobi** preconditioner. ; At contrary, everything seems fine if using **LU_SGS** preconditioner and the fsi_computation.py finally works. Maybe it's the case to point it out to the developers inveloved in this part of the code. About your last point, I'm developing at the moment some FSI features and I very much relied on fsi_computation.py in defining the interface with the SU2 core. I'm trying to keep it updated with the current version of SU2 for reliability reasons; I hope there won't be drastic changes in the python wrapping of the code! :). Thanks for the reply!. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388316476
https://github.com/su2code/SU2/issues/531#issuecomment-388316476:1187,Availability,reliab,reliability,1187,"Hi David,; Yes, I was able to figure out that and I went ahead in trying to make fsi_computation.py work with this branch. Another error (which may be a bug actually ) occurs when the wrapped function **SetInitialMesh()** is run. This directly involves the core of SU2 as I found out the error is given during the run of the function **CILUPreconditioner** (inside **matrix_structure.cpp**) which, as much I understood, builds the preconditioning matrix for the solution of the linear system at the base of the mesh deforming procedure. . SU2 uses by default **ILU** precoditioner whose relative function (see above) has remarkable differences from the Raven release (I didn't go too much into details). Same error I get if using **Jacobi** preconditioner. ; At contrary, everything seems fine if using **LU_SGS** preconditioner and the fsi_computation.py finally works. Maybe it's the case to point it out to the developers inveloved in this part of the code. About your last point, I'm developing at the moment some FSI features and I very much relied on fsi_computation.py in defining the interface with the SU2 core. I'm trying to keep it updated with the current version of SU2 for reliability reasons; I hope there won't be drastic changes in the python wrapping of the code! :). Thanks for the reply!. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388316476
https://github.com/su2code/SU2/issues/531#issuecomment-388316476:659,Deployability,release,release,659,"Hi David,; Yes, I was able to figure out that and I went ahead in trying to make fsi_computation.py work with this branch. Another error (which may be a bug actually ) occurs when the wrapped function **SetInitialMesh()** is run. This directly involves the core of SU2 as I found out the error is given during the run of the function **CILUPreconditioner** (inside **matrix_structure.cpp**) which, as much I understood, builds the preconditioning matrix for the solution of the linear system at the base of the mesh deforming procedure. . SU2 uses by default **ILU** precoditioner whose relative function (see above) has remarkable differences from the Raven release (I didn't go too much into details). Same error I get if using **Jacobi** preconditioner. ; At contrary, everything seems fine if using **LU_SGS** preconditioner and the fsi_computation.py finally works. Maybe it's the case to point it out to the developers inveloved in this part of the code. About your last point, I'm developing at the moment some FSI features and I very much relied on fsi_computation.py in defining the interface with the SU2 core. I'm trying to keep it updated with the current version of SU2 for reliability reasons; I hope there won't be drastic changes in the python wrapping of the code! :). Thanks for the reply!. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388316476
https://github.com/su2code/SU2/issues/531#issuecomment-388316476:1143,Deployability,update,updated,1143,"Hi David,; Yes, I was able to figure out that and I went ahead in trying to make fsi_computation.py work with this branch. Another error (which may be a bug actually ) occurs when the wrapped function **SetInitialMesh()** is run. This directly involves the core of SU2 as I found out the error is given during the run of the function **CILUPreconditioner** (inside **matrix_structure.cpp**) which, as much I understood, builds the preconditioning matrix for the solution of the linear system at the base of the mesh deforming procedure. . SU2 uses by default **ILU** precoditioner whose relative function (see above) has remarkable differences from the Raven release (I didn't go too much into details). Same error I get if using **Jacobi** preconditioner. ; At contrary, everything seems fine if using **LU_SGS** preconditioner and the fsi_computation.py finally works. Maybe it's the case to point it out to the developers inveloved in this part of the code. About your last point, I'm developing at the moment some FSI features and I very much relied on fsi_computation.py in defining the interface with the SU2 core. I'm trying to keep it updated with the current version of SU2 for reliability reasons; I hope there won't be drastic changes in the python wrapping of the code! :). Thanks for the reply!. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388316476
https://github.com/su2code/SU2/issues/531#issuecomment-388316476:184,Integrability,wrap,wrapped,184,"Hi David,; Yes, I was able to figure out that and I went ahead in trying to make fsi_computation.py work with this branch. Another error (which may be a bug actually ) occurs when the wrapped function **SetInitialMesh()** is run. This directly involves the core of SU2 as I found out the error is given during the run of the function **CILUPreconditioner** (inside **matrix_structure.cpp**) which, as much I understood, builds the preconditioning matrix for the solution of the linear system at the base of the mesh deforming procedure. . SU2 uses by default **ILU** precoditioner whose relative function (see above) has remarkable differences from the Raven release (I didn't go too much into details). Same error I get if using **Jacobi** preconditioner. ; At contrary, everything seems fine if using **LU_SGS** preconditioner and the fsi_computation.py finally works. Maybe it's the case to point it out to the developers inveloved in this part of the code. About your last point, I'm developing at the moment some FSI features and I very much relied on fsi_computation.py in defining the interface with the SU2 core. I'm trying to keep it updated with the current version of SU2 for reliability reasons; I hope there won't be drastic changes in the python wrapping of the code! :). Thanks for the reply!. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388316476
https://github.com/su2code/SU2/issues/531#issuecomment-388316476:1092,Integrability,interface,interface,1092,"Hi David,; Yes, I was able to figure out that and I went ahead in trying to make fsi_computation.py work with this branch. Another error (which may be a bug actually ) occurs when the wrapped function **SetInitialMesh()** is run. This directly involves the core of SU2 as I found out the error is given during the run of the function **CILUPreconditioner** (inside **matrix_structure.cpp**) which, as much I understood, builds the preconditioning matrix for the solution of the linear system at the base of the mesh deforming procedure. . SU2 uses by default **ILU** precoditioner whose relative function (see above) has remarkable differences from the Raven release (I didn't go too much into details). Same error I get if using **Jacobi** preconditioner. ; At contrary, everything seems fine if using **LU_SGS** preconditioner and the fsi_computation.py finally works. Maybe it's the case to point it out to the developers inveloved in this part of the code. About your last point, I'm developing at the moment some FSI features and I very much relied on fsi_computation.py in defining the interface with the SU2 core. I'm trying to keep it updated with the current version of SU2 for reliability reasons; I hope there won't be drastic changes in the python wrapping of the code! :). Thanks for the reply!. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388316476
https://github.com/su2code/SU2/issues/531#issuecomment-388316476:1260,Integrability,wrap,wrapping,1260,"Hi David,; Yes, I was able to figure out that and I went ahead in trying to make fsi_computation.py work with this branch. Another error (which may be a bug actually ) occurs when the wrapped function **SetInitialMesh()** is run. This directly involves the core of SU2 as I found out the error is given during the run of the function **CILUPreconditioner** (inside **matrix_structure.cpp**) which, as much I understood, builds the preconditioning matrix for the solution of the linear system at the base of the mesh deforming procedure. . SU2 uses by default **ILU** precoditioner whose relative function (see above) has remarkable differences from the Raven release (I didn't go too much into details). Same error I get if using **Jacobi** preconditioner. ; At contrary, everything seems fine if using **LU_SGS** preconditioner and the fsi_computation.py finally works. Maybe it's the case to point it out to the developers inveloved in this part of the code. About your last point, I'm developing at the moment some FSI features and I very much relied on fsi_computation.py in defining the interface with the SU2 core. I'm trying to keep it updated with the current version of SU2 for reliability reasons; I hope there won't be drastic changes in the python wrapping of the code! :). Thanks for the reply!. Rocco",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/531#issuecomment-388316476
https://github.com/su2code/SU2/pull/532#issuecomment-388169276:237,Availability,error,errors,237,"@clarkpede ; Thank you for catching this. I think a messed up something here while I was merging my implementation to the current version! Please be aware that the papers of Travin et al. and Strelets et al. also have some typographical errors, see the papers of:. Zhixiang Xiao, Jian Liu, Jingbo Huang, and Song Fu. ""Numerical Dissipation Effects on Massive Separation Around Tandem Cylinders"", AIAA Journal, Vol. 50, No. 5 (2012), pp. 1119-1136. ; https://arc.aiaa.org/doi/abs/10.2514/1.J051299 ; Mockett, ""A Comprehensive Study of Detached Eddy Simulation"" PhD Thesis. Regarding the DDES test cases, I agree that Travis will not handle any meaningful 3D test case. Do you have any suggestion? By now, all I can do is to test it outside. . Best,. Eduardo.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388169276
https://github.com/su2code/SU2/pull/532#issuecomment-388169276:499,Testability,Mock,Mockett,499,"@clarkpede ; Thank you for catching this. I think a messed up something here while I was merging my implementation to the current version! Please be aware that the papers of Travin et al. and Strelets et al. also have some typographical errors, see the papers of:. Zhixiang Xiao, Jian Liu, Jingbo Huang, and Song Fu. ""Numerical Dissipation Effects on Massive Separation Around Tandem Cylinders"", AIAA Journal, Vol. 50, No. 5 (2012), pp. 1119-1136. ; https://arc.aiaa.org/doi/abs/10.2514/1.J051299 ; Mockett, ""A Comprehensive Study of Detached Eddy Simulation"" PhD Thesis. Regarding the DDES test cases, I agree that Travis will not handle any meaningful 3D test case. Do you have any suggestion? By now, all I can do is to test it outside. . Best,. Eduardo.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388169276
https://github.com/su2code/SU2/pull/532#issuecomment-388169276:591,Testability,test,test,591,"@clarkpede ; Thank you for catching this. I think a messed up something here while I was merging my implementation to the current version! Please be aware that the papers of Travin et al. and Strelets et al. also have some typographical errors, see the papers of:. Zhixiang Xiao, Jian Liu, Jingbo Huang, and Song Fu. ""Numerical Dissipation Effects on Massive Separation Around Tandem Cylinders"", AIAA Journal, Vol. 50, No. 5 (2012), pp. 1119-1136. ; https://arc.aiaa.org/doi/abs/10.2514/1.J051299 ; Mockett, ""A Comprehensive Study of Detached Eddy Simulation"" PhD Thesis. Regarding the DDES test cases, I agree that Travis will not handle any meaningful 3D test case. Do you have any suggestion? By now, all I can do is to test it outside. . Best,. Eduardo.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388169276
https://github.com/su2code/SU2/pull/532#issuecomment-388169276:657,Testability,test,test,657,"@clarkpede ; Thank you for catching this. I think a messed up something here while I was merging my implementation to the current version! Please be aware that the papers of Travin et al. and Strelets et al. also have some typographical errors, see the papers of:. Zhixiang Xiao, Jian Liu, Jingbo Huang, and Song Fu. ""Numerical Dissipation Effects on Massive Separation Around Tandem Cylinders"", AIAA Journal, Vol. 50, No. 5 (2012), pp. 1119-1136. ; https://arc.aiaa.org/doi/abs/10.2514/1.J051299 ; Mockett, ""A Comprehensive Study of Detached Eddy Simulation"" PhD Thesis. Regarding the DDES test cases, I agree that Travis will not handle any meaningful 3D test case. Do you have any suggestion? By now, all I can do is to test it outside. . Best,. Eduardo.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388169276
https://github.com/su2code/SU2/pull/532#issuecomment-388169276:723,Testability,test,test,723,"@clarkpede ; Thank you for catching this. I think a messed up something here while I was merging my implementation to the current version! Please be aware that the papers of Travin et al. and Strelets et al. also have some typographical errors, see the papers of:. Zhixiang Xiao, Jian Liu, Jingbo Huang, and Song Fu. ""Numerical Dissipation Effects on Massive Separation Around Tandem Cylinders"", AIAA Journal, Vol. 50, No. 5 (2012), pp. 1119-1136. ; https://arc.aiaa.org/doi/abs/10.2514/1.J051299 ; Mockett, ""A Comprehensive Study of Detached Eddy Simulation"" PhD Thesis. Regarding the DDES test cases, I agree that Travis will not handle any meaningful 3D test case. Do you have any suggestion? By now, all I can do is to test it outside. . Best,. Eduardo.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388169276
https://github.com/su2code/SU2/pull/532#issuecomment-388189377:966,Integrability,depend,dependent,966,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377
https://github.com/su2code/SU2/pull/532#issuecomment-388189377:418,Testability,Mock,Mockett,418,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377
https://github.com/su2code/SU2/pull/532#issuecomment-388189377:531,Testability,test,tests,531,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377
https://github.com/su2code/SU2/pull/532#issuecomment-388189377:788,Testability,Mock,Mockett,788,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377
https://github.com/su2code/SU2/pull/532#issuecomment-388189377:1111,Usability,simpl,simpler,1111,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377
https://github.com/su2code/SU2/pull/532#issuecomment-388189377:1216,Usability,simpl,simplicity,1216,"Ah, I wasn't aware of the corrected version. Thanks for pointing out my mistake. The corrected version does make more sense, and the main changes seem to be:. + Changing the location of the sqrt in the definition of `Lturb`; + Changing `ch3` from 0.5 to 2.0; + Clarifying that S and Omega should have a factor of sqrt(2). As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. We know that they got a nice range of values for the blending constant on their tests with DDES. The cases I can see where they explicitly show the results of the blending function are:. + Circular cylinder at Re = 50,000 (Travin _et al._ 2002); + Tandem cylinders at Re = 166,000 (Xiao _et al._ 2012); + NACA0021 airfoil in deep stall (Mockett 2009). The tricky thing is that the value of the blending constant is determined by the flow solution, which is determined by the solver. So the values we obtain will be dependent both on the version of DDES used and the nature of the code. We can't expect to match any of these papers exactly. We could also use a simpler flow, such as fully developed channel flow or a flat plate boundary layer. The tradeoff would be simplicity for ease of comparison.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-388189377
https://github.com/su2code/SU2/pull/532#issuecomment-390437324:72,Testability,test,tests,72,"Thanks @clarkpede . I will merge it. We can talk more about regressions tests in another topic. Best,. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/532#issuecomment-390437324
https://github.com/su2code/SU2/issues/533#issuecomment-388532268:29,Availability,avail,available,29,Would it be possible to make available the Gmsh mesh and the config file?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-388532268
https://github.com/su2code/SU2/issues/533#issuecomment-388532268:61,Modifiability,config,config,61,Would it be possible to make available the Gmsh mesh and the config file?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-388532268
https://github.com/su2code/SU2/issues/533#issuecomment-388545925:258,Availability,error,error,258,"I noticed you mentioned that it is a multiblock structured mesh. SU2 expects a single block format, unless explicitly setting up a multi zone problem, so there's an outside chance it's only loading part of the mesh. I would expect that to throw some kind of error, but it's worth checking.; This could explain the wrong z projection, but to check you can plot the output volume solution to see if your mesh is loaded appropriately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-388545925
https://github.com/su2code/SU2/issues/533#issuecomment-388545925:190,Performance,load,loading,190,"I noticed you mentioned that it is a multiblock structured mesh. SU2 expects a single block format, unless explicitly setting up a multi zone problem, so there's an outside chance it's only loading part of the mesh. I would expect that to throw some kind of error, but it's worth checking.; This could explain the wrong z projection, but to check you can plot the output volume solution to see if your mesh is loaded appropriately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-388545925
https://github.com/su2code/SU2/issues/533#issuecomment-388545925:410,Performance,load,loaded,410,"I noticed you mentioned that it is a multiblock structured mesh. SU2 expects a single block format, unless explicitly setting up a multi zone problem, so there's an outside chance it's only loading part of the mesh. I would expect that to throw some kind of error, but it's worth checking.; This could explain the wrong z projection, but to check you can plot the output volume solution to see if your mesh is loaded appropriately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-388545925
https://github.com/su2code/SU2/issues/533#issuecomment-388723451:245,Modifiability,config,config,245,"@vdweide: I cannot give you the geometry or the mesh because they are the property of an aircraft manufacturer, a colleague is going to check if he can provide a dummy geometry, similar to the one we are working onto. What I can give you is the config file (I still had to change some values related to the geometry). @hlkline: What I meant was that the meshes were generated using a multi block strategy. Before writing into SU2 or CGNS, they were converted in a proper unstructured format. I had indeed checked the surface solution, but not the volume one. And it seems that there are some weird cells (see attached screenshot). I will investigate. Thanks for your inputs!. [EBW2v2.txt](https://github.com/su2code/SU2/files/1999732/EBW2v2.txt). ![volume](https://user-images.githubusercontent.com/39187559/39983910-a25a9172-5759-11e8-9d5e-d7066ae95d00.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-388723451
https://github.com/su2code/SU2/issues/533#issuecomment-388726367:4,Modifiability,config,config,4,"The config file is a start, but for a thorough investigation a full test case, i.e. including a grid, is preferable.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-388726367
https://github.com/su2code/SU2/issues/533#issuecomment-388726367:68,Testability,test,test,68,"The config file is a start, but for a thorough investigation a full test case, i.e. including a grid, is preferable.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-388726367
https://github.com/su2code/SU2/issues/533#issuecomment-392442127:1140,Deployability,configurat,configuration,1140,"Hi there,. I went ahead and created a dummy geometry, that is:; 1. I altered the planform so that the sweep, twist, dihedral, taper... are now different from the actual wing; 2. I replaced the airfoil by the NASA SC(2)-0712. The dummy wing has a double planform defined as:; - semi span = [5; 10]; - taper = [0.55; 0.35]; - dihedral angle = [5; 2.5]; - twist angle = [1; 0; -1] (given for root, kink and tip airfoil sections); - sweep angle at LE = 25; - Aspect ratio = 11.8; - semi area = 38. I defined the reference length as:; - reference (semi) area = 45; - reference chord = 3; - reference (semi) span = 15. The flight conditions remained unchanged:; - Mach number: 0.78; - Temperature = ~217 K; - Reynolds number: ~19 millions; - AoA = 0. I created the exact same grid as before (same number of cells, same progression), ensuring my first cell was at y+<1. Things is, this time, SU2 did not have any trouble converging and computed the right z-projected area... I checked the results with another software and the pressure distribution (taken along the chord near the kink) match, see attached Figure. I am attaching the dummy configuration file (dum.txt) as well as the mesh (dum_mesh.txt) if it can be of interest to you. The mesh is a .geo gmsh file. To get the mesh, simply open with gmsh and click mesh 3D (or, from the console: gmsh dum_mesh.txt -3). At this point, I think that my problem might be related to the actual wing airfoil geometry, which is somehow not well pre-processed by SU2... I will continue investigating and keep you posted if I find a solution. Thank you for the time you took reading this issue.; ![cp](https://user-images.githubusercontent.com/39187559/40602255-3de183ae-6258-11e8-9aba-6c8d374dc34e.png); [dum.txt](https://github.com/su2code/SU2/files/2044072/dum.txt); [dum_mesh.txt](https://github.com/su2code/SU2/files/2044073/dum_mesh.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-392442127
https://github.com/su2code/SU2/issues/533#issuecomment-392442127:1140,Modifiability,config,configuration,1140,"Hi there,. I went ahead and created a dummy geometry, that is:; 1. I altered the planform so that the sweep, twist, dihedral, taper... are now different from the actual wing; 2. I replaced the airfoil by the NASA SC(2)-0712. The dummy wing has a double planform defined as:; - semi span = [5; 10]; - taper = [0.55; 0.35]; - dihedral angle = [5; 2.5]; - twist angle = [1; 0; -1] (given for root, kink and tip airfoil sections); - sweep angle at LE = 25; - Aspect ratio = 11.8; - semi area = 38. I defined the reference length as:; - reference (semi) area = 45; - reference chord = 3; - reference (semi) span = 15. The flight conditions remained unchanged:; - Mach number: 0.78; - Temperature = ~217 K; - Reynolds number: ~19 millions; - AoA = 0. I created the exact same grid as before (same number of cells, same progression), ensuring my first cell was at y+<1. Things is, this time, SU2 did not have any trouble converging and computed the right z-projected area... I checked the results with another software and the pressure distribution (taken along the chord near the kink) match, see attached Figure. I am attaching the dummy configuration file (dum.txt) as well as the mesh (dum_mesh.txt) if it can be of interest to you. The mesh is a .geo gmsh file. To get the mesh, simply open with gmsh and click mesh 3D (or, from the console: gmsh dum_mesh.txt -3). At this point, I think that my problem might be related to the actual wing airfoil geometry, which is somehow not well pre-processed by SU2... I will continue investigating and keep you posted if I find a solution. Thank you for the time you took reading this issue.; ![cp](https://user-images.githubusercontent.com/39187559/40602255-3de183ae-6258-11e8-9aba-6c8d374dc34e.png); [dum.txt](https://github.com/su2code/SU2/files/2044072/dum.txt); [dum_mesh.txt](https://github.com/su2code/SU2/files/2044073/dum_mesh.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-392442127
https://github.com/su2code/SU2/issues/533#issuecomment-392442127:1284,Usability,simpl,simply,1284,"Hi there,. I went ahead and created a dummy geometry, that is:; 1. I altered the planform so that the sweep, twist, dihedral, taper... are now different from the actual wing; 2. I replaced the airfoil by the NASA SC(2)-0712. The dummy wing has a double planform defined as:; - semi span = [5; 10]; - taper = [0.55; 0.35]; - dihedral angle = [5; 2.5]; - twist angle = [1; 0; -1] (given for root, kink and tip airfoil sections); - sweep angle at LE = 25; - Aspect ratio = 11.8; - semi area = 38. I defined the reference length as:; - reference (semi) area = 45; - reference chord = 3; - reference (semi) span = 15. The flight conditions remained unchanged:; - Mach number: 0.78; - Temperature = ~217 K; - Reynolds number: ~19 millions; - AoA = 0. I created the exact same grid as before (same number of cells, same progression), ensuring my first cell was at y+<1. Things is, this time, SU2 did not have any trouble converging and computed the right z-projected area... I checked the results with another software and the pressure distribution (taken along the chord near the kink) match, see attached Figure. I am attaching the dummy configuration file (dum.txt) as well as the mesh (dum_mesh.txt) if it can be of interest to you. The mesh is a .geo gmsh file. To get the mesh, simply open with gmsh and click mesh 3D (or, from the console: gmsh dum_mesh.txt -3). At this point, I think that my problem might be related to the actual wing airfoil geometry, which is somehow not well pre-processed by SU2... I will continue investigating and keep you posted if I find a solution. Thank you for the time you took reading this issue.; ![cp](https://user-images.githubusercontent.com/39187559/40602255-3de183ae-6258-11e8-9aba-6c8d374dc34e.png); [dum.txt](https://github.com/su2code/SU2/files/2044072/dum.txt); [dum_mesh.txt](https://github.com/su2code/SU2/files/2044073/dum_mesh.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-392442127
https://github.com/su2code/SU2/issues/533#issuecomment-406973884:68,Availability,down,down,68,"Dear SU2 users,. I continued the investigation and managed to track down the source of the problem.; The issues I face with SU2 appear when my wing geometry has several airfoils across the span. I ran several cases with supercritical airfoils and NACA 4 digits airfoils. As soon as the airfoil was changing along the span, SU2 had troubles computing the projected and wetted area of the wing, an attaining a correct solution. To better illustrate the issue, I attached a SU2 .cfg file (dummy.txt) and Gmsh .geo file (dummy_mesh.txt) to this post.; The geometry is the same as in the previous post except that I used 3 different airfoils along the span. That is, I replaced the NASA SC(2)-0712 by the {NASA SC(2)-0714, NASA SC(2)-0712, NASA SC(3)-0712}.; These airfoils are similar, so I expected to recover similar results. However, I observed that:; - SU2 computed the wrong z-projected area : 23.1 m^2 instead of 38 m^2,; - the y+ of the first cell is way too high in certain regions (see attached image, grey zones are the area where y+<1),; - the Cp distribution if not looking good (makes sense with those values of y+), see attached file. I am unsure if the problem appears because Gmsh has trouble in generating this kind of mesh or because SU2 has trouble reading it. Any ideas are welcome. Thank you again,; Adrien. ![cp](https://user-images.githubusercontent.com/39187559/43064280-c076a5e2-8e5e-11e8-84e5-602d1ee27ea2.png); ![y](https://user-images.githubusercontent.com/39187559/43064281-c09a1f86-8e5e-11e8-82b9-4c4fddc7d470.png); [dummy_mesh.txt](https://github.com/su2code/SU2/files/2218394/dummy_mesh.txt); [dummy.txt](https://github.com/su2code/SU2/files/2218395/dummy.txt); [log.txt](https://github.com/su2code/SU2/files/2218411/log.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-406973884
https://github.com/su2code/SU2/issues/533#issuecomment-406973884:799,Availability,recover,recover,799,"Dear SU2 users,. I continued the investigation and managed to track down the source of the problem.; The issues I face with SU2 appear when my wing geometry has several airfoils across the span. I ran several cases with supercritical airfoils and NACA 4 digits airfoils. As soon as the airfoil was changing along the span, SU2 had troubles computing the projected and wetted area of the wing, an attaining a correct solution. To better illustrate the issue, I attached a SU2 .cfg file (dummy.txt) and Gmsh .geo file (dummy_mesh.txt) to this post.; The geometry is the same as in the previous post except that I used 3 different airfoils along the span. That is, I replaced the NASA SC(2)-0712 by the {NASA SC(2)-0714, NASA SC(2)-0712, NASA SC(3)-0712}.; These airfoils are similar, so I expected to recover similar results. However, I observed that:; - SU2 computed the wrong z-projected area : 23.1 m^2 instead of 38 m^2,; - the y+ of the first cell is way too high in certain regions (see attached image, grey zones are the area where y+<1),; - the Cp distribution if not looking good (makes sense with those values of y+), see attached file. I am unsure if the problem appears because Gmsh has trouble in generating this kind of mesh or because SU2 has trouble reading it. Any ideas are welcome. Thank you again,; Adrien. ![cp](https://user-images.githubusercontent.com/39187559/43064280-c076a5e2-8e5e-11e8-84e5-602d1ee27ea2.png); ![y](https://user-images.githubusercontent.com/39187559/43064281-c09a1f86-8e5e-11e8-82b9-4c4fddc7d470.png); [dummy_mesh.txt](https://github.com/su2code/SU2/files/2218394/dummy_mesh.txt); [dummy.txt](https://github.com/su2code/SU2/files/2218395/dummy.txt); [log.txt](https://github.com/su2code/SU2/files/2218411/log.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-406973884
https://github.com/su2code/SU2/issues/533#issuecomment-406973884:799,Safety,recover,recover,799,"Dear SU2 users,. I continued the investigation and managed to track down the source of the problem.; The issues I face with SU2 appear when my wing geometry has several airfoils across the span. I ran several cases with supercritical airfoils and NACA 4 digits airfoils. As soon as the airfoil was changing along the span, SU2 had troubles computing the projected and wetted area of the wing, an attaining a correct solution. To better illustrate the issue, I attached a SU2 .cfg file (dummy.txt) and Gmsh .geo file (dummy_mesh.txt) to this post.; The geometry is the same as in the previous post except that I used 3 different airfoils along the span. That is, I replaced the NASA SC(2)-0712 by the {NASA SC(2)-0714, NASA SC(2)-0712, NASA SC(3)-0712}.; These airfoils are similar, so I expected to recover similar results. However, I observed that:; - SU2 computed the wrong z-projected area : 23.1 m^2 instead of 38 m^2,; - the y+ of the first cell is way too high in certain regions (see attached image, grey zones are the area where y+<1),; - the Cp distribution if not looking good (makes sense with those values of y+), see attached file. I am unsure if the problem appears because Gmsh has trouble in generating this kind of mesh or because SU2 has trouble reading it. Any ideas are welcome. Thank you again,; Adrien. ![cp](https://user-images.githubusercontent.com/39187559/43064280-c076a5e2-8e5e-11e8-84e5-602d1ee27ea2.png); ![y](https://user-images.githubusercontent.com/39187559/43064281-c09a1f86-8e5e-11e8-82b9-4c4fddc7d470.png); [dummy_mesh.txt](https://github.com/su2code/SU2/files/2218394/dummy_mesh.txt); [dummy.txt](https://github.com/su2code/SU2/files/2218395/dummy.txt); [log.txt](https://github.com/su2code/SU2/files/2218411/log.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-406973884
https://github.com/su2code/SU2/issues/533#issuecomment-406973884:1691,Testability,log,log,1691,"Dear SU2 users,. I continued the investigation and managed to track down the source of the problem.; The issues I face with SU2 appear when my wing geometry has several airfoils across the span. I ran several cases with supercritical airfoils and NACA 4 digits airfoils. As soon as the airfoil was changing along the span, SU2 had troubles computing the projected and wetted area of the wing, an attaining a correct solution. To better illustrate the issue, I attached a SU2 .cfg file (dummy.txt) and Gmsh .geo file (dummy_mesh.txt) to this post.; The geometry is the same as in the previous post except that I used 3 different airfoils along the span. That is, I replaced the NASA SC(2)-0712 by the {NASA SC(2)-0714, NASA SC(2)-0712, NASA SC(3)-0712}.; These airfoils are similar, so I expected to recover similar results. However, I observed that:; - SU2 computed the wrong z-projected area : 23.1 m^2 instead of 38 m^2,; - the y+ of the first cell is way too high in certain regions (see attached image, grey zones are the area where y+<1),; - the Cp distribution if not looking good (makes sense with those values of y+), see attached file. I am unsure if the problem appears because Gmsh has trouble in generating this kind of mesh or because SU2 has trouble reading it. Any ideas are welcome. Thank you again,; Adrien. ![cp](https://user-images.githubusercontent.com/39187559/43064280-c076a5e2-8e5e-11e8-84e5-602d1ee27ea2.png); ![y](https://user-images.githubusercontent.com/39187559/43064281-c09a1f86-8e5e-11e8-82b9-4c4fddc7d470.png); [dummy_mesh.txt](https://github.com/su2code/SU2/files/2218394/dummy_mesh.txt); [dummy.txt](https://github.com/su2code/SU2/files/2218395/dummy.txt); [log.txt](https://github.com/su2code/SU2/files/2218411/log.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-406973884
https://github.com/su2code/SU2/issues/533#issuecomment-406973884:1745,Testability,log,log,1745,"Dear SU2 users,. I continued the investigation and managed to track down the source of the problem.; The issues I face with SU2 appear when my wing geometry has several airfoils across the span. I ran several cases with supercritical airfoils and NACA 4 digits airfoils. As soon as the airfoil was changing along the span, SU2 had troubles computing the projected and wetted area of the wing, an attaining a correct solution. To better illustrate the issue, I attached a SU2 .cfg file (dummy.txt) and Gmsh .geo file (dummy_mesh.txt) to this post.; The geometry is the same as in the previous post except that I used 3 different airfoils along the span. That is, I replaced the NASA SC(2)-0712 by the {NASA SC(2)-0714, NASA SC(2)-0712, NASA SC(3)-0712}.; These airfoils are similar, so I expected to recover similar results. However, I observed that:; - SU2 computed the wrong z-projected area : 23.1 m^2 instead of 38 m^2,; - the y+ of the first cell is way too high in certain regions (see attached image, grey zones are the area where y+<1),; - the Cp distribution if not looking good (makes sense with those values of y+), see attached file. I am unsure if the problem appears because Gmsh has trouble in generating this kind of mesh or because SU2 has trouble reading it. Any ideas are welcome. Thank you again,; Adrien. ![cp](https://user-images.githubusercontent.com/39187559/43064280-c076a5e2-8e5e-11e8-84e5-602d1ee27ea2.png); ![y](https://user-images.githubusercontent.com/39187559/43064281-c09a1f86-8e5e-11e8-82b9-4c4fddc7d470.png); [dummy_mesh.txt](https://github.com/su2code/SU2/files/2218394/dummy_mesh.txt); [dummy.txt](https://github.com/su2code/SU2/files/2218395/dummy.txt); [log.txt](https://github.com/su2code/SU2/files/2218411/log.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/533#issuecomment-406973884
https://github.com/su2code/SU2/pull/535#issuecomment-398221400:68,Deployability,release,released,68,Thanks for the reviews. Time to merge this one. . Tutorials will be released w/ v6.1 after some final edits. Some are already posted but hidden :). Here's a teaser: https://su2code.github.io/tutorials/Inc_Laminar_Step/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/535#issuecomment-398221400
https://github.com/su2code/SU2/issues/536#issuecomment-410355128:68,Availability,avail,available,68,"Preliminary agenda for the 3rd Annual SU2 Developers Meeting is now available, including hackathon format! More details on speakers to come. Check out the link from our main page: https://su2code.github.io . Keep registering and do let us know on the form if you would like to present your work!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/536#issuecomment-410355128
https://github.com/su2code/SU2/issues/537#issuecomment-392326756:45,Availability,avail,available,45,"Hi @sysu-tanlang . The average option is not available in SU2v6.0 yet. At this moment, I am working on that and soon I will submit a PR. Best. Eduardo.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/537#issuecomment-392326756
https://github.com/su2code/SU2/issues/537#issuecomment-548010843:8,Availability,avail,available,8,Will be available in version 7.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/537#issuecomment-548010843
https://github.com/su2code/SU2/pull/538#issuecomment-447083061:28,Deployability,update,updates,28,@VivaanKhatri : any news or updates to this PR? It has been sitting for some time.. looks to be a useful contribution and shares some options/keywords with #621 (hopefully not too conflicting).,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/538#issuecomment-447083061
https://github.com/su2code/SU2/issues/539#issuecomment-394713953:21,Availability,error,error,21,"Dear Reza,. like the error message already implies, currently the python wrapper does not support the AD features. It is on our list, but I cannot give an estimate when it will be available. Tim. Am 04.06.2018 13:46 schrieb najianaslreza <notifications@github.com>:. Dear all,. I am trying to use the python wrapper with AD tool support. For example I want to use CDiscAdjFluidDriver(options.filename, 1, 3, comm) but it fail and returns there is no AD support for python wrapper. Do you know how I can solve it ?!. Cheers,. reza. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/539>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5NEuzJBRfwFu5CqxXFdbh_6GY0Iyks5t5R3rgaJpZM4UY7-o>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/539#issuecomment-394713953
https://github.com/su2code/SU2/issues/539#issuecomment-394713953:180,Availability,avail,available,180,"Dear Reza,. like the error message already implies, currently the python wrapper does not support the AD features. It is on our list, but I cannot give an estimate when it will be available. Tim. Am 04.06.2018 13:46 schrieb najianaslreza <notifications@github.com>:. Dear all,. I am trying to use the python wrapper with AD tool support. For example I want to use CDiscAdjFluidDriver(options.filename, 1, 3, comm) but it fail and returns there is no AD support for python wrapper. Do you know how I can solve it ?!. Cheers,. reza. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/539>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5NEuzJBRfwFu5CqxXFdbh_6GY0Iyks5t5R3rgaJpZM4UY7-o>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/539#issuecomment-394713953
https://github.com/su2code/SU2/issues/539#issuecomment-394713953:27,Integrability,message,message,27,"Dear Reza,. like the error message already implies, currently the python wrapper does not support the AD features. It is on our list, but I cannot give an estimate when it will be available. Tim. Am 04.06.2018 13:46 schrieb najianaslreza <notifications@github.com>:. Dear all,. I am trying to use the python wrapper with AD tool support. For example I want to use CDiscAdjFluidDriver(options.filename, 1, 3, comm) but it fail and returns there is no AD support for python wrapper. Do you know how I can solve it ?!. Cheers,. reza. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/539>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5NEuzJBRfwFu5CqxXFdbh_6GY0Iyks5t5R3rgaJpZM4UY7-o>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/539#issuecomment-394713953
https://github.com/su2code/SU2/issues/539#issuecomment-394713953:73,Integrability,wrap,wrapper,73,"Dear Reza,. like the error message already implies, currently the python wrapper does not support the AD features. It is on our list, but I cannot give an estimate when it will be available. Tim. Am 04.06.2018 13:46 schrieb najianaslreza <notifications@github.com>:. Dear all,. I am trying to use the python wrapper with AD tool support. For example I want to use CDiscAdjFluidDriver(options.filename, 1, 3, comm) but it fail and returns there is no AD support for python wrapper. Do you know how I can solve it ?!. Cheers,. reza. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/539>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5NEuzJBRfwFu5CqxXFdbh_6GY0Iyks5t5R3rgaJpZM4UY7-o>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/539#issuecomment-394713953
https://github.com/su2code/SU2/issues/539#issuecomment-394713953:308,Integrability,wrap,wrapper,308,"Dear Reza,. like the error message already implies, currently the python wrapper does not support the AD features. It is on our list, but I cannot give an estimate when it will be available. Tim. Am 04.06.2018 13:46 schrieb najianaslreza <notifications@github.com>:. Dear all,. I am trying to use the python wrapper with AD tool support. For example I want to use CDiscAdjFluidDriver(options.filename, 1, 3, comm) but it fail and returns there is no AD support for python wrapper. Do you know how I can solve it ?!. Cheers,. reza. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/539>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5NEuzJBRfwFu5CqxXFdbh_6GY0Iyks5t5R3rgaJpZM4UY7-o>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/539#issuecomment-394713953
https://github.com/su2code/SU2/issues/539#issuecomment-394713953:472,Integrability,wrap,wrapper,472,"Dear Reza,. like the error message already implies, currently the python wrapper does not support the AD features. It is on our list, but I cannot give an estimate when it will be available. Tim. Am 04.06.2018 13:46 schrieb najianaslreza <notifications@github.com>:. Dear all,. I am trying to use the python wrapper with AD tool support. For example I want to use CDiscAdjFluidDriver(options.filename, 1, 3, comm) but it fail and returns there is no AD support for python wrapper. Do you know how I can solve it ?!. Cheers,. reza. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/539>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AEtI5NEuzJBRfwFu5CqxXFdbh_6GY0Iyks5t5R3rgaJpZM4UY7-o>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/539#issuecomment-394713953
https://github.com/su2code/SU2/pull/540#issuecomment-398471952:116,Deployability,release,release,116,"Let's close up v6.1 with this PR. I'll push to master now, so we can move on to PRs #528 and #530. We'll officially release in the next few days.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/540#issuecomment-398471952
https://github.com/su2code/SU2/pull/543#issuecomment-413024928:395,Performance,perform,performance,395,"1. & 2. I believe I have addressed these comments in my subsequent commits. ; 3. I will need some time to look into this, but it would be orthogonal to what was done in this work.; 4. This is a trivial change, and I'll be happy to make it when single precision support is added. The JIT features support both single and double precision.; 5. Could you suggest a RANS case for me to run to check performance?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/543#issuecomment-413024928
https://github.com/su2code/SU2/pull/543#issuecomment-416828129:4,Modifiability,config,configure,4,"The configure looks good to me now. Did you do the test for the viscous ONERA M6? It would be good to know what the speed up is here. Anyway, if you can merge with the latest develop version, it can be merged in as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/543#issuecomment-416828129
https://github.com/su2code/SU2/pull/543#issuecomment-416828129:51,Testability,test,test,51,"The configure looks good to me now. Did you do the test for the viscous ONERA M6? It would be good to know what the speed up is here. Anyway, if you can merge with the latest develop version, it can be merged in as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/543#issuecomment-416828129
https://github.com/su2code/SU2/pull/543#issuecomment-416955089:67,Modifiability,config,config,67,"I did run the viscous ONERA M6 case. The speed up with the default config was marginal (2-3%). I also tried with multigrid enabled, in which case the MKL version was 10% faster. Overall the bottlenecks for the rans case were different than the inviscid onera case. I'll look at what can be done here next.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/543#issuecomment-416955089
https://github.com/su2code/SU2/pull/543#issuecomment-416955089:190,Performance,bottleneck,bottlenecks,190,"I did run the viscous ONERA M6 case. The speed up with the default config was marginal (2-3%). I also tried with multigrid enabled, in which case the MKL version was 10% faster. Overall the bottlenecks for the rans case were different than the inviscid onera case. I'll look at what can be done here next.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/543#issuecomment-416955089
https://github.com/su2code/SU2/issues/545#issuecomment-400878975:98,Availability,failure,failure,98,"alexfeld; Thanks for your support in the compute_polar.; However, I don't manage to reproduce the failure that you have described. I have run a case; where the cfg file containes no MARKER_DESIGNING definition. Consequently, both ; config_CFD.cfg and config_SOL.cfg had no definition of that marker but nothing failed.; Could you share with me you cfg file so that I will be able to reproduce the error that you; have encountered?; BTW, I havn' t updated yet to 6.1.0 (I'm in 6.0.1). May this be the reason for the different behavior?; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/545#issuecomment-400878975
https://github.com/su2code/SU2/issues/545#issuecomment-400878975:397,Availability,error,error,397,"alexfeld; Thanks for your support in the compute_polar.; However, I don't manage to reproduce the failure that you have described. I have run a case; where the cfg file containes no MARKER_DESIGNING definition. Consequently, both ; config_CFD.cfg and config_SOL.cfg had no definition of that marker but nothing failed.; Could you share with me you cfg file so that I will be able to reproduce the error that you; have encountered?; BTW, I havn' t updated yet to 6.1.0 (I'm in 6.0.1). May this be the reason for the different behavior?; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/545#issuecomment-400878975
https://github.com/su2code/SU2/issues/545#issuecomment-400878975:447,Deployability,update,updated,447,"alexfeld; Thanks for your support in the compute_polar.; However, I don't manage to reproduce the failure that you have described. I have run a case; where the cfg file containes no MARKER_DESIGNING definition. Consequently, both ; config_CFD.cfg and config_SOL.cfg had no definition of that marker but nothing failed.; Could you share with me you cfg file so that I will be able to reproduce the error that you; have encountered?; BTW, I havn' t updated yet to 6.1.0 (I'm in 6.0.1). May this be the reason for the different behavior?; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/545#issuecomment-400878975
https://github.com/su2code/SU2/issues/545#issuecomment-402270185:182,Testability,test,test,182,"My apologies for the long delay. I did notice this bug after updating to the latest version. Using the following files and the `euler/oneram6/mesh_ONERAM6_inv_ffd.su2` mesh from the test cases: . [run_polar_template.sh.txt](https://github.com/su2code/SU2/files/2160777/run_polar_template.sh.txt); [polarCtrl.in.txt](https://github.com/su2code/SU2/files/2160761/polarCtrl.in.txt); [base_cfg.cfg.txt](https://github.com/su2code/SU2/files/2160762/base_cfg.cfg.txt). With the current version of `compute_polar.py`, if lines 285 on are comment in `base_cfg.cfg` then the script will fail. Adding the fix I describe above solves the issue. Further issues: the moment outputs in lines 458 and 459 are inconsistent with the headers defined in line 332. The ordering of the `z` and `y` moment are reversed. Also, the `x` moment is currently assigned to the `z` moment in the result structure in line 443.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/545#issuecomment-402270185
https://github.com/su2code/SU2/issues/549#issuecomment-402924930:9,Deployability,update,update,9,"Hi,. Any update on this. Need suggestion urgently. Thanks.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/549#issuecomment-402924930
https://github.com/su2code/SU2/issues/549#issuecomment-402973171:112,Modifiability,config,configure-file,112,"This issue has already been dealt with in the forum, ; https://www.cfd-online.com/Forums/su2/203777-unable-find-configure-file.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/549#issuecomment-402973171
https://github.com/su2code/SU2/issues/550#issuecomment-403600179:218,Integrability,rout,routines,218,"@clarkpede : Thank you for the detailed post, and your hunch is likely correct. Unfortunately, the existing periodic BC implementation has some limitations due to how closely it is coupled to the old mesh partitioning routines during setup. Those original partitioning routines had become difficult to maintain or expand (very hard to make quick fixes), so they were rewritten from scratch in PR #513. Now, the periodic BC is also being rewritten cleanly (hopefully for the last time :) ). A prototype can be seen in feature_periodic that is already working for Euler problems, and the rest is in progress now. I am aware that several folks are in need of this, but know that a new version is coming.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/550#issuecomment-403600179
https://github.com/su2code/SU2/issues/550#issuecomment-403600179:269,Integrability,rout,routines,269,"@clarkpede : Thank you for the detailed post, and your hunch is likely correct. Unfortunately, the existing periodic BC implementation has some limitations due to how closely it is coupled to the old mesh partitioning routines during setup. Those original partitioning routines had become difficult to maintain or expand (very hard to make quick fixes), so they were rewritten from scratch in PR #513. Now, the periodic BC is also being rewritten cleanly (hopefully for the last time :) ). A prototype can be seen in feature_periodic that is already working for Euler problems, and the rest is in progress now. I am aware that several folks are in need of this, but know that a new version is coming.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/550#issuecomment-403600179
https://github.com/su2code/SU2/issues/550#issuecomment-403697837:24,Deployability,update,update,24,Alright. Thanks for the update. I'll wait to close this issue until the periodic BCs are fixed.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/550#issuecomment-403697837
https://github.com/su2code/SU2/issues/551#issuecomment-404888496:158,Deployability,install,install,158,"If I understand, you're calling `swig` manually? The typical way to set up the python wrapper is to use the typical build process (i.e. configure, make, make install) but to include the flag `--enable-PY_WRAPPER` during the configure step. The build process will automatically call `swig` for you, with the correct arguments. See the docs for more information: https://su2code.github.io/docs/Python-Wrapper-Build/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404888496
https://github.com/su2code/SU2/issues/551#issuecomment-404888496:86,Integrability,wrap,wrapper,86,"If I understand, you're calling `swig` manually? The typical way to set up the python wrapper is to use the typical build process (i.e. configure, make, make install) but to include the flag `--enable-PY_WRAPPER` during the configure step. The build process will automatically call `swig` for you, with the correct arguments. See the docs for more information: https://su2code.github.io/docs/Python-Wrapper-Build/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404888496
https://github.com/su2code/SU2/issues/551#issuecomment-404888496:399,Integrability,Wrap,Wrapper-Build,399,"If I understand, you're calling `swig` manually? The typical way to set up the python wrapper is to use the typical build process (i.e. configure, make, make install) but to include the flag `--enable-PY_WRAPPER` during the configure step. The build process will automatically call `swig` for you, with the correct arguments. See the docs for more information: https://su2code.github.io/docs/Python-Wrapper-Build/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404888496
https://github.com/su2code/SU2/issues/551#issuecomment-404888496:136,Modifiability,config,configure,136,"If I understand, you're calling `swig` manually? The typical way to set up the python wrapper is to use the typical build process (i.e. configure, make, make install) but to include the flag `--enable-PY_WRAPPER` during the configure step. The build process will automatically call `swig` for you, with the correct arguments. See the docs for more information: https://su2code.github.io/docs/Python-Wrapper-Build/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404888496
https://github.com/su2code/SU2/issues/551#issuecomment-404888496:224,Modifiability,config,configure,224,"If I understand, you're calling `swig` manually? The typical way to set up the python wrapper is to use the typical build process (i.e. configure, make, make install) but to include the flag `--enable-PY_WRAPPER` during the configure step. The build process will automatically call `swig` for you, with the correct arguments. See the docs for more information: https://su2code.github.io/docs/Python-Wrapper-Build/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404888496
https://github.com/su2code/SU2/issues/551#issuecomment-404905415:425,Modifiability,variab,variables,425,"No, your assumption of calling `swig` manually is not the cause why I've opened this issue (though, admittedly, ""compile SU2 in `$SU2_HOME` first""  for getting the required libraries done  might sound confusing). Trying to be utterly relevant, I only replicated that part of the compilation process (yes, would-be with `--enable-PY_WRAPPER`) where one can explicitly debug the issue (please, have a look at the environment variables substituted by the `configure` script after `#` or post your `objdump -p _pysu2.so`, and/or `nm -u _pysu2.so` as also from the `config.log`/`Makefile` your `CXX`, `pySU2_CC_FLAGS`, `PY_INCLUDE`, `SO_LINK_FLAGS`, `SWIG_SO_REAL`, `SWIG_WRAP_REAL`, and `pySU2_LD_FLAGS` to compare the correct arguments). The docs had been definitely read before opening the issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404905415
https://github.com/su2code/SU2/issues/551#issuecomment-404905415:455,Modifiability,config,configure,455,"No, your assumption of calling `swig` manually is not the cause why I've opened this issue (though, admittedly, ""compile SU2 in `$SU2_HOME` first""  for getting the required libraries done  might sound confusing). Trying to be utterly relevant, I only replicated that part of the compilation process (yes, would-be with `--enable-PY_WRAPPER`) where one can explicitly debug the issue (please, have a look at the environment variables substituted by the `configure` script after `#` or post your `objdump -p _pysu2.so`, and/or `nm -u _pysu2.so` as also from the `config.log`/`Makefile` your `CXX`, `pySU2_CC_FLAGS`, `PY_INCLUDE`, `SO_LINK_FLAGS`, `SWIG_SO_REAL`, `SWIG_WRAP_REAL`, and `pySU2_LD_FLAGS` to compare the correct arguments). The docs had been definitely read before opening the issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404905415
https://github.com/su2code/SU2/issues/551#issuecomment-404905415:563,Modifiability,config,config,563,"No, your assumption of calling `swig` manually is not the cause why I've opened this issue (though, admittedly, ""compile SU2 in `$SU2_HOME` first""  for getting the required libraries done  might sound confusing). Trying to be utterly relevant, I only replicated that part of the compilation process (yes, would-be with `--enable-PY_WRAPPER`) where one can explicitly debug the issue (please, have a look at the environment variables substituted by the `configure` script after `#` or post your `objdump -p _pysu2.so`, and/or `nm -u _pysu2.so` as also from the `config.log`/`Makefile` your `CXX`, `pySU2_CC_FLAGS`, `PY_INCLUDE`, `SO_LINK_FLAGS`, `SWIG_SO_REAL`, `SWIG_WRAP_REAL`, and `pySU2_LD_FLAGS` to compare the correct arguments). The docs had been definitely read before opening the issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404905415
https://github.com/su2code/SU2/issues/551#issuecomment-404905415:570,Testability,log,log,570,"No, your assumption of calling `swig` manually is not the cause why I've opened this issue (though, admittedly, ""compile SU2 in `$SU2_HOME` first""  for getting the required libraries done  might sound confusing). Trying to be utterly relevant, I only replicated that part of the compilation process (yes, would-be with `--enable-PY_WRAPPER`) where one can explicitly debug the issue (please, have a look at the environment variables substituted by the `configure` script after `#` or post your `objdump -p _pysu2.so`, and/or `nm -u _pysu2.so` as also from the `config.log`/`Makefile` your `CXX`, `pySU2_CC_FLAGS`, `PY_INCLUDE`, `SO_LINK_FLAGS`, `SWIG_SO_REAL`, `SWIG_WRAP_REAL`, and `pySU2_LD_FLAGS` to compare the correct arguments). The docs had been definitely read before opening the issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404905415
https://github.com/su2code/SU2/issues/551#issuecomment-404937979:25,Availability,error,error,25,"Ok. I can duplicate your error on my system. The error seems to be specific to gcc 8.1. If I switch to gcc 7.2 while keeping everything else the same, the errors disappear and the build completes succesfully. Unfortunately, I'm not one of the developers who helped write the wrapper. So I'm out of my depth here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404937979
https://github.com/su2code/SU2/issues/551#issuecomment-404937979:49,Availability,error,error,49,"Ok. I can duplicate your error on my system. The error seems to be specific to gcc 8.1. If I switch to gcc 7.2 while keeping everything else the same, the errors disappear and the build completes succesfully. Unfortunately, I'm not one of the developers who helped write the wrapper. So I'm out of my depth here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404937979
https://github.com/su2code/SU2/issues/551#issuecomment-404937979:155,Availability,error,errors,155,"Ok. I can duplicate your error on my system. The error seems to be specific to gcc 8.1. If I switch to gcc 7.2 while keeping everything else the same, the errors disappear and the build completes succesfully. Unfortunately, I'm not one of the developers who helped write the wrapper. So I'm out of my depth here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404937979
https://github.com/su2code/SU2/issues/551#issuecomment-404937979:275,Integrability,wrap,wrapper,275,"Ok. I can duplicate your error on my system. The error seems to be specific to gcc 8.1. If I switch to gcc 7.2 while keeping everything else the same, the errors disappear and the build completes succesfully. Unfortunately, I'm not one of the developers who helped write the wrapper. So I'm out of my depth here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-404937979
https://github.com/su2code/SU2/issues/551#issuecomment-405023863:473,Availability,error,errors,473,"Following your suggestion I've tried to prepend the compiler with `OMPI_MPICXX=g++-7` to force `mpicxx` using  in the present particular case  `g++-7 (Ubuntu 7.3.0-16ubuntu3) 7.3.0`. Unfortunately. there was no change in the output comparing to that of `gcc-8`. Moreover, neither `clang++ version 7.0.0 (trunk)` resolved the issue, though adding/playing with `-std=gnu++11`, `-std=gnu++14`, `-std=gnu++17`, and `-std=gnu++2a` standards gave more warnings as well as same errors. Anyway, I appreciated your hint at possible `gcc` incompatibilities. It appears the python wrapper has been broken already for some time  without, actually, anybody truly reporting it. It needs some love for sure, so, there is a call for it. Meanwhile if you could share your `_pysu2.so` somewhere it would be greatly appreciated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-405023863
https://github.com/su2code/SU2/issues/551#issuecomment-405023863:572,Integrability,wrap,wrapper,572,"Following your suggestion I've tried to prepend the compiler with `OMPI_MPICXX=g++-7` to force `mpicxx` using  in the present particular case  `g++-7 (Ubuntu 7.3.0-16ubuntu3) 7.3.0`. Unfortunately. there was no change in the output comparing to that of `gcc-8`. Moreover, neither `clang++ version 7.0.0 (trunk)` resolved the issue, though adding/playing with `-std=gnu++11`, `-std=gnu++14`, `-std=gnu++17`, and `-std=gnu++2a` standards gave more warnings as well as same errors. Anyway, I appreciated your hint at possible `gcc` incompatibilities. It appears the python wrapper has been broken already for some time  without, actually, anybody truly reporting it. It needs some love for sure, so, there is a call for it. Meanwhile if you could share your `_pysu2.so` somewhere it would be greatly appreciated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-405023863
https://github.com/su2code/SU2/issues/551#issuecomment-418307677:285,Integrability,wrap,wrapper,285,"I've managed to compile the `_pysu2.so`, indeed, with the typical build process. Fiddling further with manual `swig` a bit, I narrowed where it produces the wrong output: in generating `SU2_APIPYTHON_wrap.cxx`. So, I preserved one made during the build, and then even got the Python 3 wrapper version by running `swig` with the `-py3` key. Both imports are going fine, so, I'm closing the issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/551#issuecomment-418307677
https://github.com/su2code/SU2/pull/552#issuecomment-403806479:1646,Deployability,upgrade,upgrades,1646,"### Code Verification. I used a case similar to the one detailed in references [1] and [2], with a circular cylinder in high Re flow. It's a circular cylinder with a von-Karman vortex street. There's a couple reasons to not expect exact replication of their results. They used higher-order numerics (5th/3rd), a longer grid in the spanwise direction, structured overset grids, and an SST variant of DES. Here's a figure from reference [2]:. ![travinresults](https://user-images.githubusercontent.com/13340225/42509822-bc677aea-8412-11e8-8285-6e51895258b4.png); ; And here's the results of my rough test:. ![roe_dissipation](https://user-images.githubusercontent.com/13340225/42510382-54f3b516-8414-11e8-9be4-07aafdd2468a.png). As you can see, the central/upwind blending function is doing what it's supposed to do. It's going to 0 in regions with both high vorticity and a fine grid, but goes to 1 in the near-wall RANS regions and in the outer region of the flow. There are a few artifacts around the cylinder, where the grid is fine but the eddy viscosity is still low. I'm talking about the few spots you see around the cylinder. There is a relatively high vorticity there, and the grid is fine, so the values make sense. It's hard to tell if this is due to imperfections in the grid, imperfections in the code implementation, or imperfections in the NTS model itself. ### References. 1. A. Travin, M. Shur, M. Strelets, P. Spalart, Detached-Eddy Simulations Past a Circular Cylinder, Flow Turbul. Combust. 63 (1999) 293313. doi:10.1023/A:1009901401183.; 2. A. Travin, M.L.Shur, M.K. Strelets, P.R. Spalart, M.L. Shur, Physical and numerical upgrades in the detached-eddy simulation of complex turbulent flows, Adv. LES Complex Flows Proc. Euromech Colloq. 412. (2002) 239254. doi:10.1007/0-306-48383-1_16.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403806479
https://github.com/su2code/SU2/pull/552#issuecomment-403806479:598,Testability,test,test,598,"### Code Verification. I used a case similar to the one detailed in references [1] and [2], with a circular cylinder in high Re flow. It's a circular cylinder with a von-Karman vortex street. There's a couple reasons to not expect exact replication of their results. They used higher-order numerics (5th/3rd), a longer grid in the spanwise direction, structured overset grids, and an SST variant of DES. Here's a figure from reference [2]:. ![travinresults](https://user-images.githubusercontent.com/13340225/42509822-bc677aea-8412-11e8-8285-6e51895258b4.png); ; And here's the results of my rough test:. ![roe_dissipation](https://user-images.githubusercontent.com/13340225/42510382-54f3b516-8414-11e8-9be4-07aafdd2468a.png). As you can see, the central/upwind blending function is doing what it's supposed to do. It's going to 0 in regions with both high vorticity and a fine grid, but goes to 1 in the near-wall RANS regions and in the outer region of the flow. There are a few artifacts around the cylinder, where the grid is fine but the eddy viscosity is still low. I'm talking about the few spots you see around the cylinder. There is a relatively high vorticity there, and the grid is fine, so the values make sense. It's hard to tell if this is due to imperfections in the grid, imperfections in the code implementation, or imperfections in the NTS model itself. ### References. 1. A. Travin, M. Shur, M. Strelets, P. Spalart, Detached-Eddy Simulations Past a Circular Cylinder, Flow Turbul. Combust. 63 (1999) 293313. doi:10.1023/A:1009901401183.; 2. A. Travin, M.L.Shur, M.K. Strelets, P.R. Spalart, M.L. Shur, Physical and numerical upgrades in the detached-eddy simulation of complex turbulent flows, Adv. LES Complex Flows Proc. Euromech Colloq. 412. (2002) 239254. doi:10.1007/0-306-48383-1_16.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403806479
https://github.com/su2code/SU2/pull/552#issuecomment-403842613:546,Energy Efficiency,reduce,reduces,546,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
https://github.com/su2code/SU2/pull/552#issuecomment-403842613:430,Integrability,depend,dependent,430,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
https://github.com/su2code/SU2/pull/552#issuecomment-403842613:878,Testability,Mock,Mockett,878,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
https://github.com/su2code/SU2/pull/552#issuecomment-403842613:1128,Testability,test,tests,1128,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
https://github.com/su2code/SU2/pull/552#issuecomment-403842613:1209,Testability,test,test,1209,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
https://github.com/su2code/SU2/pull/552#issuecomment-403842613:1422,Testability,test,test,1422,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
https://github.com/su2code/SU2/pull/552#issuecomment-403842613:44,Usability,clear,clear,44,"Thanks, @clarkpede, for this PR and for the clear explanation of the features proposed. LGTM in terms of implementation and code style. I'll just wait for @EduardoMolina to comment on the contents. I only have a couple of minor questions:. > I moved the calculation of the maximum cell width to the CPhysicalGeometry class. This makes inclusion in the central/upwind blending easier. For DES and DDES, the cell lengthscale is not dependent on the flow. So there's no need to compute it every iteration in the flow solver. I can see this approach reduces the computational cost of computing the MaxLength every time at the cost of having one more double in memory per point. However, would a call to SetMaxLength() be necessary in case of deformable meshes? . Also, from PR #532:; > As for code verification, I would propose using one of the cases examined by Travin, Stretlets, Mockett, or Xiao for comparison. (...) The cases I can see where they explicitly show the results of the blending function are: Circular cylinder at Re = 50,000 (Travin et al. 2002) (...). I guess this is the case for which you are showing the rough tests results in the Code Verification section. I am currently looking into some test cases at similar Re regimes. Are you using the unsteady compressible solver for this verification? I noticed that in Ref.[1] they use artificial compressibility, and I was wondering if we could also use this test case to look into the unsteady, incompressible (preconditioned) version of the solver (PR #514).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403842613
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:978,Security,validat,validation,978,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:1453,Security,validat,validation,1453,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:21,Testability,test,test,21,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:77,Testability,test,test,77,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:169,Testability,test,tests,169,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:255,Testability,test,tests,255,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:581,Testability,test,tests,581,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:869,Testability,test,test,869,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:947,Testability,test,test,947,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:1135,Testability,test,test,1135,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:1496,Testability,test,test,1496,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403850762:1478,Usability,simpl,simple,1478,"@rsanfer I'm using a test case from Ref [1], which doesn't exactly match the test case matching the figure I gave from Ref [2]. In Ref [1], they ran a whole ensemble of tests at various resolutions, corrections, and inflow/initial conditions. Some of the tests involved laminar separation, while others involved turbulent separation. I did not pick one of the Re = 50,000 cases because those cases involve laminar separation. Travin *et. al.* used a special nonuniform initial condition to promote laminar separation, which I viewed as overly complicated for the purposes of these tests. Instead, I picked a turbulent separation case at Re = 1.4 x 10^5 (roughly matching TS1 from Ref [1]). If you want more details/grids/cfg files, I can certainly provide them. Yes, I used the unsteady compressible solver. But I'm unsure if the circular cylinder case provides a good test case for the unsteady incompressible solver. I did very little with this test case in terms of a proper validation. The references I listed went to great lengths to ensure that the numerical results were consistent with experiments. It seems like a challenging test case. There were a lot of improvements I should have made if I were also trying to get consistent results. For example, my spanwise length was too short, and I didn't look into the impact of the rotation correction for the SA model. I skipped these improvements in the interest of time, since I wasn't aiming for validation, but rather a simple acceptance test.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403850762
https://github.com/su2code/SU2/pull/552#issuecomment-403873546:222,Deployability,update,updates,222,"@rsanfer. > However, would a call to SetMaxLength() be necessary in case of deformable meshes?. Good catch. I just pushed a commit that adds `SetMaxLength` calculations in all the instances I could find where the geometry updates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-403873546
https://github.com/su2code/SU2/pull/552#issuecomment-404097397:726,Deployability,update,updates,726,"@clarkpede Great, thanks for the details. I see your point. In general, vortex shedding cases are indeed challenging to match with the experiments, but that's what makes them interesting at the end. For a start, I am aiming to obtain comparable behaviours with both the compressible and the incompressible unsteady solvers under similar settings, rather than matching with experiments; mostly as an acceptance test as well. I am now working with standard SST turbulence model, but if you could share some simple meshes/cfg files to have a first go with hybrid RANS/LES, I would really appreciate it. > Good catch. I just pushed a commit that adds SetMaxLength calculations in all the instances I could find where the geometry updates. Thanks for the fix!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-404097397
https://github.com/su2code/SU2/pull/552#issuecomment-404097397:410,Testability,test,test,410,"@clarkpede Great, thanks for the details. I see your point. In general, vortex shedding cases are indeed challenging to match with the experiments, but that's what makes them interesting at the end. For a start, I am aiming to obtain comparable behaviours with both the compressible and the incompressible unsteady solvers under similar settings, rather than matching with experiments; mostly as an acceptance test as well. I am now working with standard SST turbulence model, but if you could share some simple meshes/cfg files to have a first go with hybrid RANS/LES, I would really appreciate it. > Good catch. I just pushed a commit that adds SetMaxLength calculations in all the instances I could find where the geometry updates. Thanks for the fix!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-404097397
https://github.com/su2code/SU2/pull/552#issuecomment-404097397:505,Usability,simpl,simple,505,"@clarkpede Great, thanks for the details. I see your point. In general, vortex shedding cases are indeed challenging to match with the experiments, but that's what makes them interesting at the end. For a start, I am aiming to obtain comparable behaviours with both the compressible and the incompressible unsteady solvers under similar settings, rather than matching with experiments; mostly as an acceptance test as well. I am now working with standard SST turbulence model, but if you could share some simple meshes/cfg files to have a first go with hybrid RANS/LES, I would really appreciate it. > Good catch. I just pushed a commit that adds SetMaxLength calculations in all the instances I could find where the geometry updates. Thanks for the fix!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/552#issuecomment-404097397
https://github.com/su2code/SU2/pull/554#issuecomment-406049839:188,Testability,Test,Testcase,188,"As promised (drag) gradient comparison:; The blue curve represent the current develop branch with the bug. Bugfix and FinDiff are hopefully self-explanatory. The results are taken from my Testcase, so it is really small (10 timesteps), i.e. for a longer running case the gradient deviates a lot more.; Let me know if you want some other comparisons :). ![image](https://user-images.githubusercontent.com/31306376/42903371-ea872c84-8ad1-11e8-83cc-79eee425f7ca.png). ![image](https://user-images.githubusercontent.com/31306376/42903349-db15c2e2-8ad1-11e8-87c9-ac8fac4b07be.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/554#issuecomment-406049839
https://github.com/su2code/SU2/pull/554#issuecomment-407364380:441,Availability,error,error,441,"Hi @economon @rsanfer and @talbring ,. There are no additional warnings generated. In addition to a check of the build history in travis (@rsanfer gave me the hint and checked that too) (not including any AD-build), I compared the stderr-output of this branch 2fd2eb0 with the latest develop ed149f7. I used all the additional compiler flags and enabled mpi, autodiff and direct-diff and ran the build on a single core (i.e. make install 2> error.out 1> output.out). Otherwise (i.e. multiple cores) the order gets mixed up and it is impossible to compare the warning/error output. ; A diff on the ""error.out"" of the two builds showed the files are identical (...like completely identical), although the files have ~18.000 lines. The stdout deviates only in the specified build dirs. For now I checked the box above for this PR. If there's s.th. else to check let me know. . @economon I guess you're right in demanding to check the compiler warnings to ensure a nice code. Being strict in this regard probably helps everybody in the long run. Thanks you all for the support although it is just a small contribution! It helps a lot.; Thanks! Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/554#issuecomment-407364380
https://github.com/su2code/SU2/pull/554#issuecomment-407364380:567,Availability,error,error,567,"Hi @economon @rsanfer and @talbring ,. There are no additional warnings generated. In addition to a check of the build history in travis (@rsanfer gave me the hint and checked that too) (not including any AD-build), I compared the stderr-output of this branch 2fd2eb0 with the latest develop ed149f7. I used all the additional compiler flags and enabled mpi, autodiff and direct-diff and ran the build on a single core (i.e. make install 2> error.out 1> output.out). Otherwise (i.e. multiple cores) the order gets mixed up and it is impossible to compare the warning/error output. ; A diff on the ""error.out"" of the two builds showed the files are identical (...like completely identical), although the files have ~18.000 lines. The stdout deviates only in the specified build dirs. For now I checked the box above for this PR. If there's s.th. else to check let me know. . @economon I guess you're right in demanding to check the compiler warnings to ensure a nice code. Being strict in this regard probably helps everybody in the long run. Thanks you all for the support although it is just a small contribution! It helps a lot.; Thanks! Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/554#issuecomment-407364380
https://github.com/su2code/SU2/pull/554#issuecomment-407364380:598,Availability,error,error,598,"Hi @economon @rsanfer and @talbring ,. There are no additional warnings generated. In addition to a check of the build history in travis (@rsanfer gave me the hint and checked that too) (not including any AD-build), I compared the stderr-output of this branch 2fd2eb0 with the latest develop ed149f7. I used all the additional compiler flags and enabled mpi, autodiff and direct-diff and ran the build on a single core (i.e. make install 2> error.out 1> output.out). Otherwise (i.e. multiple cores) the order gets mixed up and it is impossible to compare the warning/error output. ; A diff on the ""error.out"" of the two builds showed the files are identical (...like completely identical), although the files have ~18.000 lines. The stdout deviates only in the specified build dirs. For now I checked the box above for this PR. If there's s.th. else to check let me know. . @economon I guess you're right in demanding to check the compiler warnings to ensure a nice code. Being strict in this regard probably helps everybody in the long run. Thanks you all for the support although it is just a small contribution! It helps a lot.; Thanks! Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/554#issuecomment-407364380
https://github.com/su2code/SU2/pull/554#issuecomment-407364380:430,Deployability,install,install,430,"Hi @economon @rsanfer and @talbring ,. There are no additional warnings generated. In addition to a check of the build history in travis (@rsanfer gave me the hint and checked that too) (not including any AD-build), I compared the stderr-output of this branch 2fd2eb0 with the latest develop ed149f7. I used all the additional compiler flags and enabled mpi, autodiff and direct-diff and ran the build on a single core (i.e. make install 2> error.out 1> output.out). Otherwise (i.e. multiple cores) the order gets mixed up and it is impossible to compare the warning/error output. ; A diff on the ""error.out"" of the two builds showed the files are identical (...like completely identical), although the files have ~18.000 lines. The stdout deviates only in the specified build dirs. For now I checked the box above for this PR. If there's s.th. else to check let me know. . @economon I guess you're right in demanding to check the compiler warnings to ensure a nice code. Being strict in this regard probably helps everybody in the long run. Thanks you all for the support although it is just a small contribution! It helps a lot.; Thanks! Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/554#issuecomment-407364380
https://github.com/su2code/SU2/pull/555#issuecomment-406370798:262,Availability,redundant,redundant,262,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
https://github.com/su2code/SU2/pull/555#issuecomment-406370798:605,Availability,avail,available,605,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
https://github.com/su2code/SU2/pull/555#issuecomment-406370798:221,Integrability,rout,routines,221,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
https://github.com/su2code/SU2/pull/555#issuecomment-406370798:338,Integrability,rout,routines,338,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
https://github.com/su2code/SU2/pull/555#issuecomment-406370798:527,Integrability,rout,routines,527,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
https://github.com/su2code/SU2/pull/555#issuecomment-406370798:262,Safety,redund,redundant,262,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
https://github.com/su2code/SU2/pull/555#issuecomment-406370798:578,Safety,redund,redundancies,578,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
https://github.com/su2code/SU2/pull/555#issuecomment-406370798:63,Usability,feedback,feedback,63,"Hi, ; thanks for this contribution, I will get a more detailed feedback soon. A first comment about the CSymmetricMatrix class came up to my mind, from a first brief review.; There is already a CSysMatrix class and a few routines added in this pull request look redundant (matvect product for instance).; On the other hand, many of those routines (cholesky decomposition and so on) could turn out to be very useful also for other future code developments.; That said, perhaps it would be nice to collect all the matrix-related routines into the CSymmetricMatrix class (removing redundancies) to make them available at an higher level. Cheers,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406370798
https://github.com/su2code/SU2/pull/555#issuecomment-406516746:42,Modifiability,inherit,inherited,42,"Hi Giulio,; Thank you for the feedback. I inherited some of this code from a previous student of my PhD supervisor and I thought the same when I saw the CSymmetricMatrix class. However, as I understand it, CSysMatrix implements a block sparse format and here we have a simpler dense format. Another big difference is that CSymmetricMatrix does not need to be used in parallel. But I agree that making these two classes related somehow would be better, so I am open to suggestions.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406516746
https://github.com/su2code/SU2/pull/555#issuecomment-406516746:30,Usability,feedback,feedback,30,"Hi Giulio,; Thank you for the feedback. I inherited some of this code from a previous student of my PhD supervisor and I thought the same when I saw the CSymmetricMatrix class. However, as I understand it, CSysMatrix implements a block sparse format and here we have a simpler dense format. Another big difference is that CSymmetricMatrix does not need to be used in parallel. But I agree that making these two classes related somehow would be better, so I am open to suggestions.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406516746
https://github.com/su2code/SU2/pull/555#issuecomment-406516746:269,Usability,simpl,simpler,269,"Hi Giulio,; Thank you for the feedback. I inherited some of this code from a previous student of my PhD supervisor and I thought the same when I saw the CSymmetricMatrix class. However, as I understand it, CSysMatrix implements a block sparse format and here we have a simpler dense format. Another big difference is that CSymmetricMatrix does not need to be used in parallel. But I agree that making these two classes related somehow would be better, so I am open to suggestions.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406516746
https://github.com/su2code/SU2/pull/555#issuecomment-406847760:247,Availability,recover,recover,247,"Hi Pedro,; thanks for cleaning up Joel's code and creating the pull request. The disc_adj_fsi testcase is failing, I believe because of the relaxation. Probably you need to update the value of the test_case config and set the relaxation to 1.0 to recover the previous test. ; About the symmetric matrix class: Joel's implementation was indeed intended to populate the matrix needed for the RBF; the CSysMatrix would not be able to accommodate some terms due to the sparsity. It's well explained in the comments. Also, his implementation was only single-core. I agree that it would be very interesting to have some methods such as the cholesky decomposition available, but I think they would require some reworking (at least for parallelization).; I think this is a very valuable contribution, so it would be good to get more people on board to push it forward.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406847760
https://github.com/su2code/SU2/pull/555#issuecomment-406847760:657,Availability,avail,available,657,"Hi Pedro,; thanks for cleaning up Joel's code and creating the pull request. The disc_adj_fsi testcase is failing, I believe because of the relaxation. Probably you need to update the value of the test_case config and set the relaxation to 1.0 to recover the previous test. ; About the symmetric matrix class: Joel's implementation was indeed intended to populate the matrix needed for the RBF; the CSysMatrix would not be able to accommodate some terms due to the sparsity. It's well explained in the comments. Also, his implementation was only single-core. I agree that it would be very interesting to have some methods such as the cholesky decomposition available, but I think they would require some reworking (at least for parallelization).; I think this is a very valuable contribution, so it would be good to get more people on board to push it forward.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406847760
https://github.com/su2code/SU2/pull/555#issuecomment-406847760:173,Deployability,update,update,173,"Hi Pedro,; thanks for cleaning up Joel's code and creating the pull request. The disc_adj_fsi testcase is failing, I believe because of the relaxation. Probably you need to update the value of the test_case config and set the relaxation to 1.0 to recover the previous test. ; About the symmetric matrix class: Joel's implementation was indeed intended to populate the matrix needed for the RBF; the CSysMatrix would not be able to accommodate some terms due to the sparsity. It's well explained in the comments. Also, his implementation was only single-core. I agree that it would be very interesting to have some methods such as the cholesky decomposition available, but I think they would require some reworking (at least for parallelization).; I think this is a very valuable contribution, so it would be good to get more people on board to push it forward.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406847760
https://github.com/su2code/SU2/pull/555#issuecomment-406847760:207,Modifiability,config,config,207,"Hi Pedro,; thanks for cleaning up Joel's code and creating the pull request. The disc_adj_fsi testcase is failing, I believe because of the relaxation. Probably you need to update the value of the test_case config and set the relaxation to 1.0 to recover the previous test. ; About the symmetric matrix class: Joel's implementation was indeed intended to populate the matrix needed for the RBF; the CSysMatrix would not be able to accommodate some terms due to the sparsity. It's well explained in the comments. Also, his implementation was only single-core. I agree that it would be very interesting to have some methods such as the cholesky decomposition available, but I think they would require some reworking (at least for parallelization).; I think this is a very valuable contribution, so it would be good to get more people on board to push it forward.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406847760
https://github.com/su2code/SU2/pull/555#issuecomment-406847760:247,Safety,recover,recover,247,"Hi Pedro,; thanks for cleaning up Joel's code and creating the pull request. The disc_adj_fsi testcase is failing, I believe because of the relaxation. Probably you need to update the value of the test_case config and set the relaxation to 1.0 to recover the previous test. ; About the symmetric matrix class: Joel's implementation was indeed intended to populate the matrix needed for the RBF; the CSysMatrix would not be able to accommodate some terms due to the sparsity. It's well explained in the comments. Also, his implementation was only single-core. I agree that it would be very interesting to have some methods such as the cholesky decomposition available, but I think they would require some reworking (at least for parallelization).; I think this is a very valuable contribution, so it would be good to get more people on board to push it forward.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406847760
https://github.com/su2code/SU2/pull/555#issuecomment-406847760:94,Testability,test,testcase,94,"Hi Pedro,; thanks for cleaning up Joel's code and creating the pull request. The disc_adj_fsi testcase is failing, I believe because of the relaxation. Probably you need to update the value of the test_case config and set the relaxation to 1.0 to recover the previous test. ; About the symmetric matrix class: Joel's implementation was indeed intended to populate the matrix needed for the RBF; the CSysMatrix would not be able to accommodate some terms due to the sparsity. It's well explained in the comments. Also, his implementation was only single-core. I agree that it would be very interesting to have some methods such as the cholesky decomposition available, but I think they would require some reworking (at least for parallelization).; I think this is a very valuable contribution, so it would be good to get more people on board to push it forward.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406847760
https://github.com/su2code/SU2/pull/555#issuecomment-406847760:268,Testability,test,test,268,"Hi Pedro,; thanks for cleaning up Joel's code and creating the pull request. The disc_adj_fsi testcase is failing, I believe because of the relaxation. Probably you need to update the value of the test_case config and set the relaxation to 1.0 to recover the previous test. ; About the symmetric matrix class: Joel's implementation was indeed intended to populate the matrix needed for the RBF; the CSysMatrix would not be able to accommodate some terms due to the sparsity. It's well explained in the comments. Also, his implementation was only single-core. I agree that it would be very interesting to have some methods such as the cholesky decomposition available, but I think they would require some reworking (at least for parallelization).; I think this is a very valuable contribution, so it would be good to get more people on board to push it forward.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406847760
https://github.com/su2code/SU2/pull/555#issuecomment-406877331:48,Testability,test,test,48,"Hi Ruben,; Thanks for the tip it is passing the test now.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-406877331
https://github.com/su2code/SU2/pull/555#issuecomment-407014370:519,Integrability,rout,routines,519,"Hi,; I just had a few (very minor) comments.; Regarding the main contribution, everything makes sense to me and I didn't find any relevant issue.; This is a very nice contribution and the implementation is quite clear, we can go ahead and merge this in soon. Regarding the matrix stuff, perhaps we could start having a new, general, matrix class in Common and then extend it to parallel in future pushes.; It may not be ideal, but at least we'll get started.; I am just afraid that if we leave those potentially useful routines there, in the interpolator, we will soon forget about them (of course it doesn't have to be addressed in this PR but we should really discuss about this). ciao,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407014370
https://github.com/su2code/SU2/pull/555#issuecomment-407014370:365,Modifiability,extend,extend,365,"Hi,; I just had a few (very minor) comments.; Regarding the main contribution, everything makes sense to me and I didn't find any relevant issue.; This is a very nice contribution and the implementation is quite clear, we can go ahead and merge this in soon. Regarding the matrix stuff, perhaps we could start having a new, general, matrix class in Common and then extend it to parallel in future pushes.; It may not be ideal, but at least we'll get started.; I am just afraid that if we leave those potentially useful routines there, in the interpolator, we will soon forget about them (of course it doesn't have to be addressed in this PR but we should really discuss about this). ciao,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407014370
https://github.com/su2code/SU2/pull/555#issuecomment-407014370:212,Usability,clear,clear,212,"Hi,; I just had a few (very minor) comments.; Regarding the main contribution, everything makes sense to me and I didn't find any relevant issue.; This is a very nice contribution and the implementation is quite clear, we can go ahead and merge this in soon. Regarding the matrix stuff, perhaps we could start having a new, general, matrix class in Common and then extend it to parallel in future pushes.; It may not be ideal, but at least we'll get started.; I am just afraid that if we leave those potentially useful routines there, in the interpolator, we will soon forget about them (of course it doesn't have to be addressed in this PR but we should really discuss about this). ciao,; Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407014370
https://github.com/su2code/SU2/pull/555#issuecomment-407023516:113,Integrability,rout,routines,113,"Hi Giulio,; Great news, thanks!; After looking at CSysMatrix more, one possibility would be to move dense matrix routines to a class that would replace/augment this CSymmetricMatrix and then CSysMatrix could use it for operations on its blocks (which are dense). But since this involves refactoring a core class of SU2 I agree more people should be involved in the discussion.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407023516
https://github.com/su2code/SU2/pull/555#issuecomment-407023516:287,Modifiability,refactor,refactoring,287,"Hi Giulio,; Great news, thanks!; After looking at CSysMatrix more, one possibility would be to move dense matrix routines to a class that would replace/augment this CSymmetricMatrix and then CSysMatrix could use it for operations on its blocks (which are dense). But since this involves refactoring a core class of SU2 I agree more people should be involved in the discussion.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-407023516
https://github.com/su2code/SU2/pull/555#issuecomment-417612980:355,Availability,avail,available,355,"That should do.; @economon by the way, what is the right way to add a regression test/example? Do I just add the cfg and appropriate instructions to the scripts, and the mesh and initialization to the Testcases repo? If so does the order matter? Thanks. EDIT: The question above was addressed during the 3rd annual SU2 meeting hackaton session (recording available and recommended!)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-417612980
https://github.com/su2code/SU2/pull/555#issuecomment-417612980:81,Testability,test,test,81,"That should do.; @economon by the way, what is the right way to add a regression test/example? Do I just add the cfg and appropriate instructions to the scripts, and the mesh and initialization to the Testcases repo? If so does the order matter? Thanks. EDIT: The question above was addressed during the 3rd annual SU2 meeting hackaton session (recording available and recommended!)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-417612980
https://github.com/su2code/SU2/pull/555#issuecomment-417612980:201,Testability,Test,Testcases,201,"That should do.; @economon by the way, what is the right way to add a regression test/example? Do I just add the cfg and appropriate instructions to the scripts, and the mesh and initialization to the Testcases repo? If so does the order matter? Thanks. EDIT: The question above was addressed during the 3rd annual SU2 meeting hackaton session (recording available and recommended!)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-417612980
https://github.com/su2code/SU2/pull/555#issuecomment-423931446:84,Testability,Test,TestCases,84,"@LaSerpe thank you for your comments.; @rsanfer please accept the PR I made for the TestCases repo first, that way I can uncomment the test instructions when I push the changes Giulio requested.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-423931446
https://github.com/su2code/SU2/pull/555#issuecomment-423931446:135,Testability,test,test,135,"@LaSerpe thank you for your comments.; @rsanfer please accept the PR I made for the TestCases repo first, that way I can uncomment the test instructions when I push the changes Giulio requested.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-423931446
https://github.com/su2code/SU2/pull/555#issuecomment-423941651:67,Testability,test,test,67,"@pcarruscag done, it's merged in already so you can uncomment your test case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-423941651
https://github.com/su2code/SU2/pull/555#issuecomment-426698341:226,Modifiability,variab,variables,226,"@pcarruscag sorry for being picky :D but I would like to have the double changed to passivedouble. In case someone needs a float we can name it passivefloat. Sometimes I use automated scripts to check for occurences of double variables, so we should use passivedouble whenever we can to avoid future confusions on whether the use of double is intentionally or not.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-426698341
https://github.com/su2code/SU2/pull/555#issuecomment-426698341:287,Safety,avoid,avoid,287,"@pcarruscag sorry for being picky :D but I would like to have the double changed to passivedouble. In case someone needs a float we can name it passivefloat. Sometimes I use automated scripts to check for occurences of double variables, so we should use passivedouble whenever we can to avoid future confusions on whether the use of double is intentionally or not.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-426698341
https://github.com/su2code/SU2/pull/555#issuecomment-426946593:227,Performance,perform,performance,227,Do we really need the templates right now ? Or this is just in case ? I think if we make su2double a float we get also problems somewhere else (furthermore using float makes actually no sense on current architectures regarding performance),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/555#issuecomment-426946593
https://github.com/su2code/SU2/pull/557#issuecomment-414259961:28,Testability,test,testcases,28,"Thanks. Running grep on the testcases directory it seems we do not. For fluid applications this was not an issue because the number of iterations is usually small, I am working on some structural stuff right now, I will make sure to use this linear solver once I add some testcases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/557#issuecomment-414259961
https://github.com/su2code/SU2/pull/557#issuecomment-414259961:272,Testability,test,testcases,272,"Thanks. Running grep on the testcases directory it seems we do not. For fluid applications this was not an issue because the number of iterations is usually small, I am working on some structural stuff right now, I will make sure to use this linear solver once I add some testcases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/557#issuecomment-414259961
https://github.com/su2code/SU2/pull/558#issuecomment-411630702:279,Energy Efficiency,reduce,reduce,279,"@ScottImlay : it is wonderful to have your support from Tecplot, and we really appreciate the contribution for improvements through the open source!. I have a first question... I noticed that there are many new files, especially headers from the Boost library. Is it possible to reduce to a smaller set of files that get included, or are all of those that have been added necessary?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-411630702
https://github.com/su2code/SU2/pull/558#issuecomment-411773932:129,Energy Efficiency,reduce,reduced,129,"Hi Tom,; I did a Boost extract (bcp) which theoretically only includes the required header files. I'll look and see if it can be reduced further.; Scott; On Wednesday, August 8, 2018 09:10:15 PM PDT, Thomas D. Economon <notifications@github.com> wrote: ; ; ; @ScottImlay : it is wonderful to have your support from Tecplot, and we really appreciate the contribution for improvements through the open source!. I have a first question... I noticed that there are many new files, especially headers from the Boost library. Is it possible to reduce to a smaller set of files that get included, or are all of those that have been added necessary?. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-411773932
https://github.com/su2code/SU2/pull/558#issuecomment-411773932:555,Energy Efficiency,reduce,reduce,555,"Hi Tom,; I did a Boost extract (bcp) which theoretically only includes the required header files. I'll look and see if it can be reduced further.; Scott; On Wednesday, August 8, 2018 09:10:15 PM PDT, Thomas D. Economon <notifications@github.com> wrote: ; ; ; @ScottImlay : it is wonderful to have your support from Tecplot, and we really appreciate the contribution for improvements through the open source!. I have a first question... I noticed that there are many new files, especially headers from the Boost library. Is it possible to reduce to a smaller set of files that get included, or are all of those that have been added necessary?. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-411773932
https://github.com/su2code/SU2/pull/558#issuecomment-412665869:68,Energy Efficiency,reduce,reduce,68,"Thanks Tim!; Tom, I have not found any easy (and repeatable) way to reduce the BOOST header files further. Unless it is a major problem, I suggest we go with them as they are.; Thanks!Scott Imlay; On Monday, August 13, 2018, 1:56:19 PM PDT, Tim Albring <notifications@github.com> wrote: ; ; ; Like @economon already said, this is a interesting and useful contribution! Thanks!. I don't know why travis is not reporting. I am gonna look into it tmrw. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-412665869
https://github.com/su2code/SU2/pull/558#issuecomment-414158109:197,Availability,error,errors,197,It looks like our regression tests are failing during the compilation of TecIO on the Travis system (they use pretty standard Ubuntu builds). @ScottImlay: could you please take a look at the build errors when you have some time?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414158109
https://github.com/su2code/SU2/pull/558#issuecomment-414158109:29,Testability,test,tests,29,It looks like our regression tests are failing during the compilation of TecIO on the Travis system (they use pretty standard Ubuntu builds). @ScottImlay: could you please take a look at the build errors when you have some time?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414158109
https://github.com/su2code/SU2/pull/558#issuecomment-414463979:233,Availability,error,error,233,"Hi Tom,; I've consulted with our main TecIO developer, Dave Taflin, and the two of us are having a hard time finding the problem. There are a bunch of compile warnings in TecIO, but none of them look like they would cause the linker error. The actual error seems to be in the link of SU2, not the TecIO library. Could it be something I changed in the config stuff (configure.ac, m4/tecio.m4, or Makefile.am)?; Is it possible to get a more verbose error report for the linker?; Thanks!Scott Imlay; On Sunday, August 19, 2018, 2:44:12 PM PDT, Thomas D. Economon <notifications@github.com> wrote: ; ; ; It looks like our regression tests are failing during the compilation of TecIO on the Travis system (they use pretty standard Ubuntu builds). @ScottImlay: could you please take a look at the build errors when you have some time?. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414463979
https://github.com/su2code/SU2/pull/558#issuecomment-414463979:251,Availability,error,error,251,"Hi Tom,; I've consulted with our main TecIO developer, Dave Taflin, and the two of us are having a hard time finding the problem. There are a bunch of compile warnings in TecIO, but none of them look like they would cause the linker error. The actual error seems to be in the link of SU2, not the TecIO library. Could it be something I changed in the config stuff (configure.ac, m4/tecio.m4, or Makefile.am)?; Is it possible to get a more verbose error report for the linker?; Thanks!Scott Imlay; On Sunday, August 19, 2018, 2:44:12 PM PDT, Thomas D. Economon <notifications@github.com> wrote: ; ; ; It looks like our regression tests are failing during the compilation of TecIO on the Travis system (they use pretty standard Ubuntu builds). @ScottImlay: could you please take a look at the build errors when you have some time?. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414463979
https://github.com/su2code/SU2/pull/558#issuecomment-414463979:447,Availability,error,error,447,"Hi Tom,; I've consulted with our main TecIO developer, Dave Taflin, and the two of us are having a hard time finding the problem. There are a bunch of compile warnings in TecIO, but none of them look like they would cause the linker error. The actual error seems to be in the link of SU2, not the TecIO library. Could it be something I changed in the config stuff (configure.ac, m4/tecio.m4, or Makefile.am)?; Is it possible to get a more verbose error report for the linker?; Thanks!Scott Imlay; On Sunday, August 19, 2018, 2:44:12 PM PDT, Thomas D. Economon <notifications@github.com> wrote: ; ; ; It looks like our regression tests are failing during the compilation of TecIO on the Travis system (they use pretty standard Ubuntu builds). @ScottImlay: could you please take a look at the build errors when you have some time?. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414463979
https://github.com/su2code/SU2/pull/558#issuecomment-414463979:797,Availability,error,errors,797,"Hi Tom,; I've consulted with our main TecIO developer, Dave Taflin, and the two of us are having a hard time finding the problem. There are a bunch of compile warnings in TecIO, but none of them look like they would cause the linker error. The actual error seems to be in the link of SU2, not the TecIO library. Could it be something I changed in the config stuff (configure.ac, m4/tecio.m4, or Makefile.am)?; Is it possible to get a more verbose error report for the linker?; Thanks!Scott Imlay; On Sunday, August 19, 2018, 2:44:12 PM PDT, Thomas D. Economon <notifications@github.com> wrote: ; ; ; It looks like our regression tests are failing during the compilation of TecIO on the Travis system (they use pretty standard Ubuntu builds). @ScottImlay: could you please take a look at the build errors when you have some time?. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414463979
https://github.com/su2code/SU2/pull/558#issuecomment-414463979:351,Modifiability,config,config,351,"Hi Tom,; I've consulted with our main TecIO developer, Dave Taflin, and the two of us are having a hard time finding the problem. There are a bunch of compile warnings in TecIO, but none of them look like they would cause the linker error. The actual error seems to be in the link of SU2, not the TecIO library. Could it be something I changed in the config stuff (configure.ac, m4/tecio.m4, or Makefile.am)?; Is it possible to get a more verbose error report for the linker?; Thanks!Scott Imlay; On Sunday, August 19, 2018, 2:44:12 PM PDT, Thomas D. Economon <notifications@github.com> wrote: ; ; ; It looks like our regression tests are failing during the compilation of TecIO on the Travis system (they use pretty standard Ubuntu builds). @ScottImlay: could you please take a look at the build errors when you have some time?. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414463979
https://github.com/su2code/SU2/pull/558#issuecomment-414463979:365,Modifiability,config,configure,365,"Hi Tom,; I've consulted with our main TecIO developer, Dave Taflin, and the two of us are having a hard time finding the problem. There are a bunch of compile warnings in TecIO, but none of them look like they would cause the linker error. The actual error seems to be in the link of SU2, not the TecIO library. Could it be something I changed in the config stuff (configure.ac, m4/tecio.m4, or Makefile.am)?; Is it possible to get a more verbose error report for the linker?; Thanks!Scott Imlay; On Sunday, August 19, 2018, 2:44:12 PM PDT, Thomas D. Economon <notifications@github.com> wrote: ; ; ; It looks like our regression tests are failing during the compilation of TecIO on the Travis system (they use pretty standard Ubuntu builds). @ScottImlay: could you please take a look at the build errors when you have some time?. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414463979
https://github.com/su2code/SU2/pull/558#issuecomment-414463979:629,Testability,test,tests,629,"Hi Tom,; I've consulted with our main TecIO developer, Dave Taflin, and the two of us are having a hard time finding the problem. There are a bunch of compile warnings in TecIO, but none of them look like they would cause the linker error. The actual error seems to be in the link of SU2, not the TecIO library. Could it be something I changed in the config stuff (configure.ac, m4/tecio.m4, or Makefile.am)?; Is it possible to get a more verbose error report for the linker?; Thanks!Scott Imlay; On Sunday, August 19, 2018, 2:44:12 PM PDT, Thomas D. Economon <notifications@github.com> wrote: ; ; ; It looks like our regression tests are failing during the compilation of TecIO on the Travis system (they use pretty standard Ubuntu builds). @ScottImlay: could you please take a look at the build errors when you have some time?. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414463979
https://github.com/su2code/SU2/pull/558#issuecomment-414578307:556,Deployability,update,update,556,"For updating the build, I would recommend the following: after adding the headers and sources in the correct directories, modify only configure.ac to do the correct checks for the tecio option, m4/tecio.m4 to configure the compilation of tecio, and externals/tecio/Makefile.am to make sure the proper headers/files are being included in the build. . Then, as a final step, run the ./bootstrap script in the root directory of SU2/, which will build and run autoreconf with an older, standard version of the autotools that we ship for portability. This will update the makefiles throughout the build for you, and from there, you can run configure - make - install. Just let me know if you're still having trouble.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414578307
https://github.com/su2code/SU2/pull/558#issuecomment-414578307:654,Deployability,install,install,654,"For updating the build, I would recommend the following: after adding the headers and sources in the correct directories, modify only configure.ac to do the correct checks for the tecio option, m4/tecio.m4 to configure the compilation of tecio, and externals/tecio/Makefile.am to make sure the proper headers/files are being included in the build. . Then, as a final step, run the ./bootstrap script in the root directory of SU2/, which will build and run autoreconf with an older, standard version of the autotools that we ship for portability. This will update the makefiles throughout the build for you, and from there, you can run configure - make - install. Just let me know if you're still having trouble.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414578307
https://github.com/su2code/SU2/pull/558#issuecomment-414578307:134,Modifiability,config,configure,134,"For updating the build, I would recommend the following: after adding the headers and sources in the correct directories, modify only configure.ac to do the correct checks for the tecio option, m4/tecio.m4 to configure the compilation of tecio, and externals/tecio/Makefile.am to make sure the proper headers/files are being included in the build. . Then, as a final step, run the ./bootstrap script in the root directory of SU2/, which will build and run autoreconf with an older, standard version of the autotools that we ship for portability. This will update the makefiles throughout the build for you, and from there, you can run configure - make - install. Just let me know if you're still having trouble.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414578307
https://github.com/su2code/SU2/pull/558#issuecomment-414578307:209,Modifiability,config,configure,209,"For updating the build, I would recommend the following: after adding the headers and sources in the correct directories, modify only configure.ac to do the correct checks for the tecio option, m4/tecio.m4 to configure the compilation of tecio, and externals/tecio/Makefile.am to make sure the proper headers/files are being included in the build. . Then, as a final step, run the ./bootstrap script in the root directory of SU2/, which will build and run autoreconf with an older, standard version of the autotools that we ship for portability. This will update the makefiles throughout the build for you, and from there, you can run configure - make - install. Just let me know if you're still having trouble.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414578307
https://github.com/su2code/SU2/pull/558#issuecomment-414578307:533,Modifiability,portab,portability,533,"For updating the build, I would recommend the following: after adding the headers and sources in the correct directories, modify only configure.ac to do the correct checks for the tecio option, m4/tecio.m4 to configure the compilation of tecio, and externals/tecio/Makefile.am to make sure the proper headers/files are being included in the build. . Then, as a final step, run the ./bootstrap script in the root directory of SU2/, which will build and run autoreconf with an older, standard version of the autotools that we ship for portability. This will update the makefiles throughout the build for you, and from there, you can run configure - make - install. Just let me know if you're still having trouble.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414578307
https://github.com/su2code/SU2/pull/558#issuecomment-414578307:635,Modifiability,config,configure,635,"For updating the build, I would recommend the following: after adding the headers and sources in the correct directories, modify only configure.ac to do the correct checks for the tecio option, m4/tecio.m4 to configure the compilation of tecio, and externals/tecio/Makefile.am to make sure the proper headers/files are being included in the build. . Then, as a final step, run the ./bootstrap script in the root directory of SU2/, which will build and run autoreconf with an older, standard version of the autotools that we ship for portability. This will update the makefiles throughout the build for you, and from there, you can run configure - make - install. Just let me know if you're still having trouble.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-414578307
https://github.com/su2code/SU2/pull/558#issuecomment-425020607:71,Energy Efficiency,adapt,adapted,71,Thanks @ScottImlay. Seems to work now. Just a quick question. You only adapted the volume mesh/solution routines. Is it also possible to use the new format for the surface files (i.e. in the routines SetTecplotBinary_SurfaceMesh/SetTecplotBinary_SurfaceSolution) ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-425020607
https://github.com/su2code/SU2/pull/558#issuecomment-425020607:104,Integrability,rout,routines,104,Thanks @ScottImlay. Seems to work now. Just a quick question. You only adapted the volume mesh/solution routines. Is it also possible to use the new format for the surface files (i.e. in the routines SetTecplotBinary_SurfaceMesh/SetTecplotBinary_SurfaceSolution) ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-425020607
https://github.com/su2code/SU2/pull/558#issuecomment-425020607:191,Integrability,rout,routines,191,Thanks @ScottImlay. Seems to work now. Just a quick question. You only adapted the volume mesh/solution routines. Is it also possible to use the new format for the surface files (i.e. in the routines SetTecplotBinary_SurfaceMesh/SetTecplotBinary_SurfaceSolution) ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-425020607
https://github.com/su2code/SU2/pull/558#issuecomment-425020607:71,Modifiability,adapt,adapted,71,Thanks @ScottImlay. Seems to work now. Just a quick question. You only adapted the volume mesh/solution routines. Is it also possible to use the new format for the surface files (i.e. in the routines SetTecplotBinary_SurfaceMesh/SetTecplotBinary_SurfaceSolution) ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-425020607
https://github.com/su2code/SU2/pull/558#issuecomment-426696883:114,Performance,load,load,114,"Thanks for the answer. If it has no benefit we can leave it like that. I was just worried that is not possible to load szplt and plt files together into tecplot. But I tried it and it works :+1: . I am happy with the change. As soon as there is further approval, we can merge it in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-426696883
https://github.com/su2code/SU2/pull/558#issuecomment-426809515:361,Availability,down,downloading,361,"Thanks for getting everything cleaned up, @ScottImlay. I really would like to get this merged soon, as I think it is a great contribution. My main concern remains the size of the files that are now included due to the boost library. The externals/tecio directory has increased in size from 3.6 MB to 172 MB, and 166 MB of that is boost. Perhaps we can consider downloading this code on-the-fly during the configure process, or have a script access it as a submodule similar to CoDiPack via preconfigure.py. Open to ideas here.. any thoughts?. Lastly, if we are shipping boost source, we should add their license to the distribution by including this file in externals/tecio/boost/ : https://www.boost.org/LICENSE_1_0.txt",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-426809515
https://github.com/su2code/SU2/pull/558#issuecomment-426809515:405,Modifiability,config,configure,405,"Thanks for getting everything cleaned up, @ScottImlay. I really would like to get this merged soon, as I think it is a great contribution. My main concern remains the size of the files that are now included due to the boost library. The externals/tecio directory has increased in size from 3.6 MB to 172 MB, and 166 MB of that is boost. Perhaps we can consider downloading this code on-the-fly during the configure process, or have a script access it as a submodule similar to CoDiPack via preconfigure.py. Open to ideas here.. any thoughts?. Lastly, if we are shipping boost source, we should add their license to the distribution by including this file in externals/tecio/boost/ : https://www.boost.org/LICENSE_1_0.txt",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-426809515
https://github.com/su2code/SU2/pull/558#issuecomment-426809515:441,Security,access,access,441,"Thanks for getting everything cleaned up, @ScottImlay. I really would like to get this merged soon, as I think it is a great contribution. My main concern remains the size of the files that are now included due to the boost library. The externals/tecio directory has increased in size from 3.6 MB to 172 MB, and 166 MB of that is boost. Perhaps we can consider downloading this code on-the-fly during the configure process, or have a script access it as a submodule similar to CoDiPack via preconfigure.py. Open to ideas here.. any thoughts?. Lastly, if we are shipping boost source, we should add their license to the distribution by including this file in externals/tecio/boost/ : https://www.boost.org/LICENSE_1_0.txt",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-426809515
https://github.com/su2code/SU2/pull/558#issuecomment-427028138:122,Availability,down,download,122,"Thanks Tom and Tim. I agree that the BOOST include files make the library much larger and that isn't ideal. If we wish to download it on the fly there are a couple things to consider:. 1. The extracted include files are much smaller than the full BOOST library. I'm traveling today so I don't have the sizes handy, but I will look up the details when I'm in the office tomorrow.; 2. There is a bug in the latest release of BOOST that requires us to include an earlier version of BOOST. Hopefully they will release a new version that fixes this bug, and this problem will go away. I will double check the sizes tomorrow and post an update.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-427028138
https://github.com/su2code/SU2/pull/558#issuecomment-427028138:412,Deployability,release,release,412,"Thanks Tom and Tim. I agree that the BOOST include files make the library much larger and that isn't ideal. If we wish to download it on the fly there are a couple things to consider:. 1. The extracted include files are much smaller than the full BOOST library. I'm traveling today so I don't have the sizes handy, but I will look up the details when I'm in the office tomorrow.; 2. There is a bug in the latest release of BOOST that requires us to include an earlier version of BOOST. Hopefully they will release a new version that fixes this bug, and this problem will go away. I will double check the sizes tomorrow and post an update.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-427028138
https://github.com/su2code/SU2/pull/558#issuecomment-427028138:506,Deployability,release,release,506,"Thanks Tom and Tim. I agree that the BOOST include files make the library much larger and that isn't ideal. If we wish to download it on the fly there are a couple things to consider:. 1. The extracted include files are much smaller than the full BOOST library. I'm traveling today so I don't have the sizes handy, but I will look up the details when I'm in the office tomorrow.; 2. There is a bug in the latest release of BOOST that requires us to include an earlier version of BOOST. Hopefully they will release a new version that fixes this bug, and this problem will go away. I will double check the sizes tomorrow and post an update.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-427028138
https://github.com/su2code/SU2/pull/558#issuecomment-427028138:631,Deployability,update,update,631,"Thanks Tom and Tim. I agree that the BOOST include files make the library much larger and that isn't ideal. If we wish to download it on the fly there are a couple things to consider:. 1. The extracted include files are much smaller than the full BOOST library. I'm traveling today so I don't have the sizes handy, but I will look up the details when I'm in the office tomorrow.; 2. There is a bug in the latest release of BOOST that requires us to include an earlier version of BOOST. Hopefully they will release a new version that fixes this bug, and this problem will go away. I will double check the sizes tomorrow and post an update.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-427028138
https://github.com/su2code/SU2/pull/558#issuecomment-427287810:140,Availability,down,down,140,Another possibility would be to compress the boost files and uncompress it during configure/preconfigure. With tar.gz this reduces the size down to 15 MB.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-427287810
https://github.com/su2code/SU2/pull/558#issuecomment-427287810:123,Energy Efficiency,reduce,reduces,123,Another possibility would be to compress the boost files and uncompress it during configure/preconfigure. With tar.gz this reduces the size down to 15 MB.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-427287810
https://github.com/su2code/SU2/pull/558#issuecomment-427287810:82,Modifiability,config,configure,82,Another possibility would be to compress the boost files and uncompress it during configure/preconfigure. With tar.gz this reduces the size down to 15 MB.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-427287810
https://github.com/su2code/SU2/pull/558#issuecomment-431005389:65,Modifiability,config,configure,65,"I compressed the boost sources and added a call to extract it to configure.ac (its much easier than in the m4 scripts, since you can use shell commands). I also added a check whether the boost folder exists, so that it is only done the first time you call configure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-431005389
https://github.com/su2code/SU2/pull/558#issuecomment-431005389:256,Modifiability,config,configure,256,"I compressed the boost sources and added a call to extract it to configure.ac (its much easier than in the m4 scripts, since you can use shell commands). I also added a check whether the boost folder exists, so that it is only done the first time you call configure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-431005389
https://github.com/su2code/SU2/pull/558#issuecomment-431207236:119,Availability,error,error,119,"I was just giving this a try on a mac, and while the configure/unpack of boost seems to work fine, I get the following error:. teciosrc/auxdata.cpp:14:2239: error: cast from pointer to smaller type '___90' (aka 'int') loses information. This is with LLVM. @ScottImlay : anything obvious I am missing w.r.t. data types or the build steps for mac? Maybe there is something with 32 v 64 bit. Have others given this a try yet?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-431207236
https://github.com/su2code/SU2/pull/558#issuecomment-431207236:157,Availability,error,error,157,"I was just giving this a try on a mac, and while the configure/unpack of boost seems to work fine, I get the following error:. teciosrc/auxdata.cpp:14:2239: error: cast from pointer to smaller type '___90' (aka 'int') loses information. This is with LLVM. @ScottImlay : anything obvious I am missing w.r.t. data types or the build steps for mac? Maybe there is something with 32 v 64 bit. Have others given this a try yet?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-431207236
https://github.com/su2code/SU2/pull/558#issuecomment-431207236:53,Modifiability,config,configure,53,"I was just giving this a try on a mac, and while the configure/unpack of boost seems to work fine, I get the following error:. teciosrc/auxdata.cpp:14:2239: error: cast from pointer to smaller type '___90' (aka 'int') loses information. This is with LLVM. @ScottImlay : anything obvious I am missing w.r.t. data types or the build steps for mac? Maybe there is something with 32 v 64 bit. Have others given this a try yet?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/558#issuecomment-431207236
https://github.com/su2code/SU2/issues/559#issuecomment-453849671:28,Availability,error,error,28,"I am getting the exact same error when I try to run it out of the box - even though if I add the restrictions I get a convergence.; I tried to run it multithreaded and got very different results and in some case crash with reboot.; Then I looked closer at the result - the result from quick start should look very similar to DSN_001, but it doesn't - could the problem be in the python wrapper since that is basically the only difference between DSN_001 and quick start?; ![dsn_001](https://user-images.githubusercontent.com/12813438/51088528-097d8b80-1761-11e9-8c3e-81acee6beb6a.jpg); The last design before crash:; ![dsn_006](https://user-images.githubusercontent.com/12813438/51088530-0c787c00-1761-11e9-9b19-3204005e897d.jpg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/559#issuecomment-453849671
https://github.com/su2code/SU2/issues/559#issuecomment-453849671:223,Availability,reboot,reboot,223,"I am getting the exact same error when I try to run it out of the box - even though if I add the restrictions I get a convergence.; I tried to run it multithreaded and got very different results and in some case crash with reboot.; Then I looked closer at the result - the result from quick start should look very similar to DSN_001, but it doesn't - could the problem be in the python wrapper since that is basically the only difference between DSN_001 and quick start?; ![dsn_001](https://user-images.githubusercontent.com/12813438/51088528-097d8b80-1761-11e9-8c3e-81acee6beb6a.jpg); The last design before crash:; ![dsn_006](https://user-images.githubusercontent.com/12813438/51088530-0c787c00-1761-11e9-9b19-3204005e897d.jpg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/559#issuecomment-453849671
https://github.com/su2code/SU2/issues/559#issuecomment-453849671:386,Integrability,wrap,wrapper,386,"I am getting the exact same error when I try to run it out of the box - even though if I add the restrictions I get a convergence.; I tried to run it multithreaded and got very different results and in some case crash with reboot.; Then I looked closer at the result - the result from quick start should look very similar to DSN_001, but it doesn't - could the problem be in the python wrapper since that is basically the only difference between DSN_001 and quick start?; ![dsn_001](https://user-images.githubusercontent.com/12813438/51088528-097d8b80-1761-11e9-8c3e-81acee6beb6a.jpg); The last design before crash:; ![dsn_006](https://user-images.githubusercontent.com/12813438/51088530-0c787c00-1761-11e9-9b19-3204005e897d.jpg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/559#issuecomment-453849671
https://github.com/su2code/SU2/issues/559#issuecomment-513077626:205,Availability,error,error,205,"I know this is wicked late, but I have just recently been doing a lot of shape optimization and finally can answer some questions on it. Is this still an issue?. Usually when the optimizer exits with that error, it means the DIRECT run diverged, or something of that sort.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/559#issuecomment-513077626
https://github.com/su2code/SU2/issues/559#issuecomment-513077626:79,Performance,optimiz,optimization,79,"I know this is wicked late, but I have just recently been doing a lot of shape optimization and finally can answer some questions on it. Is this still an issue?. Usually when the optimizer exits with that error, it means the DIRECT run diverged, or something of that sort.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/559#issuecomment-513077626
https://github.com/su2code/SU2/issues/559#issuecomment-513077626:179,Performance,optimiz,optimizer,179,"I know this is wicked late, but I have just recently been doing a lot of shape optimization and finally can answer some questions on it. Is this still an issue?. Usually when the optimizer exits with that error, it means the DIRECT run diverged, or something of that sort.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/559#issuecomment-513077626
https://github.com/su2code/SU2/issues/559#issuecomment-513481846:209,Performance,optimiz,optimization,209,"Thanks for your reply - I haven't tried the latest version, but plan to do it soon.; It sound like a reasonable explanation that DIRECT diverged (the images does look rather diverged).; Have you run the shape optimization tutorial 1?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/559#issuecomment-513481846
https://github.com/su2code/SU2/pull/562#issuecomment-414092502:374,Energy Efficiency,adapt,adapting,374,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502
https://github.com/su2code/SU2/pull/562#issuecomment-414092502:123,Modifiability,portab,portable,123,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502
https://github.com/su2code/SU2/pull/562#issuecomment-414092502:374,Modifiability,adapt,adapting,374,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502
https://github.com/su2code/SU2/pull/562#issuecomment-414092502:170,Usability,simpl,simple,170,"Thanks, Edwin. I had originally toyed around with this too, but I thought using the system-specific versions would be most portable at first. However, for something this simple, I agree that we should just do it ourselves. I have reused your implementation with some minor modifications. Could you please just confirm that the code posted above is yours, you are ok with me adapting it, and that I can name you as an author at the top of the file (I have added you there)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414092502
https://github.com/su2code/SU2/pull/562#issuecomment-414104646:192,Energy Efficiency,adapt,adapting,192,"Tom,. The endian test I got from http://cs-fundamentals.com/tech-interview/c/c-program-to-check-little-and-big-endian-architecture.php. The byte swapping function is mine and I am OK with you adapting it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414104646
https://github.com/su2code/SU2/pull/562#issuecomment-414104646:192,Modifiability,adapt,adapting,192,"Tom,. The endian test I got from http://cs-fundamentals.com/tech-interview/c/c-program-to-check-little-and-big-endian-architecture.php. The byte swapping function is mine and I am OK with you adapting it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414104646
https://github.com/su2code/SU2/pull/562#issuecomment-414104646:17,Testability,test,test,17,"Tom,. The endian test I got from http://cs-fundamentals.com/tech-interview/c/c-program-to-check-little-and-big-endian-architecture.php. The byte swapping function is mine and I am OK with you adapting it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414104646
https://github.com/su2code/SU2/pull/562#issuecomment-414157987:38,Testability,test,test,38,"Sounds good. I implemented the endian test a little differently than the website you linked, so no worries there, and now with your consent to use the ByteSwap() function, this PR is ready to go. . I will wait for another review.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/562#issuecomment-414157987
https://github.com/su2code/SU2/issues/564#issuecomment-415697025:119,Availability,error,error,119,"@vdweide I agree, there might be cases where is is useful. I am totally fine with adding an additional argument to the error handler.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415697025
https://github.com/su2code/SU2/issues/564#issuecomment-415853537:207,Availability,error,errors,207,"This isn't just a hypothetical problem. In `CSolver::LoadInletProfile`, a specified inlet profile is compared against the loaded grid. Since each MPI task ""owns"" a different section of the grid, you can get errors on one task but not another. Here's the current workaround. The code currently does an `MPI_Allreduce` to check if there were any errors globally, then calls `SU2_MPI::Error` collectively if there were any errors. The code works fine how it is, but it would be nice if there was a standardized way to approach problems like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415853537
https://github.com/su2code/SU2/issues/564#issuecomment-415853537:344,Availability,error,errors,344,"This isn't just a hypothetical problem. In `CSolver::LoadInletProfile`, a specified inlet profile is compared against the loaded grid. Since each MPI task ""owns"" a different section of the grid, you can get errors on one task but not another. Here's the current workaround. The code currently does an `MPI_Allreduce` to check if there were any errors globally, then calls `SU2_MPI::Error` collectively if there were any errors. The code works fine how it is, but it would be nice if there was a standardized way to approach problems like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415853537
https://github.com/su2code/SU2/issues/564#issuecomment-415853537:382,Availability,Error,Error,382,"This isn't just a hypothetical problem. In `CSolver::LoadInletProfile`, a specified inlet profile is compared against the loaded grid. Since each MPI task ""owns"" a different section of the grid, you can get errors on one task but not another. Here's the current workaround. The code currently does an `MPI_Allreduce` to check if there were any errors globally, then calls `SU2_MPI::Error` collectively if there were any errors. The code works fine how it is, but it would be nice if there was a standardized way to approach problems like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415853537
https://github.com/su2code/SU2/issues/564#issuecomment-415853537:420,Availability,error,errors,420,"This isn't just a hypothetical problem. In `CSolver::LoadInletProfile`, a specified inlet profile is compared against the loaded grid. Since each MPI task ""owns"" a different section of the grid, you can get errors on one task but not another. Here's the current workaround. The code currently does an `MPI_Allreduce` to check if there were any errors globally, then calls `SU2_MPI::Error` collectively if there were any errors. The code works fine how it is, but it would be nice if there was a standardized way to approach problems like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415853537
https://github.com/su2code/SU2/issues/564#issuecomment-415853537:53,Performance,Load,LoadInletProfile,53,"This isn't just a hypothetical problem. In `CSolver::LoadInletProfile`, a specified inlet profile is compared against the loaded grid. Since each MPI task ""owns"" a different section of the grid, you can get errors on one task but not another. Here's the current workaround. The code currently does an `MPI_Allreduce` to check if there were any errors globally, then calls `SU2_MPI::Error` collectively if there were any errors. The code works fine how it is, but it would be nice if there was a standardized way to approach problems like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415853537
https://github.com/su2code/SU2/issues/564#issuecomment-415853537:122,Performance,load,loaded,122,"This isn't just a hypothetical problem. In `CSolver::LoadInletProfile`, a specified inlet profile is compared against the loaded grid. Since each MPI task ""owns"" a different section of the grid, you can get errors on one task but not another. Here's the current workaround. The code currently does an `MPI_Allreduce` to check if there were any errors globally, then calls `SU2_MPI::Error` collectively if there were any errors. The code works fine how it is, but it would be nice if there was a standardized way to approach problems like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415853537
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:69,Availability,error,error,69,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:113,Availability,error,error,113,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:283,Availability,error,error,283,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:380,Availability,error,error,380,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:752,Availability,error,error,752,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:643,Energy Efficiency,efficient,efficient,643,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:119,Integrability,message,message,119,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:306,Integrability,message,messages,306,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:413,Integrability,message,messages,413,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:464,Integrability,message,messages,464,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:600,Integrability,message,message,600,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-415937480:700,Integrability,message,messages,700,"What about the following?. - Find out the lowest rank that calls the error handler.; - Only this rank writes the error message. The tricky part of course is how to find out this lowest rank. A possible solution would be (although I am open for alternatives here). - The ranks in the error handler send out messages with a very specific tag to all other ranks.; - The ranks in the error handler attempt to receive messages for a certain amount of time or until all messages have been received. Typically MPI_Iprobe would be used for this purpose.; - Keep track of the lowest rank from which an actual message was received. This may not be very efficient, but you don't care here. Furthermore, not all messages will be received if not all ranks call the error handler. Again, you don't care, because the computation is killed afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-415937480
https://github.com/su2code/SU2/issues/564#issuecomment-416834675:25,Availability,error,error,25,Is it OK if I modify the error handler as described above?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-416834675
https://github.com/su2code/SU2/issues/564#issuecomment-417216607:104,Availability,error,error,104,"The corresponding OpenMP functionality would more something be like OpenMP single in order to print the error message once. I don't know MPI-3 too well yet, but I can have a look. Then we can make a decision whether or not we want to have MPI-3 functionality in there.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-417216607
https://github.com/su2code/SU2/issues/564#issuecomment-417216607:110,Integrability,message,message,110,"The corresponding OpenMP functionality would more something be like OpenMP single in order to print the error message once. I don't know MPI-3 too well yet, but I can have a look. Then we can make a decision whether or not we want to have MPI-3 functionality in there.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/564#issuecomment-417216607
https://github.com/su2code/SU2/pull/565#issuecomment-419082199:190,Integrability,rout,routines,190,"@hlkline to answer the question about LAPACK and BLAS. Yes, the code compiles and runs without them, albeit very inefficiently. However, it is necessary to have this possibility because the routines of LAPACK and BLAS cannot be used in AD mode.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/565#issuecomment-419082199
https://github.com/su2code/SU2/pull/565#issuecomment-419739985:21,Testability,test,test,21,"I need to modify the test cases. So please, do not merge in this PR yet.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/565#issuecomment-419739985
https://github.com/su2code/SU2/pull/565#issuecomment-432438321:4,Deployability,update,updates,4,"Any updates on this PR? I want to start a pull request on the wall distance calculation fix, but need this PR to go through to use some of the functions implemented by @vdweide",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/565#issuecomment-432438321
https://github.com/su2code/SU2/issues/566#issuecomment-416138200:254,Availability,error,error,254,"Seen the number of parameters that can be specified for a compiler and the different compilers that are used for SU2, I don't think checking all parameters is a feasible option. Therefore we have to live with the fact that some parameters result in swig error and you have to use common sense to solve it. I think this issue is solved and can be closed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/566#issuecomment-416138200
https://github.com/su2code/SU2/issues/567#issuecomment-416808134:175,Availability,error,error,175,"Thanks for the post. I think the issue is that ParMETIS support is enabled by default when building with '--enable-mpi' and so that option is not necessary (and may throw and error). Additionally, if the user does not enable MPI, ParMETIS will be disabled. Same for METIS. . If this is causing issues, we can remove them entirely from the set of configure options in order to avoid confusion.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/567#issuecomment-416808134
https://github.com/su2code/SU2/issues/567#issuecomment-416808134:346,Modifiability,config,configure,346,"Thanks for the post. I think the issue is that ParMETIS support is enabled by default when building with '--enable-mpi' and so that option is not necessary (and may throw and error). Additionally, if the user does not enable MPI, ParMETIS will be disabled. Same for METIS. . If this is causing issues, we can remove them entirely from the set of configure options in order to avoid confusion.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/567#issuecomment-416808134
https://github.com/su2code/SU2/issues/567#issuecomment-416808134:376,Safety,avoid,avoid,376,"Thanks for the post. I think the issue is that ParMETIS support is enabled by default when building with '--enable-mpi' and so that option is not necessary (and may throw and error). Additionally, if the user does not enable MPI, ParMETIS will be disabled. Same for METIS. . If this is causing issues, we can remove them entirely from the set of configure options in order to avoid confusion.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/567#issuecomment-416808134
https://github.com/su2code/SU2/issues/567#issuecomment-416889527:44,Modifiability,config,configure,44,"At some point we might have to clean up the configure script anyway, I guess :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/567#issuecomment-416889527
https://github.com/su2code/SU2/issues/567#issuecomment-417519404:106,Modifiability,config,configure,106,"Aok. For now, let's close this one, and please just raise another issue in the future if we need to clean configure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/567#issuecomment-417519404
https://github.com/su2code/SU2/issues/568#issuecomment-416806343:180,Testability,test,testing,180,"@TobiKattmann : nice catch, thanks for the effort to debug this one. I have also been seeing this in the regressions. . @rsanfer or @arubino : do you have a case that you used for testing the new instance index, possibly with multiple zones including harmonic balance?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/568#issuecomment-416806343
https://github.com/su2code/SU2/issues/568#issuecomment-416935622:351,Energy Efficiency,adapt,adapted,351,"Thanks @TobiKattmann, nice catch! Can you please put a pull request with the required changes? That way I can also do some tests myself and we can move the discussion there. @economon As far as I know, there is no multizone-multiinstance case running as of now. I think @arubino worked on multizone harmonic-balance, but I don't think it has yet been adapted to the new instance index. Am I right?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/568#issuecomment-416935622
https://github.com/su2code/SU2/issues/568#issuecomment-416935622:351,Modifiability,adapt,adapted,351,"Thanks @TobiKattmann, nice catch! Can you please put a pull request with the required changes? That way I can also do some tests myself and we can move the discussion there. @economon As far as I know, there is no multizone-multiinstance case running as of now. I think @arubino worked on multizone harmonic-balance, but I don't think it has yet been adapted to the new instance index. Am I right?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/568#issuecomment-416935622
https://github.com/su2code/SU2/issues/568#issuecomment-416935622:123,Testability,test,tests,123,"Thanks @TobiKattmann, nice catch! Can you please put a pull request with the required changes? That way I can also do some tests myself and we can move the discussion there. @economon As far as I know, there is no multizone-multiinstance case running as of now. I think @arubino worked on multizone harmonic-balance, but I don't think it has yet been adapted to the new instance index. Am I right?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/568#issuecomment-416935622
https://github.com/su2code/SU2/pull/569#issuecomment-417799776:71,Testability,test,test,71,"That's great, thanks. I've removed the multiple ffd finite differences test which isn't being used at the moment and will push up the changes shortly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/569#issuecomment-417799776
https://github.com/su2code/SU2/pull/570#issuecomment-417086563:141,Availability,error,errors,141,"The TravisCI checks with autodiff and direct-diff seemed to have failed. Not sure why, since I didn't change any of the files that throw the errors. All the errors seem to originate from the codi package. Any suggestions on how to fix that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-417086563
https://github.com/su2code/SU2/pull/570#issuecomment-417086563:157,Availability,error,errors,157,"The TravisCI checks with autodiff and direct-diff seemed to have failed. Not sure why, since I didn't change any of the files that throw the errors. All the errors seem to originate from the codi package. Any suggestions on how to fix that?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-417086563
https://github.com/su2code/SU2/pull/570#issuecomment-417523118:61,Availability,failure,failure,61,"@jayantmukho : I am seeing two possible reasons for the test failure.. . 1. There are changes noted to some of the autotools files that I don't normally expect. Did you run the ./bootstrap script locally in order to update the Python script install list? If not you may want to try again, since we should see minimal changes recorded in the commit. 2. The logs report that externals/codi changed, but I don't think anything should be modified from there. Can you please revert any changes in that directory?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-417523118
https://github.com/su2code/SU2/pull/570#issuecomment-417523118:216,Deployability,update,update,216,"@jayantmukho : I am seeing two possible reasons for the test failure.. . 1. There are changes noted to some of the autotools files that I don't normally expect. Did you run the ./bootstrap script locally in order to update the Python script install list? If not you may want to try again, since we should see minimal changes recorded in the commit. 2. The logs report that externals/codi changed, but I don't think anything should be modified from there. Can you please revert any changes in that directory?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-417523118
https://github.com/su2code/SU2/pull/570#issuecomment-417523118:241,Deployability,install,install,241,"@jayantmukho : I am seeing two possible reasons for the test failure.. . 1. There are changes noted to some of the autotools files that I don't normally expect. Did you run the ./bootstrap script locally in order to update the Python script install list? If not you may want to try again, since we should see minimal changes recorded in the commit. 2. The logs report that externals/codi changed, but I don't think anything should be modified from there. Can you please revert any changes in that directory?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-417523118
https://github.com/su2code/SU2/pull/570#issuecomment-417523118:56,Testability,test,test,56,"@jayantmukho : I am seeing two possible reasons for the test failure.. . 1. There are changes noted to some of the autotools files that I don't normally expect. Did you run the ./bootstrap script locally in order to update the Python script install list? If not you may want to try again, since we should see minimal changes recorded in the commit. 2. The logs report that externals/codi changed, but I don't think anything should be modified from there. Can you please revert any changes in that directory?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-417523118
https://github.com/su2code/SU2/pull/570#issuecomment-417523118:356,Testability,log,logs,356,"@jayantmukho : I am seeing two possible reasons for the test failure.. . 1. There are changes noted to some of the autotools files that I don't normally expect. Did you run the ./bootstrap script locally in order to update the Python script install list? If not you may want to try again, since we should see minimal changes recorded in the commit. 2. The logs report that externals/codi changed, but I don't think anything should be modified from there. Can you please revert any changes in that directory?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-417523118
https://github.com/su2code/SU2/pull/570#issuecomment-420018434:69,Testability,test,test,69,"Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. . Just wanted to confirm this before I change the regression scripts",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420018434
https://github.com/su2code/SU2/pull/570#issuecomment-420018434:137,Testability,test,tests,137,"Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. . Just wanted to confirm this before I change the regression scripts",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420018434
https://github.com/su2code/SU2/pull/570#issuecomment-420018434:153,Testability,test,test,153,"Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. . Just wanted to confirm this before I change the regression scripts",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420018434
https://github.com/su2code/SU2/pull/570#issuecomment-420018434:249,Testability,test,test,249,"Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. . Just wanted to confirm this before I change the regression scripts",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420018434
https://github.com/su2code/SU2/pull/570#issuecomment-420020260:40,Testability,test,tests,40,"Jayant,. Indeed: we want the regression tests to provide coverage of the code. In this case, each of your 5 sims runs a slightly modified version of the turbulence model and therefore requires a different test case. Of course, you only need to run each case for a short time and compare with a pre-recorded reference outcome. Best,. Juan. On Sep 10, 2018, at 11:43 AM, Jayant Mukhopadhaya <notifications@github.com<mailto:notifications@github.com>> wrote:. Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. Just wanted to confirm this before I change the regression scripts. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/570#issuecomment-420018434>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxIcgYYorWkbnwu8K9bGHjWlP_sTSks5uZrLYgaJpZM4WSGPb>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420020260
https://github.com/su2code/SU2/pull/570#issuecomment-420020260:207,Testability,test,test,207,"Jayant,. Indeed: we want the regression tests to provide coverage of the code. In this case, each of your 5 sims runs a slightly modified version of the turbulence model and therefore requires a different test case. Of course, you only need to run each case for a short time and compare with a pre-recorded reference outcome. Best,. Juan. On Sep 10, 2018, at 11:43 AM, Jayant Mukhopadhaya <notifications@github.com<mailto:notifications@github.com>> wrote:. Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. Just wanted to confirm this before I change the regression scripts. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/570#issuecomment-420018434>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxIcgYYorWkbnwu8K9bGHjWlP_sTSks5uZrLYgaJpZM4WSGPb>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420020260
https://github.com/su2code/SU2/pull/570#issuecomment-420020260:528,Testability,test,test,528,"Jayant,. Indeed: we want the regression tests to provide coverage of the code. In this case, each of your 5 sims runs a slightly modified version of the turbulence model and therefore requires a different test case. Of course, you only need to run each case for a short time and compare with a pre-recorded reference outcome. Best,. Juan. On Sep 10, 2018, at 11:43 AM, Jayant Mukhopadhaya <notifications@github.com<mailto:notifications@github.com>> wrote:. Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. Just wanted to confirm this before I change the regression scripts. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/570#issuecomment-420018434>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxIcgYYorWkbnwu8K9bGHjWlP_sTSks5uZrLYgaJpZM4WSGPb>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420020260
https://github.com/su2code/SU2/pull/570#issuecomment-420020260:596,Testability,test,tests,596,"Jayant,. Indeed: we want the regression tests to provide coverage of the code. In this case, each of your 5 sims runs a slightly modified version of the turbulence model and therefore requires a different test case. Of course, you only need to run each case for a short time and compare with a pre-recorded reference outcome. Best,. Juan. On Sep 10, 2018, at 11:43 AM, Jayant Mukhopadhaya <notifications@github.com<mailto:notifications@github.com>> wrote:. Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. Just wanted to confirm this before I change the regression scripts. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/570#issuecomment-420018434>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxIcgYYorWkbnwu8K9bGHjWlP_sTSks5uZrLYgaJpZM4WSGPb>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420020260
https://github.com/su2code/SU2/pull/570#issuecomment-420020260:612,Testability,test,test,612,"Jayant,. Indeed: we want the regression tests to provide coverage of the code. In this case, each of your 5 sims runs a slightly modified version of the turbulence model and therefore requires a different test case. Of course, you only need to run each case for a short time and compare with a pre-recorded reference outcome. Best,. Juan. On Sep 10, 2018, at 11:43 AM, Jayant Mukhopadhaya <notifications@github.com<mailto:notifications@github.com>> wrote:. Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. Just wanted to confirm this before I change the regression scripts. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/570#issuecomment-420018434>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxIcgYYorWkbnwu8K9bGHjWlP_sTSks5uZrLYgaJpZM4WSGPb>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420020260
https://github.com/su2code/SU2/pull/570#issuecomment-420020260:708,Testability,test,test,708,"Jayant,. Indeed: we want the regression tests to provide coverage of the code. In this case, each of your 5 sims runs a slightly modified version of the turbulence model and therefore requires a different test case. Of course, you only need to run each case for a short time and compare with a pre-recorded reference outcome. Best,. Juan. On Sep 10, 2018, at 11:43 AM, Jayant Mukhopadhaya <notifications@github.com<mailto:notifications@github.com>> wrote:. Looking at some of the other pull requests, it seems like if I add a test case to the repository, I should also add it to the regression tests. For this test case, SU2 has to run 5 different simulations. So I am assuming I should write a regression test for each of the simulations. Just wanted to confirm this before I change the regression scripts. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/570#issuecomment-420018434>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxIcgYYorWkbnwu8K9bGHjWlP_sTSks5uZrLYgaJpZM4WSGPb>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-420020260
https://github.com/su2code/SU2/pull/570#issuecomment-427468893:383,Energy Efficiency,allocate,allocate,383,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893
https://github.com/su2code/SU2/pull/570#issuecomment-427468893:98,Modifiability,config,config,98,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893
https://github.com/su2code/SU2/pull/570#issuecomment-427468893:105,Modifiability,variab,variables,105,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893
https://github.com/su2code/SU2/pull/570#issuecomment-427468893:398,Modifiability,variab,variables,398,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893
https://github.com/su2code/SU2/pull/570#issuecomment-427468893:205,Usability,clear,clearly,205,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893
https://github.com/su2code/SU2/pull/570#issuecomment-427468893:651,Usability,usab,usability,651,"Overall some solid looking code @jayantmukho, thanks!; I have a few suggestions:; 1 - Some of the config variables have fairly broad names, ""permute"" for example, I think prefixing them with UQ would more clearly identify what they are meant for.; 2 - There are a lot of dynamic allocations of static size, if the current implementation is compatible with 2 and 3 dimensions I would allocate those variables statically, makes for cleaner and faster code (stack allocations are much faster and subsequent loops would likely be unrolled by the compiler).; 3 - It looks like some of the new methods in CNumerics are for generic ""Eigenvalue-stuff"" for re-usability I suggest moving those methods to a helper class, even if for now that class becomes just a collection of static methods. In the implementation of those methods the dimension of the inputs is being assumed, if you do move them please make them generic.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-427468893
https://github.com/su2code/SU2/pull/570#issuecomment-433784029:376,Modifiability,variab,variable,376,"Hey @pcarruscag !. Thanks for the suggestions. . 1) That's a good point. I will change the option names to be more specific. . 2) Not a 100% certain what you mean by this. To be clear, instead of allocating memory using the keyword new (MeanReynoldsStress = new su2double* [3];), I should be declaring them statically (su2double MeanReynoldsStress[3][3])? I was following the variable declaration norms I saw in the code. But I guess those were usually for allocations to nDim. Is that what you are suggesting?. 3) I have generalized the Eigen-value functions to n order matrices now. But I think I am going to keep them in the numerics class. Since it seems like that is where they would be most useful. Would you suggest otherwise?. Cheers,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433784029
https://github.com/su2code/SU2/pull/570#issuecomment-433784029:178,Usability,clear,clear,178,"Hey @pcarruscag !. Thanks for the suggestions. . 1) That's a good point. I will change the option names to be more specific. . 2) Not a 100% certain what you mean by this. To be clear, instead of allocating memory using the keyword new (MeanReynoldsStress = new su2double* [3];), I should be declaring them statically (su2double MeanReynoldsStress[3][3])? I was following the variable declaration norms I saw in the code. But I guess those were usually for allocations to nDim. Is that what you are suggesting?. 3) I have generalized the Eigen-value functions to n order matrices now. But I think I am going to keep them in the numerics class. Since it seems like that is where they would be most useful. Would you suggest otherwise?. Cheers,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433784029
https://github.com/su2code/SU2/pull/570#issuecomment-433963723:452,Energy Efficiency,allocate,allocated,452,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723
https://github.com/su2code/SU2/pull/570#issuecomment-433963723:300,Modifiability,variab,variables,300,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723
https://github.com/su2code/SU2/pull/570#issuecomment-433963723:77,Security,access,accessible,77,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723
https://github.com/su2code/SU2/pull/570#issuecomment-433963723:648,Usability,feedback,feedback,648,"Good point about making the eigen-functions static. That makes it a lot more accessible in other parts of the code. Will include that in the changes along with the option name changes. . I like the idea about the static allocation, but I foresee a problem that you actually mention. If I convert the variables to be statically defined, I would have to make the eigen-functions accept statically defined arrays. Since most arrays in SU2 are dynamically allocated, this would cause some compatibility issues. . In general, I see the value in making a math library associated with matrix operations. Maybe you could pitch the idea in an issue and get feedback on it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-433963723
https://github.com/su2code/SU2/pull/570#issuecomment-434001240:21,Performance,bottleneck,bottleneck,21,"If it ever becomes a bottleneck for my objectives with SU2, I will pitch it and work on it. Until then I have to develop and consolidate high level functionality.; I do not think anyone mentioned this in Glasgow so it is probably not an issue for anyone, it is just one of those nice things to have in place when you start writing code...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-434001240
https://github.com/su2code/SU2/pull/570#issuecomment-434551782:176,Availability,error,error,176,"Made the last of the changes that I wanted too in connection to the comments provided by @economon and @pcarruscag . Just as a review of the things I changed: . 1) Changed the error message; 2) Implemented the UQ methodology for a non-ideal fluid and for both gradient methods (AvgGrad and AvgCorrectedGrad). ; 3) generalized the eigen-decomposition functions for order n matrices. Also made the functions static so that they can be used without the need for an instantiation of the CNumerics class; 4) Improved performance by moving variable declarations to the class constructor for CNumerics; 5) Changed UQ config option names to be more specific. Added an output message for when people use the previous names.; 6) This instigated some changes to the TestCases config files, and to the compute_uncertainty.py script.; 7) Some general code clean up. Let me know if there are any other improvements that I should include.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-434551782
https://github.com/su2code/SU2/pull/570#issuecomment-434551782:182,Integrability,message,message,182,"Made the last of the changes that I wanted too in connection to the comments provided by @economon and @pcarruscag . Just as a review of the things I changed: . 1) Changed the error message; 2) Implemented the UQ methodology for a non-ideal fluid and for both gradient methods (AvgGrad and AvgCorrectedGrad). ; 3) generalized the eigen-decomposition functions for order n matrices. Also made the functions static so that they can be used without the need for an instantiation of the CNumerics class; 4) Improved performance by moving variable declarations to the class constructor for CNumerics; 5) Changed UQ config option names to be more specific. Added an output message for when people use the previous names.; 6) This instigated some changes to the TestCases config files, and to the compute_uncertainty.py script.; 7) Some general code clean up. Let me know if there are any other improvements that I should include.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-434551782
https://github.com/su2code/SU2/pull/570#issuecomment-434551782:667,Integrability,message,message,667,"Made the last of the changes that I wanted too in connection to the comments provided by @economon and @pcarruscag . Just as a review of the things I changed: . 1) Changed the error message; 2) Implemented the UQ methodology for a non-ideal fluid and for both gradient methods (AvgGrad and AvgCorrectedGrad). ; 3) generalized the eigen-decomposition functions for order n matrices. Also made the functions static so that they can be used without the need for an instantiation of the CNumerics class; 4) Improved performance by moving variable declarations to the class constructor for CNumerics; 5) Changed UQ config option names to be more specific. Added an output message for when people use the previous names.; 6) This instigated some changes to the TestCases config files, and to the compute_uncertainty.py script.; 7) Some general code clean up. Let me know if there are any other improvements that I should include.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-434551782
https://github.com/su2code/SU2/pull/570#issuecomment-434551782:534,Modifiability,variab,variable,534,"Made the last of the changes that I wanted too in connection to the comments provided by @economon and @pcarruscag . Just as a review of the things I changed: . 1) Changed the error message; 2) Implemented the UQ methodology for a non-ideal fluid and for both gradient methods (AvgGrad and AvgCorrectedGrad). ; 3) generalized the eigen-decomposition functions for order n matrices. Also made the functions static so that they can be used without the need for an instantiation of the CNumerics class; 4) Improved performance by moving variable declarations to the class constructor for CNumerics; 5) Changed UQ config option names to be more specific. Added an output message for when people use the previous names.; 6) This instigated some changes to the TestCases config files, and to the compute_uncertainty.py script.; 7) Some general code clean up. Let me know if there are any other improvements that I should include.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-434551782
https://github.com/su2code/SU2/pull/570#issuecomment-434551782:610,Modifiability,config,config,610,"Made the last of the changes that I wanted too in connection to the comments provided by @economon and @pcarruscag . Just as a review of the things I changed: . 1) Changed the error message; 2) Implemented the UQ methodology for a non-ideal fluid and for both gradient methods (AvgGrad and AvgCorrectedGrad). ; 3) generalized the eigen-decomposition functions for order n matrices. Also made the functions static so that they can be used without the need for an instantiation of the CNumerics class; 4) Improved performance by moving variable declarations to the class constructor for CNumerics; 5) Changed UQ config option names to be more specific. Added an output message for when people use the previous names.; 6) This instigated some changes to the TestCases config files, and to the compute_uncertainty.py script.; 7) Some general code clean up. Let me know if there are any other improvements that I should include.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-434551782
https://github.com/su2code/SU2/pull/570#issuecomment-434551782:765,Modifiability,config,config,765,"Made the last of the changes that I wanted too in connection to the comments provided by @economon and @pcarruscag . Just as a review of the things I changed: . 1) Changed the error message; 2) Implemented the UQ methodology for a non-ideal fluid and for both gradient methods (AvgGrad and AvgCorrectedGrad). ; 3) generalized the eigen-decomposition functions for order n matrices. Also made the functions static so that they can be used without the need for an instantiation of the CNumerics class; 4) Improved performance by moving variable declarations to the class constructor for CNumerics; 5) Changed UQ config option names to be more specific. Added an output message for when people use the previous names.; 6) This instigated some changes to the TestCases config files, and to the compute_uncertainty.py script.; 7) Some general code clean up. Let me know if there are any other improvements that I should include.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-434551782
https://github.com/su2code/SU2/pull/570#issuecomment-434551782:512,Performance,perform,performance,512,"Made the last of the changes that I wanted too in connection to the comments provided by @economon and @pcarruscag . Just as a review of the things I changed: . 1) Changed the error message; 2) Implemented the UQ methodology for a non-ideal fluid and for both gradient methods (AvgGrad and AvgCorrectedGrad). ; 3) generalized the eigen-decomposition functions for order n matrices. Also made the functions static so that they can be used without the need for an instantiation of the CNumerics class; 4) Improved performance by moving variable declarations to the class constructor for CNumerics; 5) Changed UQ config option names to be more specific. Added an output message for when people use the previous names.; 6) This instigated some changes to the TestCases config files, and to the compute_uncertainty.py script.; 7) Some general code clean up. Let me know if there are any other improvements that I should include.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-434551782
https://github.com/su2code/SU2/pull/570#issuecomment-434551782:755,Testability,Test,TestCases,755,"Made the last of the changes that I wanted too in connection to the comments provided by @economon and @pcarruscag . Just as a review of the things I changed: . 1) Changed the error message; 2) Implemented the UQ methodology for a non-ideal fluid and for both gradient methods (AvgGrad and AvgCorrectedGrad). ; 3) generalized the eigen-decomposition functions for order n matrices. Also made the functions static so that they can be used without the need for an instantiation of the CNumerics class; 4) Improved performance by moving variable declarations to the class constructor for CNumerics; 5) Changed UQ config option names to be more specific. Added an output message for when people use the previous names.; 6) This instigated some changes to the TestCases config files, and to the compute_uncertainty.py script.; 7) Some general code clean up. Let me know if there are any other improvements that I should include.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-434551782
https://github.com/su2code/SU2/pull/570#issuecomment-445302768:67,Testability,test,tests,67,"Yep, time to get this one in. After updating the statement and the tests pass, let's merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/570#issuecomment-445302768
https://github.com/su2code/SU2/pull/571#issuecomment-423573353:399,Availability,error,errors,399,"Hey Pedro, . we already chatted about this during the meeting. Thanks a lot for fixing the issue I mentioned above. . I gave it a shot to the test cases that I have locally and I also saw the same as you, this (very minor) discrepancies with the previous version, but as we spoke it totally looks like they are just numerics. . I have tested a case with FSI, where any major issue would show up and errors in the physics would rapidly accumulate, and instead the difference remains stable at the same order of magnitude (around the 6th significant figure) so in practice negligible. I'm approving the PR and, if there is no further comments, I will be merging it in next week. Thanks again!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/571#issuecomment-423573353
https://github.com/su2code/SU2/pull/571#issuecomment-423573353:142,Testability,test,test,142,"Hey Pedro, . we already chatted about this during the meeting. Thanks a lot for fixing the issue I mentioned above. . I gave it a shot to the test cases that I have locally and I also saw the same as you, this (very minor) discrepancies with the previous version, but as we spoke it totally looks like they are just numerics. . I have tested a case with FSI, where any major issue would show up and errors in the physics would rapidly accumulate, and instead the difference remains stable at the same order of magnitude (around the 6th significant figure) so in practice negligible. I'm approving the PR and, if there is no further comments, I will be merging it in next week. Thanks again!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/571#issuecomment-423573353
https://github.com/su2code/SU2/pull/571#issuecomment-423573353:335,Testability,test,tested,335,"Hey Pedro, . we already chatted about this during the meeting. Thanks a lot for fixing the issue I mentioned above. . I gave it a shot to the test cases that I have locally and I also saw the same as you, this (very minor) discrepancies with the previous version, but as we spoke it totally looks like they are just numerics. . I have tested a case with FSI, where any major issue would show up and errors in the physics would rapidly accumulate, and instead the difference remains stable at the same order of magnitude (around the 6th significant figure) so in practice negligible. I'm approving the PR and, if there is no further comments, I will be merging it in next week. Thanks again!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/571#issuecomment-423573353
https://github.com/su2code/SU2/pull/572#issuecomment-417633741:72,Availability,error,error,72,"Thanks a lot, @TobiKattmann, for this fix,. I was able to reproduce the error locally as well and the fix makes perfect sense to me. I've only added one small statement:; `config_container[iZone]->SetiInst(INST_0);`; to SU2_SOL in cases with single instance, to enforce that iInst = config->GetiInst() in CBaselineSolver::LoadRestart() receives the correct value. @economon as of now, I think there are no multizone-multiinstance cases available in develop. When that comes through, it would only require an extra loop on iInst and the correct setting of; `config_container[iZone]->SetiInst(iInst);`; in the very same fashion as it is done for harmonic balance (lines 357-380 in SU2_SOL.cpp). Then, inside the LoadRestart routine, the correct container position is read in line 3939 of solver_structure.cpp,; `unsigned short iInst = config->GetiInst();`; and used onwards. . I'll wait until the tests pass for this latest commit and then merge it in by Monday morning if there are no further comments.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/572#issuecomment-417633741
https://github.com/su2code/SU2/pull/572#issuecomment-417633741:436,Availability,avail,available,436,"Thanks a lot, @TobiKattmann, for this fix,. I was able to reproduce the error locally as well and the fix makes perfect sense to me. I've only added one small statement:; `config_container[iZone]->SetiInst(INST_0);`; to SU2_SOL in cases with single instance, to enforce that iInst = config->GetiInst() in CBaselineSolver::LoadRestart() receives the correct value. @economon as of now, I think there are no multizone-multiinstance cases available in develop. When that comes through, it would only require an extra loop on iInst and the correct setting of; `config_container[iZone]->SetiInst(iInst);`; in the very same fashion as it is done for harmonic balance (lines 357-380 in SU2_SOL.cpp). Then, inside the LoadRestart routine, the correct container position is read in line 3939 of solver_structure.cpp,; `unsigned short iInst = config->GetiInst();`; and used onwards. . I'll wait until the tests pass for this latest commit and then merge it in by Monday morning if there are no further comments.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/572#issuecomment-417633741
https://github.com/su2code/SU2/pull/572#issuecomment-417633741:722,Integrability,rout,routine,722,"Thanks a lot, @TobiKattmann, for this fix,. I was able to reproduce the error locally as well and the fix makes perfect sense to me. I've only added one small statement:; `config_container[iZone]->SetiInst(INST_0);`; to SU2_SOL in cases with single instance, to enforce that iInst = config->GetiInst() in CBaselineSolver::LoadRestart() receives the correct value. @economon as of now, I think there are no multizone-multiinstance cases available in develop. When that comes through, it would only require an extra loop on iInst and the correct setting of; `config_container[iZone]->SetiInst(iInst);`; in the very same fashion as it is done for harmonic balance (lines 357-380 in SU2_SOL.cpp). Then, inside the LoadRestart routine, the correct container position is read in line 3939 of solver_structure.cpp,; `unsigned short iInst = config->GetiInst();`; and used onwards. . I'll wait until the tests pass for this latest commit and then merge it in by Monday morning if there are no further comments.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/572#issuecomment-417633741
https://github.com/su2code/SU2/pull/572#issuecomment-417633741:283,Modifiability,config,config,283,"Thanks a lot, @TobiKattmann, for this fix,. I was able to reproduce the error locally as well and the fix makes perfect sense to me. I've only added one small statement:; `config_container[iZone]->SetiInst(INST_0);`; to SU2_SOL in cases with single instance, to enforce that iInst = config->GetiInst() in CBaselineSolver::LoadRestart() receives the correct value. @economon as of now, I think there are no multizone-multiinstance cases available in develop. When that comes through, it would only require an extra loop on iInst and the correct setting of; `config_container[iZone]->SetiInst(iInst);`; in the very same fashion as it is done for harmonic balance (lines 357-380 in SU2_SOL.cpp). Then, inside the LoadRestart routine, the correct container position is read in line 3939 of solver_structure.cpp,; `unsigned short iInst = config->GetiInst();`; and used onwards. . I'll wait until the tests pass for this latest commit and then merge it in by Monday morning if there are no further comments.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/572#issuecomment-417633741
https://github.com/su2code/SU2/pull/572#issuecomment-417633741:833,Modifiability,config,config,833,"Thanks a lot, @TobiKattmann, for this fix,. I was able to reproduce the error locally as well and the fix makes perfect sense to me. I've only added one small statement:; `config_container[iZone]->SetiInst(INST_0);`; to SU2_SOL in cases with single instance, to enforce that iInst = config->GetiInst() in CBaselineSolver::LoadRestart() receives the correct value. @economon as of now, I think there are no multizone-multiinstance cases available in develop. When that comes through, it would only require an extra loop on iInst and the correct setting of; `config_container[iZone]->SetiInst(iInst);`; in the very same fashion as it is done for harmonic balance (lines 357-380 in SU2_SOL.cpp). Then, inside the LoadRestart routine, the correct container position is read in line 3939 of solver_structure.cpp,; `unsigned short iInst = config->GetiInst();`; and used onwards. . I'll wait until the tests pass for this latest commit and then merge it in by Monday morning if there are no further comments.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/572#issuecomment-417633741
https://github.com/su2code/SU2/pull/572#issuecomment-417633741:322,Performance,Load,LoadRestart,322,"Thanks a lot, @TobiKattmann, for this fix,. I was able to reproduce the error locally as well and the fix makes perfect sense to me. I've only added one small statement:; `config_container[iZone]->SetiInst(INST_0);`; to SU2_SOL in cases with single instance, to enforce that iInst = config->GetiInst() in CBaselineSolver::LoadRestart() receives the correct value. @economon as of now, I think there are no multizone-multiinstance cases available in develop. When that comes through, it would only require an extra loop on iInst and the correct setting of; `config_container[iZone]->SetiInst(iInst);`; in the very same fashion as it is done for harmonic balance (lines 357-380 in SU2_SOL.cpp). Then, inside the LoadRestart routine, the correct container position is read in line 3939 of solver_structure.cpp,; `unsigned short iInst = config->GetiInst();`; and used onwards. . I'll wait until the tests pass for this latest commit and then merge it in by Monday morning if there are no further comments.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/572#issuecomment-417633741
https://github.com/su2code/SU2/pull/572#issuecomment-417633741:710,Performance,Load,LoadRestart,710,"Thanks a lot, @TobiKattmann, for this fix,. I was able to reproduce the error locally as well and the fix makes perfect sense to me. I've only added one small statement:; `config_container[iZone]->SetiInst(INST_0);`; to SU2_SOL in cases with single instance, to enforce that iInst = config->GetiInst() in CBaselineSolver::LoadRestart() receives the correct value. @economon as of now, I think there are no multizone-multiinstance cases available in develop. When that comes through, it would only require an extra loop on iInst and the correct setting of; `config_container[iZone]->SetiInst(iInst);`; in the very same fashion as it is done for harmonic balance (lines 357-380 in SU2_SOL.cpp). Then, inside the LoadRestart routine, the correct container position is read in line 3939 of solver_structure.cpp,; `unsigned short iInst = config->GetiInst();`; and used onwards. . I'll wait until the tests pass for this latest commit and then merge it in by Monday morning if there are no further comments.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/572#issuecomment-417633741
https://github.com/su2code/SU2/pull/572#issuecomment-417633741:895,Testability,test,tests,895,"Thanks a lot, @TobiKattmann, for this fix,. I was able to reproduce the error locally as well and the fix makes perfect sense to me. I've only added one small statement:; `config_container[iZone]->SetiInst(INST_0);`; to SU2_SOL in cases with single instance, to enforce that iInst = config->GetiInst() in CBaselineSolver::LoadRestart() receives the correct value. @economon as of now, I think there are no multizone-multiinstance cases available in develop. When that comes through, it would only require an extra loop on iInst and the correct setting of; `config_container[iZone]->SetiInst(iInst);`; in the very same fashion as it is done for harmonic balance (lines 357-380 in SU2_SOL.cpp). Then, inside the LoadRestart routine, the correct container position is read in line 3939 of solver_structure.cpp,; `unsigned short iInst = config->GetiInst();`; and used onwards. . I'll wait until the tests pass for this latest commit and then merge it in by Monday morning if there are no further comments.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/572#issuecomment-417633741
https://github.com/su2code/SU2/pull/573#issuecomment-423476470:317,Deployability,release,released,317,"Thanks, @jayantmukho ,; those changes should be reverted already. In my computer, bootstrap was not working for some reason, so I needed to have @talbring to run it in his and revert some of the changes. ; That said, I think we should look into moving to a newer version of automake. We are still maintaining 1.12.5 (released in 2012)...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/573#issuecomment-423476470
https://github.com/su2code/SU2/pull/574#issuecomment-418477655:183,Modifiability,config,configure,183,I forgot to mention that MPI-3 functionality is required for these changes. Can we assume that all practical MPI implementations support the MPI-3 standard or should we add a test in configure to check?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-418477655
https://github.com/su2code/SU2/pull/574#issuecomment-418477655:175,Testability,test,test,175,I forgot to mention that MPI-3 functionality is required for these changes. Can we assume that all practical MPI implementations support the MPI-3 standard or should we add a test in configure to check?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-418477655
https://github.com/su2code/SU2/pull/574#issuecomment-418669548:15,Availability,avail,availability,15,"I ifdeffed the availability of MPI_Ibarrier for checking whether the error call is collective. If MPI_Ibarrier is not present, there is a delay in the writing of the error message of 1 second (to make sure that the buffers for the one-sided communication are updated). If MPI_Ibarrier should be used when available (this is the cleaner solution), an additional check in configure must be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-418669548
https://github.com/su2code/SU2/pull/574#issuecomment-418669548:69,Availability,error,error,69,"I ifdeffed the availability of MPI_Ibarrier for checking whether the error call is collective. If MPI_Ibarrier is not present, there is a delay in the writing of the error message of 1 second (to make sure that the buffers for the one-sided communication are updated). If MPI_Ibarrier should be used when available (this is the cleaner solution), an additional check in configure must be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-418669548
https://github.com/su2code/SU2/pull/574#issuecomment-418669548:166,Availability,error,error,166,"I ifdeffed the availability of MPI_Ibarrier for checking whether the error call is collective. If MPI_Ibarrier is not present, there is a delay in the writing of the error message of 1 second (to make sure that the buffers for the one-sided communication are updated). If MPI_Ibarrier should be used when available (this is the cleaner solution), an additional check in configure must be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-418669548
https://github.com/su2code/SU2/pull/574#issuecomment-418669548:305,Availability,avail,available,305,"I ifdeffed the availability of MPI_Ibarrier for checking whether the error call is collective. If MPI_Ibarrier is not present, there is a delay in the writing of the error message of 1 second (to make sure that the buffers for the one-sided communication are updated). If MPI_Ibarrier should be used when available (this is the cleaner solution), an additional check in configure must be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-418669548
https://github.com/su2code/SU2/pull/574#issuecomment-418669548:259,Deployability,update,updated,259,"I ifdeffed the availability of MPI_Ibarrier for checking whether the error call is collective. If MPI_Ibarrier is not present, there is a delay in the writing of the error message of 1 second (to make sure that the buffers for the one-sided communication are updated). If MPI_Ibarrier should be used when available (this is the cleaner solution), an additional check in configure must be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-418669548
https://github.com/su2code/SU2/pull/574#issuecomment-418669548:172,Integrability,message,message,172,"I ifdeffed the availability of MPI_Ibarrier for checking whether the error call is collective. If MPI_Ibarrier is not present, there is a delay in the writing of the error message of 1 second (to make sure that the buffers for the one-sided communication are updated). If MPI_Ibarrier should be used when available (this is the cleaner solution), an additional check in configure must be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-418669548
https://github.com/su2code/SU2/pull/574#issuecomment-418669548:370,Modifiability,config,configure,370,"I ifdeffed the availability of MPI_Ibarrier for checking whether the error call is collective. If MPI_Ibarrier is not present, there is a delay in the writing of the error message of 1 second (to make sure that the buffers for the one-sided communication are updated). If MPI_Ibarrier should be used when available (this is the cleaner solution), an additional check in configure must be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-418669548
https://github.com/su2code/SU2/pull/574#issuecomment-419714459:101,Availability,avail,available,101,Thanks @vdweide. This looks like a good solution. I think we could determine whether MPI_IBarrier is available or not from the version macro that the MPI implementations provide.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-419714459
https://github.com/su2code/SU2/pull/574#issuecomment-419802820:44,Modifiability,config,configure,44,"@talbring, is it easy to add such a test to configure? I have no idea how to do this to be honest?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-419802820
https://github.com/su2code/SU2/pull/574#issuecomment-419802820:36,Testability,test,test,36,"@talbring, is it easy to add such a test to configure? I have no idea how to do this to be honest?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-419802820
https://github.com/su2code/SU2/pull/574#issuecomment-419880168:17,Modifiability,config,configure,17,"If modifying the configure is necessary, I can help with that, but I think Tim is suggesting we just use the MPI_VERSION macro that is already defined by the implementations within the C++ (correct me if I am wrong). So, we could check for MPI_VERSION > 3, for instance. However, I think that in some older implementations this may not be defined, in which case we should default to something safe.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-419880168
https://github.com/su2code/SU2/pull/574#issuecomment-419880168:393,Safety,safe,safe,393,"If modifying the configure is necessary, I can help with that, but I think Tim is suggesting we just use the MPI_VERSION macro that is already defined by the implementations within the C++ (correct me if I am wrong). So, we could check for MPI_VERSION > 3, for instance. However, I think that in some older implementations this may not be defined, in which case we should default to something safe.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-419880168
https://github.com/su2code/SU2/pull/574#issuecomment-419898440:233,Testability,test,tests,233,"According to the MPI standard the macro MPI_VERSION should be defined. However, even if it is not defined, the MPI_Ibarrier will not be called. This is exactly what you want. I'll push these changes shortly and see if the regression tests go through.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/574#issuecomment-419898440
https://github.com/su2code/SU2/pull/575#issuecomment-418860081:237,Modifiability,layers,layers,237,"The behavior can be seen in the backward facing step case, as shown in a snapshot below. As currently set up, `Roe_Dissipation` is equal to `f_d` from the original DDES paper. So `Roe_Dissipation` should:. + Go to 0 in attached boundary layers; + Go to 1 in regions with resolved turbulent fluctuations. Here's a comparison of the `Roe_Dissipation` before and after this PR:. ![viscosity_comparison](https://user-images.githubusercontent.com/13340225/45117324-e5f36600-b11a-11e8-8194-fac45dff0edf.png). Here's the same case, but zoomed in at the step:. ![viscosity_comparison_zoom](https://user-images.githubusercontent.com/13340225/45117474-5ac6a000-b11b-11e8-94ab-5bd203aa5845.png). With this PR, the model does indeed go to 0 near the walls and go to 1 in the highly unsteady (""LES"") region after the step.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/575#issuecomment-418860081
https://github.com/su2code/SU2/pull/575#issuecomment-418873597:237,Energy Efficiency,power,power,237,"@vdweide It's easy to do, so I'll show the dimensional analysis here. I'll use L for length, T for time, and M for mass. The original paper defined `r_d`, which is supposed to be a nondimensional parameter. (`r_d` gets raised to the 3rd power and put into a hyperbolic tangent, so it would be messy if it were dimensional). In the code you'll see:. r_d = (nu + nu_t)/(uijuij*k2*pow(val_wall_dist, 2.0));. where `nu` is the kinematic viscosity, `nu_t` is the kinematic eddy viscosity, `uijuij` is the magnitude of the velocity gradient tensor, k2 is the square of the von-Karman constant, and `val_wall_dist` is the wall distance. + `nu` has units of L^2/T; + `nu_t` has units of L^2/T; + `uijuij` has units of 1/T; + `val_wall_dist` has units of L. So if you do the math, `r_d` has units of L^/T in the numerator and L^2/T in the denominator. `r_d` is nondimensional. If you switch `nu` and `nu_t` from kinematic viscosities to dynamic viscosities, you get that `r_d` has units matching density, or M/L^3. That's obviously not correct.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/575#issuecomment-418873597
https://github.com/su2code/SU2/pull/576#issuecomment-425256907:40,Testability,test,test,40,"Looks good to me now. If the regression test go through, it can be merged in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/576#issuecomment-425256907
https://github.com/su2code/SU2/pull/577#issuecomment-419661485:270,Modifiability,layers,layers,270,"#### Verification. The NTS method sets the value of the `Roe_Dissipation`, or the central/upwind blending constant. In this context, 1 = upwind scheme, 0 = central scheme. The NTS method was explicitly designed to make `Roe_Dissipation`:. + Go to 1 in attached boundary layers; + Go to 1 in irrotational regions, even if strain is present (i.e., the freestream); + Go to 0 in regions with high vorticity. Below is an example result from the backward facing step problem. The figure compares the current develop branch with the branch from the PR. Something definitely looks wrong with the current develop branch, but the PR looks much better. All three goals seem to be met. ![nts_comparison](https://user-images.githubusercontent.com/13340225/45257129-ccdef500-b366-11e8-88b6-a1d1df38e8fc.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/577#issuecomment-419661485
https://github.com/su2code/SU2/pull/577#issuecomment-423204225:58,Testability,test,test,58,"@talbring Last I heard, @EduardoMolina was going to run a test on this branch to check it. Aside from that, there's nothing left to complete on my side.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/577#issuecomment-423204225
https://github.com/su2code/SU2/pull/579#issuecomment-425754699:150,Usability,undo,undo,150,"Those changes in option_structure.hpp were actually done to the main branch by somebody else. I forked from main, and merged develop. I can of course undo them, if you want (or rebase my commit on develop instead of merging).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/579#issuecomment-425754699
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:1410,Availability,avail,available,1410,"uction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Dif",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:241,Deployability,configurat,configuration,241,"Hi Jayant; Thanks for being so prompt and fast in handling this very important issue.; Im currently in vacation at Scotland so Ill be brief and just add few; comments:; a. As you wrote, validation is very different from test cases. Mesh,; configuration and solutions should be optimized for accuracy, experiment; reproduction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familia",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:1284,Deployability,configurat,configuration,1284,"uction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Dif",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:3050,Deployability,configurat,configuration,3050,"able). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoil; > 9. 30P30N High Lift airfoil; > 10. ONERAM6 Wing; > 11. NASA CRM; > 12. Subsonic and Supersonic Jets; >; > It would be ideal for these test cases to have either high-fidelity data; > (wind tunnel tests, or LES/DNS data), and/or published results of other; > solvers so that comparisons can be made.; >; > I also want to point out the difference between this and the TestCases; > repository. The TestCases repo is used in regression tests to ensure that; > parts of the code don't break when changes are made. This is more a test of; > SU2's fidelity. It would feature large grids and configuration files that; > can be run to convergence.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm0MgSdkhQbG8dvGsdxlxIf9pa1xsks5ucppYgaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:651,Integrability,depend,dependent,651,"Hi Jayant; Thanks for being so prompt and fast in handling this very important issue.; Im currently in vacation at Scotland so Ill be brief and just add few; comments:; a. As you wrote, validation is very different from test cases. Mesh,; configuration and solutions should be optimized for accuracy, experiment; reproduction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familia",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:241,Modifiability,config,configuration,241,"Hi Jayant; Thanks for being so prompt and fast in handling this very important issue.; Im currently in vacation at Scotland so Ill be brief and just add few; comments:; a. As you wrote, validation is very different from test cases. Mesh,; configuration and solutions should be optimized for accuracy, experiment; reproduction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familia",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:1284,Modifiability,config,configuration,1284,"uction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Dif",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:3050,Modifiability,config,configuration,3050,"able). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoil; > 9. 30P30N High Lift airfoil; > 10. ONERAM6 Wing; > 11. NASA CRM; > 12. Subsonic and Supersonic Jets; >; > It would be ideal for these test cases to have either high-fidelity data; > (wind tunnel tests, or LES/DNS data), and/or published results of other; > solvers so that comparisons can be made.; >; > I also want to point out the difference between this and the TestCases; > repository. The TestCases repo is used in regression tests to ensure that; > parts of the code don't break when changes are made. This is more a test of; > SU2's fidelity. It would feature large grids and configuration files that; > can be run to convergence.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm0MgSdkhQbG8dvGsdxlxIf9pa1xsks5ucppYgaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:279,Performance,optimiz,optimized,279,"Hi Jayant; Thanks for being so prompt and fast in handling this very important issue.; Im currently in vacation at Scotland so Ill be brief and just add few; comments:; a. As you wrote, validation is very different from test cases. Mesh,; configuration and solutions should be optimized for accuracy, experiment; reproduction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familia",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:332,Performance,perform,performance,332,"Hi Jayant; Thanks for being so prompt and fast in handling this very important issue.; Im currently in vacation at Scotland so Ill be brief and just add few; comments:; a. As you wrote, validation is very different from test cases. Mesh,; configuration and solutions should be optimized for accuracy, experiment; reproduction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familia",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:1053,Performance,perform,performance,1053,"Hi Jayant; Thanks for being so prompt and fast in handling this very important issue.; Im currently in vacation at Scotland so Ill be brief and just add few; comments:; a. As you wrote, validation is very different from test cases. Mesh,; configuration and solutions should be optimized for accuracy, experiment; reproduction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familia",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:1344,Performance,perform,performance,1344,"uction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Dif",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:1455,Performance,perform,performance,1455,"n let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:188,Security,validat,validation,188,"Hi Jayant; Thanks for being so prompt and fast in handling this very important issue.; Im currently in vacation at Scotland so Ill be brief and just add few; comments:; a. As you wrote, validation is very different from test cases. Mesh,; configuration and solutions should be optimized for accuracy, experiment; reproduction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familia",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:386,Security,validat,validation,386,"Hi Jayant; Thanks for being so prompt and fast in handling this very important issue.; Im currently in vacation at Scotland so Ill be brief and just add few; comments:; a. As you wrote, validation is very different from test cases. Mesh,; configuration and solutions should be optimized for accuracy, experiment; reproduction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familia",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:1744,Security,validat,validation,1744," to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoil; > 9. 30P30N High Lift airfoil; > 10. ONERAM6 Wing; > 11. NASA CRM; > 12. Subsonic and Supersonic Jets; >; > It would be ideal for these test cases to have either high-fidelity data; > (wind tunnel tests, or LES/DNS data), and/or published results of oth",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:222,Testability,test,test,222,"Hi Jayant; Thanks for being so prompt and fast in handling this very important issue.; Im currently in vacation at Scotland so Ill be brief and just add few; comments:; a. As you wrote, validation is very different from test cases. Mesh,; configuration and solutions should be optimized for accuracy, experiment; reproduction and performance.; b. I think it is important to start the validation project, create a link; from the main SU2 web page to it, and than let it grow with the existing; mechanism of community contributions with approvals. Your list is very fine; for beginning. However I think we should strive to enrich it with 3D and; time dependent cases. I hope to be able to be in the loop and contribute to this important venue; Best; Eran; On Wed, Sep 19, 2018 at 8:26 PM Jayant Mukhopadhaya <; notifications@github.com> wrote:. > Hey everyone,; >; > Following the discussions at the SU2 Developers meeting this week, I; > wanted to start a conversation about compiling a comprehensive set of V&V; > cases for SU2 that can showcase it's performance in comparison to other; > solvers.; >; > I think the the NASA TMR website; > <https://turbmodels.larc.nasa.gov/index.html> is a good model to base it; > on. The idea would be to present the V&V case, provide working; > configuration and mesh files, and provide results comparing performance to; > other solvers and to higher fidelity data (when available). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familia",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:2601,Testability,test,test,2601,"able). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoil; > 9. 30P30N High Lift airfoil; > 10. ONERAM6 Wing; > 11. NASA CRM; > 12. Subsonic and Supersonic Jets; >; > It would be ideal for these test cases to have either high-fidelity data; > (wind tunnel tests, or LES/DNS data), and/or published results of other; > solvers so that comparisons can be made.; >; > I also want to point out the difference between this and the TestCases; > repository. The TestCases repo is used in regression tests to ensure that; > parts of the code don't break when changes are made. This is more a test of; > SU2's fidelity. It would feature large grids and configuration files that; > can be run to convergence.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm0MgSdkhQbG8dvGsdxlxIf9pa1xsks5ucppYgaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:2662,Testability,test,tests,2662,"able). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoil; > 9. 30P30N High Lift airfoil; > 10. ONERAM6 Wing; > 11. NASA CRM; > 12. Subsonic and Supersonic Jets; >; > It would be ideal for these test cases to have either high-fidelity data; > (wind tunnel tests, or LES/DNS data), and/or published results of other; > solvers so that comparisons can be made.; >; > I also want to point out the difference between this and the TestCases; > repository. The TestCases repo is used in regression tests to ensure that; > parts of the code don't break when changes are made. This is more a test of; > SU2's fidelity. It would feature large grids and configuration files that; > can be run to convergence.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm0MgSdkhQbG8dvGsdxlxIf9pa1xsks5ucppYgaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:2832,Testability,Test,TestCases,2832,"able). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoil; > 9. 30P30N High Lift airfoil; > 10. ONERAM6 Wing; > 11. NASA CRM; > 12. Subsonic and Supersonic Jets; >; > It would be ideal for these test cases to have either high-fidelity data; > (wind tunnel tests, or LES/DNS data), and/or published results of other; > solvers so that comparisons can be made.; >; > I also want to point out the difference between this and the TestCases; > repository. The TestCases repo is used in regression tests to ensure that; > parts of the code don't break when changes are made. This is more a test of; > SU2's fidelity. It would feature large grids and configuration files that; > can be run to convergence.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm0MgSdkhQbG8dvGsdxlxIf9pa1xsks5ucppYgaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:2861,Testability,Test,TestCases,2861,"able). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoil; > 9. 30P30N High Lift airfoil; > 10. ONERAM6 Wing; > 11. NASA CRM; > 12. Subsonic and Supersonic Jets; >; > It would be ideal for these test cases to have either high-fidelity data; > (wind tunnel tests, or LES/DNS data), and/or published results of other; > solvers so that comparisons can be made.; >; > I also want to point out the difference between this and the TestCases; > repository. The TestCases repo is used in regression tests to ensure that; > parts of the code don't break when changes are made. This is more a test of; > SU2's fidelity. It would feature large grids and configuration files that; > can be run to convergence.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm0MgSdkhQbG8dvGsdxlxIf9pa1xsks5ucppYgaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:2898,Testability,test,tests,2898,"able). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoil; > 9. 30P30N High Lift airfoil; > 10. ONERAM6 Wing; > 11. NASA CRM; > 12. Subsonic and Supersonic Jets; >; > It would be ideal for these test cases to have either high-fidelity data; > (wind tunnel tests, or LES/DNS data), and/or published results of other; > solvers so that comparisons can be made.; >; > I also want to point out the difference between this and the TestCases; > repository. The TestCases repo is used in regression tests to ensure that; > parts of the code don't break when changes are made. This is more a test of; > SU2's fidelity. It would feature large grids and configuration files that; > can be run to convergence.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm0MgSdkhQbG8dvGsdxlxIf9pa1xsks5ucppYgaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423070900:2990,Testability,test,test,2990,"able). This allows; > people to see the performance of SU2 and replicate it, if need be.; >; > The first step would be compiling a list of cases that should be covered.; > The SU2 2014 SciTech paper; > <https://su2code.github.io/documents/SU2_AIAA_SciTech2014.pdf> would be a; > good starting point as it already had a couple of validation cases. This; > list can be bolstered with some of the NASA TMR cases, and with grid; > convergence studies. I would like to propose an initial list that the; > community can talk through and make changes as we see fit. I am mostly only; > familiar with canonical CFD flows that are used in these cases. But it; > would be great to have other cases, such as Turbo-machinary or FSI cases,; > that show the full breadth of SU2's abilities. This is by no means an; > exhaustive list:; >; > 1. Zero Gradient Flat Plate; > 2. 2D and 3D Bump in Channel; > 3. Asymmetric Diffuser; > 4. Backward facing step; > 5. Unsteady Square cylinder; > 6. NACA0012; > 7. NACA4412 Trailing Edge Seperation; > 8. Joukowski Airfoil; > 9. 30P30N High Lift airfoil; > 10. ONERAM6 Wing; > 11. NASA CRM; > 12. Subsonic and Supersonic Jets; >; > It would be ideal for these test cases to have either high-fidelity data; > (wind tunnel tests, or LES/DNS data), and/or published results of other; > solvers so that comparisons can be made.; >; > I also want to point out the difference between this and the TestCases; > repository. The TestCases repo is used in regression tests to ensure that; > parts of the code don't break when changes are made. This is more a test of; > SU2's fidelity. It would feature large grids and configuration files that; > can be run to convergence.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm0MgSdkhQbG8dvGsdxlxIf9pa1xsks5ucppYgaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423070900
https://github.com/su2code/SU2/issues/581#issuecomment-423119881:89,Deployability,release,release,89,"Just one thought on this. I think it would be nice to run the validation suite for every release, that would force us to keep the configurations up to date, and provide an extra level of quality assurance. Most of the cases will be too expensive for travis but hopefully the computational burden can be spread over the community.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423119881
https://github.com/su2code/SU2/issues/581#issuecomment-423119881:130,Deployability,configurat,configurations,130,"Just one thought on this. I think it would be nice to run the validation suite for every release, that would force us to keep the configurations up to date, and provide an extra level of quality assurance. Most of the cases will be too expensive for travis but hopefully the computational burden can be spread over the community.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423119881
https://github.com/su2code/SU2/issues/581#issuecomment-423119881:130,Modifiability,config,configurations,130,"Just one thought on this. I think it would be nice to run the validation suite for every release, that would force us to keep the configurations up to date, and provide an extra level of quality assurance. Most of the cases will be too expensive for travis but hopefully the computational burden can be spread over the community.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423119881
https://github.com/su2code/SU2/issues/581#issuecomment-423119881:62,Security,validat,validation,62,"Just one thought on this. I think it would be nice to run the validation suite for every release, that would force us to keep the configurations up to date, and provide an extra level of quality assurance. Most of the cases will be too expensive for travis but hopefully the computational burden can be spread over the community.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423119881
https://github.com/su2code/SU2/issues/581#issuecomment-423122949:434,Availability,avail,available,434,"Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423122949
https://github.com/su2code/SU2/issues/581#issuecomment-423122949:197,Deployability,release,release,197,"Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423122949
https://github.com/su2code/SU2/issues/581#issuecomment-423122949:322,Deployability,release,released,322,"Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423122949
https://github.com/su2code/SU2/issues/581#issuecomment-423122949:387,Deployability,update,updates,387,"Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423122949
https://github.com/su2code/SU2/issues/581#issuecomment-423122949:229,Safety,avoid,avoiding,229,"Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423122949
https://github.com/su2code/SU2/issues/581#issuecomment-423122949:90,Testability,log,logistics,90,"Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423122949
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:1861,Availability,avail,available,1861,"es are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/581#issuecomment-423122949>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJzh9dwbOM_5DoymCA6lAIqv3biyks5uc2eqgaJpZM4Ww0V4>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:611,Deployability,configurat,configuration,611,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:831,Deployability,release,release,831,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:845,Deployability,configurat,configuration,845,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:865,Deployability,update,updated,865,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:1624,Deployability,release,release,1624,"es are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/581#issuecomment-423122949>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJzh9dwbOM_5DoymCA6lAIqv3biyks5uc2eqgaJpZM4Ww0V4>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:1749,Deployability,release,released,1749,"es are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/581#issuecomment-423122949>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJzh9dwbOM_5DoymCA6lAIqv3biyks5uc2eqgaJpZM4Ww0V4>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:1814,Deployability,update,updates,1814,"es are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/581#issuecomment-423122949>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJzh9dwbOM_5DoymCA6lAIqv3biyks5uc2eqgaJpZM4Ww0V4>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:611,Modifiability,config,configuration,611,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:845,Modifiability,config,configuration,845,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:1656,Safety,avoid,avoiding,1656,"es are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/581#issuecomment-423122949>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJzh9dwbOM_5DoymCA6lAIqv3biyks5uc2eqgaJpZM4Ww0V4>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:198,Security,validat,validation,198,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:1087,Security,access,access,1087,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:93,Testability,Test,TestCases,93,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:173,Testability,Test,TestCases,173,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:243,Testability,test,test,243,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:261,Testability,Test,TestCases,261,"All,. Thanks for getting this going. My two cents:. 1. Indeed, while these V&V cases and the TestCases directory / repo are not identical, there is some overlapsome of the TestCases are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://git",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423207120:1517,Testability,log,logistics,1517,"es are definitely validation cases too. We can continue to add test cases to the TestCases repo, knowing that only a subset of those cases belong in the V&V list. 2. An important aspect of the V&V is the convergence of the solution as the mesh is refined. As Jayant knows well, this can help us catch bugs. This means that a well-constructed V&V suite needs to include a series of meshes (of increasing density), the corresponding configuration files, and the actual experimental data (or other numerical data from runs on different solvers). I strongly agree with the suggestions made that (a) the entire V&V suite needs to be run before every major release (with configuration files updated), (b) that this should be linked form the main SU2 page, (c) that the 2014 AIAA paper (and Toms AVIATION 2018 paper) should serve as a starting point, (d) that the NASA TMR website can give us ideas of additional access, and (e) that the SU2 V&V page should be managed within GitHub.com<http://GitHub.com> so the entire community can edit / add to this / these page/s to continue to grow the number of cases and their relevance. Best,. Juan. On Sep 20, 2018, at 3:02 AM, Ruben Sanchez <notifications@github.com<mailto:notifications@github.com>> wrote:. Thanks, Pedro, I think that's a great idea. As you mention, we would have to work out the logistics as this would require quite a bit of implication from the community, but the extra burden on the release would be compensated by avoiding big ""updating"" operations every now and then. Also as most users only work with the released versions, so it's a way to ensure they always know what updates have happened / which new features are available. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/581#issuecomment-423122949>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJzh9dwbOM_5DoymCA6lAIqv3biyks5uc2eqgaJpZM4Ww0V4>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423207120
https://github.com/su2code/SU2/issues/581#issuecomment-423260699:303,Modifiability,config,config,303,"All, . Regarding the steady test cases, Embraer folks published a paper of their efforts to validate SU2 using the DPW and HLPW geometries (https://doi.org/10.2514/6.2018-2845 <https://doi.org/10.2514/6.2018-2845>) in the last AVIATION. I think that they will be happy to contribute with the meshes and config files. . Also, I can contribute with some unsteady cases. I think that the Backward Facing Step and the Tandem Cylinder test cases are a good start. Best,. Eduardo; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/issues/581#issuecomment-423207120>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AJVmCdByjE1ogiSKp7fIos58GcRe-Rdlks5uc6e0gaJpZM4Ww0V4>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423260699
https://github.com/su2code/SU2/issues/581#issuecomment-423260699:92,Security,validat,validate,92,"All, . Regarding the steady test cases, Embraer folks published a paper of their efforts to validate SU2 using the DPW and HLPW geometries (https://doi.org/10.2514/6.2018-2845 <https://doi.org/10.2514/6.2018-2845>) in the last AVIATION. I think that they will be happy to contribute with the meshes and config files. . Also, I can contribute with some unsteady cases. I think that the Backward Facing Step and the Tandem Cylinder test cases are a good start. Best,. Eduardo; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/issues/581#issuecomment-423207120>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AJVmCdByjE1ogiSKp7fIos58GcRe-Rdlks5uc6e0gaJpZM4Ww0V4>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423260699
https://github.com/su2code/SU2/issues/581#issuecomment-423260699:28,Testability,test,test,28,"All, . Regarding the steady test cases, Embraer folks published a paper of their efforts to validate SU2 using the DPW and HLPW geometries (https://doi.org/10.2514/6.2018-2845 <https://doi.org/10.2514/6.2018-2845>) in the last AVIATION. I think that they will be happy to contribute with the meshes and config files. . Also, I can contribute with some unsteady cases. I think that the Backward Facing Step and the Tandem Cylinder test cases are a good start. Best,. Eduardo; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/issues/581#issuecomment-423207120>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AJVmCdByjE1ogiSKp7fIos58GcRe-Rdlks5uc6e0gaJpZM4Ww0V4>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423260699
https://github.com/su2code/SU2/issues/581#issuecomment-423260699:430,Testability,test,test,430,"All, . Regarding the steady test cases, Embraer folks published a paper of their efforts to validate SU2 using the DPW and HLPW geometries (https://doi.org/10.2514/6.2018-2845 <https://doi.org/10.2514/6.2018-2845>) in the last AVIATION. I think that they will be happy to contribute with the meshes and config files. . Also, I can contribute with some unsteady cases. I think that the Backward Facing Step and the Tandem Cylinder test cases are a good start. Best,. Eduardo; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/issues/581#issuecomment-423207120>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AJVmCdByjE1ogiSKp7fIos58GcRe-Rdlks5uc6e0gaJpZM4Ww0V4>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423260699
https://github.com/su2code/SU2/issues/581#issuecomment-423273117:99,Deployability,release,release,99,"Hi All; Im a bit worried about the logistics related to checking this v&v data base for every new release.; Unlike the tutorials, these cases, by their nature will be large and will require long integrations(the 2D cases might not fall on this category). This means also that significant computational resources will be required for this evaluation (about twice a year for a growing list of cases). Is it practical?; The only way that I think that it might work is that each contributor will be responsible for checking the casesthat he has introduced, before each release. Being a voluntary institution, this can not be enforced (and we do not want to enforce). How about trying to be less demanding:; In each validation case there will be a statement about the last version that it was checked with and the responsible contributor. Each contributor will receive a recommendation to check his cases before a new release, and will be able to do that and update the OK label also after the release.; Less waterproof but might be more workable.; What do you think?; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423273117
https://github.com/su2code/SU2/issues/581#issuecomment-423273117:196,Deployability,integrat,integrations,196,"Hi All; Im a bit worried about the logistics related to checking this v&v data base for every new release.; Unlike the tutorials, these cases, by their nature will be large and will require long integrations(the 2D cases might not fall on this category). This means also that significant computational resources will be required for this evaluation (about twice a year for a growing list of cases). Is it practical?; The only way that I think that it might work is that each contributor will be responsible for checking the casesthat he has introduced, before each release. Being a voluntary institution, this can not be enforced (and we do not want to enforce). How about trying to be less demanding:; In each validation case there will be a statement about the last version that it was checked with and the responsible contributor. Each contributor will receive a recommendation to check his cases before a new release, and will be able to do that and update the OK label also after the release.; Less waterproof but might be more workable.; What do you think?; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423273117
https://github.com/su2code/SU2/issues/581#issuecomment-423273117:566,Deployability,release,release,566,"Hi All; Im a bit worried about the logistics related to checking this v&v data base for every new release.; Unlike the tutorials, these cases, by their nature will be large and will require long integrations(the 2D cases might not fall on this category). This means also that significant computational resources will be required for this evaluation (about twice a year for a growing list of cases). Is it practical?; The only way that I think that it might work is that each contributor will be responsible for checking the casesthat he has introduced, before each release. Being a voluntary institution, this can not be enforced (and we do not want to enforce). How about trying to be less demanding:; In each validation case there will be a statement about the last version that it was checked with and the responsible contributor. Each contributor will receive a recommendation to check his cases before a new release, and will be able to do that and update the OK label also after the release.; Less waterproof but might be more workable.; What do you think?; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423273117
https://github.com/su2code/SU2/issues/581#issuecomment-423273117:914,Deployability,release,release,914,"Hi All; Im a bit worried about the logistics related to checking this v&v data base for every new release.; Unlike the tutorials, these cases, by their nature will be large and will require long integrations(the 2D cases might not fall on this category). This means also that significant computational resources will be required for this evaluation (about twice a year for a growing list of cases). Is it practical?; The only way that I think that it might work is that each contributor will be responsible for checking the casesthat he has introduced, before each release. Being a voluntary institution, this can not be enforced (and we do not want to enforce). How about trying to be less demanding:; In each validation case there will be a statement about the last version that it was checked with and the responsible contributor. Each contributor will receive a recommendation to check his cases before a new release, and will be able to do that and update the OK label also after the release.; Less waterproof but might be more workable.; What do you think?; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423273117
https://github.com/su2code/SU2/issues/581#issuecomment-423273117:955,Deployability,update,update,955,"Hi All; Im a bit worried about the logistics related to checking this v&v data base for every new release.; Unlike the tutorials, these cases, by their nature will be large and will require long integrations(the 2D cases might not fall on this category). This means also that significant computational resources will be required for this evaluation (about twice a year for a growing list of cases). Is it practical?; The only way that I think that it might work is that each contributor will be responsible for checking the casesthat he has introduced, before each release. Being a voluntary institution, this can not be enforced (and we do not want to enforce). How about trying to be less demanding:; In each validation case there will be a statement about the last version that it was checked with and the responsible contributor. Each contributor will receive a recommendation to check his cases before a new release, and will be able to do that and update the OK label also after the release.; Less waterproof but might be more workable.; What do you think?; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423273117
https://github.com/su2code/SU2/issues/581#issuecomment-423273117:990,Deployability,release,release,990,"Hi All; Im a bit worried about the logistics related to checking this v&v data base for every new release.; Unlike the tutorials, these cases, by their nature will be large and will require long integrations(the 2D cases might not fall on this category). This means also that significant computational resources will be required for this evaluation (about twice a year for a growing list of cases). Is it practical?; The only way that I think that it might work is that each contributor will be responsible for checking the casesthat he has introduced, before each release. Being a voluntary institution, this can not be enforced (and we do not want to enforce). How about trying to be less demanding:; In each validation case there will be a statement about the last version that it was checked with and the responsible contributor. Each contributor will receive a recommendation to check his cases before a new release, and will be able to do that and update the OK label also after the release.; Less waterproof but might be more workable.; What do you think?; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423273117
https://github.com/su2code/SU2/issues/581#issuecomment-423273117:196,Integrability,integrat,integrations,196,"Hi All; Im a bit worried about the logistics related to checking this v&v data base for every new release.; Unlike the tutorials, these cases, by their nature will be large and will require long integrations(the 2D cases might not fall on this category). This means also that significant computational resources will be required for this evaluation (about twice a year for a growing list of cases). Is it practical?; The only way that I think that it might work is that each contributor will be responsible for checking the casesthat he has introduced, before each release. Being a voluntary institution, this can not be enforced (and we do not want to enforce). How about trying to be less demanding:; In each validation case there will be a statement about the last version that it was checked with and the responsible contributor. Each contributor will receive a recommendation to check his cases before a new release, and will be able to do that and update the OK label also after the release.; Less waterproof but might be more workable.; What do you think?; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423273117
https://github.com/su2code/SU2/issues/581#issuecomment-423273117:712,Security,validat,validation,712,"Hi All; Im a bit worried about the logistics related to checking this v&v data base for every new release.; Unlike the tutorials, these cases, by their nature will be large and will require long integrations(the 2D cases might not fall on this category). This means also that significant computational resources will be required for this evaluation (about twice a year for a growing list of cases). Is it practical?; The only way that I think that it might work is that each contributor will be responsible for checking the casesthat he has introduced, before each release. Being a voluntary institution, this can not be enforced (and we do not want to enforce). How about trying to be less demanding:; In each validation case there will be a statement about the last version that it was checked with and the responsible contributor. Each contributor will receive a recommendation to check his cases before a new release, and will be able to do that and update the OK label also after the release.; Less waterproof but might be more workable.; What do you think?; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423273117
https://github.com/su2code/SU2/issues/581#issuecomment-423273117:36,Testability,log,logistics,36,"Hi All; Im a bit worried about the logistics related to checking this v&v data base for every new release.; Unlike the tutorials, these cases, by their nature will be large and will require long integrations(the 2D cases might not fall on this category). This means also that significant computational resources will be required for this evaluation (about twice a year for a growing list of cases). Is it practical?; The only way that I think that it might work is that each contributor will be responsible for checking the casesthat he has introduced, before each release. Being a voluntary institution, this can not be enforced (and we do not want to enforce). How about trying to be less demanding:; In each validation case there will be a statement about the last version that it was checked with and the responsible contributor. Each contributor will receive a recommendation to check his cases before a new release, and will be able to do that and update the OK label also after the release.; Less waterproof but might be more workable.; What do you think?; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423273117
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:154,Deployability,release,releases,154,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:299,Deployability,release,releases,299,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:1049,Deployability,release,release,1049,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:1151,Deployability,integrat,integrations,1151,"to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterproof but might be more workable.; > What do you think?; > Eran; >; > ; > You are receiving this because you are subscribed to this thr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:1538,Deployability,release,release,1538," that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterproof but might be more workable.; > What do you think?; > Eran; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581#issuecomment-423273117>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AE7akEt5omvVYLjMzzdaTQ6jgPza0N4wks5uc9R-gaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:1897,Deployability,release,release,1897," that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterproof but might be more workable.; > What do you think?; > Eran; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581#issuecomment-423273117>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AE7akEt5omvVYLjMzzdaTQ6jgPza0N4wks5uc9R-gaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:1941,Deployability,update,update,1941," that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterproof but might be more workable.; > What do you think?; > Eran; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581#issuecomment-423273117>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AE7akEt5omvVYLjMzzdaTQ6jgPza0N4wks5uc9R-gaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:1976,Deployability,release,release,1976," that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterproof but might be more workable.; > What do you think?; > Eran; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581#issuecomment-423273117>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AE7akEt5omvVYLjMzzdaTQ6jgPza0N4wks5uc9R-gaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:476,Energy Efficiency,reduce,reduce,476,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:1151,Integrability,integrat,integrations,1151,"to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterproof but might be more workable.; > What do you think?; > Eran; >; > ; > You are receiving this because you are subscribed to this thr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:488,Safety,risk,risk,488,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:1689,Security,validat,validation,1689," that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterproof but might be more workable.; > What do you think?; > Eran; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/581#issuecomment-423273117>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AE7akEt5omvVYLjMzzdaTQ6jgPza0N4wks5uc9R-gaJpZM4Ww0V4>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:317,Testability,test,tested,317,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:379,Testability,test,tests,379,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:535,Testability,test,tests,535,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:715,Testability,test,tests,715,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:811,Testability,test,test,811,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423283690:983,Testability,log,logistics,983,"Hello; I'm so glad to see that the su2 meeting has been so productive!; To address Eran's concern, maybe it would be more reasonable to run v&v on; major releases only, aka 7.0 but not 7.1, and I agree that keeping a record; of the most recent version checked is a good idea-and as necessary minor; releases could be tested, as suggested by individual developers. The regression tests should ensure that the v&v results will be unlikely to; be changed. One thing we can do to reduce that risk further would be to; introduce regression tests that compare solution files rather than the; terminal output alone. I can take a stab at that if there's no other; volunteers- probably only needs to be a couple of critical tests, the file; diff may be slightly more expensive than currently, but given the increase; in test precision and detail I think it would be worth it. H. On Thu, Sep 20, 2018, 1:46 PM erangit <notifications@github.com> wrote:. > Hi All; > Im a bit worried about the logistics related to checking this v&v data; > base for every new release.; > Unlike the tutorials, these cases, by their nature will be large and will; > require long integrations(the 2D cases might not fall on this category).; > This means also that significant computational resources will be required; > for this evaluation (about twice a year for a growing list of cases). Is it; > practical?; > The only way that I think that it might work is that each contributor will; > be responsible for checking the casesthat he has introduced, before each; > release. Being a voluntary institution, this can not be enforced (and we do; > not want to enforce). How about trying to be less demanding:; > In each validation case there will be a statement about the last version; > that it was checked with and the responsible contributor. Each contributor; > will receive a recommendation to check his cases before a new release, and; > will be able to do that and update the OK label also after the release.; > Less waterpro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423283690
https://github.com/su2code/SU2/issues/581#issuecomment-423286251:163,Testability,benchmark,benchmark,163,"Dear all, . ; As I mentioned at the dev meeting earlier this week, regarding V&V, I already have joint plans; with Eduardo Molina to look at a number of turbulent benchmark cases using his (E)DDES; implementation (eg. square cylinder, tandem cylinders, massively separated NACA0012/21, etc). ; The next step after that would be to use my FWH implementation to compute farfield noise and compare them to the BANC workshop cases. NASA folks are very open to share the BANC data. ; We will likely be able to obtain the European VALIANT project data too.; I am on a short vacation right now but will start iterating with Eduardo on this next week ; when I am back in the office. . Best,. Beckett",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423286251
https://github.com/su2code/SU2/issues/581#issuecomment-423291806:476,Deployability,release,release,476,"@hlkline That's a good point about the regression tests ensuring that the v&v results will be unlikely to change. If we have the same residuals for all the test cases, it isn't a stretch to say that the final results of the v&v cases will stay the same. But sometimes the test values for the regression tests are changed during development and then we lose the guarantee. . From the viewpoint of being rigorous, I agree with the suggestion to run the v&v cases before a major release like 7.0 and also with @erangit on keeping track of the last version that they were run for. I am unsure about holding the people who add the test cases responsible for re-running them. Circumstances change, and access to resources change. That may make it hard for people to run the v&v cases. . I also think it is a good idea to have the effort be collaborative so people can add cases. My concern is about size limits that github has on repositories. Some of the mesh files are going to be massive, especially given that we want to perform grid convergence studies. We will soon be over the size limit. I am not sure about how to get around that. Suggestions would be great!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423291806
https://github.com/su2code/SU2/issues/581#issuecomment-423291806:1019,Performance,perform,perform,1019,"@hlkline That's a good point about the regression tests ensuring that the v&v results will be unlikely to change. If we have the same residuals for all the test cases, it isn't a stretch to say that the final results of the v&v cases will stay the same. But sometimes the test values for the regression tests are changed during development and then we lose the guarantee. . From the viewpoint of being rigorous, I agree with the suggestion to run the v&v cases before a major release like 7.0 and also with @erangit on keeping track of the last version that they were run for. I am unsure about holding the people who add the test cases responsible for re-running them. Circumstances change, and access to resources change. That may make it hard for people to run the v&v cases. . I also think it is a good idea to have the effort be collaborative so people can add cases. My concern is about size limits that github has on repositories. Some of the mesh files are going to be massive, especially given that we want to perform grid convergence studies. We will soon be over the size limit. I am not sure about how to get around that. Suggestions would be great!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423291806
https://github.com/su2code/SU2/issues/581#issuecomment-423291806:696,Security,access,access,696,"@hlkline That's a good point about the regression tests ensuring that the v&v results will be unlikely to change. If we have the same residuals for all the test cases, it isn't a stretch to say that the final results of the v&v cases will stay the same. But sometimes the test values for the regression tests are changed during development and then we lose the guarantee. . From the viewpoint of being rigorous, I agree with the suggestion to run the v&v cases before a major release like 7.0 and also with @erangit on keeping track of the last version that they were run for. I am unsure about holding the people who add the test cases responsible for re-running them. Circumstances change, and access to resources change. That may make it hard for people to run the v&v cases. . I also think it is a good idea to have the effort be collaborative so people can add cases. My concern is about size limits that github has on repositories. Some of the mesh files are going to be massive, especially given that we want to perform grid convergence studies. We will soon be over the size limit. I am not sure about how to get around that. Suggestions would be great!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423291806
https://github.com/su2code/SU2/issues/581#issuecomment-423291806:50,Testability,test,tests,50,"@hlkline That's a good point about the regression tests ensuring that the v&v results will be unlikely to change. If we have the same residuals for all the test cases, it isn't a stretch to say that the final results of the v&v cases will stay the same. But sometimes the test values for the regression tests are changed during development and then we lose the guarantee. . From the viewpoint of being rigorous, I agree with the suggestion to run the v&v cases before a major release like 7.0 and also with @erangit on keeping track of the last version that they were run for. I am unsure about holding the people who add the test cases responsible for re-running them. Circumstances change, and access to resources change. That may make it hard for people to run the v&v cases. . I also think it is a good idea to have the effort be collaborative so people can add cases. My concern is about size limits that github has on repositories. Some of the mesh files are going to be massive, especially given that we want to perform grid convergence studies. We will soon be over the size limit. I am not sure about how to get around that. Suggestions would be great!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423291806
https://github.com/su2code/SU2/issues/581#issuecomment-423291806:156,Testability,test,test,156,"@hlkline That's a good point about the regression tests ensuring that the v&v results will be unlikely to change. If we have the same residuals for all the test cases, it isn't a stretch to say that the final results of the v&v cases will stay the same. But sometimes the test values for the regression tests are changed during development and then we lose the guarantee. . From the viewpoint of being rigorous, I agree with the suggestion to run the v&v cases before a major release like 7.0 and also with @erangit on keeping track of the last version that they were run for. I am unsure about holding the people who add the test cases responsible for re-running them. Circumstances change, and access to resources change. That may make it hard for people to run the v&v cases. . I also think it is a good idea to have the effort be collaborative so people can add cases. My concern is about size limits that github has on repositories. Some of the mesh files are going to be massive, especially given that we want to perform grid convergence studies. We will soon be over the size limit. I am not sure about how to get around that. Suggestions would be great!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423291806
https://github.com/su2code/SU2/issues/581#issuecomment-423291806:272,Testability,test,test,272,"@hlkline That's a good point about the regression tests ensuring that the v&v results will be unlikely to change. If we have the same residuals for all the test cases, it isn't a stretch to say that the final results of the v&v cases will stay the same. But sometimes the test values for the regression tests are changed during development and then we lose the guarantee. . From the viewpoint of being rigorous, I agree with the suggestion to run the v&v cases before a major release like 7.0 and also with @erangit on keeping track of the last version that they were run for. I am unsure about holding the people who add the test cases responsible for re-running them. Circumstances change, and access to resources change. That may make it hard for people to run the v&v cases. . I also think it is a good idea to have the effort be collaborative so people can add cases. My concern is about size limits that github has on repositories. Some of the mesh files are going to be massive, especially given that we want to perform grid convergence studies. We will soon be over the size limit. I am not sure about how to get around that. Suggestions would be great!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423291806
https://github.com/su2code/SU2/issues/581#issuecomment-423291806:303,Testability,test,tests,303,"@hlkline That's a good point about the regression tests ensuring that the v&v results will be unlikely to change. If we have the same residuals for all the test cases, it isn't a stretch to say that the final results of the v&v cases will stay the same. But sometimes the test values for the regression tests are changed during development and then we lose the guarantee. . From the viewpoint of being rigorous, I agree with the suggestion to run the v&v cases before a major release like 7.0 and also with @erangit on keeping track of the last version that they were run for. I am unsure about holding the people who add the test cases responsible for re-running them. Circumstances change, and access to resources change. That may make it hard for people to run the v&v cases. . I also think it is a good idea to have the effort be collaborative so people can add cases. My concern is about size limits that github has on repositories. Some of the mesh files are going to be massive, especially given that we want to perform grid convergence studies. We will soon be over the size limit. I am not sure about how to get around that. Suggestions would be great!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423291806
https://github.com/su2code/SU2/issues/581#issuecomment-423291806:626,Testability,test,test,626,"@hlkline That's a good point about the regression tests ensuring that the v&v results will be unlikely to change. If we have the same residuals for all the test cases, it isn't a stretch to say that the final results of the v&v cases will stay the same. But sometimes the test values for the regression tests are changed during development and then we lose the guarantee. . From the viewpoint of being rigorous, I agree with the suggestion to run the v&v cases before a major release like 7.0 and also with @erangit on keeping track of the last version that they were run for. I am unsure about holding the people who add the test cases responsible for re-running them. Circumstances change, and access to resources change. That may make it hard for people to run the v&v cases. . I also think it is a good idea to have the effort be collaborative so people can add cases. My concern is about size limits that github has on repositories. Some of the mesh files are going to be massive, especially given that we want to perform grid convergence studies. We will soon be over the size limit. I am not sure about how to get around that. Suggestions would be great!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423291806
https://github.com/su2code/SU2/issues/581#issuecomment-423295060:433,Modifiability,config,config,433,"@jayantmukho If the upload size limit on Github is an issue, and I suspect it likely will be for these large 3D meshes, we can follow the BANC model -- the researchers who conducted the corresponding V&V cases are named custodians of these test case with explicit understanding that data will be shared upon request. This way, the data resides with a particular SU2 dev group or groups and need not be uploaded. However, I think the config files and all other info necessary for other users to replicate the test cases must be uploaded. Best,; Beckett",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423295060
https://github.com/su2code/SU2/issues/581#issuecomment-423295060:240,Testability,test,test,240,"@jayantmukho If the upload size limit on Github is an issue, and I suspect it likely will be for these large 3D meshes, we can follow the BANC model -- the researchers who conducted the corresponding V&V cases are named custodians of these test case with explicit understanding that data will be shared upon request. This way, the data resides with a particular SU2 dev group or groups and need not be uploaded. However, I think the config files and all other info necessary for other users to replicate the test cases must be uploaded. Best,; Beckett",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423295060
https://github.com/su2code/SU2/issues/581#issuecomment-423295060:508,Testability,test,test,508,"@jayantmukho If the upload size limit on Github is an issue, and I suspect it likely will be for these large 3D meshes, we can follow the BANC model -- the researchers who conducted the corresponding V&V cases are named custodians of these test case with explicit understanding that data will be shared upon request. This way, the data resides with a particular SU2 dev group or groups and need not be uploaded. However, I think the config files and all other info necessary for other users to replicate the test cases must be uploaded. Best,; Beckett",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-423295060
https://github.com/su2code/SU2/issues/581#issuecomment-425961143:137,Deployability,configurat,configuration,137,"@BeckettZhou I think that's a good idea. Just to make sure I understand the BANC model: for cases that have large mesh sizes, we provide configuration files, and visualization of the results (comparisons to higher fidelity data and/or to other solvers). If someone would like to run the case for themselves, they would contact the custodian and the custodian is obligated to provide the meshes. The next step would be to start the github repo. @economon Is it possible to start the repo under the su2code umbrella? Is that something you could start and people can start compiling validation test cases, and their results?. Cheers, ; Jayant",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-425961143
https://github.com/su2code/SU2/issues/581#issuecomment-425961143:137,Modifiability,config,configuration,137,"@BeckettZhou I think that's a good idea. Just to make sure I understand the BANC model: for cases that have large mesh sizes, we provide configuration files, and visualization of the results (comparisons to higher fidelity data and/or to other solvers). If someone would like to run the case for themselves, they would contact the custodian and the custodian is obligated to provide the meshes. The next step would be to start the github repo. @economon Is it possible to start the repo under the su2code umbrella? Is that something you could start and people can start compiling validation test cases, and their results?. Cheers, ; Jayant",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-425961143
https://github.com/su2code/SU2/issues/581#issuecomment-425961143:580,Security,validat,validation,580,"@BeckettZhou I think that's a good idea. Just to make sure I understand the BANC model: for cases that have large mesh sizes, we provide configuration files, and visualization of the results (comparisons to higher fidelity data and/or to other solvers). If someone would like to run the case for themselves, they would contact the custodian and the custodian is obligated to provide the meshes. The next step would be to start the github repo. @economon Is it possible to start the repo under the su2code umbrella? Is that something you could start and people can start compiling validation test cases, and their results?. Cheers, ; Jayant",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-425961143
https://github.com/su2code/SU2/issues/581#issuecomment-425961143:591,Testability,test,test,591,"@BeckettZhou I think that's a good idea. Just to make sure I understand the BANC model: for cases that have large mesh sizes, we provide configuration files, and visualization of the results (comparisons to higher fidelity data and/or to other solvers). If someone would like to run the case for themselves, they would contact the custodian and the custodian is obligated to provide the meshes. The next step would be to start the github repo. @economon Is it possible to start the repo under the su2code umbrella? Is that something you could start and people can start compiling validation test cases, and their results?. Cheers, ; Jayant",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-425961143
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:485,Deployability,configurat,configuration,485,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:783,Deployability,configurat,configuration,783,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:2237,Energy Efficiency,reduce,reduced,2237," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:485,Modifiability,config,configuration,485,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:783,Modifiability,config,configuration,783,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:2415,Modifiability,flexible,flexible,2415," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:535,Performance,optimiz,optimized,535,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1925,Performance,perform,performance,1925," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:850,Security,validat,validating,850,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1372,Security,Validat,Validation,1372," of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1757,Security,validat,validation,1757," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:53,Testability,Test,TestCases,53,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:121,Testability,test,testing,121,"@economon I was envisioning something similar to the TestCases folder. With v&v cases grouped according to what they are testing. Something along the lines of: . 1) Inviscid Simulations: ; a) 2D Inviscid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1204,Testability,test,test,1204,"scid bump; b) 2D oblique shocks interaction; c) ...; 2) RANS simulations: ; a) Flatplate; b) NACA0012; c) ...; 3) Unsteady simulations:; a) Square Cylinder; b) ...; 4) Turbomachinary: ; a) ... And so on. Each of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 c",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1568,Testability,Test,TestCases,1568,"ults. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1768,Testability,test,test,1768," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:2529,Testability,test,test,2529," case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would have to be flexible since the same level of convergence might not apply to all the cases in the repository. But for within a test case, I think it would be good to use the same convergence criteria for a family of meshes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426026053:1437,Usability,intuit,intuitive,1437," of the directories would have sub-directories for different mesh sizes, with configuration files for each mesh level that have optimized parameters for best results. So for example if we are talking about the NACA0012 case, we would have something along the lines of: . a) NACA0012; i) 113 x 33; ii) 225 x 65 ; iii) 449 x 129; iv) ... This way we have a family of meshes and configuration files that are specifically built for the purpose of validating the code and comparing with other solvers. I might be useful to compress meshes that are larger than a certain size (say 10MB). We should also put a limit on the size of a single mesh that the repository can handle (say 50MB?). . Within the home directory, the README file should list all the cases in the repository, who the custodian of the test case is (person with meshes in case the meshes are too large), and which version it was last run on. . I thought about splitting it up into Verification cases and Validation cases, but I thought it would be more informative and intuitive to split up according to the physics of the simulations. My thinking might be limited because that's how I have seen the TestCases folder organized, so any other suggestions are welcome. I think it is imperative that this is accompanied with a section on the SU2 website that showcases just the results of the validation test cases (grid convergence studies, residual reductions etc) and links to the v&v repo appropriately. This way, if people are just inquisitive about SU2's performance, they can get a quick snapshot of the results, without the need to run the cases themselves. . I also wanted to broach the topic of convergence here. Would it be a good idea to standardize the termination criteria wherever possible? For example, in the NACA0012 case we can ensure that residuals are reduced by 8 orders of magnitude for all meshes. Or for the ONERAM6, we use Cauchy convergence and make sure the C_L is converged to 6 orders of magnitude. This would hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426026053
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:1228,Safety,predict,prediction,1228,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:210,Security,validat,validation,210,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:397,Security,validat,validation,397,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:494,Security,validat,validation,494,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:801,Security,validat,validation,801,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:841,Security,validat,validation,841,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:856,Security,validat,validate,856,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:1414,Security,validat,validation,1414,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:139,Testability,test,tests,139,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:221,Testability,test,test,221,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:248,Testability,test,test,248,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:333,Testability,test,test,333,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:408,Testability,test,test,408,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:505,Testability,test,tests,505,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426239437:585,Testability,test,test,585,"Great idea! Below are some links to databases that I know of. I'd be happy to contribute. . (Some) CFD companies run very large regression tests that can take a long time to complete. Typically, you do not put validation test cases in a regression test (and run it up to convergence) because it will just take too long. A regression test should be <30s or so. ; At a certain point there *will* be validation test cases that will take a couple of weeks to run. If you want to make sure that the validation tests are up-to-date and will run with the current version, create a regression test for it: create a coarse mesh setup for it and run it for only 10 iterations and check the residuals. ; Having said that, it will be nice if there is a general 'run' script that will run all subcases of a single validation case to construct the entire validation and validate the final results with the known/stored solutions.; -nijso. ercoftac database:; http://cfd.mace.manchester.ac.uk/ercoftac/index.html; nparc database:; https://www.grc.nasa.gov/WWW/wind/valid/archive.html; cfl3d V&V database:; https://cfl3d.larc.nasa.gov/Cfl3dv6/cfl3dv6_testcases.html; V&V database for turbulence models:; https://turbmodels.larc.nasa.gov/; drag prediction workshop:; https://aiaa-dpw.larc.nasa.gov/; some cfd-online V&V links: ; https://www.cfd-online.com/Wiki/Validation_and_test_cases; https://www.cfd-online.com/Links/refs.html#validation; reacting flow database:; https://www.sandia.gov/TNF/abstract.html",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426239437
https://github.com/su2code/SU2/issues/581#issuecomment-426799490:171,Security,access,access,171,The new repo is live here: https://github.com/su2code/VandV (GitHub didn't like '&' in the title). All members of the developer team on GitHub should have read/write/push access.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426799490
https://github.com/su2code/SU2/issues/581#issuecomment-426808018:447,Availability,redundant,redundant,447,"Should we use the branching methodology that we use for the SU2 repository? In the sense that we create a develop branch, create branches for any cases we want to add, submit pull requests that can be reviewed by the rest of the community etc. . I like the idea from @bigfooted, of having some regression testing that can run the simulation for a couple of iterations and check residuals (identical to what we do for the TestCases). This might be redundant to the actual regression tests that are done in SU2, but would be an easy first check on weather a particular validation case needs to be run again. Ideally, this would be run before any major version releases, as we discussed earlier. . I can also start working on creating a section on the website for the results of the validation cases. I'll eventually upload a sample validation case with corresponding results that people can model their efforts on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426808018
https://github.com/su2code/SU2/issues/581#issuecomment-426808018:658,Deployability,release,releases,658,"Should we use the branching methodology that we use for the SU2 repository? In the sense that we create a develop branch, create branches for any cases we want to add, submit pull requests that can be reviewed by the rest of the community etc. . I like the idea from @bigfooted, of having some regression testing that can run the simulation for a couple of iterations and check residuals (identical to what we do for the TestCases). This might be redundant to the actual regression tests that are done in SU2, but would be an easy first check on weather a particular validation case needs to be run again. Ideally, this would be run before any major version releases, as we discussed earlier. . I can also start working on creating a section on the website for the results of the validation cases. I'll eventually upload a sample validation case with corresponding results that people can model their efforts on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426808018
https://github.com/su2code/SU2/issues/581#issuecomment-426808018:447,Safety,redund,redundant,447,"Should we use the branching methodology that we use for the SU2 repository? In the sense that we create a develop branch, create branches for any cases we want to add, submit pull requests that can be reviewed by the rest of the community etc. . I like the idea from @bigfooted, of having some regression testing that can run the simulation for a couple of iterations and check residuals (identical to what we do for the TestCases). This might be redundant to the actual regression tests that are done in SU2, but would be an easy first check on weather a particular validation case needs to be run again. Ideally, this would be run before any major version releases, as we discussed earlier. . I can also start working on creating a section on the website for the results of the validation cases. I'll eventually upload a sample validation case with corresponding results that people can model their efforts on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426808018
https://github.com/su2code/SU2/issues/581#issuecomment-426808018:567,Security,validat,validation,567,"Should we use the branching methodology that we use for the SU2 repository? In the sense that we create a develop branch, create branches for any cases we want to add, submit pull requests that can be reviewed by the rest of the community etc. . I like the idea from @bigfooted, of having some regression testing that can run the simulation for a couple of iterations and check residuals (identical to what we do for the TestCases). This might be redundant to the actual regression tests that are done in SU2, but would be an easy first check on weather a particular validation case needs to be run again. Ideally, this would be run before any major version releases, as we discussed earlier. . I can also start working on creating a section on the website for the results of the validation cases. I'll eventually upload a sample validation case with corresponding results that people can model their efforts on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426808018
https://github.com/su2code/SU2/issues/581#issuecomment-426808018:780,Security,validat,validation,780,"Should we use the branching methodology that we use for the SU2 repository? In the sense that we create a develop branch, create branches for any cases we want to add, submit pull requests that can be reviewed by the rest of the community etc. . I like the idea from @bigfooted, of having some regression testing that can run the simulation for a couple of iterations and check residuals (identical to what we do for the TestCases). This might be redundant to the actual regression tests that are done in SU2, but would be an easy first check on weather a particular validation case needs to be run again. Ideally, this would be run before any major version releases, as we discussed earlier. . I can also start working on creating a section on the website for the results of the validation cases. I'll eventually upload a sample validation case with corresponding results that people can model their efforts on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426808018
https://github.com/su2code/SU2/issues/581#issuecomment-426808018:830,Security,validat,validation,830,"Should we use the branching methodology that we use for the SU2 repository? In the sense that we create a develop branch, create branches for any cases we want to add, submit pull requests that can be reviewed by the rest of the community etc. . I like the idea from @bigfooted, of having some regression testing that can run the simulation for a couple of iterations and check residuals (identical to what we do for the TestCases). This might be redundant to the actual regression tests that are done in SU2, but would be an easy first check on weather a particular validation case needs to be run again. Ideally, this would be run before any major version releases, as we discussed earlier. . I can also start working on creating a section on the website for the results of the validation cases. I'll eventually upload a sample validation case with corresponding results that people can model their efforts on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426808018
https://github.com/su2code/SU2/issues/581#issuecomment-426808018:305,Testability,test,testing,305,"Should we use the branching methodology that we use for the SU2 repository? In the sense that we create a develop branch, create branches for any cases we want to add, submit pull requests that can be reviewed by the rest of the community etc. . I like the idea from @bigfooted, of having some regression testing that can run the simulation for a couple of iterations and check residuals (identical to what we do for the TestCases). This might be redundant to the actual regression tests that are done in SU2, but would be an easy first check on weather a particular validation case needs to be run again. Ideally, this would be run before any major version releases, as we discussed earlier. . I can also start working on creating a section on the website for the results of the validation cases. I'll eventually upload a sample validation case with corresponding results that people can model their efforts on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426808018
https://github.com/su2code/SU2/issues/581#issuecomment-426808018:421,Testability,Test,TestCases,421,"Should we use the branching methodology that we use for the SU2 repository? In the sense that we create a develop branch, create branches for any cases we want to add, submit pull requests that can be reviewed by the rest of the community etc. . I like the idea from @bigfooted, of having some regression testing that can run the simulation for a couple of iterations and check residuals (identical to what we do for the TestCases). This might be redundant to the actual regression tests that are done in SU2, but would be an easy first check on weather a particular validation case needs to be run again. Ideally, this would be run before any major version releases, as we discussed earlier. . I can also start working on creating a section on the website for the results of the validation cases. I'll eventually upload a sample validation case with corresponding results that people can model their efforts on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426808018
https://github.com/su2code/SU2/issues/581#issuecomment-426808018:482,Testability,test,tests,482,"Should we use the branching methodology that we use for the SU2 repository? In the sense that we create a develop branch, create branches for any cases we want to add, submit pull requests that can be reviewed by the rest of the community etc. . I like the idea from @bigfooted, of having some regression testing that can run the simulation for a couple of iterations and check residuals (identical to what we do for the TestCases). This might be redundant to the actual regression tests that are done in SU2, but would be an easy first check on weather a particular validation case needs to be run again. Ideally, this would be run before any major version releases, as we discussed earlier. . I can also start working on creating a section on the website for the results of the validation cases. I'll eventually upload a sample validation case with corresponding results that people can model their efforts on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-426808018
https://github.com/su2code/SU2/issues/581#issuecomment-470729235:313,Deployability,configurat,configuration,313,"After hibernating on this over the winter, I finally had some time to put some work into this. I am in the process of running a number of cases. So far I have results for 2 RANS cases with mesh convergence studies. These can be seen at https://github.com/su2code/VandV . The repo contains the relevant meshes and configuration files for each mesh level. It might not be necessary to have the different config files since the only changes between them are CFL numbers and mesh filenames. We can discuss this. . The folder for each case also has a README.md file that presents the test case and some of the relevant results. This displays the information nicely in the repository page, and is a decent mock up of how it would look, if we decide to put it on the website. . I just wanted to share this to get initial reactions to how I have set the repo up. I haven't included any discussion about the actual results either, but that is something that can be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-470729235
https://github.com/su2code/SU2/issues/581#issuecomment-470729235:313,Modifiability,config,configuration,313,"After hibernating on this over the winter, I finally had some time to put some work into this. I am in the process of running a number of cases. So far I have results for 2 RANS cases with mesh convergence studies. These can be seen at https://github.com/su2code/VandV . The repo contains the relevant meshes and configuration files for each mesh level. It might not be necessary to have the different config files since the only changes between them are CFL numbers and mesh filenames. We can discuss this. . The folder for each case also has a README.md file that presents the test case and some of the relevant results. This displays the information nicely in the repository page, and is a decent mock up of how it would look, if we decide to put it on the website. . I just wanted to share this to get initial reactions to how I have set the repo up. I haven't included any discussion about the actual results either, but that is something that can be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-470729235
https://github.com/su2code/SU2/issues/581#issuecomment-470729235:402,Modifiability,config,config,402,"After hibernating on this over the winter, I finally had some time to put some work into this. I am in the process of running a number of cases. So far I have results for 2 RANS cases with mesh convergence studies. These can be seen at https://github.com/su2code/VandV . The repo contains the relevant meshes and configuration files for each mesh level. It might not be necessary to have the different config files since the only changes between them are CFL numbers and mesh filenames. We can discuss this. . The folder for each case also has a README.md file that presents the test case and some of the relevant results. This displays the information nicely in the repository page, and is a decent mock up of how it would look, if we decide to put it on the website. . I just wanted to share this to get initial reactions to how I have set the repo up. I haven't included any discussion about the actual results either, but that is something that can be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-470729235
https://github.com/su2code/SU2/issues/581#issuecomment-470729235:579,Testability,test,test,579,"After hibernating on this over the winter, I finally had some time to put some work into this. I am in the process of running a number of cases. So far I have results for 2 RANS cases with mesh convergence studies. These can be seen at https://github.com/su2code/VandV . The repo contains the relevant meshes and configuration files for each mesh level. It might not be necessary to have the different config files since the only changes between them are CFL numbers and mesh filenames. We can discuss this. . The folder for each case also has a README.md file that presents the test case and some of the relevant results. This displays the information nicely in the repository page, and is a decent mock up of how it would look, if we decide to put it on the website. . I just wanted to share this to get initial reactions to how I have set the repo up. I haven't included any discussion about the actual results either, but that is something that can be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-470729235
https://github.com/su2code/SU2/issues/581#issuecomment-470729235:700,Testability,mock,mock,700,"After hibernating on this over the winter, I finally had some time to put some work into this. I am in the process of running a number of cases. So far I have results for 2 RANS cases with mesh convergence studies. These can be seen at https://github.com/su2code/VandV . The repo contains the relevant meshes and configuration files for each mesh level. It might not be necessary to have the different config files since the only changes between them are CFL numbers and mesh filenames. We can discuss this. . The folder for each case also has a README.md file that presents the test case and some of the relevant results. This displays the information nicely in the repository page, and is a decent mock up of how it would look, if we decide to put it on the website. . I just wanted to share this to get initial reactions to how I have set the repo up. I haven't included any discussion about the actual results either, but that is something that can be added.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/581#issuecomment-470729235
https://github.com/su2code/SU2/issues/582#issuecomment-423178409:831,Deployability,release,release,831,"Some additional ideas on this topic:. #### Using Github projects; - For compilation of branches, I have created a github project: https://github.com/su2code/SU2/projects/7; - In there, you can list your active/old branches by adding a note to the relevant column. Please be so kind to mark the name of the branch in bold using Markdown's format (`** my branch name **`).; - I have added some examples from my own branches. #### Where do I find my branches?; - We have all worked on branches that we no longer remember, but Github has a really nice feature for this.; - Log-in to your Github user account and go to: https://github.com/su2code/SU2/branches/yours; - All the branches in which you have added at least one commit will be listed there. #### Old branches; - We have found a lot of branches that are older than the latest release and have no commits ahead of master (you can see this in your branch list).; - This would mean that normally all of their commits have already gone into a released version of SU2 and they are no longer required.; - I am planning to do some cleaning of very old branches to have a more compact structure, however it would be helpful if all the developers could indicate explicitly which branches can be safely removed to avoid any future issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/582#issuecomment-423178409
https://github.com/su2code/SU2/issues/582#issuecomment-423178409:994,Deployability,release,released,994,"Some additional ideas on this topic:. #### Using Github projects; - For compilation of branches, I have created a github project: https://github.com/su2code/SU2/projects/7; - In there, you can list your active/old branches by adding a note to the relevant column. Please be so kind to mark the name of the branch in bold using Markdown's format (`** my branch name **`).; - I have added some examples from my own branches. #### Where do I find my branches?; - We have all worked on branches that we no longer remember, but Github has a really nice feature for this.; - Log-in to your Github user account and go to: https://github.com/su2code/SU2/branches/yours; - All the branches in which you have added at least one commit will be listed there. #### Old branches; - We have found a lot of branches that are older than the latest release and have no commits ahead of master (you can see this in your branch list).; - This would mean that normally all of their commits have already gone into a released version of SU2 and they are no longer required.; - I am planning to do some cleaning of very old branches to have a more compact structure, however it would be helpful if all the developers could indicate explicitly which branches can be safely removed to avoid any future issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/582#issuecomment-423178409
https://github.com/su2code/SU2/issues/582#issuecomment-423178409:1241,Safety,safe,safely,1241,"Some additional ideas on this topic:. #### Using Github projects; - For compilation of branches, I have created a github project: https://github.com/su2code/SU2/projects/7; - In there, you can list your active/old branches by adding a note to the relevant column. Please be so kind to mark the name of the branch in bold using Markdown's format (`** my branch name **`).; - I have added some examples from my own branches. #### Where do I find my branches?; - We have all worked on branches that we no longer remember, but Github has a really nice feature for this.; - Log-in to your Github user account and go to: https://github.com/su2code/SU2/branches/yours; - All the branches in which you have added at least one commit will be listed there. #### Old branches; - We have found a lot of branches that are older than the latest release and have no commits ahead of master (you can see this in your branch list).; - This would mean that normally all of their commits have already gone into a released version of SU2 and they are no longer required.; - I am planning to do some cleaning of very old branches to have a more compact structure, however it would be helpful if all the developers could indicate explicitly which branches can be safely removed to avoid any future issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/582#issuecomment-423178409
https://github.com/su2code/SU2/issues/582#issuecomment-423178409:1259,Safety,avoid,avoid,1259,"Some additional ideas on this topic:. #### Using Github projects; - For compilation of branches, I have created a github project: https://github.com/su2code/SU2/projects/7; - In there, you can list your active/old branches by adding a note to the relevant column. Please be so kind to mark the name of the branch in bold using Markdown's format (`** my branch name **`).; - I have added some examples from my own branches. #### Where do I find my branches?; - We have all worked on branches that we no longer remember, but Github has a really nice feature for this.; - Log-in to your Github user account and go to: https://github.com/su2code/SU2/branches/yours; - All the branches in which you have added at least one commit will be listed there. #### Old branches; - We have found a lot of branches that are older than the latest release and have no commits ahead of master (you can see this in your branch list).; - This would mean that normally all of their commits have already gone into a released version of SU2 and they are no longer required.; - I am planning to do some cleaning of very old branches to have a more compact structure, however it would be helpful if all the developers could indicate explicitly which branches can be safely removed to avoid any future issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/582#issuecomment-423178409
https://github.com/su2code/SU2/issues/582#issuecomment-423178409:569,Testability,Log,Log-in,569,"Some additional ideas on this topic:. #### Using Github projects; - For compilation of branches, I have created a github project: https://github.com/su2code/SU2/projects/7; - In there, you can list your active/old branches by adding a note to the relevant column. Please be so kind to mark the name of the branch in bold using Markdown's format (`** my branch name **`).; - I have added some examples from my own branches. #### Where do I find my branches?; - We have all worked on branches that we no longer remember, but Github has a really nice feature for this.; - Log-in to your Github user account and go to: https://github.com/su2code/SU2/branches/yours; - All the branches in which you have added at least one commit will be listed there. #### Old branches; - We have found a lot of branches that are older than the latest release and have no commits ahead of master (you can see this in your branch list).; - This would mean that normally all of their commits have already gone into a released version of SU2 and they are no longer required.; - I am planning to do some cleaning of very old branches to have a more compact structure, however it would be helpful if all the developers could indicate explicitly which branches can be safely removed to avoid any future issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/582#issuecomment-423178409
https://github.com/su2code/SU2/issues/582#issuecomment-548250496:239,Testability,test,tests,239,"Also we still strongly suggest to open Draft Pull Request as soon as possible in the development process even if it still far from being ready. This way discussions can start earlier, potential conflicts can be solved together, regression tests run and you are reminded to frequently merge with develop!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/582#issuecomment-548250496
https://github.com/su2code/SU2/issues/583#issuecomment-423180781:109,Deployability,update,updated,109,"On an added note to this topic, and to avoid some future hassle, I have collected a list of active branches (updated within the last 3 months) that are currently falling far behind the last release:. - feature_boom; - feature_caa; - feature_turbo; - feature_turbo2phase; - feature_adjoint_lut; - feature_transp_part; - feature_turbo_aeroelastic; - feature_gradientNorm. I would strongly encourage to regularly update with develop to ensure the future merging process is as smooth as possible, particularly when we start moving files around.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423180781
https://github.com/su2code/SU2/issues/583#issuecomment-423180781:190,Deployability,release,release,190,"On an added note to this topic, and to avoid some future hassle, I have collected a list of active branches (updated within the last 3 months) that are currently falling far behind the last release:. - feature_boom; - feature_caa; - feature_turbo; - feature_turbo2phase; - feature_adjoint_lut; - feature_transp_part; - feature_turbo_aeroelastic; - feature_gradientNorm. I would strongly encourage to regularly update with develop to ensure the future merging process is as smooth as possible, particularly when we start moving files around.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423180781
https://github.com/su2code/SU2/issues/583#issuecomment-423180781:410,Deployability,update,update,410,"On an added note to this topic, and to avoid some future hassle, I have collected a list of active branches (updated within the last 3 months) that are currently falling far behind the last release:. - feature_boom; - feature_caa; - feature_turbo; - feature_turbo2phase; - feature_adjoint_lut; - feature_transp_part; - feature_turbo_aeroelastic; - feature_gradientNorm. I would strongly encourage to regularly update with develop to ensure the future merging process is as smooth as possible, particularly when we start moving files around.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423180781
https://github.com/su2code/SU2/issues/583#issuecomment-423180781:39,Safety,avoid,avoid,39,"On an added note to this topic, and to avoid some future hassle, I have collected a list of active branches (updated within the last 3 months) that are currently falling far behind the last release:. - feature_boom; - feature_caa; - feature_turbo; - feature_turbo2phase; - feature_adjoint_lut; - feature_transp_part; - feature_turbo_aeroelastic; - feature_gradientNorm. I would strongly encourage to regularly update with develop to ensure the future merging process is as smooth as possible, particularly when we start moving files around.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423180781
https://github.com/su2code/SU2/issues/583#issuecomment-423970045:760,Integrability,depend,dependency,760,"In terms of file organisation I can think of two strategies, one would be grouping them according to parent class, numerics, solver, etc. this would maybe make navigation easier for people who work on the code daily but it does little more than what the naming convention already does. The other would be to group families of classes and that, I think, would help people who are less familiar with the code, so for example numerics, solvers, variables, etc. used for fluid simulations would be separate from the ones used for other physics. The main re-compilation trigger is probably the config, every file includes it and not all need it. Not much can be done here because most classes do use the config in some way but we could try to minimise how much the dependency spreads by:; - Reviewing what cpp files actually need to include config_structure.hpp; - Including from the cpp and using a forward declaration on the corresponding hpp. Other sensitive ""triggers"" are the header files of classes with many children (solver, numerics, and variable) splitting the header files for these (maybe by family for small classes to avoid an explosion of hpp files) would allow working on a child class without re-compiling all others so often. The clients of CSolver would only include the header for the abstract class so those too would be shielded from changes in children classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423970045
https://github.com/su2code/SU2/issues/583#issuecomment-423970045:442,Modifiability,variab,variables,442,"In terms of file organisation I can think of two strategies, one would be grouping them according to parent class, numerics, solver, etc. this would maybe make navigation easier for people who work on the code daily but it does little more than what the naming convention already does. The other would be to group families of classes and that, I think, would help people who are less familiar with the code, so for example numerics, solvers, variables, etc. used for fluid simulations would be separate from the ones used for other physics. The main re-compilation trigger is probably the config, every file includes it and not all need it. Not much can be done here because most classes do use the config in some way but we could try to minimise how much the dependency spreads by:; - Reviewing what cpp files actually need to include config_structure.hpp; - Including from the cpp and using a forward declaration on the corresponding hpp. Other sensitive ""triggers"" are the header files of classes with many children (solver, numerics, and variable) splitting the header files for these (maybe by family for small classes to avoid an explosion of hpp files) would allow working on a child class without re-compiling all others so often. The clients of CSolver would only include the header for the abstract class so those too would be shielded from changes in children classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423970045
https://github.com/su2code/SU2/issues/583#issuecomment-423970045:589,Modifiability,config,config,589,"In terms of file organisation I can think of two strategies, one would be grouping them according to parent class, numerics, solver, etc. this would maybe make navigation easier for people who work on the code daily but it does little more than what the naming convention already does. The other would be to group families of classes and that, I think, would help people who are less familiar with the code, so for example numerics, solvers, variables, etc. used for fluid simulations would be separate from the ones used for other physics. The main re-compilation trigger is probably the config, every file includes it and not all need it. Not much can be done here because most classes do use the config in some way but we could try to minimise how much the dependency spreads by:; - Reviewing what cpp files actually need to include config_structure.hpp; - Including from the cpp and using a forward declaration on the corresponding hpp. Other sensitive ""triggers"" are the header files of classes with many children (solver, numerics, and variable) splitting the header files for these (maybe by family for small classes to avoid an explosion of hpp files) would allow working on a child class without re-compiling all others so often. The clients of CSolver would only include the header for the abstract class so those too would be shielded from changes in children classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423970045
https://github.com/su2code/SU2/issues/583#issuecomment-423970045:699,Modifiability,config,config,699,"In terms of file organisation I can think of two strategies, one would be grouping them according to parent class, numerics, solver, etc. this would maybe make navigation easier for people who work on the code daily but it does little more than what the naming convention already does. The other would be to group families of classes and that, I think, would help people who are less familiar with the code, so for example numerics, solvers, variables, etc. used for fluid simulations would be separate from the ones used for other physics. The main re-compilation trigger is probably the config, every file includes it and not all need it. Not much can be done here because most classes do use the config in some way but we could try to minimise how much the dependency spreads by:; - Reviewing what cpp files actually need to include config_structure.hpp; - Including from the cpp and using a forward declaration on the corresponding hpp. Other sensitive ""triggers"" are the header files of classes with many children (solver, numerics, and variable) splitting the header files for these (maybe by family for small classes to avoid an explosion of hpp files) would allow working on a child class without re-compiling all others so often. The clients of CSolver would only include the header for the abstract class so those too would be shielded from changes in children classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423970045
https://github.com/su2code/SU2/issues/583#issuecomment-423970045:1042,Modifiability,variab,variable,1042,"In terms of file organisation I can think of two strategies, one would be grouping them according to parent class, numerics, solver, etc. this would maybe make navigation easier for people who work on the code daily but it does little more than what the naming convention already does. The other would be to group families of classes and that, I think, would help people who are less familiar with the code, so for example numerics, solvers, variables, etc. used for fluid simulations would be separate from the ones used for other physics. The main re-compilation trigger is probably the config, every file includes it and not all need it. Not much can be done here because most classes do use the config in some way but we could try to minimise how much the dependency spreads by:; - Reviewing what cpp files actually need to include config_structure.hpp; - Including from the cpp and using a forward declaration on the corresponding hpp. Other sensitive ""triggers"" are the header files of classes with many children (solver, numerics, and variable) splitting the header files for these (maybe by family for small classes to avoid an explosion of hpp files) would allow working on a child class without re-compiling all others so often. The clients of CSolver would only include the header for the abstract class so those too would be shielded from changes in children classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423970045
https://github.com/su2code/SU2/issues/583#issuecomment-423970045:1127,Safety,avoid,avoid,1127,"In terms of file organisation I can think of two strategies, one would be grouping them according to parent class, numerics, solver, etc. this would maybe make navigation easier for people who work on the code daily but it does little more than what the naming convention already does. The other would be to group families of classes and that, I think, would help people who are less familiar with the code, so for example numerics, solvers, variables, etc. used for fluid simulations would be separate from the ones used for other physics. The main re-compilation trigger is probably the config, every file includes it and not all need it. Not much can be done here because most classes do use the config in some way but we could try to minimise how much the dependency spreads by:; - Reviewing what cpp files actually need to include config_structure.hpp; - Including from the cpp and using a forward declaration on the corresponding hpp. Other sensitive ""triggers"" are the header files of classes with many children (solver, numerics, and variable) splitting the header files for these (maybe by family for small classes to avoid an explosion of hpp files) would allow working on a child class without re-compiling all others so often. The clients of CSolver would only include the header for the abstract class so those too would be shielded from changes in children classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-423970045
https://github.com/su2code/SU2/issues/583#issuecomment-424215054:292,Availability,redundant,redundant,292,"Nice post @pcarruscag : I think we can gain a lot by first breaking up the files, especially the headers, and then being much better about include statements. In particular, we can look at forward declarations, using more guards, and just minimizing the number of includes (I expect some are redundant). As far as breaking up the files, I think geometry is a good place to start. I can take a shot at this first soon. . More ideas out there? Anyone have some bandwidth to experiment a little with the headers?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-424215054
https://github.com/su2code/SU2/issues/583#issuecomment-424215054:292,Safety,redund,redundant,292,"Nice post @pcarruscag : I think we can gain a lot by first breaking up the files, especially the headers, and then being much better about include statements. In particular, we can look at forward declarations, using more guards, and just minimizing the number of includes (I expect some are redundant). As far as breaking up the files, I think geometry is a good place to start. I can take a shot at this first soon. . More ideas out there? Anyone have some bandwidth to experiment a little with the headers?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-424215054
https://github.com/su2code/SU2/issues/583#issuecomment-500945013:310,Testability,log,logical,310,"Bumping this thread... Files are now starting to be divided in several PRs, but we should set a clear policy for this. Seems that the consensus is to carry one class per file, move the inlines to the headers, and create subfolders where possible (i.e., have a more flat hierarchy in the src directory based on logical groups such as numerics, geometry, solvers, etc). We do not have a clear naming convention yet, but if it is one class per file, then an option is simply the class name. Am I capturing the current consensus correctly? Anything I am missing? Naming preferences?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500945013
https://github.com/su2code/SU2/issues/583#issuecomment-500945013:96,Usability,clear,clear,96,"Bumping this thread... Files are now starting to be divided in several PRs, but we should set a clear policy for this. Seems that the consensus is to carry one class per file, move the inlines to the headers, and create subfolders where possible (i.e., have a more flat hierarchy in the src directory based on logical groups such as numerics, geometry, solvers, etc). We do not have a clear naming convention yet, but if it is one class per file, then an option is simply the class name. Am I capturing the current consensus correctly? Anything I am missing? Naming preferences?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500945013
https://github.com/su2code/SU2/issues/583#issuecomment-500945013:385,Usability,clear,clear,385,"Bumping this thread... Files are now starting to be divided in several PRs, but we should set a clear policy for this. Seems that the consensus is to carry one class per file, move the inlines to the headers, and create subfolders where possible (i.e., have a more flat hierarchy in the src directory based on logical groups such as numerics, geometry, solvers, etc). We do not have a clear naming convention yet, but if it is one class per file, then an option is simply the class name. Am I capturing the current consensus correctly? Anything I am missing? Naming preferences?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500945013
https://github.com/su2code/SU2/issues/583#issuecomment-500945013:465,Usability,simpl,simply,465,"Bumping this thread... Files are now starting to be divided in several PRs, but we should set a clear policy for this. Seems that the consensus is to carry one class per file, move the inlines to the headers, and create subfolders where possible (i.e., have a more flat hierarchy in the src directory based on logical groups such as numerics, geometry, solvers, etc). We do not have a clear naming convention yet, but if it is one class per file, then an option is simply the class name. Am I capturing the current consensus correctly? Anything I am missing? Naming preferences?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500945013
https://github.com/su2code/SU2/issues/583#issuecomment-500955452:92,Modifiability,config,config,92,"One comment I have-- @pcarruscag mentioned that it's somewhat difficult to break apart the ""config"" [blob](https://sourcemaking.com/antipatterns/the-blob). I have a proposal that could work to break apart things. Some config options, like those related to grid movement or timestepping or nondimensionalization, are used throughout a lot of the code. It will be difficult to make headway there. But some config settings have a very localized impact in the code. To find examples, just look for common prefixes in the `config_template.cfg`. There's `DV_*`, `FFD_*`, `UQ_*`, `INC_*`, etc. We could break apart the config class into a group of classes. Each class would derive from the base config class and share its features. Any function that needs config settings could then pull in two config objects, one with global settings (like nondimensionalization) and one with problem-specific settings (like incompressible flow settings). That way, changing the problem-specific settings, such as the incompressible flow options, won't trigger a complete rebuild of the code. It would only trigger a rebuild of the code that uses the incompressible flow options. That's my idea. Aside from that idea, I agree with the changes as proposed by @economon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500955452
https://github.com/su2code/SU2/issues/583#issuecomment-500955452:218,Modifiability,config,config,218,"One comment I have-- @pcarruscag mentioned that it's somewhat difficult to break apart the ""config"" [blob](https://sourcemaking.com/antipatterns/the-blob). I have a proposal that could work to break apart things. Some config options, like those related to grid movement or timestepping or nondimensionalization, are used throughout a lot of the code. It will be difficult to make headway there. But some config settings have a very localized impact in the code. To find examples, just look for common prefixes in the `config_template.cfg`. There's `DV_*`, `FFD_*`, `UQ_*`, `INC_*`, etc. We could break apart the config class into a group of classes. Each class would derive from the base config class and share its features. Any function that needs config settings could then pull in two config objects, one with global settings (like nondimensionalization) and one with problem-specific settings (like incompressible flow settings). That way, changing the problem-specific settings, such as the incompressible flow options, won't trigger a complete rebuild of the code. It would only trigger a rebuild of the code that uses the incompressible flow options. That's my idea. Aside from that idea, I agree with the changes as proposed by @economon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500955452
https://github.com/su2code/SU2/issues/583#issuecomment-500955452:404,Modifiability,config,config,404,"One comment I have-- @pcarruscag mentioned that it's somewhat difficult to break apart the ""config"" [blob](https://sourcemaking.com/antipatterns/the-blob). I have a proposal that could work to break apart things. Some config options, like those related to grid movement or timestepping or nondimensionalization, are used throughout a lot of the code. It will be difficult to make headway there. But some config settings have a very localized impact in the code. To find examples, just look for common prefixes in the `config_template.cfg`. There's `DV_*`, `FFD_*`, `UQ_*`, `INC_*`, etc. We could break apart the config class into a group of classes. Each class would derive from the base config class and share its features. Any function that needs config settings could then pull in two config objects, one with global settings (like nondimensionalization) and one with problem-specific settings (like incompressible flow settings). That way, changing the problem-specific settings, such as the incompressible flow options, won't trigger a complete rebuild of the code. It would only trigger a rebuild of the code that uses the incompressible flow options. That's my idea. Aside from that idea, I agree with the changes as proposed by @economon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500955452
https://github.com/su2code/SU2/issues/583#issuecomment-500955452:612,Modifiability,config,config,612,"One comment I have-- @pcarruscag mentioned that it's somewhat difficult to break apart the ""config"" [blob](https://sourcemaking.com/antipatterns/the-blob). I have a proposal that could work to break apart things. Some config options, like those related to grid movement or timestepping or nondimensionalization, are used throughout a lot of the code. It will be difficult to make headway there. But some config settings have a very localized impact in the code. To find examples, just look for common prefixes in the `config_template.cfg`. There's `DV_*`, `FFD_*`, `UQ_*`, `INC_*`, etc. We could break apart the config class into a group of classes. Each class would derive from the base config class and share its features. Any function that needs config settings could then pull in two config objects, one with global settings (like nondimensionalization) and one with problem-specific settings (like incompressible flow settings). That way, changing the problem-specific settings, such as the incompressible flow options, won't trigger a complete rebuild of the code. It would only trigger a rebuild of the code that uses the incompressible flow options. That's my idea. Aside from that idea, I agree with the changes as proposed by @economon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500955452
https://github.com/su2code/SU2/issues/583#issuecomment-500955452:688,Modifiability,config,config,688,"One comment I have-- @pcarruscag mentioned that it's somewhat difficult to break apart the ""config"" [blob](https://sourcemaking.com/antipatterns/the-blob). I have a proposal that could work to break apart things. Some config options, like those related to grid movement or timestepping or nondimensionalization, are used throughout a lot of the code. It will be difficult to make headway there. But some config settings have a very localized impact in the code. To find examples, just look for common prefixes in the `config_template.cfg`. There's `DV_*`, `FFD_*`, `UQ_*`, `INC_*`, etc. We could break apart the config class into a group of classes. Each class would derive from the base config class and share its features. Any function that needs config settings could then pull in two config objects, one with global settings (like nondimensionalization) and one with problem-specific settings (like incompressible flow settings). That way, changing the problem-specific settings, such as the incompressible flow options, won't trigger a complete rebuild of the code. It would only trigger a rebuild of the code that uses the incompressible flow options. That's my idea. Aside from that idea, I agree with the changes as proposed by @economon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500955452
https://github.com/su2code/SU2/issues/583#issuecomment-500955452:749,Modifiability,config,config,749,"One comment I have-- @pcarruscag mentioned that it's somewhat difficult to break apart the ""config"" [blob](https://sourcemaking.com/antipatterns/the-blob). I have a proposal that could work to break apart things. Some config options, like those related to grid movement or timestepping or nondimensionalization, are used throughout a lot of the code. It will be difficult to make headway there. But some config settings have a very localized impact in the code. To find examples, just look for common prefixes in the `config_template.cfg`. There's `DV_*`, `FFD_*`, `UQ_*`, `INC_*`, etc. We could break apart the config class into a group of classes. Each class would derive from the base config class and share its features. Any function that needs config settings could then pull in two config objects, one with global settings (like nondimensionalization) and one with problem-specific settings (like incompressible flow settings). That way, changing the problem-specific settings, such as the incompressible flow options, won't trigger a complete rebuild of the code. It would only trigger a rebuild of the code that uses the incompressible flow options. That's my idea. Aside from that idea, I agree with the changes as proposed by @economon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500955452
https://github.com/su2code/SU2/issues/583#issuecomment-500955452:788,Modifiability,config,config,788,"One comment I have-- @pcarruscag mentioned that it's somewhat difficult to break apart the ""config"" [blob](https://sourcemaking.com/antipatterns/the-blob). I have a proposal that could work to break apart things. Some config options, like those related to grid movement or timestepping or nondimensionalization, are used throughout a lot of the code. It will be difficult to make headway there. But some config settings have a very localized impact in the code. To find examples, just look for common prefixes in the `config_template.cfg`. There's `DV_*`, `FFD_*`, `UQ_*`, `INC_*`, etc. We could break apart the config class into a group of classes. Each class would derive from the base config class and share its features. Any function that needs config settings could then pull in two config objects, one with global settings (like nondimensionalization) and one with problem-specific settings (like incompressible flow settings). That way, changing the problem-specific settings, such as the incompressible flow options, won't trigger a complete rebuild of the code. It would only trigger a rebuild of the code that uses the incompressible flow options. That's my idea. Aside from that idea, I agree with the changes as proposed by @economon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-500955452
https://github.com/su2code/SU2/issues/583#issuecomment-501213869:38,Testability,log,logical,38,"@economon should we have one file per logical group with all the required includes, so that elsewhere you can still write ""#include numerics"" instead of having to include all one by one?. @clarkpede that would require passing a ""matrix"" of CConfigs like we do for numerics and so on right? Which would mean making things virtual and so the inlines would not be inline anymore (I think). I like the idea of breaking up the blob... but.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-501213869
https://github.com/su2code/SU2/issues/583#issuecomment-501240303:113,Modifiability,config,config-per-class,113,"@pcarruscag Yes, we would have a group (or matrix, I guess) of CConfigs. We don't have to follow a rigorous ""one-config-per-class"" definition; we could make a lot of headway just by splitting things up very roughly. If I understand, you're thinking we would have to have a base class with lots of virtual functions, and then derived classes with specific implementations. I don't think that would be necessary. First off, that wouldn't solve any problems, since the base class would have to have virtual placeholders for all the config classes. Second, the respective solver classes know what calls they need to make. So they can just have a specific derived class as a parameter (e.g. `CIncSolverConfig`). They don't need an abstract base class because we expect the incompressible settings to incompressible settings, and we won't ever switch it out for any other type of settings. The derived classes (e.g. `CIncSolverConfig`) could implement their own config getters/setters, without having any matching virtual functions in the base Config class. That should allow us to keep our inlines and avoid dynamic dispatches. There may be other flaws with my thinking that i'm not seeing. I just wanted to put my idea out there so we can make more informed decisions. I can also move this discussion to a separate issue, if we want to flesh out this discussion more.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-501240303
https://github.com/su2code/SU2/issues/583#issuecomment-501240303:529,Modifiability,config,config,529,"@pcarruscag Yes, we would have a group (or matrix, I guess) of CConfigs. We don't have to follow a rigorous ""one-config-per-class"" definition; we could make a lot of headway just by splitting things up very roughly. If I understand, you're thinking we would have to have a base class with lots of virtual functions, and then derived classes with specific implementations. I don't think that would be necessary. First off, that wouldn't solve any problems, since the base class would have to have virtual placeholders for all the config classes. Second, the respective solver classes know what calls they need to make. So they can just have a specific derived class as a parameter (e.g. `CIncSolverConfig`). They don't need an abstract base class because we expect the incompressible settings to incompressible settings, and we won't ever switch it out for any other type of settings. The derived classes (e.g. `CIncSolverConfig`) could implement their own config getters/setters, without having any matching virtual functions in the base Config class. That should allow us to keep our inlines and avoid dynamic dispatches. There may be other flaws with my thinking that i'm not seeing. I just wanted to put my idea out there so we can make more informed decisions. I can also move this discussion to a separate issue, if we want to flesh out this discussion more.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-501240303
https://github.com/su2code/SU2/issues/583#issuecomment-501240303:956,Modifiability,config,config,956,"@pcarruscag Yes, we would have a group (or matrix, I guess) of CConfigs. We don't have to follow a rigorous ""one-config-per-class"" definition; we could make a lot of headway just by splitting things up very roughly. If I understand, you're thinking we would have to have a base class with lots of virtual functions, and then derived classes with specific implementations. I don't think that would be necessary. First off, that wouldn't solve any problems, since the base class would have to have virtual placeholders for all the config classes. Second, the respective solver classes know what calls they need to make. So they can just have a specific derived class as a parameter (e.g. `CIncSolverConfig`). They don't need an abstract base class because we expect the incompressible settings to incompressible settings, and we won't ever switch it out for any other type of settings. The derived classes (e.g. `CIncSolverConfig`) could implement their own config getters/setters, without having any matching virtual functions in the base Config class. That should allow us to keep our inlines and avoid dynamic dispatches. There may be other flaws with my thinking that i'm not seeing. I just wanted to put my idea out there so we can make more informed decisions. I can also move this discussion to a separate issue, if we want to flesh out this discussion more.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-501240303
https://github.com/su2code/SU2/issues/583#issuecomment-501240303:1038,Modifiability,Config,Config,1038,"@pcarruscag Yes, we would have a group (or matrix, I guess) of CConfigs. We don't have to follow a rigorous ""one-config-per-class"" definition; we could make a lot of headway just by splitting things up very roughly. If I understand, you're thinking we would have to have a base class with lots of virtual functions, and then derived classes with specific implementations. I don't think that would be necessary. First off, that wouldn't solve any problems, since the base class would have to have virtual placeholders for all the config classes. Second, the respective solver classes know what calls they need to make. So they can just have a specific derived class as a parameter (e.g. `CIncSolverConfig`). They don't need an abstract base class because we expect the incompressible settings to incompressible settings, and we won't ever switch it out for any other type of settings. The derived classes (e.g. `CIncSolverConfig`) could implement their own config getters/setters, without having any matching virtual functions in the base Config class. That should allow us to keep our inlines and avoid dynamic dispatches. There may be other flaws with my thinking that i'm not seeing. I just wanted to put my idea out there so we can make more informed decisions. I can also move this discussion to a separate issue, if we want to flesh out this discussion more.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-501240303
https://github.com/su2code/SU2/issues/583#issuecomment-501240303:1097,Safety,avoid,avoid,1097,"@pcarruscag Yes, we would have a group (or matrix, I guess) of CConfigs. We don't have to follow a rigorous ""one-config-per-class"" definition; we could make a lot of headway just by splitting things up very roughly. If I understand, you're thinking we would have to have a base class with lots of virtual functions, and then derived classes with specific implementations. I don't think that would be necessary. First off, that wouldn't solve any problems, since the base class would have to have virtual placeholders for all the config classes. Second, the respective solver classes know what calls they need to make. So they can just have a specific derived class as a parameter (e.g. `CIncSolverConfig`). They don't need an abstract base class because we expect the incompressible settings to incompressible settings, and we won't ever switch it out for any other type of settings. The derived classes (e.g. `CIncSolverConfig`) could implement their own config getters/setters, without having any matching virtual functions in the base Config class. That should allow us to keep our inlines and avoid dynamic dispatches. There may be other flaws with my thinking that i'm not seeing. I just wanted to put my idea out there so we can make more informed decisions. I can also move this discussion to a separate issue, if we want to flesh out this discussion more.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-501240303
https://github.com/su2code/SU2/issues/583#issuecomment-501388653:348,Integrability,depend,dependencies,348,"@pcarruscag : as for header issues, I believe the consensus was also moving toward completely splitting the headers by class as well. It is true that then we may need to include multiple headers one-by-one, but in most cases, I think that we may just need to add a handful (rather than all), and this division should also help us avoid some of the dependencies during compile time. Open to more opinions on this, of course.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-501388653
https://github.com/su2code/SU2/issues/583#issuecomment-501388653:330,Safety,avoid,avoid,330,"@pcarruscag : as for header issues, I believe the consensus was also moving toward completely splitting the headers by class as well. It is true that then we may need to include multiple headers one-by-one, but in most cases, I think that we may just need to add a handful (rather than all), and this division should also help us avoid some of the dependencies during compile time. Open to more opinions on this, of course.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-501388653
https://github.com/su2code/SU2/issues/583#issuecomment-503683529:247,Integrability,depend,dependencies,247,"Same. If we construct it correctly, I am hoping that we will actually only need to include certain individual headers in the solvers, etc. (or maybe just the parent numerics header w virtual function descriptions) so that we can break some of the dependencies that lead to longer build time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-503683529
https://github.com/su2code/SU2/issues/583#issuecomment-515439305:318,Availability,toler,tolerate,318,"Yeah, some class files are so long that even the compilers will complain. I once compiled a cross-platform project in Windows and the VS compiler complained about the length of several files in the project had exceeded the limit(they are about 4000 lines). I have to manually edit the compiler length limit to make it tolerate the codes. . **driver_structure.cpp** has about 8000 lines in the master branch. Really horrible. Luckily you have restructured them. That must be a nightmare for newcomers. Splitting the class files into pieces composed of parent class and its classes and putting them in a subfolder will be deeply appreciated. Desirable file size may be less than 1500 or 2000 lines?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-515439305
https://github.com/su2code/SU2/issues/583#issuecomment-630640981:545,Testability,log,logically,545,"We are getting closer on this topic, but I am still wondering if we can go further... . I think it would be great if we can eventually do away entirely with the first two levels of the directory structure: the Common/, SU2_CFD/, etc. level as well as the src/, obj/, etc. level below that. Instead, we can have all cpp and hpp alongside each other in the various subdirectories at the root level (or maybe inside a single cpp/ or src/ directory at the root level). . At the moment, a lot of navigation is required to move between files that are logically related due to the module structure and the separate of cpp/hpp files.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630640981
https://github.com/su2code/SU2/issues/583#issuecomment-630724704:90,Modifiability,variab,variable,90,"What do you mean by logically related? [Compressible / Incompressible / Turbulent] solver+variable+numerics+output ?; I think having the top level of folders following the class hierarchy is helpful to someone who is trying to follow the code execution for the first time.; Maybe we can have some subdirs for specific physics in /solvers /variables and /output (similar to what I did with /numerics to keep a compromise between the old file structure and the new)?; I would not mind merging Common and SU2_CFD now that there are descriptive sub-directories for geometry, solvers, etc. I'm not sure if linking everything into just one library is a good idea though (e.g. is it going to make the binaries much larger?).; We should perhaps then move the applications to a separate folder ""SU2_APPS"" where we would put CFD, DEF, DOT etc.; I don't mind having hpp's and cpp's together as we have a fair bit of implementation also in header files, I guess most IDE's have filters to separate them if folks prefer to see them that way.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630724704
https://github.com/su2code/SU2/issues/583#issuecomment-630724704:339,Modifiability,variab,variables,339,"What do you mean by logically related? [Compressible / Incompressible / Turbulent] solver+variable+numerics+output ?; I think having the top level of folders following the class hierarchy is helpful to someone who is trying to follow the code execution for the first time.; Maybe we can have some subdirs for specific physics in /solvers /variables and /output (similar to what I did with /numerics to keep a compromise between the old file structure and the new)?; I would not mind merging Common and SU2_CFD now that there are descriptive sub-directories for geometry, solvers, etc. I'm not sure if linking everything into just one library is a good idea though (e.g. is it going to make the binaries much larger?).; We should perhaps then move the applications to a separate folder ""SU2_APPS"" where we would put CFD, DEF, DOT etc.; I don't mind having hpp's and cpp's together as we have a fair bit of implementation also in header files, I guess most IDE's have filters to separate them if folks prefer to see them that way.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630724704
https://github.com/su2code/SU2/issues/583#issuecomment-630724704:20,Testability,log,logically,20,"What do you mean by logically related? [Compressible / Incompressible / Turbulent] solver+variable+numerics+output ?; I think having the top level of folders following the class hierarchy is helpful to someone who is trying to follow the code execution for the first time.; Maybe we can have some subdirs for specific physics in /solvers /variables and /output (similar to what I did with /numerics to keep a compromise between the old file structure and the new)?; I would not mind merging Common and SU2_CFD now that there are descriptive sub-directories for geometry, solvers, etc. I'm not sure if linking everything into just one library is a good idea though (e.g. is it going to make the binaries much larger?).; We should perhaps then move the applications to a separate folder ""SU2_APPS"" where we would put CFD, DEF, DOT etc.; I don't mind having hpp's and cpp's together as we have a fair bit of implementation also in header files, I guess most IDE's have filters to separate them if folks prefer to see them that way.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630724704
https://github.com/su2code/SU2/issues/583#issuecomment-630918578:33,Modifiability,variab,variable,33,"To be clear: I like the solver/, variable/, output/, etc. layout a lot, and I am simply suggesting that we move entirely to that layout (with cpp and hpp merged together in each of those folders) and merging the code in Common, SU2_CFD, and other modules into that structure too (in their own folders still, like geometry/ for example). To keep it organized you can simply make each of those directories a library in meson which all later get linked into the various binaries. The mains could live in the top level src/ directory if we keep it or a separate directory (open for me). Something like. ```; SU2/; src/; solver/; meson.build; solver_\*.cpp; solver_\*.hpp; variable/; meson.build; variable_\*.cpp; variable_\*.hpp; ...; ```. with or without the src/ directory in the root (could go either way). Might want to keep it or even name it cpp/ to differentiate from the python framework(s).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630918578
https://github.com/su2code/SU2/issues/583#issuecomment-630918578:668,Modifiability,variab,variable,668,"To be clear: I like the solver/, variable/, output/, etc. layout a lot, and I am simply suggesting that we move entirely to that layout (with cpp and hpp merged together in each of those folders) and merging the code in Common, SU2_CFD, and other modules into that structure too (in their own folders still, like geometry/ for example). To keep it organized you can simply make each of those directories a library in meson which all later get linked into the various binaries. The mains could live in the top level src/ directory if we keep it or a separate directory (open for me). Something like. ```; SU2/; src/; solver/; meson.build; solver_\*.cpp; solver_\*.hpp; variable/; meson.build; variable_\*.cpp; variable_\*.hpp; ...; ```. with or without the src/ directory in the root (could go either way). Might want to keep it or even name it cpp/ to differentiate from the python framework(s).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630918578
https://github.com/su2code/SU2/issues/583#issuecomment-630918578:6,Usability,clear,clear,6,"To be clear: I like the solver/, variable/, output/, etc. layout a lot, and I am simply suggesting that we move entirely to that layout (with cpp and hpp merged together in each of those folders) and merging the code in Common, SU2_CFD, and other modules into that structure too (in their own folders still, like geometry/ for example). To keep it organized you can simply make each of those directories a library in meson which all later get linked into the various binaries. The mains could live in the top level src/ directory if we keep it or a separate directory (open for me). Something like. ```; SU2/; src/; solver/; meson.build; solver_\*.cpp; solver_\*.hpp; variable/; meson.build; variable_\*.cpp; variable_\*.hpp; ...; ```. with or without the src/ directory in the root (could go either way). Might want to keep it or even name it cpp/ to differentiate from the python framework(s).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630918578
https://github.com/su2code/SU2/issues/583#issuecomment-630918578:81,Usability,simpl,simply,81,"To be clear: I like the solver/, variable/, output/, etc. layout a lot, and I am simply suggesting that we move entirely to that layout (with cpp and hpp merged together in each of those folders) and merging the code in Common, SU2_CFD, and other modules into that structure too (in their own folders still, like geometry/ for example). To keep it organized you can simply make each of those directories a library in meson which all later get linked into the various binaries. The mains could live in the top level src/ directory if we keep it or a separate directory (open for me). Something like. ```; SU2/; src/; solver/; meson.build; solver_\*.cpp; solver_\*.hpp; variable/; meson.build; variable_\*.cpp; variable_\*.hpp; ...; ```. with or without the src/ directory in the root (could go either way). Might want to keep it or even name it cpp/ to differentiate from the python framework(s).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630918578
https://github.com/su2code/SU2/issues/583#issuecomment-630918578:366,Usability,simpl,simply,366,"To be clear: I like the solver/, variable/, output/, etc. layout a lot, and I am simply suggesting that we move entirely to that layout (with cpp and hpp merged together in each of those folders) and merging the code in Common, SU2_CFD, and other modules into that structure too (in their own folders still, like geometry/ for example). To keep it organized you can simply make each of those directories a library in meson which all later get linked into the various binaries. The mains could live in the top level src/ directory if we keep it or a separate directory (open for me). Something like. ```; SU2/; src/; solver/; meson.build; solver_\*.cpp; solver_\*.hpp; variable/; meson.build; variable_\*.cpp; variable_\*.hpp; ...; ```. with or without the src/ directory in the root (could go either way). Might want to keep it or even name it cpp/ to differentiate from the python framework(s).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630918578
https://github.com/su2code/SU2/issues/583#issuecomment-630925996:324,Modifiability,variab,variables,324,"Got it, by navigation you mean from cpp to hpp then?; I agree with you but I would suggest having those extra subdirs in solver and co.; ```; SU2/; solvers/; meson.build; CSolver.hpp; CSolver.cpp; flow/; solver_\*.cpp; solver_\*.hpp; turbulence/; ```; For me what makes navigation a bit cumbersome is scrolling past all the variables to get to the ones of a particular solver for example, the hpp/cpp I don't mind so much they are 2 clicks away in the IDE I use.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-630925996
https://github.com/su2code/SU2/issues/583#issuecomment-631567733:605,Energy Efficiency,adapt,adaptation,605,"Documenting the plan discussed in our developers call this morning here:; * Put header and sources together ; * Remove separation between Common/, SU2_CFD/, etc.; * Each major folder becomes a library (geometry/, solvers/, etc.); * Keep some subdirectories in major folders (e.g., solvers/flow/); * Set up include paths in the meson build system to make #include statements clean in the source; * Will prob require removing automake as part of this, which cant build these libraries in parallel. Still need to finish separating files first. Tasks:; * @talbring - iteration classes; * @jayantmukho - grid adaptation, ADT structure, grid movement; * @pcarruscag - AD structure, folders for fem_\* ; * @economon - fluid model. Somewhat related:; * Run a test to see how many formatting-related conflicts result from running clang-format on and then diffing two fairly different branches (@pcarruscag). Please add anything else I am missing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-631567733
https://github.com/su2code/SU2/issues/583#issuecomment-631567733:605,Modifiability,adapt,adaptation,605,"Documenting the plan discussed in our developers call this morning here:; * Put header and sources together ; * Remove separation between Common/, SU2_CFD/, etc.; * Each major folder becomes a library (geometry/, solvers/, etc.); * Keep some subdirectories in major folders (e.g., solvers/flow/); * Set up include paths in the meson build system to make #include statements clean in the source; * Will prob require removing automake as part of this, which cant build these libraries in parallel. Still need to finish separating files first. Tasks:; * @talbring - iteration classes; * @jayantmukho - grid adaptation, ADT structure, grid movement; * @pcarruscag - AD structure, folders for fem_\* ; * @economon - fluid model. Somewhat related:; * Run a test to see how many formatting-related conflicts result from running clang-format on and then diffing two fairly different branches (@pcarruscag). Please add anything else I am missing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-631567733
https://github.com/su2code/SU2/issues/583#issuecomment-631567733:752,Testability,test,test,752,"Documenting the plan discussed in our developers call this morning here:; * Put header and sources together ; * Remove separation between Common/, SU2_CFD/, etc.; * Each major folder becomes a library (geometry/, solvers/, etc.); * Keep some subdirectories in major folders (e.g., solvers/flow/); * Set up include paths in the meson build system to make #include statements clean in the source; * Will prob require removing automake as part of this, which cant build these libraries in parallel. Still need to finish separating files first. Tasks:; * @talbring - iteration classes; * @jayantmukho - grid adaptation, ADT structure, grid movement; * @pcarruscag - AD structure, folders for fem_\* ; * @economon - fluid model. Somewhat related:; * Run a test to see how many formatting-related conflicts result from running clang-format on and then diffing two fairly different branches (@pcarruscag). Please add anything else I am missing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-631567733
https://github.com/su2code/SU2/issues/583#issuecomment-656154231:342,Safety,safe,safe,342,"Couple of issues with clang-format, found in the context of #1044, on this kind of style:. ```; su2double; foo, /* blabla */; bar; /* blabla */; ```; It goes mental sometimes. Order of includes is modified, which is guaranteed to break compilation. So running clang-format on the whole code in one go is maybe possibly perhaps definitely not safe.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-656154231
https://github.com/su2code/SU2/issues/583#issuecomment-733803863:494,Deployability,update,updates,494,"@ALL we are aiming to complete this work (see Tom's comment on the 20th of May) **within 3 months**.; In so doing we will also **discontinue the legacy build system** (pending some testing on machines without internet connection). So, if you have branches with large changes to existing files, bring them to develop ASAP to minimize conflicts.; If you have new files, the conflicts will be less severe (just include paths probably). I will try to script this file movement and subsequent meson updates, so that in the worst case folks can do the same modifications on their branches automatically and then merge the also modified develop.; But, because we also **want to put clangformat in place**, I REALLY encourage you to merge your work into develop soon!; It is the perfect time to give your code to the world and also to give code reviews to your fellow SU2'ers. I'll come back with updates and reminders. P.S. 3 months, tick-tock tick-tock :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-733803863
https://github.com/su2code/SU2/issues/583#issuecomment-733803863:889,Deployability,update,updates,889,"@ALL we are aiming to complete this work (see Tom's comment on the 20th of May) **within 3 months**.; In so doing we will also **discontinue the legacy build system** (pending some testing on machines without internet connection). So, if you have branches with large changes to existing files, bring them to develop ASAP to minimize conflicts.; If you have new files, the conflicts will be less severe (just include paths probably). I will try to script this file movement and subsequent meson updates, so that in the worst case folks can do the same modifications on their branches automatically and then merge the also modified develop.; But, because we also **want to put clangformat in place**, I REALLY encourage you to merge your work into develop soon!; It is the perfect time to give your code to the world and also to give code reviews to your fellow SU2'ers. I'll come back with updates and reminders. P.S. 3 months, tick-tock tick-tock :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-733803863
https://github.com/su2code/SU2/issues/583#issuecomment-733803863:181,Testability,test,testing,181,"@ALL we are aiming to complete this work (see Tom's comment on the 20th of May) **within 3 months**.; In so doing we will also **discontinue the legacy build system** (pending some testing on machines without internet connection). So, if you have branches with large changes to existing files, bring them to develop ASAP to minimize conflicts.; If you have new files, the conflicts will be less severe (just include paths probably). I will try to script this file movement and subsequent meson updates, so that in the worst case folks can do the same modifications on their branches automatically and then merge the also modified develop.; But, because we also **want to put clangformat in place**, I REALLY encourage you to merge your work into develop soon!; It is the perfect time to give your code to the world and also to give code reviews to your fellow SU2'ers. I'll come back with updates and reminders. P.S. 3 months, tick-tock tick-tock :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-733803863
https://github.com/su2code/SU2/issues/583#issuecomment-734184730:275,Availability,alive,alive,275,"Hi, ; I'm worried about discontinuing the legacy build system. While on internet-connected machines the Meson-Ninja build is superior, I still didn't manage to apply it on clusters without such a connection. In my opinion should keep the configure-make-make install approach alive so that installation is possible for everyone, not just very efficient to part of the community ; Best, Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-734184730
https://github.com/su2code/SU2/issues/583#issuecomment-734184730:258,Deployability,install,install,258,"Hi, ; I'm worried about discontinuing the legacy build system. While on internet-connected machines the Meson-Ninja build is superior, I still didn't manage to apply it on clusters without such a connection. In my opinion should keep the configure-make-make install approach alive so that installation is possible for everyone, not just very efficient to part of the community ; Best, Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-734184730
https://github.com/su2code/SU2/issues/583#issuecomment-734184730:289,Deployability,install,installation,289,"Hi, ; I'm worried about discontinuing the legacy build system. While on internet-connected machines the Meson-Ninja build is superior, I still didn't manage to apply it on clusters without such a connection. In my opinion should keep the configure-make-make install approach alive so that installation is possible for everyone, not just very efficient to part of the community ; Best, Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-734184730
https://github.com/su2code/SU2/issues/583#issuecomment-734184730:342,Energy Efficiency,efficient,efficient,342,"Hi, ; I'm worried about discontinuing the legacy build system. While on internet-connected machines the Meson-Ninja build is superior, I still didn't manage to apply it on clusters without such a connection. In my opinion should keep the configure-make-make install approach alive so that installation is possible for everyone, not just very efficient to part of the community ; Best, Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-734184730
https://github.com/su2code/SU2/issues/583#issuecomment-734184730:238,Modifiability,config,configure-make-make,238,"Hi, ; I'm worried about discontinuing the legacy build system. While on internet-connected machines the Meson-Ninja build is superior, I still didn't manage to apply it on clusters without such a connection. In my opinion should keep the configure-make-make install approach alive so that installation is possible for everyone, not just very efficient to part of the community ; Best, Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/583#issuecomment-734184730
https://github.com/su2code/SU2/issues/584#issuecomment-423634535:84,Deployability,update,update,84,I'm running into problems as well on some machines. So I think it is a good idea to update the autotools to a more recent version. Don't know how much work this is though.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/584#issuecomment-423634535
https://github.com/su2code/SU2/pull/585#issuecomment-424220665:245,Testability,test,tests,245,"Great to see this, and thanks for all of the effort. Your preparation really showed at the developers meeting. Is it possible for you to also share your multi zone CHT example from the dev meeting slides in this branch? I would like to do a few tests with a concrete case to try it out.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-424220665
https://github.com/su2code/SU2/pull/585#issuecomment-441210349:107,Availability,mainten,maintenance,107,"Hello all, ; as I have mentioned before, this PR is the first of a series that are coming soon for general maintenance and improved usability of the code. As you all know, we are working hard to improve the generality and usability of the code and to maintain it healthy. ; We have some other improvements/generalizations that rely on this one. Therefore, I think it would be a good idea to merge this in sooner than later, to transition smoothly to this new structure.; Best,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-441210349
https://github.com/su2code/SU2/pull/585#issuecomment-441210349:132,Usability,usab,usability,132,"Hello all, ; as I have mentioned before, this PR is the first of a series that are coming soon for general maintenance and improved usability of the code. As you all know, we are working hard to improve the generality and usability of the code and to maintain it healthy. ; We have some other improvements/generalizations that rely on this one. Therefore, I think it would be a good idea to merge this in sooner than later, to transition smoothly to this new structure.; Best,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-441210349
https://github.com/su2code/SU2/pull/585#issuecomment-441210349:222,Usability,usab,usability,222,"Hello all, ; as I have mentioned before, this PR is the first of a series that are coming soon for general maintenance and improved usability of the code. As you all know, we are working hard to improve the generality and usability of the code and to maintain it healthy. ; We have some other improvements/generalizations that rely on this one. Therefore, I think it would be a good idea to merge this in sooner than later, to transition smoothly to this new structure.; Best,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-441210349
https://github.com/su2code/SU2/pull/585#issuecomment-442003606:54,Deployability,update,updates,54,"Thanks for your comments @economon ! I have done some updates with develop, removed warnings, and I think this is good to go once the tests pass.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-442003606
https://github.com/su2code/SU2/pull/585#issuecomment-442003606:134,Testability,test,tests,134,"Thanks for your comments @economon ! I have done some updates with develop, removed warnings, and I think this is good to go once the tests pass.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/585#issuecomment-442003606
https://github.com/su2code/SU2/pull/586#issuecomment-423765856:241,Deployability,install,installed,241,What if we remove all the generated files (Makefile.in) from the repository except for the master branch ? In my opinion that makes perfectly sense since developers (so all people which use branches other than master) usually have autotools installed.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423765856
https://github.com/su2code/SU2/pull/586#issuecomment-423795781:98,Deployability,install,install,98,"Tim,; I think the Makefile.in are useful also in the developer branch. First for; cases where you install a new machine. Second, for new users who are; already opensource-expirienced and tend to work with develop branch.; Best; Eran; On Sat, Sep 22, 2018 at 20:00 Tim Albring <notifications@github.com> wrote:. > What if we remove all the generated files (Makefile.in) from the; > repository except for the master branch ? In my opinion that makes; > perfectly sense since developers (so all people which use branches other; > than master) usually have autotools installed.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/586#issuecomment-423765856>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm-t5IxKPOTuYcY_X58jdqUrmZuEFks5udojGgaJpZM4W1Vuz>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423795781
https://github.com/su2code/SU2/pull/586#issuecomment-423795781:563,Deployability,install,installed,563,"Tim,; I think the Makefile.in are useful also in the developer branch. First for; cases where you install a new machine. Second, for new users who are; already opensource-expirienced and tend to work with develop branch.; Best; Eran; On Sat, Sep 22, 2018 at 20:00 Tim Albring <notifications@github.com> wrote:. > What if we remove all the generated files (Makefile.in) from the; > repository except for the master branch ? In my opinion that makes; > perfectly sense since developers (so all people which use branches other; > than master) usually have autotools installed.; >; > ; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/586#issuecomment-423765856>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/APKNm-t5IxKPOTuYcY_X58jdqUrmZuEFks5udojGgaJpZM4W1Vuz>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423795781
https://github.com/su2code/SU2/pull/586#issuecomment-423805426:81,Modifiability,config,configure,81,"Eran,. I don't see the problem. The only thing you have to do before calling the configure script is to invoke autoreconf (which is included in all repos of any distribution). At the moment we have to do that most of the time anyway due to compatibility problems.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423805426
https://github.com/su2code/SU2/pull/586#issuecomment-423889045:404,Deployability,update,update,404,"Hi @economon,; thanks for cleaning this. One question, I think that LAPACK may be used by the RBF feature in #555, but to confirm, @pcarruscag, is this the case?; Regarding the autotools, I agree with @vdweide, I think we should use this PR to fix them. I think that @talbring proposal is a good idea, it would avoid the constant conflict that we have when we develop in different machines. I would also update the version of autotools provided in externals, so when bootstrap is run a recent version is compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423889045
https://github.com/su2code/SU2/pull/586#issuecomment-423889045:311,Safety,avoid,avoid,311,"Hi @economon,; thanks for cleaning this. One question, I think that LAPACK may be used by the RBF feature in #555, but to confirm, @pcarruscag, is this the case?; Regarding the autotools, I agree with @vdweide, I think we should use this PR to fix them. I think that @talbring proposal is a good idea, it would avoid the constant conflict that we have when we develop in different machines. I would also update the version of autotools provided in externals, so when bootstrap is run a recent version is compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423889045
https://github.com/su2code/SU2/pull/586#issuecomment-423923605:81,Modifiability,variab,variables,81,"@rsanfer, you can always specify the lapack libraries by setting the environment variables LDFLAGS and LIBS. This is what I do and it gives you more control than specifying it in configure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423923605
https://github.com/su2code/SU2/pull/586#issuecomment-423923605:179,Modifiability,config,configure,179,"@rsanfer, you can always specify the lapack libraries by setting the environment variables LDFLAGS and LIBS. This is what I do and it gives you more control than specifying it in configure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423923605
https://github.com/su2code/SU2/pull/586#issuecomment-423933257:185,Deployability,install,install,185,"@rsanfer I've only done it through the environment variables like Edwin suggests, and that is how I documented it. That way the libraries can be anywhere which is handy when you can't ""install"" them in the machine you want to run on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423933257
https://github.com/su2code/SU2/pull/586#issuecomment-423933257:51,Modifiability,variab,variables,51,"@rsanfer I've only done it through the environment variables like Edwin suggests, and that is how I documented it. That way the libraries can be anywhere which is handy when you can't ""install"" them in the machine you want to run on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423933257
https://github.com/su2code/SU2/pull/586#issuecomment-423941082:121,Modifiability,config,configure,121,"@vdweide @pcarruscag ah ok, I wasn't sure how it was working on the RBF but seeing that there is no need for it to be in configure, it's better to clean it up as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423941082
https://github.com/su2code/SU2/pull/586#issuecomment-423942141:284,Deployability,install,installed,284,"@rsanfer and me had a discussion on it. We both came to the agreement that it might the best if we just remove the generated files from the repo in general. Since buildtools are already required to have 'make' it shouldn't be much of a burden to also require autotools/automake to be installed. Furthermore, we eventually could provide a simple way of installing/compiling it within the preconfigure.py script if necessary.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423942141
https://github.com/su2code/SU2/pull/586#issuecomment-423942141:352,Deployability,install,installing,352,"@rsanfer and me had a discussion on it. We both came to the agreement that it might the best if we just remove the generated files from the repo in general. Since buildtools are already required to have 'make' it shouldn't be much of a burden to also require autotools/automake to be installed. Furthermore, we eventually could provide a simple way of installing/compiling it within the preconfigure.py script if necessary.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423942141
https://github.com/su2code/SU2/pull/586#issuecomment-423942141:338,Usability,simpl,simple,338,"@rsanfer and me had a discussion on it. We both came to the agreement that it might the best if we just remove the generated files from the repo in general. Since buildtools are already required to have 'make' it shouldn't be much of a burden to also require autotools/automake to be installed. Furthermore, we eventually could provide a simple way of installing/compiling it within the preconfigure.py script if necessary.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-423942141
https://github.com/su2code/SU2/pull/586#issuecomment-424210049:123,Availability,avail,available,123,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? Its important that we dont jump too far ahead for portability reasons (thats why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
https://github.com/su2code/SU2/pull/586#issuecomment-424210049:217,Deployability,update,update,217,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? Its important that we dont jump too far ahead for portability reasons (thats why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
https://github.com/su2code/SU2/pull/586#issuecomment-424210049:570,Deployability,update,update,570,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? Its important that we dont jump too far ahead for portability reasons (thats why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
https://github.com/su2code/SU2/pull/586#issuecomment-424210049:369,Integrability,depend,dependencies,369,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? Its important that we dont jump too far ahead for portability reasons (thats why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
https://github.com/su2code/SU2/pull/586#issuecomment-424210049:672,Modifiability,portab,portability,672,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? Its important that we dont jump too far ahead for portability reasons (thats why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
https://github.com/su2code/SU2/pull/586#issuecomment-424210049:450,Usability,clear,clearly,450,"I tend to agree w Eran on this topic. When it is working as it should, it is very convenient to have the makefiles already available in the repo. I switch between Mac, Ubuntu, and a red hat cluster without needing to update anything or call the bootstrap script. I rarely use it.. basically only when adding or removing files to the build. Also, it is good to minimize dependencies, as sometimes old machines or clusters have limited tool sets. But, clearly we should at a minimum fix the issue that some of you are finding with the autotools, which should just need an update. What systems are you having trouble with? Its important that we dont jump too far ahead for portability reasons (thats why we have kept the old versions for so long). Do you have an idea of the minimum autotools you need for the failing systems? We could start by updating to that version and see if things stabilize.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424210049
https://github.com/su2code/SU2/pull/586#issuecomment-424630264:315,Deployability,install,installed,315,"@economon, I agree with you that you only need to run the bootstrap when you add new files. At least that is the case for me, I don't know about other users. Unfortunately, I had to do that relatively often, which didn't always run smoothly with the autotools shipped with SU2. Sometimes I had to use the autotools installed on the system, which now runs Ubuntu 18.05 (automake 1.15.1). . I also agree with you that we should make sure that the entire build process works on as many systems as possible. Therefore I would say that Tim's suggestion to remove all the automatically generated files from the repository is a good one, because then you also remove all possible conflicts. Of course we have to make sure that .gitignore is updated accordingly, but that is just a detail.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424630264
https://github.com/su2code/SU2/pull/586#issuecomment-424630264:734,Deployability,update,updated,734,"@economon, I agree with you that you only need to run the bootstrap when you add new files. At least that is the case for me, I don't know about other users. Unfortunately, I had to do that relatively often, which didn't always run smoothly with the autotools shipped with SU2. Sometimes I had to use the autotools installed on the system, which now runs Ubuntu 18.05 (automake 1.15.1). . I also agree with you that we should make sure that the entire build process works on as many systems as possible. Therefore I would say that Tim's suggestion to remove all the automatically generated files from the repository is a good one, because then you also remove all possible conflicts. Of course we have to make sure that .gitignore is updated accordingly, but that is just a detail.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-424630264
https://github.com/su2code/SU2/pull/586#issuecomment-426472369:183,Testability,test,test,183,It looks like replacing autotools is fairly straightforward - while I'm at it I'll go ahead and remove the .in and .m4f files from the repo. ; I'll push that up to this branch once I test it on my own system - however I will only have tested this on an ubuntu system so it would be good to double check it on a different OS.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-426472369
https://github.com/su2code/SU2/pull/586#issuecomment-426472369:235,Testability,test,tested,235,It looks like replacing autotools is fairly straightforward - while I'm at it I'll go ahead and remove the .in and .m4f files from the repo. ; I'll push that up to this branch once I test it on my own system - however I will only have tested this on an ubuntu system so it would be good to double check it on a different OS.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-426472369
https://github.com/su2code/SU2/pull/586#issuecomment-426508949:120,Testability,test,testing,120,"Thanks for taking a shot at this. Just let us know if you need some help, and I am sure several of us can help with the testing. I can try on multiple systems here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-426508949
https://github.com/su2code/SU2/pull/586#issuecomment-426518081:6,Testability,test,test,6,"I can test it on both Centos 7.5 and Ubuntu 18.04, if needed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-426518081
https://github.com/su2code/SU2/pull/586#issuecomment-426853815:94,Deployability,install,installs,94,"Two options: one (most recent commit, 23ed002) which requires running ./bootstrap for all new installs, and in commit ce9cd2b that updates automake but doesn't require ./bootstrap (through including updated Makefile.in's, etc). ; updated automake found here: https://ftp.gnu.org/gnu/automake/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-426853815
https://github.com/su2code/SU2/pull/586#issuecomment-426853815:131,Deployability,update,updates,131,"Two options: one (most recent commit, 23ed002) which requires running ./bootstrap for all new installs, and in commit ce9cd2b that updates automake but doesn't require ./bootstrap (through including updated Makefile.in's, etc). ; updated automake found here: https://ftp.gnu.org/gnu/automake/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-426853815
https://github.com/su2code/SU2/pull/586#issuecomment-426853815:199,Deployability,update,updated,199,"Two options: one (most recent commit, 23ed002) which requires running ./bootstrap for all new installs, and in commit ce9cd2b that updates automake but doesn't require ./bootstrap (through including updated Makefile.in's, etc). ; updated automake found here: https://ftp.gnu.org/gnu/automake/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-426853815
https://github.com/su2code/SU2/pull/586#issuecomment-426853815:230,Deployability,update,updated,230,"Two options: one (most recent commit, 23ed002) which requires running ./bootstrap for all new installs, and in commit ce9cd2b that updates automake but doesn't require ./bootstrap (through including updated Makefile.in's, etc). ; updated automake found here: https://ftp.gnu.org/gnu/automake/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-426853815
https://github.com/su2code/SU2/pull/586#issuecomment-427011685:280,Modifiability,config,configure,280,"I tested this on Ubuntu 18.04 and Centos 7.5. On Ubuntu both options work fine. However, on Centos only the most recent commit (i.e. running ./bootstrap) works. The commit ce9cd2b fails, because the system runs automake 1.13 and therefore it cannot find aclocal-1.15 when running configure. This can be solved by either changing am__api_version in configure to 1.13 (dirty) or running bootstrap. However, I don't know if either option is desired. BTW, this problem will also show up for the master branch, whatever option will be chosen, as for the master branch the configure and Makefile.in's will be in the distribution. In short, the option with bootstrap works fine on the operating systems I tested (and I assume on all Linux and Unix distributions). When configure is present in the distribution, you could run into problems if the system does not have the required version of autotools.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427011685
https://github.com/su2code/SU2/pull/586#issuecomment-427011685:348,Modifiability,config,configure,348,"I tested this on Ubuntu 18.04 and Centos 7.5. On Ubuntu both options work fine. However, on Centos only the most recent commit (i.e. running ./bootstrap) works. The commit ce9cd2b fails, because the system runs automake 1.13 and therefore it cannot find aclocal-1.15 when running configure. This can be solved by either changing am__api_version in configure to 1.13 (dirty) or running bootstrap. However, I don't know if either option is desired. BTW, this problem will also show up for the master branch, whatever option will be chosen, as for the master branch the configure and Makefile.in's will be in the distribution. In short, the option with bootstrap works fine on the operating systems I tested (and I assume on all Linux and Unix distributions). When configure is present in the distribution, you could run into problems if the system does not have the required version of autotools.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427011685
https://github.com/su2code/SU2/pull/586#issuecomment-427011685:567,Modifiability,config,configure,567,"I tested this on Ubuntu 18.04 and Centos 7.5. On Ubuntu both options work fine. However, on Centos only the most recent commit (i.e. running ./bootstrap) works. The commit ce9cd2b fails, because the system runs automake 1.13 and therefore it cannot find aclocal-1.15 when running configure. This can be solved by either changing am__api_version in configure to 1.13 (dirty) or running bootstrap. However, I don't know if either option is desired. BTW, this problem will also show up for the master branch, whatever option will be chosen, as for the master branch the configure and Makefile.in's will be in the distribution. In short, the option with bootstrap works fine on the operating systems I tested (and I assume on all Linux and Unix distributions). When configure is present in the distribution, you could run into problems if the system does not have the required version of autotools.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427011685
https://github.com/su2code/SU2/pull/586#issuecomment-427011685:762,Modifiability,config,configure,762,"I tested this on Ubuntu 18.04 and Centos 7.5. On Ubuntu both options work fine. However, on Centos only the most recent commit (i.e. running ./bootstrap) works. The commit ce9cd2b fails, because the system runs automake 1.13 and therefore it cannot find aclocal-1.15 when running configure. This can be solved by either changing am__api_version in configure to 1.13 (dirty) or running bootstrap. However, I don't know if either option is desired. BTW, this problem will also show up for the master branch, whatever option will be chosen, as for the master branch the configure and Makefile.in's will be in the distribution. In short, the option with bootstrap works fine on the operating systems I tested (and I assume on all Linux and Unix distributions). When configure is present in the distribution, you could run into problems if the system does not have the required version of autotools.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427011685
https://github.com/su2code/SU2/pull/586#issuecomment-427011685:2,Testability,test,tested,2,"I tested this on Ubuntu 18.04 and Centos 7.5. On Ubuntu both options work fine. However, on Centos only the most recent commit (i.e. running ./bootstrap) works. The commit ce9cd2b fails, because the system runs automake 1.13 and therefore it cannot find aclocal-1.15 when running configure. This can be solved by either changing am__api_version in configure to 1.13 (dirty) or running bootstrap. However, I don't know if either option is desired. BTW, this problem will also show up for the master branch, whatever option will be chosen, as for the master branch the configure and Makefile.in's will be in the distribution. In short, the option with bootstrap works fine on the operating systems I tested (and I assume on all Linux and Unix distributions). When configure is present in the distribution, you could run into problems if the system does not have the required version of autotools.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427011685
https://github.com/su2code/SU2/pull/586#issuecomment-427011685:698,Testability,test,tested,698,"I tested this on Ubuntu 18.04 and Centos 7.5. On Ubuntu both options work fine. However, on Centos only the most recent commit (i.e. running ./bootstrap) works. The commit ce9cd2b fails, because the system runs automake 1.13 and therefore it cannot find aclocal-1.15 when running configure. This can be solved by either changing am__api_version in configure to 1.13 (dirty) or running bootstrap. However, I don't know if either option is desired. BTW, this problem will also show up for the master branch, whatever option will be chosen, as for the master branch the configure and Makefile.in's will be in the distribution. In short, the option with bootstrap works fine on the operating systems I tested (and I assume on all Linux and Unix distributions). When configure is present in the distribution, you could run into problems if the system does not have the required version of autotools.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427011685
https://github.com/su2code/SU2/pull/586#issuecomment-427219063:333,Deployability,install,installation,333,"It sounds like the version requiring bootstrap is the way to go - given that otherwise this is a choice between either not working on 1.15 or not working on 1.13. Assuming that updating .gitignore doesn't cause any problems that's it for now from me. ; We will probably need to either add a line about running bootstrap first to the installation directions, and/or have it taken care of inside the preconfigure.py script prior to this getting merged to master at the next release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427219063
https://github.com/su2code/SU2/pull/586#issuecomment-427219063:472,Deployability,release,release,472,"It sounds like the version requiring bootstrap is the way to go - given that otherwise this is a choice between either not working on 1.15 or not working on 1.13. Assuming that updating .gitignore doesn't cause any problems that's it for now from me. ; We will probably need to either add a line about running bootstrap first to the installation directions, and/or have it taken care of inside the preconfigure.py script prior to this getting merged to master at the next release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427219063
https://github.com/su2code/SU2/pull/586#issuecomment-427220419:185,Availability,down,download,185,"I can report that both seem to work ok for me on macOS 10.13, including the bootstrap script. It would be good to work out our strategy so that this doesn't cause issues for those that download the source distribution, keeping in mind that many users still build from source (the binaries are only serial).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427220419
https://github.com/su2code/SU2/pull/586#issuecomment-427404615:467,Deployability,install,install,467,"Just playing devil's advocate: are there reasons for removing the files other than possible conflicts in the generated Makefile.in during development?. If it works most of the time out of the box, then I think the lesser evil is for a few developers (who know a little about autotools) to deal with these conflicts from time to time rather than force all users to take an additional step to run bootstrap, which could be confusing. I think that having configure-make-install work immediately for most folks is important for the growth of the code (ease of install is critical or people will give up). In some cases it will fail, and bootstrap is there to save the day in those cases. Any other considerations I am forgetting?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427404615
https://github.com/su2code/SU2/pull/586#issuecomment-427404615:556,Deployability,install,install,556,"Just playing devil's advocate: are there reasons for removing the files other than possible conflicts in the generated Makefile.in during development?. If it works most of the time out of the box, then I think the lesser evil is for a few developers (who know a little about autotools) to deal with these conflicts from time to time rather than force all users to take an additional step to run bootstrap, which could be confusing. I think that having configure-make-install work immediately for most folks is important for the growth of the code (ease of install is critical or people will give up). In some cases it will fail, and bootstrap is there to save the day in those cases. Any other considerations I am forgetting?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427404615
https://github.com/su2code/SU2/pull/586#issuecomment-427404615:452,Modifiability,config,configure-make-install,452,"Just playing devil's advocate: are there reasons for removing the files other than possible conflicts in the generated Makefile.in during development?. If it works most of the time out of the box, then I think the lesser evil is for a few developers (who know a little about autotools) to deal with these conflicts from time to time rather than force all users to take an additional step to run bootstrap, which could be confusing. I think that having configure-make-install work immediately for most folks is important for the growth of the code (ease of install is critical or people will give up). In some cases it will fail, and bootstrap is there to save the day in those cases. Any other considerations I am forgetting?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427404615
https://github.com/su2code/SU2/pull/586#issuecomment-427430150:45,Modifiability,config,configure,45,"@economon, I think you forget one thing. The configure script requires aclocal. When a newer version of the autotools is used to create the configure script, it does not work (as far as I know) and you still need the bootstrap in order to get things to work. The solution to this would be to use a less recent version of autotools, but that is not what we want either, I guess.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427430150
https://github.com/su2code/SU2/pull/586#issuecomment-427430150:140,Modifiability,config,configure,140,"@economon, I think you forget one thing. The configure script requires aclocal. When a newer version of the autotools is used to create the configure script, it does not work (as far as I know) and you still need the bootstrap in order to get things to work. The solution to this would be to use a less recent version of autotools, but that is not what we want either, I guess.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427430150
https://github.com/su2code/SU2/pull/586#issuecomment-427689344:141,Usability,simpl,simply,141,"If you'd like me to revert the changes updating the autotools version and/or removal of auto-generated files, just let me know (you can also simply revert the last few commits for the same effect).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-427689344
https://github.com/su2code/SU2/pull/586#issuecomment-431010086:183,Deployability,install,installed,183,"And a VCS is in general not used for releasing code, but for development. So everybody who clones the repo should be considered as a (soon-to-be) developer with the proper tool-chain installed on their machines.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-431010086
https://github.com/su2code/SU2/pull/586#issuecomment-432038769:431,Deployability,update,updated,431,"LGTM. Thanks for the discussion. We need to keep moving, so let's go for the removal! We can always reevaluate if we have any issues in the future. For now, let's get this merged asap. One last request: @talbring, is it quick for you to add a ./bootstrap call to the preconfigure.py script, just to save a step? Not critical, but would be nice. Once happy, please approve and merge this one (I can't approve my own PR :) ). I have updated the README.md. I am also creating an issue to remind us to update the docs in all locations with build instructions for the next release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-432038769
https://github.com/su2code/SU2/pull/586#issuecomment-432038769:498,Deployability,update,update,498,"LGTM. Thanks for the discussion. We need to keep moving, so let's go for the removal! We can always reevaluate if we have any issues in the future. For now, let's get this merged asap. One last request: @talbring, is it quick for you to add a ./bootstrap call to the preconfigure.py script, just to save a step? Not critical, but would be nice. Once happy, please approve and merge this one (I can't approve my own PR :) ). I have updated the README.md. I am also creating an issue to remind us to update the docs in all locations with build instructions for the next release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-432038769
https://github.com/su2code/SU2/pull/586#issuecomment-432038769:568,Deployability,release,release,568,"LGTM. Thanks for the discussion. We need to keep moving, so let's go for the removal! We can always reevaluate if we have any issues in the future. For now, let's get this merged asap. One last request: @talbring, is it quick for you to add a ./bootstrap call to the preconfigure.py script, just to save a step? Not critical, but would be nice. Once happy, please approve and merge this one (I can't approve my own PR :) ). I have updated the README.md. I am also creating an issue to remind us to update the docs in all locations with build instructions for the next release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/586#issuecomment-432038769
https://github.com/su2code/SU2/issues/587#issuecomment-424241985:119,Deployability,install,installed,119,"> Hi,; > What version of mpich are you using?; > Pedro. Hi, Pedro @pcarruscag ; I'm using mpich-3.0 & mpich-3.0-devel, installed with yum on CentOS 7.; Hongyan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/587#issuecomment-424241985
https://github.com/su2code/SU2/issues/587#issuecomment-424256292:98,Availability,down,downloaded,98,"From the looks of things in that version some function signatures are not compatible with MeDi, I downloaded the source for 3.0 to be sure, version 3.3b3 on the other hand seems to be compatible. If you have the option to update give it a go, if not try compiling with -fpermissive (CXXFLAGS=""-O3 -Wall -fpermissive"" I think).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/587#issuecomment-424256292
https://github.com/su2code/SU2/issues/587#issuecomment-424256292:222,Deployability,update,update,222,"From the looks of things in that version some function signatures are not compatible with MeDi, I downloaded the source for 3.0 to be sure, version 3.3b3 on the other hand seems to be compatible. If you have the option to update give it a go, if not try compiling with -fpermissive (CXXFLAGS=""-O3 -Wall -fpermissive"" I think).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/587#issuecomment-424256292
https://github.com/su2code/SU2/issues/587#issuecomment-424283842:96,Modifiability,variab,variables,96,"@vdweide agreed, but for the sake of not giving SU2 a bad rep, the MPI standard specifies those variables to be const (https://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf page 572 or 602 of the pdf) so this is a (small-ish) mpich 3.0 implementation issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/587#issuecomment-424283842
https://github.com/su2code/SU2/issues/587#issuecomment-424290468:100,Availability,down,downloaded,100,"> From the looks of things in that version some function signatures are not compatible with MeDi, I downloaded the source for 3.0 to be sure, version 3.3b3 on the other hand seems to be compatible. If you have the option to update give it a go, if not try compiling with -fpermissive (CXXFLAGS=""-O3 -Wall -fpermissive"" I think). Switched to mpich-3.3b3, compiled successfully. Thanks a lot! @pcarruscag @vdweide",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/587#issuecomment-424290468
https://github.com/su2code/SU2/issues/587#issuecomment-424290468:224,Deployability,update,update,224,"> From the looks of things in that version some function signatures are not compatible with MeDi, I downloaded the source for 3.0 to be sure, version 3.3b3 on the other hand seems to be compatible. If you have the option to update give it a go, if not try compiling with -fpermissive (CXXFLAGS=""-O3 -Wall -fpermissive"" I think). Switched to mpich-3.3b3, compiled successfully. Thanks a lot! @pcarruscag @vdweide",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/587#issuecomment-424290468
https://github.com/su2code/SU2/issues/591#issuecomment-426812077:279,Testability,test,testing,279,"I like this a lot. I often have a hard time reading the free-stream conditions, and this makes it a lot easier to read. Don't think it is as necessary for the solver iterations, but I don't see any detriment to outputting it like that. Would this require changing the regression testing script that reads the output log to diff the numerical values?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/591#issuecomment-426812077
https://github.com/su2code/SU2/issues/591#issuecomment-426812077:316,Testability,log,log,316,"I like this a lot. I often have a hard time reading the free-stream conditions, and this makes it a lot easier to read. Don't think it is as necessary for the solver iterations, but I don't see any detriment to outputting it like that. Would this require changing the regression testing script that reads the output log to diff the numerical values?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/591#issuecomment-426812077
https://github.com/su2code/SU2/issues/591#issuecomment-427287405:15,Usability,feedback,feedback,15,Thanks for the feedback. I will modify the class in a way that it is possible to specify the separator and other decoration.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/591#issuecomment-427287405
https://github.com/su2code/SU2/pull/592#issuecomment-426818152:0,Testability,Test,Test,0,"Test case discadj_fea is failing due to a change of residuals (the derivatives are the same up to the displayed precision), the change in residuals is smaller than that caused by running on 2 cores rather than serial. Further investigation needed nevertheless.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/592#issuecomment-426818152
https://github.com/su2code/SU2/pull/592#issuecomment-427011251:87,Availability,toler,tolerances,87,"I updated the reference values.; Running the case for more iterations and with tighter tolerances on the linear solver, and comparing preaccumulation on vs off, in serial and parallel, the conclusion is that the derivatives are the same to the 10th decimal place. Which is of the order of the residual reduction, and of the order of the variation between consecutive iterations at convergence.; The data on which I base the conclusion -> [investigation.zip](https://github.com/su2code/SU2/files/2446386/investigation.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/592#issuecomment-427011251
https://github.com/su2code/SU2/pull/592#issuecomment-427011251:2,Deployability,update,updated,2,"I updated the reference values.; Running the case for more iterations and with tighter tolerances on the linear solver, and comparing preaccumulation on vs off, in serial and parallel, the conclusion is that the derivatives are the same to the 10th decimal place. Which is of the order of the residual reduction, and of the order of the variation between consecutive iterations at convergence.; The data on which I base the conclusion -> [investigation.zip](https://github.com/su2code/SU2/files/2446386/investigation.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/592#issuecomment-427011251
https://github.com/su2code/SU2/issues/593#issuecomment-427215727:206,Availability,fault,fault,206,"I think it is ok if we send a few polite messages to say that we will close them but that they should feel very welcome to update their branches and resubmit the PRs. For a couple of them, it is partly our fault that they didn't get enough attention, as it was quite some time ago before we had really established our process.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/593#issuecomment-427215727
https://github.com/su2code/SU2/issues/593#issuecomment-427215727:123,Deployability,update,update,123,"I think it is ok if we send a few polite messages to say that we will close them but that they should feel very welcome to update their branches and resubmit the PRs. For a couple of them, it is partly our fault that they didn't get enough attention, as it was quite some time ago before we had really established our process.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/593#issuecomment-427215727
https://github.com/su2code/SU2/issues/593#issuecomment-427215727:41,Integrability,message,messages,41,"I think it is ok if we send a few polite messages to say that we will close them but that they should feel very welcome to update their branches and resubmit the PRs. For a couple of them, it is partly our fault that they didn't get enough attention, as it was quite some time ago before we had really established our process.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/593#issuecomment-427215727
https://github.com/su2code/SU2/issues/593#issuecomment-427597676:22,Integrability,message,messages,22,OK. Who will send the messages?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/593#issuecomment-427597676
https://github.com/su2code/SU2/issues/594#issuecomment-427554385:221,Deployability,continuous,continuous,221,"We have also encountered the significant memory requirements of the discrete adjoint. Actually, this requirement prevented the use of fine mesh (of 10-20M cells) in optimizations process. This is not the case while using continuous adjoint but the effectiveness of the discrete adjoint is higher by far.; I think this is a very important issue in the actual use of the method. Unfortunately, I do not have any solution to suggest.; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427554385
https://github.com/su2code/SU2/issues/594#issuecomment-427554385:165,Performance,optimiz,optimizations,165,"We have also encountered the significant memory requirements of the discrete adjoint. Actually, this requirement prevented the use of fine mesh (of 10-20M cells) in optimizations process. This is not the case while using continuous adjoint but the effectiveness of the discrete adjoint is higher by far.; I think this is a very important issue in the actual use of the method. Unfortunately, I do not have any solution to suggest.; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427554385
https://github.com/su2code/SU2/issues/594#issuecomment-427559374:479,Energy Efficiency,sensor,sensors,479,"Hi Jayant,; Your figures for MG 0 are inline with what Tim reports in his 2015 paper (10-12 times increase).; As for improving it, the computation of the various residual contributions already uses pre-accumulation, so the only way I see to make that even more effective is to pre-accumulate the sum of all residuals for each edge (that would probably make the direct solver a bit faster too).; In looking at the code I noticed that some areas of the pre-processing like setting sensors, eigenvalues, etc. do not use pre-accumulation, maybe someone already tried and saw it did not make a difference? Same goes for the MG prolongation, restriction, smoothing routines.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427559374
https://github.com/su2code/SU2/issues/594#issuecomment-427559374:659,Integrability,rout,routines,659,"Hi Jayant,; Your figures for MG 0 are inline with what Tim reports in his 2015 paper (10-12 times increase).; As for improving it, the computation of the various residual contributions already uses pre-accumulation, so the only way I see to make that even more effective is to pre-accumulate the sum of all residuals for each edge (that would probably make the direct solver a bit faster too).; In looking at the code I noticed that some areas of the pre-processing like setting sensors, eigenvalues, etc. do not use pre-accumulation, maybe someone already tried and saw it did not make a difference? Same goes for the MG prolongation, restriction, smoothing routines.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427559374
https://github.com/su2code/SU2/issues/594#issuecomment-427592996:508,Energy Efficiency,reduce,reduce,508,"Another potential issue is unnecessary recording of computations. Jayant and I noticed that on his fix_wall_distance branch, the MG 2 case mentioned above was using 8GB more than on develop because during the tree search, the distance computations to all possible bounding boxes were being recorded, when the only necessary computation for recording is the final computation (once the minimum distance node is determined). So I wonder if there are other places in the code where we can turn off recording to reduce memory usage. I'm curious what @talbring's thoughts are. Best,; Brian",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427592996
https://github.com/su2code/SU2/issues/594#issuecomment-427618334:119,Availability,down,down,119,"In terms of improvements on a larger scale, this work by Tom Taylor et al. describes a hybrid approach that could take down that memory requirement quite a bit more:; https://arc.aiaa.org/doi/abs/10.2514/6.2012-3342; In short, there are theoretically ways to get at least some of the advantages of both worlds (continuous vs discrete). I recall seeing some work that got only 4x more memory required (I think it was out of Jaoquim Martin's group? And I think they did it in part by implementing boundary conditions manually and using auto diff for jacobians) but I wasn't able to find the citation as quickly as I'd like. I hope that helps. If I manage to find that paper again I'll post again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427618334
https://github.com/su2code/SU2/issues/594#issuecomment-427618334:311,Deployability,continuous,continuous,311,"In terms of improvements on a larger scale, this work by Tom Taylor et al. describes a hybrid approach that could take down that memory requirement quite a bit more:; https://arc.aiaa.org/doi/abs/10.2514/6.2012-3342; In short, there are theoretically ways to get at least some of the advantages of both worlds (continuous vs discrete). I recall seeing some work that got only 4x more memory required (I think it was out of Jaoquim Martin's group? And I think they did it in part by implementing boundary conditions manually and using auto diff for jacobians) but I wasn't able to find the citation as quickly as I'd like. I hope that helps. If I manage to find that paper again I'll post again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427618334
https://github.com/su2code/SU2/issues/594#issuecomment-427848887:100,Energy Efficiency,reduce,reduce,100,"@all, I agree that it might be a problem for bigger cases and that we have to think of some ways to reduce the memory requirements for the discrete adjoint. . One approach that I started already, is to template the linear solver in order to use double datatype also when running the differentiated version of the code. However, that was more involved than I thought, but still its on my agenda. The nice thing is that this also reduces the runtime a lot. . The next thing is, like @pcarruscag correctly pointed out, the use of preaccumulation. However, this also requires a more detailed analysis, since it can also lead to an increased memory footprint if not applied carefully. Currently, a lot of memory is used for the geometrical derivatives, i.e. the derivatives with respect to the mesh coordinates (this requires approx 1.5 times the memory needed for derivatives with respect to the conservative variables). But since these derivatives are only needed when writing the solution we could think of doing some recomputation as runtime is not that important. So you see we have some ideas and I am sure we can reduce the memory by approx 50% if we apply all of them. However, time is unfortunately limited at the moment, but I will definitely continue improving the adjoint solver. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427848887
https://github.com/su2code/SU2/issues/594#issuecomment-427848887:428,Energy Efficiency,reduce,reduces,428,"@all, I agree that it might be a problem for bigger cases and that we have to think of some ways to reduce the memory requirements for the discrete adjoint. . One approach that I started already, is to template the linear solver in order to use double datatype also when running the differentiated version of the code. However, that was more involved than I thought, but still its on my agenda. The nice thing is that this also reduces the runtime a lot. . The next thing is, like @pcarruscag correctly pointed out, the use of preaccumulation. However, this also requires a more detailed analysis, since it can also lead to an increased memory footprint if not applied carefully. Currently, a lot of memory is used for the geometrical derivatives, i.e. the derivatives with respect to the mesh coordinates (this requires approx 1.5 times the memory needed for derivatives with respect to the conservative variables). But since these derivatives are only needed when writing the solution we could think of doing some recomputation as runtime is not that important. So you see we have some ideas and I am sure we can reduce the memory by approx 50% if we apply all of them. However, time is unfortunately limited at the moment, but I will definitely continue improving the adjoint solver. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427848887
https://github.com/su2code/SU2/issues/594#issuecomment-427848887:1115,Energy Efficiency,reduce,reduce,1115,"@all, I agree that it might be a problem for bigger cases and that we have to think of some ways to reduce the memory requirements for the discrete adjoint. . One approach that I started already, is to template the linear solver in order to use double datatype also when running the differentiated version of the code. However, that was more involved than I thought, but still its on my agenda. The nice thing is that this also reduces the runtime a lot. . The next thing is, like @pcarruscag correctly pointed out, the use of preaccumulation. However, this also requires a more detailed analysis, since it can also lead to an increased memory footprint if not applied carefully. Currently, a lot of memory is used for the geometrical derivatives, i.e. the derivatives with respect to the mesh coordinates (this requires approx 1.5 times the memory needed for derivatives with respect to the conservative variables). But since these derivatives are only needed when writing the solution we could think of doing some recomputation as runtime is not that important. So you see we have some ideas and I am sure we can reduce the memory by approx 50% if we apply all of them. However, time is unfortunately limited at the moment, but I will definitely continue improving the adjoint solver. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427848887
https://github.com/su2code/SU2/issues/594#issuecomment-427848887:905,Modifiability,variab,variables,905,"@all, I agree that it might be a problem for bigger cases and that we have to think of some ways to reduce the memory requirements for the discrete adjoint. . One approach that I started already, is to template the linear solver in order to use double datatype also when running the differentiated version of the code. However, that was more involved than I thought, but still its on my agenda. The nice thing is that this also reduces the runtime a lot. . The next thing is, like @pcarruscag correctly pointed out, the use of preaccumulation. However, this also requires a more detailed analysis, since it can also lead to an increased memory footprint if not applied carefully. Currently, a lot of memory is used for the geometrical derivatives, i.e. the derivatives with respect to the mesh coordinates (this requires approx 1.5 times the memory needed for derivatives with respect to the conservative variables). But since these derivatives are only needed when writing the solution we could think of doing some recomputation as runtime is not that important. So you see we have some ideas and I am sure we can reduce the memory by approx 50% if we apply all of them. However, time is unfortunately limited at the moment, but I will definitely continue improving the adjoint solver. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-427848887
https://github.com/su2code/SU2/issues/594#issuecomment-592950547:126,Modifiability,refactor,refactor,126,"I'm pinning this issue, to my knowledge this is not being worked on directly but it should be something we keep in mind as we refactor code.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/594#issuecomment-592950547
https://github.com/su2code/SU2/pull/595#issuecomment-435698786:300,Integrability,rout,routines,300,"Thanks for the reviews guys.; @economon I added comments to the area of the code you highlighted.; The file IO is not a bottleneck at the moment, and that filtering step is only done once.; I did have a look at anything with ""adjacency"" in the name but I took the easy way out (shamelessly) as those routines looked quite intimidating.; If you have plans to make the output structure capable of handling element values I will piggy-back/collaborate on that and output the derivatives via the output instead of writing a dedicated file.; Since we have two approvals, I will turn the example case I've included into a regression and then this can be merged.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/595#issuecomment-435698786
https://github.com/su2code/SU2/pull/595#issuecomment-435698786:120,Performance,bottleneck,bottleneck,120,"Thanks for the reviews guys.; @economon I added comments to the area of the code you highlighted.; The file IO is not a bottleneck at the moment, and that filtering step is only done once.; I did have a look at anything with ""adjacency"" in the name but I took the easy way out (shamelessly) as those routines looked quite intimidating.; If you have plans to make the output structure capable of handling element values I will piggy-back/collaborate on that and output the derivatives via the output instead of writing a dedicated file.; Since we have two approvals, I will turn the example case I've included into a regression and then this can be merged.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/595#issuecomment-435698786
https://github.com/su2code/SU2/pull/595#issuecomment-437523508:150,Performance,optimiz,optimization,150,"@pcarruscag: is this all ready now that the regression is in place? We can merge in if so. Also, you mentioned that ad-hoc scripting is needed to run optimization. Is that script provided anywhere in this PR so that folks can try out your implementation?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/595#issuecomment-437523508
https://github.com/su2code/SU2/pull/595#issuecomment-437582019:175,Testability,test,testcases,175,"@economon, yeah it is ready. The regression is a file diff that has 10k lines (only 100kB though), is it ok to have the reference file in the code repo or should I move it to testcases?; No that script is not in the PR, I can try to put a minimal version together.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/595#issuecomment-437582019
https://github.com/su2code/SU2/pull/595#issuecomment-441436869:106,Testability,Test,TestCases,106,"All done @economon , I also added a quick start type example, so if anyone wants to try this just go into TestCases/fea_topology/quick_start and call topology_optimization.py",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/595#issuecomment-441436869
https://github.com/su2code/SU2/pull/597#issuecomment-429427811:176,Availability,avail,available,176,"(I seem to have a knack to find cans of worms).; What I did in a55ca26 is not accurate, the integral of the fluid stress needs to be done in current coordinates and the normal available trough CVertex is in reference (undeformed) coordinates. I've implemented this in the structural solver as a preprocessing step. For each surface element of all FSI markers an average stress is computed based on its nodal values, it is then integrated in current (deformed) coordinates. A second pass over the elements scatters the force on the element to the nodes, this is to account for nodes that participate in multiple markers.; The mechanism by which the structural solver takes the flow tractions and updates the Residual vector was not changed, so this changes are fairly local.; The only downside I see is that knowledge of whether the interpolation is consistent or conservative is now required in two locations... Verification of the FSI adjoint is still ongoing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429427811
https://github.com/su2code/SU2/pull/597#issuecomment-429427811:784,Availability,down,downside,784,"(I seem to have a knack to find cans of worms).; What I did in a55ca26 is not accurate, the integral of the fluid stress needs to be done in current coordinates and the normal available trough CVertex is in reference (undeformed) coordinates. I've implemented this in the structural solver as a preprocessing step. For each surface element of all FSI markers an average stress is computed based on its nodal values, it is then integrated in current (deformed) coordinates. A second pass over the elements scatters the force on the element to the nodes, this is to account for nodes that participate in multiple markers.; The mechanism by which the structural solver takes the flow tractions and updates the Residual vector was not changed, so this changes are fairly local.; The only downside I see is that knowledge of whether the interpolation is consistent or conservative is now required in two locations... Verification of the FSI adjoint is still ongoing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429427811
https://github.com/su2code/SU2/pull/597#issuecomment-429427811:427,Deployability,integrat,integrated,427,"(I seem to have a knack to find cans of worms).; What I did in a55ca26 is not accurate, the integral of the fluid stress needs to be done in current coordinates and the normal available trough CVertex is in reference (undeformed) coordinates. I've implemented this in the structural solver as a preprocessing step. For each surface element of all FSI markers an average stress is computed based on its nodal values, it is then integrated in current (deformed) coordinates. A second pass over the elements scatters the force on the element to the nodes, this is to account for nodes that participate in multiple markers.; The mechanism by which the structural solver takes the flow tractions and updates the Residual vector was not changed, so this changes are fairly local.; The only downside I see is that knowledge of whether the interpolation is consistent or conservative is now required in two locations... Verification of the FSI adjoint is still ongoing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429427811
https://github.com/su2code/SU2/pull/597#issuecomment-429427811:695,Deployability,update,updates,695,"(I seem to have a knack to find cans of worms).; What I did in a55ca26 is not accurate, the integral of the fluid stress needs to be done in current coordinates and the normal available trough CVertex is in reference (undeformed) coordinates. I've implemented this in the structural solver as a preprocessing step. For each surface element of all FSI markers an average stress is computed based on its nodal values, it is then integrated in current (deformed) coordinates. A second pass over the elements scatters the force on the element to the nodes, this is to account for nodes that participate in multiple markers.; The mechanism by which the structural solver takes the flow tractions and updates the Residual vector was not changed, so this changes are fairly local.; The only downside I see is that knowledge of whether the interpolation is consistent or conservative is now required in two locations... Verification of the FSI adjoint is still ongoing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429427811
https://github.com/su2code/SU2/pull/597#issuecomment-429427811:427,Integrability,integrat,integrated,427,"(I seem to have a knack to find cans of worms).; What I did in a55ca26 is not accurate, the integral of the fluid stress needs to be done in current coordinates and the normal available trough CVertex is in reference (undeformed) coordinates. I've implemented this in the structural solver as a preprocessing step. For each surface element of all FSI markers an average stress is computed based on its nodal values, it is then integrated in current (deformed) coordinates. A second pass over the elements scatters the force on the element to the nodes, this is to account for nodes that participate in multiple markers.; The mechanism by which the structural solver takes the flow tractions and updates the Residual vector was not changed, so this changes are fairly local.; The only downside I see is that knowledge of whether the interpolation is consistent or conservative is now required in two locations... Verification of the FSI adjoint is still ongoing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429427811
https://github.com/su2code/SU2/pull/597#issuecomment-429571819:227,Modifiability,config,configs,227,"I have tested the adjoint FSI solver, results from matching, conservative, and consistent interpolation all agree. I am attaching only the bare minimum [files](https://github.com/su2code/SU2/files/2475798/testing.zip): meshes, configs, histories and logs. As to avoid uploading large files, I can obviously share the solutions.; To me the original issue is fixed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429571819
https://github.com/su2code/SU2/pull/597#issuecomment-429571819:262,Safety,avoid,avoid,262,"I have tested the adjoint FSI solver, results from matching, conservative, and consistent interpolation all agree. I am attaching only the bare minimum [files](https://github.com/su2code/SU2/files/2475798/testing.zip): meshes, configs, histories and logs. As to avoid uploading large files, I can obviously share the solutions.; To me the original issue is fixed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429571819
https://github.com/su2code/SU2/pull/597#issuecomment-429571819:7,Testability,test,tested,7,"I have tested the adjoint FSI solver, results from matching, conservative, and consistent interpolation all agree. I am attaching only the bare minimum [files](https://github.com/su2code/SU2/files/2475798/testing.zip): meshes, configs, histories and logs. As to avoid uploading large files, I can obviously share the solutions.; To me the original issue is fixed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429571819
https://github.com/su2code/SU2/pull/597#issuecomment-429571819:205,Testability,test,testing,205,"I have tested the adjoint FSI solver, results from matching, conservative, and consistent interpolation all agree. I am attaching only the bare minimum [files](https://github.com/su2code/SU2/files/2475798/testing.zip): meshes, configs, histories and logs. As to avoid uploading large files, I can obviously share the solutions.; To me the original issue is fixed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429571819
https://github.com/su2code/SU2/pull/597#issuecomment-429571819:250,Testability,log,logs,250,"I have tested the adjoint FSI solver, results from matching, conservative, and consistent interpolation all agree. I am attaching only the bare minimum [files](https://github.com/su2code/SU2/files/2475798/testing.zip): meshes, configs, histories and logs. As to avoid uploading large files, I can obviously share the solutions.; To me the original issue is fixed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-429571819
https://github.com/su2code/SU2/pull/597#issuecomment-434317633:115,Availability,avail,availability,115,"Hi Ruben, no worries. Integrating on the fluid side is what makes sense for matching meshes, less hassle given the availability of dual grid information, no need for MPI boiler plate, etc. The adjoint implications are being accounted for, this integration step is being recorded and overall the dependencies have not changed, the fluid nodes are still the ones defining the direction of the stress.; As you can see from the files I attached, the sensitivities are very similar for conservative/consistent interpolation cases. . It is not possible to generalise this for conservative interpolation (i.e. using the transpose of the displacement interpolation matrix to interpolate tractions) because that approach implicitly takes care of the (possible) different areas associated with fluid and solid nodes. If you transfer stresses with conservative interpolation and then integrate you get the wrong force. The conservative approach requires forces to be transferred, otherwise we start taking liberties with the meaning of the word :). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-434317633
https://github.com/su2code/SU2/pull/597#issuecomment-434317633:22,Deployability,Integrat,Integrating,22,"Hi Ruben, no worries. Integrating on the fluid side is what makes sense for matching meshes, less hassle given the availability of dual grid information, no need for MPI boiler plate, etc. The adjoint implications are being accounted for, this integration step is being recorded and overall the dependencies have not changed, the fluid nodes are still the ones defining the direction of the stress.; As you can see from the files I attached, the sensitivities are very similar for conservative/consistent interpolation cases. . It is not possible to generalise this for conservative interpolation (i.e. using the transpose of the displacement interpolation matrix to interpolate tractions) because that approach implicitly takes care of the (possible) different areas associated with fluid and solid nodes. If you transfer stresses with conservative interpolation and then integrate you get the wrong force. The conservative approach requires forces to be transferred, otherwise we start taking liberties with the meaning of the word :). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-434317633
https://github.com/su2code/SU2/pull/597#issuecomment-434317633:244,Deployability,integrat,integration,244,"Hi Ruben, no worries. Integrating on the fluid side is what makes sense for matching meshes, less hassle given the availability of dual grid information, no need for MPI boiler plate, etc. The adjoint implications are being accounted for, this integration step is being recorded and overall the dependencies have not changed, the fluid nodes are still the ones defining the direction of the stress.; As you can see from the files I attached, the sensitivities are very similar for conservative/consistent interpolation cases. . It is not possible to generalise this for conservative interpolation (i.e. using the transpose of the displacement interpolation matrix to interpolate tractions) because that approach implicitly takes care of the (possible) different areas associated with fluid and solid nodes. If you transfer stresses with conservative interpolation and then integrate you get the wrong force. The conservative approach requires forces to be transferred, otherwise we start taking liberties with the meaning of the word :). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-434317633
https://github.com/su2code/SU2/pull/597#issuecomment-434317633:873,Deployability,integrat,integrate,873,"Hi Ruben, no worries. Integrating on the fluid side is what makes sense for matching meshes, less hassle given the availability of dual grid information, no need for MPI boiler plate, etc. The adjoint implications are being accounted for, this integration step is being recorded and overall the dependencies have not changed, the fluid nodes are still the ones defining the direction of the stress.; As you can see from the files I attached, the sensitivities are very similar for conservative/consistent interpolation cases. . It is not possible to generalise this for conservative interpolation (i.e. using the transpose of the displacement interpolation matrix to interpolate tractions) because that approach implicitly takes care of the (possible) different areas associated with fluid and solid nodes. If you transfer stresses with conservative interpolation and then integrate you get the wrong force. The conservative approach requires forces to be transferred, otherwise we start taking liberties with the meaning of the word :). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-434317633
https://github.com/su2code/SU2/pull/597#issuecomment-434317633:22,Integrability,Integrat,Integrating,22,"Hi Ruben, no worries. Integrating on the fluid side is what makes sense for matching meshes, less hassle given the availability of dual grid information, no need for MPI boiler plate, etc. The adjoint implications are being accounted for, this integration step is being recorded and overall the dependencies have not changed, the fluid nodes are still the ones defining the direction of the stress.; As you can see from the files I attached, the sensitivities are very similar for conservative/consistent interpolation cases. . It is not possible to generalise this for conservative interpolation (i.e. using the transpose of the displacement interpolation matrix to interpolate tractions) because that approach implicitly takes care of the (possible) different areas associated with fluid and solid nodes. If you transfer stresses with conservative interpolation and then integrate you get the wrong force. The conservative approach requires forces to be transferred, otherwise we start taking liberties with the meaning of the word :). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-434317633
https://github.com/su2code/SU2/pull/597#issuecomment-434317633:244,Integrability,integrat,integration,244,"Hi Ruben, no worries. Integrating on the fluid side is what makes sense for matching meshes, less hassle given the availability of dual grid information, no need for MPI boiler plate, etc. The adjoint implications are being accounted for, this integration step is being recorded and overall the dependencies have not changed, the fluid nodes are still the ones defining the direction of the stress.; As you can see from the files I attached, the sensitivities are very similar for conservative/consistent interpolation cases. . It is not possible to generalise this for conservative interpolation (i.e. using the transpose of the displacement interpolation matrix to interpolate tractions) because that approach implicitly takes care of the (possible) different areas associated with fluid and solid nodes. If you transfer stresses with conservative interpolation and then integrate you get the wrong force. The conservative approach requires forces to be transferred, otherwise we start taking liberties with the meaning of the word :). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-434317633
https://github.com/su2code/SU2/pull/597#issuecomment-434317633:295,Integrability,depend,dependencies,295,"Hi Ruben, no worries. Integrating on the fluid side is what makes sense for matching meshes, less hassle given the availability of dual grid information, no need for MPI boiler plate, etc. The adjoint implications are being accounted for, this integration step is being recorded and overall the dependencies have not changed, the fluid nodes are still the ones defining the direction of the stress.; As you can see from the files I attached, the sensitivities are very similar for conservative/consistent interpolation cases. . It is not possible to generalise this for conservative interpolation (i.e. using the transpose of the displacement interpolation matrix to interpolate tractions) because that approach implicitly takes care of the (possible) different areas associated with fluid and solid nodes. If you transfer stresses with conservative interpolation and then integrate you get the wrong force. The conservative approach requires forces to be transferred, otherwise we start taking liberties with the meaning of the word :). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-434317633
https://github.com/su2code/SU2/pull/597#issuecomment-434317633:873,Integrability,integrat,integrate,873,"Hi Ruben, no worries. Integrating on the fluid side is what makes sense for matching meshes, less hassle given the availability of dual grid information, no need for MPI boiler plate, etc. The adjoint implications are being accounted for, this integration step is being recorded and overall the dependencies have not changed, the fluid nodes are still the ones defining the direction of the stress.; As you can see from the files I attached, the sensitivities are very similar for conservative/consistent interpolation cases. . It is not possible to generalise this for conservative interpolation (i.e. using the transpose of the displacement interpolation matrix to interpolate tractions) because that approach implicitly takes care of the (possible) different areas associated with fluid and solid nodes. If you transfer stresses with conservative interpolation and then integrate you get the wrong force. The conservative approach requires forces to be transferred, otherwise we start taking liberties with the meaning of the word :). Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-434317633
https://github.com/su2code/SU2/pull/597#issuecomment-441388433:278,Usability,clear,clear,278,"@rsanfer I am attaching [some results](https://github.com/su2code/SU2/files/2612501/FFD_verification.pdf) for FFD derivatives for FSI cases (that made use of this fix) to rekindle the discussion. I am taking this directly from my early stage so apologies if not all details are clear, the conclusion is that the fix does not break the adjoint.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/597#issuecomment-441388433
https://github.com/su2code/SU2/pull/598#issuecomment-430136086:214,Testability,test,tests,214,"For the g++ compiler the following compiler flags are pretty good.; -g -Wall -Wextra -Wno-unused-parameter -Wno-empty-body. As @economon said, do this both in sequential and parallel mode. BTW, when the regression tests go through this PR can be merged in as far as I am concerned.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/598#issuecomment-430136086
https://github.com/su2code/SU2/pull/600#issuecomment-434492415:199,Testability,test,tests,199,"Hi @jaspe55 - thanks for the first contribution!. Can you please switch the email and branch name in .travis.yml back to su2code-dev@lists.stanford.edu and develop, respectively? That should get the tests running so we can give this a proper review (should be quick given the small change).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434492415
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:808,Availability,error,error,808,"Dear sirs, I just modified .travis.yml back to; su2code-dev@lists.stanford.edu and develop respectively:. Jairos-Mac-mini:SU2 jaspe$ git status. On branch feature_force_read_target_on_AD. Changes not staged for commit:. (use ""git add <file>..."" to update what will be committed). (use ""git checkout -- <file>..."" to discard changes in working directory). modified: .travis.yml. no changes added to commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:959,Availability,error,error,959,"Dear sirs, I just modified .travis.yml back to; su2code-dev@lists.stanford.edu and develop respectively:. Jairos-Mac-mini:SU2 jaspe$ git status. On branch feature_force_read_target_on_AD. Changes not staged for commit:. (use ""git add <file>..."" to update what will be committed). (use ""git checkout -- <file>..."" to discard changes in working directory). modified: .travis.yml. no changes added to commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:1566,Availability,error,error,1566," commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so we can give this a proper review (should be quick; > given the small change).; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#issuecomment-434492415>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180sVTNXVIdfr1Oo3wVM2qGfepSGfIks5uqNHngaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:248,Deployability,update,update,248,"Dear sirs, I just modified .travis.yml back to; su2code-dev@lists.stanford.edu and develop respectively:. Jairos-Mac-mini:SU2 jaspe$ git status. On branch feature_force_read_target_on_AD. Changes not staged for commit:. (use ""git add <file>..."" to update what will be committed). (use ""git checkout -- <file>..."" to discard changes in working directory). modified: .travis.yml. no changes added to commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:499,Deployability,update,update,499,"Dear sirs, I just modified .travis.yml back to; su2code-dev@lists.stanford.edu and develop respectively:. Jairos-Mac-mini:SU2 jaspe$ git status. On branch feature_force_read_target_on_AD. Changes not staged for commit:. (use ""git add <file>..."" to update what will be committed). (use ""git checkout -- <file>..."" to discard changes in working directory). modified: .travis.yml. no changes added to commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:616,Deployability,update,update,616,"Dear sirs, I just modified .travis.yml back to; su2code-dev@lists.stanford.edu and develop respectively:. Jairos-Mac-mini:SU2 jaspe$ git status. On branch feature_force_read_target_on_AD. Changes not staged for commit:. (use ""git add <file>..."" to update what will be committed). (use ""git checkout -- <file>..."" to discard changes in working directory). modified: .travis.yml. no changes added to commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:1038,Deployability,Update,Updates,1038,"anford.edu and develop respectively:. Jairos-Mac-mini:SU2 jaspe$ git status. On branch feature_force_read_target_on_AD. Changes not staged for commit:. (use ""git add <file>..."" to update what will be committed). (use ""git checkout -- <file>..."" to discard changes in working directory). modified: .travis.yml. no changes added to commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so we can give this a proper review (should be quick; > given the small",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:1229,Deployability,integrat,integrate,1229,"d <file>..."" to update what will be committed). (use ""git checkout -- <file>..."" to discard changes in working directory). modified: .travis.yml. no changes added to commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so we can give this a proper review (should be quick; > given the small change).; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/6",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:814,Integrability,message,message,814,"Dear sirs, I just modified .travis.yml back to; su2code-dev@lists.stanford.edu and develop respectively:. Jairos-Mac-mini:SU2 jaspe$ git status. On branch feature_force_read_target_on_AD. Changes not staged for commit:. (use ""git add <file>..."" to update what will be committed). (use ""git checkout -- <file>..."" to discard changes in working directory). modified: .travis.yml. no changes added to commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so w",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:1229,Integrability,integrat,integrate,1229,"d <file>..."" to update what will be committed). (use ""git checkout -- <file>..."" to discard changes in working directory). modified: .travis.yml. no changes added to commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so we can give this a proper review (should be quick; > given the small change).; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/6",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:1572,Integrability,message,message,1572," commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so we can give this a proper review (should be quick; > given the small change).; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#issuecomment-434492415>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180sVTNXVIdfr1Oo3wVM2qGfepSGfIks5uqNHngaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-434929137:1983,Testability,test,tests,1983," commit (use ""git add"" and/or ""git commit -a""). Jairos-Mac-mini:SU2 jaspe$ git commit -am ""This is an update of .travis.yml; for feature_force_read_target_on_AD."". [feature_force_read_target_on_AD 3f2115373] This is an update of; .travis.yml for feature_force_read_target_on_AD. 1 file changed, 2 insertions(+), 2 deletions(-); After that, I issued git push origin feature_force_read_target_on_AD, and; got the error message:. To https://github.com/su2code/SU2.git. ! [rejected] feature_force_read_target_on_AD ->; feature_force_read_target_on_AD (fetch first). error: failed to push some refs to 'https://github.com/su2code/SU2.git'. hint: Updates were rejected because the remote contains work that you do. hint: not have locally. This is usually caused by another repository pushing. hint: to the same ref. You may want to first integrate the remote changes. hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details.; I issued then git pull origin develop, to merge changes in remote to my; local branch, successfully , but a new git push origin; feature_force_read_target_on_AD, produced the same error message.; Would be the first commit command enough?. With kind regards,. Jairo. On Tue, Oct 30, 2018 at 7:25 PM Thomas D. Economon <notifications@github.com>; wrote:. > Hi @jaspe55 <https://github.com/jaspe55> - thanks for the first; > contribution!; >; > Can you please switch the email and branch name in .travis.yml back to; > su2code-dev@lists.stanford.edu and develop, respectively? That should get; > the tests running so we can give this a proper review (should be quick; > given the small change).; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#issuecomment-434492415>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180sVTNXVIdfr1Oo3wVM2qGfepSGfIks5uqNHngaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-434929137
https://github.com/su2code/SU2/pull/600#issuecomment-435170261:155,Availability,down,down,155,"No problem at all. I think the issue was that others had merged the changes into develop here from the web interface and those changes needed to be pulled down into your local copy before you could push the changes to .travis.yml up. I have just made the change, and I see the tests are now running! We'll get back with a review soon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-435170261
https://github.com/su2code/SU2/pull/600#issuecomment-435170261:107,Integrability,interface,interface,107,"No problem at all. I think the issue was that others had merged the changes into develop here from the web interface and those changes needed to be pulled down into your local copy before you could push the changes to .travis.yml up. I have just made the change, and I see the tests are now running! We'll get back with a review soon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-435170261
https://github.com/su2code/SU2/pull/600#issuecomment-435170261:277,Testability,test,tests,277,"No problem at all. I think the issue was that others had merged the changes into develop here from the web interface and those changes needed to be pulled down into your local copy before you could push the changes to .travis.yml up. I have just made the change, and I see the tests are now running! We'll get back with a review soon.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-435170261
https://github.com/su2code/SU2/pull/600#issuecomment-435250485:306,Availability,down,down,306,"Great!; Thank you very much.; With kind regards,. Jairo. On Thu, Nov 1, 2018 at 5:10 PM Thomas D. Economon <notifications@github.com>; wrote:. > No problem at all. I think the issue was that others had merged the; > changes into develop here from the web interface and those changes needed; > to be pulled down into your local copy before you could push the changes to; > .travis.yml up.; >; > I have just made the change, and I see the tests are now running! We'll; > get back with a review soon.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#issuecomment-435170261>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180sQoMHXa2p4ICO_ef6f3QXOmhII_ks5uq1U_gaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-435250485
https://github.com/su2code/SU2/pull/600#issuecomment-435250485:255,Integrability,interface,interface,255,"Great!; Thank you very much.; With kind regards,. Jairo. On Thu, Nov 1, 2018 at 5:10 PM Thomas D. Economon <notifications@github.com>; wrote:. > No problem at all. I think the issue was that others had merged the; > changes into develop here from the web interface and those changes needed; > to be pulled down into your local copy before you could push the changes to; > .travis.yml up.; >; > I have just made the change, and I see the tests are now running! We'll; > get back with a review soon.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#issuecomment-435170261>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180sQoMHXa2p4ICO_ef6f3QXOmhII_ks5uq1U_gaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-435250485
https://github.com/su2code/SU2/pull/600#issuecomment-435250485:437,Testability,test,tests,437,"Great!; Thank you very much.; With kind regards,. Jairo. On Thu, Nov 1, 2018 at 5:10 PM Thomas D. Economon <notifications@github.com>; wrote:. > No problem at all. I think the issue was that others had merged the; > changes into develop here from the web interface and those changes needed; > to be pulled down into your local copy before you could push the changes to; > .travis.yml up.; >; > I have just made the change, and I see the tests are now running! We'll; > get back with a review soon.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#issuecomment-435170261>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180sQoMHXa2p4ICO_ef6f3QXOmhII_ks5uq1U_gaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-435250485
https://github.com/su2code/SU2/pull/600#issuecomment-435936187:41,Availability,error,error,41,"@jaspe55 : looks like there is a compile error due to the CSolver input to the modified functions (I think one index is missing, probably '[iInst]'. Can you please take a look when you get the chance?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-435936187
https://github.com/su2code/SU2/pull/600#issuecomment-436789848:4740,Availability,error,error,4740,"ue*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[from]-rinfo[higain].... * ^*. *../../../externals/metis/libmetis/parmetis.c:336:17: **note: *use function; 'llabs'. instead. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[from]-rinfo[higain].... * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:540:15: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. mindiff = abs(pwgts[0]-pwgts[1]);. * ^*. *../../../externals/metis/libmetis/parmetis.c:540:15: **note: *use function; 'llabs'. instead. mindiff = abs(pwgts[0]-pwgts[1]);. * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:583:17: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[other]-rinfo[higain]... * ^*. *../../../externals/metis/libmetis/parmetis.c:583:17: **note: *use function; 'llabs'. instead. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[other]-rinfo[higain]... * ^~~*. llabs. CC libmetis/libmetis_a-srefine.o. On Mon, Nov 5, 2018 at 1:20 PM Thomas D. Economon <notifications@github.com>; wrote:. > @jaspe55 <https://github.com/jaspe55> : looks like there is a compile; > error due to the CSolver input to the modified functions (I think one index; > is missing, probably '[iInst]'. Can you please take a look when you get the; > chance?; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#issuecomment-435936187>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180rZieLuEu7zlQtC4-vZnTrcZYXExks5usGU-gaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-436789848
https://github.com/su2code/SU2/pull/600#issuecomment-436789848:504,Deployability,update,update,504,"Dear Dr Economon and fellows,. Thank you for the remarks.; I have included reference to index INST_0 to the code in the local branch,; and compiled it in a MacOS (El Capitn):; Successfull compilation for Inverse Design Cp & Inverse Design HeatFlux.; External METIS lib caused eight warnings on arguments of abs() function:; Suggestion is to use *llabs*() instead of *abs*(). Please see appended; extract.; I am running a local test now, which uses Inverse Design Cp; and as soon as; it finishes, I will update the remote too, so we can continue the tests. With kind regards,. Jairo. CC libmetis/libmetis_a-mincover.o. *../../../externals/metis/libmetis/parmetis.c:311:15: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. mindiff = abs(pwgts[0]-pwgts[1]);. * ^*. *../../../externals/metis/libmetis/parmetis.c:311:15: **note: *use function; 'llabs'. instead. mindiff = abs(pwgts[0]-pwgts[1]);. * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:336:17: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[from]-rinfo[higain].... * ^*. *../../../externals/metis/libmetis/parmetis.c:336:17: **note: *use function; 'llabs'. instead. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[from]-rinfo[higain].... * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:540:15: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. mindiff = abs(pwgts[0]-pwgts[1]);. * ^*. *../../../externals/metis/libmetis/parmetis.c:540:15: **note: *use function; 'llabs'. instead. mindiff = abs(pwgts[0]-pwgts[1]);. * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:583:17",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-436789848
https://github.com/su2code/SU2/pull/600#issuecomment-436789848:428,Testability,test,test,428,"Dear Dr Economon and fellows,. Thank you for the remarks.; I have included reference to index INST_0 to the code in the local branch,; and compiled it in a MacOS (El Capitn):; Successfull compilation for Inverse Design Cp & Inverse Design HeatFlux.; External METIS lib caused eight warnings on arguments of abs() function:; Suggestion is to use *llabs*() instead of *abs*(). Please see appended; extract.; I am running a local test now, which uses Inverse Design Cp; and as soon as; it finishes, I will update the remote too, so we can continue the tests. With kind regards,. Jairo. CC libmetis/libmetis_a-mincover.o. *../../../externals/metis/libmetis/parmetis.c:311:15: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. mindiff = abs(pwgts[0]-pwgts[1]);. * ^*. *../../../externals/metis/libmetis/parmetis.c:311:15: **note: *use function; 'llabs'. instead. mindiff = abs(pwgts[0]-pwgts[1]);. * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:336:17: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[from]-rinfo[higain].... * ^*. *../../../externals/metis/libmetis/parmetis.c:336:17: **note: *use function; 'llabs'. instead. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[from]-rinfo[higain].... * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:540:15: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. mindiff = abs(pwgts[0]-pwgts[1]);. * ^*. *../../../externals/metis/libmetis/parmetis.c:540:15: **note: *use function; 'llabs'. instead. mindiff = abs(pwgts[0]-pwgts[1]);. * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:583:17",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-436789848
https://github.com/su2code/SU2/pull/600#issuecomment-436789848:550,Testability,test,tests,550,"Dear Dr Economon and fellows,. Thank you for the remarks.; I have included reference to index INST_0 to the code in the local branch,; and compiled it in a MacOS (El Capitn):; Successfull compilation for Inverse Design Cp & Inverse Design HeatFlux.; External METIS lib caused eight warnings on arguments of abs() function:; Suggestion is to use *llabs*() instead of *abs*(). Please see appended; extract.; I am running a local test now, which uses Inverse Design Cp; and as soon as; it finishes, I will update the remote too, so we can continue the tests. With kind regards,. Jairo. CC libmetis/libmetis_a-mincover.o. *../../../externals/metis/libmetis/parmetis.c:311:15: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. mindiff = abs(pwgts[0]-pwgts[1]);. * ^*. *../../../externals/metis/libmetis/parmetis.c:311:15: **note: *use function; 'llabs'. instead. mindiff = abs(pwgts[0]-pwgts[1]);. * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:336:17: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[from]-rinfo[higain].... * ^*. *../../../externals/metis/libmetis/parmetis.c:336:17: **note: *use function; 'llabs'. instead. newdiff = abs(pwgts[to]+vwgt[higain] - (pwgts[from]-rinfo[higain].... * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:540:15: **warning: **absolute; value*. * function 'abs' given an argument of type 'long long' but has; parameter of*. * type 'int' which may cause truncation of value [-Wabsolute-value]*. mindiff = abs(pwgts[0]-pwgts[1]);. * ^*. *../../../externals/metis/libmetis/parmetis.c:540:15: **note: *use function; 'llabs'. instead. mindiff = abs(pwgts[0]-pwgts[1]);. * ^~~*. llabs. *../../../externals/metis/libmetis/parmetis.c:583:17",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-436789848
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:1033,Availability,error,error,1033,". Economon,. Thank you for your quick response.; I just push the updates, following the suggested hints in the messages of the first ""git push ..."" command, but even after issued the ""git pull ..."", I still received the same message (please find the dialog appended at the end of this note). . With kind regards,. Jairo (jaspe55); .........................................................................................................................................................; Jairos-Mac-mini:SU2 jaspe$ pwd; /Users/jaspe/Desktop/SU2BRANCH/SU2; Jairos-Mac-mini:SU2 jaspe$ git branch; * feature_force_read_target_on_AD; master; Jairos-Mac-mini:SU2 jaspe$ git status; On branch feature_force_read_target_on_AD; nothing to commit, working tree clean; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$ git pull origin develop; remote: Enumerating objects: 50, done.; remote: Counting objects: 100% (50/50), done.; remote: Compressing objects: 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:3173,Availability,error,error,3173,": 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xcode/SU2_CFD.xcodeproj/project.pbxproj | 166 ++++++++++++------------; SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj | 144 ++++++++++++++++----; SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.pbxproj | 130 +++++++++++--------; SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.pbxproj | 74 ++++++++++-; SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj | 124 ++++++++++++++++--; SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj | 62 +++++----; TestCases/parallel_regression.py | 26 ++--; TestCases/parallel_regression_AD.py | 4 +-; TestCases/serial_regression.py | 24 ++--; TestCases/serial_regression_AD.py | 2 +-; 19 files changed, 659 insertions(+), 292 deletions(-); Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:73,Deployability,update,updates,73,"Hello Dr. Economon,. Thank you for your quick response.; I just push the updates, following the suggested hints in the messages of the first ""git push ..."" command, but even after issued the ""git pull ..."", I still received the same message (please find the dialog appended at the end of this note). . With kind regards,. Jairo (jaspe55); .........................................................................................................................................................; Jairos-Mac-mini:SU2 jaspe$ pwd; /Users/jaspe/Desktop/SU2BRANCH/SU2; Jairos-Mac-mini:SU2 jaspe$ git branch; * feature_force_read_target_on_AD; master; Jairos-Mac-mini:SU2 jaspe$ git status; On branch feature_force_read_target_on_AD; nothing to commit, working tree clean; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$ git pull origin develop; remote: Enumerating objects: 50, done.; remote: Counting objects: 100% (50/50), done.; remote: Compressing objects: 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:1112,Deployability,Update,Updates,1112,"..."" command, but even after issued the ""git pull ..."", I still received the same message (please find the dialog appended at the end of this note). . With kind regards,. Jairo (jaspe55); .........................................................................................................................................................; Jairos-Mac-mini:SU2 jaspe$ pwd; /Users/jaspe/Desktop/SU2BRANCH/SU2; Jairos-Mac-mini:SU2 jaspe$ git branch; * feature_force_read_target_on_AD; master; Jairos-Mac-mini:SU2 jaspe$ git status; On branch feature_force_read_target_on_AD; nothing to commit, working tree clean; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$ git pull origin develop; remote: Enumerating objects: 50, done.; remote: Counting objects: 100% (50/50), done.; remote: Compressing objects: 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structur",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:1303,Deployability,integrat,integrate,1303," regards,. Jairo (jaspe55); .........................................................................................................................................................; Jairos-Mac-mini:SU2 jaspe$ pwd; /Users/jaspe/Desktop/SU2BRANCH/SU2; Jairos-Mac-mini:SU2 jaspe$ git branch; * feature_force_read_target_on_AD; master; Jairos-Mac-mini:SU2 jaspe$ git status; On branch feature_force_read_target_on_AD; nothing to commit, working tree clean; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$ git pull origin develop; remote: Enumerating objects: 50, done.; remote: Counting objects: 100% (50/50), done.; remote: Compressing objects: 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xc",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:3252,Deployability,Update,Updates,3252,": 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xcode/SU2_CFD.xcodeproj/project.pbxproj | 166 ++++++++++++------------; SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj | 144 ++++++++++++++++----; SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.pbxproj | 130 +++++++++++--------; SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.pbxproj | 74 ++++++++++-; SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj | 124 ++++++++++++++++--; SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj | 62 +++++----; TestCases/parallel_regression.py | 26 ++--; TestCases/parallel_regression_AD.py | 4 +-; TestCases/serial_regression.py | 24 ++--; TestCases/serial_regression_AD.py | 2 +-; 19 files changed, 659 insertions(+), 292 deletions(-); Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:3443,Deployability,integrat,integrate,3443,": 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xcode/SU2_CFD.xcodeproj/project.pbxproj | 166 ++++++++++++------------; SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj | 144 ++++++++++++++++----; SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.pbxproj | 130 +++++++++++--------; SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.pbxproj | 74 ++++++++++-; SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj | 124 ++++++++++++++++--; SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj | 62 +++++----; TestCases/parallel_regression.py | 26 ++--; TestCases/parallel_regression_AD.py | 4 +-; TestCases/serial_regression.py | 24 ++--; TestCases/serial_regression_AD.py | 2 +-; 19 files changed, 659 insertions(+), 292 deletions(-); Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:119,Integrability,message,messages,119,"Hello Dr. Economon,. Thank you for your quick response.; I just push the updates, following the suggested hints in the messages of the first ""git push ..."" command, but even after issued the ""git pull ..."", I still received the same message (please find the dialog appended at the end of this note). . With kind regards,. Jairo (jaspe55); .........................................................................................................................................................; Jairos-Mac-mini:SU2 jaspe$ pwd; /Users/jaspe/Desktop/SU2BRANCH/SU2; Jairos-Mac-mini:SU2 jaspe$ git branch; * feature_force_read_target_on_AD; master; Jairos-Mac-mini:SU2 jaspe$ git status; On branch feature_force_read_target_on_AD; nothing to commit, working tree clean; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$ git pull origin develop; remote: Enumerating objects: 50, done.; remote: Counting objects: 100% (50/50), done.; remote: Compressing objects: 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:233,Integrability,message,message,233,"Hello Dr. Economon,. Thank you for your quick response.; I just push the updates, following the suggested hints in the messages of the first ""git push ..."" command, but even after issued the ""git pull ..."", I still received the same message (please find the dialog appended at the end of this note). . With kind regards,. Jairo (jaspe55); .........................................................................................................................................................; Jairos-Mac-mini:SU2 jaspe$ pwd; /Users/jaspe/Desktop/SU2BRANCH/SU2; Jairos-Mac-mini:SU2 jaspe$ git branch; * feature_force_read_target_on_AD; master; Jairos-Mac-mini:SU2 jaspe$ git status; On branch feature_force_read_target_on_AD; nothing to commit, working tree clean; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$ git pull origin develop; remote: Enumerating objects: 50, done.; remote: Counting objects: 100% (50/50), done.; remote: Compressing objects: 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:1303,Integrability,integrat,integrate,1303," regards,. Jairo (jaspe55); .........................................................................................................................................................; Jairos-Mac-mini:SU2 jaspe$ pwd; /Users/jaspe/Desktop/SU2BRANCH/SU2; Jairos-Mac-mini:SU2 jaspe$ git branch; * feature_force_read_target_on_AD; master; Jairos-Mac-mini:SU2 jaspe$ git status; On branch feature_force_read_target_on_AD; nothing to commit, working tree clean; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ ; Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$ git pull origin develop; remote: Enumerating objects: 50, done.; remote: Counting objects: 100% (50/50), done.; remote: Compressing objects: 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xc",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:3443,Integrability,integrat,integrate,3443,": 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xcode/SU2_CFD.xcodeproj/project.pbxproj | 166 ++++++++++++------------; SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj | 144 ++++++++++++++++----; SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.pbxproj | 130 +++++++++++--------; SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.pbxproj | 74 ++++++++++-; SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj | 124 ++++++++++++++++--; SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj | 62 +++++----; TestCases/parallel_regression.py | 26 ++--; TestCases/parallel_regression_AD.py | 4 +-; TestCases/serial_regression.py | 24 ++--; TestCases/serial_regression_AD.py | 2 +-; 19 files changed, 659 insertions(+), 292 deletions(-); Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:2736,Testability,Test,TestCases,2736,": 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xcode/SU2_CFD.xcodeproj/project.pbxproj | 166 ++++++++++++------------; SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj | 144 ++++++++++++++++----; SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.pbxproj | 130 +++++++++++--------; SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.pbxproj | 74 ++++++++++-; SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj | 124 ++++++++++++++++--; SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj | 62 +++++----; TestCases/parallel_regression.py | 26 ++--; TestCases/parallel_regression_AD.py | 4 +-; TestCases/serial_regression.py | 24 ++--; TestCases/serial_regression_AD.py | 2 +-; 19 files changed, 659 insertions(+), 292 deletions(-); Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:2780,Testability,Test,TestCases,2780,": 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xcode/SU2_CFD.xcodeproj/project.pbxproj | 166 ++++++++++++------------; SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj | 144 ++++++++++++++++----; SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.pbxproj | 130 +++++++++++--------; SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.pbxproj | 74 ++++++++++-; SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj | 124 ++++++++++++++++--; SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj | 62 +++++----; TestCases/parallel_regression.py | 26 ++--; TestCases/parallel_regression_AD.py | 4 +-; TestCases/serial_regression.py | 24 ++--; TestCases/serial_regression_AD.py | 2 +-; 19 files changed, 659 insertions(+), 292 deletions(-); Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:2824,Testability,Test,TestCases,2824,": 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xcode/SU2_CFD.xcodeproj/project.pbxproj | 166 ++++++++++++------------; SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj | 144 ++++++++++++++++----; SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.pbxproj | 130 +++++++++++--------; SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.pbxproj | 74 ++++++++++-; SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj | 124 ++++++++++++++++--; SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj | 62 +++++----; TestCases/parallel_regression.py | 26 ++--; TestCases/parallel_regression_AD.py | 4 +-; TestCases/serial_regression.py | 24 ++--; TestCases/serial_regression_AD.py | 2 +-; 19 files changed, 659 insertions(+), 292 deletions(-); Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-438029731:2866,Testability,Test,TestCases,2866,": 100% (6/6), done.; remote: Total 81 (delta 45), reused 46 (delta 44), pack-reused 31; Unpacking objects: 100% (81/81), done.; From https://github.com/su2code/SU2; * branch develop -> FETCH_HEAD; 0811066f4..cf91b7cf4 develop -> origin/develop; Merge made by the 'recursive' strategy.; Common/include/blas_structure.hpp | 2 +-; Common/include/matrix_structure.hpp | 2 +-; Common/src/adt_structure.cpp | 11 +-; Common/src/blas_structure.cpp | 27 ++--; Common/src/fem_geometry_structure.cpp | 2 +-; Common/src/geometry_structure.cpp | 131 ++++++++++++++-----; Common/src/matrix_structure.cpp | 14 +-; Common/src/wall_model.cpp | 4 +-; SU2_CFD/src/output_structure.cpp | 2 +-; SU2_IDE/Xcode/SU2_CFD.xcodeproj/project.pbxproj | 166 ++++++++++++------------; SU2_IDE/Xcode/SU2_DEF.xcodeproj/project.pbxproj | 144 ++++++++++++++++----; SU2_IDE/Xcode/SU2_DOT.xcodeproj/project.pbxproj | 130 +++++++++++--------; SU2_IDE/Xcode/SU2_GEO.xcodeproj/project.pbxproj | 74 ++++++++++-; SU2_IDE/Xcode/SU2_MSH.xcodeproj/project.pbxproj | 124 ++++++++++++++++--; SU2_IDE/Xcode/SU2_SOL.xcodeproj/project.pbxproj | 62 +++++----; TestCases/parallel_regression.py | 26 ++--; TestCases/parallel_regression_AD.py | 4 +-; TestCases/serial_regression.py | 24 ++--; TestCases/serial_regression_AD.py | 2 +-; 19 files changed, 659 insertions(+), 292 deletions(-); Jairos-Mac-mini:SU2 jaspe$ git push origin feature_force_read_target_on_AD; To https://github.com/su2code/SU2.git; ! [rejected] feature_force_read_target_on_AD -> feature_force_read_target_on_AD (fetch first); error: failed to push some refs to 'https://github.com/su2code/SU2.git'; hint: Updates were rejected because the remote contains work that you do; hint: not have locally. This is usually caused by another repository pushing; hint: to the same ref. You may want to first integrate the remote changes; hint: (e.g., 'git pull ...') before pushing again.; hint: See the 'Note about fast-forwards' in 'git push --help' for details.; Jairos-Mac-mini:SU2 jaspe$",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-438029731
https://github.com/su2code/SU2/pull/600#issuecomment-439496260:51,Testability,test,tests,51,"Thanks, @jaspe55 ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439496260
https://github.com/su2code/SU2/pull/600#issuecomment-439496260:118,Testability,test,test,118,"Thanks, @jaspe55 ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439496260
https://github.com/su2code/SU2/pull/600#issuecomment-439496260:111,Usability,simpl,simple,111,"Thanks, @jaspe55 ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439496260
https://github.com/su2code/SU2/pull/600#issuecomment-439506935:291,Testability,test,test,291,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935
https://github.com/su2code/SU2/pull/600#issuecomment-439506935:512,Testability,test,tests,512,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935
https://github.com/su2code/SU2/pull/600#issuecomment-439506935:579,Testability,test,test,579,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935
https://github.com/su2code/SU2/pull/600#issuecomment-439506935:94,Usability,simpl,simple,94,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935
https://github.com/su2code/SU2/pull/600#issuecomment-439506935:241,Usability,simpl,simpler,241,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935
https://github.com/su2code/SU2/pull/600#issuecomment-439506935:572,Usability,simpl,simple,572,"Hello Dr. Economon,; ; At this moment, I am running a case which is lighter but sill not very simple (I am running it on a Mac with four cores, and it will finish by Monday, I suspect). As soon as it successfully completes, I will work on a simpler sample case in order to include it in the test suite, willing God. With kind regards,. Jairo. > On Nov 16, 2018, at 16:12, Thomas D. Economon <notifications@github.com> wrote:; > ; > Thanks, @jaspe55 <https://github.com/jaspe55> ! LGTM. I don't think we have any tests for the inverse design capability. Do you have a very simple test case that we can put into the regressions for this capability? I think you are working on a nozzle design.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-439496260>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180nOm5nOlpnYLID7YMRQeFOsAZQJYks5uvw4MgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-439506935
https://github.com/su2code/SU2/pull/600#issuecomment-445175541:66,Usability,simpl,simpler,66,"Hi Jairo, . what is the status here ? Is it possible to provide a simpler (smaller) case ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445175541
https://github.com/su2code/SU2/pull/600#issuecomment-445209093:142,Testability,test,tested,142,"Hello Dr. Albring,. Yes! Sorry for the delay due some internal presentations and events here.; I just finished a small model and successfully tested it on openSUSE. I expect to upload it today. With kind regards,. Jairo. > On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com> wrote:; > ; > Hi Jairo,; > ; > what is the status here ? Is it possible to provide a simpler (smaller) case ?; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445209093
https://github.com/su2code/SU2/pull/600#issuecomment-445209093:373,Usability,simpl,simpler,373,"Hello Dr. Albring,. Yes! Sorry for the delay due some internal presentations and events here.; I just finished a small model and successfully tested it on openSUSE. I expect to upload it today. With kind regards,. Jairo. > On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com> wrote:; > ; > Hi Jairo,; > ; > what is the status here ? Is it possible to provide a simpler (smaller) case ?; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445209093
https://github.com/su2code/SU2/pull/600#issuecomment-445429636:449,Availability,fault,faults,449,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> ; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636
https://github.com/su2code/SU2/pull/600#issuecomment-445429636:145,Modifiability,config,config,145,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> ; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636
https://github.com/su2code/SU2/pull/600#issuecomment-445429636:84,Testability,test,test,84,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> ; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636
https://github.com/su2code/SU2/pull/600#issuecomment-445429636:833,Testability,test,tested,833,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> ; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636
https://github.com/su2code/SU2/pull/600#issuecomment-445429636:1120,Usability,simpl,simpler,1120,"Dear Dr Albring,. I just followed the procedures and included the files to create a test case to SU2_CFD_AD [a coarse mesh, a TargetCp.dat and a config file for an Arina nozzle. The coarse mesh is a 2000 triangles one; which is enough to give us an idea of the shockwave location and the geometry modifications. The next mesh I have would be an ~85000 elements which gives us a good information on the 27th function call]. ; I had some segmentation faults during long jobs: Is there some recommended tuning I can do on OS/HW or SU2 in order to minimize them?. With kind regards,. Jairo. > On Dec 7, 2018, at 09:45, Jairo Paes Cavalcante Filho <jairo.pcfilho@gmail.com> wrote:; > ; > Hello Dr. Albring,; > ; > Yes! Sorry for the delay due some internal presentations and events here.; > I just finished a small model and successfully tested it on openSUSE. I expect to upload it today.; > ; > With kind regards,; > ; > Jairo; > ; >> On Dec 7, 2018, at 06:35, Tim Albring <notifications@github.com <mailto:notifications@github.com>> wrote:; >> ; >> Hi Jairo,; >> ; >> what is the status here ? Is it possible to provide a simpler (smaller) case ?; >> ; >> ; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-445175541>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180u4PogeqhPW9rrfY4mW705IYKjvhks5u2jZpgaJpZM4X34F2>.; >> ; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-445429636
https://github.com/su2code/SU2/pull/600#issuecomment-447209397:111,Modifiability,config,config,111,"@jaspe55 : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447209397
https://github.com/su2code/SU2/pull/600#issuecomment-447209397:150,Modifiability,config,config,150,"@jaspe55 : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447209397
https://github.com/su2code/SU2/pull/600#issuecomment-447209397:202,Testability,Test,TestCases,202,"@jaspe55 : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447209397
https://github.com/su2code/SU2/pull/600#issuecomment-447209397:314,Testability,Test,TestCases,314,"@jaspe55 : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447209397
https://github.com/su2code/SU2/pull/600#issuecomment-447209397:365,Testability,Test,TestCases,365,"@jaspe55 : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447209397
https://github.com/su2code/SU2/pull/600#issuecomment-447209397:429,Testability,Test,TestCases,429,"@jaspe55 : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447209397
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:1221,Modifiability,config,config,1221,"ance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDpbM_TXuwfdIJnHpDEpp295gqks5u4yh5gaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:1260,Modifiability,config,config,1260,"ance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDpbM_TXuwfdIJnHpDEpp295gqks5u4yh5gaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:217,Testability,Test,TestCases,217,"Dear Dr. Economon,. Thank you again for your guidance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:284,Testability,Test,TestCases,284,"Dear Dr. Economon,. Thank you again for your guidance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:1312,Testability,Test,TestCases,1312,"ance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDpbM_TXuwfdIJnHpDEpp295gqks5u4yh5gaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:1424,Testability,Test,TestCases,1424,"ance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDpbM_TXuwfdIJnHpDEpp295gqks5u4yh5gaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:1475,Testability,Test,TestCases,1475,"ance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDpbM_TXuwfdIJnHpDEpp295gqks5u4yh5gaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:1539,Testability,Test,TestCases,1539,"ance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDpbM_TXuwfdIJnHpDEpp295gqks5u4yh5gaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:1590,Testability,Test,TestCases,1590,"ance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDpbM_TXuwfdIJnHpDEpp295gqks5u4yh5gaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:45,Usability,guid,guidance,45,"Dear Dr. Economon,. Thank you again for your guidance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-447475363:890,Usability,simpl,simple,890,"Dear Dr. Economon,. Thank you again for your guidance.; The git add, git commit and git push commands worked as expected.; The only problem I had was when I tried to upload the mesh file to https://github.com/su2code/TestCases/tree/develop/disc_adj_euler: <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler:> I wanted to upload a folder arina2k, whose contents is the mesh file (.su2). I could not just upload the folder name: the system appears to be waiting for an actual file name. When I choose the file name inside that folder , it appears that the system would upload the file within the repository, but 'discarding its folder name, so I would have an orphaned file there. I tried also to create a file (which would be my folder name), but again, I am prompted with an editor in order to write an actual file, using directly the browser. I believe that there is a simple way to upload a sub-directory/filename, but i could not realize it. With kind regards,. Jairo. > On Dec 14, 2018, at 01:26, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I see that you have added the residual check for the python regression script, but I do not see the config file, target file, or mesh. The config file and target file should be placed in SU2/TestCases/disc_adj_euler/arina2k/ (according to your path in the regression script), and the mesh placed in the TestCases/disc_adj_euler/arina2k/ directory in the TestCases repository here (develop): https://github.com/su2code/TestCases/tree/develop <https://github.com/su2code/TestCases/tree/develop>. Don't forget to 'git add' the files to make sure they are included on push. We can help diagnose any segfaults with the files.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-447209397>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hTDp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-447475363
https://github.com/su2code/SU2/pull/600#issuecomment-448506828:99,Deployability,update,update,99,"I have just uploaded an empty file as a placeholder for your mesh, @jaspe55. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:. https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448506828
https://github.com/su2code/SU2/pull/600#issuecomment-448506828:153,Testability,Test,TestCases,153,"I have just uploaded an empty file as a placeholder for your mesh, @jaspe55. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:. https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448506828
https://github.com/su2code/SU2/pull/600#issuecomment-448506828:249,Testability,Test,TestCases,249,"I have just uploaded an empty file as a placeholder for your mesh, @jaspe55. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:. https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448506828
https://github.com/su2code/SU2/pull/600#issuecomment-448506828:341,Testability,Test,TestCases,341,"I have just uploaded an empty file as a placeholder for your mesh, @jaspe55. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:. https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448506828
https://github.com/su2code/SU2/pull/600#issuecomment-448831006:119,Deployability,update,updated,119,"Dear Dr. Economon,. I have uploaded a non-empty file (Arina2Kmesh.su2) to the develop branch and I was able to see the updated file in https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; Please find a glance of the evidence in the file appended to this note.; I realised that the uploading was effective after I committed it.; So I believe that now things are in the proper places. With kind regards,. Jairo. > On Dec 19, 2018, at 05:15, Thomas D. Economon <notifications@github.com> wrote:; > ; > I have just uploaded an empty file as a placeholder for your mesh, @jaspe55 <https://github.com/jaspe55>. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:; > ; > https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-448506828>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180g1pVX8bgD1AMR-pDrH4PM5AKAbcks5u6fWmgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448831006
https://github.com/su2code/SU2/pull/600#issuecomment-448831006:723,Deployability,update,update,723,"Dear Dr. Economon,. I have uploaded a non-empty file (Arina2Kmesh.su2) to the develop branch and I was able to see the updated file in https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; Please find a glance of the evidence in the file appended to this note.; I realised that the uploading was effective after I committed it.; So I believe that now things are in the proper places. With kind regards,. Jairo. > On Dec 19, 2018, at 05:15, Thomas D. Economon <notifications@github.com> wrote:; > ; > I have just uploaded an empty file as a placeholder for your mesh, @jaspe55 <https://github.com/jaspe55>. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:; > ; > https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-448506828>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180g1pVX8bgD1AMR-pDrH4PM5AKAbcks5u6fWmgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448831006
https://github.com/su2code/SU2/pull/600#issuecomment-448831006:162,Testability,Test,TestCases,162,"Dear Dr. Economon,. I have uploaded a non-empty file (Arina2Kmesh.su2) to the develop branch and I was able to see the updated file in https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; Please find a glance of the evidence in the file appended to this note.; I realised that the uploading was effective after I committed it.; So I believe that now things are in the proper places. With kind regards,. Jairo. > On Dec 19, 2018, at 05:15, Thomas D. Economon <notifications@github.com> wrote:; > ; > I have just uploaded an empty file as a placeholder for your mesh, @jaspe55 <https://github.com/jaspe55>. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:; > ; > https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-448506828>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180g1pVX8bgD1AMR-pDrH4PM5AKAbcks5u6fWmgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448831006
https://github.com/su2code/SU2/pull/600#issuecomment-448831006:236,Testability,Test,TestCases,236,"Dear Dr. Economon,. I have uploaded a non-empty file (Arina2Kmesh.su2) to the develop branch and I was able to see the updated file in https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; Please find a glance of the evidence in the file appended to this note.; I realised that the uploading was effective after I committed it.; So I believe that now things are in the proper places. With kind regards,. Jairo. > On Dec 19, 2018, at 05:15, Thomas D. Economon <notifications@github.com> wrote:; > ; > I have just uploaded an empty file as a placeholder for your mesh, @jaspe55 <https://github.com/jaspe55>. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:; > ; > https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-448506828>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180g1pVX8bgD1AMR-pDrH4PM5AKAbcks5u6fWmgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448831006
https://github.com/su2code/SU2/pull/600#issuecomment-448831006:777,Testability,Test,TestCases,777,"Dear Dr. Economon,. I have uploaded a non-empty file (Arina2Kmesh.su2) to the develop branch and I was able to see the updated file in https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; Please find a glance of the evidence in the file appended to this note.; I realised that the uploading was effective after I committed it.; So I believe that now things are in the proper places. With kind regards,. Jairo. > On Dec 19, 2018, at 05:15, Thomas D. Economon <notifications@github.com> wrote:; > ; > I have just uploaded an empty file as a placeholder for your mesh, @jaspe55 <https://github.com/jaspe55>. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:; > ; > https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-448506828>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180g1pVX8bgD1AMR-pDrH4PM5AKAbcks5u6fWmgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448831006
https://github.com/su2code/SU2/pull/600#issuecomment-448831006:873,Testability,Test,TestCases,873,"Dear Dr. Economon,. I have uploaded a non-empty file (Arina2Kmesh.su2) to the develop branch and I was able to see the updated file in https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; Please find a glance of the evidence in the file appended to this note.; I realised that the uploading was effective after I committed it.; So I believe that now things are in the proper places. With kind regards,. Jairo. > On Dec 19, 2018, at 05:15, Thomas D. Economon <notifications@github.com> wrote:; > ; > I have just uploaded an empty file as a placeholder for your mesh, @jaspe55 <https://github.com/jaspe55>. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:; > ; > https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-448506828>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180g1pVX8bgD1AMR-pDrH4PM5AKAbcks5u6fWmgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448831006
https://github.com/su2code/SU2/pull/600#issuecomment-448831006:971,Testability,Test,TestCases,971,"Dear Dr. Economon,. I have uploaded a non-empty file (Arina2Kmesh.su2) to the develop branch and I was able to see the updated file in https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; Please find a glance of the evidence in the file appended to this note.; I realised that the uploading was effective after I committed it.; So I believe that now things are in the proper places. With kind regards,. Jairo. > On Dec 19, 2018, at 05:15, Thomas D. Economon <notifications@github.com> wrote:; > ; > I have just uploaded an empty file as a placeholder for your mesh, @jaspe55 <https://github.com/jaspe55>. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:; > ; > https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-448506828>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180g1pVX8bgD1AMR-pDrH4PM5AKAbcks5u6fWmgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448831006
https://github.com/su2code/SU2/pull/600#issuecomment-448831006:1045,Testability,Test,TestCases,1045,"Dear Dr. Economon,. I have uploaded a non-empty file (Arina2Kmesh.su2) to the develop branch and I was able to see the updated file in https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; Please find a glance of the evidence in the file appended to this note.; I realised that the uploading was effective after I committed it.; So I believe that now things are in the proper places. With kind regards,. Jairo. > On Dec 19, 2018, at 05:15, Thomas D. Economon <notifications@github.com> wrote:; > ; > I have just uploaded an empty file as a placeholder for your mesh, @jaspe55 <https://github.com/jaspe55>. Can you please try to update your local copy of the develop branch from the TestCases repository and then overwrite the empty file with your mesh? You can find the file in TestCases/disc_adj_euler/arina2k/, or view in the browser here:; > ; > https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k <https://github.com/su2code/TestCases/tree/develop/disc_adj_euler/arina2k>; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-448506828>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180g1pVX8bgD1AMR-pDrH4PM5AKAbcks5u6fWmgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-448831006
https://github.com/su2code/SU2/pull/600#issuecomment-456240798:421,Deployability,update,update,421,"@jaspe55 : I have just cleaned up a couple of things and can confirm that your mesh file is there. However, we are missing the converged solution file (solution_flow.dat) and the target Cp file for inverse design. Similar to the process for the mesh, can you please upload the solution file to the TestCases repo and the target Cp file to the SU2 code repo (alongside the config file)? Once the files are present, we can update the regression values in the serial_regression_AD.py and parallel_regression_AD.py files, and this PR will be ready to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-456240798
https://github.com/su2code/SU2/pull/600#issuecomment-456240798:372,Modifiability,config,config,372,"@jaspe55 : I have just cleaned up a couple of things and can confirm that your mesh file is there. However, we are missing the converged solution file (solution_flow.dat) and the target Cp file for inverse design. Similar to the process for the mesh, can you please upload the solution file to the TestCases repo and the target Cp file to the SU2 code repo (alongside the config file)? Once the files are present, we can update the regression values in the serial_regression_AD.py and parallel_regression_AD.py files, and this PR will be ready to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-456240798
https://github.com/su2code/SU2/pull/600#issuecomment-456240798:298,Testability,Test,TestCases,298,"@jaspe55 : I have just cleaned up a couple of things and can confirm that your mesh file is there. However, we are missing the converged solution file (solution_flow.dat) and the target Cp file for inverse design. Similar to the process for the mesh, can you please upload the solution file to the TestCases repo and the target Cp file to the SU2 code repo (alongside the config file)? Once the files are present, we can update the regression values in the serial_regression_AD.py and parallel_regression_AD.py files, and this PR will be ready to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-456240798
https://github.com/su2code/SU2/pull/600#issuecomment-456794388:664,Deployability,update,update,664,"Dear Dr. Economon, . I just uploaded the mentioned files. I hope everything may be ok now. With kind regards,. Jairo. > On Jan 21, 2019, at 22:31, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I have just cleaned up a couple of things and can confirm that your mesh file is there. However, we are missing the converged solution file (solution_flow.dat) and the target Cp file for inverse design.; > ; > Similar to the process for the mesh, can you please upload the solution file to the TestCases repo and the target Cp file to the SU2 code repo (alongside the config file)? Once the files are present, we can update the regression values in the serial_regression_AD.py and parallel_regression_AD.py files, and this PR will be ready to merge.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-456240798>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180tLXcO2Ht3-J3rmwCWlPKQutyTiUks5vFmoEgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-456794388
https://github.com/su2code/SU2/pull/600#issuecomment-456794388:615,Modifiability,config,config,615,"Dear Dr. Economon, . I just uploaded the mentioned files. I hope everything may be ok now. With kind regards,. Jairo. > On Jan 21, 2019, at 22:31, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I have just cleaned up a couple of things and can confirm that your mesh file is there. However, we are missing the converged solution file (solution_flow.dat) and the target Cp file for inverse design.; > ; > Similar to the process for the mesh, can you please upload the solution file to the TestCases repo and the target Cp file to the SU2 code repo (alongside the config file)? Once the files are present, we can update the regression values in the serial_regression_AD.py and parallel_regression_AD.py files, and this PR will be ready to merge.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-456240798>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180tLXcO2Ht3-J3rmwCWlPKQutyTiUks5vFmoEgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-456794388
https://github.com/su2code/SU2/pull/600#issuecomment-456794388:541,Testability,Test,TestCases,541,"Dear Dr. Economon, . I just uploaded the mentioned files. I hope everything may be ok now. With kind regards,. Jairo. > On Jan 21, 2019, at 22:31, Thomas D. Economon <notifications@github.com> wrote:; > ; > @jaspe55 <https://github.com/jaspe55> : I have just cleaned up a couple of things and can confirm that your mesh file is there. However, we are missing the converged solution file (solution_flow.dat) and the target Cp file for inverse design.; > ; > Similar to the process for the mesh, can you please upload the solution file to the TestCases repo and the target Cp file to the SU2 code repo (alongside the config file)? Once the files are present, we can update the regression values in the serial_regression_AD.py and parallel_regression_AD.py files, and this PR will be ready to merge.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-456240798>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180tLXcO2Ht3-J3rmwCWlPKQutyTiUks5vFmoEgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-456794388
https://github.com/su2code/SU2/pull/600#issuecomment-459029239:342,Deployability,update,updated,342,"Ok. I will do it as soon as possible. . With kind regards,. Jairo. > On Jan 30, 2019, at 14:13, Thomas D. Economon <notifications@github.com> wrote:; > ; > @economon approved this pull request.; > ; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; > Just one request: I have adjusted the number of iterations for the regression test and updated the residual values in the python script. I also had to move around some files. Can you please run the case (to convergence) and verify that the results are what you expect? Note that the config file and target Cp are in the code repository and the mesh and solution file are in the testcases repository. If everything looks ok, then this is ready to be merged.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459029239
https://github.com/su2code/SU2/pull/600#issuecomment-459029239:538,Modifiability,config,config,538,"Ok. I will do it as soon as possible. . With kind regards,. Jairo. > On Jan 30, 2019, at 14:13, Thomas D. Economon <notifications@github.com> wrote:; > ; > @economon approved this pull request.; > ; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; > Just one request: I have adjusted the number of iterations for the regression test and updated the residual values in the python script. I also had to move around some files. Can you please run the case (to convergence) and verify that the results are what you expect? Note that the config file and target Cp are in the code repository and the mesh and solution file are in the testcases repository. If everything looks ok, then this is ready to be merged.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459029239
https://github.com/su2code/SU2/pull/600#issuecomment-459029239:333,Testability,test,test,333,"Ok. I will do it as soon as possible. . With kind regards,. Jairo. > On Jan 30, 2019, at 14:13, Thomas D. Economon <notifications@github.com> wrote:; > ; > @economon approved this pull request.; > ; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; > Just one request: I have adjusted the number of iterations for the regression test and updated the residual values in the python script. I also had to move around some files. Can you please run the case (to convergence) and verify that the results are what you expect? Note that the config file and target Cp are in the code repository and the mesh and solution file are in the testcases repository. If everything looks ok, then this is ready to be merged.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459029239
https://github.com/su2code/SU2/pull/600#issuecomment-459029239:633,Testability,test,testcases,633,"Ok. I will do it as soon as possible. . With kind regards,. Jairo. > On Jan 30, 2019, at 14:13, Thomas D. Economon <notifications@github.com> wrote:; > ; > @economon approved this pull request.; > ; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; > Just one request: I have adjusted the number of iterations for the regression test and updated the residual values in the python script. I also had to move around some files. Can you please run the case (to convergence) and verify that the results are what you expect? Note that the config file and target Cp are in the code repository and the mesh and solution file are in the testcases repository. If everything looks ok, then this is ready to be merged.; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459029239
https://github.com/su2code/SU2/pull/600#issuecomment-459568514:564,Deployability,update,updated,564,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
https://github.com/su2code/SU2/pull/600#issuecomment-459568514:769,Modifiability,config,config,769,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
https://github.com/su2code/SU2/pull/600#issuecomment-459568514:161,Testability,test,tests,161,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
https://github.com/su2code/SU2/pull/600#issuecomment-459568514:555,Testability,test,test,555,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
https://github.com/su2code/SU2/pull/600#issuecomment-459568514:867,Testability,test,testcases,867,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
https://github.com/su2code/SU2/pull/600#issuecomment-459568514:139,Usability,simpl,simple,139,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
https://github.com/su2code/SU2/pull/600#issuecomment-459568514:236,Usability,guid,guidance,236,"Dear Dr. Economon,. I just finished the run on AD with the files you have adjusted and it did; converge. I also have successfully run some simple inverse design tests; with a limit on the number of cycles.; Thank you very much for your guidance and help. With kind regards,. Jairo. On Wed, Jan 30, 2019 at 2:13 PM Thomas D. Economon <notifications@github.com>; wrote:. > *@economon* approved this pull request.; >; > LGMT. Thanks @jaspe55 <https://github.com/jaspe55>; >; > Just one request: I have adjusted the number of iterations for the; > regression test and updated the residual values in the python script. I; > also had to move around some files. Can you please run the case (to; > convergence) and verify that the results are what you expect? Note that the; > config file and target Cp are in the code repository and the mesh and; > solution file are in the testcases repository. If everything looks ok, then; > this is ready to be merged.; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#pullrequestreview-198200089>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180hqzVnSUPCnSBkQrTPfIv0kIltygks5vIdKrgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459568514
https://github.com/su2code/SU2/pull/600#issuecomment-459704107:141,Energy Efficiency,schedul,schedule,141,"Thank you, Dr. Economon.; When you say ""Time to merge this one"": Is this an action I should take, or; is it accomplished in the SU2 standard schedule ?. With kind regards,. Jairo. On Fri, Feb 1, 2019 at 1:17 AM Thomas D. Economon <notifications@github.com>; wrote:. > Wonderful! Time to merge this one; >; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/600#issuecomment-459600006>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/Ac180h3pv-PS55cNp0vxoX8AA717kJyDks5vI7_OgaJpZM4X34F2>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459704107
https://github.com/su2code/SU2/pull/600#issuecomment-459772171:25,Testability,test,tests,25,Was just waiting for the tests to finish. Merging now. Thanks again for the effort,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459772171
https://github.com/su2code/SU2/pull/600#issuecomment-459809638:162,Testability,test,tests,162,"Ah! Ok!. Thank you, again. Kind regards,. Jairo. > On Feb 1, 2019, at 13:02, Thomas D. Economon <notifications@github.com> wrote:; > ; > Was just waiting for the tests to finish. Merging now. Thanks again for the effort; > ; > ; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/su2code/SU2/pull/600#issuecomment-459772171>, or mute the thread <https://github.com/notifications/unsubscribe-auth/Ac180l_JvmEVR9mvZNTQjygJa9GdV-CJks5vJGUggaJpZM4X34F2>.; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/600#issuecomment-459809638
https://github.com/su2code/SU2/pull/603#issuecomment-434815411:17,Testability,test,tested,17,"Yep, this is not tested in the regression tests, so it slipped through.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/603#issuecomment-434815411
https://github.com/su2code/SU2/pull/603#issuecomment-434815411:42,Testability,test,tests,42,"Yep, this is not tested in the regression tests, so it slipped through.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/603#issuecomment-434815411
https://github.com/su2code/SU2/pull/603#issuecomment-435066556:22,Safety,safe,safeguarded,22,"@vdweide ok I think I safeguarded the required areas, if you could test this it would be great as I do not have these libraries.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/603#issuecomment-435066556
https://github.com/su2code/SU2/pull/603#issuecomment-435066556:67,Testability,test,test,67,"@vdweide ok I think I safeguarded the required areas, if you could test this it would be great as I do not have these libraries.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/603#issuecomment-435066556
https://github.com/su2code/SU2/pull/603#issuecomment-435128510:89,Testability,test,test,89,"@pcarruscag, everything looks to be working as it should. As soon as the last regression test goes through (it failed due to a connection time out), it can be merged in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/603#issuecomment-435128510
https://github.com/su2code/SU2/pull/605#issuecomment-435105466:137,Integrability,rout,routines,137,"To answer the first question, yes, the distance calculations are done based the entire surface of a boundary element. This is done using routines written by @vdweide for the higher order solver. In short, the distance to the wall of a node in the mesh is found by finding the projection of the said node on a boundary element, and the distance is calculated using that information. . I validated this on a host of grids, some of which had sheared elements near the wall, and this procedure seemed to give the right predictions regardless of the quality of the mesh. . Yes, from what I understand, by the end of the ComputeWall_Distance function all the memory, weather it is the vectors or the ADT itself, should be deallocated. I based this code on what Edwin was doing so he might be able to substantiate on why he deallocates the vectors immediately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435105466
https://github.com/su2code/SU2/pull/605#issuecomment-435105466:515,Safety,predict,predictions,515,"To answer the first question, yes, the distance calculations are done based the entire surface of a boundary element. This is done using routines written by @vdweide for the higher order solver. In short, the distance to the wall of a node in the mesh is found by finding the projection of the said node on a boundary element, and the distance is calculated using that information. . I validated this on a host of grids, some of which had sheared elements near the wall, and this procedure seemed to give the right predictions regardless of the quality of the mesh. . Yes, from what I understand, by the end of the ComputeWall_Distance function all the memory, weather it is the vectors or the ADT itself, should be deallocated. I based this code on what Edwin was doing so he might be able to substantiate on why he deallocates the vectors immediately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435105466
https://github.com/su2code/SU2/pull/605#issuecomment-435105466:386,Security,validat,validated,386,"To answer the first question, yes, the distance calculations are done based the entire surface of a boundary element. This is done using routines written by @vdweide for the higher order solver. In short, the distance to the wall of a node in the mesh is found by finding the projection of the said node on a boundary element, and the distance is calculated using that information. . I validated this on a host of grids, some of which had sheared elements near the wall, and this procedure seemed to give the right predictions regardless of the quality of the mesh. . Yes, from what I understand, by the end of the ComputeWall_Distance function all the memory, weather it is the vectors or the ADT itself, should be deallocated. I based this code on what Edwin was doing so he might be able to substantiate on why he deallocates the vectors immediately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435105466
https://github.com/su2code/SU2/pull/605#issuecomment-435131100:234,Deployability,release,release,234,"@jayantmukho, the arguments to the ADT are converted to the data structures used in the ADT. This must be done, because sometimes it is necessary to gather surface grids to all ranks for an efficient search. That is why it is safe to release the memory immediately. Note that it is not necessary to do so, but this is just to avoid that an unnecessary amount of memory is allocated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435131100
https://github.com/su2code/SU2/pull/605#issuecomment-435131100:190,Energy Efficiency,efficient,efficient,190,"@jayantmukho, the arguments to the ADT are converted to the data structures used in the ADT. This must be done, because sometimes it is necessary to gather surface grids to all ranks for an efficient search. That is why it is safe to release the memory immediately. Note that it is not necessary to do so, but this is just to avoid that an unnecessary amount of memory is allocated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435131100
https://github.com/su2code/SU2/pull/605#issuecomment-435131100:372,Energy Efficiency,allocate,allocated,372,"@jayantmukho, the arguments to the ADT are converted to the data structures used in the ADT. This must be done, because sometimes it is necessary to gather surface grids to all ranks for an efficient search. That is why it is safe to release the memory immediately. Note that it is not necessary to do so, but this is just to avoid that an unnecessary amount of memory is allocated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435131100
https://github.com/su2code/SU2/pull/605#issuecomment-435131100:226,Safety,safe,safe,226,"@jayantmukho, the arguments to the ADT are converted to the data structures used in the ADT. This must be done, because sometimes it is necessary to gather surface grids to all ranks for an efficient search. That is why it is safe to release the memory immediately. Note that it is not necessary to do so, but this is just to avoid that an unnecessary amount of memory is allocated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435131100
https://github.com/su2code/SU2/pull/605#issuecomment-435131100:326,Safety,avoid,avoid,326,"@jayantmukho, the arguments to the ADT are converted to the data structures used in the ADT. This must be done, because sometimes it is necessary to gather surface grids to all ranks for an efficient search. That is why it is safe to release the memory immediately. Note that it is not necessary to do so, but this is just to avoid that an unnecessary amount of memory is allocated.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435131100
https://github.com/su2code/SU2/pull/605#issuecomment-435402614:12,Security,validat,validate,12,"Can someone validate the Conjugate Heat Transfer test case? Perhaps @oleburghardt ? I included the CHT_WALL_INTERFACE in the list of markers that are used for the wall distance computation, but that was not present in the original implementation. I can run the test case, but I don't know what to validate the case against.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435402614
https://github.com/su2code/SU2/pull/605#issuecomment-435402614:297,Security,validat,validate,297,"Can someone validate the Conjugate Heat Transfer test case? Perhaps @oleburghardt ? I included the CHT_WALL_INTERFACE in the list of markers that are used for the wall distance computation, but that was not present in the original implementation. I can run the test case, but I don't know what to validate the case against.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435402614
https://github.com/su2code/SU2/pull/605#issuecomment-435402614:49,Testability,test,test,49,"Can someone validate the Conjugate Heat Transfer test case? Perhaps @oleburghardt ? I included the CHT_WALL_INTERFACE in the list of markers that are used for the wall distance computation, but that was not present in the original implementation. I can run the test case, but I don't know what to validate the case against.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435402614
https://github.com/su2code/SU2/pull/605#issuecomment-435402614:261,Testability,test,test,261,"Can someone validate the Conjugate Heat Transfer test case? Perhaps @oleburghardt ? I included the CHT_WALL_INTERFACE in the list of markers that are used for the wall distance computation, but that was not present in the original implementation. I can run the test case, but I don't know what to validate the case against.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435402614
https://github.com/su2code/SU2/pull/605#issuecomment-435574030:87,Testability,test,test,87,"@jayantmukho, can we merge in this one or do you prefer to wait until the data for CHT test case has been confirmed?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435574030
https://github.com/su2code/SU2/pull/605#issuecomment-435986302:30,Testability,test,test,30,"I have run the CHT regression test to convergence in both cases, and it looks ok to me. I think it is fine to move forward with this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-435986302
https://github.com/su2code/SU2/pull/605#issuecomment-436165257:162,Testability,test,test,162,"@jayantmukho, is it possible to plot the wall distance for both cases as well as the difference in wall distance? Furthermore, what is the grid you used for this test case? Do you expect large differences in the wall distances between both formulations?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-436165257
https://github.com/su2code/SU2/pull/605#issuecomment-436307962:303,Availability,down,downstream,303,"Good idea.. you can easily add the wall distance to the output in LoadLocalData_Flow() in output_structure.cpp. In the images, the half-cylinder (symmetry planes on top and bottom) has a solid zone inside with heat conduction. The interface there is a no-slip wall with the CHT_WALL_INTERFACE type. The downstream surface is also no-slip, but it is a typical ISOTHERMAL wall. Since the CHT_WALL_INTERFACE type was not considered earlier (only the trailing no-slip wall), I think that you will see a reduced wall distance near the cylinder, which will impact the turbulent solution. I expect some differences due to the change.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-436307962
https://github.com/su2code/SU2/pull/605#issuecomment-436307962:499,Energy Efficiency,reduce,reduced,499,"Good idea.. you can easily add the wall distance to the output in LoadLocalData_Flow() in output_structure.cpp. In the images, the half-cylinder (symmetry planes on top and bottom) has a solid zone inside with heat conduction. The interface there is a no-slip wall with the CHT_WALL_INTERFACE type. The downstream surface is also no-slip, but it is a typical ISOTHERMAL wall. Since the CHT_WALL_INTERFACE type was not considered earlier (only the trailing no-slip wall), I think that you will see a reduced wall distance near the cylinder, which will impact the turbulent solution. I expect some differences due to the change.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-436307962
https://github.com/su2code/SU2/pull/605#issuecomment-436307962:231,Integrability,interface,interface,231,"Good idea.. you can easily add the wall distance to the output in LoadLocalData_Flow() in output_structure.cpp. In the images, the half-cylinder (symmetry planes on top and bottom) has a solid zone inside with heat conduction. The interface there is a no-slip wall with the CHT_WALL_INTERFACE type. The downstream surface is also no-slip, but it is a typical ISOTHERMAL wall. Since the CHT_WALL_INTERFACE type was not considered earlier (only the trailing no-slip wall), I think that you will see a reduced wall distance near the cylinder, which will impact the turbulent solution. I expect some differences due to the change.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/605#issuecomment-436307962
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:100,Availability,error,error,100,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:893,Availability,down,down,893,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:126,Energy Efficiency,adapt,adaptive,126,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:275,Energy Efficiency,sensor,sensor,275,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:343,Energy Efficiency,sensor,sensor,343,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:594,Energy Efficiency,sensor,sensors,594,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:707,Energy Efficiency,sensor,sensor,707,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:970,Energy Efficiency,adapt,adapt,970,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:1388,Energy Efficiency,adapt,adapt,1388,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:37,Integrability,message,message,37,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:106,Integrability,message,message,106,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:1417,Integrability,message,message,1417,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:126,Modifiability,adapt,adaptive,126,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:970,Modifiability,adapt,adapt,970,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-434924444:1388,Modifiability,adapt,adapt,1388,"I'm the one who created that warning message, so I can fill in some details about when and why that error message occurs. For adaptive mesh refinement, SU2 looks at each element and checks how important it would be to divide that element. It then assigns a numeric value (a ""sensor"") to each element representing the relative importance. That sensor is normalized by the max value and is assumed to be positive, so its range should be from 0 to 1. SU2 defines a number of elements that it wants to create (4455 in your case). It then loops through all the elements and looks for elements whose sensors fall above a threshold. That threshold starts at 0.999, close to the max value of 1. If an element has a sensor above that threshold, SU2 marks that cell for division. If it doesn't find enough elements, then it lowers the threshold and continues looking. That process continues all the way down till the threshold hits 0. Sometimes, SU2 can't find enough elements to adapt. The threshold goes all the way to 0, and there's still not enough. Then it prints that warning and continues. That's what you're seeing. The code only mentions triangles, quadrilaterals, and tetrahedrons as a guess to what's wrong. You'll notice it says your grid ""may"" have too high a percentage of other types. If your grid were composed solely of hexahedrons, for example, then it won't find any elements to adapt and print that warning message. There's no check to confirm that this guess is actually correct. In your case, you only have quads and triangles, so the guess is obviously mistaken. As to what is actually going wrong in your case, I would have to dig in a little deeper to find out what's going on. I would guess that your elements aren't being marked as ""divisible,"" but I'm not sure why.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-434924444
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:743,Deployability,configurat,configuration,743,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:207,Energy Efficiency,sensor,sensor,207,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:325,Energy Efficiency,adapt,adaptation,325,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:430,Energy Efficiency,adapt,adaptation,430,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:568,Energy Efficiency,sensor,sensor,568,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:678,Energy Efficiency,adapt,adaptation,678,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:392,Integrability,message,message,392,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:325,Modifiability,adapt,adaptation,325,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:430,Modifiability,adapt,adaptation,430,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:678,Modifiability,adapt,adaptation,678,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-435625964:743,Modifiability,config,configuration,743,"Thanks for the clarification clarkpede. One of the things I had tried when I first ran into that warning after looking at the code was to create a coarse grid with fewer than 1000 elements (just in case the sensor value was extremely large for a single element for some reason, then it shouldve at least marked that one for adaptation). However, it still output the same results and warning message. Im not exactly sure how the adaptation index is calculated for the SUPERSONIC_SHOCK or GRAD_FLOW, but is it possible that these values could be negative, causing the sensor value to always be below the threshold value?. I havent been able to find any examples using the mesh adaptation, so I may be missing an additional parameter from the configuration file. Thanks for any additional help,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-435625964
https://github.com/su2code/SU2/issues/606#issuecomment-436131167:122,Deployability,release,release,122,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
https://github.com/su2code/SU2/issues/606#issuecomment-436131167:215,Energy Efficiency,adapt,adaptation,215,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
https://github.com/su2code/SU2/issues/606#issuecomment-436131167:80,Integrability,message,message,80,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
https://github.com/su2code/SU2/issues/606#issuecomment-436131167:215,Modifiability,adapt,adaptation,215,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
https://github.com/su2code/SU2/issues/606#issuecomment-436131167:674,Usability,clear,clear,674,"Alright. I did some digging, and the problem has nothing to do with the warning message. It goes much deeper. In a recent release, SU2 switched to reading and writing binary restart files instead of ASCII. The grid adaptation code is still written only for ASCII. If I'm right, then trying to read a binary restart file with the flow solution breaks the program. I'll submit an issue detailing the bug. For now, try adding the following lines to your cfg file when you run `SU2_CFD`:. %; % Write binary restart files (YES, NO); WRT_BINARY_RESTART= NO; %; % Read binary restart files (YES, NO); READ_BINARY_RESTART= NO. Then run `SU2_MSH`, just like you have been. Does that clear things up?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-436131167
https://github.com/su2code/SU2/issues/606#issuecomment-437553068:274,Energy Efficiency,adapt,adaptation,274,"Thank you. It does seem to work for the GRAD_FLOW option; however, it still results in the same incorrect results as before for the SUPERSONIC_SHOCK option. Also, when I add ""-c 2"" as a command line argument to mesh_adaptation.py to speed up the process of running multiple adaptation cycles, the simulation will only do a single one then exit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-437553068
https://github.com/su2code/SU2/issues/606#issuecomment-437553068:274,Modifiability,adapt,adaptation,274,"Thank you. It does seem to work for the GRAD_FLOW option; however, it still results in the same incorrect results as before for the SUPERSONIC_SHOCK option. Also, when I add ""-c 2"" as a command line argument to mesh_adaptation.py to speed up the process of running multiple adaptation cycles, the simulation will only do a single one then exit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-437553068
https://github.com/su2code/SU2/issues/606#issuecomment-438766705:227,Energy Efficiency,adapt,adapted,227,"Can you confirm what results you're actually getting with the `SUPERSONIC_SHOCK` option? I'm having trouble producing something like what you see in the figure above. When I run the `SUPERSONIC_SHOCK` option, I get no elements adapted (3626 elements for both cases). This has to due with how the supersonic shock refinement is set up, which seems ad-hoc. I don't think the `SUPERSONIC_SHOCK` option can be used for general cases. Other developers know more about this than me--that section of the code goes all the way back to v1.0 of SU2. Maybe @fpalacios or @economon can tell you more about the mesh adaptation?. You might also be interested in the recent collaboration between the SU2 developers and the developers of the INRIA-AMG library. It seems like SU2 development is moving away from in-house mesh adaptation codes and more towards leveraging the AMG library. There was a presentation about it back in 2016 [that you can find here](https://su2code.github.io/documents/su2_dev_alonso.pdf). There was also a talk about it at the recent SU2 conference that [you can watch here on YouTube](https://youtu.be/jkZaPsKDvvQ?t=16318).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-438766705
https://github.com/su2code/SU2/issues/606#issuecomment-438766705:603,Energy Efficiency,adapt,adaptation,603,"Can you confirm what results you're actually getting with the `SUPERSONIC_SHOCK` option? I'm having trouble producing something like what you see in the figure above. When I run the `SUPERSONIC_SHOCK` option, I get no elements adapted (3626 elements for both cases). This has to due with how the supersonic shock refinement is set up, which seems ad-hoc. I don't think the `SUPERSONIC_SHOCK` option can be used for general cases. Other developers know more about this than me--that section of the code goes all the way back to v1.0 of SU2. Maybe @fpalacios or @economon can tell you more about the mesh adaptation?. You might also be interested in the recent collaboration between the SU2 developers and the developers of the INRIA-AMG library. It seems like SU2 development is moving away from in-house mesh adaptation codes and more towards leveraging the AMG library. There was a presentation about it back in 2016 [that you can find here](https://su2code.github.io/documents/su2_dev_alonso.pdf). There was also a talk about it at the recent SU2 conference that [you can watch here on YouTube](https://youtu.be/jkZaPsKDvvQ?t=16318).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-438766705
https://github.com/su2code/SU2/issues/606#issuecomment-438766705:809,Energy Efficiency,adapt,adaptation,809,"Can you confirm what results you're actually getting with the `SUPERSONIC_SHOCK` option? I'm having trouble producing something like what you see in the figure above. When I run the `SUPERSONIC_SHOCK` option, I get no elements adapted (3626 elements for both cases). This has to due with how the supersonic shock refinement is set up, which seems ad-hoc. I don't think the `SUPERSONIC_SHOCK` option can be used for general cases. Other developers know more about this than me--that section of the code goes all the way back to v1.0 of SU2. Maybe @fpalacios or @economon can tell you more about the mesh adaptation?. You might also be interested in the recent collaboration between the SU2 developers and the developers of the INRIA-AMG library. It seems like SU2 development is moving away from in-house mesh adaptation codes and more towards leveraging the AMG library. There was a presentation about it back in 2016 [that you can find here](https://su2code.github.io/documents/su2_dev_alonso.pdf). There was also a talk about it at the recent SU2 conference that [you can watch here on YouTube](https://youtu.be/jkZaPsKDvvQ?t=16318).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-438766705
https://github.com/su2code/SU2/issues/606#issuecomment-438766705:227,Modifiability,adapt,adapted,227,"Can you confirm what results you're actually getting with the `SUPERSONIC_SHOCK` option? I'm having trouble producing something like what you see in the figure above. When I run the `SUPERSONIC_SHOCK` option, I get no elements adapted (3626 elements for both cases). This has to due with how the supersonic shock refinement is set up, which seems ad-hoc. I don't think the `SUPERSONIC_SHOCK` option can be used for general cases. Other developers know more about this than me--that section of the code goes all the way back to v1.0 of SU2. Maybe @fpalacios or @economon can tell you more about the mesh adaptation?. You might also be interested in the recent collaboration between the SU2 developers and the developers of the INRIA-AMG library. It seems like SU2 development is moving away from in-house mesh adaptation codes and more towards leveraging the AMG library. There was a presentation about it back in 2016 [that you can find here](https://su2code.github.io/documents/su2_dev_alonso.pdf). There was also a talk about it at the recent SU2 conference that [you can watch here on YouTube](https://youtu.be/jkZaPsKDvvQ?t=16318).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-438766705
https://github.com/su2code/SU2/issues/606#issuecomment-438766705:603,Modifiability,adapt,adaptation,603,"Can you confirm what results you're actually getting with the `SUPERSONIC_SHOCK` option? I'm having trouble producing something like what you see in the figure above. When I run the `SUPERSONIC_SHOCK` option, I get no elements adapted (3626 elements for both cases). This has to due with how the supersonic shock refinement is set up, which seems ad-hoc. I don't think the `SUPERSONIC_SHOCK` option can be used for general cases. Other developers know more about this than me--that section of the code goes all the way back to v1.0 of SU2. Maybe @fpalacios or @economon can tell you more about the mesh adaptation?. You might also be interested in the recent collaboration between the SU2 developers and the developers of the INRIA-AMG library. It seems like SU2 development is moving away from in-house mesh adaptation codes and more towards leveraging the AMG library. There was a presentation about it back in 2016 [that you can find here](https://su2code.github.io/documents/su2_dev_alonso.pdf). There was also a talk about it at the recent SU2 conference that [you can watch here on YouTube](https://youtu.be/jkZaPsKDvvQ?t=16318).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-438766705
https://github.com/su2code/SU2/issues/606#issuecomment-438766705:809,Modifiability,adapt,adaptation,809,"Can you confirm what results you're actually getting with the `SUPERSONIC_SHOCK` option? I'm having trouble producing something like what you see in the figure above. When I run the `SUPERSONIC_SHOCK` option, I get no elements adapted (3626 elements for both cases). This has to due with how the supersonic shock refinement is set up, which seems ad-hoc. I don't think the `SUPERSONIC_SHOCK` option can be used for general cases. Other developers know more about this than me--that section of the code goes all the way back to v1.0 of SU2. Maybe @fpalacios or @economon can tell you more about the mesh adaptation?. You might also be interested in the recent collaboration between the SU2 developers and the developers of the INRIA-AMG library. It seems like SU2 development is moving away from in-house mesh adaptation codes and more towards leveraging the AMG library. There was a presentation about it back in 2016 [that you can find here](https://su2code.github.io/documents/su2_dev_alonso.pdf). There was also a talk about it at the recent SU2 conference that [you can watch here on YouTube](https://youtu.be/jkZaPsKDvvQ?t=16318).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-438766705
https://github.com/su2code/SU2/issues/606#issuecomment-443926887:169,Energy Efficiency,adapt,adaptation,169,"Sorry for the delayed response,. Yes, for some reason I still receive the same results using the SUPERSONIC_SHOCK option. Thank you for the additional resources on mesh adaptation,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-443926887
https://github.com/su2code/SU2/issues/606#issuecomment-443926887:169,Modifiability,adapt,adaptation,169,"Sorry for the delayed response,. Yes, for some reason I still receive the same results using the SUPERSONIC_SHOCK option. Thank you for the additional resources on mesh adaptation,; Alex",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-443926887
https://github.com/su2code/SU2/issues/606#issuecomment-444955431:222,Energy Efficiency,adapt,adaptation,222,"Ok. My advice would be to not use the `SUPERSONIC_SHOCK` option, but other developers may have further recommendations there. It doesn't seem to be set up for general cases. Are you having any further issues with the mesh adaptation? For example, is the `GRAD_FLOW` option working as you expected? Has the issue been resolved?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-444955431
https://github.com/su2code/SU2/issues/606#issuecomment-444955431:222,Modifiability,adapt,adaptation,222,"Ok. My advice would be to not use the `SUPERSONIC_SHOCK` option, but other developers may have further recommendations there. It doesn't seem to be set up for general cases. Are you having any further issues with the mesh adaptation? For example, is the `GRAD_FLOW` option working as you expected? Has the issue been resolved?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-444955431
https://github.com/su2code/SU2/issues/606#issuecomment-445429364:49,Usability,simpl,simple,49,"Yes, the GRAD_FLOW option has worked well for my simple application. I have not tried using it on other more complex problems or geometries.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-445429364
https://github.com/su2code/SU2/issues/606#issuecomment-500491744:36,Energy Efficiency,adapt,adaptation,36,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744
https://github.com/su2code/SU2/issues/606#issuecomment-500491744:36,Modifiability,adapt,adaptation,36,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744
https://github.com/su2code/SU2/issues/606#issuecomment-500491744:79,Usability,simpl,simply,79,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744
https://github.com/su2code/SU2/issues/606#issuecomment-500491744:86,Usability,learn,learning,86,"@clarkpede I have not used the mesh adaptation tools since my last post (I was simply learning to use them for an undergrad project). With that said, I do not have any other concerns. It worked well for my application. I appreciate your help.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-500491744
https://github.com/su2code/SU2/issues/606#issuecomment-504564218:177,Availability,error,error,177,"Hi @clarkpede I still have the same issue after using the advice you suggested above for having binary to NO. Please find attaches files for your review. I am still seeing same error like @alexfangman . Can you please help?; WARNING: Tried to find 14980 cells suitable for adaptation, but only found 0; The following cell types are currently adaptable: ; + triangles; + quadrilaterals; + tetrahedrons; Your grid may have too high a percentage of other types.; Number of elements to adapt: 0; Homothetic grid adaptation",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504564218
https://github.com/su2code/SU2/issues/606#issuecomment-504564218:273,Energy Efficiency,adapt,adaptation,273,"Hi @clarkpede I still have the same issue after using the advice you suggested above for having binary to NO. Please find attaches files for your review. I am still seeing same error like @alexfangman . Can you please help?; WARNING: Tried to find 14980 cells suitable for adaptation, but only found 0; The following cell types are currently adaptable: ; + triangles; + quadrilaterals; + tetrahedrons; Your grid may have too high a percentage of other types.; Number of elements to adapt: 0; Homothetic grid adaptation",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504564218
https://github.com/su2code/SU2/issues/606#issuecomment-504564218:342,Energy Efficiency,adapt,adaptable,342,"Hi @clarkpede I still have the same issue after using the advice you suggested above for having binary to NO. Please find attaches files for your review. I am still seeing same error like @alexfangman . Can you please help?; WARNING: Tried to find 14980 cells suitable for adaptation, but only found 0; The following cell types are currently adaptable: ; + triangles; + quadrilaterals; + tetrahedrons; Your grid may have too high a percentage of other types.; Number of elements to adapt: 0; Homothetic grid adaptation",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504564218
https://github.com/su2code/SU2/issues/606#issuecomment-504564218:482,Energy Efficiency,adapt,adapt,482,"Hi @clarkpede I still have the same issue after using the advice you suggested above for having binary to NO. Please find attaches files for your review. I am still seeing same error like @alexfangman . Can you please help?; WARNING: Tried to find 14980 cells suitable for adaptation, but only found 0; The following cell types are currently adaptable: ; + triangles; + quadrilaterals; + tetrahedrons; Your grid may have too high a percentage of other types.; Number of elements to adapt: 0; Homothetic grid adaptation",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504564218
https://github.com/su2code/SU2/issues/606#issuecomment-504564218:508,Energy Efficiency,adapt,adaptation,508,"Hi @clarkpede I still have the same issue after using the advice you suggested above for having binary to NO. Please find attaches files for your review. I am still seeing same error like @alexfangman . Can you please help?; WARNING: Tried to find 14980 cells suitable for adaptation, but only found 0; The following cell types are currently adaptable: ; + triangles; + quadrilaterals; + tetrahedrons; Your grid may have too high a percentage of other types.; Number of elements to adapt: 0; Homothetic grid adaptation",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504564218
https://github.com/su2code/SU2/issues/606#issuecomment-504564218:273,Modifiability,adapt,adaptation,273,"Hi @clarkpede I still have the same issue after using the advice you suggested above for having binary to NO. Please find attaches files for your review. I am still seeing same error like @alexfangman . Can you please help?; WARNING: Tried to find 14980 cells suitable for adaptation, but only found 0; The following cell types are currently adaptable: ; + triangles; + quadrilaterals; + tetrahedrons; Your grid may have too high a percentage of other types.; Number of elements to adapt: 0; Homothetic grid adaptation",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504564218
https://github.com/su2code/SU2/issues/606#issuecomment-504564218:342,Modifiability,adapt,adaptable,342,"Hi @clarkpede I still have the same issue after using the advice you suggested above for having binary to NO. Please find attaches files for your review. I am still seeing same error like @alexfangman . Can you please help?; WARNING: Tried to find 14980 cells suitable for adaptation, but only found 0; The following cell types are currently adaptable: ; + triangles; + quadrilaterals; + tetrahedrons; Your grid may have too high a percentage of other types.; Number of elements to adapt: 0; Homothetic grid adaptation",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504564218
https://github.com/su2code/SU2/issues/606#issuecomment-504564218:482,Modifiability,adapt,adapt,482,"Hi @clarkpede I still have the same issue after using the advice you suggested above for having binary to NO. Please find attaches files for your review. I am still seeing same error like @alexfangman . Can you please help?; WARNING: Tried to find 14980 cells suitable for adaptation, but only found 0; The following cell types are currently adaptable: ; + triangles; + quadrilaterals; + tetrahedrons; Your grid may have too high a percentage of other types.; Number of elements to adapt: 0; Homothetic grid adaptation",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504564218
https://github.com/su2code/SU2/issues/606#issuecomment-504564218:508,Modifiability,adapt,adaptation,508,"Hi @clarkpede I still have the same issue after using the advice you suggested above for having binary to NO. Please find attaches files for your review. I am still seeing same error like @alexfangman . Can you please help?; WARNING: Tried to find 14980 cells suitable for adaptation, but only found 0; The following cell types are currently adaptable: ; + triangles; + quadrilaterals; + tetrahedrons; Your grid may have too high a percentage of other types.; Number of elements to adapt: 0; Homothetic grid adaptation",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504564218
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:2464,Availability,ERROR,ERROR,2464,"itute of Aeronautics.; #; # Copyright 2012-2018, Francisco D. Palacios, Thomas D. Economon,; # Tim Albring, and the SU2 contributors.; #; # SU2 is free software; you can redistribute it and/or; # modify it under the terms of the GNU Lesser General Public; # License as published by the Free Software Foundation; either; # version 2.1 of the License, or (at your option) any later version.; #; # SU2 is distributed in the hope that it will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(conf",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3103,Availability,ERROR,ERROR,3103,"will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsisten",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:5761,Availability,ERROR,ERROR,5761,"RY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'curre",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:6260,Availability,ERROR,ERROR,6260,"v_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7409,Availability,ERROR,ERROR,7409,"Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:8665,Availability,ERROR,ERROR,8665,"nfig_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mes",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:8765,Availability,ERROR,ERROR,8765,"URCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_ma",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:8994,Availability,ERROR,ERROR,8994,"s[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:9263,Availability,ERROR,ERROR,9263," (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:9371,Availability,ERROR,ERROR,9371,"amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Genera",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:9479,Availability,ERROR,ERROR,9479,"thon interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10023,Availability,ERROR,ERROR,10023," adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Runni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:11771,Availability,ERROR,ERROR,11771,"e_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.\n""; ; ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; ; #--- Print convergence history; ; plot_format = config_cfd['OUTPUT_FORMAT']; plot_extension = su2io.get_extension(plot_format); history_filename = config_cfd['CONV_FILENAME'] + plot_extension; ; history = su2io.read_history(history_filename); ; res_flow = history['Res_Flow[0]']; res_cvg = max(res_flow)-min(res_flow); ; del history; ; sys.stdout.write(' %s CFD done. Residual convergence %.2lf orders of magnitude\n' % (pad_nul, res_cvg)); ; ; to_remove = [""current.itp.solb"", config_amg['mesh_in'], config_amg['mesh_out'], config_amg['sol_in'],config_amg['itp_sol_in']]; for fil in to_remove:; if os.path.exists(fil) : os.remove(fil); ; global_iter += 1; ; os.rename(current_solution,os.path.join(cwd,config.RESTART_FLOW_FILENAME)); os.rename(current_mesh,os.path.join(cwd,config.MESH_OUT_FILENAME)); ; sys.stdout.write(""\nMesh a",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:717,Deployability,release,release,717,"@monika1387 I suggest you to switch to the INRIA pyAMG to do your mesh adaptation (https://pyamg.saclay.inria.fr). There are a couple of elements you need to keep in mind to use it: 1) at present, it seems to work with a specific branch of SU2 (see the link in the pyAMG website), 2) while working on it with INRIA people we found an issue with a file named ""amg.py"" which resides in the SU2_PY/SU2/run folder. I suggest you to replace that with the one attached here.; Please let me know if this works out for you. #!/usr/bin/env python. ## \file adjoint.py; # \brief python package for running mesh adaptation using the AMG Inria library; # \author Victorien Menier; # \version 6.0.0 ""Falcon""; #; # The current SU2 release has been coordinated by the; # SU2 International Developers Society <www.su2devsociety.org>; # with selected contributions from the open-source community.; #; # The main research teams contributing to the current release are:; # - Prof. Juan J. Alonso's group at Stanford University.; # - Prof. Piero Colonna's group at Delft University of Technology.; # - Prof. Nicolas R. Gauger's group at Kaiserslautern University of Technology.; # - Prof. Alberto Guardone's group at Polytechnic University of Milan.; # - Prof. Rafael Palacios' group at Imperial College London.; # - Prof. Vincent Terrapon's group at the University of Liege.; # - Prof. Edwin van der Weide's group at the University of Twente.; # - Lab. of New Concepts in Aeronautics at Tech. Institute of Aeronautics.; #; # Copyright 2012-2018, Francisco D. Palacios, Thomas D. Economon,; # Tim Albring, and the SU2 contributors.; #; # SU2 is free software; you can redistribute it and/or; # modify it under the terms of the GNU Lesser General Public; # License as published by the Free Software Foundation; either; # version 2.1 of the License, or (at your option) any later version.; #; # SU2 is distributed in the hope that it will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERC",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:938,Deployability,release,release,938,"@monika1387 I suggest you to switch to the INRIA pyAMG to do your mesh adaptation (https://pyamg.saclay.inria.fr). There are a couple of elements you need to keep in mind to use it: 1) at present, it seems to work with a specific branch of SU2 (see the link in the pyAMG website), 2) while working on it with INRIA people we found an issue with a file named ""amg.py"" which resides in the SU2_PY/SU2/run folder. I suggest you to replace that with the one attached here.; Please let me know if this works out for you. #!/usr/bin/env python. ## \file adjoint.py; # \brief python package for running mesh adaptation using the AMG Inria library; # \author Victorien Menier; # \version 6.0.0 ""Falcon""; #; # The current SU2 release has been coordinated by the; # SU2 International Developers Society <www.su2devsociety.org>; # with selected contributions from the open-source community.; #; # The main research teams contributing to the current release are:; # - Prof. Juan J. Alonso's group at Stanford University.; # - Prof. Piero Colonna's group at Delft University of Technology.; # - Prof. Nicolas R. Gauger's group at Kaiserslautern University of Technology.; # - Prof. Alberto Guardone's group at Polytechnic University of Milan.; # - Prof. Rafael Palacios' group at Imperial College London.; # - Prof. Vincent Terrapon's group at the University of Liege.; # - Prof. Edwin van der Weide's group at the University of Twente.; # - Lab. of New Concepts in Aeronautics at Tech. Institute of Aeronautics.; #; # Copyright 2012-2018, Francisco D. Palacios, Thomas D. Economon,; # Tim Albring, and the SU2 contributors.; #; # SU2 is free software; you can redistribute it and/or; # modify it under the terms of the GNU Lesser General Public; # License as published by the Free Software Foundation; either; # version 2.1 of the License, or (at your option) any later version.; #; # SU2 is distributed in the hope that it will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERC",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:71,Energy Efficiency,adapt,adaptation,71,"@monika1387 I suggest you to switch to the INRIA pyAMG to do your mesh adaptation (https://pyamg.saclay.inria.fr). There are a couple of elements you need to keep in mind to use it: 1) at present, it seems to work with a specific branch of SU2 (see the link in the pyAMG website), 2) while working on it with INRIA people we found an issue with a file named ""amg.py"" which resides in the SU2_PY/SU2/run folder. I suggest you to replace that with the one attached here.; Please let me know if this works out for you. #!/usr/bin/env python. ## \file adjoint.py; # \brief python package for running mesh adaptation using the AMG Inria library; # \author Victorien Menier; # \version 6.0.0 ""Falcon""; #; # The current SU2 release has been coordinated by the; # SU2 International Developers Society <www.su2devsociety.org>; # with selected contributions from the open-source community.; #; # The main research teams contributing to the current release are:; # - Prof. Juan J. Alonso's group at Stanford University.; # - Prof. Piero Colonna's group at Delft University of Technology.; # - Prof. Nicolas R. Gauger's group at Kaiserslautern University of Technology.; # - Prof. Alberto Guardone's group at Polytechnic University of Milan.; # - Prof. Rafael Palacios' group at Imperial College London.; # - Prof. Vincent Terrapon's group at the University of Liege.; # - Prof. Edwin van der Weide's group at the University of Twente.; # - Lab. of New Concepts in Aeronautics at Tech. Institute of Aeronautics.; #; # Copyright 2012-2018, Francisco D. Palacios, Thomas D. Economon,; # Tim Albring, and the SU2 contributors.; #; # SU2 is free software; you can redistribute it and/or; # modify it under the terms of the GNU Lesser General Public; # License as published by the Free Software Foundation; either; # version 2.1 of the License, or (at your option) any later version.; #; # SU2 is distributed in the hope that it will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERC",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:601,Energy Efficiency,adapt,adaptation,601,"@monika1387 I suggest you to switch to the INRIA pyAMG to do your mesh adaptation (https://pyamg.saclay.inria.fr). There are a couple of elements you need to keep in mind to use it: 1) at present, it seems to work with a specific branch of SU2 (see the link in the pyAMG website), 2) while working on it with INRIA people we found an issue with a file named ""amg.py"" which resides in the SU2_PY/SU2/run folder. I suggest you to replace that with the one attached here.; Please let me know if this works out for you. #!/usr/bin/env python. ## \file adjoint.py; # \brief python package for running mesh adaptation using the AMG Inria library; # \author Victorien Menier; # \version 6.0.0 ""Falcon""; #; # The current SU2 release has been coordinated by the; # SU2 International Developers Society <www.su2devsociety.org>; # with selected contributions from the open-source community.; #; # The main research teams contributing to the current release are:; # - Prof. Juan J. Alonso's group at Stanford University.; # - Prof. Piero Colonna's group at Delft University of Technology.; # - Prof. Nicolas R. Gauger's group at Kaiserslautern University of Technology.; # - Prof. Alberto Guardone's group at Polytechnic University of Milan.; # - Prof. Rafael Palacios' group at Imperial College London.; # - Prof. Vincent Terrapon's group at the University of Liege.; # - Prof. Edwin van der Weide's group at the University of Twente.; # - Lab. of New Concepts in Aeronautics at Tech. Institute of Aeronautics.; #; # Copyright 2012-2018, Francisco D. Palacios, Thomas D. Economon,; # Tim Albring, and the SU2 contributors.; #; # SU2 is free software; you can redistribute it and/or; # modify it under the terms of the GNU Lesser General Public; # License as published by the Free Software Foundation; either; # version 2.1 of the License, or (at your option) any later version.; #; # SU2 is distributed in the hope that it will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERC",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:2597,Energy Efficiency,Adapt,Adaptation,2597,"will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsisten",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:2705,Energy Efficiency,adapt,adaptation,2705,"will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsisten",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3796,Energy Efficiency,adapt,adaptation,3796,"UCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.R",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3807,Energy Efficiency,sensor,sensor,3807,"UCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.R",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:4234,Energy Efficiency,adapt,adaptation,4234,"# Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7901,Energy Efficiency,adapt,adaptation,7901,"sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:8805,Energy Efficiency,sensor,sensor,8805,"th.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:8815,Energy Efficiency,sensor,sensor,8815,"th.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:8910,Energy Efficiency,sensor,sensor,8910,"ss.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:9018,Energy Efficiency,sensor,sensor,9018,"s[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:9384,Energy Efficiency,adapt,adaptation,9384,"amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Genera",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10189,Energy Efficiency,sensor,sensor,10189,"; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solutio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10214,Energy Efficiency,adapt,adaptation,10214,"; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solutio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10291,Energy Efficiency,sensor,sensor,10291,"n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_c",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10362,Energy Efficiency,adapt,adapted,10362,"esh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:12755,Energy Efficiency,adapt,adaptation,12755,"new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.\n""; ; ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; ; #--- Print convergence history; ; plot_format = config_cfd['OUTPUT_FORMAT']; plot_extension = su2io.get_extension(plot_format); history_filename = config_cfd['CONV_FILENAME'] + plot_extension; ; history = su2io.read_history(history_filename); ; res_flow = history['Res_Flow[0]']; res_cvg = max(res_flow)-min(res_flow); ; del history; ; sys.stdout.write(' %s CFD done. Residual convergence %.2lf orders of magnitude\n' % (pad_nul, res_cvg)); ; ; to_remove = [""current.itp.solb"", config_amg['mesh_in'], config_amg['mesh_out'], config_amg['sol_in'],config_amg['itp_sol_in']]; for fil in to_remove:; if os.path.exists(fil) : os.remove(fil); ; global_iter += 1; ; os.rename(current_solution,os.path.join(cwd,config.RESTART_FLOW_FILENAME)); os.rename(current_mesh,os.path.join(cwd,config.MESH_OUT_FILENAME)); ; sys.stdout.write(""\nMesh adaptation successfully ended. Results files:\n""); sys.stdout.write(""%s\n%s\n\n"" % (config.MESH_OUT_FILENAME,config.RESTART_FLOW_FILENAME))",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:2379,Integrability,interface,interface,2379,"er Weide's group at the University of Twente.; # - Lab. of New Concepts in Aeronautics at Tech. Institute of Aeronautics.; #; # Copyright 2012-2018, Francisco D. Palacios, Thomas D. Economon,; # Tim Albring, and the SU2 contributors.; #; # SU2 is free software; you can redistribute it and/or; # modify it under the terms of the GNU Lesser General Public; # License as published by the Free Software Foundation; either; # version 2.1 of the License, or (at your option) any later version.; #; # SU2 is distributed in the hope that it will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed me",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3978,Integrability,interface,interface,3978,"UCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.R",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:8487,Integrability,interface,interface,8487,"if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n#",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10080,Integrability,interface,interface,10080,"fig_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdou",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:71,Modifiability,adapt,adaptation,71,"@monika1387 I suggest you to switch to the INRIA pyAMG to do your mesh adaptation (https://pyamg.saclay.inria.fr). There are a couple of elements you need to keep in mind to use it: 1) at present, it seems to work with a specific branch of SU2 (see the link in the pyAMG website), 2) while working on it with INRIA people we found an issue with a file named ""amg.py"" which resides in the SU2_PY/SU2/run folder. I suggest you to replace that with the one attached here.; Please let me know if this works out for you. #!/usr/bin/env python. ## \file adjoint.py; # \brief python package for running mesh adaptation using the AMG Inria library; # \author Victorien Menier; # \version 6.0.0 ""Falcon""; #; # The current SU2 release has been coordinated by the; # SU2 International Developers Society <www.su2devsociety.org>; # with selected contributions from the open-source community.; #; # The main research teams contributing to the current release are:; # - Prof. Juan J. Alonso's group at Stanford University.; # - Prof. Piero Colonna's group at Delft University of Technology.; # - Prof. Nicolas R. Gauger's group at Kaiserslautern University of Technology.; # - Prof. Alberto Guardone's group at Polytechnic University of Milan.; # - Prof. Rafael Palacios' group at Imperial College London.; # - Prof. Vincent Terrapon's group at the University of Liege.; # - Prof. Edwin van der Weide's group at the University of Twente.; # - Lab. of New Concepts in Aeronautics at Tech. Institute of Aeronautics.; #; # Copyright 2012-2018, Francisco D. Palacios, Thomas D. Economon,; # Tim Albring, and the SU2 contributors.; #; # SU2 is free software; you can redistribute it and/or; # modify it under the terms of the GNU Lesser General Public; # License as published by the Free Software Foundation; either; # version 2.1 of the License, or (at your option) any later version.; #; # SU2 is distributed in the hope that it will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERC",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:601,Modifiability,adapt,adaptation,601,"@monika1387 I suggest you to switch to the INRIA pyAMG to do your mesh adaptation (https://pyamg.saclay.inria.fr). There are a couple of elements you need to keep in mind to use it: 1) at present, it seems to work with a specific branch of SU2 (see the link in the pyAMG website), 2) while working on it with INRIA people we found an issue with a file named ""amg.py"" which resides in the SU2_PY/SU2/run folder. I suggest you to replace that with the one attached here.; Please let me know if this works out for you. #!/usr/bin/env python. ## \file adjoint.py; # \brief python package for running mesh adaptation using the AMG Inria library; # \author Victorien Menier; # \version 6.0.0 ""Falcon""; #; # The current SU2 release has been coordinated by the; # SU2 International Developers Society <www.su2devsociety.org>; # with selected contributions from the open-source community.; #; # The main research teams contributing to the current release are:; # - Prof. Juan J. Alonso's group at Stanford University.; # - Prof. Piero Colonna's group at Delft University of Technology.; # - Prof. Nicolas R. Gauger's group at Kaiserslautern University of Technology.; # - Prof. Alberto Guardone's group at Polytechnic University of Milan.; # - Prof. Rafael Palacios' group at Imperial College London.; # - Prof. Vincent Terrapon's group at the University of Liege.; # - Prof. Edwin van der Weide's group at the University of Twente.; # - Lab. of New Concepts in Aeronautics at Tech. Institute of Aeronautics.; #; # Copyright 2012-2018, Francisco D. Palacios, Thomas D. Economon,; # Tim Albring, and the SU2 contributors.; #; # SU2 is free software; you can redistribute it and/or; # modify it under the terms of the GNU Lesser General Public; # License as published by the Free Software Foundation; either; # version 2.1 of the License, or (at your option) any later version.; #; # SU2 is distributed in the hope that it will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERC",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:2531,Modifiability,config,config,2531," Palacios, Thomas D. Economon,; # Tim Albring, and the SU2 contributors.; #; # SU2 is free software; you can redistribute it and/or; # modify it under the terms of the GNU Lesser General Public; # License as published by the Free Software Foundation; either; # version 2.1 of the License, or (at your option) any later version.; #; # SU2 is distributed in the hope that it will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:2597,Modifiability,Adapt,Adaptation,2597,"will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsisten",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:2674,Modifiability,config,config,2674,"will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsisten",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:2705,Modifiability,adapt,adaptation,2705,"will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsisten",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3051,Modifiability,config,config,3051,"will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsisten",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3177,Modifiability,config,config,3177,"will be useful,; # but WITHOUT ANY WARRANTY; without even the implied warranty of; # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; # Lesser General Public License for more details.; #; # You should have received a copy of the GNU Lesser General Public; # License along with SU2. If not, see <http://www.gnu.org/licenses/>. import os, sys, shutil, copy, time; import numpy as np. from .. import io as su2io; from .. import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsisten",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3298,Modifiability,config,config,3298," import amginria as su2amg; from interface import CFD as SU2_CFD. try :; import pyamg ; except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(ada",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3428,Modifiability,config,config,3428,"except:; sys.stderr.write(""## ERROR : Unable to import pyamg module.\n""); sys.exit(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3474,Modifiability,config,config,3474,"t(1). def amg ( config , kind='' ):; ; sys.stdout.write(""SU2-AMG Anisotropic Mesh Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3588,Modifiability,config,config,3588,"h Adaptation\n""); ; #--- TODO: Check pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FI",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3638,Modifiability,config,config,3638,"k pyamg version compatibility; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3661,Modifiability,config,config,3661,"ty; ; #--- Check config options related to mesh adaptation; ; adap_options = ['ADAP_SIZES', 'ADAP_SUBITE', 'ADAP_SENSOR', \; 'ADAP_BACK', 'ADAP_HMAX', 'ADAP_HMIN', 'ADAP_HGRAD', 'ADAP_RESIDUAL_REDUCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:3796,Modifiability,adapt,adaptation,3796,"UCTION', 'ADAP_EXT_ITER', 'ADAP_SOURCE','ADAP_PYTHON']; required_options = ['ADAP_SIZES', 'ADAP_SUBITE', \; 'ADAP_SENSOR', 'MESH_FILENAME', 'RESTART_SOL', 'MESH_OUT_FILENAME']; ; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.R",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:4053,Modifiability,config,config,4053,"ions):; err = '\n\n## ERROR : Missing options: \n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; # Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:4234,Modifiability,adapt,adaptation,4234,"# Print adap options; sys.stdout.write(su2amg.print_adap_options(config, adap_options)); ; #--- How many iterative loops? Using what prescribed mesh sizes? ; ; mesh_sizes = su2amg.get_mesh_sizes(config); sub_iter = su2amg.get_sub_iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:4465,Modifiability,config,config,4465,"iterations(config); ; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:4488,Modifiability,config,config,4488,"; # solver iterations/ residual reduction param for each size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:4540,Modifiability,config,config,4540,"h size level; adap_ext_iter = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout =",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:4572,Modifiability,config,config,4572,"er = su2amg.get_ext_iter(config); adap_res = su2amg.get_residual_reduction(config). adap_sensor = config.ADAP_SENSOR; sensor_avail = ['MACH', 'PRES', 'MACH_PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:4701,Modifiability,config,config,4701,"PRES']; ; if adap_sensor not in sensor_avail:; raise RuntimeError , 'Unknown adaptation sensor (ADAP_SENSOR option)\n'; ; if len(mesh_sizes) != len(sub_iter):; raise RuntimeError , 'Inconsistent number of mesh sizes and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:4957,Modifiability,config,config,4957,"s and sub-iterations'; ; #--- Use the python interface to amg, or the executable?; ; amg_python = su2amg.get_python_amg(config); ; #--- Change current directory; ; warn = False; adap_dir = './ADAP'; cwd = os.getcwd(); ; if os.path.exists(adap_dir):; sys.stdout.write('./ADAP exists. Removing old mesh adaptation in 10s.\n'); sys.stdout.flush(); if warn : time.sleep(10); shutil.rmtree(adap_dir); ; os.makedirs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; curr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:5328,Modifiability,config,config,5328,"rs(adap_dir); os.chdir(adap_dir); sys.stdout.write('The %s folder was deleted\n' % adap_dir); ; os.symlink(os.path.join(cwd, config.MESH_FILENAME), config.MESH_FILENAME); os.symlink(os.path.join(cwd, config.SOLUTION_FLOW_FILENAME), config.SOLUTION_FLOW_FILENAME); ; #--- Compute initial solution if needed, else link current files; ; config_cfd = copy.deepcopy(config); for opt in adap_options:; config_cfd.pop(opt, None); config_cfd.LOW_MEMORY_OUTPUT = ""NO""; ; config_cfd.WRT_BINARY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:5709,Modifiability,config,config,5709,"RY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'curre",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:5873,Modifiability,config,config,5873,"RY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'curre",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:5944,Modifiability,config,config,5944,"RY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'curre",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:5988,Modifiability,config,config,5988,"RY_RESTART = ""NO""; #config_cfd.READ_BINARY_RESTART = ""NO""; ; current_mesh = ""Initial_mesh""; current_solution = ""Initial_solution""; ; if config['RESTART_SOL'] == 'NO':; ; stdout_hdl = open('ini.stdout','w') # new targets; stderr_hdl = open('ini.stderr','w'); ; success = False; val_out = [False]; ; sys.stdout.write('Running initial CFD solution.\n'); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_mesh = config['MESH_FILENAME']; current_solution = ""ini_restart_flow.dat""; ; config_cfd.CONV_FILENAME = ""ini_history""; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; SU2_CFD(config_cfd); ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'curre",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:6629,Modifiability,config,config,6629,".stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:6679,Modifiability,config,config,6679,".stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:6728,Modifiability,config,config,6728,".stderr = sav_stderr; ; else:; required_options=['SOLUTION_FLOW_FILENAME']; if not all (opt in config for opt in required_options):; err = '\n\n## ERROR : RESTART_SOL is set to YES, but the solution is missing:\n'; for opt in required_options:; if not opt in config:; err += opt + '\n'; raise RuntimeError , err; ; current_mesh = config['MESH_FILENAME']; current_solution = config['SOLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7008,Modifiability,config,config,7008,"OLUTION_FLOW_FILENAME']; ; sys.stdout.write('Initial CFD solution is provided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7060,Modifiability,config,config,7060,"ovided.\n'); ; #--- Check existence of initial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d -",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7112,Modifiability,config,config,7112,"tial mesh, solution; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7131,Modifiability,config,config,7131,"n; ; required_files = [current_mesh,current_solution]; ; if not all (os.path.exists(fil) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7183,Modifiability,config,config,7183,"l) for fil in required_files):; err = '\n\n## ERROR : Can\'t find:\n'; for fil in required_files:; if not os.path.exists(fil):; err += fil + '\n'; raise RuntimeError , err; ; #--- Start looping; ; # Get mesh dimension; dim = su2amg.get_su2_dim(current_mesh); if ( dim != 2 and dim != 3 ):; raise RuntimeError , ""Wrong dimension number\n""; ; #--- AMG parameters; ; config_amg = dict(); ; config_amg['hgrad'] = float(config['ADAP_HGRAD']); config_amg['hmax'] = float(config['ADAP_HMAX']); config_amg['hmin'] = float(config['ADAP_HMIN']); config_amg['mesh_in'] = 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7768,Modifiability,config,config,7768," 'current.meshb'; config_amg['mesh_out'] = 'current.new.meshb'; config_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7822,Modifiability,config,config,7822,"g_amg['metric_in'] = ''; config_amg['sol_in'] = 'current_sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sens",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:7901,Modifiability,adapt,adaptation,7901,"sensor.solb'; config_amg['itp_sol_in'] = 'current.solb'; config_amg['adap_source'] = ''; ; if 'ADAP_BACK' in config:; config_amg['adap_back'] = os.path.join(cwd,config['ADAP_BACK']); #os.symlink(os.path.join(cwd, config.ADAP_BACK), config.ADAP_BACK); else:; config_amg['adap_back'] = config['MESH_FILENAME']; ; print ""config_amg : "" + config_amg['adap_back']; back_name, back_extension = os.path.splitext(config_amg['adap_back']); ; if not os.path.exists(config_amg['adap_back']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:9384,Modifiability,adapt,adaptation,9384,"amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Genera",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10214,Modifiability,adapt,adaptation,10214,"; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solutio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10362,Modifiability,adapt,adapted,10362,"esh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:12628,Modifiability,config,config,12628,"new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.\n""; ; ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; ; #--- Print convergence history; ; plot_format = config_cfd['OUTPUT_FORMAT']; plot_extension = su2io.get_extension(plot_format); history_filename = config_cfd['CONV_FILENAME'] + plot_extension; ; history = su2io.read_history(history_filename); ; res_flow = history['Res_Flow[0]']; res_cvg = max(res_flow)-min(res_flow); ; del history; ; sys.stdout.write(' %s CFD done. Residual convergence %.2lf orders of magnitude\n' % (pad_nul, res_cvg)); ; ; to_remove = [""current.itp.solb"", config_amg['mesh_in'], config_amg['mesh_out'], config_amg['sol_in'],config_amg['itp_sol_in']]; for fil in to_remove:; if os.path.exists(fil) : os.remove(fil); ; global_iter += 1; ; os.rename(current_solution,os.path.join(cwd,config.RESTART_FLOW_FILENAME)); os.rename(current_mesh,os.path.join(cwd,config.MESH_OUT_FILENAME)); ; sys.stdout.write(""\nMesh adaptation successfully ended. Results files:\n""); sys.stdout.write(""%s\n%s\n\n"" % (config.MESH_OUT_FILENAME,config.RESTART_FLOW_FILENAME))",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:12700,Modifiability,config,config,12700,"new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.\n""; ; ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; ; #--- Print convergence history; ; plot_format = config_cfd['OUTPUT_FORMAT']; plot_extension = su2io.get_extension(plot_format); history_filename = config_cfd['CONV_FILENAME'] + plot_extension; ; history = su2io.read_history(history_filename); ; res_flow = history['Res_Flow[0]']; res_cvg = max(res_flow)-min(res_flow); ; del history; ; sys.stdout.write(' %s CFD done. Residual convergence %.2lf orders of magnitude\n' % (pad_nul, res_cvg)); ; ; to_remove = [""current.itp.solb"", config_amg['mesh_in'], config_amg['mesh_out'], config_amg['sol_in'],config_amg['itp_sol_in']]; for fil in to_remove:; if os.path.exists(fil) : os.remove(fil); ; global_iter += 1; ; os.rename(current_solution,os.path.join(cwd,config.RESTART_FLOW_FILENAME)); os.rename(current_mesh,os.path.join(cwd,config.MESH_OUT_FILENAME)); ; sys.stdout.write(""\nMesh adaptation successfully ended. Results files:\n""); sys.stdout.write(""%s\n%s\n\n"" % (config.MESH_OUT_FILENAME,config.RESTART_FLOW_FILENAME))",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:12755,Modifiability,adapt,adaptation,12755,"new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.\n""; ; ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; ; #--- Print convergence history; ; plot_format = config_cfd['OUTPUT_FORMAT']; plot_extension = su2io.get_extension(plot_format); history_filename = config_cfd['CONV_FILENAME'] + plot_extension; ; history = su2io.read_history(history_filename); ; res_flow = history['Res_Flow[0]']; res_cvg = max(res_flow)-min(res_flow); ; del history; ; sys.stdout.write(' %s CFD done. Residual convergence %.2lf orders of magnitude\n' % (pad_nul, res_cvg)); ; ; to_remove = [""current.itp.solb"", config_amg['mesh_in'], config_amg['mesh_out'], config_amg['sol_in'],config_amg['itp_sol_in']]; for fil in to_remove:; if os.path.exists(fil) : os.remove(fil); ; global_iter += 1; ; os.rename(current_solution,os.path.join(cwd,config.RESTART_FLOW_FILENAME)); os.rename(current_mesh,os.path.join(cwd,config.MESH_OUT_FILENAME)); ; sys.stdout.write(""\nMesh adaptation successfully ended. Results files:\n""); sys.stdout.write(""%s\n%s\n\n"" % (config.MESH_OUT_FILENAME,config.RESTART_FLOW_FILENAME))",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:12839,Modifiability,config,config,12839,"new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.\n""; ; ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; ; #--- Print convergence history; ; plot_format = config_cfd['OUTPUT_FORMAT']; plot_extension = su2io.get_extension(plot_format); history_filename = config_cfd['CONV_FILENAME'] + plot_extension; ; history = su2io.read_history(history_filename); ; res_flow = history['Res_Flow[0]']; res_cvg = max(res_flow)-min(res_flow); ; del history; ; sys.stdout.write(' %s CFD done. Residual convergence %.2lf orders of magnitude\n' % (pad_nul, res_cvg)); ; ; to_remove = [""current.itp.solb"", config_amg['mesh_in'], config_amg['mesh_out'], config_amg['sol_in'],config_amg['itp_sol_in']]; for fil in to_remove:; if os.path.exists(fil) : os.remove(fil); ; global_iter += 1; ; os.rename(current_solution,os.path.join(cwd,config.RESTART_FLOW_FILENAME)); os.rename(current_mesh,os.path.join(cwd,config.MESH_OUT_FILENAME)); ; sys.stdout.write(""\nMesh adaptation successfully ended. Results files:\n""); sys.stdout.write(""%s\n%s\n\n"" % (config.MESH_OUT_FILENAME,config.RESTART_FLOW_FILENAME))",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:12864,Modifiability,config,config,12864,"new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.\n""; ; ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_stderr; ; ; #--- Print convergence history; ; plot_format = config_cfd['OUTPUT_FORMAT']; plot_extension = su2io.get_extension(plot_format); history_filename = config_cfd['CONV_FILENAME'] + plot_extension; ; history = su2io.read_history(history_filename); ; res_flow = history['Res_Flow[0]']; res_cvg = max(res_flow)-min(res_flow); ; del history; ; sys.stdout.write(' %s CFD done. Residual convergence %.2lf orders of magnitude\n' % (pad_nul, res_cvg)); ; ; to_remove = [""current.itp.solb"", config_amg['mesh_in'], config_amg['mesh_out'], config_amg['sol_in'],config_amg['itp_sol_in']]; for fil in to_remove:; if os.path.exists(fil) : os.remove(fil); ; global_iter += 1; ; os.rename(current_solution,os.path.join(cwd,config.RESTART_FLOW_FILENAME)); os.rename(current_mesh,os.path.join(cwd,config.MESH_OUT_FILENAME)); ; sys.stdout.write(""\nMesh adaptation successfully ended. Results files:\n""); sys.stdout.write(""%s\n%s\n\n"" % (config.MESH_OUT_FILENAME,config.RESTART_FLOW_FILENAME))",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:8379,Performance,Load,Load,8379,"ck']):; raise RuntimeError , ""\n\n##ERROR : Can't find back mesh: %s.\n\n"" % config_amg['adap_back']; ; if back_extension == "".su2"":; ; #pyamg.su2_to_libmeshb(config_amg['adap_back'], """", ""amg_back""); print ""skipping back mesh ...""; #import _amgio as amgio; #amgio.py_ConvertSU2toInria(config_amg['adap_back'], """", ""amg_back""); #config_amg['adap_back'] = ""amg_back.meshb""; ; if 'ADAP_SOURCE' in config:; config_amg['adap_source'] = os.path.join(cwd,config['ADAP_SOURCE']); ; global_iter = 0; ; sys.stdout.write(""\nStarting mesh adaptation process.\n""); ; for iSiz in range(len(mesh_sizes)):; ; mesh_size = int(mesh_sizes[iSiz]); nSub = int(sub_iter[iSiz]); ; sys.stdout.write(""\nIteration %d/%d - Mesh size coefficient %.1lf\n"" % (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERR",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10100,Performance,Load,Load,10100,"fig_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdou",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:9079,Testability,Log,Log,9079,"% (iSiz+1, len(mesh_sizes), mesh_size)); ; for iSub in range(nSub):; ; config_amg['size'] = mesh_size; config_amg['amg_log'] = 'ite%d.amg.stdout' % (global_iter); ; # Prints; pad_cpt = (""(%d/%d)"" % (iSub+1, nSub)).ljust(9); pad_nul = """".ljust(9); ; if not amg_python : ; ; #--- Load su2 mesh ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- If not using the amg python interface, convert the mesh and make system call; ; su2amg.write_mesh(""current.meshb"", ""current.solb"", mesh); ; if not os.path.exists(""current.solb""):; raise RuntimeError , ""\n##ERROR : Can't find solution.\n""; if not os.path.exists(""current.meshb""):; raise RuntimeError , ""\n##ERROR : Can't find mesh.\n""; ; #--- Get sensor; ; sensor = su2amg.create_sensor(mesh, adap_sensor); su2amg.write_solution(""current_sensor.solb"", sensor); ; if not os.path.exists(""current_sensor.solb""):; raise RuntimeError , ""\n##ERROR : Can't find adap sensor.\n""; ; #--- Run amg; ; sys.stdout.write(""Running amg. Log : %s\n"" % config_amg['amg_log']); ; if os.path.exists(""current.itp.solb""):; os.remove(""current.itp.solb""); ; try :; su2amg.amg_call(config_amg); except:; raise RuntimeError , ""\n##ERROR : Call to AMG failed.\n""; ; if not os.path.exists(config_amg['mesh_out']):; raise RuntimeError , ""\n##ERROR : Mesh adaptation failed.\n""; ; if not os.path.exists(""current.itp.solb""):; raise RuntimeError , ""\n##ERROR AMG: Solution interpolation failed.\n"" ; ; #--- Convert output from Inria mesh format to su2; # Deal with markers; ; save_markers = mesh['markers']; del mesh; ; # Read Inria mesh; mesh = su2amg.read_mesh(config_amg['mesh_out'], ""current.itp.solb""); mesh['markers'] = save_markers; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Lo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10823,Testability,log,log,10823,""" % global_iter; current_solution = ""ite%d.dat"" % global_iter ; ; su2amg.write_mesh(current_mesh, current_solution, mesh); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10883,Testability,log,log,10883,"); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.\n""; ; ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504636643:10936,Testability,log,log,10936,"); ; if not os.path.exists(current_mesh) or not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : Conversion to SU2 failed.\n"". else : # Use pyAmg interface; ; ; #--- Load su2 mesh ; ; mesh = su2amg.read_mesh(current_mesh, current_solution); ; #--- Create sensor used to drive the adaptation; ; sensor_wrap = su2amg.create_sensor(mesh, adap_sensor); ; mesh['sensor'] = sensor_wrap['solution']; ; sys.stdout.write(' %s Generating adapted mesh using AMG\n' % pad_cpt); ; mesh_new = su2amg.amg_call_python(mesh, config_amg); ; #--- print mesh size; ; sys.stdout.write(' %s AMG done: %s\n' % (pad_nul, su2amg.return_mesh_size(mesh_new))); ; mesh_new['markers'] = mesh['markers']; mesh_new['dimension'] = mesh['dimension']; ; current_mesh = ""ite%d.su2"" % global_iter; current_solution = ""ite%d.dat"" % global_iter; ; su2amg.write_mesh(current_mesh, current_solution, mesh_new); ; #--- Run su2; ; log = 'ite%d.SU2'%global_iter; stdout_hdl = open('%sstdout'%log,'w') # new targets; stderr_hdl = open('%sstderr'%log,'w'); ; success = False; val_out = [False]; ; sys.stdout.write(' %s Running CFD\n' % pad_nul); ; try: # run with redirected outputs; ; sav_stdout, sys.stdout = sys.stdout, stdout_hdl ; sav_stderr, sys.stderr = sys.stderr, stderr_hdl; ; current_solution_ini = ""ite%d_ini.dat"" % global_iter; os.rename(current_solution, current_solution_ini); ; config_cfd.MESH_FILENAME = current_mesh; config_cfd.CONV_FILENAME = ""ite%d_history"" % global_iter; config_cfd.SOLUTION_FLOW_FILENAME = current_solution_ini; config_cfd.RESTART_FLOW_FILENAME = current_solution; ; config_cfd.RESIDUAL_REDUCTION = float(adap_res[iSiz]); config_cfd.EXT_ITER = int(adap_ext_iter[iSiz]); ; config_cfd.WRT_BINARY_RESTART = ""NO""; config_cfd.READ_BINARY_RESTART = ""NO""; ; SU2_CFD(config_cfd); ; if not os.path.exists(current_solution) :; raise RuntimeError , ""\n##ERROR : SU2_CFD Failed.\n""; ; ; except:; sys.stdout = sav_stdout; sys.stderr = sav_stderr; raise; ; sys.stdout = sav_stdout; sys.stderr = sav_",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504636643
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:902,Deployability,update,updated,902,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:268,Energy Efficiency,adapt,adaptation,268,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:671,Energy Efficiency,adapt,adapted,671,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1169,Energy Efficiency,adapt,adaptive,1169,"date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADA",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1299,Energy Efficiency,adapt,adaptations,1299,"ed) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/599",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1329,Energy Efficiency,adapt,adaptive,1329,"ed) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/599",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1388,Energy Efficiency,adapt,adaptive,1388,"it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/59965706-940fa700-94c6-11e9-811c-4379694f0f7b.png); ![sol](https://user-images.githubusercontent.com/19416354/59965707-940fa700-94c6-11e9-9e1a-e0ae6854d412.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1567,Energy Efficiency,adapt,adaptive,1567,"it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/59965706-940fa700-94c6-11e9-811c-4379694f0f7b.png); ![sol](https://user-images.githubusercontent.com/19416354/59965707-940fa700-94c6-11e9-9e1a-e0ae6854d412.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1686,Energy Efficiency,adapt,adaptive,1686,"it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/59965706-940fa700-94c6-11e9-811c-4379694f0f7b.png); ![sol](https://user-images.githubusercontent.com/19416354/59965707-940fa700-94c6-11e9-9e1a-e0ae6854d412.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:957,Integrability,interface,interface,957,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:268,Modifiability,adapt,adaptation,268,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:531,Modifiability,extend,extended,531,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:671,Modifiability,adapt,adapted,671,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1169,Modifiability,adapt,adaptive,1169,"date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADA",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1299,Modifiability,adapt,adaptations,1299,"ed) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/599",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1329,Modifiability,adapt,adaptive,1329,"ed) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/599",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1388,Modifiability,adapt,adaptive,1388,"it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/59965706-940fa700-94c6-11e9-811c-4379694f0f7b.png); ![sol](https://user-images.githubusercontent.com/19416354/59965707-940fa700-94c6-11e9-9e1a-e0ae6854d412.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1567,Modifiability,adapt,adaptive,1567,"it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/59965706-940fa700-94c6-11e9-811c-4379694f0f7b.png); ![sol](https://user-images.githubusercontent.com/19416354/59965707-940fa700-94c6-11e9-9e1a-e0ae6854d412.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1686,Modifiability,adapt,adaptive,1686,"it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/59965706-940fa700-94c6-11e9-811c-4379694f0f7b.png); ![sol](https://user-images.githubusercontent.com/19416354/59965707-940fa700-94c6-11e9-9e1a-e0ae6854d412.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:1311,Performance,perform,performed,1311,"ed) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:; ADAP_SIZES= (12800, 19200, 25600); ADAP_SUBITE= (2, 2, 2); ADAP_EXT_ITER= (9999, 9999, 9999); ADAP_RESIDUAL_REDUCTION= (6, 6, 6); ADAP_SENSOR= GOAL; ADAP_HMAX= 10.0; ADAP_HMIN= 1e-8; ADAP_HGRAD= 1.5. ![mesh](https://user-images.githubusercontent.com/19416354/599",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:404,Testability,test,tested,404,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:799,Testability,test,testing,799,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-504675574:942,Testability,test,tested,942,"@MarcoFossati @monika1387 @economon I've been working with Adrien Loseille from INRIA to bring Vic's old fork (referenced above) up to date with develop. Check out [feature_adap](https://github.com/su2code/SU2/tree/feature_adap). It uses goal-oriented (adjoint-based) adaptation instead of feature-based (just based on Mach or pressure) that Vic's fork used. Some things to note:; 1. It's currently only tested on Euler (it uses a Hessian of the Euler fluxes so it might work for NS/RANS, but probably not) (@WallyMaier and I also extended it to TNE2 in [feature_amgtne2](https://github.com/su2code/SU2/tree/feature_amgtne2) but the source terms are giving us trouble on adapted meshes); 2. It requires AD support since it uses the discrete adjoint to weigh the Euler flux Hessians; 3. I did all my testing with the AMG executable since pyAMG doesn't have all the features I currently need, but I just updated the branch to use pyAMG. I just tested the new interface with an airfoil and it seems to be working, but there might still be some bugs. You'll want to run mesh_adaptation_amg.py with the following options:; **ADAP_SIZES:** list of mesh complexities for each adaptive level. This is correlated to mesh size, but picking good values requires some playing around; **ADAP_SUBITE:** number of adaptations performed at each adaptive level. If set to (2,3) for example, it will run 2 adaptive iterations to try to reach ADAP_SIZES[0], and 3 iterations to try to reach ADAP_SIZES[1]; **ADAP_EXT_ITER:** number of iterations used by SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_RESIDUAL_REDUCTION:** order of magnitude residual reduction for SU2_CFD and SU2_CFD_AD for each adaptive level; **ADAP_SENSOR:** currently only works for GOAL; **ADAP_HMAX:** maximum cell size (m); **ADAP_HMIN:** minimum cell size (m); **ADAP_HGRAD:** gradation coefficient (>1) used by AMG during mesh smoothing. A larger value corresponds to larger allowed gradient in mesh size. E.g. for the RAE2822 I used:;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-504675574
https://github.com/su2code/SU2/issues/606#issuecomment-505164187:45,Deployability,update,updated,45,"@bmunguia: Great! Is this work planned to be updated in the develop branch at some point? Since you have put in the effort to get it updated, it would be great to get it under regression testing to protect it once you are happy with the changes. Just let us know if there's anything we can do to help coordinate. Sounds like you might already be discussing w/ @MarcoFossati",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505164187
https://github.com/su2code/SU2/issues/606#issuecomment-505164187:133,Deployability,update,updated,133,"@bmunguia: Great! Is this work planned to be updated in the develop branch at some point? Since you have put in the effort to get it updated, it would be great to get it under regression testing to protect it once you are happy with the changes. Just let us know if there's anything we can do to help coordinate. Sounds like you might already be discussing w/ @MarcoFossati",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505164187
https://github.com/su2code/SU2/issues/606#issuecomment-505164187:187,Testability,test,testing,187,"@bmunguia: Great! Is this work planned to be updated in the develop branch at some point? Since you have put in the effort to get it updated, it would be great to get it under regression testing to protect it once you are happy with the changes. Just let us know if there's anything we can do to help coordinate. Sounds like you might already be discussing w/ @MarcoFossati",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505164187
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:78,Energy Efficiency,adapt,adaptivity,78,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:286,Energy Efficiency,adapt,adaptivity,286,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:419,Energy Efficiency,adapt,adaptation,419,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:696,Energy Efficiency,adapt,adaptivity,696,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:767,Energy Efficiency,adapt,adaptation,767,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:78,Modifiability,adapt,adaptivity,78,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:286,Modifiability,adapt,adaptivity,286,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:419,Modifiability,adapt,adaptation,419,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:696,Modifiability,adapt,adaptivity,696,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-505438349:767,Modifiability,adapt,adaptation,767,"@monika1387 There are numerous bugs and difficulties with SU2's in-house mesh adaptivity. Without knowing more specifics about your problem (e.g. seeing your *.cfg file), it's hard to know what the problem is. For example, you should probably *not* be using the `SUPERSONIC_SHOCK` mesh adaptivity option. It seems to be ad-hoc and not generalized to arbitrary shock positions. If you want help with SU2's in-house mesh adaptation, could you post your *.cfg file?. Based on comments by @bmunguia and @MarcoFossati, it seems like you've got a bit of an [X/Y problem](https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem). You could try to fix the problems with SU2's in-house mesh adaptivity. But the bigger question is ""What's the best way to do mesh adaptation in SU2?"" For that, INRIA's AMG library may be the best solution.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-505438349
https://github.com/su2code/SU2/issues/606#issuecomment-578501709:322,Deployability,update,update,322,Hi; I have noticed that the distance function in SU2-6 is based on the distance to the vertices on solid wall which is not accurate for the anisotropic meshes produced by PYAMG for RANS simulations. This seems to be corrected in version SU2-7 but PYAMG currently has interface for only SU2-6 version. Is there gone be any update on the PYAMG side to use version SU2-7?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-578501709
https://github.com/su2code/SU2/issues/606#issuecomment-578501709:267,Integrability,interface,interface,267,Hi; I have noticed that the distance function in SU2-6 is based on the distance to the vertices on solid wall which is not accurate for the anisotropic meshes produced by PYAMG for RANS simulations. This seems to be corrected in version SU2-7 but PYAMG currently has interface for only SU2-6 version. Is there gone be any update on the PYAMG side to use version SU2-7?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-578501709
https://github.com/su2code/SU2/issues/606#issuecomment-578842312:267,Energy Efficiency,adapt,adaptation,267,"Hi @msahinae00,. The branch [feature_adap_flux](https://github.com/su2code/SU2/tree/feature_adap_flux) has the fixed wall distance computations (the branch itself isn't up to date with v7, but I merged in develop way after the wall distance was fixed). However, RANS adaptation is still under development. While I've gotten decent looking meshes, e.g.:; ![vortex](https://user-images.githubusercontent.com/19416354/73195095-1c4fcd80-40e2-11ea-9590-4fbc4baf279d.png); ![Screen Shot 2019-11-04 at 1 36 27 PM](https://user-images.githubusercontent.com/19416354/73195106-2245ae80-40e2-11ea-8e24-38ec76d4cfb4.png); I still haven't properly verified the code. Cheers,; Brian",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-578842312
https://github.com/su2code/SU2/issues/606#issuecomment-578842312:267,Modifiability,adapt,adaptation,267,"Hi @msahinae00,. The branch [feature_adap_flux](https://github.com/su2code/SU2/tree/feature_adap_flux) has the fixed wall distance computations (the branch itself isn't up to date with v7, but I merged in develop way after the wall distance was fixed). However, RANS adaptation is still under development. While I've gotten decent looking meshes, e.g.:; ![vortex](https://user-images.githubusercontent.com/19416354/73195095-1c4fcd80-40e2-11ea-9590-4fbc4baf279d.png); ![Screen Shot 2019-11-04 at 1 36 27 PM](https://user-images.githubusercontent.com/19416354/73195106-2245ae80-40e2-11ea-8e24-38ec76d4cfb4.png); I still haven't properly verified the code. Cheers,; Brian",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-578842312
https://github.com/su2code/SU2/issues/606#issuecomment-579140612:249,Availability,error,error,249,"Hi Brain. I have uploaded the branch but having problem to compile it. I use the following configuration. ./configure --prefix=/home/msahin/SU2 -enable-mpi -enable-metis --with-cxx=mpicxx --enable-PY_WRAPPER CXXFLAGS='-O3'. but having the following error message:. ... ; ...; CXX ../src/linear_algebra/libSU2_a-CPastixWrapper.o; AR libSU2.a; make[1]: Leaving directory `/home/msahin/SU2/Common/lib'; Making all in SU2_PY; make[1]: Entering directory `/home/msahin/SU2/SU2_PY'; make[1]: *** No rule to make target `SU2/amginria/_amgio.so', needed by `all-am'. Stop.; make[1]: Leaving directory `/home/msahin/SU2/SU2_PY'; make: *** [all-recursive] Error 1. Am l missing something in the configuration?. Mehmet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-579140612
https://github.com/su2code/SU2/issues/606#issuecomment-579140612:646,Availability,Error,Error,646,"Hi Brain. I have uploaded the branch but having problem to compile it. I use the following configuration. ./configure --prefix=/home/msahin/SU2 -enable-mpi -enable-metis --with-cxx=mpicxx --enable-PY_WRAPPER CXXFLAGS='-O3'. but having the following error message:. ... ; ...; CXX ../src/linear_algebra/libSU2_a-CPastixWrapper.o; AR libSU2.a; make[1]: Leaving directory `/home/msahin/SU2/Common/lib'; Making all in SU2_PY; make[1]: Entering directory `/home/msahin/SU2/SU2_PY'; make[1]: *** No rule to make target `SU2/amginria/_amgio.so', needed by `all-am'. Stop.; make[1]: Leaving directory `/home/msahin/SU2/SU2_PY'; make: *** [all-recursive] Error 1. Am l missing something in the configuration?. Mehmet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-579140612
https://github.com/su2code/SU2/issues/606#issuecomment-579140612:91,Deployability,configurat,configuration,91,"Hi Brain. I have uploaded the branch but having problem to compile it. I use the following configuration. ./configure --prefix=/home/msahin/SU2 -enable-mpi -enable-metis --with-cxx=mpicxx --enable-PY_WRAPPER CXXFLAGS='-O3'. but having the following error message:. ... ; ...; CXX ../src/linear_algebra/libSU2_a-CPastixWrapper.o; AR libSU2.a; make[1]: Leaving directory `/home/msahin/SU2/Common/lib'; Making all in SU2_PY; make[1]: Entering directory `/home/msahin/SU2/SU2_PY'; make[1]: *** No rule to make target `SU2/amginria/_amgio.so', needed by `all-am'. Stop.; make[1]: Leaving directory `/home/msahin/SU2/SU2_PY'; make: *** [all-recursive] Error 1. Am l missing something in the configuration?. Mehmet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-579140612
https://github.com/su2code/SU2/issues/606#issuecomment-579140612:685,Deployability,configurat,configuration,685,"Hi Brain. I have uploaded the branch but having problem to compile it. I use the following configuration. ./configure --prefix=/home/msahin/SU2 -enable-mpi -enable-metis --with-cxx=mpicxx --enable-PY_WRAPPER CXXFLAGS='-O3'. but having the following error message:. ... ; ...; CXX ../src/linear_algebra/libSU2_a-CPastixWrapper.o; AR libSU2.a; make[1]: Leaving directory `/home/msahin/SU2/Common/lib'; Making all in SU2_PY; make[1]: Entering directory `/home/msahin/SU2/SU2_PY'; make[1]: *** No rule to make target `SU2/amginria/_amgio.so', needed by `all-am'. Stop.; make[1]: Leaving directory `/home/msahin/SU2/SU2_PY'; make: *** [all-recursive] Error 1. Am l missing something in the configuration?. Mehmet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-579140612
https://github.com/su2code/SU2/issues/606#issuecomment-579140612:255,Integrability,message,message,255,"Hi Brain. I have uploaded the branch but having problem to compile it. I use the following configuration. ./configure --prefix=/home/msahin/SU2 -enable-mpi -enable-metis --with-cxx=mpicxx --enable-PY_WRAPPER CXXFLAGS='-O3'. but having the following error message:. ... ; ...; CXX ../src/linear_algebra/libSU2_a-CPastixWrapper.o; AR libSU2.a; make[1]: Leaving directory `/home/msahin/SU2/Common/lib'; Making all in SU2_PY; make[1]: Entering directory `/home/msahin/SU2/SU2_PY'; make[1]: *** No rule to make target `SU2/amginria/_amgio.so', needed by `all-am'. Stop.; make[1]: Leaving directory `/home/msahin/SU2/SU2_PY'; make: *** [all-recursive] Error 1. Am l missing something in the configuration?. Mehmet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-579140612
https://github.com/su2code/SU2/issues/606#issuecomment-579140612:91,Modifiability,config,configuration,91,"Hi Brain. I have uploaded the branch but having problem to compile it. I use the following configuration. ./configure --prefix=/home/msahin/SU2 -enable-mpi -enable-metis --with-cxx=mpicxx --enable-PY_WRAPPER CXXFLAGS='-O3'. but having the following error message:. ... ; ...; CXX ../src/linear_algebra/libSU2_a-CPastixWrapper.o; AR libSU2.a; make[1]: Leaving directory `/home/msahin/SU2/Common/lib'; Making all in SU2_PY; make[1]: Entering directory `/home/msahin/SU2/SU2_PY'; make[1]: *** No rule to make target `SU2/amginria/_amgio.so', needed by `all-am'. Stop.; make[1]: Leaving directory `/home/msahin/SU2/SU2_PY'; make: *** [all-recursive] Error 1. Am l missing something in the configuration?. Mehmet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-579140612
https://github.com/su2code/SU2/issues/606#issuecomment-579140612:108,Modifiability,config,configure,108,"Hi Brain. I have uploaded the branch but having problem to compile it. I use the following configuration. ./configure --prefix=/home/msahin/SU2 -enable-mpi -enable-metis --with-cxx=mpicxx --enable-PY_WRAPPER CXXFLAGS='-O3'. but having the following error message:. ... ; ...; CXX ../src/linear_algebra/libSU2_a-CPastixWrapper.o; AR libSU2.a; make[1]: Leaving directory `/home/msahin/SU2/Common/lib'; Making all in SU2_PY; make[1]: Entering directory `/home/msahin/SU2/SU2_PY'; make[1]: *** No rule to make target `SU2/amginria/_amgio.so', needed by `all-am'. Stop.; make[1]: Leaving directory `/home/msahin/SU2/SU2_PY'; make: *** [all-recursive] Error 1. Am l missing something in the configuration?. Mehmet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-579140612
https://github.com/su2code/SU2/issues/606#issuecomment-579140612:685,Modifiability,config,configuration,685,"Hi Brain. I have uploaded the branch but having problem to compile it. I use the following configuration. ./configure --prefix=/home/msahin/SU2 -enable-mpi -enable-metis --with-cxx=mpicxx --enable-PY_WRAPPER CXXFLAGS='-O3'. but having the following error message:. ... ; ...; CXX ../src/linear_algebra/libSU2_a-CPastixWrapper.o; AR libSU2.a; make[1]: Leaving directory `/home/msahin/SU2/Common/lib'; Making all in SU2_PY; make[1]: Entering directory `/home/msahin/SU2/SU2_PY'; make[1]: *** No rule to make target `SU2/amginria/_amgio.so', needed by `all-am'. Stop.; make[1]: Leaving directory `/home/msahin/SU2/SU2_PY'; make: *** [all-recursive] Error 1. Am l missing something in the configuration?. Mehmet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-579140612
https://github.com/su2code/SU2/issues/606#issuecomment-583368735:294,Energy Efficiency,sensor,sensor,294,![Mesh](https://user-images.githubusercontent.com/60317454/74029438-c0c4f000-49bd-11ea-8f83-4a823c7c69d7.jpg); ![Mach](https://user-images.githubusercontent.com/60317454/74029449-c7536780-49bd-11ea-92e6-49c9812e670f.jpg). I have moved PYAMG interface to SU2-6.2.0 and made some changes to Mach sensor on the solid wall.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-583368735
https://github.com/su2code/SU2/issues/606#issuecomment-583368735:241,Integrability,interface,interface,241,![Mesh](https://user-images.githubusercontent.com/60317454/74029438-c0c4f000-49bd-11ea-8f83-4a823c7c69d7.jpg); ![Mach](https://user-images.githubusercontent.com/60317454/74029449-c7536780-49bd-11ea-92e6-49c9812e670f.jpg). I have moved PYAMG interface to SU2-6.2.0 and made some changes to Mach sensor on the solid wall.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-583368735
https://github.com/su2code/SU2/issues/606#issuecomment-650061484:212,Energy Efficiency,adapt,adapted,212,"Hi Brain. One quick question. I have noticed that you have set ADAP_NORM to 1 (Lp=1) in one example for Euler solution. I am using original PYAMG examples and changing "" remesh_options['Lp'] "" does not alter the adapted mesh. The log file always saying LP=2 . Are you using a different PYAMG version? . Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-650061484
https://github.com/su2code/SU2/issues/606#issuecomment-650061484:212,Modifiability,adapt,adapted,212,"Hi Brain. One quick question. I have noticed that you have set ADAP_NORM to 1 (Lp=1) in one example for Euler solution. I am using original PYAMG examples and changing "" remesh_options['Lp'] "" does not alter the adapted mesh. The log file always saying LP=2 . Are you using a different PYAMG version? . Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-650061484
https://github.com/su2code/SU2/issues/606#issuecomment-650061484:230,Testability,log,log,230,"Hi Brain. One quick question. I have noticed that you have set ADAP_NORM to 1 (Lp=1) in one example for Euler solution. I am using original PYAMG examples and changing "" remesh_options['Lp'] "" does not alter the adapted mesh. The log file always saying LP=2 . Are you using a different PYAMG version? . Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/606#issuecomment-650061484
https://github.com/su2code/SU2/issues/609#issuecomment-438736476:919,Testability,test,tests,919,"This sounds like an important thing to fix, and it looks like you've done some serious work to confirm it. ; Would you mind putting your changes into a pull request?. Since the ideal gas version has been around for longer, I would initially suspect that there is another sign flip somewhere else in the code for some reason (which may be hard to find... especially if the code needs some cleanup). Just in case, I suggest running a verification case with both versions, using the ideal gas law as the 'arbitrary' equation of state, and comparing against the built-in ideal gas, under both versions of the code, in order to confirm that the result changes to be the same when the sign is changed as you suggest. Ideally, something that can be compared to results from another code or to experiment to confirm that the sign-corrected version is correct, especially since I'm guessing this will effect a lot of regression tests. Code cleanup is of course always appreciated as well. @salvovitale & @LaSerpe since it looks like you've worked on the real gas version: any comments, and do you have a viscous test case?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-438736476
https://github.com/su2code/SU2/issues/609#issuecomment-438736476:1103,Testability,test,test,1103,"This sounds like an important thing to fix, and it looks like you've done some serious work to confirm it. ; Would you mind putting your changes into a pull request?. Since the ideal gas version has been around for longer, I would initially suspect that there is another sign flip somewhere else in the code for some reason (which may be hard to find... especially if the code needs some cleanup). Just in case, I suggest running a verification case with both versions, using the ideal gas law as the 'arbitrary' equation of state, and comparing against the built-in ideal gas, under both versions of the code, in order to confirm that the result changes to be the same when the sign is changed as you suggest. Ideally, something that can be compared to results from another code or to experiment to confirm that the sign-corrected version is correct, especially since I'm guessing this will effect a lot of regression tests. Code cleanup is of course always appreciated as well. @salvovitale & @LaSerpe since it looks like you've worked on the real gas version: any comments, and do you have a viscous test case?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-438736476
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:1200,Integrability,depend,depend,1200,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:22,Testability,test,test,22,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:74,Testability,test,tests,74,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:109,Testability,test,testing,109,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:159,Testability,test,test,159,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:216,Testability,test,testing,216,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:288,Testability,test,testing,288,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:306,Testability,test,test,306,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:438,Testability,test,test,438,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:778,Testability,test,tests,778,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:902,Testability,test,test,902,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:970,Testability,test,tested,970,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:1409,Testability,test,testing,1409,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439491945:10,Usability,simpl,simple,10,"Writing a simple unit test is difficult, since SU2 both doesn't have unit tests and wasn't written with unit testing in mind. That being said, I've got a unit test that I'm happy with. Our group has put our own unit-testing framework into our fork of SU2, based off of Boost and automake testing. The unit test I created runs off of that framework. That means it won't run out-of-the-box on the develop branch of SU2. When I run the unit test with no changes to `CNumerics::GetViscousProjJacs`, I get that the residuals and Jacobians match to within 10 times the machine epsilon, aside from the [4][0] value of the Jacobians. There, the relative difference is of the order 1E-6. When I switch the two lines in `CNumerics::GetViscousProjJacs` for ideal gases to be negative, the tests run with no complaints. Ideal gas and generalized variants match to within 10 times machine epsilon. I'm uploading my test file just as an example, in case anyone wants to see what I've tested.; [viscous_ideal_vs_general.zip](https://github.com/su2code/SU2/files/2590517/viscous_ideal_vs_general.zip). As for comparison to some results from another code, I think that's a lot to ask. Getting a good comparison would depend on an understanding of how the ideal gas model, viscosity, numerics, and Jacobians are handled in the external code. Small differences would make the comparison completely invalid. I completely support testing and checking the changes I'm proposing. But comparison with an external code seems to provide a very low return on investment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439491945
https://github.com/su2code/SU2/issues/609#issuecomment-439493827:76,Testability,test,test,76,"As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede : I'm interested in your unit testing set up...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439493827
https://github.com/su2code/SU2/issues/609#issuecomment-439493827:403,Testability,test,testing,403,"As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede : I'm interested in your unit testing set up...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439493827
https://github.com/su2code/SU2/issues/609#issuecomment-439500791:177,Integrability,rout,routine,177,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
https://github.com/su2code/SU2/issues/609#issuecomment-439500791:304,Modifiability,refactor,refactoring,304,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
https://github.com/su2code/SU2/issues/609#issuecomment-439500791:319,Performance,perform,perform,319,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
https://github.com/su2code/SU2/issues/609#issuecomment-439500791:331,Testability,test,test,331,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
https://github.com/su2code/SU2/issues/609#issuecomment-439500791:663,Testability,test,test,663,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
https://github.com/su2code/SU2/issues/609#issuecomment-439500791:1020,Testability,test,testing,1020,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
https://github.com/su2code/SU2/issues/609#issuecomment-439500791:123,Usability,simpl,simply,123,"All,. Of course, another approach to verifying which sign is correct is to do an analytic differentiation (using CoDi?) or simply using complex-step on the residual calculation routine to get exact Jacobians (for a particular state) and confirm the correct sign. This does require some code extraction / refactoring to perform the test, but it has the benefit that you would know exactly what the correct answer is for the specific residual implementation. Best,. Juan. On Nov 16, 2018, at 11:03 AM, Thomas D. Economon <notifications@github.com<mailto:notifications@github.com>> wrote:. As Jacobians affect convergence rate and not accuracy, you could do a quick test of the same problem with the current version and the sign flipped to see if there is measurable difference in the convergence rate. If yes, then it should give you a hint about which direction. If no, then we should still correct it, but prob don't need to put in too much effort. @clarkpede<https://github.com/clarkpede> : I'm interested in your unit testing set up... ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/609#issuecomment-439493827>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxInSS3cmLF8iFkD22AoYAp0G3G2yks5uvwvxgaJpZM4YeD9V>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439500791
https://github.com/su2code/SU2/issues/609#issuecomment-439538677:822,Modifiability,refactor,refactoring,822,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677
https://github.com/su2code/SU2/issues/609#issuecomment-439538677:12,Testability,test,tested,12,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677
https://github.com/su2code/SU2/issues/609#issuecomment-439538677:300,Testability,test,tests,300,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677
https://github.com/su2code/SU2/issues/609#issuecomment-439538677:507,Testability,test,test,507,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677
https://github.com/su2code/SU2/issues/609#issuecomment-439538677:31,Usability,simpl,simpler,31,"@economon I tested a couple of simpler problems at subsonic speeds, including the ONERA M6 case at M=0.8395. There's occasionally a difference of one iteration out of about 20. Usually the current develop branch is the one that requires more iterations, but not always. I included a snapshot from my tests on the ONERA M6 case at CFL=30. ![convergence_comparison](https://user-images.githubusercontent.com/13340225/48648855-6c97af80-e9b6-11e8-863a-56dfdf0903c8.png). I don't have a good supersonic, viscous test problem, but I suspect the differences in convergence won't be huge there either. This sign change affects a single term out of many and a single component of a 4x4 or 5x5 Jacobian. My take is that the differences are there, but they are very small. I wouldn't have noticed the problem myself if I hadn't been refactoring the code to enable some changes on our end.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439538677
https://github.com/su2code/SU2/issues/609#issuecomment-439579886:664,Availability,down,down,664,"This looks good; with repeated and well-checked analytical derivations plus numerical checks, and given the scale and impact (a single line of code, and a slight change to convergence rate), if this was in a pull request I would approve it. ; @juanjosealonso, @pcarruscag the AD information is still worth getting, and sharing the process of how to get it, since I'd guess that would be very useful for checking similar problems in the future - just maybe not as a reason to delay this specific change. I've seen accidental reversions in the past, I think it's something we should all keep an eye out for when reviewing pull requests. @LaSerpe thanks for tracking down the history on the changes. For unit tests: agreed, those would be very useful and I would be interested in seeing them too. ; For short term/ad hoc purposes, another option that hasn't been mentioned in this thread is using a debugger to inspect the values as the code runs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439579886
https://github.com/su2code/SU2/issues/609#issuecomment-439579886:706,Testability,test,tests,706,"This looks good; with repeated and well-checked analytical derivations plus numerical checks, and given the scale and impact (a single line of code, and a slight change to convergence rate), if this was in a pull request I would approve it. ; @juanjosealonso, @pcarruscag the AD information is still worth getting, and sharing the process of how to get it, since I'd guess that would be very useful for checking similar problems in the future - just maybe not as a reason to delay this specific change. I've seen accidental reversions in the past, I think it's something we should all keep an eye out for when reviewing pull requests. @LaSerpe thanks for tracking down the history on the changes. For unit tests: agreed, those would be very useful and I would be interested in seeing them too. ; For short term/ad hoc purposes, another option that hasn't been mentioned in this thread is using a debugger to inspect the values as the code runs.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/609#issuecomment-439579886
https://github.com/su2code/SU2/pull/612#issuecomment-440467191:134,Deployability,update,updated,134,"From a quick skim it looks like it's failing due to small differences in residual values, which is not unexpected here.; Those can be updated in the regression test scripts in SU2/TestCases/ in order to pass the tests, otherwise LGTM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/612#issuecomment-440467191
https://github.com/su2code/SU2/pull/612#issuecomment-440467191:160,Testability,test,test,160,"From a quick skim it looks like it's failing due to small differences in residual values, which is not unexpected here.; Those can be updated in the regression test scripts in SU2/TestCases/ in order to pass the tests, otherwise LGTM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/612#issuecomment-440467191
https://github.com/su2code/SU2/pull/612#issuecomment-440467191:180,Testability,Test,TestCases,180,"From a quick skim it looks like it's failing due to small differences in residual values, which is not unexpected here.; Those can be updated in the regression test scripts in SU2/TestCases/ in order to pass the tests, otherwise LGTM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/612#issuecomment-440467191
https://github.com/su2code/SU2/pull/612#issuecomment-440467191:212,Testability,test,tests,212,"From a quick skim it looks like it's failing due to small differences in residual values, which is not unexpected here.; Those can be updated in the regression test scripts in SU2/TestCases/ in order to pass the tests, otherwise LGTM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/612#issuecomment-440467191
https://github.com/su2code/SU2/pull/614#issuecomment-441300657:187,Energy Efficiency,sensor,sensor,187,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657
https://github.com/su2code/SU2/pull/614#issuecomment-441300657:263,Modifiability,variab,variables,263,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657
https://github.com/su2code/SU2/pull/614#issuecomment-441300657:666,Modifiability,variab,variables,666,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657
https://github.com/su2code/SU2/pull/614#issuecomment-441300657:724,Modifiability,variab,variables,724,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657
https://github.com/su2code/SU2/pull/614#issuecomment-441300657:768,Modifiability,variab,variables,768,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657
https://github.com/su2code/SU2/pull/614#issuecomment-441300657:15,Usability,feedback,feedback,15,"Thanks for the feedback @pcarruscag. @jayantmukho and I discussed this when we implemented the objective function. The main motivation was that since our implementation of the separation sensor is computed using the skin friction coefficient, we only defined the variables Buffet_Sensor, Buffet_Metric, etc. for the NSSolver class. Since the NSSolver needs to be able to evaluate all the same objectives as the EulerSolver, but the buffet objective is exclusive to the NSSolver, I copy pasted the function and added the new objective. Let me know if you have any suggestions for a cleaner implementation. We were basically choosing between defining all the Buffet_* variables in EulerSolver which would just add unnecessary variables to the constantly growing list of variables, or copying EvaluateObj_Func to allow for NS-specific objectives.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/614#issuecomment-441300657
https://github.com/su2code/SU2/pull/615#issuecomment-455994325:538,Energy Efficiency,monitor,monitor,538,"Hi @rsanfer,; Regarding patterns, larger cases are more likely to have the issue than small ones, I did not test boundary conditions.; I have not tested the forward mode because it differentiates linear solvers and in the past I have found that to be very limiting so I'd rather not go there. The most detailed verification we have is that present by @cvencro at scitech (finite differences). @cvencro do you have any before/after cases where this problem showed?; On the recording of variables, I like the FEM_VARIABLES as a convergence monitor. But for larger sets of variables, e.g. grid nodes, topology, a ""post processing"" recording step makes sense, that increase in memory footprint is why I have not created a PR for FSI shape derivatives yet. I talked about this briefly with @oleburghardt during the annual meeting and the new adjoint driver should have hooks for this type of post processing.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-455994325
https://github.com/su2code/SU2/pull/615#issuecomment-455994325:485,Modifiability,variab,variables,485,"Hi @rsanfer,; Regarding patterns, larger cases are more likely to have the issue than small ones, I did not test boundary conditions.; I have not tested the forward mode because it differentiates linear solvers and in the past I have found that to be very limiting so I'd rather not go there. The most detailed verification we have is that present by @cvencro at scitech (finite differences). @cvencro do you have any before/after cases where this problem showed?; On the recording of variables, I like the FEM_VARIABLES as a convergence monitor. But for larger sets of variables, e.g. grid nodes, topology, a ""post processing"" recording step makes sense, that increase in memory footprint is why I have not created a PR for FSI shape derivatives yet. I talked about this briefly with @oleburghardt during the annual meeting and the new adjoint driver should have hooks for this type of post processing.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-455994325
https://github.com/su2code/SU2/pull/615#issuecomment-455994325:570,Modifiability,variab,variables,570,"Hi @rsanfer,; Regarding patterns, larger cases are more likely to have the issue than small ones, I did not test boundary conditions.; I have not tested the forward mode because it differentiates linear solvers and in the past I have found that to be very limiting so I'd rather not go there. The most detailed verification we have is that present by @cvencro at scitech (finite differences). @cvencro do you have any before/after cases where this problem showed?; On the recording of variables, I like the FEM_VARIABLES as a convergence monitor. But for larger sets of variables, e.g. grid nodes, topology, a ""post processing"" recording step makes sense, that increase in memory footprint is why I have not created a PR for FSI shape derivatives yet. I talked about this briefly with @oleburghardt during the annual meeting and the new adjoint driver should have hooks for this type of post processing.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-455994325
https://github.com/su2code/SU2/pull/615#issuecomment-455994325:108,Testability,test,test,108,"Hi @rsanfer,; Regarding patterns, larger cases are more likely to have the issue than small ones, I did not test boundary conditions.; I have not tested the forward mode because it differentiates linear solvers and in the past I have found that to be very limiting so I'd rather not go there. The most detailed verification we have is that present by @cvencro at scitech (finite differences). @cvencro do you have any before/after cases where this problem showed?; On the recording of variables, I like the FEM_VARIABLES as a convergence monitor. But for larger sets of variables, e.g. grid nodes, topology, a ""post processing"" recording step makes sense, that increase in memory footprint is why I have not created a PR for FSI shape derivatives yet. I talked about this briefly with @oleburghardt during the annual meeting and the new adjoint driver should have hooks for this type of post processing.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-455994325
https://github.com/su2code/SU2/pull/615#issuecomment-455994325:146,Testability,test,tested,146,"Hi @rsanfer,; Regarding patterns, larger cases are more likely to have the issue than small ones, I did not test boundary conditions.; I have not tested the forward mode because it differentiates linear solvers and in the past I have found that to be very limiting so I'd rather not go there. The most detailed verification we have is that present by @cvencro at scitech (finite differences). @cvencro do you have any before/after cases where this problem showed?; On the recording of variables, I like the FEM_VARIABLES as a convergence monitor. But for larger sets of variables, e.g. grid nodes, topology, a ""post processing"" recording step makes sense, that increase in memory footprint is why I have not created a PR for FSI shape derivatives yet. I talked about this briefly with @oleburghardt during the annual meeting and the new adjoint driver should have hooks for this type of post processing.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-455994325
https://github.com/su2code/SU2/pull/615#issuecomment-457242410:19,Deployability,update,updated,19,"Hi @rsanfer,; I've updated those booleans.; The results of that verification are [these](https://github.com/su2code/SU2/files/2612501/FFD_verification.pdf), which I had linked to in #597.; I do not think the case will run without this PR, in any case [here](https://github.com/su2code/SU2/files/2792370/results.zip) are the config/mesh and solution files.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457242410
https://github.com/su2code/SU2/pull/615#issuecomment-457242410:324,Modifiability,config,config,324,"Hi @rsanfer,; I've updated those booleans.; The results of that verification are [these](https://github.com/su2code/SU2/files/2612501/FFD_verification.pdf), which I had linked to in #597.; I do not think the case will run without this PR, in any case [here](https://github.com/su2code/SU2/files/2792370/results.zip) are the config/mesh and solution files.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457242410
https://github.com/su2code/SU2/pull/615#issuecomment-457485924:70,Testability,test,test,70,"LGTM, thanks for updating the booleans. I think you can still add the test case to the PR right?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457485924
https://github.com/su2code/SU2/pull/615#issuecomment-457582842:343,Integrability,interface,interface,343,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842
https://github.com/su2code/SU2/pull/615#issuecomment-457582842:542,Modifiability,variab,variables,542,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842
https://github.com/su2code/SU2/pull/615#issuecomment-457582842:732,Modifiability,variab,variables,732,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842
https://github.com/su2code/SU2/pull/615#issuecomment-457582842:627,Performance,perform,performance,627,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842
https://github.com/su2code/SU2/pull/615#issuecomment-457582842:1024,Usability,clear,clear,1024,"Hi @pcarruscag, just a small follow-up to my comment in the code section concerning the new adjoint implementation that might also help here (either by using it directly or just for getting some ideas). What I would like to change is in fact not the `CDiscAdjSolver` (which I find is very good) - but I'd like to propose some changes for the *interface* to the AD tool. And some subsequent stuff.; It will allow for a more direct control of derivatives which is favourable in case one deals with multiple zones, multiple sets of conservative variables, geometry coordinates in case of FSI, and so on. And of course in terms of performance as one needs only one tape that one can keep during all iterations, regardless of what their variables might be. In case you are interested, take a look at the implementation in [su2code:sc_develop](https://github.com/su2code/SU2/tree/sc_develop). I'll open the PR as soon as @talbring opened his one for his great rework on input/ouput. As for this PR, let me wait a second if we can clear up the issue concerning the registration and I'll leave a small review afterwards.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/615#issuecomment-457582842
https://github.com/su2code/SU2/pull/619#issuecomment-442863838:29,Integrability,depend,dependencies,29,"Hi Ole,; I see that the heat dependencies are currently being set in the adjoint fluid iteration and on the new adjoint heat iteration. Would it make sense to define them at the heat solver level to centralize things a bit? If not please add a comment to those areas of the code (a similar issue made me chase my tail sometime ago).; Otherwise all looks nice and clean! And I look forward to see the generic adjoint driver!; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/619#issuecomment-442863838
https://github.com/su2code/SU2/pull/619#issuecomment-442874041:22,Integrability,depend,dependencies,22,> I see that the heat dependencies are currently being set in the adjoint fluid iteration and on the new adjoint heat iteration. . Thanks for the comment. Could you give me an example to what kind of dependencies you are referring to?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/619#issuecomment-442874041
https://github.com/su2code/SU2/pull/619#issuecomment-442874041:200,Integrability,depend,dependencies,200,> I see that the heat dependencies are currently being set in the adjoint fluid iteration and on the new adjoint heat iteration. . Thanks for the comment. Could you give me an example to what kind of dependencies you are referring to?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/619#issuecomment-442874041
https://github.com/su2code/SU2/issues/620#issuecomment-443434414:102,Availability,failure,failure,102,"@economon it does work with python 2.7, I have not tried multiple versions of python 3, just 3.7. The failure occurs with the python script and does not get to the point where it starts executing SU2_DEG. The minimum example to reproduce the error is:. ```; from mesh_deformation import mesh_deformation as su2Deform; su2Deform( ""testing.cfg"" ); ```; using [testing.cfg](https://github.com/su2code/SU2/files/2635991/testing.txt), but with a txt extension.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/620#issuecomment-443434414
https://github.com/su2code/SU2/issues/620#issuecomment-443434414:242,Availability,error,error,242,"@economon it does work with python 2.7, I have not tried multiple versions of python 3, just 3.7. The failure occurs with the python script and does not get to the point where it starts executing SU2_DEG. The minimum example to reproduce the error is:. ```; from mesh_deformation import mesh_deformation as su2Deform; su2Deform( ""testing.cfg"" ); ```; using [testing.cfg](https://github.com/su2code/SU2/files/2635991/testing.txt), but with a txt extension.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/620#issuecomment-443434414
https://github.com/su2code/SU2/issues/620#issuecomment-443434414:330,Testability,test,testing,330,"@economon it does work with python 2.7, I have not tried multiple versions of python 3, just 3.7. The failure occurs with the python script and does not get to the point where it starts executing SU2_DEG. The minimum example to reproduce the error is:. ```; from mesh_deformation import mesh_deformation as su2Deform; su2Deform( ""testing.cfg"" ); ```; using [testing.cfg](https://github.com/su2code/SU2/files/2635991/testing.txt), but with a txt extension.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/620#issuecomment-443434414
https://github.com/su2code/SU2/issues/620#issuecomment-443434414:358,Testability,test,testing,358,"@economon it does work with python 2.7, I have not tried multiple versions of python 3, just 3.7. The failure occurs with the python script and does not get to the point where it starts executing SU2_DEG. The minimum example to reproduce the error is:. ```; from mesh_deformation import mesh_deformation as su2Deform; su2Deform( ""testing.cfg"" ); ```; using [testing.cfg](https://github.com/su2code/SU2/files/2635991/testing.txt), but with a txt extension.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/620#issuecomment-443434414
https://github.com/su2code/SU2/issues/620#issuecomment-443434414:416,Testability,test,testing,416,"@economon it does work with python 2.7, I have not tried multiple versions of python 3, just 3.7. The failure occurs with the python script and does not get to the point where it starts executing SU2_DEG. The minimum example to reproduce the error is:. ```; from mesh_deformation import mesh_deformation as su2Deform; su2Deform( ""testing.cfg"" ); ```; using [testing.cfg](https://github.com/su2code/SU2/files/2635991/testing.txt), but with a txt extension.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/620#issuecomment-443434414
https://github.com/su2code/SU2/issues/620#issuecomment-460561225:30,Availability,error,error,30,"Hi all, I am also seeing this error with Python 3.7.2 in the finite_difference.py script. I replaced `len(new_value)` with `len(list(new_value))` here and there but then the DV_VALUE_NEW doesn't get correctly set. Any new hints?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/620#issuecomment-460561225
https://github.com/su2code/SU2/pull/622#issuecomment-443521982:73,Availability,down,download,73,"Hmmm this didn't work because Travis doesn't have a Python 3.7 binary to download, even though it wouldn't be used. Going to require some more thought if this is worth testing for.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-443521982
https://github.com/su2code/SU2/pull/622#issuecomment-443521982:168,Testability,test,testing,168,"Hmmm this didn't work because Travis doesn't have a Python 3.7 binary to download, even though it wouldn't be used. Going to require some more thought if this is worth testing for.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-443521982
https://github.com/su2code/SU2/pull/622#issuecomment-443522164:170,Testability,test,test,170,"We should also think of a smarter way of setting up the travis system. Running 12 independent jobs, each of them having to compile the whole code multiple times, just to test python is a little bit of an overhead.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-443522164
https://github.com/su2code/SU2/pull/622#issuecomment-443684684:77,Availability,avail,available,77,"Not sure if it's preferable, but I changed the environment to use the latest available Python 3, rather than 3.6, and the tests still pass with Python 3.7.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-443684684
https://github.com/su2code/SU2/pull/622#issuecomment-443684684:122,Testability,test,tests,122,"Not sure if it's preferable, but I changed the environment to use the latest available Python 3, rather than 3.6, and the tests still pass with Python 3.7.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-443684684
https://github.com/su2code/SU2/pull/622#issuecomment-443963958:47,Availability,failure,failure,47,@petebachant : do you have any ideas about the failure in #620 posted by @galbramc ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-443963958
https://github.com/su2code/SU2/pull/622#issuecomment-444086237:59,Testability,test,test,59,"The use of SU2deform in #620 is apparently not part of the test suite, so testing with Python 3.7 doesn't replicate the issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-444086237
https://github.com/su2code/SU2/pull/622#issuecomment-444086237:74,Testability,test,testing,74,"The use of SU2deform in #620 is apparently not part of the test suite, so testing with Python 3.7 doesn't replicate the issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-444086237
https://github.com/su2code/SU2/pull/622#issuecomment-445503034:20,Availability,error,error,20,I would imagine the error I got will occur with Python 3.6. So just adding SU2deform to the test suite should reproduce the error.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-445503034
https://github.com/su2code/SU2/pull/622#issuecomment-445503034:124,Availability,error,error,124,I would imagine the error I got will occur with Python 3.6. So just adding SU2deform to the test suite should reproduce the error.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-445503034
https://github.com/su2code/SU2/pull/622#issuecomment-445503034:92,Testability,test,test,92,I would imagine the error I got will occur with Python 3.6. So just adding SU2deform to the test suite should reproduce the error.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-445503034
https://github.com/su2code/SU2/pull/622#issuecomment-445541373:167,Availability,avail,available,167,"Yep, I don't know of any changes to `map` from Python 3.6 to Python 3.7. In light of that, though it may be useful in the future to always test with the latest Python available from Anaconda, I'm going to close this for now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-445541373
https://github.com/su2code/SU2/pull/622#issuecomment-445541373:139,Testability,test,test,139,"Yep, I don't know of any changes to `map` from Python 3.6 to Python 3.7. In light of that, though it may be useful in the future to always test with the latest Python available from Anaconda, I'm going to close this for now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/622#issuecomment-445541373
https://github.com/su2code/SU2/pull/623#issuecomment-443665804:426,Availability,toler,tolerance,426,Thanks @economon this makes a lot of sense. And if it goes ahead maybe the options DEFORM_LINEAR_SOLVER_ITER and DEFORM_LINEAR_ITER should also be fused?. This is has a smallish negative implication to FSI cases. There because the deformation is incremental it is acceptable to converge the solver to 1e-6 or only 1e-5. But in shape optimization (@cvencro and I are working on that) we would be limited by the lowest required tolerance. @rsanfer this is something to consider in the mesh deformation refactoring.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-443665804
https://github.com/su2code/SU2/pull/623#issuecomment-443665804:500,Modifiability,refactor,refactoring,500,Thanks @economon this makes a lot of sense. And if it goes ahead maybe the options DEFORM_LINEAR_SOLVER_ITER and DEFORM_LINEAR_ITER should also be fused?. This is has a smallish negative implication to FSI cases. There because the deformation is incremental it is acceptable to converge the solver to 1e-6 or only 1e-5. But in shape optimization (@cvencro and I are working on that) we would be limited by the lowest required tolerance. @rsanfer this is something to consider in the mesh deformation refactoring.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-443665804
https://github.com/su2code/SU2/pull/623#issuecomment-443665804:333,Performance,optimiz,optimization,333,Thanks @economon this makes a lot of sense. And if it goes ahead maybe the options DEFORM_LINEAR_SOLVER_ITER and DEFORM_LINEAR_ITER should also be fused?. This is has a smallish negative implication to FSI cases. There because the deformation is incremental it is acceptable to converge the solver to 1e-6 or only 1e-5. But in shape optimization (@cvencro and I are working on that) we would be limited by the lowest required tolerance. @rsanfer this is something to consider in the mesh deformation refactoring.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-443665804
https://github.com/su2code/SU2/pull/623#issuecomment-444003331:141,Availability,toler,tolerance,141,"I think combining options where possible would be great. Also, wont the move to multiple config files for multizone avoid the linear solver tolerance issue you mention for FSI, as the elasticity config can again reuse Linear_Solver_Error once it is not simultaneously being used by the fluid? Therefore, the deform option can be solely for grid deformation either during shape design or for the mesh equations in FSI problems.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-444003331
https://github.com/su2code/SU2/pull/623#issuecomment-444003331:90,Modifiability,config,config,90,"I think combining options where possible would be great. Also, wont the move to multiple config files for multizone avoid the linear solver tolerance issue you mention for FSI, as the elasticity config can again reuse Linear_Solver_Error once it is not simultaneously being used by the fluid? Therefore, the deform option can be solely for grid deformation either during shape design or for the mesh equations in FSI problems.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-444003331
https://github.com/su2code/SU2/pull/623#issuecomment-444003331:196,Modifiability,config,config,196,"I think combining options where possible would be great. Also, wont the move to multiple config files for multizone avoid the linear solver tolerance issue you mention for FSI, as the elasticity config can again reuse Linear_Solver_Error once it is not simultaneously being used by the fluid? Therefore, the deform option can be solely for grid deformation either during shape design or for the mesh equations in FSI problems.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-444003331
https://github.com/su2code/SU2/pull/623#issuecomment-444003331:117,Safety,avoid,avoid,117,"I think combining options where possible would be great. Also, wont the move to multiple config files for multizone avoid the linear solver tolerance issue you mention for FSI, as the elasticity config can again reuse Linear_Solver_Error once it is not simultaneously being used by the fluid? Therefore, the deform option can be solely for grid deformation either during shape design or for the mesh equations in FSI problems.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-444003331
https://github.com/su2code/SU2/pull/623#issuecomment-456293206:329,Modifiability,variab,variable,329,"I agree with @pcarruscag , we should try to merge options. I have been thinking for quite some time that we should make the mesh deformation a full solver on its own and homogenise all the options and procedures, be able to define different boundary conditions, etc. It should be based on the linear elasticity but have it's own variable definition, so it's usable out of the box with the adjoint solver. I have a preliminary implementation in [`feature_mesh_solver` ](https://github.com/su2code/SU2/tree/feature_mesh_solver), but I would need some help with that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-456293206
https://github.com/su2code/SU2/pull/623#issuecomment-456293206:358,Usability,usab,usable,358,"I agree with @pcarruscag , we should try to merge options. I have been thinking for quite some time that we should make the mesh deformation a full solver on its own and homogenise all the options and procedures, be able to define different boundary conditions, etc. It should be based on the linear elasticity but have it's own variable definition, so it's usable out of the box with the adjoint solver. I have a preliminary implementation in [`feature_mesh_solver` ](https://github.com/su2code/SU2/tree/feature_mesh_solver), but I would need some help with that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-456293206
https://github.com/su2code/SU2/pull/623#issuecomment-463522098:68,Deployability,update,update,68,Thanks @rsanfer. Just a reminder that we need to merge the tutorial update in the website repo too simultaneously if we agree to merge this one.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/623#issuecomment-463522098
https://github.com/su2code/SU2/pull/625#issuecomment-459996705:29,Usability,feedback,feedback,29,Thanks again for the helpful feedback @oleburghardt. Time to get this one merged so we can keep moving.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/625#issuecomment-459996705
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:767,Availability,error,errors,767,"Alright. There's a thorny part of this merge that needs to be resolved. I would like the decisions reviewed before I proceed to make any more changes. The differences between revision d1e3a18 and revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:1509,Availability,error,errors,1509," revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is how to update the tests. We could just update the regression test values, but I would propose fixing the regression test. It seems to be sensitive to what I believe are unimportant differences.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:2009,Deployability,update,update,2009," revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is how to update the tests. We could just update the regression test values, but I would propose fixing the regression test. It seems to be sensitive to what I believe are unimportant differences.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:2041,Deployability,update,update,2041," revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is how to update the tests. We could just update the regression test values, but I would propose fixing the regression test. It seems to be sensitive to what I believe are unimportant differences.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:249,Testability,test,test,249,"Alright. There's a thorny part of this merge that needs to be resolved. I would like the decisions reviewed before I proceed to make any more changes. The differences between revision d1e3a18 and revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:302,Testability,test,tests,302,"Alright. There's a thorny part of this merge that needs to be resolved. I would like the decisions reviewed before I proceed to make any more changes. The differences between revision d1e3a18 and revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:351,Testability,test,tests,351,"Alright. There's a thorny part of this merge that needs to be resolved. I would like the decisions reviewed before I proceed to make any more changes. The differences between revision d1e3a18 and revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:430,Testability,test,test,430,"Alright. There's a thorny part of this merge that needs to be resolved. I would like the decisions reviewed before I proceed to make any more changes. The differences between revision d1e3a18 and revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:832,Testability,test,test,832,"Alright. There's a thorny part of this merge that needs to be resolved. I would like the decisions reviewed before I proceed to make any more changes. The differences between revision d1e3a18 and revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:2020,Testability,test,tests,2020," revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is how to update the tests. We could just update the regression test values, but I would propose fixing the regression test. It seems to be sensitive to what I believe are unimportant differences.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:2063,Testability,test,test,2063," revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is how to update the tests. We could just update the regression test values, but I would propose fixing the regression test. It seems to be sensitive to what I believe are unimportant differences.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-444655022:2118,Testability,test,test,2118," revision e6e6e6b are very small, aside from an extra test file. But revision d1e3a18 fails the regression tests and revision e6e6e6b passes the regression tests. Specifically, it's only the CHT incompressible case that's failing. The test results show:. test_vals (stored): 0.000000, 0.000000, -7.685301, -12947.783696; sim_vals (computed): 0.000000, 0.000000, -7.685301, -12947.783678 ; delta_vals: 0.000000, 0.000000, 0.000000, 0.000018. It's only the total heat flux that's different, and it's only off by 1E-7%. I believe that these changes are due to floating-point errors. To check and make sure nothing is going crazy, I ran the test case under both the develop and the PR branches. When I compared the solution files, I couldn't find any points where the solution differed by more than 0.0003%. The differences seem to be very small. The two differences between revision d1e3a18 and revision e6e6e6b can be summarized as follows:. 1. In the `CNumerics::GetViscousIncProjJacs()` calculation on the develop branch, a quantity called `theta` is calculated. `theta` is the magnitude of the `val_normal` parameter, squared. The catch is that `val_normal` is passed as a unit vector (named `UnitNormal` in `CAvgGradInc_Flow::ComputeResidual`). So `theta` should always be equal to one, with some floating point errors. In the failing revision, the value is set explicitly to one. In the passing revision, the magnitude is calculated explicitly. I checked, and the difference between `theta` and 1.0 is always of the order 1E-16 or less.; 2. The second change affects where the area is multiplied into the Jacobian. When the area is multiplied at a later stage, very small differences in the calculated quantities appear. I don't like revision e6e6e6b, and I would like to revert it. The question then is how to update the tests. We could just update the regression test values, but I would propose fixing the regression test. It seems to be sensitive to what I believe are unimportant differences.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-444655022
https://github.com/su2code/SU2/pull/626#issuecomment-447080866:115,Availability,down,down,115,"@clarkpede : I am not too concerned about differences on the order of what you are seeing with the CHT case. It is down in the range of the changes you would see just due to switching hardware / OS / etc. One option is to loosen the tolerance in the python regression script, e.g., increase 'cht_incompressible.tol = 0.00001' to a higher val so it is not as sensitive.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-447080866
https://github.com/su2code/SU2/pull/626#issuecomment-447080866:233,Availability,toler,tolerance,233,"@clarkpede : I am not too concerned about differences on the order of what you are seeing with the CHT case. It is down in the range of the changes you would see just due to switching hardware / OS / etc. One option is to loosen the tolerance in the python regression script, e.g., increase 'cht_incompressible.tol = 0.00001' to a higher val so it is not as sensitive.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-447080866
https://github.com/su2code/SU2/pull/626#issuecomment-456790919:51,Availability,toler,tolerance,51,"So I've changed the CHT test case to have a higher tolerance for errors, and I've merged in the changes from PR #570. Everything looks ready to go. On a side note, I've noticed that SU2 has some internal inconsistencies with the viscous/turbulent stresses. Some new options, such as QCR, SST UQ, and wall functions, have been added to the stress tensor definition over the past two years. But there's still some parts of the code, such as `CNSSolver::BC_Isothermal_Wall` and `CSourceIncAxisymmetric_Flow::ComputeResidual` where those changes aren't reflected. The stress tensor is still defined the old way. Is this intentional? Or was it an oversight?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-456790919
https://github.com/su2code/SU2/pull/626#issuecomment-456790919:65,Availability,error,errors,65,"So I've changed the CHT test case to have a higher tolerance for errors, and I've merged in the changes from PR #570. Everything looks ready to go. On a side note, I've noticed that SU2 has some internal inconsistencies with the viscous/turbulent stresses. Some new options, such as QCR, SST UQ, and wall functions, have been added to the stress tensor definition over the past two years. But there's still some parts of the code, such as `CNSSolver::BC_Isothermal_Wall` and `CSourceIncAxisymmetric_Flow::ComputeResidual` where those changes aren't reflected. The stress tensor is still defined the old way. Is this intentional? Or was it an oversight?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-456790919
https://github.com/su2code/SU2/pull/626#issuecomment-456790919:24,Testability,test,test,24,"So I've changed the CHT test case to have a higher tolerance for errors, and I've merged in the changes from PR #570. Everything looks ready to go. On a side note, I've noticed that SU2 has some internal inconsistencies with the viscous/turbulent stresses. Some new options, such as QCR, SST UQ, and wall functions, have been added to the stress tensor definition over the past two years. But there's still some parts of the code, such as `CNSSolver::BC_Isothermal_Wall` and `CSourceIncAxisymmetric_Flow::ComputeResidual` where those changes aren't reflected. The stress tensor is still defined the old way. Is this intentional? Or was it an oversight?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-456790919
https://github.com/su2code/SU2/pull/626#issuecomment-458177675:114,Integrability,depend,depends,114,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675
https://github.com/su2code/SU2/pull/626#issuecomment-458177675:182,Modifiability,refactor,refactoring,182,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675
https://github.com/su2code/SU2/pull/626#issuecomment-458177675:234,Performance,perform,performance,234,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675
https://github.com/su2code/SU2/pull/626#issuecomment-458177675:330,Performance,perform,performance,330,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675
https://github.com/su2code/SU2/pull/626#issuecomment-458177675:524,Usability,clear,clear,524,"> Thanks for pointing that out. I dont think it is intentional. Maybe we can use this PR also to fix this ?. That depends on how atomic we want these PRs to be. This PR is largely a refactoring PR, and shouldn't change any underlying performance. But adding extra calculations on source terms and wall conditions might change the performance of the code. The two changes are completely compatible, so combining them wouldn't be hard. Nevertheless, I propose we keep these changes separate, so that the purpose of each PR is clear and easy to see. In my mind, two small PRs are easier to check and review than one large PR. @talbring @economon What do you think? One big PR or two small PRs?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458177675
https://github.com/su2code/SU2/pull/626#issuecomment-458193864:81,Modifiability,refactor,refactoring,81,Two PRs is fine for me.. good strategy I also use: much easier to complete a big refactoring if you know the residuals shouldn't change on the regressions (I am doing this with the MPI comms now). Do you have the bandwidth to put in another PR after this? We appreciate it,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-458193864
https://github.com/su2code/SU2/pull/626#issuecomment-460945824:18,Deployability,update,updates,18,Does it need some updates now that #631 has been merged in ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-460945824
https://github.com/su2code/SU2/pull/626#issuecomment-461109183:258,Deployability,release,release,258,@clarkpede Yep you are right :+1: I like this PR. Removing code by still keeping the same functionality. As soon as the regression tests pass we can merge it in. Do you think you can submit the other PR some time next week ? So that we have it for the 6.2.0 release ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-461109183
https://github.com/su2code/SU2/pull/626#issuecomment-461109183:131,Testability,test,tests,131,@clarkpede Yep you are right :+1: I like this PR. Removing code by still keeping the same functionality. As soon as the regression tests pass we can merge it in. Do you think you can submit the other PR some time next week ? So that we have it for the 6.2.0 release ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/626#issuecomment-461109183
https://github.com/su2code/SU2/issues/627#issuecomment-444813302:102,Modifiability,variab,variables,102,"If I'm not mistaken the residual of discrete adjoints is based on normalized variation of the adjoint variables (since there is no conservation principle) and this is already akin to the Cauchy criterion.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/627#issuecomment-444813302
https://github.com/su2code/SU2/pull/628#issuecomment-522633022:231,Availability,Error,Error,231,"Hello. Can you add a test case about AUSMPLUSUP or AUSMPLUSUP2? I installed SU2 6.2.0 and used it to simulate two-dimensional lid-driven cavity flow. When I set 'CONV_NUM_METHOD_FOLW' to be 'AUSMPLUSUP' or 'AUSMPLUSUP2', it shows 'Error in ''void CSoLver::SetResidual_RMS(CGeometry*, CConfig*):' and 'MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD'. But when I set it to be other schemes like AUSM, ROE or so, it runs. Maybe if there is a test case, I can find where is my mistake. Thank you.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522633022
https://github.com/su2code/SU2/pull/628#issuecomment-522633022:66,Deployability,install,installed,66,"Hello. Can you add a test case about AUSMPLUSUP or AUSMPLUSUP2? I installed SU2 6.2.0 and used it to simulate two-dimensional lid-driven cavity flow. When I set 'CONV_NUM_METHOD_FOLW' to be 'AUSMPLUSUP' or 'AUSMPLUSUP2', it shows 'Error in ''void CSoLver::SetResidual_RMS(CGeometry*, CConfig*):' and 'MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD'. But when I set it to be other schemes like AUSM, ROE or so, it runs. Maybe if there is a test case, I can find where is my mistake. Thank you.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522633022
https://github.com/su2code/SU2/pull/628#issuecomment-522633022:21,Testability,test,test,21,"Hello. Can you add a test case about AUSMPLUSUP or AUSMPLUSUP2? I installed SU2 6.2.0 and used it to simulate two-dimensional lid-driven cavity flow. When I set 'CONV_NUM_METHOD_FOLW' to be 'AUSMPLUSUP' or 'AUSMPLUSUP2', it shows 'Error in ''void CSoLver::SetResidual_RMS(CGeometry*, CConfig*):' and 'MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD'. But when I set it to be other schemes like AUSM, ROE or so, it runs. Maybe if there is a test case, I can find where is my mistake. Thank you.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522633022
https://github.com/su2code/SU2/pull/628#issuecomment-522633022:455,Testability,test,test,455,"Hello. Can you add a test case about AUSMPLUSUP or AUSMPLUSUP2? I installed SU2 6.2.0 and used it to simulate two-dimensional lid-driven cavity flow. When I set 'CONV_NUM_METHOD_FOLW' to be 'AUSMPLUSUP' or 'AUSMPLUSUP2', it shows 'Error in ''void CSoLver::SetResidual_RMS(CGeometry*, CConfig*):' and 'MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD'. But when I set it to be other schemes like AUSM, ROE or so, it runs. Maybe if there is a test case, I can find where is my mistake. Thank you.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522633022
https://github.com/su2code/SU2/pull/628#issuecomment-522656848:123,Availability,error,error,123,"Hi, @cjz667. When I tried lid driven cavity case with default setting and switching ROE to AUSMPLUSUP, I got the following error - Error in void CSyssolve::ModGramSchmidt(int.........; SU2 has diverged (It ran for 2 iterations). Reduced the CFL to 0.5 (originally 2.0), it runs fine.; But it is going to take more number of iterations.; This issue was noted earlier as well and reason behind that is inconsistent Jacobian (Roe here) with AUSM family of schemes. This restricts the allowable CFL number to a lower values for these scehemes. For low speed flows u may have to use smaller value of CFL with these two schemes. . Dr. Padro (pcarruscage) has done some work in this direction and implemented hybrid Jacobian for some of these schemes (available in develop branch) , which improves this situation and u can try higher CFL. I have also worked out analytical Jacobian and will be pushing in future release. I hope you can go with reasonable CFL for majority of the other cases, where Mach number is not too small.; I have added one Testcase for high speed flow past blunt body in testcase folder /euler/bluntbody, which uses AUSMPLUSUP. Give a try with other cases, I have tried many in RANS, NS, EULER.; Hope this help. . Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522656848
https://github.com/su2code/SU2/pull/628#issuecomment-522656848:131,Availability,Error,Error,131,"Hi, @cjz667. When I tried lid driven cavity case with default setting and switching ROE to AUSMPLUSUP, I got the following error - Error in void CSyssolve::ModGramSchmidt(int.........; SU2 has diverged (It ran for 2 iterations). Reduced the CFL to 0.5 (originally 2.0), it runs fine.; But it is going to take more number of iterations.; This issue was noted earlier as well and reason behind that is inconsistent Jacobian (Roe here) with AUSM family of schemes. This restricts the allowable CFL number to a lower values for these scehemes. For low speed flows u may have to use smaller value of CFL with these two schemes. . Dr. Padro (pcarruscage) has done some work in this direction and implemented hybrid Jacobian for some of these schemes (available in develop branch) , which improves this situation and u can try higher CFL. I have also worked out analytical Jacobian and will be pushing in future release. I hope you can go with reasonable CFL for majority of the other cases, where Mach number is not too small.; I have added one Testcase for high speed flow past blunt body in testcase folder /euler/bluntbody, which uses AUSMPLUSUP. Give a try with other cases, I have tried many in RANS, NS, EULER.; Hope this help. . Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522656848
https://github.com/su2code/SU2/pull/628#issuecomment-522656848:746,Availability,avail,available,746,"Hi, @cjz667. When I tried lid driven cavity case with default setting and switching ROE to AUSMPLUSUP, I got the following error - Error in void CSyssolve::ModGramSchmidt(int.........; SU2 has diverged (It ran for 2 iterations). Reduced the CFL to 0.5 (originally 2.0), it runs fine.; But it is going to take more number of iterations.; This issue was noted earlier as well and reason behind that is inconsistent Jacobian (Roe here) with AUSM family of schemes. This restricts the allowable CFL number to a lower values for these scehemes. For low speed flows u may have to use smaller value of CFL with these two schemes. . Dr. Padro (pcarruscage) has done some work in this direction and implemented hybrid Jacobian for some of these schemes (available in develop branch) , which improves this situation and u can try higher CFL. I have also worked out analytical Jacobian and will be pushing in future release. I hope you can go with reasonable CFL for majority of the other cases, where Mach number is not too small.; I have added one Testcase for high speed flow past blunt body in testcase folder /euler/bluntbody, which uses AUSMPLUSUP. Give a try with other cases, I have tried many in RANS, NS, EULER.; Hope this help. . Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522656848
https://github.com/su2code/SU2/pull/628#issuecomment-522656848:906,Deployability,release,release,906,"Hi, @cjz667. When I tried lid driven cavity case with default setting and switching ROE to AUSMPLUSUP, I got the following error - Error in void CSyssolve::ModGramSchmidt(int.........; SU2 has diverged (It ran for 2 iterations). Reduced the CFL to 0.5 (originally 2.0), it runs fine.; But it is going to take more number of iterations.; This issue was noted earlier as well and reason behind that is inconsistent Jacobian (Roe here) with AUSM family of schemes. This restricts the allowable CFL number to a lower values for these scehemes. For low speed flows u may have to use smaller value of CFL with these two schemes. . Dr. Padro (pcarruscage) has done some work in this direction and implemented hybrid Jacobian for some of these schemes (available in develop branch) , which improves this situation and u can try higher CFL. I have also worked out analytical Jacobian and will be pushing in future release. I hope you can go with reasonable CFL for majority of the other cases, where Mach number is not too small.; I have added one Testcase for high speed flow past blunt body in testcase folder /euler/bluntbody, which uses AUSMPLUSUP. Give a try with other cases, I have tried many in RANS, NS, EULER.; Hope this help. . Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522656848
https://github.com/su2code/SU2/pull/628#issuecomment-522656848:230,Energy Efficiency,Reduce,Reduced,230,"Hi, @cjz667. When I tried lid driven cavity case with default setting and switching ROE to AUSMPLUSUP, I got the following error - Error in void CSyssolve::ModGramSchmidt(int.........; SU2 has diverged (It ran for 2 iterations). Reduced the CFL to 0.5 (originally 2.0), it runs fine.; But it is going to take more number of iterations.; This issue was noted earlier as well and reason behind that is inconsistent Jacobian (Roe here) with AUSM family of schemes. This restricts the allowable CFL number to a lower values for these scehemes. For low speed flows u may have to use smaller value of CFL with these two schemes. . Dr. Padro (pcarruscage) has done some work in this direction and implemented hybrid Jacobian for some of these schemes (available in develop branch) , which improves this situation and u can try higher CFL. I have also worked out analytical Jacobian and will be pushing in future release. I hope you can go with reasonable CFL for majority of the other cases, where Mach number is not too small.; I have added one Testcase for high speed flow past blunt body in testcase folder /euler/bluntbody, which uses AUSMPLUSUP. Give a try with other cases, I have tried many in RANS, NS, EULER.; Hope this help. . Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522656848
https://github.com/su2code/SU2/pull/628#issuecomment-522656848:1040,Testability,Test,Testcase,1040,"Hi, @cjz667. When I tried lid driven cavity case with default setting and switching ROE to AUSMPLUSUP, I got the following error - Error in void CSyssolve::ModGramSchmidt(int.........; SU2 has diverged (It ran for 2 iterations). Reduced the CFL to 0.5 (originally 2.0), it runs fine.; But it is going to take more number of iterations.; This issue was noted earlier as well and reason behind that is inconsistent Jacobian (Roe here) with AUSM family of schemes. This restricts the allowable CFL number to a lower values for these scehemes. For low speed flows u may have to use smaller value of CFL with these two schemes. . Dr. Padro (pcarruscage) has done some work in this direction and implemented hybrid Jacobian for some of these schemes (available in develop branch) , which improves this situation and u can try higher CFL. I have also worked out analytical Jacobian and will be pushing in future release. I hope you can go with reasonable CFL for majority of the other cases, where Mach number is not too small.; I have added one Testcase for high speed flow past blunt body in testcase folder /euler/bluntbody, which uses AUSMPLUSUP. Give a try with other cases, I have tried many in RANS, NS, EULER.; Hope this help. . Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522656848
https://github.com/su2code/SU2/pull/628#issuecomment-522656848:1088,Testability,test,testcase,1088,"Hi, @cjz667. When I tried lid driven cavity case with default setting and switching ROE to AUSMPLUSUP, I got the following error - Error in void CSyssolve::ModGramSchmidt(int.........; SU2 has diverged (It ran for 2 iterations). Reduced the CFL to 0.5 (originally 2.0), it runs fine.; But it is going to take more number of iterations.; This issue was noted earlier as well and reason behind that is inconsistent Jacobian (Roe here) with AUSM family of schemes. This restricts the allowable CFL number to a lower values for these scehemes. For low speed flows u may have to use smaller value of CFL with these two schemes. . Dr. Padro (pcarruscage) has done some work in this direction and implemented hybrid Jacobian for some of these schemes (available in develop branch) , which improves this situation and u can try higher CFL. I have also worked out analytical Jacobian and will be pushing in future release. I hope you can go with reasonable CFL for majority of the other cases, where Mach number is not too small.; I have added one Testcase for high speed flow past blunt body in testcase folder /euler/bluntbody, which uses AUSMPLUSUP. Give a try with other cases, I have tried many in RANS, NS, EULER.; Hope this help. . Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-522656848
https://github.com/su2code/SU2/pull/628#issuecomment-523374440:376,Usability,learn,learn,376,"Hello, @aeroamit . Thank you very much. I try for some times and find that mach number matters. When I simulate two-dimensional lid-driven cavity flow, the flow starts from static. So this case always fails. I try laminar boundary layer case with 0.1 incoming mach number. This time SU2 runs well with AUSMPLUSUP, at a very low CFL number(0.01 or lower), converging slowly. I learn that this scheme is perfect for high speed flow, but it may not be good at low mach number case. Perhaps there are some mistakes when I use it. I think I am not familiar with this scheme enough and that I know SU2 not very well. Before using it in practice, I should read more papers and codes. By the way, SU2 6.2.0 doesn't have the option 'USE_ACCURATE_FLUX_JACOBIANS'. Thanks again. Regards; Cao J. Z.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-523374440
https://github.com/su2code/SU2/pull/628#issuecomment-523467130:13,Availability,Down,Download,13,"Hi @cjz667,; Download and install the develop branch, you can use the USE_ACCURATE_FLUX_JACOBIANS option. This option was added by @pcarruscag.; It will allow reasonably good CFL.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-523467130
https://github.com/su2code/SU2/pull/628#issuecomment-523467130:26,Deployability,install,install,26,"Hi @cjz667,; Download and install the develop branch, you can use the USE_ACCURATE_FLUX_JACOBIANS option. This option was added by @pcarruscag.; It will allow reasonably good CFL.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/628#issuecomment-523467130
https://github.com/su2code/SU2/pull/631#issuecomment-446719294:194,Availability,down,down,194,"Hi @aeroamit ,; Thank you for the work you have been doing on AUSM schemes.; This and your previous PR seem to share a lot of the code, do you think it is possible to generalize this? i.e. boil down AUSM schemes to just a change in the constants of the method, see for example what has been done in #626.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-446719294
https://github.com/su2code/SU2/pull/631#issuecomment-446730390:300,Modifiability,variab,variables,300,"Hi @pcarruscag,; You are right, it shares a lot of code with previous PR. Here constants does not change. Differences are as follows - . 1- It has different pressure flux definition (new expression); 2 - Here sum of squares of velocity components were needed for left and right state; 3- removed few variables and added few.; 4- Also left and right state split Mach numbers are Mach number polynomials only (for programming purpose) without pressure terms. Previously SLAU and SLAU2 scheme have already been implemented in the code separately. I mean some of these sucessive schemes share a lot of common formulation but differ with some expressions, constants etc. ; So it may be fine to keep them separate. . I will see your advice and further look into similar variation implementation in the code (sorry if I missed out some simple point you mentioned). . Thanks ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-446730390
https://github.com/su2code/SU2/pull/631#issuecomment-446730390:829,Usability,simpl,simple,829,"Hi @pcarruscag,; You are right, it shares a lot of code with previous PR. Here constants does not change. Differences are as follows - . 1- It has different pressure flux definition (new expression); 2 - Here sum of squares of velocity components were needed for left and right state; 3- removed few variables and added few.; 4- Also left and right state split Mach numbers are Mach number polynomials only (for programming purpose) without pressure terms. Previously SLAU and SLAU2 scheme have already been implemented in the code separately. I mean some of these sucessive schemes share a lot of common formulation but differ with some expressions, constants etc. ; So it may be fine to keep them separate. . I will see your advice and further look into similar variation implementation in the code (sorry if I missed out some simple point you mentioned). . Thanks ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-446730390
https://github.com/su2code/SU2/pull/631#issuecomment-446732267:138,Availability,robust,robust,138,"Hi @EduardoMolina,; AUSM+ - up2 uses SLAU2 pressure flux and rest old formulation of AUSM+-up but two are different. Indeed SLAU2 is less robust and prone to shock anomalies in comparison to AUSM+up2 and LDFSS02 (KITAMURA paper latter two scheme does the better job for high speed flows). . I will check the SLAU2 formulation in the code to resolve this. . Thanks and regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-446732267
https://github.com/su2code/SU2/pull/631#issuecomment-446897513:636,Availability,avail,available,636,"Hi @EduardoMolina ,; I have checked the code/paper so -. **SLAU2 = SLAU+modified pressure flux** &. **AUSM+-up2 = AUSM+ -up + SLAU2 modified pressure flux**. So AUSM+-up2 implementation differs from SLAU2 (page no. 72-73 of reference - Towards shock-stable and accurate hypersonic heating computations: A new pressure flux for AUSM-family schemes, KeiichiKitamura, EijiShima, 245 (2013) 6283). Also I am just copying the lines from the paper (page no. - 81) - ""....Thus, for **practical usage**, it is advised that the **users adopt AUSM+-up2** or **LDFSS2001-2** for **hypersonic flows** or low speed flows when reference velocity is available, whereas **SLAU2** is **recommended for low speed flows** **without reference velocity**; either of these three can be used for moderate speeds, as they are exactly the same as their original fluxes ....."". Hence AUSM+-up2 can be a good candidate for usage. I think this resolves the issue @EduardoMolina . Cheers.; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-446897513
https://github.com/su2code/SU2/pull/631#issuecomment-447080026:246,Testability,test,testing,246,"Thanks for the technical exchange, @aeroamit @EduardoMolina, this is nice to see. @aeroamit : do you have any specific cases that use the different schemes you are submitting? Could be good to see the differences and also use them for regression testing (our matrix could prob be better at covering more convective schemes).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-447080026
https://github.com/su2code/SU2/pull/631#issuecomment-447092111:33,Testability,Test,Test,33,"Hi @economon ,. I tried existing Test cases from Repository (NACA0012 etc.). At lower Mach numbers, there is improvement in accuracy over AUSM, HLLC or Roe scheme (especially stagnation region values and there is some more story to it). ; I will try to workout some specific test case for higher Mach number to show the differences.; Also some of these latest schemes are likely to be better in comparison to existing ones/predecessors in most of the situations (incrementally or reasonably). Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-447092111
https://github.com/su2code/SU2/pull/631#issuecomment-447092111:275,Testability,test,test,275,"Hi @economon ,. I tried existing Test cases from Repository (NACA0012 etc.). At lower Mach numbers, there is improvement in accuracy over AUSM, HLLC or Roe scheme (especially stagnation region values and there is some more story to it). ; I will try to workout some specific test case for higher Mach number to show the differences.; Also some of these latest schemes are likely to be better in comparison to existing ones/predecessors in most of the situations (incrementally or reasonably). Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-447092111
https://github.com/su2code/SU2/pull/631#issuecomment-453234901:47,Testability,test,test,47,Hi @economon @EduardoMolina . I have tried two test cases - NACA 0012 airfoil and flow past blunt body. Please see the attached pdf file containing the details. [AUSM_UP_UP2.pdf](https://github.com/su2code/SU2/files/2746891/AUSM_UP_UP2.pdf). Regards; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-453234901
https://github.com/su2code/SU2/pull/631#issuecomment-453343533:156,Deployability,update,update,156,"Hi @aeroamit . Thank you for your time and for share this great material. I really appreciated. I will review your pull request in a couple of days. Please update this branch with the develop. Best,. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-453343533
https://github.com/su2code/SU2/pull/631#issuecomment-453447518:42,Testability,test,testing,42,"Hi @aeroamit,; Thank you for the detailed testing, the results look quite good, I might give these schemes a try.; By the way, my question on whether these schemes could be merged was not just with code clean-up in mind, if different schemes could be obtained by changing some constants then in theory the discrete adjoint solver could be used to get sensitivities of numerical phenomena with respect to the choice of method.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-453447518
https://github.com/su2code/SU2/pull/631#issuecomment-454542835:110,Testability,test,test,110,"Hi @aeroamit ,. LGTM! Thanks. Just a mark: I think it is interesting to add the flow past a blunt body on the test repo. What do think? If not, it is ready to merge. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-454542835
https://github.com/su2code/SU2/pull/631#issuecomment-455009027:43,Testability,test,test,43,"Hi @EduardoMolina . I will add this in the test repo. It is a standard case used in majority of the papers (relevant).; What are the changes/additions I need to carry out , can you guide me with the procedure of adding the test case in repo. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455009027
https://github.com/su2code/SU2/pull/631#issuecomment-455009027:223,Testability,test,test,223,"Hi @EduardoMolina . I will add this in the test repo. It is a standard case used in majority of the papers (relevant).; What are the changes/additions I need to carry out , can you guide me with the procedure of adding the test case in repo. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455009027
https://github.com/su2code/SU2/pull/631#issuecomment-455009027:181,Usability,guid,guide,181,"Hi @EduardoMolina . I will add this in the test repo. It is a standard case used in majority of the papers (relevant).; What are the changes/additions I need to carry out , can you guide me with the procedure of adding the test case in repo. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455009027
https://github.com/su2code/SU2/pull/631#issuecomment-455422968:303,Deployability,update,update,303,"Hi @aeroamit . Sure. Please see this link: https://su2code.github.io/docs/Gitting-Started/. Basically, you need to modify the python regression files in order to add your new test case. Also, you need to upload the grid in https://github.com/su2code/TestCases, you can create a branch for that. Lastly, update .travis.yml but don't forget to revert it before merge. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455422968
https://github.com/su2code/SU2/pull/631#issuecomment-455422968:175,Testability,test,test,175,"Hi @aeroamit . Sure. Please see this link: https://su2code.github.io/docs/Gitting-Started/. Basically, you need to modify the python regression files in order to add your new test case. Also, you need to upload the grid in https://github.com/su2code/TestCases, you can create a branch for that. Lastly, update .travis.yml but don't forget to revert it before merge. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455422968
https://github.com/su2code/SU2/pull/631#issuecomment-455422968:250,Testability,Test,TestCases,250,"Hi @aeroamit . Sure. Please see this link: https://su2code.github.io/docs/Gitting-Started/. Basically, you need to modify the python regression files in order to add your new test case. Also, you need to upload the grid in https://github.com/su2code/TestCases, you can create a branch for that. Lastly, update .travis.yml but don't forget to revert it before merge. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-455422968
https://github.com/su2code/SU2/pull/631#issuecomment-456556642:311,Availability,error,error,311,"Hi @EduardoMolina. I have 1- created a folder and added a .cfg file (TestCases/euler/bluntbody/blunt.cfg) 2- added details in serial as well as parallel_regression.py 3- Added the mesh TestCases/euler/bluntbody/blunt_91.su2 in online repository (merged with develop branch). Now Travis CI is throwing following error- ; Traceback (most recent call last):; File ""serial_regression.py"", line 1403, in <module>; main(); File ""serial_regression.py"", line 129, in main; test_list.append(bluntbody); NameError: global name 'bluntbody' is not defined; The command ""python $TEST_SCRIPT"" exited with 1. (In parallel_regression as well); (I missed out some small changes??). Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-456556642
https://github.com/su2code/SU2/pull/631#issuecomment-456556642:69,Testability,Test,TestCases,69,"Hi @EduardoMolina. I have 1- created a folder and added a .cfg file (TestCases/euler/bluntbody/blunt.cfg) 2- added details in serial as well as parallel_regression.py 3- Added the mesh TestCases/euler/bluntbody/blunt_91.su2 in online repository (merged with develop branch). Now Travis CI is throwing following error- ; Traceback (most recent call last):; File ""serial_regression.py"", line 1403, in <module>; main(); File ""serial_regression.py"", line 129, in main; test_list.append(bluntbody); NameError: global name 'bluntbody' is not defined; The command ""python $TEST_SCRIPT"" exited with 1. (In parallel_regression as well); (I missed out some small changes??). Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-456556642
https://github.com/su2code/SU2/pull/631#issuecomment-456556642:185,Testability,Test,TestCases,185,"Hi @EduardoMolina. I have 1- created a folder and added a .cfg file (TestCases/euler/bluntbody/blunt.cfg) 2- added details in serial as well as parallel_regression.py 3- Added the mesh TestCases/euler/bluntbody/blunt_91.su2 in online repository (merged with develop branch). Now Travis CI is throwing following error- ; Traceback (most recent call last):; File ""serial_regression.py"", line 1403, in <module>; main(); File ""serial_regression.py"", line 129, in main; test_list.append(bluntbody); NameError: global name 'bluntbody' is not defined; The command ""python $TEST_SCRIPT"" exited with 1. (In parallel_regression as well); (I missed out some small changes??). Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-456556642
https://github.com/su2code/SU2/pull/631#issuecomment-457849144:99,Testability,Test,TestCases,99,"Hi @aeroamit ,. It seems you added the grid to your own fork instead of https://github.com/su2code/TestCases/tree/develop. This is the reason travis CI didn't find your grid and is hanging. Please submit a PR also for the test case. Please let me know if you need further help. Happy weekend!. Thanks; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-457849144
https://github.com/su2code/SU2/pull/631#issuecomment-457849144:222,Testability,test,test,222,"Hi @aeroamit ,. It seems you added the grid to your own fork instead of https://github.com/su2code/TestCases/tree/develop. This is the reason travis CI didn't find your grid and is hanging. Please submit a PR also for the test case. Please let me know if you need further help. Happy weekend!. Thanks; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-457849144
https://github.com/su2code/SU2/pull/631#issuecomment-458291038:40,Testability,Test,Testcase,40,Hi @EduardoMolina. Submitted the PR for Testcase (mesh file); Thanks; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-458291038
https://github.com/su2code/SU2/pull/631#issuecomment-458695640:8,Deployability,update,update,8,Can you update this branch to develop? I think now Travis will run fine. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-458695640
https://github.com/su2code/SU2/pull/631#issuecomment-460078452:75,Testability,test,tests,75,Hi @EduardoMolina @aeroamit : I think it is running now. I don't think the tests could execute because the travis file was pointing to a branch in an external fork. I have reverted it to develop.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-460078452
https://github.com/su2code/SU2/pull/631#issuecomment-460093192:84,Testability,test,test,84,Thanks @economon .... @aeroamit : Can you please check the values of the blunt body test case? I think the test case you added failed. Best.; Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-460093192
https://github.com/su2code/SU2/pull/631#issuecomment-460093192:107,Testability,test,test,107,Thanks @economon .... @aeroamit : Can you please check the values of the blunt body test case? I think the test case you added failed. Best.; Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-460093192
https://github.com/su2code/SU2/pull/631#issuecomment-460435706:73,Deployability,update,update,73,"Hi @aeroamit, . Please revert back *.travis.yml to su2code mail list and update to develop....; Once all checks passed again, I will merge it ASAP. Thanks,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/631#issuecomment-460435706
https://github.com/su2code/SU2/pull/633#issuecomment-455978636:66,Usability,clear,clearer,66,"Hi @talbring,; thanks for this, I think it makes the output a lot clearer. ; We should merge this in soon, and open a discussion on how to improve the screen output, not only in terms of the residual convergence (I know you have been working hard on that and it's looking great) but also on the initial print-out, which is currently very chunky and not so easy to add new options to.; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/633#issuecomment-455978636
https://github.com/su2code/SU2/pull/637#issuecomment-460937949:112,Testability,test,tests,112,"Thanks @economon for the fix, this is a small one, if there are no further comments I'll get it merged when the tests pass.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/637#issuecomment-460937949
https://github.com/su2code/SU2/pull/638#issuecomment-459389510:323,Testability,test,tests,323,"Thanks Ruben, everything looks good to me.; It is a nice clean up and the implementation of the added capabilities is aligned to what we already have, so I don't see any issue with merging this in.; I just had a minor comment but it is just about a coding style preferences.; We can merge this in as soon as the regression tests pass. Giulio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/638#issuecomment-459389510
https://github.com/su2code/SU2/pull/638#issuecomment-460218066:0,Testability,Test,Tests,0,"Tests are passing, so if there are no further comments I'll merge this one in. I'll further tackle driver generalisation in PRs to come.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/638#issuecomment-460218066
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:35,Availability,error,error,35,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:73,Availability,error,error,73,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:648,Availability,error,error,648,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:755,Availability,error,error,755,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:981,Availability,ERROR,ERROR,981,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:1288,Availability,error,error,1288,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:1061,Integrability,wrap,wrapper,1061,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:1165,Integrability,wrap,wrapper,1165,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:1339,Integrability,interface,interfaces,1339,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:1402,Integrability,interface,interfaces,1402,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:505,Modifiability,coupling,coupling,505,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:1501,Modifiability,config,config,1501,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/642#issuecomment-548054290:583,Testability,TEST,TESTER,583,"Hi, Komahan, ; I also noticed this error in fsi_computation.py. And this error was fixed by adding a periodic boundary condition. For example: ; Adding one line in parser part:; `parser.add_option(""--periodic"", dest=""periodic"", default=""False"", help=""Define whether the problem has periodic boundary conditions"", metavar=""PERIODIC""); `; And the Line 109 changes to; ` FluidSolver = pysu2.CFluidDriver(CFD_ConFile, 1, FSI_config['NDIM'], options.periodic, comm)`. However, when I want to run the basic fsi coupling of two-dimensional pitching-plunging NACA 0012 airfoil by using the 'TESTER' CSD Solver 'PitchPlungeAirfoilStructuralTester', another error occurs. If I run by typing:; `fsi_computation.py -f FSICoupler_config.cfg`; This gives the following error:; `***************************** Initializing fluid solver *****************************; ('A TypeError occured in pysu2.CSingleZoneDriver : ', TypeError(""in method 'new_CFluidDriver', argument 5 of type 'SU2_Comm'"",)); ERROR : You are trying to launch a computation without initializing MPI but the wrapper has been built in parallel. Please add the --parallel option in order to initialize MPI for the wrapper.; `. If I run in parallel by typing:; 'fsi_computation.py -f FSICoupler_config.cfg --parallel'; This works without error but the program stops at Mapping fluid-solid interfaces; `***************************** Mapping fluid-solid interfaces *****************************; Building interpolation matrices...; `. Here I upload the config files and the mesh, hope someone can notice those bugs and help to solve. Best!. [2d_coupled_fsi.zip](https://github.com/su2code/SU2/files/3790605/2d_coupled_fsi.zip); includes:; FSICoupler_config.cfg, NACA0012RANS_FullHexa.su2, StructuralTester_config.cfg, SU2_config.cfg",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/642#issuecomment-548054290
https://github.com/su2code/SU2/issues/643#issuecomment-459562945:493,Performance,scalab,scalable-linear-solvers-multigrid-methods,493,"@EduardoMolina and I have discussed this over the past few weeks and are also in favor of using an external library. I don't have a strong opinion on the library we choose, but he seems to be in favor of [PETSc](https://www.mcs.anl.gov/petsc/) from ANL, which has a 2-clause BSD license and is used by ADflow (formerly SUmb), among other solvers. Eduardo could probably provide more details. Another one that's come up in our discussions is [HYPRE](https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods) from LLNL which has a GNU LGPL.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459562945
https://github.com/su2code/SU2/issues/643#issuecomment-459566859:180,Integrability,rout,routines,180,"All,. I would agree that we need to look at an existing library and not re-develop one. The standard for dense linear algebra is LAPACK. It has been around forever, relies on BLAS routines, is currently being used in the SU2 higher-order DG-FEM solver. Various computer vendors (including GPU manufacturers) have spent many years optimizing BLAS and LAPACK calls on their own computer architectures. This means that your code is (a) portable and, by linking to the appropriate vendor-provided version of the library (say like Intels MKL), (b) you get highest performance. I am not familiar with Eigen (just looked at the web page), but there is an interesting comparison between Eigen and LAPACK (written by the developers of Eigentake it with a grain of salt) here<http://eigen.tuxfamily.org/index.php?title=FAQ#How_does_Eigen_compare_to_BLAS.2FLAPACK.3F>. If all they say is true, then Eigen would be a very good choice. If it is a bit exaggerated, then maybe LAPACK is better. Does anyone have experience with Eigen? Are there any reasons why LAPACK is better? Can the folks involved in FV and DG-FEM solvers talk to each other before making a decision?. While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense.but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). Best,. Juan. On Jan 31, 2019, at 4:43 PM, Brian Mungua <notifications@github.com<mailto:notifications@github.com>> wrote:. @EduardoMolina<https://github.com/EduardoMolina> and I have discussed this over the past few weeks and are also in favor of using an external library. I don't have a strong opinion on the library we choose, but he seems to be in favor of PETSc<https://www.mcs.anl.gov/p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459566859
https://github.com/su2code/SU2/issues/643#issuecomment-459566859:433,Modifiability,portab,portable,433,"All,. I would agree that we need to look at an existing library and not re-develop one. The standard for dense linear algebra is LAPACK. It has been around forever, relies on BLAS routines, is currently being used in the SU2 higher-order DG-FEM solver. Various computer vendors (including GPU manufacturers) have spent many years optimizing BLAS and LAPACK calls on their own computer architectures. This means that your code is (a) portable and, by linking to the appropriate vendor-provided version of the library (say like Intels MKL), (b) you get highest performance. I am not familiar with Eigen (just looked at the web page), but there is an interesting comparison between Eigen and LAPACK (written by the developers of Eigentake it with a grain of salt) here<http://eigen.tuxfamily.org/index.php?title=FAQ#How_does_Eigen_compare_to_BLAS.2FLAPACK.3F>. If all they say is true, then Eigen would be a very good choice. If it is a bit exaggerated, then maybe LAPACK is better. Does anyone have experience with Eigen? Are there any reasons why LAPACK is better? Can the folks involved in FV and DG-FEM solvers talk to each other before making a decision?. While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense.but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). Best,. Juan. On Jan 31, 2019, at 4:43 PM, Brian Mungua <notifications@github.com<mailto:notifications@github.com>> wrote:. @EduardoMolina<https://github.com/EduardoMolina> and I have discussed this over the past few weeks and are also in favor of using an external library. I don't have a strong opinion on the library we choose, but he seems to be in favor of PETSc<https://www.mcs.anl.gov/p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459566859
https://github.com/su2code/SU2/issues/643#issuecomment-459566859:330,Performance,optimiz,optimizing,330,"All,. I would agree that we need to look at an existing library and not re-develop one. The standard for dense linear algebra is LAPACK. It has been around forever, relies on BLAS routines, is currently being used in the SU2 higher-order DG-FEM solver. Various computer vendors (including GPU manufacturers) have spent many years optimizing BLAS and LAPACK calls on their own computer architectures. This means that your code is (a) portable and, by linking to the appropriate vendor-provided version of the library (say like Intels MKL), (b) you get highest performance. I am not familiar with Eigen (just looked at the web page), but there is an interesting comparison between Eigen and LAPACK (written by the developers of Eigentake it with a grain of salt) here<http://eigen.tuxfamily.org/index.php?title=FAQ#How_does_Eigen_compare_to_BLAS.2FLAPACK.3F>. If all they say is true, then Eigen would be a very good choice. If it is a bit exaggerated, then maybe LAPACK is better. Does anyone have experience with Eigen? Are there any reasons why LAPACK is better? Can the folks involved in FV and DG-FEM solvers talk to each other before making a decision?. While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense.but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). Best,. Juan. On Jan 31, 2019, at 4:43 PM, Brian Mungua <notifications@github.com<mailto:notifications@github.com>> wrote:. @EduardoMolina<https://github.com/EduardoMolina> and I have discussed this over the past few weeks and are also in favor of using an external library. I don't have a strong opinion on the library we choose, but he seems to be in favor of PETSc<https://www.mcs.anl.gov/p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459566859
https://github.com/su2code/SU2/issues/643#issuecomment-459566859:560,Performance,perform,performance,560,"All,. I would agree that we need to look at an existing library and not re-develop one. The standard for dense linear algebra is LAPACK. It has been around forever, relies on BLAS routines, is currently being used in the SU2 higher-order DG-FEM solver. Various computer vendors (including GPU manufacturers) have spent many years optimizing BLAS and LAPACK calls on their own computer architectures. This means that your code is (a) portable and, by linking to the appropriate vendor-provided version of the library (say like Intels MKL), (b) you get highest performance. I am not familiar with Eigen (just looked at the web page), but there is an interesting comparison between Eigen and LAPACK (written by the developers of Eigentake it with a grain of salt) here<http://eigen.tuxfamily.org/index.php?title=FAQ#How_does_Eigen_compare_to_BLAS.2FLAPACK.3F>. If all they say is true, then Eigen would be a very good choice. If it is a bit exaggerated, then maybe LAPACK is better. Does anyone have experience with Eigen? Are there any reasons why LAPACK is better? Can the folks involved in FV and DG-FEM solvers talk to each other before making a decision?. While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense.but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). Best,. Juan. On Jan 31, 2019, at 4:43 PM, Brian Mungua <notifications@github.com<mailto:notifications@github.com>> wrote:. @EduardoMolina<https://github.com/EduardoMolina> and I have discussed this over the past few weeks and are also in favor of using an external library. I don't have a strong opinion on the library we choose, but he seems to be in favor of PETSc<https://www.mcs.anl.gov/p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459566859
https://github.com/su2code/SU2/issues/643#issuecomment-459566859:2255,Performance,scalab,scalable-linear-solvers-multigrid-methods,2255,"here is an interesting comparison between Eigen and LAPACK (written by the developers of Eigentake it with a grain of salt) here<http://eigen.tuxfamily.org/index.php?title=FAQ#How_does_Eigen_compare_to_BLAS.2FLAPACK.3F>. If all they say is true, then Eigen would be a very good choice. If it is a bit exaggerated, then maybe LAPACK is better. Does anyone have experience with Eigen? Are there any reasons why LAPACK is better? Can the folks involved in FV and DG-FEM solvers talk to each other before making a decision?. While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense.but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). Best,. Juan. On Jan 31, 2019, at 4:43 PM, Brian Mungua <notifications@github.com<mailto:notifications@github.com>> wrote:. @EduardoMolina<https://github.com/EduardoMolina> and I have discussed this over the past few weeks and are also in favor of using an external library. I don't have a strong opinion on the library we choose, but he seems to be in favor of PETSc<https://www.mcs.anl.gov/petsc/> from ANL, which has a 2-clause BSD license and is used by ADflow (formerly SUmb), among other solvers. Eduardo could probably provide more details. Another one that's come up in our discussions is HYPRE<https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods> from LLNL which has a GNU LGPL. ; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459562945>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxJH0ySGyxvngq-G9YuG-H1HbBcYFks5vI42qgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459566859
https://github.com/su2code/SU2/issues/643#issuecomment-459613905:152,Modifiability,portab,portability,152,"Hi; I also support external libraries usage (no need to repeat the many advantages as it is well described above) but I think we should be very wary of portability issues. For instance in SUMB, PETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. Reading what I wrote, sounds to me a bit like the concept of the old conservative, trying to hold back the young diligent revolutionaries. I don't like to be in this spot, but still...; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459613905
https://github.com/su2code/SU2/issues/643#issuecomment-459621000:131,Performance,optimiz,optimized,131,"@pcarruscag, could you give some more details what kind of dense matrix functionalities you would like to add? There is already an optimized implementation using the Intel MKL library (I know this is not open source, but developers can use it freely) and as Juan mentioned the DG-FEM solver also uses quite a bit of dense matrix functionality. One thing you have to realize though is that the whole enchilada has to work as well for the discrete adjoint solver. This means that no matter what external libraries you choose, you have to come up with your own functionality that works for the types used by CoDiPack. @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well....",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459621000
https://github.com/su2code/SU2/issues/643#issuecomment-459622513:127,Integrability,interface,interface,127,"Sign me up for the old folks team. If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. Otherwise, I agree that reusing the DG hooks would save you some implementation time for dense operations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459622513
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:486,Deployability,integrat,integration,486,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:132,Integrability,rout,routines,132,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:486,Integrability,integrat,integration,486,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:740,Integrability,rout,routines,740,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:918,Integrability,rout,routines,918,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1905,Integrability,rout,routines,1905," feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclai",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1978,Integrability,interface,interface,1978,"ares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:2186,Integrability,rout,routines,2186,"implified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebra library (that is compatible with AD) would greatly simplify our work and further drop the entry barrier to new developers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:2367,Integrability,rout,routines,2367,"implified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebra library (that is compatible with AD) would greatly simplify our work and further drop the entry barrier to new developers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1257,Modifiability,refactor,refactoring,1257,"(Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:2229,Modifiability,portab,portable,2229,"implified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebra library (that is compatible with AD) would greatly simplify our work and further drop the entry barrier to new developers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1157,Performance,optimiz,optimized,1157,"(Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:397,Security,access,access,397,"(I was not expecting this many comments so quickly, thanks guys!). First let me clarify the intent.; I do not propose replacing the routines that deal with CSysMatrix, or change its format, all that (Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulat",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:2113,Security,access,access,2113,"e could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebra library (that is compatible with AD) would greatly simplify our work and further drop the entry barrier to new",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1144,Usability,simpl,simplified,1144,"(Krylov solvers, sparse approximate factorizations, etc.) is relatively independent from what I have in mind.; Nevertheless being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD.; What I would like is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1428,Usability,simpl,simply,1428," is to have a ""CMatrixDense"" class, to give concrete examples:; - For RBF interpolation the guy who worked on it before me implemented his own Cholesky and LU factorizations, matrix-matrix, matrix-vector routines, etc.; - @jayantmukho recently needed some eigenvector decomposition's for the uncertainty quantification feature.; - I imagine in some other places of the code similar routines were needed, for example small matrix inversion when computing gradients by weighted least squares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithme",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:1960,Usability,simpl,simplify,1960,"ares (indeed what I need now is a QR decomposition). And, as an added bonus, I think some other areas of the code could be simplified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459653772:3074,Usability,simpl,simplify,3074,"implified / optimized by adopting a dense matrix format, for example:; - This snipped from the viscous numerics refactoring`for (iDim = 0; iDim < nDim; iDim++) {; TauElem[iDim] = 0.0;; for (jDim = 0; jDim < nDim; jDim++); TauElem[iDim] += tau[iDim][jDim]*UnitNormal[jDim];; }` would simply become `TauElem=tau*UnitNormal`; - Cumbersome allocations like `tau_jacobian_i = new su2double* [nDim];; for (iDim = 0; iDim < nDim; iDim++) {; tau_jacobian_i[iDim] = new su2double [nVar];; }` become `Matrix tau_jacobian_i(nDim,nVar);` and the cleanup is dealt with by the destructor of the object automatically. Now to answer some questions.; @juanjosealonso @erangit LAPACK and BLAS are indeed the standard, so much so that most (all?) newer libraries will call their routines behind the scenes.; However they considerably simplify the user interface by encapsulating the aforementioned construction/destruction and by exposing natural ways of manipulating the matrices, e.g. access entire rows, columns, blocks, etc.; Another issue with using BLAS routines is that we then need to provide a portable version that can be differentiated with CoDi or to implement the exact differentiation (similar to what is done in the ""solve_b"" routines). @vdweide that is not an issue with Eigen because everything is templated and therefore compatible with any type or class that overloads the appropriate arithmetic operators.; I have used it for over 2 years and I can attest to its compatibility with AD tools (I've tried 3), and speed when linked with a BLAS library, their native implementations are also very good, peeking inside their code... you can tell they know what they are doing. P.S. I feel this post needs a disclaimer, I am not affiliated in any way to Eigen, my motivation is not to promote their work (but I obviously think they deserve it). I genuinely think adopting an algebra library (that is compatible with AD) would greatly simplify our work and further drop the entry barrier to new developers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459653772
https://github.com/su2code/SU2/issues/643#issuecomment-459656519:503,Availability,down,down,503,"Hi all,; really interesting topic going on here. As @pcarruscag just very well explained, and after quite some time working on the code, I can totally see the need for dense algebra. . I agree with @juanjosealonso and @erangit that maintaining the code portable and very easy to install should be a must. It has been a signature of SU2 since the beginning and we should continue on that line. I've had some problems before with codes that rely heavily on PETSc, so I wouldn't particularly be keen to go down that road. . **Eigen** would be really easy to integrate in SU2: they have a mirror on GitHub here: [Eigen Github repo](https://github.com/eigenteam/eigen-git-mirror) which could be easily added as a submodule in the same way as CoDiPack or MeDiPack. Given that they are only header files, there would be no need to compile any external library. And there is another very important point made by @vdweide and @pcarruscag: we need to ensure compatibility with the discrete adjoint functionality. One huge advantage of Eigen is that is fully templated: we recently differentiated a code that was heavy reliant on Eigen in an afternoon, and it worked great. While LAPACK is indeed a very mature library, I believe that it would require using external functions for every functionality, which would be a really big burden. @talbring @MaxSagebaum could add some more hints in this discussion. As an additional note, I would make sure that we keep everything open source.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459656519
https://github.com/su2code/SU2/issues/643#issuecomment-459656519:279,Deployability,install,install,279,"Hi all,; really interesting topic going on here. As @pcarruscag just very well explained, and after quite some time working on the code, I can totally see the need for dense algebra. . I agree with @juanjosealonso and @erangit that maintaining the code portable and very easy to install should be a must. It has been a signature of SU2 since the beginning and we should continue on that line. I've had some problems before with codes that rely heavily on PETSc, so I wouldn't particularly be keen to go down that road. . **Eigen** would be really easy to integrate in SU2: they have a mirror on GitHub here: [Eigen Github repo](https://github.com/eigenteam/eigen-git-mirror) which could be easily added as a submodule in the same way as CoDiPack or MeDiPack. Given that they are only header files, there would be no need to compile any external library. And there is another very important point made by @vdweide and @pcarruscag: we need to ensure compatibility with the discrete adjoint functionality. One huge advantage of Eigen is that is fully templated: we recently differentiated a code that was heavy reliant on Eigen in an afternoon, and it worked great. While LAPACK is indeed a very mature library, I believe that it would require using external functions for every functionality, which would be a really big burden. @talbring @MaxSagebaum could add some more hints in this discussion. As an additional note, I would make sure that we keep everything open source.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459656519
https://github.com/su2code/SU2/issues/643#issuecomment-459656519:555,Deployability,integrat,integrate,555,"Hi all,; really interesting topic going on here. As @pcarruscag just very well explained, and after quite some time working on the code, I can totally see the need for dense algebra. . I agree with @juanjosealonso and @erangit that maintaining the code portable and very easy to install should be a must. It has been a signature of SU2 since the beginning and we should continue on that line. I've had some problems before with codes that rely heavily on PETSc, so I wouldn't particularly be keen to go down that road. . **Eigen** would be really easy to integrate in SU2: they have a mirror on GitHub here: [Eigen Github repo](https://github.com/eigenteam/eigen-git-mirror) which could be easily added as a submodule in the same way as CoDiPack or MeDiPack. Given that they are only header files, there would be no need to compile any external library. And there is another very important point made by @vdweide and @pcarruscag: we need to ensure compatibility with the discrete adjoint functionality. One huge advantage of Eigen is that is fully templated: we recently differentiated a code that was heavy reliant on Eigen in an afternoon, and it worked great. While LAPACK is indeed a very mature library, I believe that it would require using external functions for every functionality, which would be a really big burden. @talbring @MaxSagebaum could add some more hints in this discussion. As an additional note, I would make sure that we keep everything open source.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459656519
https://github.com/su2code/SU2/issues/643#issuecomment-459656519:555,Integrability,integrat,integrate,555,"Hi all,; really interesting topic going on here. As @pcarruscag just very well explained, and after quite some time working on the code, I can totally see the need for dense algebra. . I agree with @juanjosealonso and @erangit that maintaining the code portable and very easy to install should be a must. It has been a signature of SU2 since the beginning and we should continue on that line. I've had some problems before with codes that rely heavily on PETSc, so I wouldn't particularly be keen to go down that road. . **Eigen** would be really easy to integrate in SU2: they have a mirror on GitHub here: [Eigen Github repo](https://github.com/eigenteam/eigen-git-mirror) which could be easily added as a submodule in the same way as CoDiPack or MeDiPack. Given that they are only header files, there would be no need to compile any external library. And there is another very important point made by @vdweide and @pcarruscag: we need to ensure compatibility with the discrete adjoint functionality. One huge advantage of Eigen is that is fully templated: we recently differentiated a code that was heavy reliant on Eigen in an afternoon, and it worked great. While LAPACK is indeed a very mature library, I believe that it would require using external functions for every functionality, which would be a really big burden. @talbring @MaxSagebaum could add some more hints in this discussion. As an additional note, I would make sure that we keep everything open source.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459656519
https://github.com/su2code/SU2/issues/643#issuecomment-459656519:253,Modifiability,portab,portable,253,"Hi all,; really interesting topic going on here. As @pcarruscag just very well explained, and after quite some time working on the code, I can totally see the need for dense algebra. . I agree with @juanjosealonso and @erangit that maintaining the code portable and very easy to install should be a must. It has been a signature of SU2 since the beginning and we should continue on that line. I've had some problems before with codes that rely heavily on PETSc, so I wouldn't particularly be keen to go down that road. . **Eigen** would be really easy to integrate in SU2: they have a mirror on GitHub here: [Eigen Github repo](https://github.com/eigenteam/eigen-git-mirror) which could be easily added as a submodule in the same way as CoDiPack or MeDiPack. Given that they are only header files, there would be no need to compile any external library. And there is another very important point made by @vdweide and @pcarruscag: we need to ensure compatibility with the discrete adjoint functionality. One huge advantage of Eigen is that is fully templated: we recently differentiated a code that was heavy reliant on Eigen in an afternoon, and it worked great. While LAPACK is indeed a very mature library, I believe that it would require using external functions for every functionality, which would be a really big burden. @talbring @MaxSagebaum could add some more hints in this discussion. As an additional note, I would make sure that we keep everything open source.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459656519
https://github.com/su2code/SU2/issues/643#issuecomment-459705131:135,Performance,perform,performance,135,Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459705131
https://github.com/su2code/SU2/issues/643#issuecomment-459705131:42,Testability,test,test,42,Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459705131
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:564,Integrability,rout,routines,564,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:748,Integrability,interface,interface,748,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:57,Performance,perform,performance,57,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:140,Performance,tune,tuned,140,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:539,Performance,perform,performance,539,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:1042,Performance,perform,performance,1042,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:769,Security,expose,exposes,769,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:454,Testability,test,test,454,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:530,Testability,test,test,530,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:949,Testability,test,test,949,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459845576:323,Usability,simpl,simplify,323,"All,. I looked a bit more through Eigen and, indeed, the performance is pretty impressive and generally better than MKL and Atlas (the self-tuned implementation of LAPACK) ant most/all matrix sizes. I agree with comments made by @pcarruscg that having a standard for matrix operations throughout the source would clean up /simplify the code considerably and, since it does not seem to impact the AD approach, it should be pursued. It sounds like a quick test branch like @vdweide is suggesting makes sense. A quick driver code to test the performance of the Eigen routines vs MKL makes sense too. The only thing that @vdweide should comment on is how much work it would be to change the LAPACK/BLAS based implementation in the DG-FEM solver to the interface that Eigen exposes. Best,. Juan. On Feb 1, 2019, at 4:19 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. Would it be an idea to create a branch to test things out and make a decision based on the results? It would be interesting to see the performance for e.g. the dense matrix multiplications in the DG-solver compared to Intel's MKL. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459705131>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxM1gm0iy_FeGBMFzxVQnYFFzEHt4ks5vJDDlgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459845576
https://github.com/su2code/SU2/issues/643#issuecomment-459864800:19,Performance,perform,performance,19,"From my experience performance will not be better than current MKL, unless the matrices in question are small and their sizes known at compile time.; The selling point is not speed vs MKL, is that you get the same speed (if using a BLAS backend) plus the syntactic sugar, plus compatibility with any data type.; The DG solver is probably one of the most optimized parts of SU2 so I doubt it would gain any performance.; Since there seems to be interest I will try to ""port"" one of the fluid numerics classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459864800
https://github.com/su2code/SU2/issues/643#issuecomment-459864800:354,Performance,optimiz,optimized,354,"From my experience performance will not be better than current MKL, unless the matrices in question are small and their sizes known at compile time.; The selling point is not speed vs MKL, is that you get the same speed (if using a BLAS backend) plus the syntactic sugar, plus compatibility with any data type.; The DG solver is probably one of the most optimized parts of SU2 so I doubt it would gain any performance.; Since there seems to be interest I will try to ""port"" one of the fluid numerics classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459864800
https://github.com/su2code/SU2/issues/643#issuecomment-459864800:406,Performance,perform,performance,406,"From my experience performance will not be better than current MKL, unless the matrices in question are small and their sizes known at compile time.; The selling point is not speed vs MKL, is that you get the same speed (if using a BLAS backend) plus the syntactic sugar, plus compatibility with any data type.; The DG solver is probably one of the most optimized parts of SU2 so I doubt it would gain any performance.; Since there seems to be interest I will try to ""port"" one of the fluid numerics classes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459864800
https://github.com/su2code/SU2/issues/643#issuecomment-459943384:255,Performance,perform,performance,255,"In the lab we are also writing/rewriting another largish solver with eigen (https://ic-sharpy.rtfd.io/). A major advantage (and, I think, critical for open source) was code readability to ease the learning curve for newcomers, with no reported penalty on performance. I second all the other nice things about it written by @pcarruscag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459943384
https://github.com/su2code/SU2/issues/643#issuecomment-459943384:197,Usability,learn,learning,197,"In the lab we are also writing/rewriting another largish solver with eigen (https://ic-sharpy.rtfd.io/). A major advantage (and, I think, critical for open source) was code readability to ease the learning curve for newcomers, with no reported penalty on performance. I second all the other nice things about it written by @pcarruscag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459943384
https://github.com/su2code/SU2/issues/643#issuecomment-459952137:836,Availability,down,downloaded,836,"@pcarruscag, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). . For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459952137
https://github.com/su2code/SU2/issues/643#issuecomment-459952137:661,Integrability,rout,routines,661,"@pcarruscag, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). . For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459952137
https://github.com/su2code/SU2/issues/643#issuecomment-459952137:163,Performance,perform,performance,163,"@pcarruscag, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). . For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459952137
https://github.com/su2code/SU2/issues/643#issuecomment-459952137:254,Performance,perform,performance,254,"@pcarruscag, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). . For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459952137
https://github.com/su2code/SU2/issues/643#issuecomment-459952137:560,Testability,test,test,560,"@pcarruscag, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). . For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459952137
https://github.com/su2code/SU2/issues/643#issuecomment-459952137:748,Testability,test,test,748,"@pcarruscag, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). . For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459952137
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:1489,Availability,down,downloaded,1489,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:1283,Integrability,rout,routines,1283,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:29,Performance,perform,performance,29,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:206,Performance,perform,performance,206,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:285,Performance,perform,performance,285,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:758,Performance,perform,performance,758,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:849,Performance,perform,performance,849,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:133,Testability,Benchmark,Benchmark,133,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:297,Testability,test,tests,297,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:1153,Testability,test,test,1153,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:1370,Testability,test,test,1370,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-459986613:317,Usability,simpl,simple,317,"All,. The following page has performance comparisons between eigen and mkl (and others):. http://eigen.tuxfamily.org/index.php?title=Benchmark. They are dated 2011, so they are a bit old, but if the quoted performance is real, I would say it is a no-brainer to switch to eigen. If the performance tests (for at least simple things like daxpy and gemm) could be repeated to verify the numbers, that would help us make a final decision. Best,. Juan. On Feb 2, 2019, at 1:58 AM, Edwin van der Weide <notifications@github.com<mailto:notifications@github.com>> wrote:. @pcarruscag<https://github.com/pcarruscag>, I agree with you it will be hard to beat the MKL (running at 60 percent peak for most of the gemm calls for the DG-solver), but if you don't have any performance loss, that would already be nice, as it improves readability. Furthermore, the performance of the DG solver in combination with the discrete adjoint is horrible, because it relies on my very naive implementation of the matrix products. So it would already be something if we can get an improvement there, although we do not use the DG adjoint solver (yet). For me the easiest way to test things out for the DG-solver would actually be in SU2 itself. @economon<https://github.com/economon> put some nice profiling routines in there for the gemm calls, which can be used without any additional work to test eigen. @pcarruscag<https://github.com/pcarruscag> (or somebody else), could you create a branch in which eigen is downloaded in the external directory? I think I can manage from there. Thanks,. Edwin. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-459952137>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxCgydwy1nS3qPJvyCMJXLXWNMSFsks5vJWEkgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-459986613
https://github.com/su2code/SU2/issues/643#issuecomment-460055024:23,Deployability,configurat,configuration,23,"@vdweide, I hacked the configuration scripts to clone Eigen into externals and added the required search paths and flags in configure.ac. I also put an include in blas_structure just to test and looks ok.; I suggest we both work on this branch (feature_test_eigen) and create a PR once we have a ""demo"" working.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460055024
https://github.com/su2code/SU2/issues/643#issuecomment-460055024:23,Modifiability,config,configuration,23,"@vdweide, I hacked the configuration scripts to clone Eigen into externals and added the required search paths and flags in configure.ac. I also put an include in blas_structure just to test and looks ok.; I suggest we both work on this branch (feature_test_eigen) and create a PR once we have a ""demo"" working.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460055024
https://github.com/su2code/SU2/issues/643#issuecomment-460055024:124,Modifiability,config,configure,124,"@vdweide, I hacked the configuration scripts to clone Eigen into externals and added the required search paths and flags in configure.ac. I also put an include in blas_structure just to test and looks ok.; I suggest we both work on this branch (feature_test_eigen) and create a PR once we have a ""demo"" working.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460055024
https://github.com/su2code/SU2/issues/643#issuecomment-460055024:186,Testability,test,test,186,"@vdweide, I hacked the configuration scripts to clone Eigen into externals and added the required search paths and flags in configure.ac. I also put an include in blas_structure just to test and looks ok.; I suggest we both work on this branch (feature_test_eigen) and create a PR once we have a ""demo"" working.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460055024
https://github.com/su2code/SU2/issues/643#issuecomment-460092205:80,Performance,perform,performance,80,"Thanks, I hope I can run some tests in the next couple of weeks and compare the performance with other implementations, especially MKL, because this gives the fastest results at the moment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460092205
https://github.com/su2code/SU2/issues/643#issuecomment-460092205:30,Testability,test,tests,30,"Thanks, I hope I can run some tests in the next couple of weeks and compare the performance with other implementations, especially MKL, because this gives the fastest results at the moment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460092205
https://github.com/su2code/SU2/issues/643#issuecomment-460479862:451,Performance,perform,performance,451,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862
https://github.com/su2code/SU2/issues/643#issuecomment-460479862:53,Testability,test,test,53,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862
https://github.com/su2code/SU2/issues/643#issuecomment-460479862:490,Testability,test,test,490,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862
https://github.com/su2code/SU2/issues/643#issuecomment-460479862:323,Usability,feedback,feedback,323,"Hi @pcarruscag and @vdweide ,. Thanks for creating a test branch and for bringing this discussion. When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2. ; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. ; I will be happy to help test Eigen and see if it is a good candidate. Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460479862
https://github.com/su2code/SU2/issues/643#issuecomment-460666656:124,Usability,simpl,simply,124,"Hi @EduardoMolina,. That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. However Eigen is not the tool for that as the sparse linear solvers it has are similar and are not distributed parallel.; When I opened this issue I was thinking exclusively about how we handle small-medium dense matrices that live on a single rank, and associated algorithms (the kind used for RBF interpolation for example).; I think the two issues are fairly orthogonal, so we can open another to discuss large solvers, for which related work has already been started. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460666656
https://github.com/su2code/SU2/issues/643#issuecomment-460671586:119,Modifiability,variab,variables,119,"All,; If you have a look at ""feature_test_eigen"", I ""ported"" the JST ComputeResidual method.; I only changed the local variables of the method, so some temporaries are required to make things compatible with the outside world and with base class variables. Nevertheless, the performance is not worse (direct and discrete adjoint) and I think it reads better, but that is subjective.; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460671586
https://github.com/su2code/SU2/issues/643#issuecomment-460671586:246,Modifiability,variab,variables,246,"All,; If you have a look at ""feature_test_eigen"", I ""ported"" the JST ComputeResidual method.; I only changed the local variables of the method, so some temporaries are required to make things compatible with the outside world and with base class variables. Nevertheless, the performance is not worse (direct and discrete adjoint) and I think it reads better, but that is subjective.; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460671586
https://github.com/su2code/SU2/issues/643#issuecomment-460671586:275,Performance,perform,performance,275,"All,; If you have a look at ""feature_test_eigen"", I ""ported"" the JST ComputeResidual method.; I only changed the local variables of the method, so some temporaries are required to make things compatible with the outside world and with base class variables. Nevertheless, the performance is not worse (direct and discrete adjoint) and I think it reads better, but that is subjective.; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460671586
https://github.com/su2code/SU2/issues/643#issuecomment-460714752:105,Performance,perform,performance,105,"Folks,. Perhaps we can split this issue to a separate thread. But it is indeed a critical one. Improving performance of the solver (or trying other preconditioned solvers) would be a significant improvement amortized over a very large number of users. Add it as a topic of discussion for the Annual Meeting in May?. Juan. On Feb 5, 2019, at 6:54 AM, pcarruscag <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @EduardoMolina<https://github.com/EduardoMolina>,. That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. However Eigen is not the tool for that as the sparse linear solvers it has are similar and are not distributed parallel.; When I opened this issue I was thinking exclusively about how we handle small-medium dense matrices that live on a single rank, and associated algorithms (the kind used for RBF interpolation for example).; I think the two issues are fairly orthogonal, so we can open another to discuss large solvers, for which related work has already been started. Cheers,; Pedro. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-460666656>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxClv7-iTk5lFN9sK4fkqM7lk0FZEks5vKZsPgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460714752
https://github.com/su2code/SU2/issues/643#issuecomment-460714752:587,Usability,simpl,simply,587,"Folks,. Perhaps we can split this issue to a separate thread. But it is indeed a critical one. Improving performance of the solver (or trying other preconditioned solvers) would be a significant improvement amortized over a very large number of users. Add it as a topic of discussion for the Annual Meeting in May?. Juan. On Feb 5, 2019, at 6:54 AM, pcarruscag <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @EduardoMolina<https://github.com/EduardoMolina>,. That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. However Eigen is not the tool for that as the sparse linear solvers it has are similar and are not distributed parallel.; When I opened this issue I was thinking exclusively about how we handle small-medium dense matrices that live on a single rank, and associated algorithms (the kind used for RBF interpolation for example).; I think the two issues are fairly orthogonal, so we can open another to discuss large solvers, for which related work has already been started. Cheers,; Pedro. ; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/643#issuecomment-460666656>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ADpSxClv7-iTk5lFN9sK4fkqM7lk0FZEks5vKZsPgaJpZM4adbAo>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460714752
https://github.com/su2code/SU2/issues/643#issuecomment-460811699:624,Availability,toler,tolerance,624,"Agreed that it is a bit different... . I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options. If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. Just some options to try - it is an important topic and it would be good to isolate the primary restriction.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460811699
https://github.com/su2code/SU2/issues/643#issuecomment-460811699:776,Performance,perform,performant,776,"Agreed that it is a bit different... . I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options. If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. Just some options to try - it is an important topic and it would be good to isolate the primary restriction.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460811699
https://github.com/su2code/SU2/issues/643#issuecomment-460811699:352,Testability,test,test,352,"Agreed that it is a bit different... . I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options. If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. Just some options to try - it is an important topic and it would be good to isolate the primary restriction.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-460811699
https://github.com/su2code/SU2/issues/643#issuecomment-462075284:279,Performance,perform,performance,279,"Folks,. I replaced the matrix multiplication in the DG solver (gemm in terms of BLAS) with the functionality provided by Eigen. It was very easy and it gives a very readable code. . I ran a couple of tests and, unfortunately, the preliminary conclusion is that you only get good performance if you let Eigen use an optimized BLAS implementation. In my case I used MKL. Compared to directly calling the MKL, there is an overhead of around 10 percent, which is still acceptable. However, if you do not use MKL and let Eigen do the matrix multiplication itself, the performance drops a factor of 7 for the test I carried out, which is a representative 3D test case. This factor is observed for both for the Intel and GNU compiler. It is still a factor 2 faster than my naive implementation though. So it looks like, at least for the DG solver, it is an absolute necessity to use an optimized BLAS implementation, unless there are some magic options in Eigen to make the gemm functionality faster. Using an optimized BLAS implementation in combination with Eigen is fine when doubles are used, i.e. when the solver is run in analysis mode. However, for the discrete adjoint solver the situation is a bit more complicated and we may have to come up with something better than just let Eigen handle the matrix multiplications. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462075284
https://github.com/su2code/SU2/issues/643#issuecomment-462075284:315,Performance,optimiz,optimized,315,"Folks,. I replaced the matrix multiplication in the DG solver (gemm in terms of BLAS) with the functionality provided by Eigen. It was very easy and it gives a very readable code. . I ran a couple of tests and, unfortunately, the preliminary conclusion is that you only get good performance if you let Eigen use an optimized BLAS implementation. In my case I used MKL. Compared to directly calling the MKL, there is an overhead of around 10 percent, which is still acceptable. However, if you do not use MKL and let Eigen do the matrix multiplication itself, the performance drops a factor of 7 for the test I carried out, which is a representative 3D test case. This factor is observed for both for the Intel and GNU compiler. It is still a factor 2 faster than my naive implementation though. So it looks like, at least for the DG solver, it is an absolute necessity to use an optimized BLAS implementation, unless there are some magic options in Eigen to make the gemm functionality faster. Using an optimized BLAS implementation in combination with Eigen is fine when doubles are used, i.e. when the solver is run in analysis mode. However, for the discrete adjoint solver the situation is a bit more complicated and we may have to come up with something better than just let Eigen handle the matrix multiplications. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462075284
https://github.com/su2code/SU2/issues/643#issuecomment-462075284:563,Performance,perform,performance,563,"Folks,. I replaced the matrix multiplication in the DG solver (gemm in terms of BLAS) with the functionality provided by Eigen. It was very easy and it gives a very readable code. . I ran a couple of tests and, unfortunately, the preliminary conclusion is that you only get good performance if you let Eigen use an optimized BLAS implementation. In my case I used MKL. Compared to directly calling the MKL, there is an overhead of around 10 percent, which is still acceptable. However, if you do not use MKL and let Eigen do the matrix multiplication itself, the performance drops a factor of 7 for the test I carried out, which is a representative 3D test case. This factor is observed for both for the Intel and GNU compiler. It is still a factor 2 faster than my naive implementation though. So it looks like, at least for the DG solver, it is an absolute necessity to use an optimized BLAS implementation, unless there are some magic options in Eigen to make the gemm functionality faster. Using an optimized BLAS implementation in combination with Eigen is fine when doubles are used, i.e. when the solver is run in analysis mode. However, for the discrete adjoint solver the situation is a bit more complicated and we may have to come up with something better than just let Eigen handle the matrix multiplications. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462075284
https://github.com/su2code/SU2/issues/643#issuecomment-462075284:879,Performance,optimiz,optimized,879,"Folks,. I replaced the matrix multiplication in the DG solver (gemm in terms of BLAS) with the functionality provided by Eigen. It was very easy and it gives a very readable code. . I ran a couple of tests and, unfortunately, the preliminary conclusion is that you only get good performance if you let Eigen use an optimized BLAS implementation. In my case I used MKL. Compared to directly calling the MKL, there is an overhead of around 10 percent, which is still acceptable. However, if you do not use MKL and let Eigen do the matrix multiplication itself, the performance drops a factor of 7 for the test I carried out, which is a representative 3D test case. This factor is observed for both for the Intel and GNU compiler. It is still a factor 2 faster than my naive implementation though. So it looks like, at least for the DG solver, it is an absolute necessity to use an optimized BLAS implementation, unless there are some magic options in Eigen to make the gemm functionality faster. Using an optimized BLAS implementation in combination with Eigen is fine when doubles are used, i.e. when the solver is run in analysis mode. However, for the discrete adjoint solver the situation is a bit more complicated and we may have to come up with something better than just let Eigen handle the matrix multiplications. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462075284
https://github.com/su2code/SU2/issues/643#issuecomment-462075284:1003,Performance,optimiz,optimized,1003,"Folks,. I replaced the matrix multiplication in the DG solver (gemm in terms of BLAS) with the functionality provided by Eigen. It was very easy and it gives a very readable code. . I ran a couple of tests and, unfortunately, the preliminary conclusion is that you only get good performance if you let Eigen use an optimized BLAS implementation. In my case I used MKL. Compared to directly calling the MKL, there is an overhead of around 10 percent, which is still acceptable. However, if you do not use MKL and let Eigen do the matrix multiplication itself, the performance drops a factor of 7 for the test I carried out, which is a representative 3D test case. This factor is observed for both for the Intel and GNU compiler. It is still a factor 2 faster than my naive implementation though. So it looks like, at least for the DG solver, it is an absolute necessity to use an optimized BLAS implementation, unless there are some magic options in Eigen to make the gemm functionality faster. Using an optimized BLAS implementation in combination with Eigen is fine when doubles are used, i.e. when the solver is run in analysis mode. However, for the discrete adjoint solver the situation is a bit more complicated and we may have to come up with something better than just let Eigen handle the matrix multiplications. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462075284
https://github.com/su2code/SU2/issues/643#issuecomment-462075284:200,Testability,test,tests,200,"Folks,. I replaced the matrix multiplication in the DG solver (gemm in terms of BLAS) with the functionality provided by Eigen. It was very easy and it gives a very readable code. . I ran a couple of tests and, unfortunately, the preliminary conclusion is that you only get good performance if you let Eigen use an optimized BLAS implementation. In my case I used MKL. Compared to directly calling the MKL, there is an overhead of around 10 percent, which is still acceptable. However, if you do not use MKL and let Eigen do the matrix multiplication itself, the performance drops a factor of 7 for the test I carried out, which is a representative 3D test case. This factor is observed for both for the Intel and GNU compiler. It is still a factor 2 faster than my naive implementation though. So it looks like, at least for the DG solver, it is an absolute necessity to use an optimized BLAS implementation, unless there are some magic options in Eigen to make the gemm functionality faster. Using an optimized BLAS implementation in combination with Eigen is fine when doubles are used, i.e. when the solver is run in analysis mode. However, for the discrete adjoint solver the situation is a bit more complicated and we may have to come up with something better than just let Eigen handle the matrix multiplications. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462075284
https://github.com/su2code/SU2/issues/643#issuecomment-462075284:603,Testability,test,test,603,"Folks,. I replaced the matrix multiplication in the DG solver (gemm in terms of BLAS) with the functionality provided by Eigen. It was very easy and it gives a very readable code. . I ran a couple of tests and, unfortunately, the preliminary conclusion is that you only get good performance if you let Eigen use an optimized BLAS implementation. In my case I used MKL. Compared to directly calling the MKL, there is an overhead of around 10 percent, which is still acceptable. However, if you do not use MKL and let Eigen do the matrix multiplication itself, the performance drops a factor of 7 for the test I carried out, which is a representative 3D test case. This factor is observed for both for the Intel and GNU compiler. It is still a factor 2 faster than my naive implementation though. So it looks like, at least for the DG solver, it is an absolute necessity to use an optimized BLAS implementation, unless there are some magic options in Eigen to make the gemm functionality faster. Using an optimized BLAS implementation in combination with Eigen is fine when doubles are used, i.e. when the solver is run in analysis mode. However, for the discrete adjoint solver the situation is a bit more complicated and we may have to come up with something better than just let Eigen handle the matrix multiplications. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462075284
https://github.com/su2code/SU2/issues/643#issuecomment-462075284:652,Testability,test,test,652,"Folks,. I replaced the matrix multiplication in the DG solver (gemm in terms of BLAS) with the functionality provided by Eigen. It was very easy and it gives a very readable code. . I ran a couple of tests and, unfortunately, the preliminary conclusion is that you only get good performance if you let Eigen use an optimized BLAS implementation. In my case I used MKL. Compared to directly calling the MKL, there is an overhead of around 10 percent, which is still acceptable. However, if you do not use MKL and let Eigen do the matrix multiplication itself, the performance drops a factor of 7 for the test I carried out, which is a representative 3D test case. This factor is observed for both for the Intel and GNU compiler. It is still a factor 2 faster than my naive implementation though. So it looks like, at least for the DG solver, it is an absolute necessity to use an optimized BLAS implementation, unless there are some magic options in Eigen to make the gemm functionality faster. Using an optimized BLAS implementation in combination with Eigen is fine when doubles are used, i.e. when the solver is run in analysis mode. However, for the discrete adjoint solver the situation is a bit more complicated and we may have to come up with something better than just let Eigen handle the matrix multiplications. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462075284
https://github.com/su2code/SU2/issues/643#issuecomment-462083402:281,Performance,optimiz,optimized,281,"Hi @vdweide,. Thank you for testing this out.; I had a look at the code and I think the overhead may be partly due to the multiplication function being compiled in one library and used in another. Which leaves little chance for some boiler plate code in the Eigen::Map class to be optimized way. If you share the test case and it fits in 16GB of ram I am happy to hack a bit and try to get those 10%.; As for Eigen beating MKL, like I said I never thought that would be the case, but out of curiosity what is the typical size of the matrices in the DG solver?. Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462083402
https://github.com/su2code/SU2/issues/643#issuecomment-462083402:28,Testability,test,testing,28,"Hi @vdweide,. Thank you for testing this out.; I had a look at the code and I think the overhead may be partly due to the multiplication function being compiled in one library and used in another. Which leaves little chance for some boiler plate code in the Eigen::Map class to be optimized way. If you share the test case and it fits in 16GB of ram I am happy to hack a bit and try to get those 10%.; As for Eigen beating MKL, like I said I never thought that would be the case, but out of curiosity what is the typical size of the matrices in the DG solver?. Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462083402
https://github.com/su2code/SU2/issues/643#issuecomment-462083402:313,Testability,test,test,313,"Hi @vdweide,. Thank you for testing this out.; I had a look at the code and I think the overhead may be partly due to the multiplication function being compiled in one library and used in another. Which leaves little chance for some boiler plate code in the Eigen::Map class to be optimized way. If you share the test case and it fits in 16GB of ram I am happy to hack a bit and try to get those 10%.; As for Eigen beating MKL, like I said I never thought that would be the case, but out of curiosity what is the typical size of the matrices in the DG solver?. Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462083402
https://github.com/su2code/SU2/issues/643#issuecomment-462245462:49,Availability,avail,available,49,"@pcarruscag . Of course I can make the test case available. Could you give me your email address, such that I can send you a link?; The typical size of the matrices is problem dependent. You can profile the gemm calls by adding the -DPROFILE flag to the compiler options. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462245462
https://github.com/su2code/SU2/issues/643#issuecomment-462245462:176,Integrability,depend,dependent,176,"@pcarruscag . Of course I can make the test case available. Could you give me your email address, such that I can send you a link?; The typical size of the matrices is problem dependent. You can profile the gemm calls by adding the -DPROFILE flag to the compiler options. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462245462
https://github.com/su2code/SU2/issues/643#issuecomment-462245462:39,Testability,test,test,39,"@pcarruscag . Of course I can make the test case available. Could you give me your email address, such that I can send you a link?; The typical size of the matrices is problem dependent. You can profile the gemm calls by adding the -DPROFILE flag to the compiler options. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462245462
https://github.com/su2code/SU2/issues/643#issuecomment-462272618:400,Availability,avail,available,400,"The adjoint handling of the Eigen library can actually be a two step process. In the first step we just use the BlackBox differentiation of Eigen. This will work for every user in the primal code and adjoint code. As a second step we would then look into the BLAS wrapper of Eigen and check if we can provide a special treatment for the adjoint aka CoDiPack version. In general there are two options available:. 1. Wrap the BLAS calls in external functions, requires a lot of manual programming but can be generalized so that it is also available as a general feature of CoDiPack (e.g. We can handle BLAS to XX %). 2. Make use of the ""new"" AD tool I am currently programming. This tool does not insert itself into the Eigen structures, but wraps around them. Then the special path for BLAS can be activated without the AD tool even noticing it. For both options it will be very interesting for us to see how the performance compares with respect to the primal optimized and non optimized version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462272618
https://github.com/su2code/SU2/issues/643#issuecomment-462272618:537,Availability,avail,available,537,"The adjoint handling of the Eigen library can actually be a two step process. In the first step we just use the BlackBox differentiation of Eigen. This will work for every user in the primal code and adjoint code. As a second step we would then look into the BLAS wrapper of Eigen and check if we can provide a special treatment for the adjoint aka CoDiPack version. In general there are two options available:. 1. Wrap the BLAS calls in external functions, requires a lot of manual programming but can be generalized so that it is also available as a general feature of CoDiPack (e.g. We can handle BLAS to XX %). 2. Make use of the ""new"" AD tool I am currently programming. This tool does not insert itself into the Eigen structures, but wraps around them. Then the special path for BLAS can be activated without the AD tool even noticing it. For both options it will be very interesting for us to see how the performance compares with respect to the primal optimized and non optimized version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462272618
https://github.com/su2code/SU2/issues/643#issuecomment-462272618:264,Integrability,wrap,wrapper,264,"The adjoint handling of the Eigen library can actually be a two step process. In the first step we just use the BlackBox differentiation of Eigen. This will work for every user in the primal code and adjoint code. As a second step we would then look into the BLAS wrapper of Eigen and check if we can provide a special treatment for the adjoint aka CoDiPack version. In general there are two options available:. 1. Wrap the BLAS calls in external functions, requires a lot of manual programming but can be generalized so that it is also available as a general feature of CoDiPack (e.g. We can handle BLAS to XX %). 2. Make use of the ""new"" AD tool I am currently programming. This tool does not insert itself into the Eigen structures, but wraps around them. Then the special path for BLAS can be activated without the AD tool even noticing it. For both options it will be very interesting for us to see how the performance compares with respect to the primal optimized and non optimized version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462272618
https://github.com/su2code/SU2/issues/643#issuecomment-462272618:415,Integrability,Wrap,Wrap,415,"The adjoint handling of the Eigen library can actually be a two step process. In the first step we just use the BlackBox differentiation of Eigen. This will work for every user in the primal code and adjoint code. As a second step we would then look into the BLAS wrapper of Eigen and check if we can provide a special treatment for the adjoint aka CoDiPack version. In general there are two options available:. 1. Wrap the BLAS calls in external functions, requires a lot of manual programming but can be generalized so that it is also available as a general feature of CoDiPack (e.g. We can handle BLAS to XX %). 2. Make use of the ""new"" AD tool I am currently programming. This tool does not insert itself into the Eigen structures, but wraps around them. Then the special path for BLAS can be activated without the AD tool even noticing it. For both options it will be very interesting for us to see how the performance compares with respect to the primal optimized and non optimized version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462272618
https://github.com/su2code/SU2/issues/643#issuecomment-462272618:740,Integrability,wrap,wraps,740,"The adjoint handling of the Eigen library can actually be a two step process. In the first step we just use the BlackBox differentiation of Eigen. This will work for every user in the primal code and adjoint code. As a second step we would then look into the BLAS wrapper of Eigen and check if we can provide a special treatment for the adjoint aka CoDiPack version. In general there are two options available:. 1. Wrap the BLAS calls in external functions, requires a lot of manual programming but can be generalized so that it is also available as a general feature of CoDiPack (e.g. We can handle BLAS to XX %). 2. Make use of the ""new"" AD tool I am currently programming. This tool does not insert itself into the Eigen structures, but wraps around them. Then the special path for BLAS can be activated without the AD tool even noticing it. For both options it will be very interesting for us to see how the performance compares with respect to the primal optimized and non optimized version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462272618
https://github.com/su2code/SU2/issues/643#issuecomment-462272618:912,Performance,perform,performance,912,"The adjoint handling of the Eigen library can actually be a two step process. In the first step we just use the BlackBox differentiation of Eigen. This will work for every user in the primal code and adjoint code. As a second step we would then look into the BLAS wrapper of Eigen and check if we can provide a special treatment for the adjoint aka CoDiPack version. In general there are two options available:. 1. Wrap the BLAS calls in external functions, requires a lot of manual programming but can be generalized so that it is also available as a general feature of CoDiPack (e.g. We can handle BLAS to XX %). 2. Make use of the ""new"" AD tool I am currently programming. This tool does not insert itself into the Eigen structures, but wraps around them. Then the special path for BLAS can be activated without the AD tool even noticing it. For both options it will be very interesting for us to see how the performance compares with respect to the primal optimized and non optimized version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462272618
https://github.com/su2code/SU2/issues/643#issuecomment-462272618:960,Performance,optimiz,optimized,960,"The adjoint handling of the Eigen library can actually be a two step process. In the first step we just use the BlackBox differentiation of Eigen. This will work for every user in the primal code and adjoint code. As a second step we would then look into the BLAS wrapper of Eigen and check if we can provide a special treatment for the adjoint aka CoDiPack version. In general there are two options available:. 1. Wrap the BLAS calls in external functions, requires a lot of manual programming but can be generalized so that it is also available as a general feature of CoDiPack (e.g. We can handle BLAS to XX %). 2. Make use of the ""new"" AD tool I am currently programming. This tool does not insert itself into the Eigen structures, but wraps around them. Then the special path for BLAS can be activated without the AD tool even noticing it. For both options it will be very interesting for us to see how the performance compares with respect to the primal optimized and non optimized version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462272618
https://github.com/su2code/SU2/issues/643#issuecomment-462272618:978,Performance,optimiz,optimized,978,"The adjoint handling of the Eigen library can actually be a two step process. In the first step we just use the BlackBox differentiation of Eigen. This will work for every user in the primal code and adjoint code. As a second step we would then look into the BLAS wrapper of Eigen and check if we can provide a special treatment for the adjoint aka CoDiPack version. In general there are two options available:. 1. Wrap the BLAS calls in external functions, requires a lot of manual programming but can be generalized so that it is also available as a general feature of CoDiPack (e.g. We can handle BLAS to XX %). 2. Make use of the ""new"" AD tool I am currently programming. This tool does not insert itself into the Eigen structures, but wraps around them. Then the special path for BLAS can be activated without the AD tool even noticing it. For both options it will be very interesting for us to see how the performance compares with respect to the primal optimized and non optimized version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-462272618
https://github.com/su2code/SU2/issues/643#issuecomment-463181396:419,Availability,down,downside,419,"Hi @MaxSagebaum,. The two options in your second step sound very interesting and I guess are the only way to get good performance for arithmetic intensive operations, like the ones in the DG solver. If I understand correctly option 1 is something that could be tried already, by applying the external function mechanism to the gemm and gemv functions (akin to what is done now for large linear systems) right? The only downside would be the creation of temporary matrices of passivedouble required to call the blas functions.; With option 2 maybe these temporaries would not be required? As there would be an active matrix class whose internal data structures would be passive matrices that could interface with blas directly?. I guess the important question is: For performance sensitive applications, do you see merit in developing something in house that could better leverage the new AD tool, or will it be able to handle ""any"" object oriented library we might adopt?. Thanks and regards,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463181396
https://github.com/su2code/SU2/issues/643#issuecomment-463181396:697,Integrability,interface,interface,697,"Hi @MaxSagebaum,. The two options in your second step sound very interesting and I guess are the only way to get good performance for arithmetic intensive operations, like the ones in the DG solver. If I understand correctly option 1 is something that could be tried already, by applying the external function mechanism to the gemm and gemv functions (akin to what is done now for large linear systems) right? The only downside would be the creation of temporary matrices of passivedouble required to call the blas functions.; With option 2 maybe these temporaries would not be required? As there would be an active matrix class whose internal data structures would be passive matrices that could interface with blas directly?. I guess the important question is: For performance sensitive applications, do you see merit in developing something in house that could better leverage the new AD tool, or will it be able to handle ""any"" object oriented library we might adopt?. Thanks and regards,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463181396
https://github.com/su2code/SU2/issues/643#issuecomment-463181396:118,Performance,perform,performance,118,"Hi @MaxSagebaum,. The two options in your second step sound very interesting and I guess are the only way to get good performance for arithmetic intensive operations, like the ones in the DG solver. If I understand correctly option 1 is something that could be tried already, by applying the external function mechanism to the gemm and gemv functions (akin to what is done now for large linear systems) right? The only downside would be the creation of temporary matrices of passivedouble required to call the blas functions.; With option 2 maybe these temporaries would not be required? As there would be an active matrix class whose internal data structures would be passive matrices that could interface with blas directly?. I guess the important question is: For performance sensitive applications, do you see merit in developing something in house that could better leverage the new AD tool, or will it be able to handle ""any"" object oriented library we might adopt?. Thanks and regards,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463181396
https://github.com/su2code/SU2/issues/643#issuecomment-463181396:767,Performance,perform,performance,767,"Hi @MaxSagebaum,. The two options in your second step sound very interesting and I guess are the only way to get good performance for arithmetic intensive operations, like the ones in the DG solver. If I understand correctly option 1 is something that could be tried already, by applying the external function mechanism to the gemm and gemv functions (akin to what is done now for large linear systems) right? The only downside would be the creation of temporary matrices of passivedouble required to call the blas functions.; With option 2 maybe these temporaries would not be required? As there would be an active matrix class whose internal data structures would be passive matrices that could interface with blas directly?. I guess the important question is: For performance sensitive applications, do you see merit in developing something in house that could better leverage the new AD tool, or will it be able to handle ""any"" object oriented library we might adopt?. Thanks and regards,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463181396
