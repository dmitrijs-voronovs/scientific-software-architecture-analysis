id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/491:22972,Performance,load,load,22972,"t_pepper.vcf.gz --output_gvcf=/cromwell_root/pepper_output/T708322218_ONT.10_14-p.deepvariant_pepper.g.vcf.gz --sample_name=""6061-SL-0029"" --intermediate_results_dir=/cromwell_root/pepper_output/dv_intermediate_outputs/ --num_shards=64 --make_examples_extra_args=""alt_aligned_pileup=none,realign_reads=false,min_mapping_quality=1,min_base_quality=1,sort_by_haplotypes=true,parse_sam_aux_fields=true,add_hp_channel=false,variant_caller=vcf_candidate_importer,proposed_variants=/cromwell_root/pepper_output/PEPPER_HP_OUPUT.vcf.gz"" --postprocess_variants_extra_args=""use_multiallelic_model=True"" 2>&1 | tee /cromwell_root/pepper_output/logs/4_DeepVariant.log; -------; STARTING DEEPVARIANT; I1103 14:39:53.527210 140335058065216 run_deepvariant.py:317] Re-using the directory for intermediate results in /cromwell_root/pepper_output/dv_intermediate_outputs/; I1103 14:39:53.527496 140335058065216 run_deepvariant.py:327] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load /opt/dv_models/ont_1121_none/model.ckpt-30200 instead. ***** Intermediate results will be written to /cromwell_root/pepper_output/dv_intermediate_outputs/ in docker. ****. ***** Running the command:*****; ( time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa"" --reads ""/cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam"" --examples ""/cromwell_root/pepper_output/dv_intermediate_outputs/make_examples.tfrecord@64.gz"" --noadd_hp_channel --alt_aligned_pileup ""none"" --gvcf ""/cromwell_root/pepper_output/dv_intermediate_outputs/gvcf.tfrecord@64.gz"" --min_base_quality ""1"" --min_mapping_quality ""1"" --parse_sam_aux_fields --proposed_variants ""/cromwell_root/pepper_output/PEPPER_HP_OUPUT.vcf.gz"" --norealign_reads --sample_name ""6061-SL-0029"" --sort_by_haplotypes --variant_cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:3774,Safety,PREDICT,PREDICTION,3774,"1] INFO: IMAGE OUTPUT: /cromwell_root/pepper_output/pepper_snp/images_11032021_134041/; [11-03-2021 13:40:41] STEP 1: GENERATING IMAGES; [11-03-2021 13:40:41] INFO: COMMON CONTIGS FOUND: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrM', 'chrX', 'chrY']; [11-03-2021 13:40:41] INFO: TOTAL CONTIGS: 25 TOTAL INTERVALS: 30895; [11-03-2021 13:40:41] STARTING THREAD: 0 FOR 483 INTERVALS; [11-03-2021 13:40:41] INFO: 10/483 COMPLETE (2%) [ELAPSED TIME: 0 Min 0 Sec]; ...; [11-03-2021 13:42:49] INFO: 470/483 COMPLETE (97%) [ELAPSED TIME: 2 Min 8 Sec]; [11-03-2021 13:42:49] INFO: 480/483 COMPLETE (99%) [ELAPSED TIME: 2 Min 8 Sec]; [11-03-2021 13:42:49] THREAD 0 FINISHED SUCCESSFULLY.; [11-03-2021 13:44:25] FINISHED IMAGE GENERATION; [11-03-2021 13:44:25] TOTAL ELAPSED TIME FOR IMAGE GENERATION: 3 Min 44 Sec; [11-03-2021 13:44:25] STEP 2: RUNNING INFERENCE; [11-03-2021 13:44:25] INFO: PREDICTION OUTPUT: /cromwell_root/pepper_output/pepper_snp/predictions_11032021_134041/; [11-03-2021 13:44:25] INFO: DISTRIBUTED CPU SETUP.; [11-03-2021 13:44:25] INFO: TOTAL CALLERS: 64; [11-03-2021 13:44:25] INFO: THREADS PER CALLER: 1; [11-03-2021 13:44:25] INFO: MODEL LOADING TO ONNX; [11-03-2021 13:45:22] INFO: BATCHES PROCESSED 5/35.; [11-03-2021 13:46:21] INFO: BATCHES PROCESSED 10/35.; [11-03-2021 13:47:17] INFO: BATCHES PROCESSED 15/35.; [11-03-2021 13:48:11] INFO: BATCHES PROCESSED 20/35.; [11-03-2021 13:49:06] INFO: BATCHES PROCESSED 25/35.; [11-03-2021 13:49:59] INFO: BATCHES PROCESSED 30/35.; [11-03-2021 13:50:39] INFO: BATCHES PROCESSED 35/35.; [11-03-2021 13:50:39] INFO: THREAD 0 FINISHED SUCCESSFULLY.; [11-03-2021 13:50:44] INFO: FINISHED PREDICTION; [11-03-2021 13:50:44] INFO: ELAPSED TIME: 6 Min 18 Sec; [11-03-2021 13:50:44] INFO: PREDICTION FINISHED SUCCESSFULLY. ; [11-03-2021 13:50:44] TOTAL ELAPSED TIME FOR INFERENCE: 6 Min 18 Sec; ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:4539,Safety,PREDICT,PREDICTION,4539,"3:44:25] FINISHED IMAGE GENERATION; [11-03-2021 13:44:25] TOTAL ELAPSED TIME FOR IMAGE GENERATION: 3 Min 44 Sec; [11-03-2021 13:44:25] STEP 2: RUNNING INFERENCE; [11-03-2021 13:44:25] INFO: PREDICTION OUTPUT: /cromwell_root/pepper_output/pepper_snp/predictions_11032021_134041/; [11-03-2021 13:44:25] INFO: DISTRIBUTED CPU SETUP.; [11-03-2021 13:44:25] INFO: TOTAL CALLERS: 64; [11-03-2021 13:44:25] INFO: THREADS PER CALLER: 1; [11-03-2021 13:44:25] INFO: MODEL LOADING TO ONNX; [11-03-2021 13:45:22] INFO: BATCHES PROCESSED 5/35.; [11-03-2021 13:46:21] INFO: BATCHES PROCESSED 10/35.; [11-03-2021 13:47:17] INFO: BATCHES PROCESSED 15/35.; [11-03-2021 13:48:11] INFO: BATCHES PROCESSED 20/35.; [11-03-2021 13:49:06] INFO: BATCHES PROCESSED 25/35.; [11-03-2021 13:49:59] INFO: BATCHES PROCESSED 30/35.; [11-03-2021 13:50:39] INFO: BATCHES PROCESSED 35/35.; [11-03-2021 13:50:39] INFO: THREAD 0 FINISHED SUCCESSFULLY.; [11-03-2021 13:50:44] INFO: FINISHED PREDICTION; [11-03-2021 13:50:44] INFO: ELAPSED TIME: 6 Min 18 Sec; [11-03-2021 13:50:44] INFO: PREDICTION FINISHED SUCCESSFULLY. ; [11-03-2021 13:50:44] TOTAL ELAPSED TIME FOR INFERENCE: 6 Min 18 Sec; [11-03-2021 13:50:44] STEP 3: RUNNING FIND CANDIDATES; [11-03-2021 13:50:44] INFO: PREDICTION OUTPUT: /cromwell_root/pepper_output/pepper_snp/; [11-03-2021 13:50:44] INFO: PROCESSING CONTIG: chr10; [11-03-2021 13:53:46] INFO: FINISHED PROCESSING chr10, TOTAL CANDIDATES FOUND: 345013.; [11-03-2021 13:53:53] INFO: PROCESSING CONTIG: chr14; [11-03-2021 13:54:02] INFO: FINISHED PROCESSING chr14, TOTAL CANDIDATES FOUND: 3092.; [11-03-2021 13:54:02] TOTAL ELAPSED TIME FOR VARIANT CALLING: 13 Min 21 Sec. real	13m23.051s; user	579m29.953s; sys	11m32.825s; [11-03-2021 13:54:03] INFO: [3/9] RUNNING THE FOLLOWING COMMAND; -------; mv /cromwell_root/pepper_output/pepper_snp/*.vcf /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf; ; bgzip /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf; ; tabix -p vcf /cromwell_root/pepper_output/PEPPER_SNP_O",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:4635,Safety,PREDICT,PREDICTION,4635,"3:44:25] FINISHED IMAGE GENERATION; [11-03-2021 13:44:25] TOTAL ELAPSED TIME FOR IMAGE GENERATION: 3 Min 44 Sec; [11-03-2021 13:44:25] STEP 2: RUNNING INFERENCE; [11-03-2021 13:44:25] INFO: PREDICTION OUTPUT: /cromwell_root/pepper_output/pepper_snp/predictions_11032021_134041/; [11-03-2021 13:44:25] INFO: DISTRIBUTED CPU SETUP.; [11-03-2021 13:44:25] INFO: TOTAL CALLERS: 64; [11-03-2021 13:44:25] INFO: THREADS PER CALLER: 1; [11-03-2021 13:44:25] INFO: MODEL LOADING TO ONNX; [11-03-2021 13:45:22] INFO: BATCHES PROCESSED 5/35.; [11-03-2021 13:46:21] INFO: BATCHES PROCESSED 10/35.; [11-03-2021 13:47:17] INFO: BATCHES PROCESSED 15/35.; [11-03-2021 13:48:11] INFO: BATCHES PROCESSED 20/35.; [11-03-2021 13:49:06] INFO: BATCHES PROCESSED 25/35.; [11-03-2021 13:49:59] INFO: BATCHES PROCESSED 30/35.; [11-03-2021 13:50:39] INFO: BATCHES PROCESSED 35/35.; [11-03-2021 13:50:39] INFO: THREAD 0 FINISHED SUCCESSFULLY.; [11-03-2021 13:50:44] INFO: FINISHED PREDICTION; [11-03-2021 13:50:44] INFO: ELAPSED TIME: 6 Min 18 Sec; [11-03-2021 13:50:44] INFO: PREDICTION FINISHED SUCCESSFULLY. ; [11-03-2021 13:50:44] TOTAL ELAPSED TIME FOR INFERENCE: 6 Min 18 Sec; [11-03-2021 13:50:44] STEP 3: RUNNING FIND CANDIDATES; [11-03-2021 13:50:44] INFO: PREDICTION OUTPUT: /cromwell_root/pepper_output/pepper_snp/; [11-03-2021 13:50:44] INFO: PROCESSING CONTIG: chr10; [11-03-2021 13:53:46] INFO: FINISHED PROCESSING chr10, TOTAL CANDIDATES FOUND: 345013.; [11-03-2021 13:53:53] INFO: PROCESSING CONTIG: chr14; [11-03-2021 13:54:02] INFO: FINISHED PROCESSING chr14, TOTAL CANDIDATES FOUND: 3092.; [11-03-2021 13:54:02] TOTAL ELAPSED TIME FOR VARIANT CALLING: 13 Min 21 Sec. real	13m23.051s; user	579m29.953s; sys	11m32.825s; [11-03-2021 13:54:03] INFO: [3/9] RUNNING THE FOLLOWING COMMAND; -------; mv /cromwell_root/pepper_output/pepper_snp/*.vcf /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf; ; bgzip /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf; ; tabix -p vcf /cromwell_root/pepper_output/PEPPER_SNP_O",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:4824,Safety,PREDICT,PREDICTION,4824,"1032021_134041/; [11-03-2021 13:44:25] INFO: DISTRIBUTED CPU SETUP.; [11-03-2021 13:44:25] INFO: TOTAL CALLERS: 64; [11-03-2021 13:44:25] INFO: THREADS PER CALLER: 1; [11-03-2021 13:44:25] INFO: MODEL LOADING TO ONNX; [11-03-2021 13:45:22] INFO: BATCHES PROCESSED 5/35.; [11-03-2021 13:46:21] INFO: BATCHES PROCESSED 10/35.; [11-03-2021 13:47:17] INFO: BATCHES PROCESSED 15/35.; [11-03-2021 13:48:11] INFO: BATCHES PROCESSED 20/35.; [11-03-2021 13:49:06] INFO: BATCHES PROCESSED 25/35.; [11-03-2021 13:49:59] INFO: BATCHES PROCESSED 30/35.; [11-03-2021 13:50:39] INFO: BATCHES PROCESSED 35/35.; [11-03-2021 13:50:39] INFO: THREAD 0 FINISHED SUCCESSFULLY.; [11-03-2021 13:50:44] INFO: FINISHED PREDICTION; [11-03-2021 13:50:44] INFO: ELAPSED TIME: 6 Min 18 Sec; [11-03-2021 13:50:44] INFO: PREDICTION FINISHED SUCCESSFULLY. ; [11-03-2021 13:50:44] TOTAL ELAPSED TIME FOR INFERENCE: 6 Min 18 Sec; [11-03-2021 13:50:44] STEP 3: RUNNING FIND CANDIDATES; [11-03-2021 13:50:44] INFO: PREDICTION OUTPUT: /cromwell_root/pepper_output/pepper_snp/; [11-03-2021 13:50:44] INFO: PROCESSING CONTIG: chr10; [11-03-2021 13:53:46] INFO: FINISHED PROCESSING chr10, TOTAL CANDIDATES FOUND: 345013.; [11-03-2021 13:53:53] INFO: PROCESSING CONTIG: chr14; [11-03-2021 13:54:02] INFO: FINISHED PROCESSING chr14, TOTAL CANDIDATES FOUND: 3092.; [11-03-2021 13:54:02] TOTAL ELAPSED TIME FOR VARIANT CALLING: 13 Min 21 Sec. real	13m23.051s; user	579m29.953s; sys	11m32.825s; [11-03-2021 13:54:03] INFO: [3/9] RUNNING THE FOLLOWING COMMAND; -------; mv /cromwell_root/pepper_output/pepper_snp/*.vcf /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf; ; bgzip /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf; ; tabix -p vcf /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf.gz; ; rm -rf /cromwell_root/pepper_output/pepper_snp/; ; echo ""CONTIGS FOUND IN PEPPER SNP VCF:""; ; zcat /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf.gz | grep -v '#' | cut -f1 | uniq; -------; CONTIGS FOUND IN PEPPER SNP VCF:; chr10; chr14; [11-03-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:20159,Safety,PREDICT,PREDICTION,20159,"1 14:31:57] INFO: THREAD 25 FINISHED SUCCESSFULLY.; [11-03-2021 14:31:58] INFO: THREAD 0 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:00] INFO: THREAD 52 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:00] INFO: THREAD 32 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:01] INFO: THREAD 23 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:03] INFO: THREAD 30 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:03] INFO: THREAD 43 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:03] INFO: THREAD 11 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:04] INFO: THREAD 1 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:07] INFO: THREAD 13 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:07] INFO: THREAD 59 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:12] INFO: THREAD 57 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:20] INFO: THREAD 47 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:23] INFO: THREAD 27 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:23] INFO: THREAD 29 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:23] INFO: FINISHED PREDICTION; [11-03-2021 14:32:23] INFO: ELAPSED TIME: 14 Min 14 Sec; [11-03-2021 14:32:23] INFO: PREDICTION FINISHED SUCCESSFULLY. ; [11-03-2021 14:32:23] TOTAL ELAPSED TIME FOR INFERENCE: 14 Min 14 Sec; [11-03-2021 14:32:23] STEP 3.1: CALLING VARIANTS; [11-03-2021 14:32:23] INFO: OUTPUT: /cromwell_root/pepper_output/pepper_hp/; [11-03-2021 14:32:23] INFO: PROCESSING HAPLOTAG: 0; [11-03-2021 14:32:24] INFO: PROCESSING CONTIG: chr10; [11-03-2021 14:39:30] INFO: FINISHED PROCESSING chr10, TOTAL CANDIDATES FOUND: 378085 TOTAL TIME SPENT: 7 Min 6 Sec; [11-03-2021 14:39:37] INFO: PROCESSING CONTIG: chr14; [11-03-2021 14:39:48] INFO: FINISHED PROCESSING chr14, TOTAL CANDIDATES FOUND: 2550 TOTAL TIME SPENT: 0 Min 11 Sec; [11-03-2021 14:39:49] TOTAL ELAPSED TIME FOR VARIANT CALLING: 26 Min 43 Sec. real	26m44.555s; user	1220m53.668s; sys	15m35.409s; [11-03-2021 14:39:49] INFO: [6/9] RUNNING THE FOLLOWING COMMAND; -------; mv /cromwell_root/pepper_output/pepper_hp/*.vcf /cromwell_root/pepper_output/PEPPER_HP_OUPUT.vcf; ; bgzip /cromwell_roo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:20256,Safety,PREDICT,PREDICTION,20256,"1 14:31:57] INFO: THREAD 25 FINISHED SUCCESSFULLY.; [11-03-2021 14:31:58] INFO: THREAD 0 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:00] INFO: THREAD 52 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:00] INFO: THREAD 32 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:01] INFO: THREAD 23 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:03] INFO: THREAD 30 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:03] INFO: THREAD 43 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:03] INFO: THREAD 11 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:04] INFO: THREAD 1 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:07] INFO: THREAD 13 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:07] INFO: THREAD 59 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:12] INFO: THREAD 57 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:20] INFO: THREAD 47 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:23] INFO: THREAD 27 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:23] INFO: THREAD 29 FINISHED SUCCESSFULLY.; [11-03-2021 14:32:23] INFO: FINISHED PREDICTION; [11-03-2021 14:32:23] INFO: ELAPSED TIME: 14 Min 14 Sec; [11-03-2021 14:32:23] INFO: PREDICTION FINISHED SUCCESSFULLY. ; [11-03-2021 14:32:23] TOTAL ELAPSED TIME FOR INFERENCE: 14 Min 14 Sec; [11-03-2021 14:32:23] STEP 3.1: CALLING VARIANTS; [11-03-2021 14:32:23] INFO: OUTPUT: /cromwell_root/pepper_output/pepper_hp/; [11-03-2021 14:32:23] INFO: PROCESSING HAPLOTAG: 0; [11-03-2021 14:32:24] INFO: PROCESSING CONTIG: chr10; [11-03-2021 14:39:30] INFO: FINISHED PROCESSING chr10, TOTAL CANDIDATES FOUND: 378085 TOTAL TIME SPENT: 7 Min 6 Sec; [11-03-2021 14:39:37] INFO: PROCESSING CONTIG: chr14; [11-03-2021 14:39:48] INFO: FINISHED PROCESSING chr14, TOTAL CANDIDATES FOUND: 2550 TOTAL TIME SPENT: 0 Min 11 Sec; [11-03-2021 14:39:49] TOTAL ELAPSED TIME FOR VARIANT CALLING: 26 Min 43 Sec. real	26m44.555s; user	1220m53.668s; sys	15m35.409s; [11-03-2021 14:39:49] INFO: [6/9] RUNNING THE FOLLOWING COMMAND; -------; mv /cromwell_root/pepper_output/pepper_hp/*.vcf /cromwell_root/pepper_output/PEPPER_HP_OUPUT.vcf; ; bgzip /cromwell_roo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:36228,Safety,predict,predicting,36228,"3 14:53:07.275555 139714691082048 make_examples_core.py:163] Task 53/64: 2400 candidates (2566 examples) [15.76s elapsed]; I1103 14:53:07.719906 140657934407488 make_examples_core.py:163] Task 27/64: 2739 candidates (3035 examples) [5.45s elapsed]; I1103 14:53:07.775277 140126785840960 make_examples_core.py:163] Task 16/64: 2308 candidates (2374 examples) [2.44s elapsed]; I1103 14:53:08.681667 139823122659136 make_examples_core.py:163] Task 45/64: 2652 candidates (2750 examples) [5.88s elapsed]; I1103 14:53:08.499621 140345388750656 make_examples_core.py:163] Task 50/64: 2517 candidates (2651 examples) [4.04s elapsed]; I1103 14:53:08.077846 139826026686272 make_examples_core.py:163] Task 55/64: 2412 candidates (2556 examples) [8.96s elapsed]; I1103 14:53:08.165700 140447748351808 make_examples_core.py:163] Task 29/64: 2805 candidates (2883 examples) [2.81s elapsed]; I1103 14:53:08.086294 140152994068288 make_examples_core.py:163] Task 4/64: 2265 candidates (2381 examples) [3.39s elapsed]; I1103 14:53:08.115124 140349764978496 make_examples_core.py:163] Task 58/64: 2401 candidates (2511 examples) [13.20s elapsed]; I1103 14:53:07.834557 140529397729088 make_examples_core.py:163] Task 44/64: 2614 candidates (2702 examples) [1.68s elapsed]; I1103 14:53:08.208366 140388734826304 make_examples_core.py:163] Task 13/64: 2206 candidates (2302 examples) [8.06s elapsed]; # the program died here; ```. For one failed task, the input BAM size is 19GB, and allocated disk size is 300GB. **Does the quick start test work on your system?**. Some inputs finish, while others fail using the exact same workflow (PAPI error 10), so it's unlikely to be a coding issue. **Any additional context:**. We have successful runs with inputs of similar sizes that failed with PAPI 10. So I'm wondering if there's an empirical formula for predicting disk space usage. Additionally, is there a way to make DV less verbose? The log file goes to hundreds of MB, which makes debugging less easy. Thanks!; Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:640,Testability,log,log,640,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.2/docs/FAQ.md**:; Yes. **Describe the issue:**. When running WDL workflows backed with PAPI, I get PAPI error 10, which indicates the disk is full. **Setup**; - Operating system: Docker image coming with DV-Margin-Pepper: `kishwars/pepper_deepvariant:r0.4.1`; - DeepVariant version: Docker image coming with DV-Margin-Pepper: `kishwars/pepper_deepvariant:r0.4.1`; - Installation method (Docker, built from source, etc.): Docker; - Type of data: ONT, GRCh38, process by chromosome. **Steps to reproduce:**. ```; # This is the command from Pepper, but judged from the log, the command failed during the DV stage.; run_pepper_margin_deepvariant \; call_variant \; -b ~{bam} \; -f ~{ref_fasta} \; -t ""${num_core}"" \; -s ""${SM}"" \; -o ""~{output_root}"" \; -p ""~{prefix}"" \; --gvcf \; --phased_output \; --ont; ```; Relevant part of the log file (which is over 200MB):. ```; run_pepper_margin_deepvariant call_variant -b /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-84a6-20c8f2b9373f/ONTWholeGenome/977d19ea-5082-4605-8595-803df94ec9dc/call-CallVariants/CallVariants/2ab0b7ef-d657-4d70-9d3c-3b9b74720a00/call-size_balanced_scatter/shard-2/cacheCopy/T708322218_ONT.10_14-p.bam -f /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa -t 64 -s 6061-SL-0029 -o /cromwell_root/pepper_output -p T708322218_ONT.10_14-p.deepvariant_pepper --gvcf --phased_output --ont; [11-03-2021 13:40:40] INFO: VARIANT CALLING MODULE SELECTED; [11-03-2021 13:40:40] INFO: [1/9] RUNNING THE FOLLOWING COMMAND; -------; mkdir -p /cromwell_root/pepper_output; ; mkdir -p /cromwell_root/pepper_output/logs; ; mkdir -p /cromwell_root/pepper_output/intermediate_files;; -------; [11-03-2021 13:40:40] INFO: [2/9] RUNNING THE FOLLOWING COMMAND; -------; time pepper_snp call_variant -b /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:904,Testability,log,log,904,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.2/docs/FAQ.md**:; Yes. **Describe the issue:**. When running WDL workflows backed with PAPI, I get PAPI error 10, which indicates the disk is full. **Setup**; - Operating system: Docker image coming with DV-Margin-Pepper: `kishwars/pepper_deepvariant:r0.4.1`; - DeepVariant version: Docker image coming with DV-Margin-Pepper: `kishwars/pepper_deepvariant:r0.4.1`; - Installation method (Docker, built from source, etc.): Docker; - Type of data: ONT, GRCh38, process by chromosome. **Steps to reproduce:**. ```; # This is the command from Pepper, but judged from the log, the command failed during the DV stage.; run_pepper_margin_deepvariant \; call_variant \; -b ~{bam} \; -f ~{ref_fasta} \; -t ""${num_core}"" \; -s ""${SM}"" \; -o ""~{output_root}"" \; -p ""~{prefix}"" \; --gvcf \; --phased_output \; --ont; ```; Relevant part of the log file (which is over 200MB):. ```; run_pepper_margin_deepvariant call_variant -b /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-84a6-20c8f2b9373f/ONTWholeGenome/977d19ea-5082-4605-8595-803df94ec9dc/call-CallVariants/CallVariants/2ab0b7ef-d657-4d70-9d3c-3b9b74720a00/call-size_balanced_scatter/shard-2/cacheCopy/T708322218_ONT.10_14-p.bam -f /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa -t 64 -s 6061-SL-0029 -o /cromwell_root/pepper_output -p T708322218_ONT.10_14-p.deepvariant_pepper --gvcf --phased_output --ont; [11-03-2021 13:40:40] INFO: VARIANT CALLING MODULE SELECTED; [11-03-2021 13:40:40] INFO: [1/9] RUNNING THE FOLLOWING COMMAND; -------; mkdir -p /cromwell_root/pepper_output; ; mkdir -p /cromwell_root/pepper_output/logs; ; mkdir -p /cromwell_root/pepper_output/intermediate_files;; -------; [11-03-2021 13:40:40] INFO: [2/9] RUNNING THE FOLLOWING COMMAND; -------; time pepper_snp call_variant -b /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:1744,Testability,log,logs,1744,\; --gvcf \; --phased_output \; --ont; ```; Relevant part of the log file (which is over 200MB):. ```; run_pepper_margin_deepvariant call_variant -b /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-84a6-20c8f2b9373f/ONTWholeGenome/977d19ea-5082-4605-8595-803df94ec9dc/call-CallVariants/CallVariants/2ab0b7ef-d657-4d70-9d3c-3b9b74720a00/call-size_balanced_scatter/shard-2/cacheCopy/T708322218_ONT.10_14-p.bam -f /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa -t 64 -s 6061-SL-0029 -o /cromwell_root/pepper_output -p T708322218_ONT.10_14-p.deepvariant_pepper --gvcf --phased_output --ont; [11-03-2021 13:40:40] INFO: VARIANT CALLING MODULE SELECTED; [11-03-2021 13:40:40] INFO: [1/9] RUNNING THE FOLLOWING COMMAND; -------; mkdir -p /cromwell_root/pepper_output; ; mkdir -p /cromwell_root/pepper_output/logs; ; mkdir -p /cromwell_root/pepper_output/intermediate_files;; -------; [11-03-2021 13:40:40] INFO: [2/9] RUNNING THE FOLLOWING COMMAND; -------; time pepper_snp call_variant -b /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-84a6-20c8f2b9373f/ONTWholeGenome/977d19ea-5082-4605-8595-803df94ec9dc/call-CallVariants/CallVariants/2ab0b7ef-d657-4d70-9d3c-3b9b74720a00/call-size_balanced_scatter/shard-2/cacheCopy/T708322218_ONT.10_14-p.bam -f /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa -t 64 -m /opt/pepper_models/PEPPER_SNP_R941_ONT_V4.pkl -o /cromwell_root/pepper_output/pepper_snp/ -s 6061-SL-0029 -w 4 -bs 64 --ont 2>&1 | tee /cromwell_root/pepper_output/logs/1_pepper_snp.log; -------; [11-03-2021 13:40:41] INFO: CALL VARIANT MODULE SELECTED.; [11-03-2021 13:40:41] INFO: ONT PROFILE SET FOR VARIANT CALLING.; [11-03-2021 13:40:41] INFO: RUN-ID: 11032021_134041; [11-03-2021 13:40:41] INFO: IMAGE OUTPUT: /cromwell_root/pepper_output/pepper_snp/images_11032021_134041/; [11-03-2021,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:2512,Testability,log,logs,2512,"08322218_ONT.10_14-p.deepvariant_pepper --gvcf --phased_output --ont; [11-03-2021 13:40:40] INFO: VARIANT CALLING MODULE SELECTED; [11-03-2021 13:40:40] INFO: [1/9] RUNNING THE FOLLOWING COMMAND; -------; mkdir -p /cromwell_root/pepper_output; ; mkdir -p /cromwell_root/pepper_output/logs; ; mkdir -p /cromwell_root/pepper_output/intermediate_files;; -------; [11-03-2021 13:40:40] INFO: [2/9] RUNNING THE FOLLOWING COMMAND; -------; time pepper_snp call_variant -b /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-84a6-20c8f2b9373f/ONTWholeGenome/977d19ea-5082-4605-8595-803df94ec9dc/call-CallVariants/CallVariants/2ab0b7ef-d657-4d70-9d3c-3b9b74720a00/call-size_balanced_scatter/shard-2/cacheCopy/T708322218_ONT.10_14-p.bam -f /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa -t 64 -m /opt/pepper_models/PEPPER_SNP_R941_ONT_V4.pkl -o /cromwell_root/pepper_output/pepper_snp/ -s 6061-SL-0029 -w 4 -bs 64 --ont 2>&1 | tee /cromwell_root/pepper_output/logs/1_pepper_snp.log; -------; [11-03-2021 13:40:41] INFO: CALL VARIANT MODULE SELECTED.; [11-03-2021 13:40:41] INFO: ONT PROFILE SET FOR VARIANT CALLING.; [11-03-2021 13:40:41] INFO: RUN-ID: 11032021_134041; [11-03-2021 13:40:41] INFO: IMAGE OUTPUT: /cromwell_root/pepper_output/pepper_snp/images_11032021_134041/; [11-03-2021 13:40:41] STEP 1: GENERATING IMAGES; [11-03-2021 13:40:41] INFO: COMMON CONTIGS FOUND: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrM', 'chrX', 'chrY']; [11-03-2021 13:40:41] INFO: TOTAL CONTIGS: 25 TOTAL INTERVALS: 30895; [11-03-2021 13:40:41] STARTING THREAD: 0 FOR 483 INTERVALS; [11-03-2021 13:40:41] INFO: 10/483 COMPLETE (2%) [ELAPSED TIME: 0 Min 0 Sec]; ...; [11-03-2021 13:42:49] INFO: 470/483 COMPLETE (97%) [ELAPSED TIME: 2 Min 8 Sec]; [11-03-2021 13:42:49] IN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:2530,Testability,log,log,2530," CALLING MODULE SELECTED; [11-03-2021 13:40:40] INFO: [1/9] RUNNING THE FOLLOWING COMMAND; -------; mkdir -p /cromwell_root/pepper_output; ; mkdir -p /cromwell_root/pepper_output/logs; ; mkdir -p /cromwell_root/pepper_output/intermediate_files;; -------; [11-03-2021 13:40:40] INFO: [2/9] RUNNING THE FOLLOWING COMMAND; -------; time pepper_snp call_variant -b /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-84a6-20c8f2b9373f/ONTWholeGenome/977d19ea-5082-4605-8595-803df94ec9dc/call-CallVariants/CallVariants/2ab0b7ef-d657-4d70-9d3c-3b9b74720a00/call-size_balanced_scatter/shard-2/cacheCopy/T708322218_ONT.10_14-p.bam -f /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa -t 64 -m /opt/pepper_models/PEPPER_SNP_R941_ONT_V4.pkl -o /cromwell_root/pepper_output/pepper_snp/ -s 6061-SL-0029 -w 4 -bs 64 --ont 2>&1 | tee /cromwell_root/pepper_output/logs/1_pepper_snp.log; -------; [11-03-2021 13:40:41] INFO: CALL VARIANT MODULE SELECTED.; [11-03-2021 13:40:41] INFO: ONT PROFILE SET FOR VARIANT CALLING.; [11-03-2021 13:40:41] INFO: RUN-ID: 11032021_134041; [11-03-2021 13:40:41] INFO: IMAGE OUTPUT: /cromwell_root/pepper_output/pepper_snp/images_11032021_134041/; [11-03-2021 13:40:41] STEP 1: GENERATING IMAGES; [11-03-2021 13:40:41] INFO: COMMON CONTIGS FOUND: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrM', 'chrX', 'chrY']; [11-03-2021 13:40:41] INFO: TOTAL CONTIGS: 25 TOTAL INTERVALS: 30895; [11-03-2021 13:40:41] STARTING THREAD: 0 FOR 483 INTERVALS; [11-03-2021 13:40:41] INFO: 10/483 COMPLETE (2%) [ELAPSED TIME: 0 Min 0 Sec]; ...; [11-03-2021 13:42:49] INFO: 470/483 COMPLETE (97%) [ELAPSED TIME: 2 Min 8 Sec]; [11-03-2021 13:42:49] INFO: 480/483 COMPLETE (99%) [ELAPSED TIME: 2 Min 8 Sec]; [11-03-2021 13:42:49] THREAD 0 FINISHED SUCCESSFUL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:6564,Testability,log,logs,6564,"omwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf.gz; ; rm -rf /cromwell_root/pepper_output/pepper_snp/; ; echo ""CONTIGS FOUND IN PEPPER SNP VCF:""; ; zcat /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf.gz | grep -v '#' | cut -f1 | uniq; -------; CONTIGS FOUND IN PEPPER SNP VCF:; chr10; chr14; [11-03-2021 13:54:07] INFO: [4/9] RUNNING THE FOLLOWING COMMAND; -------; time margin phase /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-84a6-20c8f2b9373f/ONTWholeGenome/977d19ea-5082-4605-8595-803df94ec9dc/call-CallVariants/CallVariants/2ab0b7ef-d657-4d70-9d3c-3b9b74720a00/call-size_balanced_scatter/shard-2/cacheCopy/T708322218_ONT.10_14-p.bam /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf.gz /opt/margin_dir/params/misc/allParams.ont_haplotag.json -t 64 -V -o /cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN 2>&1 | tee /cromwell_root/pepper_output/logs/2_margin_haplotag.log;; mv /cromwell_root/pepper_output/*.bam /cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam; ; samtools index -@64 /cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam; -------; Running OpenMP with 64 threads.; > Parsing model parameters from file: /opt/margin_dir/params/misc/allParams.ont_haplotag.json; > Parsed 346237 HET VCF entries from /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf.gz; skipped 0 for region, 0 for not being PASS, 115453 for being homozygous, 0 for being INDEL; > Set up bam chunker in 20s with chunk size 100000 and overlap 10000 (for region=chr10,chr14), resulting in 1342 total chunks; > Ordering chunks by estimated depth; > Setup complete, beginning run; > Polishing 3% complete (46/1342). Estimated time remaining: unknown; > Polishing 5% complete (80/1342). Estimated time remaining: 3m 10s; > Polishing 9% complete (131/1342). Estimated time remaining: 2m 51s; > Polishing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:6587,Testability,log,log,6587,"cromwell_root/pepper_output/pepper_snp/; ; echo ""CONTIGS FOUND IN PEPPER SNP VCF:""; ; zcat /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf.gz | grep -v '#' | cut -f1 | uniq; -------; CONTIGS FOUND IN PEPPER SNP VCF:; chr10; chr14; [11-03-2021 13:54:07] INFO: [4/9] RUNNING THE FOLLOWING COMMAND; -------; time margin phase /cromwell_root/fc-1aea7e86-3760-4d8f-9f98-d199e815e8e2/7a319de0-a99a-4429-84a6-20c8f2b9373f/ONTWholeGenome/977d19ea-5082-4605-8595-803df94ec9dc/call-CallVariants/CallVariants/2ab0b7ef-d657-4d70-9d3c-3b9b74720a00/call-size_balanced_scatter/shard-2/cacheCopy/T708322218_ONT.10_14-p.bam /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf.gz /opt/margin_dir/params/misc/allParams.ont_haplotag.json -t 64 -V -o /cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN 2>&1 | tee /cromwell_root/pepper_output/logs/2_margin_haplotag.log;; mv /cromwell_root/pepper_output/*.bam /cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam; ; samtools index -@64 /cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam; -------; Running OpenMP with 64 threads.; > Parsing model parameters from file: /opt/margin_dir/params/misc/allParams.ont_haplotag.json; > Parsed 346237 HET VCF entries from /cromwell_root/pepper_output/PEPPER_SNP_OUPUT.vcf.gz; skipped 0 for region, 0 for not being PASS, 115453 for being homozygous, 0 for being INDEL; > Set up bam chunker in 20s with chunk size 100000 and overlap 10000 (for region=chr10,chr14), resulting in 1342 total chunks; > Ordering chunks by estimated depth; > Setup complete, beginning run; > Polishing 3% complete (46/1342). Estimated time remaining: unknown; > Polishing 5% complete (80/1342). Estimated time remaining: 3m 10s; > Polishing 9% complete (131/1342). Estimated time remaining: 2m 51s; > Polishing 14% complete (191/1342). Estimated time remaining: 2m 39s; ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:9747,Testability,log,logs,9747,". Estimated time remaining: 30s; > Polishing 92% complete (1235/1342). Estimated time remaining: 14s; > Starting merge; > Merging results from 1342 chunks.; > Merging took 7s; > Merge cleanup took 0s; Separated reads with divisions: H1 475116, H2 453908, and H0 159194; > Wrote haplotyped bams in 1m 43s; > Finished phasing in 18m 46s. real	18m47.373s; user	245m51.236s; sys	2m8.903s; mv: '/cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam' and '/cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam' are the same file; [11-03-2021 14:13:04] INFO: [5/9] RUNNING THE FOLLOWING COMMAND; -------; time pepper_hp call_variant -b /cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam -f /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa -t 64 -m /opt/pepper_models/PEPPER_HP_R941_ONT_V4.pkl -o /cromwell_root/pepper_output/pepper_hp/ -s 6061-SL-0029 -w 4 -bs 64 --ont 2>&1 | tee /cromwell_root/pepper_output/logs/3_pepper_hp.log; -------; [11-03-2021 14:13:05] INFO: CALL VARIANT MODULE SELECTED; [11-03-2021 14:13:05] INFO: ONT VARIANT CALLING PROFILE SET.; [11-03-2021 14:13:05] INFO: RUN-ID: 11032021_141305; [11-03-2021 14:13:05] INFO: IMAGE OUTPUT: /cromwell_root/pepper_output/pepper_hp/images_11032021_141305/; [11-03-2021 14:13:05] STEP 1: GENERATING IMAGES:; [11-03-2021 14:13:05] INFO: COMMON CONTIGS FOUND: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrM', 'chrX', 'chrY']; [11-03-2021 14:13:05] INFO: TOTAL CONTIGS: 25 TOTAL INTERVALS: 30895 TOTAL BASES: 3094460376; [11-03-2021 14:13:05] STARTING THREAD: 0 FOR 483 INTERVALS; [11-03-2021 14:13:05] INFO: [THREAD 00] 10/483 COMPLETE (2%) [ELAPSED TIME: 0 Min 0 Sec]; [11-03-2021 14:13:06] INFO: [THREAD 00] 20/483 COMPLETE (4%) [ELAPSED TIME: 0 M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:9764,Testability,log,log,9764,"ts from 1342 chunks.; > Merging took 7s; > Merge cleanup took 0s; Separated reads with divisions: H1 475116, H2 453908, and H0 159194; > Wrote haplotyped bams in 1m 43s; > Finished phasing in 18m 46s. real	18m47.373s; user	245m51.236s; sys	2m8.903s; mv: '/cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam' and '/cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam' are the same file; [11-03-2021 14:13:04] INFO: [5/9] RUNNING THE FOLLOWING COMMAND; -------; time pepper_hp call_variant -b /cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam -f /cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa -t 64 -m /opt/pepper_models/PEPPER_HP_R941_ONT_V4.pkl -o /cromwell_root/pepper_output/pepper_hp/ -s 6061-SL-0029 -w 4 -bs 64 --ont 2>&1 | tee /cromwell_root/pepper_output/logs/3_pepper_hp.log; -------; [11-03-2021 14:13:05] INFO: CALL VARIANT MODULE SELECTED; [11-03-2021 14:13:05] INFO: ONT VARIANT CALLING PROFILE SET.; [11-03-2021 14:13:05] INFO: RUN-ID: 11032021_141305; [11-03-2021 14:13:05] INFO: IMAGE OUTPUT: /cromwell_root/pepper_output/pepper_hp/images_11032021_141305/; [11-03-2021 14:13:05] STEP 1: GENERATING IMAGES:; [11-03-2021 14:13:05] INFO: COMMON CONTIGS FOUND: ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrM', 'chrX', 'chrY']; [11-03-2021 14:13:05] INFO: TOTAL CONTIGS: 25 TOTAL INTERVALS: 30895 TOTAL BASES: 3094460376; [11-03-2021 14:13:05] STARTING THREAD: 0 FOR 483 INTERVALS; [11-03-2021 14:13:05] INFO: [THREAD 00] 10/483 COMPLETE (2%) [ELAPSED TIME: 0 Min 0 Sec]; [11-03-2021 14:13:06] INFO: [THREAD 00] 20/483 COMPLETE (4%) [ELAPSED TIME: 0 Min 0 Sec]; [11-03-2021 14:13:06] INFO: [THREAD 00] 30/483 COMPLETE (6%) [ELAPSED TIME: 0 Min 0 Sec]; [11-03-2021 14:13:06] INFO: [THREA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:22589,Testability,log,logs,22589," /opt/deepvariant/bin/run_deepvariant --model_type=WGS --customized_model=/opt/dv_models/ont_1121_none/model.ckpt-30200 --ref=/cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa --reads=/cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam --output_vcf=/cromwell_root/pepper_output/T708322218_ONT.10_14-p.deepvariant_pepper.vcf.gz --output_gvcf=/cromwell_root/pepper_output/T708322218_ONT.10_14-p.deepvariant_pepper.g.vcf.gz --sample_name=""6061-SL-0029"" --intermediate_results_dir=/cromwell_root/pepper_output/dv_intermediate_outputs/ --num_shards=64 --make_examples_extra_args=""alt_aligned_pileup=none,realign_reads=false,min_mapping_quality=1,min_base_quality=1,sort_by_haplotypes=true,parse_sam_aux_fields=true,add_hp_channel=false,variant_caller=vcf_candidate_importer,proposed_variants=/cromwell_root/pepper_output/PEPPER_HP_OUPUT.vcf.gz"" --postprocess_variants_extra_args=""use_multiallelic_model=True"" 2>&1 | tee /cromwell_root/pepper_output/logs/4_DeepVariant.log; -------; STARTING DEEPVARIANT; I1103 14:39:53.527210 140335058065216 run_deepvariant.py:317] Re-using the directory for intermediate results in /cromwell_root/pepper_output/dv_intermediate_outputs/; I1103 14:39:53.527496 140335058065216 run_deepvariant.py:327] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load /opt/dv_models/ont_1121_none/model.ckpt-30200 instead. ***** Intermediate results will be written to /cromwell_root/pepper_output/dv_intermediate_outputs/ in docker. ****. ***** Running the command:*****; ( time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa"" --reads ""/cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam"" --examples ""/cromwell_root/pepper_outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:22608,Testability,log,log,22608,"ont_1121_none/model.ckpt-30200 --ref=/cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa --reads=/cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam --output_vcf=/cromwell_root/pepper_output/T708322218_ONT.10_14-p.deepvariant_pepper.vcf.gz --output_gvcf=/cromwell_root/pepper_output/T708322218_ONT.10_14-p.deepvariant_pepper.g.vcf.gz --sample_name=""6061-SL-0029"" --intermediate_results_dir=/cromwell_root/pepper_output/dv_intermediate_outputs/ --num_shards=64 --make_examples_extra_args=""alt_aligned_pileup=none,realign_reads=false,min_mapping_quality=1,min_base_quality=1,sort_by_haplotypes=true,parse_sam_aux_fields=true,add_hp_channel=false,variant_caller=vcf_candidate_importer,proposed_variants=/cromwell_root/pepper_output/PEPPER_HP_OUPUT.vcf.gz"" --postprocess_variants_extra_args=""use_multiallelic_model=True"" 2>&1 | tee /cromwell_root/pepper_output/logs/4_DeepVariant.log; -------; STARTING DEEPVARIANT; I1103 14:39:53.527210 140335058065216 run_deepvariant.py:317] Re-using the directory for intermediate results in /cromwell_root/pepper_output/dv_intermediate_outputs/; I1103 14:39:53.527496 140335058065216 run_deepvariant.py:327] You set --customized_model. Instead of using the default model for WGS, `call_variants` step will load /opt/dv_models/ont_1121_none/model.ckpt-30200 instead. ***** Intermediate results will be written to /cromwell_root/pepper_output/dv_intermediate_outputs/ in docker. ****. ***** Running the command:*****; ( time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/broad-dsde-methods-long-reads/resources/references/grch38_noalt/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa"" --reads ""/cromwell_root/pepper_output/MARGIN_PHASED.PEPPER_SNP_MARGIN.haplotagged.bam"" --examples ""/cromwell_root/pepper_output/dv_intermediate_outputs/make_examples.tfrecord@64.gz"" --noadd_hp_channel --alt_aligned_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:35914,Testability,test,test,35914,"3 14:53:07.275555 139714691082048 make_examples_core.py:163] Task 53/64: 2400 candidates (2566 examples) [15.76s elapsed]; I1103 14:53:07.719906 140657934407488 make_examples_core.py:163] Task 27/64: 2739 candidates (3035 examples) [5.45s elapsed]; I1103 14:53:07.775277 140126785840960 make_examples_core.py:163] Task 16/64: 2308 candidates (2374 examples) [2.44s elapsed]; I1103 14:53:08.681667 139823122659136 make_examples_core.py:163] Task 45/64: 2652 candidates (2750 examples) [5.88s elapsed]; I1103 14:53:08.499621 140345388750656 make_examples_core.py:163] Task 50/64: 2517 candidates (2651 examples) [4.04s elapsed]; I1103 14:53:08.077846 139826026686272 make_examples_core.py:163] Task 55/64: 2412 candidates (2556 examples) [8.96s elapsed]; I1103 14:53:08.165700 140447748351808 make_examples_core.py:163] Task 29/64: 2805 candidates (2883 examples) [2.81s elapsed]; I1103 14:53:08.086294 140152994068288 make_examples_core.py:163] Task 4/64: 2265 candidates (2381 examples) [3.39s elapsed]; I1103 14:53:08.115124 140349764978496 make_examples_core.py:163] Task 58/64: 2401 candidates (2511 examples) [13.20s elapsed]; I1103 14:53:07.834557 140529397729088 make_examples_core.py:163] Task 44/64: 2614 candidates (2702 examples) [1.68s elapsed]; I1103 14:53:08.208366 140388734826304 make_examples_core.py:163] Task 13/64: 2206 candidates (2302 examples) [8.06s elapsed]; # the program died here; ```. For one failed task, the input BAM size is 19GB, and allocated disk size is 300GB. **Does the quick start test work on your system?**. Some inputs finish, while others fail using the exact same workflow (PAPI error 10), so it's unlikely to be a coding issue. **Any additional context:**. We have successful runs with inputs of similar sizes that failed with PAPI 10. So I'm wondering if there's an empirical formula for predicting disk space usage. Additionally, is there a way to make DV less verbose? The log file goes to hundreds of MB, which makes debugging less easy. Thanks!; Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/491:36315,Testability,log,log,36315,"3 14:53:07.275555 139714691082048 make_examples_core.py:163] Task 53/64: 2400 candidates (2566 examples) [15.76s elapsed]; I1103 14:53:07.719906 140657934407488 make_examples_core.py:163] Task 27/64: 2739 candidates (3035 examples) [5.45s elapsed]; I1103 14:53:07.775277 140126785840960 make_examples_core.py:163] Task 16/64: 2308 candidates (2374 examples) [2.44s elapsed]; I1103 14:53:08.681667 139823122659136 make_examples_core.py:163] Task 45/64: 2652 candidates (2750 examples) [5.88s elapsed]; I1103 14:53:08.499621 140345388750656 make_examples_core.py:163] Task 50/64: 2517 candidates (2651 examples) [4.04s elapsed]; I1103 14:53:08.077846 139826026686272 make_examples_core.py:163] Task 55/64: 2412 candidates (2556 examples) [8.96s elapsed]; I1103 14:53:08.165700 140447748351808 make_examples_core.py:163] Task 29/64: 2805 candidates (2883 examples) [2.81s elapsed]; I1103 14:53:08.086294 140152994068288 make_examples_core.py:163] Task 4/64: 2265 candidates (2381 examples) [3.39s elapsed]; I1103 14:53:08.115124 140349764978496 make_examples_core.py:163] Task 58/64: 2401 candidates (2511 examples) [13.20s elapsed]; I1103 14:53:07.834557 140529397729088 make_examples_core.py:163] Task 44/64: 2614 candidates (2702 examples) [1.68s elapsed]; I1103 14:53:08.208366 140388734826304 make_examples_core.py:163] Task 13/64: 2206 candidates (2302 examples) [8.06s elapsed]; # the program died here; ```. For one failed task, the input BAM size is 19GB, and allocated disk size is 300GB. **Does the quick start test work on your system?**. Some inputs finish, while others fail using the exact same workflow (PAPI error 10), so it's unlikely to be a coding issue. **Any additional context:**. We have successful runs with inputs of similar sizes that failed with PAPI 10. So I'm wondering if there's an empirical formula for predicting disk space usage. Additionally, is there a way to make DV less verbose? The log file goes to hundreds of MB, which makes debugging less easy. Thanks!; Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/491
https://github.com/google/deepvariant/issues/492:550,Availability,Error,Error,550,"I have used the following commandline for running deepvariant. sudo docker run \; -v ""/media/eniac/WD1/Hifi_Assemblies/mapping/"":""/input"" \; -v ""/media/eniac/WD1/Hifi_Assemblies/mapping/docker_out:/output"" \; google/deepvariant:1.2.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/G1.asm.hic.hap2.p_ctg.fa \; --reads=/input/G1_hap2.bam \; --output_vcf=/output/output.vcf \; --num_shards=4. Deepvariant docker version is unable to find the indexed file. But there is an index file located in the specified directory. *****Error Message *******; I1104 14:33:59.843885 140094834329408 run_deepvariant.py:344] Re-using the directory for intermediate results in /tmp/tmp6zw47x4_; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:02.363862 139708777084736 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; W1104 14:34:02.364024 139708777084736 make_examples_core.py:273] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument.; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:02.363985 139750224725824 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; W1104 14:34:02.364139 139750224725824 make_examples_core.py:273] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument.; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:02.364016 140243238704960 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; W1104 14:34:02.364171 140243238704960 make_examples_core.py:273] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument.; [E::idx_find_and_load] Co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/492
https://github.com/google/deepvariant/issues/492:556,Integrability,Message,Message,556,"I have used the following commandline for running deepvariant. sudo docker run \; -v ""/media/eniac/WD1/Hifi_Assemblies/mapping/"":""/input"" \; -v ""/media/eniac/WD1/Hifi_Assemblies/mapping/docker_out:/output"" \; google/deepvariant:1.2.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/G1.asm.hic.hap2.p_ctg.fa \; --reads=/input/G1_hap2.bam \; --output_vcf=/output/output.vcf \; --num_shards=4. Deepvariant docker version is unable to find the indexed file. But there is an index file located in the specified directory. *****Error Message *******; I1104 14:33:59.843885 140094834329408 run_deepvariant.py:344] Re-using the directory for intermediate results in /tmp/tmp6zw47x4_; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:02.363862 139708777084736 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; W1104 14:34:02.364024 139708777084736 make_examples_core.py:273] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument.; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:02.363985 139750224725824 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; W1104 14:34:02.364139 139750224725824 make_examples_core.py:273] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument.; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:02.364016 140243238704960 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; W1104 14:34:02.364171 140243238704960 make_examples_core.py:273] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument.; [E::idx_find_and_load] Co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/492
https://github.com/google/deepvariant/issues/492:11778,Modifiability,extend,extend,11778,"azel.runfiles_o60bhxse/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_o60bhxse/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_o60bhxse/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 163, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_o60bhxse/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1569, in make_examples_runner; runtimes) = region_processor.process(region); File ""/tmp/Bazel.runfiles_o60bhxse/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 918, in process; reads = self.region_reads(; File ""/tmp/Bazel.runfiles_o60bhxse/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1024, in region_reads; raise err; File ""/tmp/Bazel.runfiles_o60bhxse/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1002, in region_reads; reads.extend(sam_reader.query(region)); File ""/tmp/Bazel.runfiles_o60bhxse/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 247, in query; return self._reader.query(region); File ""/tmp/Bazel.runfiles_o60bhxse/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 245, in query; return self._reader.query(region); ValueError: Failed precondition: Cannot query without an index; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:03.068893 139750224725824 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:03.193795 139750224725824 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; I1104 14:34:03.194288 139750224725824 make_examples_core.py:236] Task 3/4: Writing examples to /tmp/tmp6zw47x4_/make_examples.tfrecord-00003-of-00004.gz; I1104 14:34:03.194392 139750224725824 make_examples_core.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/492
https://github.com/google/deepvariant/issues/492:14022,Modifiability,extend,extend,14022,"azel.runfiles_j563zta4/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_j563zta4/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_j563zta4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 163, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_j563zta4/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1569, in make_examples_runner; runtimes) = region_processor.process(region); File ""/tmp/Bazel.runfiles_j563zta4/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 918, in process; reads = self.region_reads(; File ""/tmp/Bazel.runfiles_j563zta4/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1024, in region_reads; raise err; File ""/tmp/Bazel.runfiles_j563zta4/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1002, in region_reads; reads.extend(sam_reader.query(region)); File ""/tmp/Bazel.runfiles_j563zta4/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 247, in query; return self._reader.query(region); File ""/tmp/Bazel.runfiles_j563zta4/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 245, in query; return self._reader.query(region); ValueError: Failed precondition: Cannot query without an index; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:03.079088 140243238704960 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:03.208736 140243238704960 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; I1104 14:34:03.209183 140243238704960 make_examples_core.py:236] Task 2/4: Writing examples to /tmp/tmp6zw47x4_/make_examples.tfrecord-00002-of-00004.gz; I1104 14:34:03.209277 140243238704960 make_examples_core.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/492
https://github.com/google/deepvariant/issues/492:16266,Modifiability,extend,extend,16266,"azel.runfiles_fkyy0r3x/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_fkyy0r3x/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_fkyy0r3x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 163, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_fkyy0r3x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1569, in make_examples_runner; runtimes) = region_processor.process(region); File ""/tmp/Bazel.runfiles_fkyy0r3x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 918, in process; reads = self.region_reads(; File ""/tmp/Bazel.runfiles_fkyy0r3x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1024, in region_reads; raise err; File ""/tmp/Bazel.runfiles_fkyy0r3x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1002, in region_reads; reads.extend(sam_reader.query(region)); File ""/tmp/Bazel.runfiles_fkyy0r3x/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 247, in query; return self._reader.query(region); File ""/tmp/Bazel.runfiles_fkyy0r3x/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 245, in query; return self._reader.query(region); ValueError: Failed precondition: Cannot query without an index; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:03.079069 139685650237248 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; [E::idx_find_and_load] Could not retrieve index file for '/input/G1_hap2.bam'; I1104 14:34:03.205049 139685650237248 genomics_reader.py:222] Reading /input/G1_hap2.bam with NativeSamReader; I1104 14:34:03.205483 139685650237248 make_examples_core.py:236] Task 0/4: Writing examples to /tmp/tmp6zw47x4_/make_examples.tfrecord-00000-of-00004.gz; I1104 14:34:03.205575 139685650237248 make_examples_core.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/492
https://github.com/google/deepvariant/issues/492:18510,Modifiability,extend,extend,18510,"/4: Writing examples to /tmp/tmp6zw47x4_/make_examples.tfrecord-00000-of-00004.gz; I1104 14:34:03.205575 139685650237248 make_examples_core.py:236] Task 0/4: Overhead for preparing inputs: 0 seconds; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 173, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 163, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1569, in make_examples_runner; runtimes) = region_processor.process(region); File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 918, in process; reads = self.region_reads(; File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1024, in region_reads; raise err; File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1002, in region_reads; reads.extend(sam_reader.query(region)); File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 247, in query; return self._reader.query(region); File ""/tmp/Bazel.runfiles_z12b2b_u/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 245, in query; return self._reader.query(region); ValueError: Failed precondition: Cannot query without an index; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/G1.asm.hic.hap2.p_ctg.fa --reads /input/G1_hap2.bam --examples /tmp/tmp6zw47x4_/make_examples.tfrecord@4.gz --task 3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/492
https://github.com/google/deepvariant/issues/496:644,Deployability,Install,Installation,644,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.2/docs/FAQ.md**:. **Describe the issue:**; Hello,. I would like to run deepvariant on a very depth datasets (up to 10K reads at the same locus). When I am looking to the VCF, I can see depth per allele at max 1.5K. Is it possible to modify the call_variant parameter to allow more reads per bp position ?; I am also wondering how I can see the full list of parameters for call_variant (the allowed flags to put in ""--call_variants_extra_args"" like min_fraction_snps, min_fraction_indels, ...). Thanks . **Setup**; - Operating system:CentOS; - DeepVariant version:1.2; - Installation method (Docker, built from source, etc.):docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?)PacBio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/496
https://github.com/google/deepvariant/issues/499:148,Availability,error,error,148,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:. **Describe the issue:**; Deepvariant dies with protobuf error message when using Docker containers for version 1.2.0 and above. Works with 1.1.0 container. . **Setup**; - Operating system: Centos7; - DeepVariant version: 1.2.0, 1.3.0, latest; - Installation method (Docker, built from source, etc.): Docker container, executed with Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): short reads, Novaseq 6000. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=Homo_sapiens_GRCh38_no_alts.fa.gz --reads Indiv_I33975_Sample_I33975-L2.dedup.bam --output_vcf=Indiv_I33975_Sample_I33975-L2.dedup.vcf.gz --output_gvcf=Indiv_I33975_Sample_I33975-L2.dedup.g.vcf.gz --regions=xgen-exome-research-panel-targets-v2.bed --num_shards=16; - ; - Error trace: (if applicable). Command output:; sys.exit(main(argv)); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_egfjk32i/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 160, in main; proto_utils.uses_fast_cpp_protos_or_die(); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_egfjk32i/runfiles/com_google_deepvariant/third_party/nucleus/util/proto_utils.py"", line 41, in uses_fast_cpp_protos_or_die; raise ValueError('Expected to be using C++ protobuf implementation '; ValueError: Expected to be using C++ protobuf implementation (api_implementation.Type() == ""cpp"") but it is python; Traceback (most recent call last):; File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(main); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/absl_py/absl/app.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/499
https://github.com/google/deepvariant/issues/499:941,Availability,Error,Error,941,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:. **Describe the issue:**; Deepvariant dies with protobuf error message when using Docker containers for version 1.2.0 and above. Works with 1.1.0 container. . **Setup**; - Operating system: Centos7; - DeepVariant version: 1.2.0, 1.3.0, latest; - Installation method (Docker, built from source, etc.): Docker container, executed with Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): short reads, Novaseq 6000. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=Homo_sapiens_GRCh38_no_alts.fa.gz --reads Indiv_I33975_Sample_I33975-L2.dedup.bam --output_vcf=Indiv_I33975_Sample_I33975-L2.dedup.vcf.gz --output_gvcf=Indiv_I33975_Sample_I33975-L2.dedup.g.vcf.gz --regions=xgen-exome-research-panel-targets-v2.bed --num_shards=16; - ; - Error trace: (if applicable). Command output:; sys.exit(main(argv)); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_egfjk32i/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 160, in main; proto_utils.uses_fast_cpp_protos_or_die(); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_egfjk32i/runfiles/com_google_deepvariant/third_party/nucleus/util/proto_utils.py"", line 41, in uses_fast_cpp_protos_or_die; raise ValueError('Expected to be using C++ protobuf implementation '; ValueError: Expected to be using C++ protobuf implementation (api_implementation.Type() == ""cpp"") but it is python; Traceback (most recent call last):; File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(main); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/absl_py/absl/app.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/499
https://github.com/google/deepvariant/issues/499:337,Deployability,Install,Installation,337,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:. **Describe the issue:**; Deepvariant dies with protobuf error message when using Docker containers for version 1.2.0 and above. Works with 1.1.0 container. . **Setup**; - Operating system: Centos7; - DeepVariant version: 1.2.0, 1.3.0, latest; - Installation method (Docker, built from source, etc.): Docker container, executed with Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): short reads, Novaseq 6000. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=Homo_sapiens_GRCh38_no_alts.fa.gz --reads Indiv_I33975_Sample_I33975-L2.dedup.bam --output_vcf=Indiv_I33975_Sample_I33975-L2.dedup.vcf.gz --output_gvcf=Indiv_I33975_Sample_I33975-L2.dedup.g.vcf.gz --regions=xgen-exome-research-panel-targets-v2.bed --num_shards=16; - ; - Error trace: (if applicable). Command output:; sys.exit(main(argv)); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_egfjk32i/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 160, in main; proto_utils.uses_fast_cpp_protos_or_die(); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_egfjk32i/runfiles/com_google_deepvariant/third_party/nucleus/util/proto_utils.py"", line 41, in uses_fast_cpp_protos_or_die; raise ValueError('Expected to be using C++ protobuf implementation '; ValueError: Expected to be using C++ protobuf implementation (api_implementation.Type() == ""cpp"") but it is python; Traceback (most recent call last):; File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(main); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/absl_py/absl/app.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/499
https://github.com/google/deepvariant/issues/499:154,Integrability,message,message,154,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:. **Describe the issue:**; Deepvariant dies with protobuf error message when using Docker containers for version 1.2.0 and above. Works with 1.1.0 container. . **Setup**; - Operating system: Centos7; - DeepVariant version: 1.2.0, 1.3.0, latest; - Installation method (Docker, built from source, etc.): Docker container, executed with Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): short reads, Novaseq 6000. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=Homo_sapiens_GRCh38_no_alts.fa.gz --reads Indiv_I33975_Sample_I33975-L2.dedup.bam --output_vcf=Indiv_I33975_Sample_I33975-L2.dedup.vcf.gz --output_gvcf=Indiv_I33975_Sample_I33975-L2.dedup.g.vcf.gz --regions=xgen-exome-research-panel-targets-v2.bed --num_shards=16; - ; - Error trace: (if applicable). Command output:; sys.exit(main(argv)); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_egfjk32i/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 160, in main; proto_utils.uses_fast_cpp_protos_or_die(); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_egfjk32i/runfiles/com_google_deepvariant/third_party/nucleus/util/proto_utils.py"", line 41, in uses_fast_cpp_protos_or_die; raise ValueError('Expected to be using C++ protobuf implementation '; ValueError: Expected to be using C++ protobuf implementation (api_implementation.Type() == ""cpp"") but it is python; Traceback (most recent call last):; File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(main); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_24d7l2zv/runfiles/absl_py/absl/app.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/499
https://github.com/google/deepvariant/issues/499:5477,Testability,test,test,5477,"sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(main); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 160, in main; proto_utils.uses_fast_cpp_protos_or_die(); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/com_google_deepvariant/third_party/nucleus/util/proto_utils.py"", line 41, in uses_fast_cpp_protos_or_die; raise ValueError('Expected to be using C++ protobuf implementation '; ValueError: Expected to be using C++ protobuf implementation (api_implementation.Type() == ""cpp"") but it is python; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref Homo_sapiens_GRCh38_no_alts.fa.gz --reads Indiv_I33975_Sample_I33975-L2.dedup.bam --examples /scratch/SlurmTMP/sukmb352.4618444/tmpdh6mqoql/make_examples.tfrecord@16.gz --gvcf /scratch/SlurmTMP/sukmb352.4618444/tmpdh6mqoql/gvcf.tfrecord@16.gz --regions xgen-exome-research-panel-targets-v2.bed --task 14; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref Homo_sapiens_GRCh38_no_alts.fa.gz --reads Indiv_I33975_Sample_I33975-L2.dedup.bam --examples /scratch/SlurmTMP/sukmb352.4618444/tmpdh6mqoql/make_examples.tfrecord@16.gz --gvcf /scratch/SlurmTMP/sukmb352.4618444/tmpdh6mqoql/gvcf.tfrecord@16.gz --regions xgen-exome-research-panel-targets-v2.bed --task 7. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/499
https://github.com/google/deepvariant/issues/499:5513,Testability,test,test,5513,"sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(main); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 160, in main; proto_utils.uses_fast_cpp_protos_or_die(); File ""/scratch/SlurmTMP/sukmb352.4618444/Bazel.runfiles_ipgylakz/runfiles/com_google_deepvariant/third_party/nucleus/util/proto_utils.py"", line 41, in uses_fast_cpp_protos_or_die; raise ValueError('Expected to be using C++ protobuf implementation '; ValueError: Expected to be using C++ protobuf implementation (api_implementation.Type() == ""cpp"") but it is python; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref Homo_sapiens_GRCh38_no_alts.fa.gz --reads Indiv_I33975_Sample_I33975-L2.dedup.bam --examples /scratch/SlurmTMP/sukmb352.4618444/tmpdh6mqoql/make_examples.tfrecord@16.gz --gvcf /scratch/SlurmTMP/sukmb352.4618444/tmpdh6mqoql/gvcf.tfrecord@16.gz --regions xgen-exome-research-panel-targets-v2.bed --task 14; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref Homo_sapiens_GRCh38_no_alts.fa.gz --reads Indiv_I33975_Sample_I33975-L2.dedup.bam --examples /scratch/SlurmTMP/sukmb352.4618444/tmpdh6mqoql/make_examples.tfrecord@16.gz --gvcf /scratch/SlurmTMP/sukmb352.4618444/tmpdh6mqoql/gvcf.tfrecord@16.gz --regions xgen-exome-research-panel-targets-v2.bed --task 7. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/499
https://github.com/google/deepvariant/issues/500:163,Availability,error,error,163,"Hi,. I was trying to train a PacBio HiFi model for bacteria (surprisingly the default DeepVariant 1.3.0 PacBio model seems to work pretty well), but I run into an error with the `model_train` binary such that this command works:. ```bash; GCS_PRETRAINED_MODEL=""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"". singularity exec --nv ~/bin/deepvariant-1.3.0-gpu.simg \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""examples/training_set.dataset_config.pbtxt"" \; --train_dir=""training"" \; --model_name=""inception_v3"" \; --number_of_steps=900 \; --save_interval_secs=300 \; --start_from_checkpoint=""${GCS_PRETRAINED_MODEL}""; ```. But, when I try the following. ```bash; GCS_PRETRAINED_MODEL=""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-pacbio_standard/model.ckpt"". singularity exec --nv ~/bin/deepvariant-1.3.0-gpu.simg \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""examples/training_set.dataset_config.pbtxt"" \; --train_dir=""training"" \; --model_name=""inception_v3"" \; --number_of_steps=900 \; --save_interval_secs=300 \; --start_from_checkpoint=""${GCS_PRETRAINED_MODEL}""; ```; I get the following error presumably because the `model_train` binary does make the correct tensor shape for the PacBio model's checkpoint?. ```python; Warm-starting variables only in TRAINABLE_VARIABLES.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 298, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_eh_1d4e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/500
https://github.com/google/deepvariant/issues/500:1216,Availability,error,error,1216,"`model_train` binary such that this command works:. ```bash; GCS_PRETRAINED_MODEL=""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"". singularity exec --nv ~/bin/deepvariant-1.3.0-gpu.simg \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""examples/training_set.dataset_config.pbtxt"" \; --train_dir=""training"" \; --model_name=""inception_v3"" \; --number_of_steps=900 \; --save_interval_secs=300 \; --start_from_checkpoint=""${GCS_PRETRAINED_MODEL}""; ```. But, when I try the following. ```bash; GCS_PRETRAINED_MODEL=""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-pacbio_standard/model.ckpt"". singularity exec --nv ~/bin/deepvariant-1.3.0-gpu.simg \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""examples/training_set.dataset_config.pbtxt"" \; --train_dir=""training"" \; --model_name=""inception_v3"" \; --number_of_steps=900 \; --save_interval_secs=300 \; --start_from_checkpoint=""${GCS_PRETRAINED_MODEL}""; ```; I get the following error presumably because the `model_train` binary does make the correct tensor shape for the PacBio model's checkpoint?. ```python; Warm-starting variables only in TRAINABLE_VARIABLES.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 298, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 283, in main; parse_and_run(); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/500
https://github.com/google/deepvariant/issues/500:1324,Availability,checkpoint,checkpoint,1324,"`model_train` binary such that this command works:. ```bash; GCS_PRETRAINED_MODEL=""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"". singularity exec --nv ~/bin/deepvariant-1.3.0-gpu.simg \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""examples/training_set.dataset_config.pbtxt"" \; --train_dir=""training"" \; --model_name=""inception_v3"" \; --number_of_steps=900 \; --save_interval_secs=300 \; --start_from_checkpoint=""${GCS_PRETRAINED_MODEL}""; ```. But, when I try the following. ```bash; GCS_PRETRAINED_MODEL=""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-pacbio_standard/model.ckpt"". singularity exec --nv ~/bin/deepvariant-1.3.0-gpu.simg \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""examples/training_set.dataset_config.pbtxt"" \; --train_dir=""training"" \; --model_name=""inception_v3"" \; --number_of_steps=900 \; --save_interval_secs=300 \; --start_from_checkpoint=""${GCS_PRETRAINED_MODEL}""; ```; I get the following error presumably because the `model_train` binary does make the correct tensor shape for the PacBio model's checkpoint?. ```python; Warm-starting variables only in TRAINABLE_VARIABLES.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 298, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 283, in main; parse_and_run(); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/500
https://github.com/google/deepvariant/issues/500:4518,Availability,checkpoint,checkpoint,4518,"s/tensorflow_estimator/python/estimator/estimator.py"", line 1175, in _train_model; return self._train_model_default(input_fn, hooks, saving_listeners); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1206, in _train_model_default; return self._train_with_estimator_spec(estimator_spec, worker_hooks,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1388, in _train_with_estimator_spec; tf.compat.v1.train.warm_start(*self._warm_start_settings); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/warm_starting_util.py"", line 532, in warm_start; checkpoint_utils.init_from_checkpoint(ckpt_to_initialize_from, vocabless_vars); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 311, in init_from_checkpoint; distribution_strategy_context.get_replica_context().merge_call(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 3048, in merge_call; return self._merge_call(merge_fn, args, kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 3055, in _merge_call; return merge_fn(self._strategy, *args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py"", line 597, in wrapper; return func(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 306, in <lambda>; init_from_checkpoint_fn = lambda _: _init_from_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 347, in _init_from_checkpoint; raise ValueError(; ValueError: Shape of variable InceptionV3/Conv2d_1a_3x3/weights:0 ((3, 3, 6, 32)) doesn't match with shape of tensor InceptionV3/Conv2d_1a_3x3/weights ([3, 3, 9, 32]) from checkpoint reader.; ```. How does one specify the shape in `model_train`?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/500
https://github.com/google/deepvariant/issues/500:3981,Integrability,wrap,wrapper,3981,"s/tensorflow_estimator/python/estimator/estimator.py"", line 1175, in _train_model; return self._train_model_default(input_fn, hooks, saving_listeners); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1206, in _train_model_default; return self._train_with_estimator_spec(estimator_spec, worker_hooks,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1388, in _train_with_estimator_spec; tf.compat.v1.train.warm_start(*self._warm_start_settings); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/warm_starting_util.py"", line 532, in warm_start; checkpoint_utils.init_from_checkpoint(ckpt_to_initialize_from, vocabless_vars); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 311, in init_from_checkpoint; distribution_strategy_context.get_replica_context().merge_call(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 3048, in merge_call; return self._merge_call(merge_fn, args, kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 3055, in _merge_call; return merge_fn(self._strategy, *args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py"", line 597, in wrapper; return func(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 306, in <lambda>; init_from_checkpoint_fn = lambda _: _init_from_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 347, in _init_from_checkpoint; raise ValueError(; ValueError: Shape of variable InceptionV3/Conv2d_1a_3x3/weights:0 ((3, 3, 6, 32)) doesn't match with shape of tensor InceptionV3/Conv2d_1a_3x3/weights ([3, 3, 9, 32]) from checkpoint reader.; ```. How does one specify the shape in `model_train`?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/500
https://github.com/google/deepvariant/issues/500:1362,Modifiability,variab,variables,1362,"gularity exec --nv ~/bin/deepvariant-1.3.0-gpu.simg \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""examples/training_set.dataset_config.pbtxt"" \; --train_dir=""training"" \; --model_name=""inception_v3"" \; --number_of_steps=900 \; --save_interval_secs=300 \; --start_from_checkpoint=""${GCS_PRETRAINED_MODEL}""; ```. But, when I try the following. ```bash; GCS_PRETRAINED_MODEL=""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-pacbio_standard/model.ckpt"". singularity exec --nv ~/bin/deepvariant-1.3.0-gpu.simg \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""examples/training_set.dataset_config.pbtxt"" \; --train_dir=""training"" \; --model_name=""inception_v3"" \; --number_of_steps=900 \; --save_interval_secs=300 \; --start_from_checkpoint=""${GCS_PRETRAINED_MODEL}""; ```; I get the following error presumably because the `model_train` binary does make the correct tensor shape for the PacBio model's checkpoint?. ```python; Warm-starting variables only in TRAINABLE_VARIABLES.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 298, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 283, in main; parse_and_run(); File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 229, in parse_and_run; return run(; File ""/tmp/Bazel.runfiles_eh_1d4ep/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 191, in run; estimator.train(;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/500
https://github.com/google/deepvariant/issues/500:4367,Modifiability,variab,variable,4367,"s/tensorflow_estimator/python/estimator/estimator.py"", line 1175, in _train_model; return self._train_model_default(input_fn, hooks, saving_listeners); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1206, in _train_model_default; return self._train_with_estimator_spec(estimator_spec, worker_hooks,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1388, in _train_with_estimator_spec; tf.compat.v1.train.warm_start(*self._warm_start_settings); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/warm_starting_util.py"", line 532, in warm_start; checkpoint_utils.init_from_checkpoint(ckpt_to_initialize_from, vocabless_vars); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 311, in init_from_checkpoint; distribution_strategy_context.get_replica_context().merge_call(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 3048, in merge_call; return self._merge_call(merge_fn, args, kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 3055, in _merge_call; return merge_fn(self._strategy, *args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py"", line 597, in wrapper; return func(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 306, in <lambda>; init_from_checkpoint_fn = lambda _: _init_from_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/checkpoint_utils.py"", line 347, in _init_from_checkpoint; raise ValueError(; ValueError: Shape of variable InceptionV3/Conv2d_1a_3x3/weights:0 ((3, 3, 6, 32)) doesn't match with shape of tensor InceptionV3/Conv2d_1a_3x3/weights ([3, 3, 9, 32]) from checkpoint reader.; ```. How does one specify the shape in `model_train`?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/500
https://github.com/google/deepvariant/issues/501:378,Deployability,Install,Installation,378,"**Describe the issue:**; When calling I get a low number of records in a vcf file (20-40k variants). In comparison with GATK there are at last 10 times less variants generated. Also, it is much less than from 1 thousand genomes deepvariant dataset truncated to the same exome region - 1.7 mln records. **Setup**; - Operating system:; CentoOS 7; - DeepVariant version:; 1.3.0; - Installation method (Docker, built from source, etc.):; podman/singularity; - Type of data:; The data are human's whole exome sequences from Illumina. As a reference I use hg38 with alt contigs. I use truseq v1.2 exome bed file. Besides using bwa-mem2, samtools merge and sort there is not much preprocessing. **Steps to reproduce:**; - Command:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=\$PWD/$idxbase \; --reads=\$PWD/${sample_id}.bam \; --regions=\$PWD/$bed_file \; --output_vcf=\$PWD/${sample_id}.vcf.gz \; --output_gvcf=\$PWD/${sample_id}.g.vcf.gz \; --num_shards=${task.cpus}. ```. I also used glnexus; ```; glnexus_cli ; --bed /in/truseq-dna-exome-targeted-regions-manifest-v1-2.bed ; --config DeepVariantWES /in/vcf_deepvariant/*.g.vcf.gz > merged.bcf; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/501
https://github.com/google/deepvariant/issues/501:1102,Modifiability,config,config,1102,"**Describe the issue:**; When calling I get a low number of records in a vcf file (20-40k variants). In comparison with GATK there are at last 10 times less variants generated. Also, it is much less than from 1 thousand genomes deepvariant dataset truncated to the same exome region - 1.7 mln records. **Setup**; - Operating system:; CentoOS 7; - DeepVariant version:; 1.3.0; - Installation method (Docker, built from source, etc.):; podman/singularity; - Type of data:; The data are human's whole exome sequences from Illumina. As a reference I use hg38 with alt contigs. I use truseq v1.2 exome bed file. Besides using bwa-mem2, samtools merge and sort there is not much preprocessing. **Steps to reproduce:**; - Command:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=\$PWD/$idxbase \; --reads=\$PWD/${sample_id}.bam \; --regions=\$PWD/$bed_file \; --output_vcf=\$PWD/${sample_id}.vcf.gz \; --output_gvcf=\$PWD/${sample_id}.g.vcf.gz \; --num_shards=${task.cpus}. ```. I also used glnexus; ```; glnexus_cli ; --bed /in/truseq-dna-exome-targeted-regions-manifest-v1-2.bed ; --config DeepVariantWES /in/vcf_deepvariant/*.g.vcf.gz > merged.bcf; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/501
https://github.com/google/deepvariant/issues/506:442,Performance,load,load,442,"This might be an obvious question but i cannot work it out, what does the -B mean?. For example from your singularity guide: . ```; singularity run **-B** /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; ```. Also, if using a singularity container would you use it like this (fake link to the container):. ```; wget https://containers/deepvariant_1.3.0.sif ; module load singularity. singularity run deepvariant_1.3.0.sif -B --model_type=WES -ref=PolyposisExomeAnalysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna; --reads=PolyposisExomeAnalysis/samtoolssort/{}PE_samtoolssorted.bam; --output_vcf=PolyposisExomeAnalysis/deepvariant/vcf/PE_output.vcf.gz ; --output_gvcf=PolyposisExomeAnalysis/deepvariant/gvcf/PE_output.vcf.gz; --intermediate_results_dir PolyposisExomeAnalysis/deepvariant/intermediateresults/; ```. Sorry, still figuring it out! Thanks, Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/506
https://github.com/google/deepvariant/issues/506:118,Usability,guid,guide,118,"This might be an obvious question but i cannot work it out, what does the -B mean?. For example from your singularity guide: . ```; singularity run **-B** /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; ```. Also, if using a singularity container would you use it like this (fake link to the container):. ```; wget https://containers/deepvariant_1.3.0.sif ; module load singularity. singularity run deepvariant_1.3.0.sif -B --model_type=WES -ref=PolyposisExomeAnalysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna; --reads=PolyposisExomeAnalysis/samtoolssort/{}PE_samtoolssorted.bam; --output_vcf=PolyposisExomeAnalysis/deepvariant/vcf/PE_output.vcf.gz ; --output_gvcf=PolyposisExomeAnalysis/deepvariant/gvcf/PE_output.vcf.gz; --intermediate_results_dir PolyposisExomeAnalysis/deepvariant/intermediateresults/; ```. Sorry, still figuring it out! Thanks, Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/506
https://github.com/google/deepvariant/issues/511:195,Availability,error,error,195,"Hello, latest bazel build (5.0.0) dropped support of `--incompatible_prohibit_aapt1` flag ass you can see in patch notes https://blog.bazel.build/2022/01/19/bazel-5.0.html#android and here is my error:; ```; + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api deepvariant/...; [0m[91mINFO: Reading rc options for 'test' from /soft/tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2; [0m[91mERROR: --noincompatible_prohibit_aapt1 :: Unrecognized option: --noincompatible_prohibit_aapt1; ```. Tensorflow removed this flag from their `.bazelrc` in June 2021 https://github.com/tensorflow/tensorflow/pull/50310 . Now deepvariant image cannot be build with latest `bazel` due to this - I ask you to update tensorflow version where this is fixed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/511
https://github.com/google/deepvariant/issues/511:109,Deployability,patch,patch,109,"Hello, latest bazel build (5.0.0) dropped support of `--incompatible_prohibit_aapt1` flag ass you can see in patch notes https://blog.bazel.build/2022/01/19/bazel-5.0.html#android and here is my error:; ```; + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api deepvariant/...; [0m[91mINFO: Reading rc options for 'test' from /soft/tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2; [0m[91mERROR: --noincompatible_prohibit_aapt1 :: Unrecognized option: --noincompatible_prohibit_aapt1; ```. Tensorflow removed this flag from their `.bazelrc` in June 2021 https://github.com/tensorflow/tensorflow/pull/50310 . Now deepvariant image cannot be build with latest `bazel` due to this - I ask you to update tensorflow version where this is fixed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/511
https://github.com/google/deepvariant/issues/511:1266,Deployability,update,update,1266,"Hello, latest bazel build (5.0.0) dropped support of `--incompatible_prohibit_aapt1` flag ass you can see in patch notes https://blog.bazel.build/2022/01/19/bazel-5.0.html#android and here is my error:; ```; + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api deepvariant/...; [0m[91mINFO: Reading rc options for 'test' from /soft/tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2; [0m[91mERROR: --noincompatible_prohibit_aapt1 :: Unrecognized option: --noincompatible_prohibit_aapt1; ```. Tensorflow removed this flag from their `.bazelrc` in June 2021 https://github.com/tensorflow/tensorflow/pull/50310 . Now deepvariant image cannot be build with latest `bazel` due to this - I ask you to update tensorflow version where this is fixed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/511
https://github.com/google/deepvariant/issues/511:428,Modifiability,Inherit,Inherited,428,"Hello, latest bazel build (5.0.0) dropped support of `--incompatible_prohibit_aapt1` flag ass you can see in patch notes https://blog.bazel.build/2022/01/19/bazel-5.0.html#android and here is my error:; ```; + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api deepvariant/...; [0m[91mINFO: Reading rc options for 'test' from /soft/tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2; [0m[91mERROR: --noincompatible_prohibit_aapt1 :: Unrecognized option: --noincompatible_prohibit_aapt1; ```. Tensorflow removed this flag from their `.bazelrc` in June 2021 https://github.com/tensorflow/tensorflow/pull/50310 . Now deepvariant image cannot be build with latest `bazel` due to this - I ask you to update tensorflow version where this is fixed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/511
https://github.com/google/deepvariant/issues/511:922,Modifiability,config,config,922,"Hello, latest bazel build (5.0.0) dropped support of `--incompatible_prohibit_aapt1` flag ass you can see in patch notes https://blog.bazel.build/2022/01/19/bazel-5.0.html#android and here is my error:; ```; + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api deepvariant/...; [0m[91mINFO: Reading rc options for 'test' from /soft/tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2; [0m[91mERROR: --noincompatible_prohibit_aapt1 :: Unrecognized option: --noincompatible_prohibit_aapt1; ```. Tensorflow removed this flag from their `.bazelrc` in June 2021 https://github.com/tensorflow/tensorflow/pull/50310 . Now deepvariant image cannot be build with latest `bazel` due to this - I ask you to update tensorflow version where this is fixed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/511
https://github.com/google/deepvariant/issues/511:942,Modifiability,config,config,942,"Hello, latest bazel build (5.0.0) dropped support of `--incompatible_prohibit_aapt1` flag ass you can see in patch notes https://blog.bazel.build/2022/01/19/bazel-5.0.html#android and here is my error:; ```; + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api deepvariant/...; [0m[91mINFO: Reading rc options for 'test' from /soft/tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2; [0m[91mERROR: --noincompatible_prohibit_aapt1 :: Unrecognized option: --noincompatible_prohibit_aapt1; ```. Tensorflow removed this flag from their `.bazelrc` in June 2021 https://github.com/tensorflow/tensorflow/pull/50310 . Now deepvariant image cannot be build with latest `bazel` due to this - I ask you to update tensorflow version where this is fixed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/511
https://github.com/google/deepvariant/issues/511:216,Testability,test,test,216,"Hello, latest bazel build (5.0.0) dropped support of `--incompatible_prohibit_aapt1` flag ass you can see in patch notes https://blog.bazel.build/2022/01/19/bazel-5.0.html#android and here is my error:; ```; + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api deepvariant/...; [0m[91mINFO: Reading rc options for 'test' from /soft/tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2; [0m[91mERROR: --noincompatible_prohibit_aapt1 :: Unrecognized option: --noincompatible_prohibit_aapt1; ```. Tensorflow removed this flag from their `.bazelrc` in June 2021 https://github.com/tensorflow/tensorflow/pull/50310 . Now deepvariant image cannot be build with latest `bazel` due to this - I ask you to update tensorflow version where this is fixed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/511
https://github.com/google/deepvariant/issues/511:389,Testability,test,test,389,"Hello, latest bazel build (5.0.0) dropped support of `--incompatible_prohibit_aapt1` flag ass you can see in patch notes https://blog.bazel.build/2022/01/19/bazel-5.0.html#android and here is my error:; ```; + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api deepvariant/...; [0m[91mINFO: Reading rc options for 'test' from /soft/tensorflow/.bazelrc:; Inherited 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2; [0m[91mERROR: --noincompatible_prohibit_aapt1 :: Unrecognized option: --noincompatible_prohibit_aapt1; ```. Tensorflow removed this flag from their `.bazelrc` in June 2021 https://github.com/tensorflow/tensorflow/pull/50310 . Now deepvariant image cannot be build with latest `bazel` due to this - I ask you to update tensorflow version where this is fixed.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/511
https://github.com/google/deepvariant/issues/512:304,Availability,Error,Error,304,"Hello, more of a question than an issue: what does the ""Could not create PileupImage for candidate"" mean during make_examples? What triggers it?. **Setup**; - DeepVariant version: 1.1.0 and 1.3.0; - Installation method: Singularity; - Type of data: illumina on a Pinus genome (big, repetitive genome). **Error trace** ; ```; W1203 19:21:43.514668 139865530996480 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_1:9 ; W1203 19:21:43.515001 139865530996480 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_1:83 ; W1203 19:21:43.515132 139865530996480 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_1:91 ; W1203 19:21:48.118362 140507900241664 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_4:129804; W1203 19:21:51.183064 139737683482368 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_19:82 ; W1203 19:21:51.183443 139737683482368 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_19:106 ; ```. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/512
https://github.com/google/deepvariant/issues/512:199,Deployability,Install,Installation,199,"Hello, more of a question than an issue: what does the ""Could not create PileupImage for candidate"" mean during make_examples? What triggers it?. **Setup**; - DeepVariant version: 1.1.0 and 1.3.0; - Installation method: Singularity; - Type of data: illumina on a Pinus genome (big, repetitive genome). **Error trace** ; ```; W1203 19:21:43.514668 139865530996480 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_1:9 ; W1203 19:21:43.515001 139865530996480 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_1:83 ; W1203 19:21:43.515132 139865530996480 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_1:91 ; W1203 19:21:48.118362 140507900241664 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_4:129804; W1203 19:21:51.183064 139737683482368 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_19:82 ; W1203 19:21:51.183443 139737683482368 make_examples.py:1855] Could not create PileupImage for candidate at scaffold_19:106 ; ```. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/512
https://github.com/google/deepvariant/issues/513:176,Availability,error,error,176,"Hi. when I try to pull the deepvariant docker image via singularity using the following command:; singularity pull docker://google/deepvariant:""1.3.0""; it return the following error:; WARNING: pull for Docker Hub is not guaranteed to produce the; WARNING: same image on repeated pull. Use Singularity Registry; WARNING: (shub://) to pull exactly equivalent images.; ERROR Authentication error, exiting.; Cleaning up...; ERROR: pulling container failed!. could you please help. I don't have the permission to install docker.; Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/513
https://github.com/google/deepvariant/issues/513:366,Availability,ERROR,ERROR,366,"Hi. when I try to pull the deepvariant docker image via singularity using the following command:; singularity pull docker://google/deepvariant:""1.3.0""; it return the following error:; WARNING: pull for Docker Hub is not guaranteed to produce the; WARNING: same image on repeated pull. Use Singularity Registry; WARNING: (shub://) to pull exactly equivalent images.; ERROR Authentication error, exiting.; Cleaning up...; ERROR: pulling container failed!. could you please help. I don't have the permission to install docker.; Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/513
https://github.com/google/deepvariant/issues/513:387,Availability,error,error,387,"Hi. when I try to pull the deepvariant docker image via singularity using the following command:; singularity pull docker://google/deepvariant:""1.3.0""; it return the following error:; WARNING: pull for Docker Hub is not guaranteed to produce the; WARNING: same image on repeated pull. Use Singularity Registry; WARNING: (shub://) to pull exactly equivalent images.; ERROR Authentication error, exiting.; Cleaning up...; ERROR: pulling container failed!. could you please help. I don't have the permission to install docker.; Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/513
https://github.com/google/deepvariant/issues/513:420,Availability,ERROR,ERROR,420,"Hi. when I try to pull the deepvariant docker image via singularity using the following command:; singularity pull docker://google/deepvariant:""1.3.0""; it return the following error:; WARNING: pull for Docker Hub is not guaranteed to produce the; WARNING: same image on repeated pull. Use Singularity Registry; WARNING: (shub://) to pull exactly equivalent images.; ERROR Authentication error, exiting.; Cleaning up...; ERROR: pulling container failed!. could you please help. I don't have the permission to install docker.; Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/513
https://github.com/google/deepvariant/issues/513:508,Deployability,install,install,508,"Hi. when I try to pull the deepvariant docker image via singularity using the following command:; singularity pull docker://google/deepvariant:""1.3.0""; it return the following error:; WARNING: pull for Docker Hub is not guaranteed to produce the; WARNING: same image on repeated pull. Use Singularity Registry; WARNING: (shub://) to pull exactly equivalent images.; ERROR Authentication error, exiting.; Cleaning up...; ERROR: pulling container failed!. could you please help. I don't have the permission to install docker.; Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/513
https://github.com/google/deepvariant/issues/513:372,Security,Authenticat,Authentication,372,"Hi. when I try to pull the deepvariant docker image via singularity using the following command:; singularity pull docker://google/deepvariant:""1.3.0""; it return the following error:; WARNING: pull for Docker Hub is not guaranteed to produce the; WARNING: same image on repeated pull. Use Singularity Registry; WARNING: (shub://) to pull exactly equivalent images.; ERROR Authentication error, exiting.; Cleaning up...; ERROR: pulling container failed!. could you please help. I don't have the permission to install docker.; Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/513
https://github.com/google/deepvariant/issues/514:1606,Availability,error,error,1606,"-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>; _ll.load_library(_main_dir); File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library; py_tf.TF_LoadLibrary(lib); tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb; ```. I'm wondering if this error can help highlight the error I'm experiencing? . Is there something I can run with CUDA to test that implementation on our new GPU server?. Than",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:2465,Availability,error,error,2465,"""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>; _ll.load_library(_main_dir); File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library; py_tf.TF_LoadLibrary(lib); tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb; ```. I'm wondering if this error can help highlight the error I'm experiencing? . Is there something I can run with CUDA to test that implementation on our new GPU server?. Thanks!; Phil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:2494,Availability,error,error,2494,"""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>; _ll.load_library(_main_dir); File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library; py_tf.TF_LoadLibrary(lib); tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb; ```. I'm wondering if this error can help highlight the error I'm experiencing? . Is there something I can run with CUDA to test that implementation on our new GPU server?. Thanks!; Phil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:31,Deployability,install,installation,31,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:324,Performance,load,loaded,324,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:676,Performance,Load,Load,676,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:697,Performance,load,load,697,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:722,Performance,load,load,722,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:753,Performance,load,load,753,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:783,Performance,load,load,783,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:810,Performance,load,load,810,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:839,Performance,load,load,839,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:870,Performance,load,load,870,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:616,Testability,test,testdata,616,"Hello,. I'm trying to debug my installation of the singularity GPU version for a new C4140 GPU node with Tesla V100s. I've run the CPU version successfully in production and am very happy with it, but the shift to GPU is giving me trouble, likely running into an issue with CUDA or TensorFlow. . I have several CUDA modules loaded, but perhaps I'm missing one of the key libraries? ; I have TensorFlow in a conda environment (although that's probably satisfied inside the singularity image)?. Here's the code I'm running from the Quickstart:; ```; OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:2562,Testability,test,test,2562,"""; mkdir -p ""${OUTPUT_DIR}"". BIN_VERSION=""1.3.0"". # Load modules; module load singularity; module load cuda-dcgm/2.2.9.1; module load cuda11.4/toolkit; module load cuda11.4/blas; module load cuda11.4/nsight; module load cuda11.4/profiler; module load cuda11.4/fft; source /mnt/common/Precision/Miniconda3/opt/miniconda3/etc/profile.d/conda.sh; conda activate TensorFlow_GPU. # Pull the image.; singularity pull docker://google/deepvariant:""${BIN_VERSION}-gpu"". # Run; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; --nv \; docker://google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir""; ```. And here's my error:; ```; 2022-02-07 11:50:52.952780: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>; _ll.load_library(_main_dir); File ""/home/BCRICWH.LAN/prichmond/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library; py_tf.TF_LoadLibrary(lib); tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringERKNS_15OpKernelContextEb; ```. I'm wondering if this error can help highlight the error I'm experiencing? . Is there something I can run with CUDA to test that implementation on our new GPU server?. Thanks!; Phil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/515:639,Availability,error,error,639,"Hello. OS: Scicore Cluster, Linux; Deep Variant version:1.2.0; Installation: Singularity; Instrument: Ilumina; Data type: Whole exome sequencing analysis. I used the script given from this site:https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-exome-case-study.md. I edited the script to run in the cluster here:; ```; #!/bin/bash. #SBATCH --job-name=Deepvariant_debug; #SBATCH --cpus-per-task=2 # change this according to your needs; #SBATCH --mem=8G # change this according to your needs; #SBATCH --qos=30min # this was just for testing, but the example runs in less than 30 minutes; #SBATCH --output=myrun.o%j; #SBATCH --error=myrun.e%j. mkdir -p output; mkdir -p /scicore/home/cichon/GROUP/Ilumina/output/intermediate_results_dir. ulimit -u 10000; BIN_VERSION=""1.2.0""; # OUTPUT_DIR and INPUT_DIR should reside and exist inside your $HOME folder; export OUTPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output ; export INPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:2596,Availability,error,error,2596,"IR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/Twist_ComprehensiveExome_targets_hg38.bed; --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.vcf.gz \; --output_gvcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.gvcf.gz \; --call_variants_extra_args=""use_openvino=true"" \; --num_shards=$(nproc) \; --intermediate_results_dir=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/intermediate_results_dir \; --dry_run=true; ```. After reading the line, where the interval bed file is given as an input, it gives an error that output.vcf is not found. Then I get the below error as well:. `/var/lib/slurm/slurmd/job31271228/slurm_script: line 29: --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.vcf.gz: No such file or directory`. I am confused, does the interval file step, require vcf file. Why the output files are not created?. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:2653,Availability,error,error,2653,"IR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/Twist_ComprehensiveExome_targets_hg38.bed; --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.vcf.gz \; --output_gvcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.gvcf.gz \; --call_variants_extra_args=""use_openvino=true"" \; --num_shards=$(nproc) \; --intermediate_results_dir=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/intermediate_results_dir \; --dry_run=true; ```. After reading the line, where the interval bed file is given as an input, it gives an error that output.vcf is not found. Then I get the below error as well:. `/var/lib/slurm/slurmd/job31271228/slurm_script: line 29: --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.vcf.gz: No such file or directory`. I am confused, does the interval file step, require vcf file. Why the output files are not created?. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:63,Deployability,Install,Installation,63,"Hello. OS: Scicore Cluster, Linux; Deep Variant version:1.2.0; Installation: Singularity; Instrument: Ilumina; Data type: Whole exome sequencing analysis. I used the script given from this site:https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-exome-case-study.md. I edited the script to run in the cluster here:; ```; #!/bin/bash. #SBATCH --job-name=Deepvariant_debug; #SBATCH --cpus-per-task=2 # change this according to your needs; #SBATCH --mem=8G # change this according to your needs; #SBATCH --qos=30min # this was just for testing, but the example runs in less than 30 minutes; #SBATCH --output=myrun.o%j; #SBATCH --error=myrun.e%j. mkdir -p output; mkdir -p /scicore/home/cichon/GROUP/Ilumina/output/intermediate_results_dir. ulimit -u 10000; BIN_VERSION=""1.2.0""; # OUTPUT_DIR and INPUT_DIR should reside and exist inside your $HOME folder; export OUTPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output ; export INPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:1073,Modifiability,variab,variables,1073," the script given from this site:https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-exome-case-study.md. I edited the script to run in the cluster here:; ```; #!/bin/bash. #SBATCH --job-name=Deepvariant_debug; #SBATCH --cpus-per-task=2 # change this according to your needs; #SBATCH --mem=8G # change this according to your needs; #SBATCH --qos=30min # this was just for testing, but the example runs in less than 30 minutes; #SBATCH --output=myrun.o%j; #SBATCH --error=myrun.e%j. mkdir -p output; mkdir -p /scicore/home/cichon/GROUP/Ilumina/output/intermediate_results_dir. ulimit -u 10000; BIN_VERSION=""1.2.0""; # OUTPUT_DIR and INPUT_DIR should reside and exist inside your $HOME folder; export OUTPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output ; export INPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/Twist_ComprehensiveExome_targets_hg38.bed; --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:546,Testability,test,testing,546,"Hello. OS: Scicore Cluster, Linux; Deep Variant version:1.2.0; Installation: Singularity; Instrument: Ilumina; Data type: Whole exome sequencing analysis. I used the script given from this site:https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-exome-case-study.md. I edited the script to run in the cluster here:; ```; #!/bin/bash. #SBATCH --job-name=Deepvariant_debug; #SBATCH --cpus-per-task=2 # change this according to your needs; #SBATCH --mem=8G # change this according to your needs; #SBATCH --qos=30min # this was just for testing, but the example runs in less than 30 minutes; #SBATCH --output=myrun.o%j; #SBATCH --error=myrun.e%j. mkdir -p output; mkdir -p /scicore/home/cichon/GROUP/Ilumina/output/intermediate_results_dir. ulimit -u 10000; BIN_VERSION=""1.2.0""; # OUTPUT_DIR and INPUT_DIR should reside and exist inside your $HOME folder; export OUTPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output ; export INPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:1024,Testability,test,testdata,1024," the script given from this site:https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-exome-case-study.md. I edited the script to run in the cluster here:; ```; #!/bin/bash. #SBATCH --job-name=Deepvariant_debug; #SBATCH --cpus-per-task=2 # change this according to your needs; #SBATCH --mem=8G # change this according to your needs; #SBATCH --qos=30min # this was just for testing, but the example runs in less than 30 minutes; #SBATCH --output=myrun.o%j; #SBATCH --error=myrun.e%j. mkdir -p output; mkdir -p /scicore/home/cichon/GROUP/Ilumina/output/intermediate_results_dir. ulimit -u 10000; BIN_VERSION=""1.2.0""; # OUTPUT_DIR and INPUT_DIR should reside and exist inside your $HOME folder; export OUTPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output ; export INPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/Twist_ComprehensiveExome_targets_hg38.bed; --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:1830,Testability,test,testdata,1830,"1.2.0""; # OUTPUT_DIR and INPUT_DIR should reside and exist inside your $HOME folder; export OUTPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output ; export INPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/Twist_ComprehensiveExome_targets_hg38.bed; --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.vcf.gz \; --output_gvcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.gvcf.gz \; --call_variants_extra_args=""use_openvino=true"" \; --num_shards=$(nproc) \; --intermediate_results_dir=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/intermediate_results_dir \; --dry_run=true; ```. After reading the line, where the interval bed file is given as an input, it gives an error that output.vcf is not found. Then I get the below error as well:. `/var/lib/slurm/slurmd/job31271228/slurm_script: line 29: --output_vcf=/scicore/home/cichon/thirun0000/Illumina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:1946,Testability,test,testdata,1946,"umina_dv/Ilumina/output ; export INPUT_DIR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/Twist_ComprehensiveExome_targets_hg38.bed; --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.vcf.gz \; --output_gvcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.gvcf.gz \; --call_variants_extra_args=""use_openvino=true"" \; --num_shards=$(nproc) \; --intermediate_results_dir=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/intermediate_results_dir \; --dry_run=true; ```. After reading the line, where the interval bed file is given as an input, it gives an error that output.vcf is not found. Then I get the below error as well:. `/var/lib/slurm/slurmd/job31271228/slurm_script: line 29: --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.vcf.gz: No such file or directory`. I am confused, does the interval file step, require vcf file. Why t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:2050,Testability,test,testdata,2050,"IR=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata ; # the important part is to export the variables of paths used in the execution of the singularity command (OUTPUT_DIR and INPUT_DIR) and then add; # -B ${TMPDIR}:${TMPDIR} which mounts the $TMPDIR path defined by SLURM in the same place inside the container so you can use /scratch correctly and it exists inside the container; # This is where we run the container, and instead of ""docker run"" we use ""singularity run"" I just removed the docker part as we already have the container image (deepvariant_1.2.0.sif); singularity run -B /usr/lib/locale/:/usr/lib/locale/ -B ${TMPDIR}:${TMPDIR} \; /export/soft/singularity-containers/deepvariant/deepvariant_1.2.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/GRCh38_no_alt_analysis_set.fasta \; --reads=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/sample_1_recal.bam \; --regions=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/quickstart-testdata/Twist_ComprehensiveExome_targets_hg38.bed; --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.vcf.gz \; --output_gvcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.gvcf.gz \; --call_variants_extra_args=""use_openvino=true"" \; --num_shards=$(nproc) \; --intermediate_results_dir=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/intermediate_results_dir \; --dry_run=true; ```. After reading the line, where the interval bed file is given as an input, it gives an error that output.vcf is not found. Then I get the below error as well:. `/var/lib/slurm/slurmd/job31271228/slurm_script: line 29: --output_vcf=/scicore/home/cichon/thirun0000/Illumina_dv/Ilumina/output/sample_1.output.vcf.gz: No such file or directory`. I am confused, does the interval file step, require vcf file. Why the output files are not created?. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/516:325,Testability,log,logically,325,"I have a sample with a 4bp deletion at pos 775 and 1bp del at 779. Looking at the raw reads they seem to always be separate, and I confirmed there are no 5bp deletions called in this region in the alignment (via analyzing cigarStrings). DeepVariant is calling the 4bp del at 40% AD and the 1bp del at 77% AD. How could these logically add up to > 100%? Wouldn't that imply instances of 5bp deletion, but that would be reported separately, no? If someone could help me interoperate this that would be great. <img width=""113"" alt=""ComplimentaryIndelsP01-24"" src=""https://user-images.githubusercontent.com/65191963/153235606-e34c7406-d339-4b20-8ba7-fb29b42c713d.PNG"">",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/516
https://github.com/google/deepvariant/issues/517:125,Availability,error,error,125,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; The error arises during the ""postprocess_variants"" step. The quick-test and a run on chr22 from the same sample ran through without any issue. I tried to use `group_variants=false` as suggested [here](https://github.com/google/deepvariant/issues/341#issuecomment-686657676). But a similar error/crash occurs at a different variant/location. A similar problem was reported [here](https://github.com/google/deepvariant/issues/485), but the final fix is not provided. **Setup**; - Operating system: CentOS 7; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity image built from docker image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) WGS, Illumina x10. **Steps to reproduce:**; - Command: ; ```; # Modified script; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=hs37d5_PhiX.fa \; --reads=/input/${pid}/alignment/${prefix}_${pid}_merged.mdup.bam \; --intermediate_results_dir=/input/${pid}/deepvariant_calling/tmp/${prefix}/ \; --output_vcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz \; --output_gvcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.g.vcf.gz \; --num_shards=15; ```; I have also tried postprocessing with `group_variants`, which also produces a similar error.; ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/postprocess_variants \; --group_variants=false \; --ref=hs37d5_PhiX.fa \; --infile=/input/${pid}/deepvariant_calling/tmp/${prefix}/call_variants_output.tfrecord.gz \; --outfile=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz; ```; - Error t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:410,Availability,error,error,410,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; The error arises during the ""postprocess_variants"" step. The quick-test and a run on chr22 from the same sample ran through without any issue. I tried to use `group_variants=false` as suggested [here](https://github.com/google/deepvariant/issues/341#issuecomment-686657676). But a similar error/crash occurs at a different variant/location. A similar problem was reported [here](https://github.com/google/deepvariant/issues/485), but the final fix is not provided. **Setup**; - Operating system: CentOS 7; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity image built from docker image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) WGS, Illumina x10. **Steps to reproduce:**; - Command: ; ```; # Modified script; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=hs37d5_PhiX.fa \; --reads=/input/${pid}/alignment/${prefix}_${pid}_merged.mdup.bam \; --intermediate_results_dir=/input/${pid}/deepvariant_calling/tmp/${prefix}/ \; --output_vcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz \; --output_gvcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.g.vcf.gz \; --num_shards=15; ```; I have also tried postprocessing with `group_variants`, which also produces a similar error.; ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/postprocess_variants \; --group_variants=false \; --ref=hs37d5_PhiX.fa \; --infile=/input/${pid}/deepvariant_calling/tmp/${prefix}/call_variants_output.tfrecord.gz \; --outfile=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz; ```; - Error t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:1583,Availability,error,error,1583,"pvariant/issues/485), but the final fix is not provided. **Setup**; - Operating system: CentOS 7; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity image built from docker image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) WGS, Illumina x10. **Steps to reproduce:**; - Command: ; ```; # Modified script; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=hs37d5_PhiX.fa \; --reads=/input/${pid}/alignment/${prefix}_${pid}_merged.mdup.bam \; --intermediate_results_dir=/input/${pid}/deepvariant_calling/tmp/${prefix}/ \; --output_vcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz \; --output_gvcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.g.vcf.gz \; --num_shards=15; ```; I have also tried postprocessing with `group_variants`, which also produces a similar error.; ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/postprocess_variants \; --group_variants=false \; --ref=hs37d5_PhiX.fa \; --infile=/input/${pid}/deepvariant_calling/tmp/${prefix}/call_variants_output.tfrecord.gz \; --outfile=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz; ```; - Error trace: (if applicable); ```; I0217 17:00:21.108631 47945364948800 postprocess_variants.py:1115] Using sample name from call_variants output. Sample name: sample_; 2022-02-17 17:00:21.116319: I deepvariant/postprocess_variants.cc:88] Read from: ""...""/call_variants_output.tfrecord.gz; 2022-02-17 17:00:22.403255: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 228285; I0217 17:00:24.204934 47945364948800 postprocess_variants.py:1180] CVO sorting took 0.051486388842264814 minutes; I0217 17:00:24",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:1994,Availability,Error,Error,1994,"_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=hs37d5_PhiX.fa \; --reads=/input/${pid}/alignment/${prefix}_${pid}_merged.mdup.bam \; --intermediate_results_dir=/input/${pid}/deepvariant_calling/tmp/${prefix}/ \; --output_vcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz \; --output_gvcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.g.vcf.gz \; --num_shards=15; ```; I have also tried postprocessing with `group_variants`, which also produces a similar error.; ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/postprocess_variants \; --group_variants=false \; --ref=hs37d5_PhiX.fa \; --infile=/input/${pid}/deepvariant_calling/tmp/${prefix}/call_variants_output.tfrecord.gz \; --outfile=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz; ```; - Error trace: (if applicable); ```; I0217 17:00:21.108631 47945364948800 postprocess_variants.py:1115] Using sample name from call_variants output. Sample name: sample_; 2022-02-17 17:00:21.116319: I deepvariant/postprocess_variants.cc:88] Read from: ""...""/call_variants_output.tfrecord.gz; 2022-02-17 17:00:22.403255: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 228285; I0217 17:00:24.204934 47945364948800 postprocess_variants.py:1180] CVO sorting took 0.051486388842264814 minutes; I0217 17:00:24.205343 47945364948800 postprocess_variants.py:1183] Transforming call_variants_output to variants.; I0217 17:00:24.205814 47945364948800 postprocess_variants.py:1204] Writing variants to VCF.; I0217 17:00:24.205858 47945364948800 postprocess_variants.py:774] Writing output to VCF file: ""...""/_deepvariant.vcf.gz; I0217 17:00:24.230250 47945364948800 genomics_writer.py:175] Writing ""...""/_deepvariant.vcf.gz with NativeVcfWriter; I0217 17:00:24.234843 47945364948800 postprocess_vari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:659,Deployability,Install,Installation,659,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; The error arises during the ""postprocess_variants"" step. The quick-test and a run on chr22 from the same sample ran through without any issue. I tried to use `group_variants=false` as suggested [here](https://github.com/google/deepvariant/issues/341#issuecomment-686657676). But a similar error/crash occurs at a different variant/location. A similar problem was reported [here](https://github.com/google/deepvariant/issues/485), but the final fix is not provided. **Setup**; - Operating system: CentOS 7; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity image built from docker image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) WGS, Illumina x10. **Steps to reproduce:**; - Command: ; ```; # Modified script; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=hs37d5_PhiX.fa \; --reads=/input/${pid}/alignment/${prefix}_${pid}_merged.mdup.bam \; --intermediate_results_dir=/input/${pid}/deepvariant_calling/tmp/${prefix}/ \; --output_vcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz \; --output_gvcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.g.vcf.gz \; --num_shards=15; ```; I have also tried postprocessing with `group_variants`, which also produces a similar error.; ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/postprocess_variants \; --group_variants=false \; --ref=hs37d5_PhiX.fa \; --infile=/input/${pid}/deepvariant_calling/tmp/${prefix}/call_variants_output.tfrecord.gz \; --outfile=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz; ```; - Error t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:5380,Safety,predict,predictions,5380,"nt/deepvariant/postprocess_variants.py"", line 1249, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1205, in main; write_variants_to_vcf(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 778, in write_variants_to_vcf; for variant in variant_iterable:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 87, in maybe_resolve_conflicting_variants; for overlapping_candidates in _group_overlapping_variants(sorted_variants):; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 106, in _group_overlapping_variants; for variant in sorted_variants:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 853, in _transform_call_variants_output_to_variants; canonical_variant, predictions = merge_predictions(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 717, in merge_predictions; raise ValueError('`call_variants_outputs` did not pass sanity check.'); ValueError: `call_variants_outputs` did not pass sanity check.; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? ; No, the quick start and also chr22 from the same sample ran through. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:5606,Safety,sanity check,sanity check,5606,"nt/deepvariant/postprocess_variants.py"", line 1249, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1205, in main; write_variants_to_vcf(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 778, in write_variants_to_vcf; for variant in variant_iterable:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 87, in maybe_resolve_conflicting_variants; for overlapping_candidates in _group_overlapping_variants(sorted_variants):; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 106, in _group_overlapping_variants; for variant in sorted_variants:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 853, in _transform_call_variants_output_to_variants; canonical_variant, predictions = merge_predictions(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 717, in merge_predictions; raise ValueError('`call_variants_outputs` did not pass sanity check.'); ValueError: `call_variants_outputs` did not pass sanity check.; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? ; No, the quick start and also chr22 from the same sample ran through. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:5672,Safety,sanity check,sanity check,5672,"nt/deepvariant/postprocess_variants.py"", line 1249, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1205, in main; write_variants_to_vcf(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 778, in write_variants_to_vcf; for variant in variant_iterable:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 87, in maybe_resolve_conflicting_variants; for overlapping_candidates in _group_overlapping_variants(sorted_variants):; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 106, in _group_overlapping_variants; for variant in sorted_variants:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 853, in _transform_call_variants_output_to_variants; canonical_variant, predictions = merge_predictions(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 717, in merge_predictions; raise ValueError('`call_variants_outputs` did not pass sanity check.'); ValueError: `call_variants_outputs` did not pass sanity check.; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? ; No, the quick start and also chr22 from the same sample ran through. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:188,Testability,test,test,188,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; The error arises during the ""postprocess_variants"" step. The quick-test and a run on chr22 from the same sample ran through without any issue. I tried to use `group_variants=false` as suggested [here](https://github.com/google/deepvariant/issues/341#issuecomment-686657676). But a similar error/crash occurs at a different variant/location. A similar problem was reported [here](https://github.com/google/deepvariant/issues/485), but the final fix is not provided. **Setup**; - Operating system: CentOS 7; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity image built from docker image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) WGS, Illumina x10. **Steps to reproduce:**; - Command: ; ```; # Modified script; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=hs37d5_PhiX.fa \; --reads=/input/${pid}/alignment/${prefix}_${pid}_merged.mdup.bam \; --intermediate_results_dir=/input/${pid}/deepvariant_calling/tmp/${prefix}/ \; --output_vcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz \; --output_gvcf=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.g.vcf.gz \; --num_shards=15; ```; I have also tried postprocessing with `group_variants`, which also produces a similar error.; ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; -B ${INPUT_PATH}:/input \; compute_envs/deepvariant_latest.sif \; /opt/deepvariant/bin/postprocess_variants \; --group_variants=false \; --ref=hs37d5_PhiX.fa \; --infile=/input/${pid}/deepvariant_calling/tmp/${prefix}/call_variants_output.tfrecord.gz \; --outfile=/input/${pid}/deepvariant_calling/${prefix}_${pid}_deepvariant.vcf.gz; ```; - Error t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:5715,Testability,test,test,5715,"nt/deepvariant/postprocess_variants.py"", line 1249, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1205, in main; write_variants_to_vcf(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 778, in write_variants_to_vcf; for variant in variant_iterable:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 87, in maybe_resolve_conflicting_variants; for overlapping_candidates in _group_overlapping_variants(sorted_variants):; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 106, in _group_overlapping_variants; for variant in sorted_variants:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 853, in _transform_call_variants_output_to_variants; canonical_variant, predictions = merge_predictions(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 717, in merge_predictions; raise ValueError('`call_variants_outputs` did not pass sanity check.'); ValueError: `call_variants_outputs` did not pass sanity check.; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? ; No, the quick start and also chr22 from the same sample ran through. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:5751,Testability,test,test,5751,"nt/deepvariant/postprocess_variants.py"", line 1249, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1205, in main; write_variants_to_vcf(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 778, in write_variants_to_vcf; for variant in variant_iterable:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 87, in maybe_resolve_conflicting_variants; for overlapping_candidates in _group_overlapping_variants(sorted_variants):; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 106, in _group_overlapping_variants; for variant in sorted_variants:; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 853, in _transform_call_variants_output_to_variants; canonical_variant, predictions = merge_predictions(; File ""/tmp/Bazel.runfiles_ohe4bkg1/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 717, in merge_predictions; raise ValueError('`call_variants_outputs` did not pass sanity check.'); ValueError: `call_variants_outputs` did not pass sanity check.; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? ; No, the quick start and also chr22 from the same sample ran through. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/518:1402,Availability,echo,echo,1402,"nt.com/16579982/154755554-3642728e-03c3-4c87-ba89-d66f0ecd6982.png). Now, I'll go into the representation from the DeepVariant --> GVCF --> GLnexus pipeline:. ## DeepVariant Pipeline:; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; FAMILY_ID=Case1; PROBAND_ID=Case1_proband; MOTHER_ID=Case1_mother; FATHER_ID=Case1_father; SIBLING_ID=.; PED=$FAMILY_ID.ped. MOTHER_PRESENT=true; FATHER_PRESENT=true; SIBLING_PRESENT=false. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_ID}.sorted.bam; MOTHER_BAM=${MOTHER_ID}.sorted.bam; SIBLING_BAM=${SIBLING_ID}.sorted.bam. PROBAND_VCF=${PROBAND_ID}.vcf.gz; FATHER_VCF=${FATHER_ID}.vcf.gz; MOTHER_VCF=${MOTHER_ID}.vcf.gz; SIBLING_VCF=${SIBLING_ID}.vcf.gz. PROBAND_GVCF=${PROBAND_ID}.gvcf.gz; FATHER_GVCF=${FATHER_ID}.gvcf.gz; MOTHER_GVCF=${MOTHER_ID}.gvcf.gz; SIBLING_GVCF=${SIBLING_ID}.gvcf.gz. # Now use the booleans to choose whether or not you run each deepvariant over these samples; # We always run over proband. ## Proband ; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; 	-B ""${BAM_DIR}"":""/bamdir"" \; 	-B ""${FASTA_DIR}"":""/genomedir"" \; 	-B ""${OUTPUT_DIR}"":""/ou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:7657,Availability,echo,echo,7657,"49:..	0/1:37:19,18:54:54,0,64:..	1/1:18:0,18:52:61,55,0:..; ```. # DeepTrio . Now, with the DeepTrio -> GVCF -> GLNexus pipeline:; Pipeline; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; export SINGULARITY_CACHEDIR=$PWD; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis/. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; Case_ID=Case1; FAMILY_ID=$Case_ID; PROBAND_ID=${Case_ID}_proband; MOTHER_ID=${Case_ID}_mother; FATHER_ID=${Case_ID}_father. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_ID}.sorted.bam; MOTHER_BAM=${MOTHER_ID}.sorted.bam. PROBAND_VCF=${PROBAND_ID}.vcf.gz; FATHER_VCF=${FATHER_ID}.vcf.gz; MOTHER_VCF=${MOTHER_ID}.vcf.gz. PROBAND_GVCF=${PROBAND_ID}.gvcf.gz; FATHER_GVCF=${FATHER_ID}.gvcf.gz; MOTHER_GVCF=${MOTHER_ID}.gvcf.gz. # Run singularity; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; 	-B ""${BAM_DIR}"":""/bamdir"" \; 	-B ""${FASTA_DIR}"":""/genomedir"" \; 	-B ""${OUTPUT_DIR}"":""/output"" \; 	docker://google/deepvariant:deeptrio-""${BIN_VERSION}"" \; 	/opt/deepvariant/bin/deeptrio/run_deeptrio \; 	--model_type=$SEQ_TYPE \; 	--ref=""/genomedir/$FASTA_FILE"" \; 	--reads_child=""/bamdir/$PROBAND_BAM"" \; 	--reads_parent1=""/bamdir/$FATHER_BAM"" \; 	--reads_parent2=""/bamdir/$MOTHE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:11830,Availability,down,downstream,11830," ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}; ##bcftools_viewVersion=1.10.2+htslib-1.10.2; ##bcftools_viewCommand=view Case1.glnexus.merged.bcf; Date=Sun Jan 30 20:56:13 2022; ```. ### Variant line; ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Case1_father	Case1_mother	Case1_proband; X	48684399	X_48684399_C_A	C	A	45	.	AF=0.333333;AQ=45	GT:DP:AD:GQ:PL:RNC	0/0:22:22,0:50:0,75,749:..	0/1:37:19,18:45:45,0,54:..	0/1:18:0,18:4:33,0,1:..; ```. Here the male proband, fully hemizygous for the variant, is represented as 0/1: 0/1:18:0,18:4:33,0,1:.. # Why it matters; Now, this is a **BIG** problem, because downstream tools like Exomiser will treat the output here for variant prioritization in rare disease cases. So take a look at this. Exomiser HTML for DeepVariant, where variant is represented as 1/1. This gene is the top ranked hit for this simulated rare disease case. Good:. ![image](https://user-images.githubusercontent.com/16579982/154753891-458869c2-741b-4728-a74f-f2d58ca7f816.png). Exomiser HTML output for DeepTrio, where variant is represented as 0/1. Notice that now the gene is not even in the top 10 candidates, as Exomiser has interpreted this variant incorrectly (likely assuming it was a PAR region on X). The variant score dropped to 0.00 because the assumption on the GT string was violated:. ![image](https://user-images.githubusercontent.com/16579982/154754163-4833835e-905e-450e-b081-a447340d034c.png). I can send the HTML outputs, VCFs, or even CRAMs if you are interested by email or other file transfer. Anyways, going to try with 1.3 while I wait for an answer here. Cheers,; Phil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:599,Deployability,pipeline,pipeline,599,"Hello,. Noticed this issue with your tool DeepTrio regarding the representation of hemizygous variants in the non-pseudoautosomal (PAR) X-chromosome. This may be fixed now in 1.3? If so ignore this, but if not this is what I noticed. . Note, this is a simulated pathogenic variant from bamsurgeon, but the VCF representation is the focus of this problem. . Let's start with an IGV snapshot of the variant:; ![image](https://user-images.githubusercontent.com/16579982/154755554-3642728e-03c3-4c87-ba89-d66f0ecd6982.png). Now, I'll go into the representation from the DeepVariant --> GVCF --> GLnexus pipeline:. ## DeepVariant Pipeline:; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; FAMILY_ID=Case1; PROBAND_ID=Case1_proband; MOTHER_ID=Case1_mother; FATHER_ID=Case1_father; SIBLING_ID=.; PED=$FAMILY_ID.ped. MOTHER_PRESENT=true; FATHER_PRESENT=true; SIBLING_PRESENT=false. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_ID}.sorted.bam; MOTHER_BAM=${MOTHER_ID}.sorted.bam; SIBLING_BAM=${SIBLING_ID}.sorted.bam. PROBAND_VCF=${PROBAND_ID}.vcf.gz; FATHER_VCF=${FATHER_ID}.vcf.gz; MOTHER_VCF=${MOTHER_ID}.vcf.gz; SIBL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:625,Deployability,Pipeline,Pipeline,625,"Hello,. Noticed this issue with your tool DeepTrio regarding the representation of hemizygous variants in the non-pseudoautosomal (PAR) X-chromosome. This may be fixed now in 1.3? If so ignore this, but if not this is what I noticed. . Note, this is a simulated pathogenic variant from bamsurgeon, but the VCF representation is the focus of this problem. . Let's start with an IGV snapshot of the variant:; ![image](https://user-images.githubusercontent.com/16579982/154755554-3642728e-03c3-4c87-ba89-d66f0ecd6982.png). Now, I'll go into the representation from the DeepVariant --> GVCF --> GLnexus pipeline:. ## DeepVariant Pipeline:; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; FAMILY_ID=Case1; PROBAND_ID=Case1_proband; MOTHER_ID=Case1_mother; FATHER_ID=Case1_father; SIBLING_ID=.; PED=$FAMILY_ID.ped. MOTHER_PRESENT=true; FATHER_PRESENT=true; SIBLING_PRESENT=false. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_ID}.sorted.bam; MOTHER_BAM=${MOTHER_ID}.sorted.bam; SIBLING_BAM=${SIBLING_ID}.sorted.bam. PROBAND_VCF=${PROBAND_ID}.vcf.gz; FATHER_VCF=${FATHER_ID}.vcf.gz; MOTHER_VCF=${MOTHER_ID}.vcf.gz; SIBL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:6826,Deployability,pipeline,pipeline,6826,"_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}; ##bcftools_viewVersion=1.10.2+htslib-1.10.2; ##bcftools_viewCommand=view Case1.glnexus.merged.bcf; Date=Tue Feb 15 12:15:20 2022; ```. ### Variant line; ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	father	mother	proband; X	48684399	X_48684399_C_A	C	A	61	.	AF=0.5;AQ=61	GT:DP:AD:GQ:PL:RNC	0/0:22:22,0:50:0,75,749:..	0/1:37:19,18:54:54,0,64:..	1/1:18:0,18:52:61,55,0:..; ```. # DeepTrio . Now, with the DeepTrio -> GVCF -> GLNexus pipeline:; Pipeline; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; export SINGULARITY_CACHEDIR=$PWD; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis/. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; Case_ID=Case1; FAMILY_ID=$Case_I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:6837,Deployability,Pipeline,Pipeline,6837,"_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}; ##bcftools_viewVersion=1.10.2+htslib-1.10.2; ##bcftools_viewCommand=view Case1.glnexus.merged.bcf; Date=Tue Feb 15 12:15:20 2022; ```. ### Variant line; ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	father	mother	proband; X	48684399	X_48684399_C_A	C	A	61	.	AF=0.5;AQ=61	GT:DP:AD:GQ:PL:RNC	0/0:22:22,0:50:0,75,749:..	0/1:37:19,18:54:54,0,64:..	1/1:18:0,18:52:61,55,0:..; ```. # DeepTrio . Now, with the DeepTrio -> GVCF -> GLNexus pipeline:; Pipeline; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; export SINGULARITY_CACHEDIR=$PWD; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis/. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; Case_ID=Case1; FAMILY_ID=$Case_I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:643,Performance,Load,Load,643,"Hello,. Noticed this issue with your tool DeepTrio regarding the representation of hemizygous variants in the non-pseudoautosomal (PAR) X-chromosome. This may be fixed now in 1.3? If so ignore this, but if not this is what I noticed. . Note, this is a simulated pathogenic variant from bamsurgeon, but the VCF representation is the focus of this problem. . Let's start with an IGV snapshot of the variant:; ![image](https://user-images.githubusercontent.com/16579982/154755554-3642728e-03c3-4c87-ba89-d66f0ecd6982.png). Now, I'll go into the representation from the DeepVariant --> GVCF --> GLnexus pipeline:. ## DeepVariant Pipeline:; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; FAMILY_ID=Case1; PROBAND_ID=Case1_proband; MOTHER_ID=Case1_mother; FATHER_ID=Case1_father; SIBLING_ID=.; PED=$FAMILY_ID.ped. MOTHER_PRESENT=true; FATHER_PRESENT=true; SIBLING_PRESENT=false. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_ID}.sorted.bam; MOTHER_BAM=${MOTHER_ID}.sorted.bam; SIBLING_BAM=${SIBLING_ID}.sorted.bam. PROBAND_VCF=${PROBAND_ID}.vcf.gz; FATHER_VCF=${FATHER_ID}.vcf.gz; MOTHER_VCF=${MOTHER_ID}.vcf.gz; SIBL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:668,Performance,load,load,668,"Hello,. Noticed this issue with your tool DeepTrio regarding the representation of hemizygous variants in the non-pseudoautosomal (PAR) X-chromosome. This may be fixed now in 1.3? If so ignore this, but if not this is what I noticed. . Note, this is a simulated pathogenic variant from bamsurgeon, but the VCF representation is the focus of this problem. . Let's start with an IGV snapshot of the variant:; ![image](https://user-images.githubusercontent.com/16579982/154755554-3642728e-03c3-4c87-ba89-d66f0ecd6982.png). Now, I'll go into the representation from the DeepVariant --> GVCF --> GLnexus pipeline:. ## DeepVariant Pipeline:; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; FAMILY_ID=Case1; PROBAND_ID=Case1_proband; MOTHER_ID=Case1_mother; FATHER_ID=Case1_father; SIBLING_ID=.; PED=$FAMILY_ID.ped. MOTHER_PRESENT=true; FATHER_PRESENT=true; SIBLING_PRESENT=false. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_ID}.sorted.bam; MOTHER_BAM=${MOTHER_ID}.sorted.bam; SIBLING_BAM=${SIBLING_ID}.sorted.bam. PROBAND_VCF=${PROBAND_ID}.vcf.gz; FATHER_VCF=${FATHER_ID}.vcf.gz; MOTHER_VCF=${MOTHER_ID}.vcf.gz; SIBL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:709,Performance,Load,Load,709,"Hello,. Noticed this issue with your tool DeepTrio regarding the representation of hemizygous variants in the non-pseudoautosomal (PAR) X-chromosome. This may be fixed now in 1.3? If so ignore this, but if not this is what I noticed. . Note, this is a simulated pathogenic variant from bamsurgeon, but the VCF representation is the focus of this problem. . Let's start with an IGV snapshot of the variant:; ![image](https://user-images.githubusercontent.com/16579982/154755554-3642728e-03c3-4c87-ba89-d66f0ecd6982.png). Now, I'll go into the representation from the DeepVariant --> GVCF --> GLnexus pipeline:. ## DeepVariant Pipeline:; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; FAMILY_ID=Case1; PROBAND_ID=Case1_proband; MOTHER_ID=Case1_mother; FATHER_ID=Case1_father; SIBLING_ID=.; PED=$FAMILY_ID.ped. MOTHER_PRESENT=true; FATHER_PRESENT=true; SIBLING_PRESENT=false. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_ID}.sorted.bam; MOTHER_BAM=${MOTHER_ID}.sorted.bam; SIBLING_BAM=${SIBLING_ID}.sorted.bam. PROBAND_VCF=${PROBAND_ID}.vcf.gz; FATHER_VCF=${FATHER_ID}.vcf.gz; MOTHER_VCF=${MOTHER_ID}.vcf.gz; SIBL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:6854,Performance,Load,Load,6854,"_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}; ##bcftools_viewVersion=1.10.2+htslib-1.10.2; ##bcftools_viewCommand=view Case1.glnexus.merged.bcf; Date=Tue Feb 15 12:15:20 2022; ```. ### Variant line; ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	father	mother	proband; X	48684399	X_48684399_C_A	C	A	61	.	AF=0.5;AQ=61	GT:DP:AD:GQ:PL:RNC	0/0:22:22,0:50:0,75,749:..	0/1:37:19,18:54:54,0,64:..	1/1:18:0,18:52:61,55,0:..; ```. # DeepTrio . Now, with the DeepTrio -> GVCF -> GLNexus pipeline:; Pipeline; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; export SINGULARITY_CACHEDIR=$PWD; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis/. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; Case_ID=Case1; FAMILY_ID=$Case_I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:6879,Performance,load,load,6879,"_type: zero, count: 0, combi_method: min, ignore_non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}; ##bcftools_viewVersion=1.10.2+htslib-1.10.2; ##bcftools_viewCommand=view Case1.glnexus.merged.bcf; Date=Tue Feb 15 12:15:20 2022; ```. ### Variant line; ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	father	mother	proband; X	48684399	X_48684399_C_A	C	A	61	.	AF=0.5;AQ=61	GT:DP:AD:GQ:PL:RNC	0/0:22:22,0:50:0,75,749:..	0/1:37:19,18:54:54,0,64:..	1/1:18:0,18:52:61,55,0:..; ```. # DeepTrio . Now, with the DeepTrio -> GVCF -> GLNexus pipeline:; Pipeline; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; export SINGULARITY_CACHEDIR=$PWD; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis/. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; Case_ID=Case1; FAMILY_ID=$Case_I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:6920,Performance,Load,Load,6920,"r,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}; ##bcftools_viewVersion=1.10.2+htslib-1.10.2; ##bcftools_viewCommand=view Case1.glnexus.merged.bcf; Date=Tue Feb 15 12:15:20 2022; ```. ### Variant line; ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	father	mother	proband; X	48684399	X_48684399_C_A	C	A	61	.	AF=0.5;AQ=61	GT:DP:AD:GQ:PL:RNC	0/0:22:22,0:50:0,75,749:..	0/1:37:19,18:54:54,0,64:..	1/1:18:0,18:52:61,55,0:..; ```. # DeepTrio . Now, with the DeepTrio -> GVCF -> GLNexus pipeline:; Pipeline; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; export SINGULARITY_CACHEDIR=$PWD; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis/. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; Case_ID=Case1; FAMILY_ID=$Case_ID; PROBAND_ID=${Case_ID}_proband; MOTHER_ID=${Case_ID}_mother; FATHER_ID=${Case_ID}_father. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1302,Testability,test,test,1302,"ticed. . Note, this is a simulated pathogenic variant from bamsurgeon, but the VCF representation is the focus of this problem. . Let's start with an IGV snapshot of the variant:; ![image](https://user-images.githubusercontent.com/16579982/154755554-3642728e-03c3-4c87-ba89-d66f0ecd6982.png). Now, I'll go into the representation from the DeepVariant --> GVCF --> GLnexus pipeline:. ## DeepVariant Pipeline:; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; singularity pull docker://google/deepvariant:""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; FAMILY_ID=Case1; PROBAND_ID=Case1_proband; MOTHER_ID=Case1_mother; FATHER_ID=Case1_father; SIBLING_ID=.; PED=$FAMILY_ID.ped. MOTHER_PRESENT=true; FATHER_PRESENT=true; SIBLING_PRESENT=false. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_ID}.sorted.bam; MOTHER_BAM=${MOTHER_ID}.sorted.bam; SIBLING_BAM=${SIBLING_ID}.sorted.bam. PROBAND_VCF=${PROBAND_ID}.vcf.gz; FATHER_VCF=${FATHER_ID}.vcf.gz; MOTHER_VCF=${MOTHER_ID}.vcf.gz; SIBLING_VCF=${SIBLING_ID}.vcf.gz. PROBAND_GVCF=${PROBAND_ID}.gvcf.gz; FATHER_GVCF=${FATHER_ID}.gvcf.gz; MOTHER_GVCF=${MOTHER_ID}.gvcf.gz; SIBLING_GVCF=${SIBLING_ID}.gvcf.gz. # Now use the booleans to choose whether or not you run ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:7556,Testability,test,test,7556,"ged.bcf; Date=Tue Feb 15 12:15:20 2022; ```. ### Variant line; ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	father	mother	proband; X	48684399	X_48684399_C_A	C	A	61	.	AF=0.5;AQ=61	GT:DP:AD:GQ:PL:RNC	0/0:22:22,0:50:0,75,749:..	0/1:37:19,18:54:54,0,64:..	1/1:18:0,18:52:61,55,0:..; ```. # DeepTrio . Now, with the DeepTrio -> GVCF -> GLNexus pipeline:; Pipeline; ```; # Load singularity; module load singularity; BIN_VERSION=""1.1.0"". # Load env for bcftools; ANNOTATEVARIANTS_INSTALL=/mnt/common/WASSERMAN_SOFTWARE/AnnotateVariants/; source $ANNOTATEVARIANTS_INSTALL/opt/miniconda3/etc/profile.d/conda.sh; conda activate $ANNOTATEVARIANTS_INSTALL/opt/AnnotateVariantsEnvironment. # Pull latest version, if you already have it, this will be skipped; export SINGULARITY_CACHEDIR=$PWD; singularity pull docker://google/deepvariant:deeptrio-""${BIN_VERSION}"". # Number of threads; NSLOTS=$SLURM_CPUS_PER_TASK. # Go to the submission directory (where the sbatch was entered); cd $SLURM_SUBMIT_DIR; WORKING_DIR=/mnt/scratch/Public/TRAINING/GenomeAnalysisModule/StudentSpaces/Old/test/CaseAnalysis/. ## Set working space; mkdir -p $WORKING_DIR; cd $WORKING_DIR. #### GRCh38 #### ; echo ""GRCh38 genome""; GENOME=GRCh38; FASTA_DIR=/mnt/common/DATABASES/REFERENCES/GRCh38/GENOME/; FASTA_FILE=GRCh38-lite.fa. SEQ_TYPE=WGS; BAM_DIR=$WORKING_DIR; Case_ID=Case1; FAMILY_ID=$Case_ID; PROBAND_ID=${Case_ID}_proband; MOTHER_ID=${Case_ID}_mother; FATHER_ID=${Case_ID}_father. PROBAND_BAM=${PROBAND_ID}.sorted.bam; FATHER_BAM=${FATHER_ID}.sorted.bam; MOTHER_BAM=${MOTHER_ID}.sorted.bam. PROBAND_VCF=${PROBAND_ID}.vcf.gz; FATHER_VCF=${FATHER_ID}.vcf.gz; MOTHER_VCF=${MOTHER_ID}.vcf.gz. PROBAND_GVCF=${PROBAND_ID}.gvcf.gz; FATHER_GVCF=${FATHER_ID}.gvcf.gz; MOTHER_GVCF=${MOTHER_ID}.gvcf.gz. # Run singularity; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; 	-B ""${BAM_DIR}"":""/bamdir"" \; 	-B ""${FASTA_DIR}"":""/genomedir"" \; 	-B ""${OUTPUT_DIR}"":""/output"" \; 	docker://google/deepvariant:deeptrio-""${BIN_VERSION}"" \;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/520:1428,Availability,Error,Error,1428,"**Describe the issue:**. DV calls two adjacent SNPs rather than one larger variant - eventho these variants are on the same reads. The DV call looks as follows:. `chr17 63951760 . G T 53 PASS . GT:GQ:DP:AD:VAF:PL 0/1:53:139:64,75:0.539568:53,0,62. chr17 63951761 . A T 45.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:45:139:62,75:0.539568:45,0,55; `; Expected for this locus (same BAM file, with Freebayes):. `chr17 63951760 . GA TT 1766.67 . AB=0.515152;ABP=3.27351;AC=1;AF=0.5;AN=2;AO=68;CIGAR=2X;DP=132;DPB=132;DPRA=0;EPP=3.0103;EPPR=3.15039;GTI=0;LEN=2;MEANALT=3;MQM=60;MQMR=60;NS=1;NUMALT=1;ODDS=361.082;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2481;QR=2251;RO=62;RPL=25;RPP=13.3567;RPPR=3.57068;RPR=43;RUN=1;SAF=29;SAP=6.20364;SAR=39;SRF=25;SRP=8.05372;SRR=37;TYPE=mnp;technology.ILLUMINA=1 GT:DP:AD:RO:QR:AO:QA:GL 0/1:132:62,68:62:2251:68:2481:-184.277,0,-163.588; `. BAM file (+/-150 bases): https://www.dropbox.com/s/hcxmotqgxzhtm9k/test.bam?dl=0; BAI file: https://www.dropbox.com/s/fnkzzi8mh1qhwsl/test.bam.bai?dl=0. Reference genome: hg38 (no ALT). **Setup**; - Operating system:; - DeepVariant version: 1.3.0, latest ; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) 2*150bp Illumina, NovaSeq600, Exome. . **Steps to reproduce:**; - Command: Call variants with run_deepvariant wrapper script. ; - Error trace: (if applicable). ![igv_snapshot](https://user-images.githubusercontent.com/22975/154966285-a761d2b4-4eba-46e2-a1f4-4f3af93ddbc8.png)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1126,Deployability,Install,Installation,1126,"**Describe the issue:**. DV calls two adjacent SNPs rather than one larger variant - eventho these variants are on the same reads. The DV call looks as follows:. `chr17 63951760 . G T 53 PASS . GT:GQ:DP:AD:VAF:PL 0/1:53:139:64,75:0.539568:53,0,62. chr17 63951761 . A T 45.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:45:139:62,75:0.539568:45,0,55; `; Expected for this locus (same BAM file, with Freebayes):. `chr17 63951760 . GA TT 1766.67 . AB=0.515152;ABP=3.27351;AC=1;AF=0.5;AN=2;AO=68;CIGAR=2X;DP=132;DPB=132;DPRA=0;EPP=3.0103;EPPR=3.15039;GTI=0;LEN=2;MEANALT=3;MQM=60;MQMR=60;NS=1;NUMALT=1;ODDS=361.082;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2481;QR=2251;RO=62;RPL=25;RPP=13.3567;RPPR=3.57068;RPR=43;RUN=1;SAF=29;SAP=6.20364;SAR=39;SRF=25;SRP=8.05372;SRR=37;TYPE=mnp;technology.ILLUMINA=1 GT:DP:AD:RO:QR:AO:QA:GL 0/1:132:62,68:62:2251:68:2481:-184.277,0,-163.588; `. BAM file (+/-150 bases): https://www.dropbox.com/s/hcxmotqgxzhtm9k/test.bam?dl=0; BAI file: https://www.dropbox.com/s/fnkzzi8mh1qhwsl/test.bam.bai?dl=0. Reference genome: hg38 (no ALT). **Setup**; - Operating system:; - DeepVariant version: 1.3.0, latest ; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) 2*150bp Illumina, NovaSeq600, Exome. . **Steps to reproduce:**; - Command: Call variants with run_deepvariant wrapper script. ; - Error trace: (if applicable). ![igv_snapshot](https://user-images.githubusercontent.com/22975/154966285-a761d2b4-4eba-46e2-a1f4-4f3af93ddbc8.png)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1408,Integrability,wrap,wrapper,1408,"**Describe the issue:**. DV calls two adjacent SNPs rather than one larger variant - eventho these variants are on the same reads. The DV call looks as follows:. `chr17 63951760 . G T 53 PASS . GT:GQ:DP:AD:VAF:PL 0/1:53:139:64,75:0.539568:53,0,62. chr17 63951761 . A T 45.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:45:139:62,75:0.539568:45,0,55; `; Expected for this locus (same BAM file, with Freebayes):. `chr17 63951760 . GA TT 1766.67 . AB=0.515152;ABP=3.27351;AC=1;AF=0.5;AN=2;AO=68;CIGAR=2X;DP=132;DPB=132;DPRA=0;EPP=3.0103;EPPR=3.15039;GTI=0;LEN=2;MEANALT=3;MQM=60;MQMR=60;NS=1;NUMALT=1;ODDS=361.082;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2481;QR=2251;RO=62;RPL=25;RPP=13.3567;RPPR=3.57068;RPR=43;RUN=1;SAF=29;SAP=6.20364;SAR=39;SRF=25;SRP=8.05372;SRR=37;TYPE=mnp;technology.ILLUMINA=1 GT:DP:AD:RO:QR:AO:QA:GL 0/1:132:62,68:62:2251:68:2481:-184.277,0,-163.588; `. BAM file (+/-150 bases): https://www.dropbox.com/s/hcxmotqgxzhtm9k/test.bam?dl=0; BAI file: https://www.dropbox.com/s/fnkzzi8mh1qhwsl/test.bam.bai?dl=0. Reference genome: hg38 (no ALT). **Setup**; - Operating system:; - DeepVariant version: 1.3.0, latest ; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) 2*150bp Illumina, NovaSeq600, Exome. . **Steps to reproduce:**; - Command: Call variants with run_deepvariant wrapper script. ; - Error trace: (if applicable). ![igv_snapshot](https://user-images.githubusercontent.com/22975/154966285-a761d2b4-4eba-46e2-a1f4-4f3af93ddbc8.png)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:934,Testability,test,test,934,"**Describe the issue:**. DV calls two adjacent SNPs rather than one larger variant - eventho these variants are on the same reads. The DV call looks as follows:. `chr17 63951760 . G T 53 PASS . GT:GQ:DP:AD:VAF:PL 0/1:53:139:64,75:0.539568:53,0,62. chr17 63951761 . A T 45.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:45:139:62,75:0.539568:45,0,55; `; Expected for this locus (same BAM file, with Freebayes):. `chr17 63951760 . GA TT 1766.67 . AB=0.515152;ABP=3.27351;AC=1;AF=0.5;AN=2;AO=68;CIGAR=2X;DP=132;DPB=132;DPRA=0;EPP=3.0103;EPPR=3.15039;GTI=0;LEN=2;MEANALT=3;MQM=60;MQMR=60;NS=1;NUMALT=1;ODDS=361.082;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2481;QR=2251;RO=62;RPL=25;RPP=13.3567;RPPR=3.57068;RPR=43;RUN=1;SAF=29;SAP=6.20364;SAR=39;SRF=25;SRP=8.05372;SRR=37;TYPE=mnp;technology.ILLUMINA=1 GT:DP:AD:RO:QR:AO:QA:GL 0/1:132:62,68:62:2251:68:2481:-184.277,0,-163.588; `. BAM file (+/-150 bases): https://www.dropbox.com/s/hcxmotqgxzhtm9k/test.bam?dl=0; BAI file: https://www.dropbox.com/s/fnkzzi8mh1qhwsl/test.bam.bai?dl=0. Reference genome: hg38 (no ALT). **Setup**; - Operating system:; - DeepVariant version: 1.3.0, latest ; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) 2*150bp Illumina, NovaSeq600, Exome. . **Steps to reproduce:**; - Command: Call variants with run_deepvariant wrapper script. ; - Error trace: (if applicable). ![igv_snapshot](https://user-images.githubusercontent.com/22975/154966285-a761d2b4-4eba-46e2-a1f4-4f3af93ddbc8.png)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1001,Testability,test,test,1001,"**Describe the issue:**. DV calls two adjacent SNPs rather than one larger variant - eventho these variants are on the same reads. The DV call looks as follows:. `chr17 63951760 . G T 53 PASS . GT:GQ:DP:AD:VAF:PL 0/1:53:139:64,75:0.539568:53,0,62. chr17 63951761 . A T 45.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:45:139:62,75:0.539568:45,0,55; `; Expected for this locus (same BAM file, with Freebayes):. `chr17 63951760 . GA TT 1766.67 . AB=0.515152;ABP=3.27351;AC=1;AF=0.5;AN=2;AO=68;CIGAR=2X;DP=132;DPB=132;DPRA=0;EPP=3.0103;EPPR=3.15039;GTI=0;LEN=2;MEANALT=3;MQM=60;MQMR=60;NS=1;NUMALT=1;ODDS=361.082;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2481;QR=2251;RO=62;RPL=25;RPP=13.3567;RPPR=3.57068;RPR=43;RUN=1;SAF=29;SAP=6.20364;SAR=39;SRF=25;SRP=8.05372;SRR=37;TYPE=mnp;technology.ILLUMINA=1 GT:DP:AD:RO:QR:AO:QA:GL 0/1:132:62,68:62:2251:68:2481:-184.277,0,-163.588; `. BAM file (+/-150 bases): https://www.dropbox.com/s/hcxmotqgxzhtm9k/test.bam?dl=0; BAI file: https://www.dropbox.com/s/fnkzzi8mh1qhwsl/test.bam.bai?dl=0. Reference genome: hg38 (no ALT). **Setup**; - Operating system:; - DeepVariant version: 1.3.0, latest ; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) 2*150bp Illumina, NovaSeq600, Exome. . **Steps to reproduce:**; - Command: Call variants with run_deepvariant wrapper script. ; - Error trace: (if applicable). ![igv_snapshot](https://user-images.githubusercontent.com/22975/154966285-a761d2b4-4eba-46e2-a1f4-4f3af93ddbc8.png)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/521:474,Availability,down,down,474,"Hi,. I am using [Pepper-MARGIN-DeepVariant r0.7](https://github.com/kishwarshafin/pepper) with custom made models for Pepper-SNP, Pepper-HP and DeepVariant. As far as I know, this release uses DeepVariant 1.2. I have run this pipeline successfully for a small cohort of about 100 genomes but when merging the GVCF files, [GLnexus 1.4.1](https://github.com/dnanexus-rnd/GLnexus) (with config `DeepVariant`) complains that at least one variant is missing PL values. I tracked down the issue to one GVCF were the record is:; ```; CHR	POS	.	A	G,<*>	9.9	NoCall	.	GT:GQ:DP:AD:VAF:PL	./.:0:5:0,0,0:0,0:0,0,990,990,990; ```; We can see that this GVCF record has 5 PL values where there should be 6. The corresponding record in the VCF file is:; ```; CHR POS .	A	G	9.9	refCall	.	GT:GQ:DP:AD:VAF:C	./.:0:5:0:0:DV; ```; The VCF record indicates that the variant call was issued by DeepVariant. . Any ideas what could be the issue here?. Thank you for your help,; Guillaume",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:180,Deployability,release,release,180,"Hi,. I am using [Pepper-MARGIN-DeepVariant r0.7](https://github.com/kishwarshafin/pepper) with custom made models for Pepper-SNP, Pepper-HP and DeepVariant. As far as I know, this release uses DeepVariant 1.2. I have run this pipeline successfully for a small cohort of about 100 genomes but when merging the GVCF files, [GLnexus 1.4.1](https://github.com/dnanexus-rnd/GLnexus) (with config `DeepVariant`) complains that at least one variant is missing PL values. I tracked down the issue to one GVCF were the record is:; ```; CHR	POS	.	A	G,<*>	9.9	NoCall	.	GT:GQ:DP:AD:VAF:PL	./.:0:5:0,0,0:0,0:0,0,990,990,990; ```; We can see that this GVCF record has 5 PL values where there should be 6. The corresponding record in the VCF file is:; ```; CHR POS .	A	G	9.9	refCall	.	GT:GQ:DP:AD:VAF:C	./.:0:5:0:0:DV; ```; The VCF record indicates that the variant call was issued by DeepVariant. . Any ideas what could be the issue here?. Thank you for your help,; Guillaume",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:226,Deployability,pipeline,pipeline,226,"Hi,. I am using [Pepper-MARGIN-DeepVariant r0.7](https://github.com/kishwarshafin/pepper) with custom made models for Pepper-SNP, Pepper-HP and DeepVariant. As far as I know, this release uses DeepVariant 1.2. I have run this pipeline successfully for a small cohort of about 100 genomes but when merging the GVCF files, [GLnexus 1.4.1](https://github.com/dnanexus-rnd/GLnexus) (with config `DeepVariant`) complains that at least one variant is missing PL values. I tracked down the issue to one GVCF were the record is:; ```; CHR	POS	.	A	G,<*>	9.9	NoCall	.	GT:GQ:DP:AD:VAF:PL	./.:0:5:0,0,0:0,0:0,0,990,990,990; ```; We can see that this GVCF record has 5 PL values where there should be 6. The corresponding record in the VCF file is:; ```; CHR POS .	A	G	9.9	refCall	.	GT:GQ:DP:AD:VAF:C	./.:0:5:0:0:DV; ```; The VCF record indicates that the variant call was issued by DeepVariant. . Any ideas what could be the issue here?. Thank you for your help,; Guillaume",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:384,Modifiability,config,config,384,"Hi,. I am using [Pepper-MARGIN-DeepVariant r0.7](https://github.com/kishwarshafin/pepper) with custom made models for Pepper-SNP, Pepper-HP and DeepVariant. As far as I know, this release uses DeepVariant 1.2. I have run this pipeline successfully for a small cohort of about 100 genomes but when merging the GVCF files, [GLnexus 1.4.1](https://github.com/dnanexus-rnd/GLnexus) (with config `DeepVariant`) complains that at least one variant is missing PL values. I tracked down the issue to one GVCF were the record is:; ```; CHR	POS	.	A	G,<*>	9.9	NoCall	.	GT:GQ:DP:AD:VAF:PL	./.:0:5:0,0,0:0,0:0,0,990,990,990; ```; We can see that this GVCF record has 5 PL values where there should be 6. The corresponding record in the VCF file is:; ```; CHR POS .	A	G	9.9	refCall	.	GT:GQ:DP:AD:VAF:C	./.:0:5:0:0:DV; ```; The VCF record indicates that the variant call was issued by DeepVariant. . Any ideas what could be the issue here?. Thank you for your help,; Guillaume",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/522:218,Availability,error,error,218,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.); Running singularity on HPC returns this error, our HPC does not have docker so I assumed singularity would work: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:1868,Availability,Error,Error,1868,"k: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/deepvariant:1.3.0: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp 52.0.218.102:443: connect: network is unreachable``. This may be an error on my behalf, but I have tried all other options and asked lots of different people. Thanks,; Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:1926,Availability,error,error,1926,"k: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/deepvariant:1.3.0: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp 52.0.218.102:443: connect: network is unreachable``. This may be an error on my behalf, but I have tried all other options and asked lots of different people. Thanks,; Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:2019,Availability,ping,pinging,2019,"k: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/deepvariant:1.3.0: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp 52.0.218.102:443: connect: network is unreachable``. This may be an error on my behalf, but I have tried all other options and asked lots of different people. Thanks,; Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:2185,Availability,error,error,2185,"k: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/deepvariant:1.3.0: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp 52.0.218.102:443: connect: network is unreachable``. This may be an error on my behalf, but I have tried all other options and asked lots of different people. Thanks,; Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:367,Deployability,Install,Installation,367,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.); Running singularity on HPC returns this error, our HPC does not have docker so I assumed singularity would work: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:958,Performance,load,load,958,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.); Running singularity on HPC returns this error, our HPC does not have docker so I assumed singularity would work: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:983,Performance,load,load,983,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.); Running singularity on HPC returns this error, our HPC does not have docker so I assumed singularity would work: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:1950,Performance,cache,cache,1950,"k: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/deepvariant:1.3.0: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp 52.0.218.102:443: connect: network is unreachable``. This may be an error on my behalf, but I have tried all other options and asked lots of different people. Thanks,; Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:1971,Security,checksum,checksum,1971,"k: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/deepvariant:1.3.0: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp 52.0.218.102:443: connect: network is unreachable``. This may be an error on my behalf, but I have tried all other options and asked lots of different people. Thanks,; Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:500,Testability,log,login,500,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.); Running singularity on HPC returns this error, our HPC does not have docker so I assumed singularity would work: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:124,Usability,clear,clear,124,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.); Running singularity on HPC returns this error, our HPC does not have docker so I assumed singularity would work: . **Setup**; - Operating system: Linux HPC; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WES. **Steps to reproduce:**; ```; #!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p c_compute_wgp; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-33; #SBATCH --time=02:00:00; #SBATCH --time=072:00:00; #SBATCH --mem-per-cpu=32GB. module purge; module load singularity; module load parallel. set -eu. cd /scratch/c.c21087028/; BIN_VERSION=""1.3.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; -ref=Polyposis_Exome_Analysis/bwa/index/HumanRefSeq/GRCh38_latest_genomic.fna \; --reads=Polyposis_Exome_Analysis/samtools/index/indexed_picardbamfiles/{}PE_markedduplicates.bam \; --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \; --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \; --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate""; ```. **Error::**. ``FATAL: While making image from oci registry: error fetching image to cache: failed to get checksum for docker://google/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/524:837,Deployability,pipeline,pipelines,837,"Hello,. I'm using DeepVariant docker container v1.3 to call variants using the `run_deepvariant` command. What I've done in the past to manage temp files was to create a `temp_dir` in the working directory and then use `--intermediate_results_dir temp_dir` to make DeepVariant write temp files in this custom location. However, the same approach is not working anymore for me in the new HPC system since on computing node the default temp folder stored in `$TMPDIR` is set to a special space `\localscratch` that is not among the path automatically mounted by Docker or Singularity (like \tmp) apparently. I realized that, in addition to intermediate files written to `--intermediate_results_dir`, DeepVariant writes some additional temp files to the default temp dir location (`$TMPDIR`) and this created some issues when running it in pipelines (like Nextflow). . I've created a work around by manually setting `$TMPDIR` in the sh script so that it points to another folder in the work directory, and I can see there are a bunch of small files created in there (~30Mb total) like the following; ```; Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx; ```. I wonder which kind of files are written to `$TMPDIR` and if it's possible to redirect them by command line option without having to set `$TMPDIR`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/525:437,Availability,Error,Error,437,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/525
https://github.com/google/deepvariant/issues/525:232,Deployability,Install,Installation,232,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/525
https://github.com/google/deepvariant/issues/525:490,Testability,test,test,490,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/525
https://github.com/google/deepvariant/issues/525:526,Testability,test,test,526,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/525
https://github.com/google/deepvariant/issues/525:120,Usability,clear,clear,120,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/525
https://github.com/google/deepvariant/issues/526:41,Usability,guid,guidelines,41,"Hello,. I have tried following along the guidelines presented under [Best practices for multi-sample variant calling](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration) but am still unclear as to how to run DeepVariant on a large sample size (~200). The example provided only uses a trio and the paper cited doesn't provide any code for their large cohort experiment. Do you have any resources for adjusting the parameters/running the samples in parallel so as to not run all ~200 samples sequentially? Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/529:264,Deployability,Install,Installation,264,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:; YES. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: ubuntu **16.04**; - DeepVariant version: **1.1.0**; - Installation method (Docker, built from source, etc.): **built from source**; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **WGS**. **Here is the problem:** I was trying to count reference supporting reads by the class ""**ReadSupportsAlt**"" defined in pileup_image_native.cc. To make sure it was correct, I also printed out the first value of Allele Depth (""**AD**"") for reference supporting reads. However, it turned out that there was an inconsistent number of reads counted by these two ways. To be more specific, there were more reference supporting reads counted by ""**ReadSupportAlt**"" than “**AD**“ did in general. At the very beginning, I thought it was non-alternate-allele reads that made this kind of inconsistent, then I viewed log files. Unfortunately, I found that there were at least 2 more reference supporting reads counted by ""**ReadSupportAlt**"" than “**AD**“ did (SNP, min_counts_snps = 2). So I am confused with the result. I would appreciate it if someone help me with this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:1068,Testability,log,log,1068,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:; YES. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: ubuntu **16.04**; - DeepVariant version: **1.1.0**; - Installation method (Docker, built from source, etc.): **built from source**; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **WGS**. **Here is the problem:** I was trying to count reference supporting reads by the class ""**ReadSupportsAlt**"" defined in pileup_image_native.cc. To make sure it was correct, I also printed out the first value of Allele Depth (""**AD**"") for reference supporting reads. However, it turned out that there was an inconsistent number of reads counted by these two ways. To be more specific, there were more reference supporting reads counted by ""**ReadSupportAlt**"" than “**AD**“ did in general. At the very beginning, I thought it was non-alternate-allele reads that made this kind of inconsistent, then I viewed log files. Unfortunately, I found that there were at least 2 more reference supporting reads counted by ""**ReadSupportAlt**"" than “**AD**“ did (SNP, min_counts_snps = 2). So I am confused with the result. I would appreciate it if someone help me with this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:125,Usability,clear,clear,125,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**:; YES. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: ubuntu **16.04**; - DeepVariant version: **1.1.0**; - Installation method (Docker, built from source, etc.): **built from source**; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **WGS**. **Here is the problem:** I was trying to count reference supporting reads by the class ""**ReadSupportsAlt**"" defined in pileup_image_native.cc. To make sure it was correct, I also printed out the first value of Allele Depth (""**AD**"") for reference supporting reads. However, it turned out that there was an inconsistent number of reads counted by these two ways. To be more specific, there were more reference supporting reads counted by ""**ReadSupportAlt**"" than “**AD**“ did in general. At the very beginning, I thought it was non-alternate-allele reads that made this kind of inconsistent, then I viewed log files. Unfortunately, I found that there were at least 2 more reference supporting reads counted by ""**ReadSupportAlt**"" than “**AD**“ did (SNP, min_counts_snps = 2). So I am confused with the result. I would appreciate it if someone help me with this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/530:141,Availability,error,error,141,"I ran this using singularity. I tried to tell the system to read and write files to a folder in my machine's /mnt/ folder. I keep getting an error. After inspecting, it looks like this image has an empty /mnt/ directory that is not writable. This is a problem for us and many users because it is very common to store large amounts of data in the /mnt/ folder on servers that access shared space from a common storage device. Please tell your Dockerfile to ""RUN rm -rf /mnt/"" or something (I'm not a docker expert by any means). The deepvariant docker container clearly does not need /mnt/. **Setup**; - Centos 7; - deepvariant 1.3.0; - Singularity run pulling from here: docker://google/deepvariant:""1.3.0""; - quickstart example. **Steps to reproduce:**; ...please note that /mnt/share is an NFS mount. My server mounts a drive on another machine running nfs.service ; mkdir -p /mnt/share/jasontest; cd /mnt/share/jasontest; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; BIN_VERSION=""1.3.0""; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:375,Security,access,access,375,"I ran this using singularity. I tried to tell the system to read and write files to a folder in my machine's /mnt/ folder. I keep getting an error. After inspecting, it looks like this image has an empty /mnt/ directory that is not writable. This is a problem for us and many users because it is very common to store large amounts of data in the /mnt/ folder on servers that access shared space from a common storage device. Please tell your Dockerfile to ""RUN rm -rf /mnt/"" or something (I'm not a docker expert by any means). The deepvariant docker container clearly does not need /mnt/. **Setup**; - Centos 7; - deepvariant 1.3.0; - Singularity run pulling from here: docker://google/deepvariant:""1.3.0""; - quickstart example. **Steps to reproduce:**; ...please note that /mnt/share is an NFS mount. My server mounts a drive on another machine running nfs.service ; mkdir -p /mnt/share/jasontest; cd /mnt/share/jasontest; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; BIN_VERSION=""1.3.0""; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:954,Testability,test,testdata,954,"I ran this using singularity. I tried to tell the system to read and write files to a folder in my machine's /mnt/ folder. I keep getting an error. After inspecting, it looks like this image has an empty /mnt/ directory that is not writable. This is a problem for us and many users because it is very common to store large amounts of data in the /mnt/ folder on servers that access shared space from a common storage device. Please tell your Dockerfile to ""RUN rm -rf /mnt/"" or something (I'm not a docker expert by any means). The deepvariant docker container clearly does not need /mnt/. **Setup**; - Centos 7; - deepvariant 1.3.0; - Singularity run pulling from here: docker://google/deepvariant:""1.3.0""; - quickstart example. **Steps to reproduce:**; ...please note that /mnt/share is an NFS mount. My server mounts a drive on another machine running nfs.service ; mkdir -p /mnt/share/jasontest; cd /mnt/share/jasontest; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; BIN_VERSION=""1.3.0""; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:1034,Testability,test,testdata,1034,"d and write files to a folder in my machine's /mnt/ folder. I keep getting an error. After inspecting, it looks like this image has an empty /mnt/ directory that is not writable. This is a problem for us and many users because it is very common to store large amounts of data in the /mnt/ folder on servers that access shared space from a common storage device. Please tell your Dockerfile to ""RUN rm -rf /mnt/"" or something (I'm not a docker expert by any means). The deepvariant docker container clearly does not need /mnt/. **Setup**; - Centos 7; - deepvariant 1.3.0; - Singularity run pulling from here: docker://google/deepvariant:""1.3.0""; - quickstart example. **Steps to reproduce:**; ...please note that /mnt/share is an NFS mount. My server mounts a drive on another machine running nfs.service ; mkdir -p /mnt/share/jasontest; cd /mnt/share/jasontest; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; BIN_VERSION=""1.3.0""; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:3668,Testability,test,test,3668,"}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; BIN_VERSION=""1.3.0""; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" --num_shards=1; . stack trace:. I0317 09:40:21.184321 140398386173760 run_deepvariant.py:341] Creating a directory for intermediate results in /mnt/share/jasontest/quickstart-output/intermediate_results_dir; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 460, in main; intermediate_results_dir = check_or_create_intermediate_results_dir(; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 343, in check_or_create_intermediate_results_dir; os.makedirs(intermediate_results_dir); File ""/usr/lib/python3.8/os.py"", line 213, in makedirs; makedirs(head, exist_ok=exist_ok); File ""/usr/lib/python3.8/os.py"", line 213, in makedirs; makedirs(head, exist_ok=exist_ok); File ""/usr/lib/python3.8/os.py"", line 213, in makedirs; makedirs(head, exist_ok=exist_ok); [Previous line repeated 1 more time]; File ""/usr/lib/python3.8/os.py"", line 223, in makedirs; mkdir(name, mode); OSError: [Errno 30] Read-only file system: '/mnt/share'. **Does the quick start test work on your system?**; The quick test works on my system as long as my data is not in the /mnt/ folder. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:3707,Testability,test,test,3707,"}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; BIN_VERSION=""1.3.0""; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" --num_shards=1; . stack trace:. I0317 09:40:21.184321 140398386173760 run_deepvariant.py:341] Creating a directory for intermediate results in /mnt/share/jasontest/quickstart-output/intermediate_results_dir; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 460, in main; intermediate_results_dir = check_or_create_intermediate_results_dir(; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 343, in check_or_create_intermediate_results_dir; os.makedirs(intermediate_results_dir); File ""/usr/lib/python3.8/os.py"", line 213, in makedirs; makedirs(head, exist_ok=exist_ok); File ""/usr/lib/python3.8/os.py"", line 213, in makedirs; makedirs(head, exist_ok=exist_ok); File ""/usr/lib/python3.8/os.py"", line 213, in makedirs; makedirs(head, exist_ok=exist_ok); [Previous line repeated 1 more time]; File ""/usr/lib/python3.8/os.py"", line 223, in makedirs; mkdir(name, mode); OSError: [Errno 30] Read-only file system: '/mnt/share'. **Does the quick start test work on your system?**; The quick test works on my system as long as my data is not in the /mnt/ folder. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:561,Usability,clear,clearly,561,"I ran this using singularity. I tried to tell the system to read and write files to a folder in my machine's /mnt/ folder. I keep getting an error. After inspecting, it looks like this image has an empty /mnt/ directory that is not writable. This is a problem for us and many users because it is very common to store large amounts of data in the /mnt/ folder on servers that access shared space from a common storage device. Please tell your Dockerfile to ""RUN rm -rf /mnt/"" or something (I'm not a docker expert by any means). The deepvariant docker container clearly does not need /mnt/. **Setup**; - Centos 7; - deepvariant 1.3.0; - Singularity run pulling from here: docker://google/deepvariant:""1.3.0""; - quickstart example. **Steps to reproduce:**; ...please note that /mnt/share is an NFS mount. My server mounts a drive on another machine running nfs.service ; mkdir -p /mnt/share/jasontest; cd /mnt/share/jasontest; INPUT_DIR=""${PWD}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; BIN_VERSION=""1.3.0""; OUTPUT_DIR=""${PWD}/quickstart-output""; mkdir -p ""${OUTPUT_DIR}""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/531:360,Energy Efficiency,reduce,reduce,360,"Hi,. I have been looking for documentation about the quality scores and how to interpret those. I am working on WGS data for human samples derived from patients affected by rare inherited disorders. I am looking to establish a filtering strategy on the raw VCF data, specifically for `RefCall` variants. I assume that simply getting rid of all those calls may reduce sensitivity. Therefore, I would like to figure out a quality score to use to filter these variants to maximize both sensitivity and specificity.; Any suggestion?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:178,Modifiability,inherit,inherited,178,"Hi,. I have been looking for documentation about the quality scores and how to interpret those. I am working on WGS data for human samples derived from patients affected by rare inherited disorders. I am looking to establish a filtering strategy on the raw VCF data, specifically for `RefCall` variants. I assume that simply getting rid of all those calls may reduce sensitivity. Therefore, I would like to figure out a quality score to use to filter these variants to maximize both sensitivity and specificity.; Any suggestion?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:318,Usability,simpl,simply,318,"Hi,. I have been looking for documentation about the quality scores and how to interpret those. I am working on WGS data for human samples derived from patients affected by rare inherited disorders. I am looking to establish a filtering strategy on the raw VCF data, specifically for `RefCall` variants. I assume that simply getting rid of all those calls may reduce sensitivity. Therefore, I would like to figure out a quality score to use to filter these variants to maximize both sensitivity and specificity.; Any suggestion?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/532:352,Deployability,Install,Installation,352,"**Describe the issue:**; Hi! I am trying to use deep-trio to call variants of drosophila (PACBIO data). I have noticed you have provide guides for training CNN model of deep variant, but I have no idea of training model of deep trio. Can I train a drosophila model of deep trio?. **Setup**; - Operating system: Cent OS; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) pacbio sequencing data",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:136,Usability,guid,guides,136,"**Describe the issue:**; Hi! I am trying to use deep-trio to call variants of drosophila (PACBIO data). I have noticed you have provide guides for training CNN model of deep variant, but I have no idea of training model of deep trio. Can I train a drosophila model of deep trio?. **Setup**; - Operating system: Cent OS; - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) pacbio sequencing data",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/533:402,Availability,error,error,402,"**Describe the issue:**; I am following the tutorial for [PacBio HiFi data](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md). When I reach the step for calling singularity to `run_deepvariant` ([this step](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-chromosome-20-alignments)), I receive an error which appears to be associated with the tempfile/TMPDIR path:. Command: ; ```; BIN_VERSION=""1.3.0""; mkdir -p deepvariant1. singularity exec --bind /usr/lib/locale/ \; docker://google/deepvariant:${BIN_VERSION} \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref reference/GRCh38_no_alt_analysis_set.fasta \; --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \; --output_vcf deepvariant1/output.vcf.gz \; --num_shards $(nproc) \; --regions chr20; ```. **Error 1**; ```; INFO: Using cached SIF image; I0403 10:34:56.987876 23171167450944 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp40dn43xh. ***** Intermediate results will be written to /tmp/tmp40dn43xh in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/[tmp/tmp40dn43xh/make_examples.tfrecord@16.gz](mailto:tmp/tmp40dn43xh/make_examples.tfrecord@16.gz)"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /local_scratch/pbs.4762337.pbs02/parXXXXX.par: Parent directory (/local_scratch/pbs.4762337.pbs02/) does not exist at /usr/bin/parallel line 3889.; ```. I can set `export TMPDIR = "".""` and this bypasses this error only to receive a different error stating that it canno",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:881,Availability,Error,Error,881,"**Describe the issue:**; I am following the tutorial for [PacBio HiFi data](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md). When I reach the step for calling singularity to `run_deepvariant` ([this step](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-chromosome-20-alignments)), I receive an error which appears to be associated with the tempfile/TMPDIR path:. Command: ; ```; BIN_VERSION=""1.3.0""; mkdir -p deepvariant1. singularity exec --bind /usr/lib/locale/ \; docker://google/deepvariant:${BIN_VERSION} \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref reference/GRCh38_no_alt_analysis_set.fasta \; --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \; --output_vcf deepvariant1/output.vcf.gz \; --num_shards $(nproc) \; --regions chr20; ```. **Error 1**; ```; INFO: Using cached SIF image; I0403 10:34:56.987876 23171167450944 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp40dn43xh. ***** Intermediate results will be written to /tmp/tmp40dn43xh in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/[tmp/tmp40dn43xh/make_examples.tfrecord@16.gz](mailto:tmp/tmp40dn43xh/make_examples.tfrecord@16.gz)"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /local_scratch/pbs.4762337.pbs02/parXXXXX.par: Parent directory (/local_scratch/pbs.4762337.pbs02/) does not exist at /usr/bin/parallel line 3889.; ```. I can set `export TMPDIR = "".""` and this bypasses this error only to receive a different error stating that it canno",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1697,Availability,Error,Error,1697,"set.fasta \; --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \; --output_vcf deepvariant1/output.vcf.gz \; --num_shards $(nproc) \; --regions chr20; ```. **Error 1**; ```; INFO: Using cached SIF image; I0403 10:34:56.987876 23171167450944 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp40dn43xh. ***** Intermediate results will be written to /tmp/tmp40dn43xh in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/[tmp/tmp40dn43xh/make_examples.tfrecord@16.gz](mailto:tmp/tmp40dn43xh/make_examples.tfrecord@16.gz)"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /local_scratch/pbs.4762337.pbs02/parXXXXX.par: Parent directory (/local_scratch/pbs.4762337.pbs02/) does not exist at /usr/bin/parallel line 3889.; ```. I can set `export TMPDIR = "".""` and this bypasses this error only to receive a different error stating that it cannot find any of the files that are downloaded in the previous steps of the tutorial. . **Error 2**; ```; INFO: Using cached SIF image; I0404 16:29:50.730109 22987118802752 run_deepvariant.py:345] Re-using the directory for intermediate results in ./tmpkj84jstw. ***** Intermediate results will be written to ./tmpkj84jstw in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""./tmpkj84jstw/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1940,Availability,error,error,1940,"he directory for intermediate results in /tmp/tmp40dn43xh. ***** Intermediate results will be written to /tmp/tmp40dn43xh in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/[tmp/tmp40dn43xh/make_examples.tfrecord@16.gz](mailto:tmp/tmp40dn43xh/make_examples.tfrecord@16.gz)"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /local_scratch/pbs.4762337.pbs02/parXXXXX.par: Parent directory (/local_scratch/pbs.4762337.pbs02/) does not exist at /usr/bin/parallel line 3889.; ```. I can set `export TMPDIR = "".""` and this bypasses this error only to receive a different error stating that it cannot find any of the files that are downloaded in the previous steps of the tutorial. . **Error 2**; ```; INFO: Using cached SIF image; I0404 16:29:50.730109 22987118802752 run_deepvariant.py:345] Re-using the directory for intermediate results in ./tmpkj84jstw. ***** Intermediate results will be written to ./tmpkj84jstw in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""./tmpkj84jstw/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. [E::hts_open_format] Failed to open file ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" : No such file or directory; Traceback (most recent call last):; File ""./B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1974,Availability,error,error,1974,"he directory for intermediate results in /tmp/tmp40dn43xh. ***** Intermediate results will be written to /tmp/tmp40dn43xh in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/[tmp/tmp40dn43xh/make_examples.tfrecord@16.gz](mailto:tmp/tmp40dn43xh/make_examples.tfrecord@16.gz)"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /local_scratch/pbs.4762337.pbs02/parXXXXX.par: Parent directory (/local_scratch/pbs.4762337.pbs02/) does not exist at /usr/bin/parallel line 3889.; ```. I can set `export TMPDIR = "".""` and this bypasses this error only to receive a different error stating that it cannot find any of the files that are downloaded in the previous steps of the tutorial. . **Error 2**; ```; INFO: Using cached SIF image; I0404 16:29:50.730109 22987118802752 run_deepvariant.py:345] Re-using the directory for intermediate results in ./tmpkj84jstw. ***** Intermediate results will be written to ./tmpkj84jstw in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""./tmpkj84jstw/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. [E::hts_open_format] Failed to open file ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" : No such file or directory; Traceback (most recent call last):; File ""./B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:2034,Availability,down,downloaded,2034,"he directory for intermediate results in /tmp/tmp40dn43xh. ***** Intermediate results will be written to /tmp/tmp40dn43xh in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/[tmp/tmp40dn43xh/make_examples.tfrecord@16.gz](mailto:tmp/tmp40dn43xh/make_examples.tfrecord@16.gz)"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /local_scratch/pbs.4762337.pbs02/parXXXXX.par: Parent directory (/local_scratch/pbs.4762337.pbs02/) does not exist at /usr/bin/parallel line 3889.; ```. I can set `export TMPDIR = "".""` and this bypasses this error only to receive a different error stating that it cannot find any of the files that are downloaded in the previous steps of the tutorial. . **Error 2**; ```; INFO: Using cached SIF image; I0404 16:29:50.730109 22987118802752 run_deepvariant.py:345] Re-using the directory for intermediate results in ./tmpkj84jstw. ***** Intermediate results will be written to ./tmpkj84jstw in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""./tmpkj84jstw/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. [E::hts_open_format] Failed to open file ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" : No such file or directory; Traceback (most recent call last):; File ""./B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:2088,Availability,Error,Error,2088,"xh in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/[tmp/tmp40dn43xh/make_examples.tfrecord@16.gz](mailto:tmp/tmp40dn43xh/make_examples.tfrecord@16.gz)"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /local_scratch/pbs.4762337.pbs02/parXXXXX.par: Parent directory (/local_scratch/pbs.4762337.pbs02/) does not exist at /usr/bin/parallel line 3889.; ```. I can set `export TMPDIR = "".""` and this bypasses this error only to receive a different error stating that it cannot find any of the files that are downloaded in the previous steps of the tutorial. . **Error 2**; ```; INFO: Using cached SIF image; I0404 16:29:50.730109 22987118802752 run_deepvariant.py:345] Re-using the directory for intermediate results in ./tmpkj84jstw. ***** Intermediate results will be written to ./tmpkj84jstw in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""./tmpkj84jstw/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. [E::hts_open_format] Failed to open file ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" : No such file or directory; Traceback (most recent call last):; File ""./Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:4779,Availability,ERROR,ERROR,4779,"unfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 131, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: Not found: Could not open input/HG003.GRCh38.chr20.pFDA_truthv2.bam. ...REPEAT ABOVE ERROR {NPROC} TIMES... parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --examples ./tmpkj84jstw/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --pileup_image_width 199 --norealign_reads --regions chr20 --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 12. real	0m4.843s; user	0m3.036s; sys	0m0.866s; ```. **Setup**; - Operating system: CentOS Linux release 8.2.2004 (Core); - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity/Docker; - Type of data: [Tutorial Data]((https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md)). **Does the quick start test work on your system?**; The same error occurs in the quick start test with `Error in tempfile() using template...` as above.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:5648,Availability,error,error,5648,"unfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 131, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: Not found: Could not open input/HG003.GRCh38.chr20.pFDA_truthv2.bam. ...REPEAT ABOVE ERROR {NPROC} TIMES... parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --examples ./tmpkj84jstw/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --pileup_image_width 199 --norealign_reads --regions chr20 --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 12. real	0m4.843s; user	0m3.036s; sys	0m0.866s; ```. **Setup**; - Operating system: CentOS Linux release 8.2.2004 (Core); - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity/Docker; - Type of data: [Tutorial Data]((https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md)). **Does the quick start test work on your system?**; The same error occurs in the quick start test with `Error in tempfile() using template...` as above.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:5691,Availability,Error,Error,5691,"unfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 131, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: Not found: Could not open input/HG003.GRCh38.chr20.pFDA_truthv2.bam. ...REPEAT ABOVE ERROR {NPROC} TIMES... parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --examples ./tmpkj84jstw/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --pileup_image_width 199 --norealign_reads --regions chr20 --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 12. real	0m4.843s; user	0m3.036s; sys	0m0.866s; ```. **Setup**; - Operating system: CentOS Linux release 8.2.2004 (Core); - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity/Docker; - Type of data: [Tutorial Data]((https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md)). **Does the quick start test work on your system?**; The same error occurs in the quick start test with `Error in tempfile() using template...` as above.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:5327,Deployability,release,release,5327,"unfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 131, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: Not found: Could not open input/HG003.GRCh38.chr20.pFDA_truthv2.bam. ...REPEAT ABOVE ERROR {NPROC} TIMES... parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --examples ./tmpkj84jstw/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --pileup_image_width 199 --norealign_reads --regions chr20 --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 12. real	0m4.843s; user	0m3.036s; sys	0m0.866s; ```. **Setup**; - Operating system: CentOS Linux release 8.2.2004 (Core); - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity/Docker; - Type of data: [Tutorial Data]((https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md)). **Does the quick start test work on your system?**; The same error occurs in the quick start test with `Error in tempfile() using template...` as above.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:5384,Deployability,Install,Installation,5384,"unfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 131, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: Not found: Could not open input/HG003.GRCh38.chr20.pFDA_truthv2.bam. ...REPEAT ABOVE ERROR {NPROC} TIMES... parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --examples ./tmpkj84jstw/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --pileup_image_width 199 --norealign_reads --regions chr20 --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 12. real	0m4.843s; user	0m3.036s; sys	0m0.866s; ```. **Setup**; - Operating system: CentOS Linux release 8.2.2004 (Core); - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity/Docker; - Type of data: [Tutorial Data]((https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md)). **Does the quick start test work on your system?**; The same error occurs in the quick start test with `Error in tempfile() using template...` as above.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:909,Performance,cache,cached,909,"**Describe the issue:**; I am following the tutorial for [PacBio HiFi data](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md). When I reach the step for calling singularity to `run_deepvariant` ([this step](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md#run-deepvariant-on-chromosome-20-alignments)), I receive an error which appears to be associated with the tempfile/TMPDIR path:. Command: ; ```; BIN_VERSION=""1.3.0""; mkdir -p deepvariant1. singularity exec --bind /usr/lib/locale/ \; docker://google/deepvariant:${BIN_VERSION} \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref reference/GRCh38_no_alt_analysis_set.fasta \; --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \; --output_vcf deepvariant1/output.vcf.gz \; --num_shards $(nproc) \; --regions chr20; ```. **Error 1**; ```; INFO: Using cached SIF image; I0403 10:34:56.987876 23171167450944 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp40dn43xh. ***** Intermediate results will be written to /tmp/tmp40dn43xh in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/[tmp/tmp40dn43xh/make_examples.tfrecord@16.gz](mailto:tmp/tmp40dn43xh/make_examples.tfrecord@16.gz)"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /local_scratch/pbs.4762337.pbs02/parXXXXX.par: Parent directory (/local_scratch/pbs.4762337.pbs02/) does not exist at /usr/bin/parallel line 3889.; ```. I can set `export TMPDIR = "".""` and this bypasses this error only to receive a different error stating that it canno",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:2116,Performance,cache,cached,2116,"xh in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/[tmp/tmp40dn43xh/make_examples.tfrecord@16.gz](mailto:tmp/tmp40dn43xh/make_examples.tfrecord@16.gz)"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /local_scratch/pbs.4762337.pbs02/parXXXXX.par: Parent directory (/local_scratch/pbs.4762337.pbs02/) does not exist at /usr/bin/parallel line 3889.; ```. I can set `export TMPDIR = "".""` and this bypasses this error only to receive a different error stating that it cannot find any of the files that are downloaded in the previous steps of the tutorial. . **Error 2**; ```; INFO: Using cached SIF image; I0404 16:29:50.730109 22987118802752 run_deepvariant.py:345] Re-using the directory for intermediate results in ./tmpkj84jstw. ***** Intermediate results will be written to ./tmpkj84jstw in docker. ****. ***** Running the command:*****; time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""./tmpkj84jstw/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. [E::hts_open_format] Failed to open file ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" : No such file or directory; Traceback (most recent call last):; File ""./Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:5610,Testability,test,test,5610,"unfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 131, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: Not found: Could not open input/HG003.GRCh38.chr20.pFDA_truthv2.bam. ...REPEAT ABOVE ERROR {NPROC} TIMES... parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --examples ./tmpkj84jstw/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --pileup_image_width 199 --norealign_reads --regions chr20 --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 12. real	0m4.843s; user	0m3.036s; sys	0m0.866s; ```. **Setup**; - Operating system: CentOS Linux release 8.2.2004 (Core); - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity/Docker; - Type of data: [Tutorial Data]((https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md)). **Does the quick start test work on your system?**; The same error occurs in the quick start test with `Error in tempfile() using template...` as above.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:5680,Testability,test,test,5680,"unfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 131, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/home/rrautsa/Bazel.runfiles_bpldxvlm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: Not found: Could not open input/HG003.GRCh38.chr20.pFDA_truthv2.bam. ...REPEAT ABOVE ERROR {NPROC} TIMES... parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref reference/GRCh38_no_alt_analysis_set.fasta --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --examples ./tmpkj84jstw/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --pileup_image_width 199 --norealign_reads --regions chr20 --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 12. real	0m4.843s; user	0m3.036s; sys	0m0.866s; ```. **Setup**; - Operating system: CentOS Linux release 8.2.2004 (Core); - DeepVariant version: 1.3.0; - Installation method (Docker, built from source, etc.): Singularity/Docker; - Type of data: [Tutorial Data]((https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-pacbio-model-case-study.md)). **Does the quick start test work on your system?**; The same error occurs in the quick start test with `Error in tempfile() using template...` as above.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/534:172,Deployability,release,released,172,"**Describe the issue:**. I apologize as this is a question rather than a problem.; So this ticket isn't using any predefined template. Here's my question:; given the newly released human T2T reference (v2.0), should DV be re-trained against that reference?; I must admit I don't understand DV deep enough to ponder with what the potential benefits would be, so am curious about your thoughts. Thanks!. Steve. p.s. the data modes most relevant for us are CCS, ONT.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/537:680,Availability,error,error,680,"I am trying to use deepvariant to call variants using a TPU Node v3-8, but I am running into a persistent issue. Here is the command I am using:; ```bash; docker run \; -v `pwd`:`pwd` -w `pwd` \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \; --model_type=WGS \; --ref=""input/data/${REF}"" \; --reads=""input/data/${BAM}"" \; --output_vcf=""output/${OUTPUT_VCF}"" \; --output_gvcf=""output/${OUTPUT_GVCF}"" \; --regions chr20 \; --num_shards=$(nproc) \; --intermediate_results_dir /output/intermediate_results_dir; ```; However, I am seeing the following error in the call variants step.; ```bash; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@96.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/output/intermediate_results_dir"" --tpu_name ""variantcaller-node1"" --tpu_zone ""europe-west4-a"" --use_tpu. I0524 21:18:26.485428 140032543119168 transport.py:157] Attempting refresh to obtain initial access_token; I0524 21:18:26.576728 140032543119168 call_variants.py:336] Shape of input examples: [100, 221, 6]; I0524 21:18:26.579230 140032543119168 call_variants.py:361] /opt/models/wgs/model.ckpt.input_shape has the correct shape: [100, 221, 6].; 2022-05-24 21:18:26.581705: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-05-24 21:18:26.586196: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:951,Availability,checkpoint,checkpoint,951,"I am trying to use deepvariant to call variants using a TPU Node v3-8, but I am running into a persistent issue. Here is the command I am using:; ```bash; docker run \; -v `pwd`:`pwd` -w `pwd` \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \; --model_type=WGS \; --ref=""input/data/${REF}"" \; --reads=""input/data/${BAM}"" \; --output_vcf=""output/${OUTPUT_VCF}"" \; --output_gvcf=""output/${OUTPUT_GVCF}"" \; --regions chr20 \; --num_shards=$(nproc) \; --intermediate_results_dir /output/intermediate_results_dir; ```; However, I am seeing the following error in the call variants step.; ```bash; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@96.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/output/intermediate_results_dir"" --tpu_name ""variantcaller-node1"" --tpu_zone ""europe-west4-a"" --use_tpu. I0524 21:18:26.485428 140032543119168 transport.py:157] Attempting refresh to obtain initial access_token; I0524 21:18:26.576728 140032543119168 call_variants.py:336] Shape of input examples: [100, 221, 6]; I0524 21:18:26.579230 140032543119168 call_variants.py:361] /opt/models/wgs/model.ckpt.input_shape has the correct shape: [100, 221, 6].; 2022-05-24 21:18:26.581705: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-05-24 21:18:26.586196: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6307,Availability,Avail,Available,6307,"//10.73.74.226:8470) for TPU system metadata.; I0524 21:18:26.625535 140032543119168 tpu_system_metadata.py:90] Querying Tensorflow master (grpc://10.73.74.226:8470) for TPU system metadata.; 2022-05-24 21:18:26.626490: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:373] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.; INFO:tensorflow:Found TPU system:; I0524 21:18:26.631762 140032543119168 tpu_system_metadata.py:159] Found TPU system:; INFO:tensorflow:*** Num TPU Cores: 8; I0524 21:18:26.631872 140032543119168 tpu_system_metadata.py:160] *** Num TPU Cores: 8; INFO:tensorflow:*** Num TPU Workers: 1; I0524 21:18:26.631940 140032543119168 tpu_system_metadata.py:161] *** Num TPU Workers: 1; INFO:tensorflow:*** Num TPU Cores Per Worker: 8; I0524 21:18:26.631998 140032543119168 tpu_system_metadata.py:162] *** Num TPU Cores Per Worker: 8; INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); I0524 21:18:26.632062 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); I0524 21:18:26.632296 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6491,Availability,Avail,Available,6491,"3] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.; INFO:tensorflow:Found TPU system:; I0524 21:18:26.631762 140032543119168 tpu_system_metadata.py:159] Found TPU system:; INFO:tensorflow:*** Num TPU Cores: 8; I0524 21:18:26.631872 140032543119168 tpu_system_metadata.py:160] *** Num TPU Cores: 8; INFO:tensorflow:*** Num TPU Workers: 1; I0524 21:18:26.631940 140032543119168 tpu_system_metadata.py:161] *** Num TPU Workers: 1; INFO:tensorflow:*** Num TPU Cores Per Worker: 8; I0524 21:18:26.631998 140032543119168 tpu_system_metadata.py:162] *** Num TPU Cores Per Worker: 8; INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); I0524 21:18:26.632062 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); I0524 21:18:26.632296 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INF",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6625,Availability,Avail,Available,6625,"3] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.; INFO:tensorflow:Found TPU system:; I0524 21:18:26.631762 140032543119168 tpu_system_metadata.py:159] Found TPU system:; INFO:tensorflow:*** Num TPU Cores: 8; I0524 21:18:26.631872 140032543119168 tpu_system_metadata.py:160] *** Num TPU Cores: 8; INFO:tensorflow:*** Num TPU Workers: 1; I0524 21:18:26.631940 140032543119168 tpu_system_metadata.py:161] *** Num TPU Workers: 1; INFO:tensorflow:*** Num TPU Cores Per Worker: 8; I0524 21:18:26.631998 140032543119168 tpu_system_metadata.py:162] *** Num TPU Cores Per Worker: 8; INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); I0524 21:18:26.632062 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); I0524 21:18:26.632296 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INF",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6819,Availability,Avail,Available,6819,"9168 tpu_system_metadata.py:160] *** Num TPU Cores: 8; INFO:tensorflow:*** Num TPU Workers: 1; I0524 21:18:26.631940 140032543119168 tpu_system_metadata.py:161] *** Num TPU Workers: 1; INFO:tensorflow:*** Num TPU Cores Per Worker: 8; I0524 21:18:26.631998 140032543119168 tpu_system_metadata.py:162] *** Num TPU Cores Per Worker: 8; INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); I0524 21:18:26.632062 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); I0524 21:18:26.632296 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6963,Availability,Avail,Available,6963,"9168 tpu_system_metadata.py:160] *** Num TPU Cores: 8; INFO:tensorflow:*** Num TPU Workers: 1; I0524 21:18:26.631940 140032543119168 tpu_system_metadata.py:161] *** Num TPU Workers: 1; INFO:tensorflow:*** Num TPU Cores Per Worker: 8; I0524 21:18:26.631998 140032543119168 tpu_system_metadata.py:162] *** Num TPU Cores Per Worker: 8; INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); I0524 21:18:26.632062 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); I0524 21:18:26.632296 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7157,Availability,Avail,Available,7157,"tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); I0524 21:18:26.632062 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); I0524 21:18:26.632296 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7301,Availability,Avail,Available,7301,"tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); I0524 21:18:26.632062 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 3314463783741359823); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); I0524 21:18:26.632296 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7495,Availability,Avail,Available,7495,"able Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); I0524 21:18:26.632296 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7639,Availability,Avail,Available,7639,"able Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); I0524 21:18:26.632296 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -1873770143808342957); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7833,Availability,Avail,Available,7833,"able Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7977,Availability,Avail,Available,7977,"able Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); I0524 21:18:26.632360 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -3891821674854936774); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8170,Availability,Avail,Available,8170,"lable Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8313,Availability,Avail,Available,8313,"lable Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); I0524 21:18:26.632421 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -6041584165456864718); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8507,Availability,Avail,Available,8507,"ilable Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); I0524 21:18:26.632860 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8651,Availability,Avail,Available,8651,"ilable Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); I0524 21:18:26.632479 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -4899456949080638211); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); I0524 21:18:26.632860 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8844,Availability,Avail,Available,8844,"ailable Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); I0524 21:18:26.632860 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); I0524 21:18:26.632941 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8987,Availability,Avail,Available,8987,"ailable Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); I0524 21:18:26.632545 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6180324062742322030); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); I0524 21:18:26.632860 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); I0524 21:18:26.632941 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9181,Availability,Avail,Available,9181,"Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); I0524 21:18:26.632860 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); I0524 21:18:26.632941 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); INFO:tensorflow:Calling model_fn.; I0524 21:18:26.633588 140032543119168 estimator.py:1162] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `laye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9325,Availability,Avail,Available,9325,"Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); I0524 21:18:26.632611 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -2652458924365639691); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); I0524 21:18:26.632860 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); I0524 21:18:26.632941 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); INFO:tensorflow:Calling model_fn.; I0524 21:18:26.633588 140032543119168 estimator.py:1162] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `laye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9532,Availability,Avail,Available,9532,"ttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); I0524 21:18:26.632860 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); I0524 21:18:26.632941 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); INFO:tensorflow:Calling model_fn.; I0524 21:18:26.633588 140032543119168 estimator.py:1162] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0524 21:18:32.742463 140032543119168 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:TPU job name tpu_worker; I0524 21:18:33.019782 140032543119168 tpu_estimator.py:514] TPU job name tpu_worker; INFO:tensorflow:Graph was fin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9689,Availability,Avail,Available,9689,"ttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); I0524 21:18:26.632669 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3158275143315040778); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); I0524 21:18:26.632860 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); I0524 21:18:26.632941 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); INFO:tensorflow:Calling model_fn.; I0524 21:18:26.633588 140032543119168 estimator.py:1162] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0524 21:18:32.742463 140032543119168 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:TPU job name tpu_worker; I0524 21:18:33.019782 140032543119168 tpu_estimator.py:514] TPU job name tpu_worker; INFO:tensorflow:Graph was fin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9890,Availability,Avail,Available,9890," INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); I0524 21:18:26.632792 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -4822366763137283978); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); I0524 21:18:26.632860 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2291186206241199287); INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); I0524 21:18:26.632941 140032543119168 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7884439564287565365); INFO:tensorflow:Calling model_fn.; I0524 21:18:26.633588 140032543119168 estimator.py:1162] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0524 21:18:32.742463 140032543119168 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:TPU job name tpu_worker; I0524 21:18:33.019782 140032543119168 tpu_estimator.py:514] TPU job name tpu_worker; INFO:tensorflow:Graph was finalized.; I0524 21:18:33.525068 140032543119168 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0524 21:18:33.525994 140032543119168 saver.py:1298] Restoring parameters from /opt/models/wgs/model.ckpt; INFO:tensorflow:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11137,Availability,error,error,11137,"1162] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0524 21:18:32.742463 140032543119168 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:TPU job name tpu_worker; I0524 21:18:33.019782 140032543119168 tpu_estimator.py:514] TPU job name tpu_worker; INFO:tensorflow:Graph was finalized.; I0524 21:18:33.525068 140032543119168 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0524 21:18:33.525994 140032543119168 saver.py:1298] Restoring parameters from /opt/models/wgs/model.ckpt; INFO:tensorflow:prediction_loop marked as finished; I0524 21:18:34.251420 140032543119168 error_handling.py:115] prediction_loop marked as finished; WARNING:tensorflow:Reraising captured error; W0524 21:18:34.251592 140032543119168 error_handling.py:149] Reraising captured error; Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call; return fn(*args); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn; return self._call_tf_sessionrun(options, feed_dict, fetch_list,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun; return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,; tensorflow.python.framework.errors_impl.InvalidArgumentError: From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'); [[{{node save_1/RestoreV2}}]]. During handling",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11224,Availability,error,error,11224,"pply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0524 21:18:32.742463 140032543119168 estimator.py:1164] Done calling model_fn.; INFO:tensorflow:TPU job name tpu_worker; I0524 21:18:33.019782 140032543119168 tpu_estimator.py:514] TPU job name tpu_worker; INFO:tensorflow:Graph was finalized.; I0524 21:18:33.525068 140032543119168 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0524 21:18:33.525994 140032543119168 saver.py:1298] Restoring parameters from /opt/models/wgs/model.ckpt; INFO:tensorflow:prediction_loop marked as finished; I0524 21:18:34.251420 140032543119168 error_handling.py:115] prediction_loop marked as finished; WARNING:tensorflow:Reraising captured error; W0524 21:18:34.251592 140032543119168 error_handling.py:149] Reraising captured error; Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call; return fn(*args); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn; return self._call_tf_sessionrun(options, feed_dict, fetch_list,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun; return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,; tensorflow.python.framework.errors_impl.InvalidArgumentError: From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'); [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21339,Availability,checkpoint,checkpoint,21339,"f_sess = self._session_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session; return self._get_session_manager().prepare_session(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session; sess, is_loaded_from_checkpoint = self._restore_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint; _restore_checkpoint_and_maybe_run_saved_model_initializers(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers; saver.restore(sess, path); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1339, in restore; raise _wrap_restore_error_with_msg(; tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'); [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21445,Availability,checkpoint,checkpoint,21445,".8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session; return self._get_session_manager().prepare_session(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session; sess, is_loaded_from_checkpoint = self._restore_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint; _restore_checkpoint_and_maybe_run_saved_model_initializers(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers; saver.restore(sess, path); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1339, in restore; raise _wrap_restore_error_with_msg(; tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'); [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21529,Availability,checkpoint,checkpoint,21529,"on; return self._get_session_manager().prepare_session(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session; sess, is_loaded_from_checkpoint = self._restore_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint; _restore_checkpoint_and_maybe_run_saved_model_initializers(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers; saver.restore(sess, path); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1339, in restore; raise _wrap_restore_error_with_msg(; tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'); [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21550,Availability,error,error,21550,"sion(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session; sess, is_loaded_from_checkpoint = self._restore_checkpoint(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint; _restore_checkpoint_and_maybe_run_saved_model_initializers(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers; saver.restore(sess, path); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1339, in restore; raise _wrap_restore_error_with_msg(; tensorflow.python.framework.errors_impl.InvalidArgumentError: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'); [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14608,Energy Efficiency,Monitor,MonitoredSession,14608,"ib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session; self._scaffold.finalize(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14751,Energy Efficiency,Monitor,MonitoredSession,14751,"arser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session; self._scaffold.finalize(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in fina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19496,Energy Efficiency,Monitor,MonitoredSession,19496,"nt/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict; rendezvous.raise_errors(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors; six.reraise(typ, value, traceback); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session; return self._get_s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19640,Energy Efficiency,Monitor,MonitoredSession,19640,"om_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict; rendezvous.raise_errors(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors; six.reraise(typ, value, traceback); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session; return self._get_session_manager().prepare_session(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:23118,Energy Efficiency,Monitor,MonitoredSession,23118,"ib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session; self._scaffold.finalize(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:23261,Energy Efficiency,Monitor,MonitoredSession,23261,"arser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session; self._scaffold.finalize(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in fina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12976,Integrability,message,message,12976,"kpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'); [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore; sess.run(self.saver_def.restore_op_name,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run; result = self._run(None, fetches, feed_dict, options_ptr,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run; results = self._do_run(handle, final_targets, final_fetches,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run; return self._do_call(_run_fn, feeds, fetches, targets, options,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call; raise type(e)(node_def, op, message); tensorflow.python.framework.errors_impl.InvalidArgumentError: From /job:tpu_worker/replica:0/task:0:; Unsuccessful TensorSliceReader constructor: Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'); [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2356,Modifiability,config,config,2356,"tions: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-05-24 21:18:26.586196: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2022-05-24 21:18:26.587127: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000160000 Hz; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_f348kd0; W0524 21:18:26.619681 140032543119168 estimator.py:1846] Using temporary folder as model directory: /tmp/tmp_f348kd0; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_f348kd0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true; graph_options {; rewrite_options {; meta_optimizer_iterations: ONE; }; }; , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.74.226:8470', '_evaluation_master': 'grpc://10.73.74.226:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}; I0524 21:18:26.620151 140032543119168 estimat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3715,Modifiability,config,config,3715,"_cluster': 0, '_master': 'grpc://10.73.74.226:8470', '_evaluation_master': 'grpc://10.73.74.226:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}; I0524 21:18:26.620151 140032543119168 estimator.py:191] Using config: {'_model_dir': '/tmp/tmp_f348kd0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true; graph_options {; rewrite_options {; meta_optimizer_iterations: ONE; }; }; , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.74.226:8470', '_evaluation_master': 'grpc://10.73.74.226:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': None}; INFO:tensorflow:_TPUContext: eval_on_tpu True; I0524 21:18:26.620373 140032543119168",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1571,Performance,optimiz,optimized,1571,"wing error in the call variants step.; ```bash; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@96.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/output/intermediate_results_dir"" --tpu_name ""variantcaller-node1"" --tpu_zone ""europe-west4-a"" --use_tpu. I0524 21:18:26.485428 140032543119168 transport.py:157] Attempting refresh to obtain initial access_token; I0524 21:18:26.576728 140032543119168 call_variants.py:336] Shape of input examples: [100, 221, 6]; I0524 21:18:26.579230 140032543119168 call_variants.py:361] /opt/models/wgs/model.ckpt.input_shape has the correct shape: [100, 221, 6].; 2022-05-24 21:18:26.581705: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-05-24 21:18:26.586196: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2022-05-24 21:18:26.587127: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000160000 Hz; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_f348kd0; W0524 21:18:26.619681 140032543119168 estimator.py:1846] Using temporary folder as model directory: /tmp/tmp_f348kd0; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_f348kd0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true; graph_options {; rewrite_options {; meta_optimizer_iterations: ONE; }; }; , '_keep_checkpoint_max': 100000, '_ke",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1671,Performance,perform,performance-critical,1671,"wing error in the call variants step.; ```bash; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@96.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/output/intermediate_results_dir"" --tpu_name ""variantcaller-node1"" --tpu_zone ""europe-west4-a"" --use_tpu. I0524 21:18:26.485428 140032543119168 transport.py:157] Attempting refresh to obtain initial access_token; I0524 21:18:26.576728 140032543119168 call_variants.py:336] Shape of input examples: [100, 221, 6]; I0524 21:18:26.579230 140032543119168 call_variants.py:361] /opt/models/wgs/model.ckpt.input_shape has the correct shape: [100, 221, 6].; 2022-05-24 21:18:26.581705: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-05-24 21:18:26.586196: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2022-05-24 21:18:26.587127: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000160000 Hz; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_f348kd0; W0524 21:18:26.619681 140032543119168 estimator.py:1846] Using temporary folder as model directory: /tmp/tmp_f348kd0; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_f348kd0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true; graph_options {; rewrite_options {; meta_optimizer_iterations: ONE; }; }; , '_keep_checkpoint_max': 100000, '_ke",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1956,Performance,Tune,Tune,1956,"kpt"" --openvino_model_dir ""/output/intermediate_results_dir"" --tpu_name ""variantcaller-node1"" --tpu_zone ""europe-west4-a"" --use_tpu. I0524 21:18:26.485428 140032543119168 transport.py:157] Attempting refresh to obtain initial access_token; I0524 21:18:26.576728 140032543119168 call_variants.py:336] Shape of input examples: [100, 221, 6]; I0524 21:18:26.579230 140032543119168 call_variants.py:361] /opt/models/wgs/model.ckpt.input_shape has the correct shape: [100, 221, 6].; 2022-05-24 21:18:26.581705: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-05-24 21:18:26.586196: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2022-05-24 21:18:26.587127: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000160000 Hz; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_f348kd0; W0524 21:18:26.619681 140032543119168 estimator.py:1846] Using temporary folder as model directory: /tmp/tmp_f348kd0; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_f348kd0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true; graph_options {; rewrite_options {; meta_optimizer_iterations: ONE; }; }; , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': Tr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2005,Performance,perform,performance,2005,"kpt"" --openvino_model_dir ""/output/intermediate_results_dir"" --tpu_name ""variantcaller-node1"" --tpu_zone ""europe-west4-a"" --use_tpu. I0524 21:18:26.485428 140032543119168 transport.py:157] Attempting refresh to obtain initial access_token; I0524 21:18:26.576728 140032543119168 call_variants.py:336] Shape of input examples: [100, 221, 6]; I0524 21:18:26.579230 140032543119168 call_variants.py:361] /opt/models/wgs/model.ckpt.input_shape has the correct shape: [100, 221, 6].; 2022-05-24 21:18:26.581705: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-05-24 21:18:26.586196: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2022-05-24 21:18:26.587127: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000160000 Hz; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_f348kd0; W0524 21:18:26.619681 140032543119168 estimator.py:1846] Using temporary folder as model directory: /tmp/tmp_f348kd0; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_f348kd0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true; graph_options {; rewrite_options {; meta_optimizer_iterations: ONE; }; }; , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': Tr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14255,Safety,predict,prediction,14255,"els/wgs/model.ckpt'); [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14273,Safety,predict,predictions,14273,"els/wgs/model.ckpt'); [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14406,Safety,predict,predict,14406,"]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14455,Safety,predict,predict,14455," ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14575,Safety,predict,predict,14575,"3, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18715,Safety,predict,prediction,18715,""", line 2045, in __init__; self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict; rendezvous.raise_errors(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors; six.reraise(typ, value, traceback); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""/usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18733,Safety,predict,predictions,18733,""", line 2045, in __init__; self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict; rendezvous.raise_errors(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors; six.reraise(typ, value, traceback); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""/usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18867,Safety,predict,predict,18867,"exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict; rendezvous.raise_errors(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors; six.reraise(typ, value, traceback); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""/usr/loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19293,Safety,predict,predict,19293,"299, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict; rendezvous.raise_errors(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors; six.reraise(typ, value, traceback); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19342,Safety,predict,predict,19342,"runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict; rendezvous.raise_errors(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors; six.reraise(typ, value, traceback); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.cr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19463,Safety,predict,predict,19463,"/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict; rendezvous.raise_errors(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors; six.reraise(typ, value, traceback); File ""/tmp/Bazel.runfiles_o0nxhusg/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_ses",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22765,Safety,predict,prediction,22765,"els/wgs/model.ckpt'); [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22783,Safety,predict,predictions,22783,"els/wgs/model.ckpt'); [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22916,Safety,predict,predict,22916,"]. Original stack trace for 'save_1/RestoreV2':; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22965,Safety,predict,predict,22965," ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:23085,Safety,predict,predict,23085,"3, in <module>; tf.compat.v1.app.run(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 299, in run; _run_main(main, args); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/absl_py/absl/app.py"", line 250, in _run_main; sys.exit(main(argv)); File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main; call_variants(; File ""tmp/Bazel.runfiles_o0nxhusg/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants; prediction = next(predictions); File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict; for result in super(TPUEstimator, self).predict(; File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict; with tf.compat.v1.train.MonitoredSession(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__; super(MonitoredSession, self).__init__(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15833,Security,access,access,15833,"ages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session; self._scaffold.finalize(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize; self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default; saver = Saver(sharded=True, allow_empty=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__; self.build(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build; self._build(self._filename, build_save=True, build_restore=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build; self.saver_def = self._builder._build_internal( # pylint: disable=protected-access; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal; restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps; self._AddRestoreOps(; File ""usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:16472,Security,access,access,16472,"create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session; self._scaffold.finalize(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize; self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default; saver = Saver(sharded=True, allow_empty=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__; self.build(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build; self._build(self._filename, build_save=True, build_restore=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build; self.saver_def = self._builder._build_internal( # pylint: disable=protected-access; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal; restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps; self._AddRestoreOps(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps; all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore; return io_ops.restore_v2(filename_tensor, names, slices, dtypes); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper; op = g._create",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:24343,Security,access,access,24343,"ages/tensorflow/python/training/monitored_session.py"", line 750, in __init__; self._sess = _RecoverableSession(self._coordinated_creator); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__; _WrappedSession.__init__(self, self._create_session()); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session; return self._sess_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session; self.tf_sess = self._session_creator.create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session; self._scaffold.finalize(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize; self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default; saver = Saver(sharded=True, allow_empty=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__; self.build(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build; self._build(self._filename, build_save=True, build_restore=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build; self.saver_def = self._builder._build_internal( # pylint: disable=protected-access; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal; restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps; self._AddRestoreOps(; File ""usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:24982,Security,access,access,24982,"create_session(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session; self._scaffold.finalize(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize; self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default; saver = Saver(sharded=True, allow_empty=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__; self.build(); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build; self._build(self._filename, build_save=True, build_restore=True); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build; self.saver_def = self._builder._build_internal( # pylint: disable=protected-access; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal; restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps; self._AddRestoreOps(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps; all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore; return io_ops.restore_v2(filename_tensor, names, slices, dtypes); File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper; op = g._create",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/539:863,Availability,error,error,863,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: yes . **Describe the issue:**; I am running deep-variant trough a docker installation of the pepper-margin-deepvariant pipeline `kishwars/pepper_deepvariant:r0.8-gpu` on data aligned with minimap2 and data aligned with lra. It is working fine with the minimap2 aligned data, but deepvariant does not produce a final VCF with lra aligned data. . It seems that deep-variant cannot read the base quality score during SNP calling:. ```; 2022-05-26 00:08:16.416812: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores 2e95d959-f3f1-403f-acff-a2bf4f2c12fe: Not found: Could not read base quality scores; 2022-05-26 00:08:16.450548: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (81 vs. 0); Fatal Python error: Aborted; ```; and the job eventually fails:. ```; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /media/euphrasie/DATA/reference_genome/hg38/hg38_GenDev.fa --reads /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:2663,Availability,Error,Error,2663," /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.4; - DeepVariant version: pepper_deepvariant:r0.8-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command: ; ```; 	docker run --ipc=host \; 	--gpus all \; 	-v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \; 	-v ""${BASE}"":""${BASE}"" \; 	-v ""${REF}"":""${REF}"" \; 	-v ""${BAMPATH}"":""${BAMPATH}"" \; 	kishwars/pepper_deepvariant:r0.8-gpu \; 	run_pepper_margin_deepvariant call_variant \; 	-o ""${OUTPUT_DIR}"" \; 	-b ""${BAM}"" \; 	-f ""${REF}"" \; 	-p ""${OUTPUT_PREFIX}"" \; 	-t ${THREADS} \; 	-g \; 	--ont_r9_guppy5_sup; ```. - Error trace: (if applicable); ; [5.1_DeepVariant_SNP.log](https://github.com/google/deepvariant/files/8785347/5.1_DeepVariant_SNP.log). **Does the quick start test work on your system?** yes ; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? no. **Any additional context:** Ultra-long reads",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:164,Deployability,install,installation,164,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: yes . **Describe the issue:**; I am running deep-variant trough a docker installation of the pepper-margin-deepvariant pipeline `kishwars/pepper_deepvariant:r0.8-gpu` on data aligned with minimap2 and data aligned with lra. It is working fine with the minimap2 aligned data, but deepvariant does not produce a final VCF with lra aligned data. . It seems that deep-variant cannot read the base quality score during SNP calling:. ```; 2022-05-26 00:08:16.416812: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores 2e95d959-f3f1-403f-acff-a2bf4f2c12fe: Not found: Could not read base quality scores; 2022-05-26 00:08:16.450548: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (81 vs. 0); Fatal Python error: Aborted; ```; and the job eventually fails:. ```; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /media/euphrasie/DATA/reference_genome/hg38/hg38_GenDev.fa --reads /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:210,Deployability,pipeline,pipeline,210,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: yes . **Describe the issue:**; I am running deep-variant trough a docker installation of the pepper-margin-deepvariant pipeline `kishwars/pepper_deepvariant:r0.8-gpu` on data aligned with minimap2 and data aligned with lra. It is working fine with the minimap2 aligned data, but deepvariant does not produce a final VCF with lra aligned data. . It seems that deep-variant cannot read the base quality score during SNP calling:. ```; 2022-05-26 00:08:16.416812: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores 2e95d959-f3f1-403f-acff-a2bf4f2c12fe: Not found: Could not read base quality scores; 2022-05-26 00:08:16.450548: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (81 vs. 0); Fatal Python error: Aborted; ```; and the job eventually fails:. ```; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /media/euphrasie/DATA/reference_genome/hg38/hg38_GenDev.fa --reads /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:2058,Deployability,Install,Installation,2058," /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.4; - DeepVariant version: pepper_deepvariant:r0.8-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command: ; ```; 	docker run --ipc=host \; 	--gpus all \; 	-v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \; 	-v ""${BASE}"":""${BASE}"" \; 	-v ""${REF}"":""${REF}"" \; 	-v ""${BAMPATH}"":""${BAMPATH}"" \; 	kishwars/pepper_deepvariant:r0.8-gpu \; 	run_pepper_margin_deepvariant call_variant \; 	-o ""${OUTPUT_DIR}"" \; 	-b ""${BAM}"" \; 	-f ""${REF}"" \; 	-p ""${OUTPUT_PREFIX}"" \; 	-t ${THREADS} \; 	-g \; 	--ont_r9_guppy5_sup; ```. - Error trace: (if applicable); ; [5.1_DeepVariant_SNP.log](https://github.com/google/deepvariant/files/8785347/5.1_DeepVariant_SNP.log). **Does the quick start test work on your system?** yes ; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? no. **Any additional context:** Ultra-long reads",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:870,Safety,Abort,Aborted,870,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md**: yes . **Describe the issue:**; I am running deep-variant trough a docker installation of the pepper-margin-deepvariant pipeline `kishwars/pepper_deepvariant:r0.8-gpu` on data aligned with minimap2 and data aligned with lra. It is working fine with the minimap2 aligned data, but deepvariant does not produce a final VCF with lra aligned data. . It seems that deep-variant cannot read the base quality score during SNP calling:. ```; 2022-05-26 00:08:16.416812: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores 2e95d959-f3f1-403f-acff-a2bf4f2c12fe: Not found: Could not read base quality scores; 2022-05-26 00:08:16.450548: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (81 vs. 0); Fatal Python error: Aborted; ```; and the job eventually fails:. ```; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /media/euphrasie/DATA/reference_genome/hg38/hg38_GenDev.fa --reads /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:1939,Testability,log,log,1939," /opt/deepvariant/bin/make_examples --mode calling --ref /media/euphrasie/DATA/reference_genome/hg38/hg38_GenDev.fa --reads /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.4; - DeepVariant version: pepper_deepvariant:r0.8-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command: ; ```; 	docker run --ipc=host \; 	--gpus all \; 	-v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \; 	-v ""${BASE}"":""${BASE}"" \; 	-v ""${REF}"":""${REF}"" \; 	-v ""${BAMPATH}"":""${BAMPATH}"" \; 	kishwars/pepper_deepvariant:r0.8-gpu \; 	run_pepper_margin_deepvariant call_variant \; 	-o ""${OUTPUT_DIR}"" \; 	-b ""${BAM}"" \; 	-f ""${REF}"" \; 	-p ""${OUTPUT_PREFIX}"" \; 	-t ${THREADS} \; 	-g \; 	--ont_r9_guppy5_sup; ```. - Error trace: (if applicable); ; [5.1_DeepVariant_SNP.log](https://github.com/google/deepvariant/files/8785347/5.1_DeepVariant_SNP.log). **Does the quick start test work on your system?** yes ; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-sta",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:2716,Testability,log,log,2716," /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.4; - DeepVariant version: pepper_deepvariant:r0.8-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command: ; ```; 	docker run --ipc=host \; 	--gpus all \; 	-v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \; 	-v ""${BASE}"":""${BASE}"" \; 	-v ""${REF}"":""${REF}"" \; 	-v ""${BAMPATH}"":""${BAMPATH}"" \; 	kishwars/pepper_deepvariant:r0.8-gpu \; 	run_pepper_margin_deepvariant call_variant \; 	-o ""${OUTPUT_DIR}"" \; 	-b ""${BAM}"" \; 	-f ""${REF}"" \; 	-p ""${OUTPUT_PREFIX}"" \; 	-t ${THREADS} \; 	-g \; 	--ont_r9_guppy5_sup; ```. - Error trace: (if applicable); ; [5.1_DeepVariant_SNP.log](https://github.com/google/deepvariant/files/8785347/5.1_DeepVariant_SNP.log). **Does the quick start test work on your system?** yes ; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? no. **Any additional context:** Ultra-long reads",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:2793,Testability,log,log,2793," /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.4; - DeepVariant version: pepper_deepvariant:r0.8-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command: ; ```; 	docker run --ipc=host \; 	--gpus all \; 	-v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \; 	-v ""${BASE}"":""${BASE}"" \; 	-v ""${REF}"":""${REF}"" \; 	-v ""${BAMPATH}"":""${BAMPATH}"" \; 	kishwars/pepper_deepvariant:r0.8-gpu \; 	run_pepper_margin_deepvariant call_variant \; 	-o ""${OUTPUT_DIR}"" \; 	-b ""${BAM}"" \; 	-f ""${REF}"" \; 	-p ""${OUTPUT_PREFIX}"" \; 	-t ${THREADS} \; 	-g \; 	--ont_r9_guppy5_sup; ```. - Error trace: (if applicable); ; [5.1_DeepVariant_SNP.log](https://github.com/google/deepvariant/files/8785347/5.1_DeepVariant_SNP.log). **Does the quick start test work on your system?** yes ; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? no. **Any additional context:** Ultra-long reads",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:2822,Testability,test,test,2822," /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.4; - DeepVariant version: pepper_deepvariant:r0.8-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command: ; ```; 	docker run --ipc=host \; 	--gpus all \; 	-v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \; 	-v ""${BASE}"":""${BASE}"" \; 	-v ""${REF}"":""${REF}"" \; 	-v ""${BAMPATH}"":""${BAMPATH}"" \; 	kishwars/pepper_deepvariant:r0.8-gpu \; 	run_pepper_margin_deepvariant call_variant \; 	-o ""${OUTPUT_DIR}"" \; 	-b ""${BAM}"" \; 	-f ""${REF}"" \; 	-p ""${OUTPUT_PREFIX}"" \; 	-t ${THREADS} \; 	-g \; 	--ont_r9_guppy5_sup; ```. - Error trace: (if applicable); ; [5.1_DeepVariant_SNP.log](https://github.com/google/deepvariant/files/8785347/5.1_DeepVariant_SNP.log). **Does the quick start test work on your system?** yes ; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? no. **Any additional context:** Ultra-long reads",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:2863,Testability,test,test,2863," /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PHASED.PEPPER_MARGIN.haplotagged.bam --examples /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/dv_intermediate_outputs/make_examples.tfrecord@16.gz --add_hp_channel --alt_aligned_pileup none --min_base_quality 1 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 10000 --proposed_variants /media/euphrasie/Alienware_May202/HG002_PAG07506/pmdv/HG002_PAG07506_38_lra/output/intermediate_files/PEPPER_VARIANT_OUTPUT_VARIANT_CALLING_SNPs.vcf.gz --norealign_reads --sample_name Sample --sort_by_haplotypes --variant_caller vcf_candidate_importer --task 7; ```. I checked the lra bam with samtools view and the base quality scores are there.; I wonder what is wrong with my lra aligned reads. The full `5.1_DeepVariant_SNP.log` is attached. **Setup**; - Operating system: Ubuntu 20.04.4; - DeepVariant version: pepper_deepvariant:r0.8-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command: ; ```; 	docker run --ipc=host \; 	--gpus all \; 	-v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \; 	-v ""${BASE}"":""${BASE}"" \; 	-v ""${REF}"":""${REF}"" \; 	-v ""${BAMPATH}"":""${BAMPATH}"" \; 	kishwars/pepper_deepvariant:r0.8-gpu \; 	run_pepper_margin_deepvariant call_variant \; 	-o ""${OUTPUT_DIR}"" \; 	-b ""${BAM}"" \; 	-f ""${REF}"" \; 	-p ""${OUTPUT_PREFIX}"" \; 	-t ${THREADS} \; 	-g \; 	--ont_r9_guppy5_sup; ```. - Error trace: (if applicable); ; [5.1_DeepVariant_SNP.log](https://github.com/google/deepvariant/files/8785347/5.1_DeepVariant_SNP.log). **Does the quick start test work on your system?** yes ; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? no. **Any additional context:** Ultra-long reads",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/541:174,Availability,error,error,174,"I've been trying out the new v1.4 docker image through singularity, but have been running into openvino issues again (#404 and #416, maybe I should just move on :wink:). The error during call_variants is below (and similar to #432); ```; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants; ie_estimator = OpenVINOEstimator(; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__; freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb); File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph; graph_def = optimize_for_inference_lib.optimize_for_inference(; NameError: name 'optimize_for_inference_lib' is not defined; ```. Which comes from [here](https://github.com/google/deepvariant/blob/d2a3aca8691318221e794594ea08e7c88e21359b/deepvariant/openvino_estimator.py#L42). However, after playing around inside the image, the line `from tensorflow.python.tools import optimize_for_inference_lib` works fine as I can successfully run; ```; python -c 'from tensorflow.python.tools import optimize_for_inference_lib'; ```. The real issue is openvino is not installed ; ```; python -c 'from openvino.runtime import Core, AsyncInferQueue, Type'; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'openvino'; ```. which triggers the ImportError and pass statement skipping the import of optimize_for_inference_lib. Not to expose my limited understanding of dockerfiles, but [here](https://hub.docker.com/layers/deepvariant/google/deepvariant/latest/images/sha256-83ce0d6bbe3695bcbaa348b73c48737bdbfaeaea2272b0105dd4bdfa7a804f18?context=explore) it appears that the current latest build has ` ENV DV_OPENVINO_BUILD=0`. I've seen a lot of back and forth with openvino no longer being as helpful, but then there has been ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:1282,Deployability,install,installed,1282,"nd #416, maybe I should just move on :wink:). The error during call_variants is below (and similar to #432); ```; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants; ie_estimator = OpenVINOEstimator(; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__; freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb); File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph; graph_def = optimize_for_inference_lib.optimize_for_inference(; NameError: name 'optimize_for_inference_lib' is not defined; ```. Which comes from [here](https://github.com/google/deepvariant/blob/d2a3aca8691318221e794594ea08e7c88e21359b/deepvariant/openvino_estimator.py#L42). However, after playing around inside the image, the line `from tensorflow.python.tools import optimize_for_inference_lib` works fine as I can successfully run; ```; python -c 'from tensorflow.python.tools import optimize_for_inference_lib'; ```. The real issue is openvino is not installed ; ```; python -c 'from openvino.runtime import Core, AsyncInferQueue, Type'; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'openvino'; ```. which triggers the ImportError and pass statement skipping the import of optimize_for_inference_lib. Not to expose my limited understanding of dockerfiles, but [here](https://hub.docker.com/layers/deepvariant/google/deepvariant/latest/images/sha256-83ce0d6bbe3695bcbaa348b73c48737bdbfaeaea2272b0105dd4bdfa7a804f18?context=explore) it appears that the current latest build has ` ENV DV_OPENVINO_BUILD=0`. I've seen a lot of back and forth with openvino no longer being as helpful, but then there has been some recent updates, so not sure if it is still recommended or deprecated as it has disappeared from some docs. Best,; Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:2013,Deployability,update,updates,2013,"nd #416, maybe I should just move on :wink:). The error during call_variants is below (and similar to #432); ```; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants; ie_estimator = OpenVINOEstimator(; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__; freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb); File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph; graph_def = optimize_for_inference_lib.optimize_for_inference(; NameError: name 'optimize_for_inference_lib' is not defined; ```. Which comes from [here](https://github.com/google/deepvariant/blob/d2a3aca8691318221e794594ea08e7c88e21359b/deepvariant/openvino_estimator.py#L42). However, after playing around inside the image, the line `from tensorflow.python.tools import optimize_for_inference_lib` works fine as I can successfully run; ```; python -c 'from tensorflow.python.tools import optimize_for_inference_lib'; ```. The real issue is openvino is not installed ; ```; python -c 'from openvino.runtime import Core, AsyncInferQueue, Type'; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'openvino'; ```. which triggers the ImportError and pass statement skipping the import of optimize_for_inference_lib. Not to expose my limited understanding of dockerfiles, but [here](https://hub.docker.com/layers/deepvariant/google/deepvariant/latest/images/sha256-83ce0d6bbe3695bcbaa348b73c48737bdbfaeaea2272b0105dd4bdfa7a804f18?context=explore) it appears that the current latest build has ` ENV DV_OPENVINO_BUILD=0`. I've seen a lot of back and forth with openvino no longer being as helpful, but then there has been some recent updates, so not sure if it is still recommended or deprecated as it has disappeared from some docs. Best,; Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:1687,Modifiability,layers,layers,1687,"nd #416, maybe I should just move on :wink:). The error during call_variants is below (and similar to #432); ```; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants; ie_estimator = OpenVINOEstimator(; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__; freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb); File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph; graph_def = optimize_for_inference_lib.optimize_for_inference(; NameError: name 'optimize_for_inference_lib' is not defined; ```. Which comes from [here](https://github.com/google/deepvariant/blob/d2a3aca8691318221e794594ea08e7c88e21359b/deepvariant/openvino_estimator.py#L42). However, after playing around inside the image, the line `from tensorflow.python.tools import optimize_for_inference_lib` works fine as I can successfully run; ```; python -c 'from tensorflow.python.tools import optimize_for_inference_lib'; ```. The real issue is openvino is not installed ; ```; python -c 'from openvino.runtime import Core, AsyncInferQueue, Type'; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'openvino'; ```. which triggers the ImportError and pass statement skipping the import of optimize_for_inference_lib. Not to expose my limited understanding of dockerfiles, but [here](https://hub.docker.com/layers/deepvariant/google/deepvariant/latest/images/sha256-83ce0d6bbe3695bcbaa348b73c48737bdbfaeaea2272b0105dd4bdfa7a804f18?context=explore) it appears that the current latest build has ` ENV DV_OPENVINO_BUILD=0`. I've seen a lot of back and forth with openvino no longer being as helpful, but then there has been some recent updates, so not sure if it is still recommended or deprecated as it has disappeared from some docs. Best,; Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:1605,Security,expose,expose,1605,"nd #416, maybe I should just move on :wink:). The error during call_variants is below (and similar to #432); ```; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 416, in call_variants; ie_estimator = OpenVINOEstimator(; File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 90, in __init__; freeze_graph(model, checkpoint_path, tensor_shape, openvino_model_pb); File ""/tmp/Bazel.runfiles_ya87e4x1/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph; graph_def = optimize_for_inference_lib.optimize_for_inference(; NameError: name 'optimize_for_inference_lib' is not defined; ```. Which comes from [here](https://github.com/google/deepvariant/blob/d2a3aca8691318221e794594ea08e7c88e21359b/deepvariant/openvino_estimator.py#L42). However, after playing around inside the image, the line `from tensorflow.python.tools import optimize_for_inference_lib` works fine as I can successfully run; ```; python -c 'from tensorflow.python.tools import optimize_for_inference_lib'; ```. The real issue is openvino is not installed ; ```; python -c 'from openvino.runtime import Core, AsyncInferQueue, Type'; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'openvino'; ```. which triggers the ImportError and pass statement skipping the import of optimize_for_inference_lib. Not to expose my limited understanding of dockerfiles, but [here](https://hub.docker.com/layers/deepvariant/google/deepvariant/latest/images/sha256-83ce0d6bbe3695bcbaa348b73c48737bdbfaeaea2272b0105dd4bdfa7a804f18?context=explore) it appears that the current latest build has ` ENV DV_OPENVINO_BUILD=0`. I've seen a lot of back and forth with openvino no longer being as helpful, but then there has been some recent updates, so not sure if it is still recommended or deprecated as it has disappeared from some docs. Best,; Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/542:1429,Availability,error,error,1429,"nts (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-23; #SBATCH --time=12:00:00; #SBATCH --mem-per-cpu=128GB. module purge; module load parallel; module load singularity; EXOME_IDs_FILE=Polyposis_Exome_Analysis_JOB27/fastp/All_fastp_input/IDswithoutR1R2_JOB27; HG38_REFERENCE=Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna; PICARDMARKDUPLICATES_SORTEDBAM=Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam; BED_REGIONS=Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed; OUTPUT_VCF=Polyposis_Exome_Analysis_JOB27/deepvariant/vcf/{}PE_output.vcf.gz; OUTPUT_GVCF=Polyposis_Exome_Analysis_JOB27/deepvariant/gvcf/{}PE_output.vcf.gz; INTERMEDIATE_RESULTS=Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$BED_REGIONS \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```. **Error trace:**. ***** Intermediate results will be written to Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate in docker. ****. ***** Running the command:*****; ```; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna"" --reads ""Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/15M11163_L7_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:1461,Availability,error,error,1461,"nts (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-23; #SBATCH --time=12:00:00; #SBATCH --mem-per-cpu=128GB. module purge; module load parallel; module load singularity; EXOME_IDs_FILE=Polyposis_Exome_Analysis_JOB27/fastp/All_fastp_input/IDswithoutR1R2_JOB27; HG38_REFERENCE=Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna; PICARDMARKDUPLICATES_SORTEDBAM=Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam; BED_REGIONS=Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed; OUTPUT_VCF=Polyposis_Exome_Analysis_JOB27/deepvariant/vcf/{}PE_output.vcf.gz; OUTPUT_GVCF=Polyposis_Exome_Analysis_JOB27/deepvariant/gvcf/{}PE_output.vcf.gz; INTERMEDIATE_RESULTS=Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$BED_REGIONS \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```. **Error trace:**. ***** Intermediate results will be written to Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate in docker. ****. ***** Running the command:*****; ```; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna"" --reads ""Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/15M11163_L7_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:1923,Availability,Error,Error,1923,"sis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam; BED_REGIONS=Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed; OUTPUT_VCF=Polyposis_Exome_Analysis_JOB27/deepvariant/vcf/{}PE_output.vcf.gz; OUTPUT_GVCF=Polyposis_Exome_Analysis_JOB27/deepvariant/gvcf/{}PE_output.vcf.gz; INTERMEDIATE_RESULTS=Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$BED_REGIONS \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```. **Error trace:**. ***** Intermediate results will be written to Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate in docker. ****. ***** Running the command:*****; ```; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna"" --reads ""Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/15M11163_L7_PE_markedduplicates.bam"" --examples ""Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate/make_examples.tfrecord@1.gz"" --gvcf ""Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate/gvcf.tfrecord@1.gz"" --regions ""Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed"" --task {}. perl: warning: Setting locale failed.; perl: warning: Pl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:18524,Availability,error,error,18524,"cleus/util/ranges.py"", line 459, in bed_parser; for r in fin.iterate():; File ""/tmp/Bazel.runfiles_pz6djil_/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__; record, not_done = self._raw_next(); File ""/tmp/Bazel.runfiles_pz6djil_/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 102, in _raw_next; not_done = self._cc_iterable.PythonNext(record); ValueError: Unknown: BED record has invalid number of fields; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna --reads Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/15M11163_L7_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed --task 0. real	0m3.367s; user	0m2.683s; sys	0m0.545s; ```. **First lines:**; **First 10 lines of sorted marked duplicate bam is: ** ; BAM?P@HD	VN:1.6	SO:coordinate; @SQ	SN:NC_000001.11	LN:248956422; @SQ	SN:NT_187361.1	LN:175055; @SQ	SN:NT_187362.1	LN:32032; @SQ	SN:NT_187363.1	LN:127682; @SQ	SN:NT_187364.1	LN:66860; @SQ	SN:NT_187365.1	LN:40176; @SQ	SN:NT_187366.1	LN:42210; @SQ	SN:NT_187367.1	LN:176043; @SQ	SN:NT_187368.1	LN:40745. **First line of reference hg38 is:**; >NC_000001.11 Homo sapiens chromosome 1, GRCh38.p13 Primary Assembly. **First line of bed file is:**; NC_000001.11 65509 65625. I have got deepvariant and the above code to work for another dataset with a different bed file used - but I'm not sure why the ValueError: Unknown: BED record has invalid number of fields error is occurring. . Thanks!; Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:55,Deployability,Install,Installation,55,"Hello, ; Operatin system: Linux HPC ; Version: 1.3.0 ; Installation: Singularity ; Data: WES - with Agilent SureSelect DNA Human All ExonV5_hg38 bed file. **Steps to reproduce:**; **Command**; ```; `#!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p compute; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-23; #SBATCH --time=12:00:00; #SBATCH --mem-per-cpu=128GB. module purge; module load parallel; module load singularity; EXOME_IDs_FILE=Polyposis_Exome_Analysis_JOB27/fastp/All_fastp_input/IDswithoutR1R2_JOB27; HG38_REFERENCE=Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna; PICARDMARKDUPLICATES_SORTEDBAM=Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam; BED_REGIONS=Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed; OUTPUT_VCF=Polyposis_Exome_Analysis_JOB27/deepvariant/vcf/{}PE_output.vcf.gz; OUTPUT_GVCF=Polyposis_Exome_Analysis_JOB27/deepvariant/gvcf/{}PE_output.vcf.gz; INTERMEDIATE_RESULTS=Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$BED_REGIONS \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```. **Error trace:**. ***** Intermediate results will be written to Polyposis_Exome_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:3051,Deployability,install,installed,3051,"M11163_L7_PE_output_intermediate in docker. ****. ***** Running the command:*****; ```; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna"" --reads ""Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/15M11163_L7_PE_markedduplicates.bam"" --examples ""Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate/make_examples.tfrecord@1.gz"" --gvcf ""Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate/gvcf.tfrecord@1.gz"" --regions ""Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed"" --task {}. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LANG = ""en_GB.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LANG = ""en_GB.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; I0614 20:20:45.812468 47288495204160 genomics_reader.py:222] Reading Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/15M11163_L7_PE_markedduplicates.bam with NativeSamReader; W0614 20:20:45.812704 47288495204160 make_examples_core.py:276] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument.; I0614 20:20:45.822298 47288495204160 make_examples_core.py:239] Preparing inputs; I0614 20:20:45.836667 47288495204160 genomics_reader.py:222] Reading Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:3315,Deployability,install,installed,3315,"ools_faidx/GRCh38_latest_genomic.fna"" --reads ""Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/15M11163_L7_PE_markedduplicates.bam"" --examples ""Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate/make_examples.tfrecord@1.gz"" --gvcf ""Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/15M11163_L7_PE_output_intermediate/gvcf.tfrecord@1.gz"" --regions ""Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed"" --task {}. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LANG = ""en_GB.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LANG = ""en_GB.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; I0614 20:20:45.812468 47288495204160 genomics_reader.py:222] Reading Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/15M11163_L7_PE_markedduplicates.bam with NativeSamReader; W0614 20:20:45.812704 47288495204160 make_examples_core.py:276] No non-empty sample name found in the input reads. DeepVariant will use default as the sample name. You can also provide a sample name with the --sample_name argument.; I0614 20:20:45.822298 47288495204160 make_examples_core.py:239] Preparing inputs; I0614 20:20:45.836667 47288495204160 genomics_reader.py:222] Reading Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/15M11163_L7_PE_markedduplicates.bam with NativeSamReader; I0614 20:20:46.057183 47288495204160 make_examples_core.py:239] Common contigs are ['NC_000001.11', 'NT_187361.1', 'NT_187362.1', 'NT_187363.1', 'NT_187364.1', 'NT_187365.1', 'NT_187366.1', 'NT_187367.1', 'N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:640,Performance,load,load,640,"Hello, ; Operatin system: Linux HPC ; Version: 1.3.0 ; Installation: Singularity ; Data: WES - with Agilent SureSelect DNA Human All ExonV5_hg38 bed file. **Steps to reproduce:**; **Command**; ```; `#!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p compute; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-23; #SBATCH --time=12:00:00; #SBATCH --mem-per-cpu=128GB. module purge; module load parallel; module load singularity; EXOME_IDs_FILE=Polyposis_Exome_Analysis_JOB27/fastp/All_fastp_input/IDswithoutR1R2_JOB27; HG38_REFERENCE=Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna; PICARDMARKDUPLICATES_SORTEDBAM=Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam; BED_REGIONS=Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed; OUTPUT_VCF=Polyposis_Exome_Analysis_JOB27/deepvariant/vcf/{}PE_output.vcf.gz; OUTPUT_GVCF=Polyposis_Exome_Analysis_JOB27/deepvariant/gvcf/{}PE_output.vcf.gz; INTERMEDIATE_RESULTS=Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$BED_REGIONS \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```. **Error trace:**. ***** Intermediate results will be written to Polyposis_Exome_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:662,Performance,load,load,662,"Hello, ; Operatin system: Linux HPC ; Version: 1.3.0 ; Installation: Singularity ; Data: WES - with Agilent SureSelect DNA Human All ExonV5_hg38 bed file. **Steps to reproduce:**; **Command**; ```; `#!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p compute; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-23; #SBATCH --time=12:00:00; #SBATCH --mem-per-cpu=128GB. module purge; module load parallel; module load singularity; EXOME_IDs_FILE=Polyposis_Exome_Analysis_JOB27/fastp/All_fastp_input/IDswithoutR1R2_JOB27; HG38_REFERENCE=Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna; PICARDMARKDUPLICATES_SORTEDBAM=Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam; BED_REGIONS=Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed; OUTPUT_VCF=Polyposis_Exome_Analysis_JOB27/deepvariant/vcf/{}PE_output.vcf.gz; OUTPUT_GVCF=Polyposis_Exome_Analysis_JOB27/deepvariant/gvcf/{}PE_output.vcf.gz; INTERMEDIATE_RESULTS=Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$BED_REGIONS \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```. **Error trace:**. ***** Intermediate results will be written to Polyposis_Exome_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:213,Testability,log,login,213,"Hello, ; Operatin system: Linux HPC ; Version: 1.3.0 ; Installation: Singularity ; Data: WES - with Agilent SureSelect DNA Human All ExonV5_hg38 bed file. **Steps to reproduce:**; **Command**; ```; `#!/bin/bash --login; #SBATCH -J AmyHouseman_deepvariant; #SBATCH -o %x.stdout.%J.%N; #SBATCH -e %x.stderr.%J.%N; #SBATCH --ntasks=1; #SBATCH --ntasks-per-node=1; #SBATCH -p compute; #SBATCH --account=scw1581; #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL); #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail; #SBATCH --array=1-23; #SBATCH --time=12:00:00; #SBATCH --mem-per-cpu=128GB. module purge; module load parallel; module load singularity; EXOME_IDs_FILE=Polyposis_Exome_Analysis_JOB27/fastp/All_fastp_input/IDswithoutR1R2_JOB27; HG38_REFERENCE=Polyposis_Exome_Analysis_JOB27/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fna; PICARDMARKDUPLICATES_SORTEDBAM=Polyposis_Exome_Analysis_JOB27/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam; BED_REGIONS=Polyposis_Exome_Analysis_JOB27/deepvariant/bed/AgilentSureSelectDNASureSelectXTHumanAllExonV5_hg38_recoded_nocol4.bed; OUTPUT_VCF=Polyposis_Exome_Analysis_JOB27/deepvariant/vcf/{}PE_output.vcf.gz; OUTPUT_GVCF=Polyposis_Exome_Analysis_JOB27/deepvariant/gvcf/{}PE_output.vcf.gz; INTERMEDIATE_RESULTS=Polyposis_Exome_Analysis_JOB27/deepvariant/intermediateresults/{}PE_output_intermediate. # Set bash error trapping to exit on first error.; set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" $EXOME_IDs_FILE | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \; --ref=$HG38_REFERENCE \; --reads=$PICARDMARKDUPLICATES_SORTEDBAM \; --regions=$BED_REGIONS \; --output_vcf=$OUTPUT_VCF \; --output_gvcf=$OUTPUT_GVCF \; --intermediate_results_dir=$INTERMEDIATE_RESULTS""; ```. **Error trace:**. ***** Intermediate results will be written to Polyposis_Exome_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/543:54,Availability,error,error,54,"Hello, . When running DeepVariant I have a persistent error that the .fa and .fai reference genome files don't exist. I have checked that the given path is correct by displaying the files via copying the path given in the error sheet - the paths are correct and I don't have this problem with the input bam files, . I'm running the program via a script on a Linux Ubuntu server. I'm using singularity v3.5.3, which is pre-installed and loaded as a module. The data is Illumina short read which has been mapped with BWA-Kit. The following is the script I'm using is: . # Load modules needed; . /etc/profile.d/modules.sh; module load xxxxx/singularity/3.5.3. # inputs; reference=$2; bam=$1.final.bam; sampleid=$1; outdir=deepvar. # Create output directories; if [ ! -e deepvar ]; then mkdir deepvar; fi; if [ ! -e deepvar/$sampleid ]; then mkdir deepvar/$sampleid; fi. # Set singularity caches; if [ ! -e ${PWD}/.singularity ]; then mkdir ${PWD}/.singularity; fi; export SINGULARITY_TMPDIR=$PWD/.singularity; export SINGULARITY_CACHEDIR=$PWD/.singularity. # Download the image; if [ ! -e deepvariant.sif ]; then singularity build deepvariant.sif docker://google/deepvariant:latest; fi. # Run Deepvariant; singularity exec -p -B ${TMPDIR} -B ${PWD} deepvariant.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${reference} \; --reads=${bam} \; --output_vcf=deepvar/${sampleid}/${sampleid}.vcf.gz \; --output_gvcf=deepvar/${sampleid}/${sampleid}.g.vcf.gz \; --num_shards=${NSLOTS}. I can run the test data on the command line but have the same problem when I use the above script to run it. I've not been able to find a fix, and have tried fixes suggested for similar issues on this site. . Very appreciative of any suggestion for a solve. . [runDV.sh.o21362497.txt](https://github.com/google/deepvariant/files/8985669/runDV.sh.o21362497.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:222,Availability,error,error,222,"Hello, . When running DeepVariant I have a persistent error that the .fa and .fai reference genome files don't exist. I have checked that the given path is correct by displaying the files via copying the path given in the error sheet - the paths are correct and I don't have this problem with the input bam files, . I'm running the program via a script on a Linux Ubuntu server. I'm using singularity v3.5.3, which is pre-installed and loaded as a module. The data is Illumina short read which has been mapped with BWA-Kit. The following is the script I'm using is: . # Load modules needed; . /etc/profile.d/modules.sh; module load xxxxx/singularity/3.5.3. # inputs; reference=$2; bam=$1.final.bam; sampleid=$1; outdir=deepvar. # Create output directories; if [ ! -e deepvar ]; then mkdir deepvar; fi; if [ ! -e deepvar/$sampleid ]; then mkdir deepvar/$sampleid; fi. # Set singularity caches; if [ ! -e ${PWD}/.singularity ]; then mkdir ${PWD}/.singularity; fi; export SINGULARITY_TMPDIR=$PWD/.singularity; export SINGULARITY_CACHEDIR=$PWD/.singularity. # Download the image; if [ ! -e deepvariant.sif ]; then singularity build deepvariant.sif docker://google/deepvariant:latest; fi. # Run Deepvariant; singularity exec -p -B ${TMPDIR} -B ${PWD} deepvariant.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${reference} \; --reads=${bam} \; --output_vcf=deepvar/${sampleid}/${sampleid}.vcf.gz \; --output_gvcf=deepvar/${sampleid}/${sampleid}.g.vcf.gz \; --num_shards=${NSLOTS}. I can run the test data on the command line but have the same problem when I use the above script to run it. I've not been able to find a fix, and have tried fixes suggested for similar issues on this site. . Very appreciative of any suggestion for a solve. . [runDV.sh.o21362497.txt](https://github.com/google/deepvariant/files/8985669/runDV.sh.o21362497.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:1056,Availability,Down,Download,1056,"Hello, . When running DeepVariant I have a persistent error that the .fa and .fai reference genome files don't exist. I have checked that the given path is correct by displaying the files via copying the path given in the error sheet - the paths are correct and I don't have this problem with the input bam files, . I'm running the program via a script on a Linux Ubuntu server. I'm using singularity v3.5.3, which is pre-installed and loaded as a module. The data is Illumina short read which has been mapped with BWA-Kit. The following is the script I'm using is: . # Load modules needed; . /etc/profile.d/modules.sh; module load xxxxx/singularity/3.5.3. # inputs; reference=$2; bam=$1.final.bam; sampleid=$1; outdir=deepvar. # Create output directories; if [ ! -e deepvar ]; then mkdir deepvar; fi; if [ ! -e deepvar/$sampleid ]; then mkdir deepvar/$sampleid; fi. # Set singularity caches; if [ ! -e ${PWD}/.singularity ]; then mkdir ${PWD}/.singularity; fi; export SINGULARITY_TMPDIR=$PWD/.singularity; export SINGULARITY_CACHEDIR=$PWD/.singularity. # Download the image; if [ ! -e deepvariant.sif ]; then singularity build deepvariant.sif docker://google/deepvariant:latest; fi. # Run Deepvariant; singularity exec -p -B ${TMPDIR} -B ${PWD} deepvariant.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${reference} \; --reads=${bam} \; --output_vcf=deepvar/${sampleid}/${sampleid}.vcf.gz \; --output_gvcf=deepvar/${sampleid}/${sampleid}.g.vcf.gz \; --num_shards=${NSLOTS}. I can run the test data on the command line but have the same problem when I use the above script to run it. I've not been able to find a fix, and have tried fixes suggested for similar issues on this site. . Very appreciative of any suggestion for a solve. . [runDV.sh.o21362497.txt](https://github.com/google/deepvariant/files/8985669/runDV.sh.o21362497.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:422,Deployability,install,installed,422,"Hello, . When running DeepVariant I have a persistent error that the .fa and .fai reference genome files don't exist. I have checked that the given path is correct by displaying the files via copying the path given in the error sheet - the paths are correct and I don't have this problem with the input bam files, . I'm running the program via a script on a Linux Ubuntu server. I'm using singularity v3.5.3, which is pre-installed and loaded as a module. The data is Illumina short read which has been mapped with BWA-Kit. The following is the script I'm using is: . # Load modules needed; . /etc/profile.d/modules.sh; module load xxxxx/singularity/3.5.3. # inputs; reference=$2; bam=$1.final.bam; sampleid=$1; outdir=deepvar. # Create output directories; if [ ! -e deepvar ]; then mkdir deepvar; fi; if [ ! -e deepvar/$sampleid ]; then mkdir deepvar/$sampleid; fi. # Set singularity caches; if [ ! -e ${PWD}/.singularity ]; then mkdir ${PWD}/.singularity; fi; export SINGULARITY_TMPDIR=$PWD/.singularity; export SINGULARITY_CACHEDIR=$PWD/.singularity. # Download the image; if [ ! -e deepvariant.sif ]; then singularity build deepvariant.sif docker://google/deepvariant:latest; fi. # Run Deepvariant; singularity exec -p -B ${TMPDIR} -B ${PWD} deepvariant.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${reference} \; --reads=${bam} \; --output_vcf=deepvar/${sampleid}/${sampleid}.vcf.gz \; --output_gvcf=deepvar/${sampleid}/${sampleid}.g.vcf.gz \; --num_shards=${NSLOTS}. I can run the test data on the command line but have the same problem when I use the above script to run it. I've not been able to find a fix, and have tried fixes suggested for similar issues on this site. . Very appreciative of any suggestion for a solve. . [runDV.sh.o21362497.txt](https://github.com/google/deepvariant/files/8985669/runDV.sh.o21362497.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:436,Performance,load,loaded,436,"Hello, . When running DeepVariant I have a persistent error that the .fa and .fai reference genome files don't exist. I have checked that the given path is correct by displaying the files via copying the path given in the error sheet - the paths are correct and I don't have this problem with the input bam files, . I'm running the program via a script on a Linux Ubuntu server. I'm using singularity v3.5.3, which is pre-installed and loaded as a module. The data is Illumina short read which has been mapped with BWA-Kit. The following is the script I'm using is: . # Load modules needed; . /etc/profile.d/modules.sh; module load xxxxx/singularity/3.5.3. # inputs; reference=$2; bam=$1.final.bam; sampleid=$1; outdir=deepvar. # Create output directories; if [ ! -e deepvar ]; then mkdir deepvar; fi; if [ ! -e deepvar/$sampleid ]; then mkdir deepvar/$sampleid; fi. # Set singularity caches; if [ ! -e ${PWD}/.singularity ]; then mkdir ${PWD}/.singularity; fi; export SINGULARITY_TMPDIR=$PWD/.singularity; export SINGULARITY_CACHEDIR=$PWD/.singularity. # Download the image; if [ ! -e deepvariant.sif ]; then singularity build deepvariant.sif docker://google/deepvariant:latest; fi. # Run Deepvariant; singularity exec -p -B ${TMPDIR} -B ${PWD} deepvariant.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${reference} \; --reads=${bam} \; --output_vcf=deepvar/${sampleid}/${sampleid}.vcf.gz \; --output_gvcf=deepvar/${sampleid}/${sampleid}.g.vcf.gz \; --num_shards=${NSLOTS}. I can run the test data on the command line but have the same problem when I use the above script to run it. I've not been able to find a fix, and have tried fixes suggested for similar issues on this site. . Very appreciative of any suggestion for a solve. . [runDV.sh.o21362497.txt](https://github.com/google/deepvariant/files/8985669/runDV.sh.o21362497.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:570,Performance,Load,Load,570,"Hello, . When running DeepVariant I have a persistent error that the .fa and .fai reference genome files don't exist. I have checked that the given path is correct by displaying the files via copying the path given in the error sheet - the paths are correct and I don't have this problem with the input bam files, . I'm running the program via a script on a Linux Ubuntu server. I'm using singularity v3.5.3, which is pre-installed and loaded as a module. The data is Illumina short read which has been mapped with BWA-Kit. The following is the script I'm using is: . # Load modules needed; . /etc/profile.d/modules.sh; module load xxxxx/singularity/3.5.3. # inputs; reference=$2; bam=$1.final.bam; sampleid=$1; outdir=deepvar. # Create output directories; if [ ! -e deepvar ]; then mkdir deepvar; fi; if [ ! -e deepvar/$sampleid ]; then mkdir deepvar/$sampleid; fi. # Set singularity caches; if [ ! -e ${PWD}/.singularity ]; then mkdir ${PWD}/.singularity; fi; export SINGULARITY_TMPDIR=$PWD/.singularity; export SINGULARITY_CACHEDIR=$PWD/.singularity. # Download the image; if [ ! -e deepvariant.sif ]; then singularity build deepvariant.sif docker://google/deepvariant:latest; fi. # Run Deepvariant; singularity exec -p -B ${TMPDIR} -B ${PWD} deepvariant.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${reference} \; --reads=${bam} \; --output_vcf=deepvar/${sampleid}/${sampleid}.vcf.gz \; --output_gvcf=deepvar/${sampleid}/${sampleid}.g.vcf.gz \; --num_shards=${NSLOTS}. I can run the test data on the command line but have the same problem when I use the above script to run it. I've not been able to find a fix, and have tried fixes suggested for similar issues on this site. . Very appreciative of any suggestion for a solve. . [runDV.sh.o21362497.txt](https://github.com/google/deepvariant/files/8985669/runDV.sh.o21362497.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:627,Performance,load,load,627,"Hello, . When running DeepVariant I have a persistent error that the .fa and .fai reference genome files don't exist. I have checked that the given path is correct by displaying the files via copying the path given in the error sheet - the paths are correct and I don't have this problem with the input bam files, . I'm running the program via a script on a Linux Ubuntu server. I'm using singularity v3.5.3, which is pre-installed and loaded as a module. The data is Illumina short read which has been mapped with BWA-Kit. The following is the script I'm using is: . # Load modules needed; . /etc/profile.d/modules.sh; module load xxxxx/singularity/3.5.3. # inputs; reference=$2; bam=$1.final.bam; sampleid=$1; outdir=deepvar. # Create output directories; if [ ! -e deepvar ]; then mkdir deepvar; fi; if [ ! -e deepvar/$sampleid ]; then mkdir deepvar/$sampleid; fi. # Set singularity caches; if [ ! -e ${PWD}/.singularity ]; then mkdir ${PWD}/.singularity; fi; export SINGULARITY_TMPDIR=$PWD/.singularity; export SINGULARITY_CACHEDIR=$PWD/.singularity. # Download the image; if [ ! -e deepvariant.sif ]; then singularity build deepvariant.sif docker://google/deepvariant:latest; fi. # Run Deepvariant; singularity exec -p -B ${TMPDIR} -B ${PWD} deepvariant.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${reference} \; --reads=${bam} \; --output_vcf=deepvar/${sampleid}/${sampleid}.vcf.gz \; --output_gvcf=deepvar/${sampleid}/${sampleid}.g.vcf.gz \; --num_shards=${NSLOTS}. I can run the test data on the command line but have the same problem when I use the above script to run it. I've not been able to find a fix, and have tried fixes suggested for similar issues on this site. . Very appreciative of any suggestion for a solve. . [runDV.sh.o21362497.txt](https://github.com/google/deepvariant/files/8985669/runDV.sh.o21362497.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:885,Performance,cache,caches,885,"Hello, . When running DeepVariant I have a persistent error that the .fa and .fai reference genome files don't exist. I have checked that the given path is correct by displaying the files via copying the path given in the error sheet - the paths are correct and I don't have this problem with the input bam files, . I'm running the program via a script on a Linux Ubuntu server. I'm using singularity v3.5.3, which is pre-installed and loaded as a module. The data is Illumina short read which has been mapped with BWA-Kit. The following is the script I'm using is: . # Load modules needed; . /etc/profile.d/modules.sh; module load xxxxx/singularity/3.5.3. # inputs; reference=$2; bam=$1.final.bam; sampleid=$1; outdir=deepvar. # Create output directories; if [ ! -e deepvar ]; then mkdir deepvar; fi; if [ ! -e deepvar/$sampleid ]; then mkdir deepvar/$sampleid; fi. # Set singularity caches; if [ ! -e ${PWD}/.singularity ]; then mkdir ${PWD}/.singularity; fi; export SINGULARITY_TMPDIR=$PWD/.singularity; export SINGULARITY_CACHEDIR=$PWD/.singularity. # Download the image; if [ ! -e deepvariant.sif ]; then singularity build deepvariant.sif docker://google/deepvariant:latest; fi. # Run Deepvariant; singularity exec -p -B ${TMPDIR} -B ${PWD} deepvariant.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${reference} \; --reads=${bam} \; --output_vcf=deepvar/${sampleid}/${sampleid}.vcf.gz \; --output_gvcf=deepvar/${sampleid}/${sampleid}.g.vcf.gz \; --num_shards=${NSLOTS}. I can run the test data on the command line but have the same problem when I use the above script to run it. I've not been able to find a fix, and have tried fixes suggested for similar issues on this site. . Very appreciative of any suggestion for a solve. . [runDV.sh.o21362497.txt](https://github.com/google/deepvariant/files/8985669/runDV.sh.o21362497.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:1513,Testability,test,test,1513,"Hello, . When running DeepVariant I have a persistent error that the .fa and .fai reference genome files don't exist. I have checked that the given path is correct by displaying the files via copying the path given in the error sheet - the paths are correct and I don't have this problem with the input bam files, . I'm running the program via a script on a Linux Ubuntu server. I'm using singularity v3.5.3, which is pre-installed and loaded as a module. The data is Illumina short read which has been mapped with BWA-Kit. The following is the script I'm using is: . # Load modules needed; . /etc/profile.d/modules.sh; module load xxxxx/singularity/3.5.3. # inputs; reference=$2; bam=$1.final.bam; sampleid=$1; outdir=deepvar. # Create output directories; if [ ! -e deepvar ]; then mkdir deepvar; fi; if [ ! -e deepvar/$sampleid ]; then mkdir deepvar/$sampleid; fi. # Set singularity caches; if [ ! -e ${PWD}/.singularity ]; then mkdir ${PWD}/.singularity; fi; export SINGULARITY_TMPDIR=$PWD/.singularity; export SINGULARITY_CACHEDIR=$PWD/.singularity. # Download the image; if [ ! -e deepvariant.sif ]; then singularity build deepvariant.sif docker://google/deepvariant:latest; fi. # Run Deepvariant; singularity exec -p -B ${TMPDIR} -B ${PWD} deepvariant.sif /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=${reference} \; --reads=${bam} \; --output_vcf=deepvar/${sampleid}/${sampleid}.vcf.gz \; --output_gvcf=deepvar/${sampleid}/${sampleid}.g.vcf.gz \; --num_shards=${NSLOTS}. I can run the test data on the command line but have the same problem when I use the above script to run it. I've not been able to find a fix, and have tried fixes suggested for similar issues on this site. . Very appreciative of any suggestion for a solve. . [runDV.sh.o21362497.txt](https://github.com/google/deepvariant/files/8985669/runDV.sh.o21362497.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/544:276,Availability,error,error,276,"Hello,. Please find below the description of an issue with the flag --output_gvcf_merged in DeepTrio.; Thanks for considering this request; Fred-07. **Describe the issue:**; Running the ""DeepTrio quick start"" commands with the additional flag --output_gvcf_merged produces no error but the""merged"" file is not created.; https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-quick-start.md; All other expected files are created. **Setup**; - Operating system: Linux 3.10.0-1160.71.1.el7.x86_64; - DeepVariant version: 1.4.0; - Installation method: singularity pull from docker, LSF as batch system; - Type of data: ""DeepTrio quick start"" data. **Steps to reproduce:**; - Command: additional flag; `--output_gvcf_merged ""${OUTPUT_DIR}""/ALL.g.vcf.gz`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:534,Deployability,Install,Installation,534,"Hello,. Please find below the description of an issue with the flag --output_gvcf_merged in DeepTrio.; Thanks for considering this request; Fred-07. **Describe the issue:**; Running the ""DeepTrio quick start"" commands with the additional flag --output_gvcf_merged produces no error but the""merged"" file is not created.; https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-quick-start.md; All other expected files are created. **Setup**; - Operating system: Linux 3.10.0-1160.71.1.el7.x86_64; - DeepVariant version: 1.4.0; - Installation method: singularity pull from docker, LSF as batch system; - Type of data: ""DeepTrio quick start"" data. **Steps to reproduce:**; - Command: additional flag; `--output_gvcf_merged ""${OUTPUT_DIR}""/ALL.g.vcf.gz`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/545:379,Availability,avail,available,379,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Issue encountered during running with Docker, thinking it is possibly due to tf not supported by m1 chip, here is the issue. ; The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.; qemu: uncaught target signal 6 (Aborted) - core dumped. **Setup**; - Operating system: MacOs (Mac mini/ m1 chip); - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); The test data from GitHub; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/545
https://github.com/google/deepvariant/issues/545:791,Availability,Error,Error,791,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Issue encountered during running with Docker, thinking it is possibly due to tf not supported by m1 chip, here is the issue. ; The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.; qemu: uncaught target signal 6 (Aborted) - core dumped. **Setup**; - Operating system: MacOs (Mac mini/ m1 chip); - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); The test data from GitHub; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/545
https://github.com/google/deepvariant/issues/545:552,Deployability,Install,Installation,552,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Issue encountered during running with Docker, thinking it is possibly due to tf not supported by m1 chip, here is the issue. ; The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.; qemu: uncaught target signal 6 (Aborted) - core dumped. **Setup**; - Operating system: MacOs (Mac mini/ m1 chip); - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); The test data from GitHub; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/545
https://github.com/google/deepvariant/issues/545:439,Safety,Abort,Aborted,439,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Issue encountered during running with Docker, thinking it is possibly due to tf not supported by m1 chip, here is the issue. ; The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.; qemu: uncaught target signal 6 (Aborted) - core dumped. **Setup**; - Operating system: MacOs (Mac mini/ m1 chip); - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); The test data from GitHub; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/545
https://github.com/google/deepvariant/issues/545:729,Testability,test,test,729,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Issue encountered during running with Docker, thinking it is possibly due to tf not supported by m1 chip, here is the issue. ; The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.; qemu: uncaught target signal 6 (Aborted) - core dumped. **Setup**; - Operating system: MacOs (Mac mini/ m1 chip); - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); The test data from GitHub; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/545
https://github.com/google/deepvariant/issues/545:844,Testability,test,test,844,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Issue encountered during running with Docker, thinking it is possibly due to tf not supported by m1 chip, here is the issue. ; The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.; qemu: uncaught target signal 6 (Aborted) - core dumped. **Setup**; - Operating system: MacOs (Mac mini/ m1 chip); - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); The test data from GitHub; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/545
https://github.com/google/deepvariant/issues/545:880,Testability,test,test,880,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Issue encountered during running with Docker, thinking it is possibly due to tf not supported by m1 chip, here is the issue. ; The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.; qemu: uncaught target signal 6 (Aborted) - core dumped. **Setup**; - Operating system: MacOs (Mac mini/ m1 chip); - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); The test data from GitHub; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/545
https://github.com/google/deepvariant/issues/545:120,Usability,clear,clear,120,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Issue encountered during running with Docker, thinking it is possibly due to tf not supported by m1 chip, here is the issue. ; The TensorFlow library was compiled to use AVX instructions, but these aren't available on your machine.; qemu: uncaught target signal 6 (Aborted) - core dumped. **Setup**; - Operating system: MacOs (Mac mini/ m1 chip); - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); The test data from GitHub; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/545
https://github.com/google/deepvariant/issues/546:399,Deployability,Install,Installation,399,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. When using the singularity-gpu version, the make_examples step will only run sequentially (i.e., one shard processed at a time using only a single CPU) no matter what value I supply to ```--num_shards```. **Setup**; - Operating system: CentOS 7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); WES data from the tutorial. **Steps to reproduce:**; - Command:; ; ```; #!/usr/bin/env bash. INPUT_DIR=""input""; OUTPUT_DIR=""output"". BIN_VERSION=1.4.0; export TMPDIR=""$PWD/tmp_dir"". singularity run \; --nv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}""-gpu \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=reference/GRCh38_no_alt_analysis_set.fasta \; --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions=""${INPUT_DIR}""/idt_capture_novogene.grch38.bed \; --output_vcf=""${OUTPUT_DIR}""/HG003.output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/HG003.output.g.vcf.gz \; --intermediate_results_dir=""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=28; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Yes, though only sequentially. **Any additional context:**. Based on the the documentation and by looking at the code, I _assume_ that the value for ```--num_shards``` is supposed to indicate how many chunks of sequence should be processed in parallel by the ```make_examples``` command, but this does not seem to be working for me. Any suggestions or ideas?. Thanks!; Dave",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1333,Testability,test,test,1333,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. When using the singularity-gpu version, the make_examples step will only run sequentially (i.e., one shard processed at a time using only a single CPU) no matter what value I supply to ```--num_shards```. **Setup**; - Operating system: CentOS 7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); WES data from the tutorial. **Steps to reproduce:**; - Command:; ; ```; #!/usr/bin/env bash. INPUT_DIR=""input""; OUTPUT_DIR=""output"". BIN_VERSION=1.4.0; export TMPDIR=""$PWD/tmp_dir"". singularity run \; --nv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}""-gpu \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=reference/GRCh38_no_alt_analysis_set.fasta \; --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions=""${INPUT_DIR}""/idt_capture_novogene.grch38.bed \; --output_vcf=""${OUTPUT_DIR}""/HG003.output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/HG003.output.g.vcf.gz \; --intermediate_results_dir=""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=28; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Yes, though only sequentially. **Any additional context:**. Based on the the documentation and by looking at the code, I _assume_ that the value for ```--num_shards``` is supposed to indicate how many chunks of sequence should be processed in parallel by the ```make_examples``` command, but this does not seem to be working for me. Any suggestions or ideas?. Thanks!; Dave",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1369,Testability,test,test,1369,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**. When using the singularity-gpu version, the make_examples step will only run sequentially (i.e., one shard processed at a time using only a single CPU) no matter what value I supply to ```--num_shards```. **Setup**; - Operating system: CentOS 7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); WES data from the tutorial. **Steps to reproduce:**; - Command:; ; ```; #!/usr/bin/env bash. INPUT_DIR=""input""; OUTPUT_DIR=""output"". BIN_VERSION=1.4.0; export TMPDIR=""$PWD/tmp_dir"". singularity run \; --nv -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}""-gpu \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=reference/GRCh38_no_alt_analysis_set.fasta \; --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions=""${INPUT_DIR}""/idt_capture_novogene.grch38.bed \; --output_vcf=""${OUTPUT_DIR}""/HG003.output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/HG003.output.g.vcf.gz \; --intermediate_results_dir=""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=28; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Yes, though only sequentially. **Any additional context:**. Based on the the documentation and by looking at the code, I _assume_ that the value for ```--num_shards``` is supposed to indicate how many chunks of sequence should be processed in parallel by the ```make_examples``` command, but this does not seem to be working for me. Any suggestions or ideas?. Thanks!; Dave",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/548:797,Availability,Error,Error,797,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; The same script runs successfully on Chr5 but not on the other 4 chromosomes. **Setup**; - Operating system: Debian GNU/Linux 9; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.):; - Type of data: hybrid of Illumina and HiFi data, the reference is the assembly based on the hifi reads. **Steps to reproduce:**; - Command: singularity run --bind ${PWD} \; /software/deepvariant/deepvariant.img \; /opt/deepvariant/bin/run_deepvariant \; --model_type HYBRID_PACBIO_ILLUMINA \; --ref ragtag.fasta \; --reads hifi_illu.bam \; --intermediate_results_dir ./tmp \; --output_vcf rep1.hifi-illu.Chr1.vcf.gz \; --num_shards 4 \; --regions Chr1_RagTag. - Error trace: Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call; return fn(*args); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn; return self._call_tf_sessionrun(options, feed_dict, fetch_list,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun; return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,; tensorflow.python.framework.errors_impl.DataLossError: inflate() failed with error -3: invalid literal/length code; [[{{node IteratorGetNext}}]]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/548:1413,Availability,error,error,1413,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; The same script runs successfully on Chr5 but not on the other 4 chromosomes. **Setup**; - Operating system: Debian GNU/Linux 9; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.):; - Type of data: hybrid of Illumina and HiFi data, the reference is the assembly based on the hifi reads. **Steps to reproduce:**; - Command: singularity run --bind ${PWD} \; /software/deepvariant/deepvariant.img \; /opt/deepvariant/bin/run_deepvariant \; --model_type HYBRID_PACBIO_ILLUMINA \; --ref ragtag.fasta \; --reads hifi_illu.bam \; --intermediate_results_dir ./tmp \; --output_vcf rep1.hifi-illu.Chr1.vcf.gz \; --num_shards 4 \; --regions Chr1_RagTag. - Error trace: Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call; return fn(*args); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn; return self._call_tf_sessionrun(options, feed_dict, fetch_list,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun; return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,; tensorflow.python.framework.errors_impl.DataLossError: inflate() failed with error -3: invalid literal/length code; [[{{node IteratorGetNext}}]]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/548:278,Deployability,Install,Installation,278,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; The same script runs successfully on Chr5 but not on the other 4 chromosomes. **Setup**; - Operating system: Debian GNU/Linux 9; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.):; - Type of data: hybrid of Illumina and HiFi data, the reference is the assembly based on the hifi reads. **Steps to reproduce:**; - Command: singularity run --bind ${PWD} \; /software/deepvariant/deepvariant.img \; /opt/deepvariant/bin/run_deepvariant \; --model_type HYBRID_PACBIO_ILLUMINA \; --ref ragtag.fasta \; --reads hifi_illu.bam \; --intermediate_results_dir ./tmp \; --output_vcf rep1.hifi-illu.Chr1.vcf.gz \; --num_shards 4 \; --regions Chr1_RagTag. - Error trace: Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1380, in _do_call; return fn(*args); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1363, in _run_fn; return self._call_tf_sessionrun(options, feed_dict, fetch_list,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1456, in _call_tf_sessionrun; return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,; tensorflow.python.framework.errors_impl.DataLossError: inflate() failed with error -3: invalid literal/length code; [[{{node IteratorGetNext}}]]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/550:1557,Availability,Error,Error,1557,"hecked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS Linux release 7.9.2009; - DeepVariant version: deepvariant:0.9.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - Illumina, HG38, standard capture panel. **Steps to reproduce:**; - Command: Snakemake command:; - docker --rm -v {params.input_dir}/:/input -v {params.output_dir}/{params.sample}_DeepVariant:/output -v /data:/data -v {params.bed_dir}:/bed --user $CURRENT_UID google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/{params.sample}.bam --regions=/bed/{params.primary_bed} --output_vcf=/output/{params.sample}_DeepVariant.vcf.gz --output_gvcf=/output/{params.sample}_DeepVariant.gvcf.gz --num_shards=12; - actual command (XXXXX = removed for security purposes) ; - docker --rm -v XXXXXXXXX/gatk_align_metrics_t/:/input -v XXXXXXXXX/deep_variant2/xGENIDTn2_DeepVariant:/output -v /XXXXXXXXX/deepvariant/data:/data -v XXXXXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the quickstart creates files as root. As it's a high performance computing cluster, I am no longer able to delete these files. How do I stop it from creating files as root?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:218,Deployability,release,release,218,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS Linux release 7.9.2009; - DeepVariant version: deepvariant:0.9.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - Illumina, HG38, standard capture panel. **Steps to reproduce:**; - Command: Snakemake command:; - docker --rm -v {params.input_dir}/:/input -v {params.output_dir}/{params.sample}_DeepVariant:/output -v /data:/data -v {params.bed_dir}:/bed --user $CURRENT_UID google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/{params.sample}.bam --regions=/bed/{params.primary_bed} --output_vcf=/output/{params.sample}_DeepVariant.vcf.gz --output_gvcf=/output/{params.sample}_DeepVariant.gvcf.gz --num_shards=12; - actual command (XXXXX = removed for security purposes) ; - docker --rm -v XXXXXXXXX/gatk_align_metrics_t/:/input -v XXXXXXXXX/deep_variant2/xGENIDTn2_DeepVariant:/output -v /XXXXXXXXX/deepvariant/data:/data -v XXXXXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the quickstart creates files as root. As it's a high performance computing cluster, I am no longer able to delete these files. How do I stop it from creating files as root?. **Any additional",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:280,Deployability,Install,Installation,280,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS Linux release 7.9.2009; - DeepVariant version: deepvariant:0.9.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - Illumina, HG38, standard capture panel. **Steps to reproduce:**; - Command: Snakemake command:; - docker --rm -v {params.input_dir}/:/input -v {params.output_dir}/{params.sample}_DeepVariant:/output -v /data:/data -v {params.bed_dir}:/bed --user $CURRENT_UID google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/{params.sample}.bam --regions=/bed/{params.primary_bed} --output_vcf=/output/{params.sample}_DeepVariant.vcf.gz --output_gvcf=/output/{params.sample}_DeepVariant.gvcf.gz --num_shards=12; - actual command (XXXXX = removed for security purposes) ; - docker --rm -v XXXXXXXXX/gatk_align_metrics_t/:/input -v XXXXXXXXX/deep_variant2/xGENIDTn2_DeepVariant:/output -v /XXXXXXXXX/deepvariant/data:/data -v XXXXXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the quickstart creates files as root. As it's a high performance computing cluster, I am no longer able to delete these files. How do I stop it from creating files as root?. **Any additional",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1864,Performance,perform,performance,1864,"hecked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS Linux release 7.9.2009; - DeepVariant version: deepvariant:0.9.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - Illumina, HG38, standard capture panel. **Steps to reproduce:**; - Command: Snakemake command:; - docker --rm -v {params.input_dir}/:/input -v {params.output_dir}/{params.sample}_DeepVariant:/output -v /data:/data -v {params.bed_dir}:/bed --user $CURRENT_UID google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/{params.sample}.bam --regions=/bed/{params.primary_bed} --output_vcf=/output/{params.sample}_DeepVariant.vcf.gz --output_gvcf=/output/{params.sample}_DeepVariant.gvcf.gz --num_shards=12; - actual command (XXXXX = removed for security purposes) ; - docker --rm -v XXXXXXXXX/gatk_align_metrics_t/:/input -v XXXXXXXXX/deep_variant2/xGENIDTn2_DeepVariant:/output -v /XXXXXXXXX/deepvariant/data:/data -v XXXXXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the quickstart creates files as root. As it's a high performance computing cluster, I am no longer able to delete these files. How do I stop it from creating files as root?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1056,Security,secur,security,1056,"hecked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS Linux release 7.9.2009; - DeepVariant version: deepvariant:0.9.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - Illumina, HG38, standard capture panel. **Steps to reproduce:**; - Command: Snakemake command:; - docker --rm -v {params.input_dir}/:/input -v {params.output_dir}/{params.sample}_DeepVariant:/output -v /data:/data -v {params.bed_dir}:/bed --user $CURRENT_UID google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/{params.sample}.bam --regions=/bed/{params.primary_bed} --output_vcf=/output/{params.sample}_DeepVariant.vcf.gz --output_gvcf=/output/{params.sample}_DeepVariant.gvcf.gz --num_shards=12; - actual command (XXXXX = removed for security purposes) ; - docker --rm -v XXXXXXXXX/gatk_align_metrics_t/:/input -v XXXXXXXXX/deep_variant2/xGENIDTn2_DeepVariant:/output -v /XXXXXXXXX/deepvariant/data:/data -v XXXXXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the quickstart creates files as root. As it's a high performance computing cluster, I am no longer able to delete these files. How do I stop it from creating files as root?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1610,Testability,test,test,1610,"hecked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS Linux release 7.9.2009; - DeepVariant version: deepvariant:0.9.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - Illumina, HG38, standard capture panel. **Steps to reproduce:**; - Command: Snakemake command:; - docker --rm -v {params.input_dir}/:/input -v {params.output_dir}/{params.sample}_DeepVariant:/output -v /data:/data -v {params.bed_dir}:/bed --user $CURRENT_UID google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/{params.sample}.bam --regions=/bed/{params.primary_bed} --output_vcf=/output/{params.sample}_DeepVariant.vcf.gz --output_gvcf=/output/{params.sample}_DeepVariant.gvcf.gz --num_shards=12; - actual command (XXXXX = removed for security purposes) ; - docker --rm -v XXXXXXXXX/gatk_align_metrics_t/:/input -v XXXXXXXXX/deep_variant2/xGENIDTn2_DeepVariant:/output -v /XXXXXXXXX/deepvariant/data:/data -v XXXXXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the quickstart creates files as root. As it's a high performance computing cluster, I am no longer able to delete these files. How do I stop it from creating files as root?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1646,Testability,test,test,1646,"hecked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS Linux release 7.9.2009; - DeepVariant version: deepvariant:0.9.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - Illumina, HG38, standard capture panel. **Steps to reproduce:**; - Command: Snakemake command:; - docker --rm -v {params.input_dir}/:/input -v {params.output_dir}/{params.sample}_DeepVariant:/output -v /data:/data -v {params.bed_dir}:/bed --user $CURRENT_UID google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/{params.sample}.bam --regions=/bed/{params.primary_bed} --output_vcf=/output/{params.sample}_DeepVariant.vcf.gz --output_gvcf=/output/{params.sample}_DeepVariant.gvcf.gz --num_shards=12; - actual command (XXXXX = removed for security purposes) ; - docker --rm -v XXXXXXXXX/gatk_align_metrics_t/:/input -v XXXXXXXXX/deep_variant2/xGENIDTn2_DeepVariant:/output -v /XXXXXXXXX/deepvariant/data:/data -v XXXXXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the quickstart creates files as root. As it's a high performance computing cluster, I am no longer able to delete these files. How do I stop it from creating files as root?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:120,Usability,clear,clear,120,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS Linux release 7.9.2009; - DeepVariant version: deepvariant:0.9.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - Illumina, HG38, standard capture panel. **Steps to reproduce:**; - Command: Snakemake command:; - docker --rm -v {params.input_dir}/:/input -v {params.output_dir}/{params.sample}_DeepVariant:/output -v /data:/data -v {params.bed_dir}:/bed --user $CURRENT_UID google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/{params.sample}.bam --regions=/bed/{params.primary_bed} --output_vcf=/output/{params.sample}_DeepVariant.vcf.gz --output_gvcf=/output/{params.sample}_DeepVariant.gvcf.gz --num_shards=12; - actual command (XXXXX = removed for security purposes) ; - docker --rm -v XXXXXXXXX/gatk_align_metrics_t/:/input -v XXXXXXXXX/deep_variant2/xGENIDTn2_DeepVariant:/output -v /XXXXXXXXX/deepvariant/data:/data -v XXXXXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the quickstart creates files as root. As it's a high performance computing cluster, I am no longer able to delete these files. How do I stop it from creating files as root?. **Any additional",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/552:77,Availability,error,error,77,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:175,Availability,avail,available,175,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:676,Availability,Error,Error,676,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:770,Availability,avail,available,770,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:428,Deployability,Install,Installation,428,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:83,Integrability,message,message,83,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:251,Safety,Abort,Aborted,251,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:846,Safety,Abort,Aborted,846,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:948,Testability,test,test,948,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:984,Testability,test,test,984,"When executing ""docker run google/deepvariant:1.4.0"" I receive the following error message:; `The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@""`. **Setup**; - Operating system: Ubuntu 20.04.4 LTS (Focal Fossa); - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: docker run google/deepvariant:1.4.0; - Error trace: The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.; /opt/deepvariant/bin/run_deepvariant: line 2: 7 Aborted (core dumped) python3 -u /opt/deepvariant/bin/run_deepvariant.py ""$@"". **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; CPU information from /proc/cpuinfo; product: Common KVM processor; vendor: Intel Corp.; physical id: 2; bus info: cpu@1; width: 64 bits; capabilities: fpu fpu_exception wp vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx x86-64 constant_tsc nopl xtopology cpuid tsc_known_freq pni cx16 x2apic hypervisor lahf_lm cpuid_fault pti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/555:501,Performance,cache,cached,501,"Is this issue related to TF version?; Any help to fix this issue? Thanks.; ```; (base) [tahmad@gcn35 tests]$ BIN_VERSION=""1.4.0""; (base) [tahmad@gcn35 tests]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref reference/GRCh38_no_alt_analysis_set.fasta; --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --output_vcf deepvariant_output/output.vcf.gz --num_shards $(nproc) --regions chr20; INFO: Using cached SIF image; 2022-08-20 12:59:52.389461: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>; _ll.load_library(_main_dir); File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library; py_tf.TF_LoadLibrary(lib); tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:101,Testability,test,tests,101,"Is this issue related to TF version?; Any help to fix this issue? Thanks.; ```; (base) [tahmad@gcn35 tests]$ BIN_VERSION=""1.4.0""; (base) [tahmad@gcn35 tests]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref reference/GRCh38_no_alt_analysis_set.fasta; --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --output_vcf deepvariant_output/output.vcf.gz --num_shards $(nproc) --regions chr20; INFO: Using cached SIF image; 2022-08-20 12:59:52.389461: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>; _ll.load_library(_main_dir); File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library; py_tf.TF_LoadLibrary(lib); tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:151,Testability,test,tests,151,"Is this issue related to TF version?; Any help to fix this issue? Thanks.; ```; (base) [tahmad@gcn35 tests]$ BIN_VERSION=""1.4.0""; (base) [tahmad@gcn35 tests]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref reference/GRCh38_no_alt_analysis_set.fasta; --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam --output_vcf deepvariant_output/output.vcf.gz --num_shards $(nproc) --regions chr20; INFO: Using cached SIF image; 2022-08-20 12:59:52.389461: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>; _ll.load_library(_main_dir); File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library; py_tf.TF_LoadLibrary(lib); tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/556:134,Availability,Error,Error,134,"Running DeepVariant/DeepTrio 1.4.0 using singularity, based on the provided docker images, with many regions results in a `'parallel: Error: Command line too long (<num> >= 65524)` error. My use case is processing .bam files aligned against `GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz` (containing 2500+ contigs) in parallel. Splitting by contig would result in 2500+ chunks which introduces too much overhead so I group contigs together based on the number of reads. In practice this results in chunks for chr1, ... chr22, chrX, chrY, chrM and one chunk for the other ~2500 contigs. This results in a very long command-line arg for `--regions` and thus the error. What would you think of adding an additional `--regions-file` command-line argument similar to e.g. [bcftools](https://samtools.github.io/bcftools/bcftools.html) which accepts a text file containing one region per line?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:181,Availability,error,error,181,"Running DeepVariant/DeepTrio 1.4.0 using singularity, based on the provided docker images, with many regions results in a `'parallel: Error: Command line too long (<num> >= 65524)` error. My use case is processing .bam files aligned against `GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz` (containing 2500+ contigs) in parallel. Splitting by contig would result in 2500+ chunks which introduces too much overhead so I group contigs together based on the number of reads. In practice this results in chunks for chr1, ... chr22, chrX, chrY, chrM and one chunk for the other ~2500 contigs. This results in a very long command-line arg for `--regions` and thus the error. What would you think of adding an additional `--regions-file` command-line argument similar to e.g. [bcftools](https://samtools.github.io/bcftools/bcftools.html) which accepts a text file containing one region per line?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:666,Availability,error,error,666,"Running DeepVariant/DeepTrio 1.4.0 using singularity, based on the provided docker images, with many regions results in a `'parallel: Error: Command line too long (<num> >= 65524)` error. My use case is processing .bam files aligned against `GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz` (containing 2500+ contigs) in parallel. Splitting by contig would result in 2500+ chunks which introduces too much overhead so I group contigs together based on the number of reads. In practice this results in chunks for chr1, ... chr22, chrX, chrY, chrM and one chunk for the other ~2500 contigs. This results in a very long command-line arg for `--regions` and thus the error. What would you think of adding an additional `--regions-file` command-line argument similar to e.g. [bcftools](https://samtools.github.io/bcftools/bcftools.html) which accepts a text file containing one region per line?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/557:43,Availability,avail,available,43,"Hi,; Is there any additional documentation available on the new single-step phasing method? It would be very helpful to have an overview of how that compares to the previous WhatsHap-based process in terms of how the phasing information is generated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/558:963,Availability,error,error,963,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Running singularity on the test data I get the following:; ```. OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata"". singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \ **Optional.; --num_shards=20 \ **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. My error: . ...; ...; Try --helpfull to get a list of all flags.; deepvariant.sing.sh: line 13: --ref=/mnt/scratch/username/software/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; deepvariant.sing.sh: line 18: make_examples: command not found; deepvariant.sing.sh: line 18: --num_shards=20: command not found. ```; I have checked and these paths and files exist and can be opened used the above links. . **Setup**; - Operating system: linux; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) test data tutorial. **Steps to reproduce:**; - Command: ; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:1703,Availability,Error,Error,1703,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Running singularity on the test data I get the following:; ```. OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata"". singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \ **Optional.; --num_shards=20 \ **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. My error: . ...; ...; Try --helpfull to get a list of all flags.; deepvariant.sing.sh: line 13: --ref=/mnt/scratch/username/software/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; deepvariant.sing.sh: line 18: make_examples: command not found; deepvariant.sing.sh: line 18: --num_shards=20: command not found. ```; I have checked and these paths and files exist and can be opened used the above links. . **Setup**; - Operating system: linux; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) test data tutorial. **Steps to reproduce:**; - Command: ; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:1466,Deployability,Install,Installation,1466,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Running singularity on the test data I get the following:; ```. OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata"". singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \ **Optional.; --num_shards=20 \ **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. My error: . ...; ...; Try --helpfull to get a list of all flags.; deepvariant.sing.sh: line 13: --ref=/mnt/scratch/username/software/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; deepvariant.sing.sh: line 18: make_examples: command not found; deepvariant.sing.sh: line 18: --num_shards=20: command not found. ```; I have checked and these paths and files exist and can be opened used the above links. . **Setup**; - Operating system: linux; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) test data tutorial. **Steps to reproduce:**; - Command: ; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:144,Testability,test,test,144,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Running singularity on the test data I get the following:; ```. OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata"". singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \ **Optional.; --num_shards=20 \ **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. My error: . ...; ...; Try --helpfull to get a list of all flags.; deepvariant.sing.sh: line 13: --ref=/mnt/scratch/username/software/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; deepvariant.sing.sh: line 18: make_examples: command not found; deepvariant.sing.sh: line 18: --num_shards=20: command not found. ```; I have checked and these paths and files exist and can be opened used the above links. . **Setup**; - Operating system: linux; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) test data tutorial. **Steps to reproduce:**; - Command: ; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:249,Testability,test,testdata,249,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Running singularity on the test data I get the following:; ```. OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata"". singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \ **Optional.; --num_shards=20 \ **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. My error: . ...; ...; Try --helpfull to get a list of all flags.; deepvariant.sing.sh: line 13: --ref=/mnt/scratch/username/software/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; deepvariant.sing.sh: line 18: make_examples: command not found; deepvariant.sing.sh: line 18: --num_shards=20: command not found. ```; I have checked and these paths and files exist and can be opened used the above links. . **Setup**; - Operating system: linux; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) test data tutorial. **Steps to reproduce:**; - Command: ; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:1104,Testability,test,testdata,1104,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Running singularity on the test data I get the following:; ```. OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata"". singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \ **Optional.; --num_shards=20 \ **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. My error: . ...; ...; Try --helpfull to get a list of all flags.; deepvariant.sing.sh: line 13: --ref=/mnt/scratch/username/software/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; deepvariant.sing.sh: line 18: make_examples: command not found; deepvariant.sing.sh: line 18: --num_shards=20: command not found. ```; I have checked and these paths and files exist and can be opened used the above links. . **Setup**; - Operating system: linux; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) test data tutorial. **Steps to reproduce:**; - Command: ; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:1643,Testability,test,test,1643,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Running singularity on the test data I get the following:; ```. OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata"". singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \ **Optional.; --num_shards=20 \ **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. My error: . ...; ...; Try --helpfull to get a list of all flags.; deepvariant.sing.sh: line 13: --ref=/mnt/scratch/username/software/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; deepvariant.sing.sh: line 18: make_examples: command not found; deepvariant.sing.sh: line 18: --num_shards=20: command not found. ```; I have checked and these paths and files exist and can be opened used the above links. . **Setup**; - Operating system: linux; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) test data tutorial. **Steps to reproduce:**; - Command: ; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:1756,Testability,test,test,1756,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Running singularity on the test data I get the following:; ```. OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata"". singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \ **Optional.; --num_shards=20 \ **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. My error: . ...; ...; Try --helpfull to get a list of all flags.; deepvariant.sing.sh: line 13: --ref=/mnt/scratch/username/software/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; deepvariant.sing.sh: line 18: make_examples: command not found; deepvariant.sing.sh: line 18: --num_shards=20: command not found. ```; I have checked and these paths and files exist and can be opened used the above links. . **Setup**; - Operating system: linux; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) test data tutorial. **Steps to reproduce:**; - Command: ; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:1792,Testability,test,test,1792,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Running singularity on the test data I get the following:; ```. OUTPUT_DIR=""${PWD}/quickstart-output""; INPUT_DIR=""${PWD}/quickstart-testdata"". singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \ **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \ **Optional.; --num_shards=20 \ **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. My error: . ...; ...; Try --helpfull to get a list of all flags.; deepvariant.sing.sh: line 13: --ref=/mnt/scratch/username/software/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta: No such file or directory; deepvariant.sing.sh: line 18: make_examples: command not found; deepvariant.sing.sh: line 18: --num_shards=20: command not found. ```; I have checked and these paths and files exist and can be opened used the above links. . **Setup**; - Operating system: linux; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) test data tutorial. **Steps to reproduce:**; - Command: ; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/559:66,Availability,error,error,66,"I am trying to run this PacBio use case and encountered following error: ; https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. Any hint/info to solve this issue? . ```; INFO: Using cached SIF image; I0828 10:16:33.630316 22957909862208 run_deepvariant.py:342] Re-using the directory for intermediate results in /scratch-local/tahmad.1459036/tmpcy60f694. ***** Intermediate results will be written to /scratch-local/tahmad.1459036/tmpcy60f694 in docker. ****. ***** Running the command:*****; time seq 0 71 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/scratch-local/tahmad.1459036/tmpcy60f694/make_examples.tfrecord@72.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. 2022-08-28 10:16:41.685530: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.9 SO:coordinate pb:3.0.7; I0828 10:16:41.685937 22858289674048 genomics_reader.py:222] Reading input/HG003.GRCh38.chr20.pFDA_truthv2.bam with NativeSamReader; I0828 10:16:41.693562 22858289674048 make_examples_core.py:243] Task 0/72: Preparing inputs; 2022-08-28 10:16:41.685378: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.9 SO:coordinate pb:3.0.7; I0828 10:16:41.685891 23090607179584 genomics_reader.py:222] Reading input/HG003.GRCh38.chr20.pFDA_truthv2.bam with NativeSamReader; I0828 10:16:41.693572 23090607179584 make_examples_core.py:243] Task 51/72: Preparing inputs; 2022-08-28 10:16:41.910178: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:8636,Modifiability,extend,extend,8636,"tahmad.1459036/Bazel.runfiles_w_myh_2e/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_w_myh_2e/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_w_myh_2e/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main; make_examples_core.make_examples_runner(options); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_w_myh_2e/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795, in make_examples_runner; runtimes) = region_processor.process(region); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_w_myh_2e/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123, in process; reads = self.region_reads(; File ""/scratch-local/tahmad.1459036/Bazel.runfiles_w_myh_2e/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1200, in region_reads; reads.extend(sam_reader.query(region)); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_w_myh_2e/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__; record, not_done = self._raw_next(); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_w_myh_2e/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next; not_done = self._cc_iterable.PythonNext(record); RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed; 2022-08-28 10:16:42.621554: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.9 SO:coordinate pb:3.0.7; I0828 10:16:42.621905 23090607179584 genomics_reader.py:222] Reading input/HG003.GRCh38.chr20.pFDA_truthv2.bam with NativeSamReader; 2022-08-28 10:16:42.705882: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.9 SO:coordinate pb:3.0.7; I0828 10:16:42.706136 23090607179584 genomics_reader.py:222] Reading",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:11357,Modifiability,extend,extend,11357,"tahmad.1459036/Bazel.runfiles_v_r0zvkm/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_v_r0zvkm/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_v_r0zvkm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main; make_examples_core.make_examples_runner(options); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_v_r0zvkm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795, in make_examples_runner; runtimes) = region_processor.process(region); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_v_r0zvkm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123, in process; reads = self.region_reads(; File ""/scratch-local/tahmad.1459036/Bazel.runfiles_v_r0zvkm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1200, in region_reads; reads.extend(sam_reader.query(region)); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_v_r0zvkm/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__; record, not_done = self._raw_next(); File ""/scratch-local/tahmad.1459036/Bazel.runfiles_v_r0zvkm/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next; not_done = self._cc_iterable.PythonNext(record); RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed; 2022-08-28 10:16:42.783298: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.9 SO:coordinate pb:3.0.7; I0828 10:16:42.783742 22429787215680 genomics_reader.py:222] Reading input/HG003.GRCh38.chr20.pFDA_truthv2.bam with NativeSamReader; I0828 10:16:42.790578 22429787215680 make_examples_core.py:243] Task 35/72: Preparing inputs; 2022-08-28 10:16:42.806732: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:222,Performance,cache,cached,222,"I am trying to run this PacBio use case and encountered following error: ; https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. Any hint/info to solve this issue? . ```; INFO: Using cached SIF image; I0828 10:16:33.630316 22957909862208 run_deepvariant.py:342] Re-using the directory for intermediate results in /scratch-local/tahmad.1459036/tmpcy60f694. ***** Intermediate results will be written to /scratch-local/tahmad.1459036/tmpcy60f694 in docker. ****. ***** Running the command:*****; time seq 0 71 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/scratch-local/tahmad.1459036/tmpcy60f694/make_examples.tfrecord@72.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}. 2022-08-28 10:16:41.685530: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.9 SO:coordinate pb:3.0.7; I0828 10:16:41.685937 22858289674048 genomics_reader.py:222] Reading input/HG003.GRCh38.chr20.pFDA_truthv2.bam with NativeSamReader; I0828 10:16:41.693562 22858289674048 make_examples_core.py:243] Task 0/72: Preparing inputs; 2022-08-28 10:16:41.685378: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.9 SO:coordinate pb:3.0.7; I0828 10:16:41.685891 23090607179584 genomics_reader.py:222] Reading input/HG003.GRCh38.chr20.pFDA_truthv2.bam with NativeSamReader; I0828 10:16:41.693572 23090607179584 make_examples_core.py:243] Task 51/72: Preparing inputs; 2022-08-28 10:16:41.910178: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/561:995,Availability,Error,Error,995,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:** After running the code in the deepvariant docker container (quick start), the output vcf files have not been generated.; (A clear and concise description of what the issue is.). **Setup**; - Operating system:Mac OS ; - DeepVariant version: Latest; - Installation method (Docker, built from source, etc.): Docker; - Type of data: Test files(sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: sudoa docker run \-v ""${INPUT_DIR}"":""/input"" \-v ""${INPUT_DIR}"":""/output"" \google/deepvariant:""${BIN_VERSION}"" \/opt/deepvariant/bin/run_deepvariant \--model_type=WES \--ref=/input/ucsc.hg19.chr20.unittest.fasta \--reads=/input/NA12878_S1.chr20.10_10p1mb.bam \--regions ""chr20:10,000,000-10,010,000"" \--output_vcf=/output/output.vcf.gz \--output_gvcf=/output/output.g.vcf.gz \--num_shards=1 \--dry_run=true; - Error trace: No error.(if applicable)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:1011,Availability,error,error,1011,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:** After running the code in the deepvariant docker container (quick start), the output vcf files have not been generated.; (A clear and concise description of what the issue is.). **Setup**; - Operating system:Mac OS ; - DeepVariant version: Latest; - Installation method (Docker, built from source, etc.): Docker; - Type of data: Test files(sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: sudoa docker run \-v ""${INPUT_DIR}"":""/input"" \-v ""${INPUT_DIR}"":""/output"" \google/deepvariant:""${BIN_VERSION}"" \/opt/deepvariant/bin/run_deepvariant \--model_type=WES \--ref=/input/ucsc.hg19.chr20.unittest.fasta \--reads=/input/NA12878_S1.chr20.10_10p1mb.bam \--regions ""chr20:10,000,000-10,010,000"" \--output_vcf=/output/output.vcf.gz \--output_gvcf=/output/output.g.vcf.gz \--num_shards=1 \--dry_run=true; - Error trace: No error.(if applicable)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:366,Deployability,Install,Installation,366,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:** After running the code in the deepvariant docker container (quick start), the output vcf files have not been generated.; (A clear and concise description of what the issue is.). **Setup**; - Operating system:Mac OS ; - DeepVariant version: Latest; - Installation method (Docker, built from source, etc.): Docker; - Type of data: Test files(sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: sudoa docker run \-v ""${INPUT_DIR}"":""/input"" \-v ""${INPUT_DIR}"":""/output"" \google/deepvariant:""${BIN_VERSION}"" \/opt/deepvariant/bin/run_deepvariant \--model_type=WES \--ref=/input/ucsc.hg19.chr20.unittest.fasta \--reads=/input/NA12878_S1.chr20.10_10p1mb.bam \--regions ""chr20:10,000,000-10,010,000"" \--output_vcf=/output/output.vcf.gz \--output_gvcf=/output/output.g.vcf.gz \--num_shards=1 \--dry_run=true; - Error trace: No error.(if applicable)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:445,Testability,Test,Test,445,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:** After running the code in the deepvariant docker container (quick start), the output vcf files have not been generated.; (A clear and concise description of what the issue is.). **Setup**; - Operating system:Mac OS ; - DeepVariant version: Latest; - Installation method (Docker, built from source, etc.): Docker; - Type of data: Test files(sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: sudoa docker run \-v ""${INPUT_DIR}"":""/input"" \-v ""${INPUT_DIR}"":""/output"" \google/deepvariant:""${BIN_VERSION}"" \/opt/deepvariant/bin/run_deepvariant \--model_type=WES \--ref=/input/ucsc.hg19.chr20.unittest.fasta \--reads=/input/NA12878_S1.chr20.10_10p1mb.bam \--regions ""chr20:10,000,000-10,010,000"" \--output_vcf=/output/output.vcf.gz \--output_gvcf=/output/output.g.vcf.gz \--num_shards=1 \--dry_run=true; - Error trace: No error.(if applicable)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:240,Usability,clear,clear,240,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:** After running the code in the deepvariant docker container (quick start), the output vcf files have not been generated.; (A clear and concise description of what the issue is.). **Setup**; - Operating system:Mac OS ; - DeepVariant version: Latest; - Installation method (Docker, built from source, etc.): Docker; - Type of data: Test files(sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: sudoa docker run \-v ""${INPUT_DIR}"":""/input"" \-v ""${INPUT_DIR}"":""/output"" \google/deepvariant:""${BIN_VERSION}"" \/opt/deepvariant/bin/run_deepvariant \--model_type=WES \--ref=/input/ucsc.hg19.chr20.unittest.fasta \--reads=/input/NA12878_S1.chr20.10_10p1mb.bam \--regions ""chr20:10,000,000-10,010,000"" \--output_vcf=/output/output.vcf.gz \--output_gvcf=/output/output.g.vcf.gz \--num_shards=1 \--dry_run=true; - Error trace: No error.(if applicable)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/563:121,Availability,error,error,121,"**Describe the issue:**; I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:; ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**; - Operating system: Linux Ubuntu 20.04; - DeepVariant version: 1.4; - Installation method: Docker; Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**; /opt/deepvariant/bin/run_deepvariant \; --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \; --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \; --customized_model=model.ckpt-364300 \; --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \; --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \; --model_type WGS \; --make_examples_extra_args phase_reads=true,channels=blank \; --regions CHM13v2.chrY \; --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca""; I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:181,Availability,checkpoint,checkpoint,181,"**Describe the issue:**; I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:; ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**; - Operating system: Linux Ubuntu 20.04; - DeepVariant version: 1.4; - Installation method: Docker; Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**; /opt/deepvariant/bin/run_deepvariant \; --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \; --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \; --customized_model=model.ckpt-364300 \; --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \; --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \; --model_type WGS \; --make_examples_extra_args phase_reads=true,channels=blank \; --regions CHM13v2.chrY \; --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca""; I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:214,Availability,checkpoint,checkpoint,214,"**Describe the issue:**; I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:; ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**; - Operating system: Linux Ubuntu 20.04; - DeepVariant version: 1.4; - Installation method: Docker; Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**; /opt/deepvariant/bin/run_deepvariant \; --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \; --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \; --customized_model=model.ckpt-364300 \; --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \; --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \; --model_type WGS \; --make_examples_extra_args phase_reads=true,channels=blank \; --regions CHM13v2.chrY \; --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca""; I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:1395,Availability,checkpoint,checkpoint,1395," being called on the T2T reference fasta. **Steps to reproduce:**; /opt/deepvariant/bin/run_deepvariant \; --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \; --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \; --customized_model=model.ckpt-364300 \; --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \; --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \; --model_type WGS \; --make_examples_extra_args phase_reads=true,channels=blank \; --regions CHM13v2.chrY \; --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca""; I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:2586,Availability,checkpoint,checkpoint,2586,"_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca""; I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**; DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***; An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:2651,Availability,checkpoint,checkpoint,2651,"_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca""; I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**; DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***; An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:2684,Availability,checkpoint,checkpoint,2684,"_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca""; I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7. **Any additional context:**; DeepVariant 1.4 added an additional default channel. This appears to have broken all previously trained models. Using the convenient ""run_deepvariant"" script with the channels=blank options does not result in make_examples generating input examples with only six features. ***Desired Output:***; An option in run_deepvariant that will allow for the creation of example files with the previously standard six input channels.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:350,Deployability,Install,Installation,350,"**Describe the issue:**; I am attempting to use DeepVariant 1.4 with a model trained on DeepVariant 1.3. I encounter the error:; ""ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 6 channels while the examples have 7."". **Setup**; - Operating system: Linux Ubuntu 20.04; - DeepVariant version: 1.4; - Installation method: Docker; Just regular bam files being called on the T2T reference fasta. **Steps to reproduce:**; /opt/deepvariant/bin/run_deepvariant \; --ref=hprc-jun1-mc-chm13-minaf.0.1.fasta \; --reads=HSB340-CHM13v2.chrY.sorted.deduped.cram \; --customized_model=model.ckpt-364300 \; --output_vcf=HSB340-CHM13v2.chrY.deepvariant.vcf.gz \; --output_gvcf=HSB340-CHM13v2.chrY.deepvariant.g.vcf.gz \; --model_type WGS \; --make_examples_extra_args phase_reads=true,channels=blank \; --regions CHM13v2.chrY \; --num_shards=24. parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""hprc-jun1-mc-chm13-minaf.0.1.fasta"" --reads ""HSB340-CHM13v2.chrY.sorted.deduped.cram"" -examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --channels ""blank"" --gvcf ""/tmp/tmpwn2kfxca/gvcf.tfrecord@24.gz"" --phase_reads --regions ""CHM13v2.chrY"" --task {}. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpwn2kfxca/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpwn2kfxca/make_examples.tfrecord@24.gz"" --checkpoint ""model.ckpt-364300"" --openvino_model_dir ""/tmp/tmpwn2kfxca""; I0901 22:59:14.275113 140554215814976 call_variants.py:317] From /tmp/tmpwn2kfxca/make_examples.tfrecord-00000-of-00024.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 18].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_2ucnuw5e/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/564:165,Availability,error,error,165,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes; **Describe the issue:**; At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached; (A clear and concise description of what the issue is.). **Setup**; - Operating system:CentOS7 ; - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: ; - `singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \; --workdir /paedyl01/disk1/yangyxt \; ${image} \; /opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \; --num_shards=${threads} && \; ls -lh ${output_vcf} && \; ls -lh ${output_gvcf}`; - Error trace: (if applicable); - ; - `***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1243,Availability,Error,Error,1243,"ogle/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes; **Describe the issue:**; At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached; (A clear and concise description of what the issue is.). **Setup**; - Operating system:CentOS7 ; - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: ; - `singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \; --workdir /paedyl01/disk1/yangyxt \; ${image} \; /opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \; --num_shards=${threads} && \; ls -lh ${output_vcf} && \; ls -lh ${output_gvcf}`; - Error trace: (if applicable); - ; - `***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:1508,Availability,checkpoint,checkpoint,1508,"/google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: ; - `singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \; --workdir /paedyl01/disk1/yangyxt \; ${image} \; /opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \; --num_shards=${threads} && \; ls -lh ${output_vcf} && \; ls -lh ${output_gvcf}`; - Error trace: (if applicable); - ; - `***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:13078,Availability,Error,Errors,13078,"in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run; result = self._run(None, fetches, feed_dict, options_ptr,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run; results = self._do_run(handle, final_targets, final_fetches,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run; return self._do_call(_run_fn, feeds, fetches, targets, options,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call; raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter; tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached; 	 [[node IteratorGetNext; (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60); ]]. Errors may have originated from an input operation.; Input Source operations connected to node IteratorGetNext:; In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last); >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; >>> tf.compat.v1.app.run(); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; >>> _run_main(main, args); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; >>> sys.exit(main(argv)); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; >>> call_variants(; >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17167,Availability,ERROR,ERROR,17167,"on3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next; flat_ret = gen_dataset_ops.iterator_get_next(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper; op = g._create_op_internal(op_type_name, inputs, dtypes=None,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal; ret = Operation(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__; self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s; user	1063m44.358s; sys	25m21.900s; INFO: Cleaning up image...; ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied; singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; No; **Any additional context:**; Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:417,Deployability,Install,Installation,417,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes; **Describe the issue:**; At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached; (A clear and concise description of what the issue is.). **Setup**; - Operating system:CentOS7 ; - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: ; - `singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \; --workdir /paedyl01/disk1/yangyxt \; ${image} \; /opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \; --num_shards=${threads} && \; ls -lh ${output_vcf} && \; ls -lh ${output_gvcf}`; - Error trace: (if applicable); - ; - `***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:12782,Integrability,message,message,12782,"on.py"", line 1405, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 970, in run; result = self._run(None, fetches, feed_dict, options_ptr,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1193, in _run; results = self._do_run(handle, final_targets, final_fetches,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1373, in _do_run; return self._do_call(_run_fn, feeds, fetches, targets, options,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1399, in _do_call; raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter; tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached; 	 [[node IteratorGetNext; (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:60); ]]. Errors may have originated from an input operation.; Input Source operations connected to node IteratorGetNext:; In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last); >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; >>> tf.compat.v1.app.run(); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; >>> _run_main(main, args); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2860,Modifiability,config,config,2860,"0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance.; WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}; I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:3700,Modifiability,config,config,3700,"20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}; I0826 20:44:28.953302 47737984214848 estimator.py:202] Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}; I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0826 20:44:29.309295 47737984214848 estimator.py:117",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4779,Modifiability,layers,layers,4779,"eed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}; I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:4786,Modifiability,layers,layers,4786,"eed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}; I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5007,Modifiability,layers,layers,5007,"'_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}; I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Done calling model_fn.; I0826 20:44:33.173107 47737984214848 estimator.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5014,Modifiability,layers,layers,5014,"'_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}; I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Done calling model_fn.; I0826 20:44:33.173107 47737984214848 estimator.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5256,Modifiability,layers,layers,5256,"service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}; I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Done calling model_fn.; I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn.; INFO:tensorflow:Graph was finalized.; I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0826 20:44:34.048974 47",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5263,Modifiability,layers,layers,5263,"service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}; I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Done calling model_fn.; I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn.; INFO:tensorflow:Graph was finalized.; I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0826 20:44:34.048974 47",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5484,Modifiability,layers,layers,5484,"I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Done calling model_fn.; I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn.; INFO:tensorflow:Graph was finalized.; I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt; INFO:tensorflow:Running local_init_op.; I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op.; INFO:tensorflow:Done ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5491,Modifiability,layers,layers,5491,"I0826 20:44:28.953605 47737984214848 call_variants.py:446] Writing calls to /paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0826 20:44:29.309295 47737984214848 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Done calling model_fn.; I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn.; INFO:tensorflow:Graph was finalized.; I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt; INFO:tensorflow:Running local_init_op.; I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op.; INFO:tensorflow:Done ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5711,Modifiability,layers,layers,5711,":1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Done calling model_fn.; I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn.; INFO:tensorflow:Graph was finalized.; I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt; INFO:tensorflow:Running local_init_op.; I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op.; INFO:tensorflow:Done running local_init_op.; I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op.; INFO:tensorflow:Reloading EMA...; I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA...; INFO:te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:5718,Modifiability,layers,layers,5718,":1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Done calling model_fn.; I0826 20:44:33.173107 47737984214848 estimator.py:1175] Done calling model_fn.; INFO:tensorflow:Graph was finalized.; I0826 20:44:34.048544 47737984214848 monitored_session.py:247] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0826 20:44:34.048974 47737984214848 saver.py:1399] Restoring parameters from /opt/models/wgs/model.ckpt; INFO:tensorflow:Running local_init_op.; I0826 20:44:34.790676 47737984214848 session_manager.py:531] Running local_init_op.; INFO:tensorflow:Done running local_init_op.; I0826 20:44:34.816158 47737984214848 session_manager.py:534] Done running local_init_op.; INFO:tensorflow:Reloading EMA...; I0826 20:44:35.138201 47737984214848 modeling.py:418] Reloading EMA...; INFO:te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2165,Performance,optimiz,optimized,2165,"cable); - ; - `***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance.; WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2265,Performance,perform,performance-critical,2265,"cable); - ; - `***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance.; WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2542,Performance,Tune,Tune,2542,"aedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance.; WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:2591,Performance,perform,performance,2591,"aedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-08-26 20:44:28.903729: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-08-26 20:44:28.905866: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 3. Tune using inter_op_parallelism_threads for best performance.; WARNING:tensorflow:Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; W0826 20:44:28.952679 47737984214848 estimator.py:1864] Using temporary folder as model directory: /tmp/pbs.1173981.omics/tmpag6nq5vt; INFO:tensorflow:Using config: {'_model_dir': '/tmp/pbs.1173981.omics/tmpag6nq5vt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10954,Safety,predict,prediction,10954,"During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict; preds_evaluated = mon_sess.run(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run; raise six.reraise(*original_exc_info); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run; out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:10972,Safety,predict,predictions,10972,"During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict; preds_evaluated = mon_sess.run(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run; raise six.reraise(*original_exc_info); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run; out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11097,Safety,predict,predict,11097,"l.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict; preds_evaluated = mon_sess.run(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run; raise six.reraise(*original_exc_info); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:11137,Safety,predict,predictions,11137,"t/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict; preds_evaluated = mon_sess.run(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1315, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1420, in run; raise six.reraise(*original_exc_info); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/six_archive/six.py"", line 703, in reraise; raise value; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1405, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1473, in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in run; return self._sess.run(*args, **kwargs); File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14134,Safety,predict,prediction,14134,"ons connected to node IteratorGetNext:; In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last); >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; >>> tf.compat.v1.app.run(); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; >>> _run_main(main, args); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; >>> sys.exit(main(argv)); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; >>> call_variants(; >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; >>> prediction = next(predictions); >>> ; >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; >>> features, input_hooks = self._get_features_from_input_fn(; >>> ; >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; >>> result, _, hooks = estimator_util.parse_input_fn_result(result); >>> ; >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; >>> result = iterator.get_next(); >>> . Original stack trace for 'IteratorGetNext':; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.117",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14152,Safety,predict,predictions,14152,"ons connected to node IteratorGetNext:; In[0] IteratorV2 (defined at /usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py:58). Operation defined at: (most recent call last); >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; >>> tf.compat.v1.app.run(); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; >>> _run_main(main, args); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; >>> sys.exit(main(argv)); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; >>> call_variants(; >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; >>> prediction = next(predictions); >>> ; >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; >>> features, input_hooks = self._get_features_from_input_fn(; >>> ; >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; >>> result, _, hooks = estimator_util.parse_input_fn_result(result); >>> ; >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; >>> result = iterator.get_next(); >>> . Original stack trace for 'IteratorGetNext':; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.117",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:14287,Safety,predict,predict,14287,"il.py:58). Operation defined at: (most recent call last); >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; >>> tf.compat.v1.app.run(); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; >>> _run_main(main, args); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; >>> sys.exit(main(argv)); >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; >>> call_variants(; >>> ; >>> File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; >>> prediction = next(predictions); >>> ; >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; >>> features, input_hooks = self._get_features_from_input_fn(; >>> ; >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; >>> result, _, hooks = estimator_util.parse_input_fn_result(result); >>> ; >>> File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; >>> result = iterator.get_next(); >>> . Original stack trace for 'IteratorGetNext':; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/pbs.1173981.omics/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15683,Safety,predict,prediction,15683,"se_input_fn_result; >>> result = iterator.get_next(); >>> . Original stack trace for 'IteratorGetNext':; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next; flat_ret = gen_dataset_ops.iterator_get_next(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15701,Safety,predict,predictions,15701,"se_input_fn_result; >>> result = iterator.get_next(); >>> . Original stack trace for 'IteratorGetNext':; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next; flat_ret = gen_dataset_ops.iterator_get_next(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:15826,Safety,predict,predict,15826,".runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/pbs.1173981.omics/Bazel.runfiles_pfgek2w5/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next; flat_ret = gen_dataset_ops.iterator_get_next(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper; op = g._create_op_internal(op_type_name, inputs, dtypes=None,; File ""/usr/local/lib/python3.8/dist-packages/tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17439,Testability,test,test,17439,"on3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next; flat_ret = gen_dataset_ops.iterator_get_next(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper; op = g._create_op_internal(op_type_name, inputs, dtypes=None,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal; ret = Operation(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__; self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s; user	1063m44.358s; sys	25m21.900s; INFO: Cleaning up image...; ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied; singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; No; **Any additional context:**; Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:17475,Testability,test,test,17475,"on3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 444, in get_next; flat_ret = gen_dataset_ops.iterator_get_next(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2865, in iterator_get_next; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 744, in _apply_op_helper; op = g._create_op_internal(op_type_name, inputs, dtypes=None,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3697, in _create_op_internal; ret = Operation(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2101, in __init__; self._traceback = tf_stack.extract_stack_for_node(self._c_op). real	41m45.880s; user	1063m44.358s; sys	25m21.900s; INFO: Cleaning up image...; ERROR: failed to delete container image tempDir /tmp/pbs.1173981.omics/rootfs-2853380811: unlinkat /tmp/pbs.1173981.omics/rootfs-2853380811/tmp-rootfs-1307439201/opt/traps/lib/libmodule64.so: permission denied; singularity/3.10.0 is unloaded . - `. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; No; **Any additional context:**; Input BAM file seems valid. Checked with samtools quickcheck -v command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:292,Usability,clear,clear,292,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes; **Describe the issue:**; At the call_variants.py step, running into error that tensorflow.python.framework.errors_impl.DataLossError: truncated record at 19179998357' failed with EOF reached; (A clear and concise description of what the issue is.). **Setup**; - Operating system:CentOS7 ; - DeepVariant version:1.4.0; - Installation method (Docker, built from source, etc.):singularity run with SIF image pulled from docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument: BGI, reference genome: hg19, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: ; - `singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale:/usr/lib/locale,/tmp:/paedyl01/disk1/yangyxt/test_tmp"" \; --workdir /paedyl01/disk1/yangyxt \; ${image} \; /opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \; --num_shards=${threads} && \; ls -lh ${output_vcf} && \; ls -lh ${output_gvcf}`; - Error trace: (if applicable); - ; - `***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/paedyl01/disk1/yangyxt/test_tmp/call_variants_output.tfrecord.gz"" --examples ""/paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord@14.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/paedyl01/disk1/yangyxt/test_tmp"". I0826 20:44:28.894064 47737984214848 call_variants.py:317] From /paedyl01/disk1/yangyxt/test_tmp/make_examples.tfrecord-00000-of-00014.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I0826 20:44:28.898550 47737984214848 call_variants.py:317] From /opt/models/wgs/model.ckpt.example_info.json: Shape of input examples: [100, 221, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/565:69,Availability,avail,availability,69,"Hi,. I am wondering if the DV team has done an evaluation on how the availability of BAQ (the `BQ:Z:...` tag) affects the quality of calls generated from HiFi reads. Thank you!; Steve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/566:696,Availability,Error,Error,696,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): docker pull ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**; - Command: ; - singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \; --env LANG=""en_US.UTF-8"" \; --env LC_ALL=""C"" \; --env LANGUAGE=""en_US.UTF-8"" \; --env LC_CTYPE=""UTF-8"" \; ...... - Error trace: (if applicable); ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:287,Deployability,Install,Installation,287,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): docker pull ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**; - Command: ; - singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \; --env LANG=""en_US.UTF-8"" \; --env LC_ALL=""C"" \; --env LANGUAGE=""en_US.UTF-8"" \; --env LC_CTYPE=""UTF-8"" \; ...... - Error trace: (if applicable); ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:142,Testability,log,log,142,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): docker pull ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**; - Command: ; - singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \; --env LANG=""en_US.UTF-8"" \; --env LC_ALL=""C"" \; --env LANGUAGE=""en_US.UTF-8"" \; --env LC_CTYPE=""UTF-8"" \; ...... - Error trace: (if applicable); ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:862,Testability,test,test,862,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): docker pull ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**; - Command: ; - singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \; --env LANG=""en_US.UTF-8"" \; --env LC_ALL=""C"" \; --env LANGUAGE=""en_US.UTF-8"" \; --env LC_CTYPE=""UTF-8"" \; ...... - Error trace: (if applicable); ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:898,Testability,test,test,898,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; According to the running log: the setlocale failed when trying to change LC_ALL to 'en_US.UTF-8'. **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): docker pull ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) DNA seq. **Steps to reproduce:**; - Command: ; - singularity run \; -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \; --env LANG=""en_US.UTF-8"" \; --env LC_ALL=""C"" \; --env LANGUAGE=""en_US.UTF-8"" \; --env LC_CTYPE=""UTF-8"" \; ...... - Error trace: (if applicable); ![image](https://user-images.githubusercontent.com/40780228/190950415-84faaa5d-7371-42a7-9e13-f6caf53a3dea.png). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/567:273,Availability,error,error,273,"Hello!; I've tried to run DeepVariant1.1.0 on hundreds of WES data. However, I mistakenly specified the ""model_type"" parameter as ""PACBIO"" instead of ""WES"".The program generated gvcf files normally and the gvcf files can be merged by GLnexus.; I wonder how serious is this error? Do I have to run the program again?; Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/568:922,Availability,Avail,Available,922,"Describe the issue:**; I previously used the following PopVCF [model.ckpt](https://console.cloud.google.com/storage/browser/brain-genomics-public/research/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:; ```; --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets.; (default: 'false'); --[no]add_hp_channel: If true, add another channel to represent HP tags per read.; (default: 'false'); --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size; ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:; ```; --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls.; ```. If so, do they include one additional channel or permutations of multiple channels?. If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**; - Operating system:; - DeepVariant version: v1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WGS. **Steps to reproduce:**; - Command: ; ```; time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1139,Availability,avail,available,1139,"earch/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:; ```; --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets.; (default: 'false'); --[no]add_hp_channel: If true, add another channel to represent HP tags per read.; (default: 'false'); --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size; ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:; ```; --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls.; ```. If so, do they include one additional channel or permutations of multiple channels?. If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**; - Operating system:; - DeepVariant version: v1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WGS. **Steps to reproduce:**; - Command: ; ```; time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif ; /opt/deepvariant/bin/run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1199,Availability,checkpoint,checkpoint,1199,"earch/allele_frequency/pretrained_model_WGS;tab=objects?pli=1&prefix=&forceOnObjectsSortingFiltering=false) with `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:; ```; --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets.; (default: 'false'); --[no]add_hp_channel: If true, add another channel to represent HP tags per read.; (default: 'false'); --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size; ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:; ```; --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls.; ```. If so, do they include one additional channel or permutations of multiple channels?. If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**; - Operating system:; - DeepVariant version: v1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WGS. **Steps to reproduce:**; - Command: ; ```; time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif ; /opt/deepvariant/bin/run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1250,Availability,checkpoint,checkpoint,1250,"h `run_deepvariant` v.1.1 while including a PopVCF channel during `make_examples`. However, that model does not include a channel for `insert_size` as their work predates v1.4. . With the default extra channel for `'insert_size'` in v1.4, and `make_examples` having numerous options to include additional channels:; ```; --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets.; (default: 'false'); --[no]add_hp_channel: If true, add another channel to represent HP tags per read.; (default: 'false'); --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size; ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:; ```; --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls.; ```. If so, do they include one additional channel or permutations of multiple channels?. If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**; - Operating system:; - DeepVariant version: v1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WGS. **Steps to reproduce:**; - Command: ; ```; time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif ; /opt/deepvariant/bin/run_deepvariant ; --model_type=WGS; --ref='/ref_dir/reference.fa' ; --reads='/bam_dir/id.bam' ; --output_vcf='/ou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1503,Availability,checkpoint,checkpoint,1503,"` having numerous options to include additional channels:; ```; --[no]use_allele_frequency: If True, add another channel for pileup images to represent allele frequency information gathered from population call sets.; (default: 'false'); --[no]add_hp_channel: If true, add another channel to represent HP tags per read.; (default: 'false'); --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size; ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:; ```; --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls.; ```. If so, do they include one additional channel or permutations of multiple channels?. If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**; - Operating system:; - DeepVariant version: v1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WGS. **Steps to reproduce:**; - Command: ; ```; time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif ; /opt/deepvariant/bin/run_deepvariant ; --model_type=WGS; --ref='/ref_dir/reference.fa' ; --reads='/bam_dir/id.bam' ; --output_vcf='/out_dir/test1.vcf.gz' ; --intermediate_results_dir='/out_dir/tmp/test1/' ; --num_shards='39' ; --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" ; --regions=/region_dir/regions_to_test.bed ; ```; - Error ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2513,Availability,Error,Error,2513,"nclude both `insert_size` and `allele_frequency` with v1.4. **Setup**; - Operating system:; - DeepVariant version: v1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WGS. **Steps to reproduce:**; - Command: ; ```; time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif ; /opt/deepvariant/bin/run_deepvariant ; --model_type=WGS; --ref='/ref_dir/reference.fa' ; --reads='/bam_dir/id.bam' ; --output_vcf='/out_dir/test1.vcf.gz' ; --intermediate_results_dir='/out_dir/tmp/test1/' ; --num_shards='39' ; --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" ; --regions=/region_dir/regions_to_test.bed ; ```; - Error trace: (if applicable); ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/ap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2748,Availability,checkpoint,checkpoint,2748,": Singularity; - Type of data: WGS. **Steps to reproduce:**; - Command: ; ```; time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif ; /opt/deepvariant/bin/run_deepvariant ; --model_type=WGS; --ref='/ref_dir/reference.fa' ; --reads='/bam_dir/id.bam' ; --output_vcf='/out_dir/test1.vcf.gz' ; --intermediate_results_dir='/out_dir/tmp/test1/' ; --num_shards='39' ; --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" ; --regions=/region_dir/regions_to_test.bed ; ```; - Error trace: (if applicable); ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:3955,Availability,checkpoint,checkpoint,3955,"ference.fa' ; --reads='/bam_dir/id.bam' ; --output_vcf='/out_dir/test1.vcf.gz' ; --intermediate_results_dir='/out_dir/tmp/test1/' ; --num_shards='39' ; --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" ; --regions=/region_dir/regions_to_test.bed ; ```; - Error trace: (if applicable); ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s; user 0m4.066s; sys 0m4.174s. real 77m45.059s; user 2960m49.979s; sys 39m40.911s```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4020,Availability,checkpoint,checkpoint,4020,"ference.fa' ; --reads='/bam_dir/id.bam' ; --output_vcf='/out_dir/test1.vcf.gz' ; --intermediate_results_dir='/out_dir/tmp/test1/' ; --num_shards='39' ; --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" ; --regions=/region_dir/regions_to_test.bed ; ```; - Error trace: (if applicable); ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s; user 0m4.066s; sys 0m4.174s. real 77m45.059s; user 2960m49.979s; sys 39m40.911s```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4053,Availability,checkpoint,checkpoint,4053,"ference.fa' ; --reads='/bam_dir/id.bam' ; --output_vcf='/out_dir/test1.vcf.gz' ; --intermediate_results_dir='/out_dir/tmp/test1/' ; --num_shards='39' ; --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" ; --regions=/region_dir/regions_to_test.bed ; ```; - Error trace: (if applicable); ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfrecord@39.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --openvino_model_dir ""/out_dir/tmp/test1/"". I0919 17:19:47.185331 46912500266816 call_variants.py:317] From /out_dir/tmp/test1/make_examples.tfrecord-00000-of-00039.gz.example_info.json: Shape of input examples: [100, 221, 8], Channels of input examples: [1, 2, 3, 4, 5, 6, 8, 19].; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_l3__pco1/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. real 0m3.217s; user 0m4.066s; sys 0m4.174s. real 77m45.059s; user 2960m49.979s; sys 39m40.911s```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1709,Deployability,Install,Installation,1709,"ts.; (default: 'false'); --[no]add_hp_channel: If true, add another channel to represent HP tags per read.; (default: 'false'); --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size; ```. Are there `model-ckpt` files for these channel options available somewhere to provide `call_variants` via:; ```; --checkpoint: Required. Path to the TensorFlow model checkpoint to use to evaluate candidate variant calls.; ```. If so, do they include one additional channel or permutations of multiple channels?. If not, is there an alternative way to have `run_deepvariant` use different channels than what the default checkpoint contains during `call_variants`? For example, I am currently unable to include both `insert_size` and `allele_frequency` with v1.4. **Setup**; - Operating system:; - DeepVariant version: v1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: WGS. **Steps to reproduce:**; - Command: ; ```; time singularity run -B '/usr/lib/locale/:/usr/lib/locale/,/path/to/region_files/:/region_dir/,/path/to/container/deep-variant/:/run_dir/,/path/to/output/:/path/to/reference_genome/:/ref_dir/,/path/to/bam_files/:/bam_dir/,/path/to/population_vcf/:/popVCF_dir/' . deepvariant_1.4.0.sif ; /opt/deepvariant/bin/run_deepvariant ; --model_type=WGS; --ref='/ref_dir/reference.fa' ; --reads='/bam_dir/id.bam' ; --output_vcf='/out_dir/test1.vcf.gz' ; --intermediate_results_dir='/out_dir/tmp/test1/' ; --num_shards='39' ; --make_examples_extra_args=""use_allele_frequency=true,population_vcfs=/popVCF_dir/UMAG1.POP.FREQ.vcf.gz"" ; --regions=/region_dir/regions_to_test.bed ; ```; - Error trace: (if applicable); ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/out_dir/tmp/test1/call_variants_output.tfrecord.gz"" --examples ""/out_dir/tmp/test1/make_examples.tfr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/571:621,Deployability,Install,Installation,621,"I was planning to analyse runs of homozygosity in a genome assembly with Plink using DeepVariant for the variant calling. Unfortunately Plink needs basepair resolution in the input vcf file, e.g. a vcf/gvcf file that includes homozygous reference calls as well. I tried different options in DeepVariant but there seems to be no option for basepair resolution. GATK has the option to output this (-ERC BP_RESOLUTION) but since DeepVariant is more accurate and much faster I was wondering if would it be possible to add such a feature in the future? . **Setup**; - Operating system: CentOS; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Genome assembly plus PacBio HIFI or Illumina WGS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/573:326,Availability,Error,Error,326,"the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**; - Ubuntu 20.04:; - DeepVariant version - 1.4.0:; - Installation method - Conda; - Type of data - sequencing, illumina. **Steps to reproduce:**; - Command:; dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>; import numpy as np; ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:59,Deployability,install,installed,59,"the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**; - Ubuntu 20.04:; - DeepVariant version - 1.4.0:; - Installation method - Conda; - Type of data - sequencing, illumina. **Steps to reproduce:**; - Command:; dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>; import numpy as np; ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:144,Deployability,Install,Installation,144,"the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**; - Ubuntu 20.04:; - DeepVariant version - 1.4.0:; - Installation method - Conda; - Type of data - sequencing, illumina. **Steps to reproduce:**; - Command:; dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>; import numpy as np; ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:585,Deployability,install,installed,585,"the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**; - Ubuntu 20.04:; - DeepVariant version - 1.4.0:; - Installation method - Conda; - Type of data - sequencing, illumina. **Steps to reproduce:**; - Command:; dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>; import numpy as np; ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:17,Integrability,wrap,wrapper,17,"the deep variant wrapper dv_call_variants.py crushing when installed using conda. **Setup**; - Ubuntu 20.04:; - DeepVariant version - 1.4.0:; - Installation method - Conda; - Type of data - sequencing, illumina. **Steps to reproduce:**; - Command:; dv_call_variants.py --outfile OUTFILE --examples EXAMPLES --sample SAMPLE. - Error trace: (if applicable) ; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_zviaa5zy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 39, in <module>; import numpy as np; ModuleNotFoundError: No module named 'numpy'. numpy installed in enviroment",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/pull/576:78,Deployability,release,release,78,* DeepVariant Logo.; * DeepVariant RNA-seq case study.; * DeepVariant RNA-seq release.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/576
https://github.com/google/deepvariant/pull/576:14,Testability,Log,Logo,14,* DeepVariant Logo.; * DeepVariant RNA-seq case study.; * DeepVariant RNA-seq release.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/576
https://github.com/google/deepvariant/issues/578:1378,Availability,Error,Error,1378,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**; I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**; - Operating system: centOS 7; - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now); - Installation method (Docker, built from source, etc.): converted docker image to singularity image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**; - Command: ; ```; singularity exec ~/virtual_server/deepvariant.sif \; bash -c ""; /opt/deepvariant/bin/run_deepvariant \; --model_type=""HYBRID_PACBIO_ILLUMINA"" \; --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \; --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \; --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \; --num_shards=$SLURM_CPUS_PER_TASK \; --logging_dir=""${OUTPUT_DIR}""/logs \; --intermediate_results_dir=""${OUTPUT_DIR}""/tmp""; ```; - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**; [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:555,Deployability,Install,Installation,555,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**; I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**; - Operating system: centOS 7; - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now); - Installation method (Docker, built from source, etc.): converted docker image to singularity image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**; - Command: ; ```; singularity exec ~/virtual_server/deepvariant.sif \; bash -c ""; /opt/deepvariant/bin/run_deepvariant \; --model_type=""HYBRID_PACBIO_ILLUMINA"" \; --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \; --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \; --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \; --num_shards=$SLURM_CPUS_PER_TASK \; --logging_dir=""${OUTPUT_DIR}""/logs \; --intermediate_results_dir=""${OUTPUT_DIR}""/tmp""; ```; - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**; [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1314,Testability,log,logs,1314,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**; I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**; - Operating system: centOS 7; - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now); - Installation method (Docker, built from source, etc.): converted docker image to singularity image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**; - Command: ; ```; singularity exec ~/virtual_server/deepvariant.sif \; bash -c ""; /opt/deepvariant/bin/run_deepvariant \; --model_type=""HYBRID_PACBIO_ILLUMINA"" \; --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \; --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \; --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \; --num_shards=$SLURM_CPUS_PER_TASK \; --logging_dir=""${OUTPUT_DIR}""/logs \; --intermediate_results_dir=""${OUTPUT_DIR}""/tmp""; ```; - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**; [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1467,Testability,test,test,1467,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**; I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**; - Operating system: centOS 7; - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now); - Installation method (Docker, built from source, etc.): converted docker image to singularity image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**; - Command: ; ```; singularity exec ~/virtual_server/deepvariant.sif \; bash -c ""; /opt/deepvariant/bin/run_deepvariant \; --model_type=""HYBRID_PACBIO_ILLUMINA"" \; --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \; --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \; --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \; --num_shards=$SLURM_CPUS_PER_TASK \; --logging_dir=""${OUTPUT_DIR}""/logs \; --intermediate_results_dir=""${OUTPUT_DIR}""/tmp""; ```; - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**; [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:1503,Testability,test,test,1503,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: yes. **Describe the issue:**; I am running DeepVariant on a custom genome assembly using a hybrid of pacbio hifi and illumina short reads and it's been running for 17days. I wonder if something is wrong and is there a way to speed thing up? I am already using 30 shards. **Setup**; - Operating system: centOS 7; - DeepVariant version: 1.4.0 and 1.1.0 (tried version 1.1.0 been running for 17 days then I'm trying the 1.4.0 and it's been running for 3 days now); - Installation method (Docker, built from source, etc.): converted docker image to singularity image; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am using custom genome. **Steps to reproduce:**; - Command: ; ```; singularity exec ~/virtual_server/deepvariant.sif \; bash -c ""; /opt/deepvariant/bin/run_deepvariant \; --model_type=""HYBRID_PACBIO_ILLUMINA"" \; --ref=""${REF_DIR}""/scaffolds_FINAL.fasta \; --reads=""${INPUT_DIR}""/hybrid_hifi_Kapa_combined.bam \; --output_vcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/A673.HiFi.Kapa.scaffolds_FINAL_hap1.deepvar.g.vcf.gz \; --num_shards=$SLURM_CPUS_PER_TASK \; --logging_dir=""${OUTPUT_DIR}""/logs \; --intermediate_results_dir=""${OUTPUT_DIR}""/tmp""; ```; - Error trace: (if applicable) attached r_deepvariant_hybrid_2.txt. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? I was able to run quick start. I was also able to run DeepVariant on the same singularity system with pacbio HiFi reads only, using human reference genome hg19. **Any additional context:**; [r_deepvariant_hybrid_2_662510.txt](https://github.com/google/deepvariant/files/9853335/r_deepvariant_hybrid_2_662510.txt)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/580:246,Availability,error,error,246,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:338,Availability,error,error,338,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:420,Availability,error,error,420,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:276,Deployability,install,installing,276,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:533,Deployability,install,install,533,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:646,Deployability,Install,Installation,646,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:426,Integrability,message,message,426,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1372,Modifiability,sandbox,sandbox,1372,"uf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>; from tensorflow.core.framework import function_pb2; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>; from google.protobuf import descriptor as _descriptor; File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>; from google.protobuf.internal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:840,Performance,cache,cache,840,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:708,Testability,test,test,708,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1372,Testability,sandbox,sandbox,1372,"uf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>; from tensorflow.core.framework import function_pb2; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>; from google.protobuf import descriptor as _descriptor; File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>; from google.protobuf.internal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:154,Usability,guid,guide,154,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes. **Describe the issue:**; I was following the quick start guide for running singularity on a gpu node. Initially, I encounter the dynamic cast failed error similar to #559 . After installing the google-nucleus package, I encountered this new error about protobuf package. I tried protobuf version 3.20.3 and 4.21.9, but the error message is the same. In order to run DeepVariant successfully, what additional packages (version) should I install besides cloning the singularity image?. **Setup**; - Operating system: ; - DeepVariant version: 1.4.0; - Installation method: singularity; - Type of data: quick start test; ; **Steps to reproduce:**; ; ```; SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/cache singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; deepvariant_1.4.0-gpu.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1. INFO: Converting SIF file to temporary sandbox...; WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/581:13940,Availability,error,error,13940,"mics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz; I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds; I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz; I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449; Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15513,Availability,error,error,15513,"runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403; Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:17086,Availability,error,error,17086,"runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287; Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18659,Availability,error,error,18659,"runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101; Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20232,Availability,error,error,20232,"runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106; Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21805,Availability,error,error,21805,"runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165; Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23378,Availability,error,error,23378,"runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899; Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24951,Availability,error,error,24951,"runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350; Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:13947,Safety,Abort,Aborted,13947,"mics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; I1029 09:19:03.708104 139762738964288 make_examples_core.py:243] Task 2/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00002-of-00008.gz; I1029 09:19:03.708200 139762738964288 make_examples_core.py:243] Task 2/8: Overhead for preparing inputs: 2 seconds; I1029 09:19:04.060117 140039545739072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader; I1029 09:19:04.129533 140039545739072 make_examples_core.py:243] Task 6/8: Writing examples to output/intermediate_results_dir/make_examples.tfrecord-00006-of-00008.gz; I1029 09:19:04.129874 140039545739072 make_examples_core.py:243] Task 6/8: Overhead for preparing inputs: 2 seconds; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449; Fatal Python error: Aborted. Current thread 0x00007f543a64b740 (most recent call first):; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:15520,Safety,Abort,Aborted,15520,"runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_r72dsu_k/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.586897: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277206 end: 277403; Fatal Python error: Aborted. Current thread 0x00007f6797491740 (most recent call first):; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:17093,Safety,Abort,Aborted,17093,"runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_kpkzlrts/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.544568: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 271187 end: 271287; Fatal Python error: Aborted. Current thread 0x00007f4836ae3740 (most recent call first):; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:18666,Safety,Abort,Aborted,18666,"runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_amrrdv68/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.559681: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 283943 end: 284101; Fatal Python error: Aborted. Current thread 0x00007f84f61df740 (most recent call first):; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20239,Safety,Abort,Aborted,20239,"runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_hpi9dr8x/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.554670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 275948 end: 276106; Fatal Python error: Aborted. Current thread 0x00007f9594dae740 (most recent call first):; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:21812,Safety,Abort,Aborted,21812,"runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_cf7f414f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.553988: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 277024 end: 277165; Fatal Python error: Aborted. Current thread 0x00007f1c6e524740 (most recent call first):; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:23385,Safety,Abort,Aborted,23385,"runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_brb4vywu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.521271: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 276773 end: 276899; Fatal Python error: Aborted. Current thread 0x00007f1d0c68a740 (most recent call first):; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:24958,Safety,Abort,Aborted,24958,"runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170 in main; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 251 in _run_main; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/tmp/Bazel.runfiles_r0rx38k1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180 in <module>; [E::fai_retrieve] Failed to retrieve block: unexpected end of file; 2022-10-29 09:19:04.668786: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 279152 end: 279350; Fatal Python error: Aborted. Current thread 0x00007f5d7f60d740 (most recent call first):; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 67 in _candidates_from_reads; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/window_selector.py"", line 233 in select_windows; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/realigner/realigner.py"", line 675 in realign_reads; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1244 in region_reads; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1123 in process; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1795 in make_examples_runner; File ""/tmp/Bazel.runfiles_wddxsjgc/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/583:15,Modifiability,inherit,inherited,15,"Hello,. I have inherited some haloplex data, and ideally I would like to use deepvariant for its analyses as I have used this for my WES. . Do you think deepvariant would work proficiently for haloplex data?. Thanks!; Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/583
https://github.com/google/deepvariant/issues/584:216,Security,access,access,216,"Hi,. From the RNA example doc, it states; > We will also restrict analysis to CDS regions on chromosome 20 to make this demonstration quicker. I'm not 100% on the biological nuances, but the total RNA samples I have access to should enable variant calling (nearly) genome-wide. Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only?; ; Best,; Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/585:2502,Performance,load,load,2502,"; app.run(main); File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner; regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options; ref_contigs = fasta.IndexedFastaReader(; File ""/tmp/Bazel.runfiles_2wmov4iu/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__; self._reader = reference.IndexedFastaReader.from_file(; ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa; [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'; I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader; I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs; [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main; make_examples_core.make_examples_runner(options); File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:4094,Performance,load,load,4094,"e(; ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa; [E::idx_find_and_load] Could not retrieve index file for '/input/A_J.chr19.bam'; I1114 07:56:46.139744 140275925796672 genomics_reader.py:222] Reading /input/A_J.chr19.bam with NativeSamReader; I1114 07:56:46.142346 140275925796672 make_examples_core.py:243] Task 0/2: Preparing inputs; [E::fai_load3_core] Failed to open FASTA index /input/chr19_new.fa.fai: No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 300, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/absl_py/absl/app.py"", line 251, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner; regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1653, in processing_regions_from_options; ref_contigs = fasta.IndexedFastaReader(; File ""/tmp/Bazel.runfiles_1n42qf4z/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 105, in __init__; self._reader = reference.IndexedFastaReader.from_file(; ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /input/chr19_new.fa; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/chr19_new.fa --reads /input/A_J.chr19.bam --examples /tmp/tmpr4ux434h/make_examples.tfrecord@2.gz --channels insert_size --gvcf /tmp/tmpr4ux434h/gvcf.tfrecord@2.gz --task 1. real 0m2.768s; user 0m2.534s; sys 0m0.541s. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/586:1263,Deployability,Install,Installation,1263,"**Describe the issue:**; On a specific batch of samples, GQs and QUALs seem to be abnormal.; The GQ and QUAL distributions are bimodal and for variants they are much lower than I would expect. It doesn't seem like there is anything wrong with the calls themselves; I get an expected number of variants. I also can not find anything wrong with the input data. It has high base quality throughout the reads, they are 100bp paired end reads from a NovaSeq with the four value binned base quality scores. This is the visual report for one sample. <img width=""1307"" alt=""image"" src=""https://user-images.githubusercontent.com/8237552/202532045-0aa0f5fa-28bd-40d3-be4f-72a74e5ea072.png"">. Here is an example. I would expect this variant to have a much higher GQ and QUAL. I also have attached deepvariant's channels png for this variant. ; ```; chr1 169421916 . A G 18.4 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:58:29,29:0.5:18,0,22; ```; ![chr1_169421916_A-G](https://user-images.githubusercontent.com/8237552/202532164-d069b9c8-d1e8-4d19-9dba-f1b95f34fcd7.png). Is this expected or is something strange happening here, any insight you can provide would be very appreciated.; Thank you. **Setup**; - Operating system: Ubuntu 20.04; - DeepVariant version: 1.4 (but also 1.2); - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Novaseq, 100bp paired, HG38. **Steps to reproduce:**; ```; singularity run -B /usr/lib/locale/:/usr/lib/locale/ -c --pwd $(pwd) -W $(pwd) -B $(pwd) docker://google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref $REF --reads $CRAM --output_vcf $VCF --output_gvcf $GVCF --intermediate_results_dir ./int_results --regions $BED; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/588:850,Availability,Error,Error,850,"Hi.; I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue.; Can you assist in any way?; Thanks. **Setup**; - Operating system: Ubuntu 20.04.5 LTS; - DeepVariant version: 1.4.0; - Installation method: Docker; - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**; - Command:; ```; BIN_VERSION=""1.4.0"". sudo docker run \; -v ""input"":""/input"" \; -v ""output"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \; --reads=/input/1115492_23181_0_0.cram \; --regions ""chr3:10,049,322-10,156,156"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=5 ; ```; - Error trace:; ; > parallel: This job failed:; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; retu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:21,Deployability,pipeline,pipeline,21,"Hi.; I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue.; Can you assist in any way?; Thanks. **Setup**; - Operating system: Ubuntu 20.04.5 LTS; - DeepVariant version: 1.4.0; - Installation method: Docker; - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**; - Command:; ```; BIN_VERSION=""1.4.0"". sudo docker run \; -v ""input"":""/input"" \; -v ""output"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \; --reads=/input/1115492_23181_0_0.cram \; --regions ""chr3:10,049,322-10,156,156"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=5 ; ```; - Error trace:; ; > parallel: This job failed:; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; retu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:62,Deployability,pipeline,pipeline,62,"Hi.; I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue.; Can you assist in any way?; Thanks. **Setup**; - Operating system: Ubuntu 20.04.5 LTS; - DeepVariant version: 1.4.0; - Installation method: Docker; - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**; - Command:; ```; BIN_VERSION=""1.4.0"". sudo docker run \; -v ""input"":""/input"" \; -v ""output"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \; --reads=/input/1115492_23181_0_0.cram \; --regions ""chr3:10,049,322-10,156,156"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=5 ; ```; - Error trace:; ; > parallel: This job failed:; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; retu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:247,Deployability,Install,Installation,247,"Hi.; I'm running the pipeline on a CRAM file. I read that the pipeline works with CRAM files, so I guess that's not the issue.; Can you assist in any way?; Thanks. **Setup**; - Operating system: Ubuntu 20.04.5 LTS; - DeepVariant version: 1.4.0; - Installation method: Docker; - Type of data: I have no information about the sequencing instrument, the reference genome was GRCh38. **Steps to reproduce:**; - Command:; ```; BIN_VERSION=""1.4.0"". sudo docker run \; -v ""input"":""/input"" \; -v ""output"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/GCF_000001405.26_GRCh38_genomic1.fa.gz \; --reads=/input/1115492_23181_0_0.cram \; --regions ""chr3:10,049,322-10,156,156"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=5 ; ```; - Error trace:; ; > parallel: This job failed:; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; retu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/588:2650,Testability,test,test,2650,"fa.gz \; --reads=/input/1115492_23181_0_0.cram \; --regions ""chr3:10,049,322-10,156,156"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=5 ; ```; - Error trace:; ; > parallel: This job failed:; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 166, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 128, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 85, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 134, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_ir3xkizo/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: NOT_FOUND: Could not open /input/1115492_23181_0_0.cram; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/GCF_000001405.26_GRCh38_genomic1.fa.gz --reads /input/1115492_23181_0_0.cram --examples /tmp/tmpf8z5m2q; 0/make_examples.tfrecord@5.gz --channels insert_size --gvcf /tmp/tmpf8z5m2q0/gvcf.tfrecord@5.gz --regions chr3:10,049,322-10,156,156 --task 4. I didn't try the quick start test.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/588
https://github.com/google/deepvariant/issues/589:1038,Testability,log,log,1038,"Hello, I am trying to train my pacbio model using ”DeepVariant-inception_v3-1.4.0+data-pacbio_standard“ on ”HG003.pacbio-hifi.21x.haplotag.grch38.bam“. I noticed that the pre-trained model accepted the following channels: ""channels"": [1, 2, 3, 4, 5, 6, 7, 9, 10]}. I tried the following command:. ( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --line-buffer \; sudo docker run \; -v ${BASE}:${BASE} \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/make_examples \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM_003}"" \; --examples ""${MEDATA_DIR}/validation_set.hg003.tfrecord@${N_SHARDS}.gz"" \; --truth_variants ""${TRUTH_VCF_003}"" \; --confident_regions ""${TRUTH_BED_003}"" \; --task {} \; --regions ' ""chr20"" ' \; 	 --sort_by_haplotypes \; 	 --parse_sam_aux_fields \; 	 --add_hp_channel \; 	 --channels ' ""read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size"" ' \; ) 2>&1 | tee ""${LOG_DIR}/validation_set.with_label.make_examples.log"". get ”example_channels = [1, 2, 3, 4, 5, 6, 7, 11, 12, 13, 14, 15, 16, 17, 18, 19]“. I'm curious how do I get channels 9 and 10？Thanks！",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/589
https://github.com/google/deepvariant/issues/590:142,Usability,guid,guide,142,"**Describe the issue:**; Since I couldn't run DeepVariant with Docker, I thought I'd try the prebuilt binaries version, but I couldn't find a guide on how to use the prebuilt binaries DeepVariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/590
https://github.com/google/deepvariant/issues/591:135,Deployability,release,release,135,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed.; I modified scripts to install packages that is need to build DV-1.4, which didn't work for me.; Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**; - Operating system: **Ubuntu16.04**; - DeepVariant version: **1.4**; - Installation method (Docker, built from source, etc.): **built from source**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:208,Deployability,install,install,208,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed.; I modified scripts to install packages that is need to build DV-1.4, which didn't work for me.; Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**; - Operating system: **Ubuntu16.04**; - DeepVariant version: **1.4**; - Installation method (Docker, built from source, etc.): **built from source**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/591:513,Deployability,Install,Installation,513,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: **YES**. **Describe the issue:**. _Building release binaries of DV-1.4 on ubuntu16.04 failed.; I modified scripts to install packages that is need to build DV-1.4, which didn't work for me.; Updating operating system is not allowed for me, so I am eager to know whether there is any chance that I build DV-1.4 on ubuntu16.04 technically?_. **Setup**; - Operating system: **Ubuntu16.04**; - DeepVariant version: **1.4**; - Installation method (Docker, built from source, etc.): **built from source**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/591
https://github.com/google/deepvariant/issues/592:1811,Availability,Error,Error,1811,"nt/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:; ```; chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0; ```; .gvcf file:; ```; chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990; ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:; ```; chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0; ```; ```; chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990; ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same?. **Setup**; - Operating system: Ubuntu16.04; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**; - Command:; ```; docker run \; -v ${MOUNT_DIR}:${MOUNT_DIR} \; google/deepvariant:1.2.0-rc0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${REFERENCE}"" \; --reads=""${INPUT}"" \; --regions=""${CAPTURE_KIT}"" \; --output_vcf=${OUTPUT_VCF} \; --output_gvcf=${OUTPUT_GVCF} \; --num_shards=64 \; --postprocess_variants_extra_args=""only_keep_pass=true""; ```; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1165,Deployability,Install,Installation,1165,"nt/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:; ```; chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0; ```; .gvcf file:; ```; chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990; ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:; ```; chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0; ```; ```; chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990; ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same?. **Setup**; - Operating system: Ubuntu16.04; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**; - Command:; ```; docker run \; -v ${MOUNT_DIR}:${MOUNT_DIR} \; google/deepvariant:1.2.0-rc0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${REFERENCE}"" \; --reads=""${INPUT}"" \; --regions=""${CAPTURE_KIT}"" \; --output_vcf=${OUTPUT_VCF} \; --output_gvcf=${OUTPUT_GVCF} \; --num_shards=64 \; --postprocess_variants_extra_args=""only_keep_pass=true""; ```; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1864,Testability,test,test,1864,"nt/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:; ```; chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0; ```; .gvcf file:; ```; chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990; ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:; ```; chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0; ```; ```; chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990; ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same?. **Setup**; - Operating system: Ubuntu16.04; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**; - Command:; ```; docker run \; -v ${MOUNT_DIR}:${MOUNT_DIR} \; google/deepvariant:1.2.0-rc0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${REFERENCE}"" \; --reads=""${INPUT}"" \; --regions=""${CAPTURE_KIT}"" \; --output_vcf=${OUTPUT_VCF} \; --output_gvcf=${OUTPUT_GVCF} \; --num_shards=64 \; --postprocess_variants_extra_args=""only_keep_pass=true""; ```; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:1900,Testability,test,test,1900,"nt/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:; ```; chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0; ```; .gvcf file:; ```; chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990; ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:; ```; chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0; ```; ```; chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990; ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same?. **Setup**; - Operating system: Ubuntu16.04; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**; - Command:; ```; docker run \; -v ${MOUNT_DIR}:${MOUNT_DIR} \; google/deepvariant:1.2.0-rc0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${REFERENCE}"" \; --reads=""${INPUT}"" \; --regions=""${CAPTURE_KIT}"" \; --output_vcf=${OUTPUT_VCF} \; --output_gvcf=${OUTPUT_GVCF} \; --num_shards=64 \; --postprocess_variants_extra_args=""only_keep_pass=true""; ```; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; No.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:124,Usability,clear,clear,124,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:; ```; chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0; ```; .gvcf file:; ```; chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990; ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:; ```; chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0; ```; ```; chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990; ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same?. **Setup**; - Operating system: Ubuntu16.04; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**; - Command:; ```; docker run \; -v ${MOUNT_DIR}:${MOUNT_DIR} \; google/deepvariant:1.2.0-rc0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${REFERENCE}"" \; --reads=""${INPUT}"" \; --regions=""${CAPTURE_KIT}"" \; --output_vcf=${OUTPUT_VCF} \; --output_gvcf=${OUTPUT_GVCF} \; --num_shards=64 \; --postprocess_variants_extra_args=""only_keep_pass=true""; ```; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/592:292,Usability,clear,clearly,292,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**; (A clear and concise description of what the issue is.). A variant with VAF value 1 is called as heterozygous. The IGV visualisation of the .bam file shows that it should clearly be a homozygous variant. ![igv_panel_chr2_24146804](https://user-images.githubusercontent.com/84016709/204764192-9bd69aa6-7f23-4490-9391-7af95e909e3f.png). Here the line from .vcf file:; ```; chr2	24146804	.	C	T	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162:1:26,0,0; ```; .gvcf file:; ```; chr2	24146804	.	C	T,<*>	29.5	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:3:162:0,162,0:1,0:26,0,0,990,990,990; ```. We also asked our collaborators to run the same sample and in their results, a homozygous variant is called:; ```; chr2	24146804	.	C	T	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161:1:28,2,0; ```; ```; chr2	24146804	.	C	T,<*>	30.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:5:161:0,161,0:1,0:28,2,0,990,990,990; ```. What could cause this discrepancy, if the DeepVariant versions and commands are the same?. **Setup**; - Operating system: Ubuntu16.04; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); NovaSeq 6000 using Twist Comprehensive Exome with mtDNA add-in, GRCh38. **Steps to reproduce:**; - Command:; ```; docker run \; -v ${MOUNT_DIR}:${MOUNT_DIR} \; google/deepvariant:1.2.0-rc0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${REFERENCE}"" \; --reads=""${INPUT}"" \; --regions=""${CAPTURE_KIT}"" \; --output_vcf=${OUTPUT_VCF} \; --output_gvcf=${OUTPUT_GVCF} \; --num_shards=64 \; --postprocess_variants_extra_args=""only_keep_pass=true""; ```; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/592
https://github.com/google/deepvariant/issues/593:135,Availability,error,error,135,"Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. ; <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,; Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/593:232,Availability,error,error,232,"Hey, I tried to run the docker run single command following step by step from your instructions on macOS. Unfortunately, I ran into an error that couldn't give me any idea what's wrong! I attached the screenshot, so you can see the error. ; <img width=""1512"" alt=""Screenshot 2022-12-01 at 14 28 42"" src=""https://user-images.githubusercontent.com/75676816/205064985-34617012-9e82-4734-88a6-0d702f7bd445.png"">. Thanks,; Anil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/593
https://github.com/google/deepvariant/issues/595:321,Availability,error,error,321,"Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive!. I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields ; --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'; Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:350,Availability,error,error,350,"Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive!. I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields ; --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'; Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:584,Deployability,pipeline,pipeline,584,"Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive!. I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields ; --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'; Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:817,Deployability,pipeline,pipeline,817,"Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive!. I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields ; --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'; Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:124,Security,validat,validation,124,"Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive!. I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields ; --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'; Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:177,Testability,test,test,177,"Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive!. I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields ; --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'; Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/595:575,Testability,test,test,575,"Hi, I'm running DeepVariant with BQSR -adjusted bam files. I have sequencing data for hg002 and hg005 and I have to say the validation results are very impressive!. I wanted to test the option for using the original base quality scores with:. --parse_sam_aux_fields ; --use_original_quality_scores. but get the following error: . FATAL Flags parsing error: Unknown command line flag 'parse_sam_aux_fields'; Pass --helpshort or --helpfull to see help on flags. I was running DeepVariant with docker by following the whole genome sequencing case study -tutorial, but will next test the pipeline for multi-sample variant calling for my cohort of 50 samples. I'm wondering should I realign the reads or is it possible to use the original base quality scores from BQSR adjusted bam files? I was previously using the GATK4 pipeline, but the results are so much better with DeepVariant and as a bonus, it's a million times easier (and quicker). Thanks. Karoliina",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/595
https://github.com/google/deepvariant/issues/596:35,Availability,down,downloading,35,"After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/596:259,Deployability,Install,Installation,259,"After creating the directories and downloading the required files in their respective folders, I used the single command run_deeppvariant script. But it not's working. I'm attaching the screenshot. . - Operating system: MacOS; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: Illumina seq, short reads. <img width=""1510"" alt=""Screenshot 2022-12-05 at 12 09 45"" src=""https://user-images.githubusercontent.com/75676816/205648651-e8ad6b73-7139-4fa6-9b5d-b496cdcf7bc2.png"">",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/596
https://github.com/google/deepvariant/issues/597:19,Availability,error,error,19,"Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs; Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****; time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader; I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs; I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader; I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:6677,Availability,checkpoint,checkpoint,6677,"ake_examples_core.py:243] Task 0/2: Found 77 candidate variants; I1214 06:02:02.320545 140052653934400 make_examples_core.py:243] Task 0/2: Created 89 examples; I1214 06:10:23.735674 140555214505792 make_examples_core.py:243] Task 1/2: Writing example info to /tmp/tmpiy9bfzyx/make_examples.tfrecord-00001-of-00002.gz.example_info.json; I1214 06:10:23.736027 140555214505792 make_examples_core.py:1883] example_shape = [100, 221, 7]; I1214 06:10:23.736302 140555214505792 make_examples_core.py:1884] example_channels = [1, 2, 3, 4, 5, 6, 19]; I1214 06:10:23.748708 140555214505792 make_examples_core.py:243] Task 1/2: Found 77 candidate variants; I1214 06:10:23.748840 140555214505792 make_examples_core.py:243] Task 1/2: Created 84 examples. real	25m4.324s; user	39m40.647s; sys	0m24.239s. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino; I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7950,Modifiability,layers,layers,7950," 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7957,Modifiability,layers,layers,7957," 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8178,Modifiability,layers,layers,8178,"put examples: [1, 2, 3, 4, 5, 6, 19].; 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt; I1214 06:10:37.470",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8185,Modifiability,layers,layers,8185,"put examples: [1, 2, 3, 4, 5, 6, 19].; 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt; I1214 06:10:37.470",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8427,Modifiability,layers,layers,8427,"formance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt; I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt; WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8434,Modifiability,layers,layers,8434,"formance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt; I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt; WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8655,Modifiability,layers,layers,8655,"ing new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt; I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt; WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.; Instructions for updating:; Use `tf.compat.v1.graph_util.convert_variables_to_constants`; W1214 06:10:41.056998 140363019278144",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8662,Modifiability,layers,layers,8662,"ing new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt; I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt; WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.; Instructions for updating:; Use `tf.compat.v1.graph_util.convert_variables_to_constants`; W1214 06:10:41.056998 140363019278144",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8882,Modifiability,layers,layers,8882,"nsor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt; I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt; WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.; Instructions for updating:; Use `tf.compat.v1.graph_util.convert_variables_to_constants`; W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and wi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:8889,Modifiability,layers,layers,8889,"nsor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1638: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); INFO:tensorflow:Restoring parameters from /opt/models/wes/model.ckpt; I1214 06:10:37.470187 140363019278144 saver.py:1399] Restoring parameters from /opt/models/wes/model.ckpt; WARNING:tensorflow:From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.; Instructions for updating:; Use `tf.compat.v1.graph_util.convert_variables_to_constants`; W1214 06:10:41.056998 140363019278144 deprecation.py:341] From /tmp/Bazel.runfiles_oh47rpgj/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py:75: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and wi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7319,Performance,optimiz,optimized,7319," examples. real	25m4.324s; user	39m40.647s; sys	0m24.239s. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino; I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7419,Performance,perform,performance-critical,7419," examples. real	25m4.324s; user	39m40.647s; sys	0m24.239s. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpiy9bfzyx/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/tmpiy9bfzyx"" --use_openvino; I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7704,Performance,Tune,Tune,7704,"dir ""/tmp/tmpiy9bfzyx"" --use_openvino; I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be remo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:7753,Performance,perform,performance,7753,"dir ""/tmp/tmpiy9bfzyx"" --use_openvino; I1214 06:10:30.972710 140363019278144 call_variants.py:317] From /tmp/tmpiy9bfzyx/make_examples.tfrecord-00000-of-00002.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1214 06:10:30.995939 140363019278144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; 2022-12-14 06:10:31.060396: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2022-12-14 06:10:31.101084: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; I1214 06:10:31.288279 140363019278144 openvino_estimator.py:55] Processing ckpt=/opt/models/wes/model.ckpt, tensor_shape=[100, 221, 7]; /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:1083: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:678: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs, training=is_training); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:2441: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; outputs = layer.apply(inputs); /usr/local/lib/python3.8/dist-packages/tf_slim/layers/layers.py:118: UserWarning: `layer.apply` is deprecated and will be remo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/597:601,Testability,log,logs,601,"Hello, I'm getting error below - please let me know if I can fix it in anyway.. . [root@localhost processed]# docker run -v /home/imusayev/Documents/RNAseq:/input -v /home/imusayev/Documents/RNAseq:/output google/deepvariant:1.4.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --regions=chr16:56191390-56357444 --ref=/input/hg38/hg38.fa --reads=/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam --output_vcf=/output/MUT60d.sorted.bam.vcf --output_gvcf=/output/MUT60d.sorted.bam.gvcf --call_variants_extra_args=use_openvino=true --num_shards=2 --logging_dir=/output/logs; Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. I1214 05:45:20.217978 140442762327872 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmpiy9bfzyx. ***** Intermediate results will be written to /tmp/tmpiy9bfzyx in docker. ****. ***** Running the command:*****; time seq 0 1 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/hg38/hg38.fa"" --reads ""/input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam"" --examples ""/tmp/tmpiy9bfzyx/make_examples.tfrecord@2.gz"" --channels ""insert_size"" --gvcf ""/tmp/tmpiy9bfzyx/gvcf.tfrecord@2.gz"" --regions ""chr16:56191390-56357444"" --task {}. I1214 05:45:33.914664 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader; I1214 05:45:33.947415 140555214505792 make_examples_core.py:243] Task 1/2: Preparing inputs; I1214 05:45:34.038768 140555214505792 genomics_reader.py:222] Reading /input/60d/processed/work/89/e7822adaaaf824f73f3d6acd1334bb/MUT60d.sorted.bam with NativeSamReader; I1214 05:45:34.078675 140555214505792 make_examples_core.py:243] Task 1/2: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/597
https://github.com/google/deepvariant/issues/598:1159,Availability,error,error,1159,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1217,Availability,error,error,1217,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1275,Availability,error,error,1275,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1333,Availability,error,error,1333,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1391,Availability,error,error,1391,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1449,Availability,error,error,1449,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1507,Availability,error,error,1507,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1565,Availability,error,error,1565,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1623,Availability,error,error,1623,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1681,Availability,error,error,1681,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1739,Availability,error,error,1739,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1797,Availability,error,error,1797,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1855,Availability,error,error,1855,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1913,Availability,error,error,1913,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:1971,Availability,error,error,1971,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2029,Availability,error,error,2029,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2087,Availability,error,error,2087,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2145,Availability,error,error,2145,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2203,Availability,error,error,2203,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:2261,Availability,error,error,2261,"lps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; Traceback (most recent call last):; File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/path/Mambaforge-4.14.0-1/envs/dpv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/path/Mambaforge-4.14.0-1/envs/dpv/share/deepvariant-1.4.0-0/binaries/DeepVariant/1.4.0/DeepVariant-1.4.0/make_examples.zip/__main__.py"", line 387, in <module>; File ""/pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:673,Energy Efficiency,Power,Power,673,"Hi,; I want to call variations on the Pacbio bam data to get gvcf files.; But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? ; Please help!; (No root permission;Centos7 x86;Only the user directory has read and write permission); ```; dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF; ```; ```; Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemente",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:410,Testability,log,logdir,410,"Hi,; I want to call variations on the Pacbio bam data to get gvcf files.; But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? ; Please help!; (No root permission;Centos7 x86;Only the user directory has read and write permission); ```; dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF; ```; ```; Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemente",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/598:687,Testability,log,login,687,"Hi,; I want to call variations on the Pacbio bam data to get gvcf files.; But something went wrong with the program, and I spent two days wondering what went wrong. How do you solve this problem? ; Please help!; (No root permission;Centos7 x86;Only the user directory has read and write permission); ```; dv_make_examples.py --cores 3 --sample QJ --ref QJref.fa --reads F0F_sorted.merged.addg.uniq.rmdup.bam --logdir . --examples EXAMPLES --gvcf GVCF; ```; ```; Academic tradition requires you to cite works you base your article on.; When using programs that use GNU Parallel to process data for publication; please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,; ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT.; If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. Computers / CPU cores / Max jobs to run; 1:local / 48 / 3. Computer:jobs running/jobs completed/%of started jobs/Average seconds to complete; ETA: 0s Left: 3 AVG: 0.00s local:3/0/100%/0.0s lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemented; lchmod (file attributes) error: Function not implemente",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/598
https://github.com/google/deepvariant/issues/599:630,Availability,Error,Error,630,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:** DeepVariant does not complete postprocess_variants (feels like stuck; already waiting for completion for two days; other SAMPLES have already finished runninig). **Setup**; - Operating system: HPC; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker --> Singularity; - Type of data: WGS data. **Steps to reproduce:**; - Command: `run_deepvariant --model_type=WGS --ref=${FASTA} --reads=${BAMFILE} --output_vcf=${OUT_SAMPLE}.vcf.gz --output_gvcf=${OUT_SAMPLE}.g.vcf.gz`; - Error trace: (if applicable) . No error, but DeepVariant does not seem to continue processing:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/home/rzei0002/xm41_scratch/hg38_resources/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta"" --infile ""/tmp/tmp8vfbqj_y/call_variants_output.tfrecord.gz"" --outfile ""/scratch/xm41; /ct/bamsDown/30x/DEEPV/GRALF001.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmp8vfbqj_y/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/scratch/xm41/ct/bamsDown/30x/DEEPV/GRALF001.g.vcf.gz""; ```. ![image](https://user-images.githubusercontent.com/73748542/208531940-a0cbd86a-acb7-4ff4-9168-57c3b865625c.png). Based on other processes, the final process should not take that long:. ![image](https://user-images.githubusercontent.com/73748542/208532607-d0ae4fd2-38ac-48f9-889d-2d4343e60fe5.png). Is there a way to only re-initiate the postprocess_variants process?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/599
https://github.com/google/deepvariant/issues/599:664,Availability,error,error,664,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:** DeepVariant does not complete postprocess_variants (feels like stuck; already waiting for completion for two days; other SAMPLES have already finished runninig). **Setup**; - Operating system: HPC; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker --> Singularity; - Type of data: WGS data. **Steps to reproduce:**; - Command: `run_deepvariant --model_type=WGS --ref=${FASTA} --reads=${BAMFILE} --output_vcf=${OUT_SAMPLE}.vcf.gz --output_gvcf=${OUT_SAMPLE}.g.vcf.gz`; - Error trace: (if applicable) . No error, but DeepVariant does not seem to continue processing:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/home/rzei0002/xm41_scratch/hg38_resources/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta"" --infile ""/tmp/tmp8vfbqj_y/call_variants_output.tfrecord.gz"" --outfile ""/scratch/xm41; /ct/bamsDown/30x/DEEPV/GRALF001.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmp8vfbqj_y/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/scratch/xm41/ct/bamsDown/30x/DEEPV/GRALF001.g.vcf.gz""; ```. ![image](https://user-images.githubusercontent.com/73748542/208531940-a0cbd86a-acb7-4ff4-9168-57c3b865625c.png). Based on other processes, the final process should not take that long:. ![image](https://user-images.githubusercontent.com/73748542/208532607-d0ae4fd2-38ac-48f9-889d-2d4343e60fe5.png). Is there a way to only re-initiate the postprocess_variants process?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/599
https://github.com/google/deepvariant/issues/599:346,Deployability,Install,Installation,346,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:** DeepVariant does not complete postprocess_variants (feels like stuck; already waiting for completion for two days; other SAMPLES have already finished runninig). **Setup**; - Operating system: HPC; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker --> Singularity; - Type of data: WGS data. **Steps to reproduce:**; - Command: `run_deepvariant --model_type=WGS --ref=${FASTA} --reads=${BAMFILE} --output_vcf=${OUT_SAMPLE}.vcf.gz --output_gvcf=${OUT_SAMPLE}.g.vcf.gz`; - Error trace: (if applicable) . No error, but DeepVariant does not seem to continue processing:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""/home/rzei0002/xm41_scratch/hg38_resources/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta"" --infile ""/tmp/tmp8vfbqj_y/call_variants_output.tfrecord.gz"" --outfile ""/scratch/xm41; /ct/bamsDown/30x/DEEPV/GRALF001.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmp8vfbqj_y/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/scratch/xm41/ct/bamsDown/30x/DEEPV/GRALF001.g.vcf.gz""; ```. ![image](https://user-images.githubusercontent.com/73748542/208531940-a0cbd86a-acb7-4ff4-9168-57c3b865625c.png). Based on other processes, the final process should not take that long:. ![image](https://user-images.githubusercontent.com/73748542/208532607-d0ae4fd2-38ac-48f9-889d-2d4343e60fe5.png). Is there a way to only re-initiate the postprocess_variants process?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/599
https://github.com/google/deepvariant/issues/601:263,Availability,error,error,263,"**Describe the issue:**; Hi, I am following the [deepvariant-quick-start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md) tutorial on singularity to try out DeepVariant on our study. When I do `singularity run` command, I get the error about `temple()` please see the error message below. I'm wondering if anyone can help with this. **Setup**; - Operating system: CentOS Linux 7 (Core); - Singularity version: 3.5-8.el7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: WGS. **Steps to reproduce:**; - Command:; > singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""1.4.0"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=${reference_genome} \; > --reads=${bam} \; > --regions=""chr1"" \; > --output_vcf=${vcf_dir}/${sample}.vcf.gz \; > --output_gvcf=${gvcf_dir}/${sample}.g.vcf.gz \; > --intermediate_results_dir ${tmp_dir} \; > --num_shards=${ncpu}. - Error trace: (if applicable); > Error in tempfile() using template /XXX/parXXXXX.par: Parent directory (/XXX/) does not exist at /usr/bin/parallel line 3889. **Additional comments:**; I also tried with `--no-home` flag which did not work at all. ; I don't have the root access since I am running this on a HPC Torque system managed by others.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/601
https://github.com/google/deepvariant/issues/601:301,Availability,error,error,301,"**Describe the issue:**; Hi, I am following the [deepvariant-quick-start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md) tutorial on singularity to try out DeepVariant on our study. When I do `singularity run` command, I get the error about `temple()` please see the error message below. I'm wondering if anyone can help with this. **Setup**; - Operating system: CentOS Linux 7 (Core); - Singularity version: 3.5-8.el7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: WGS. **Steps to reproduce:**; - Command:; > singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""1.4.0"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=${reference_genome} \; > --reads=${bam} \; > --regions=""chr1"" \; > --output_vcf=${vcf_dir}/${sample}.vcf.gz \; > --output_gvcf=${gvcf_dir}/${sample}.g.vcf.gz \; > --intermediate_results_dir ${tmp_dir} \; > --num_shards=${ncpu}. - Error trace: (if applicable); > Error in tempfile() using template /XXX/parXXXXX.par: Parent directory (/XXX/) does not exist at /usr/bin/parallel line 3889. **Additional comments:**; I also tried with `--no-home` flag which did not work at all. ; I don't have the root access since I am running this on a HPC Torque system managed by others.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/601
https://github.com/google/deepvariant/issues/601:1013,Availability,Error,Error,1013,"**Describe the issue:**; Hi, I am following the [deepvariant-quick-start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md) tutorial on singularity to try out DeepVariant on our study. When I do `singularity run` command, I get the error about `temple()` please see the error message below. I'm wondering if anyone can help with this. **Setup**; - Operating system: CentOS Linux 7 (Core); - Singularity version: 3.5-8.el7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: WGS. **Steps to reproduce:**; - Command:; > singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""1.4.0"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=${reference_genome} \; > --reads=${bam} \; > --regions=""chr1"" \; > --output_vcf=${vcf_dir}/${sample}.vcf.gz \; > --output_gvcf=${gvcf_dir}/${sample}.g.vcf.gz \; > --intermediate_results_dir ${tmp_dir} \; > --num_shards=${ncpu}. - Error trace: (if applicable); > Error in tempfile() using template /XXX/parXXXXX.par: Parent directory (/XXX/) does not exist at /usr/bin/parallel line 3889. **Additional comments:**; I also tried with `--no-home` flag which did not work at all. ; I don't have the root access since I am running this on a HPC Torque system managed by others.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/601
https://github.com/google/deepvariant/issues/601:1045,Availability,Error,Error,1045,"**Describe the issue:**; Hi, I am following the [deepvariant-quick-start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md) tutorial on singularity to try out DeepVariant on our study. When I do `singularity run` command, I get the error about `temple()` please see the error message below. I'm wondering if anyone can help with this. **Setup**; - Operating system: CentOS Linux 7 (Core); - Singularity version: 3.5-8.el7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: WGS. **Steps to reproduce:**; - Command:; > singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""1.4.0"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=${reference_genome} \; > --reads=${bam} \; > --regions=""chr1"" \; > --output_vcf=${vcf_dir}/${sample}.vcf.gz \; > --output_gvcf=${gvcf_dir}/${sample}.g.vcf.gz \; > --intermediate_results_dir ${tmp_dir} \; > --num_shards=${ncpu}. - Error trace: (if applicable); > Error in tempfile() using template /XXX/parXXXXX.par: Parent directory (/XXX/) does not exist at /usr/bin/parallel line 3889. **Additional comments:**; I also tried with `--no-home` flag which did not work at all. ; I don't have the root access since I am running this on a HPC Torque system managed by others.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/601
https://github.com/google/deepvariant/issues/601:486,Deployability,Install,Installation,486,"**Describe the issue:**; Hi, I am following the [deepvariant-quick-start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md) tutorial on singularity to try out DeepVariant on our study. When I do `singularity run` command, I get the error about `temple()` please see the error message below. I'm wondering if anyone can help with this. **Setup**; - Operating system: CentOS Linux 7 (Core); - Singularity version: 3.5-8.el7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: WGS. **Steps to reproduce:**; - Command:; > singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""1.4.0"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=${reference_genome} \; > --reads=${bam} \; > --regions=""chr1"" \; > --output_vcf=${vcf_dir}/${sample}.vcf.gz \; > --output_gvcf=${gvcf_dir}/${sample}.g.vcf.gz \; > --intermediate_results_dir ${tmp_dir} \; > --num_shards=${ncpu}. - Error trace: (if applicable); > Error in tempfile() using template /XXX/parXXXXX.par: Parent directory (/XXX/) does not exist at /usr/bin/parallel line 3889. **Additional comments:**; I also tried with `--no-home` flag which did not work at all. ; I don't have the root access since I am running this on a HPC Torque system managed by others.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/601
https://github.com/google/deepvariant/issues/601:307,Integrability,message,message,307,"**Describe the issue:**; Hi, I am following the [deepvariant-quick-start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md) tutorial on singularity to try out DeepVariant on our study. When I do `singularity run` command, I get the error about `temple()` please see the error message below. I'm wondering if anyone can help with this. **Setup**; - Operating system: CentOS Linux 7 (Core); - Singularity version: 3.5-8.el7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: WGS. **Steps to reproduce:**; - Command:; > singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""1.4.0"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=${reference_genome} \; > --reads=${bam} \; > --regions=""chr1"" \; > --output_vcf=${vcf_dir}/${sample}.vcf.gz \; > --output_gvcf=${gvcf_dir}/${sample}.g.vcf.gz \; > --intermediate_results_dir ${tmp_dir} \; > --num_shards=${ncpu}. - Error trace: (if applicable); > Error in tempfile() using template /XXX/parXXXXX.par: Parent directory (/XXX/) does not exist at /usr/bin/parallel line 3889. **Additional comments:**; I also tried with `--no-home` flag which did not work at all. ; I don't have the root access since I am running this on a HPC Torque system managed by others.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/601
https://github.com/google/deepvariant/issues/601:1283,Security,access,access,1283,"**Describe the issue:**; Hi, I am following the [deepvariant-quick-start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md) tutorial on singularity to try out DeepVariant on our study. When I do `singularity run` command, I get the error about `temple()` please see the error message below. I'm wondering if anyone can help with this. **Setup**; - Operating system: CentOS Linux 7 (Core); - Singularity version: 3.5-8.el7; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: WGS. **Steps to reproduce:**; - Command:; > singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; > docker://google/deepvariant:""1.4.0"" \; > /opt/deepvariant/bin/run_deepvariant \; > --model_type=WGS \; > --ref=${reference_genome} \; > --reads=${bam} \; > --regions=""chr1"" \; > --output_vcf=${vcf_dir}/${sample}.vcf.gz \; > --output_gvcf=${gvcf_dir}/${sample}.g.vcf.gz \; > --intermediate_results_dir ${tmp_dir} \; > --num_shards=${ncpu}. - Error trace: (if applicable); > Error in tempfile() using template /XXX/parXXXXX.par: Parent directory (/XXX/) does not exist at /usr/bin/parallel line 3889. **Additional comments:**; I also tried with `--no-home` flag which did not work at all. ; I don't have the root access since I am running this on a HPC Torque system managed by others.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/601
https://github.com/google/deepvariant/issues/602:2631,Availability,down,down,2631,"/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of the log file. I am happy to include the entire log file but there is nothing out of the ordinary between those lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided cores: 64; Rules claiming more threads will be scaled down.; Select jobs to execute... > [Wed Jan 4 18:30:51 2023]; > rule deepvariant:; > input: results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam, /mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta; > output: results/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2.vcf.gz; > log: logs/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2/stdout.log; > jobid: 0; > wildcards: sample=s534_EKDN210017195-1A_HTTJ3DSX2_L2; > threads: 64; > resources: mem_mb=163840, disk_mb=16401, tmpdir=/tmp/kmarians_4189323; > ; > Activating singularity image singularity/deepvariant_1.4.0.sif; > INFO: Convert SIF file to sandbox...; > I0104 18:31:03.183642 139718628308800 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/kmarians_4189323/tmpxrz5rqbp; > ; > ***** Intermediate results will be written to /tmp/kmarians_4189323/tmpxrz5rqbp in docker. ****; > ; > ; > ***** Running the command:*****; > time seq 0 63 | pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:4573,Availability,checkpoint,checkpoint,4573,"rallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta"" --reads ""results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam"" --examples ""/tmp/kmarians_4189323/tmpxrz5rqbp/make_examples.tfrecord@64.gz"" --channels ""insert_size"" --vsc_min_count_indels ""3"" --vsc_min_count_snps ""3"" --vsc_min_fraction_indels ""0.10"" --vsc_min_fraction_snps ""0.2"" --task {}. > *; > *; > *; > I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; > I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples; > real	18m21.465s; > user	893m16.250s; > sys	15m57.561s; > ; > ***** Running the command:*****; > time /opt/deepvariant/bin/call_variants --outfile ""/tmp/kmarians_4189323/tmpxrz5rqbp/call_variants_output.tfrecord.gz"" --examples ""/tmp/kmarians_4189323/tmpxrz5rqbp/make_examples.tfrecord@64.gz"" --checkpoint ""/opt/models/wes/model.ckpt"" --openvino_model_dir ""/tmp/kmarians_4189323/tmpxrz5rqbp""; > ; > I0104 18:49:26.695084 139646404110144 call_variants.py:317] From /tmp/kmarians_4189323/tmpxrz5rqbp/make_examples.tfrecord-00000-of-00064.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; > I0104 18:49:26.697470 139646404110144 call_variants.py:317] From /opt/models/wes/model.ckpt.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; > Traceback (most recent call last):; > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; > tf.compat.v1.app.run(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; > _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/absl_py/absl/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:7373,Availability,avail,available,7373,"s); > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/absl_py/absl/app.py"", line 251, in _run_main; > sys.exit(main(argv)); > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; > call_variants(; > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in call_variants; > init_op = tf.group(tf.compat.v1.global_variables_initializer(),; > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py"", line 3319, in global_variables_initializer; > return variables_initializer(global_variables()); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py"", line 3139, in global_variables; > return ops.get_collection(ops.GraphKeys.GLOBAL_VARIABLES, scope); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 6605, in get_collection; > return get_default_graph().get_collection(key, scope); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 6231, in get_default_graph; > return _default_graph_stack.get_default(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 5742, in get_default; > self._global_default_graph = Graph(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3113, in __init__; > self._scoped_c_graph = c_api_util.ScopedTFGraph(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/c_api_util.py"", line 50, in __init__; > self.graph = c_api.TF_NewGraph(); > RuntimeError: random_device::random_device(const std::string&): device not available; > Exception ignored in: <function ScopedTFGraph.__del__ at 0x7f01d64378b0>; > Traceback (most recent call last):; > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/c_api_util.py"", line 58, in __del__; > AttributeError: deleter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:156,Deployability,pipeline,pipeline,156,"Hi DeepVariant team,. I'm running DeepVariant via Singularity via Snakemake on a HPC cluster and overall, if I create an interactive session, my entire WES pipeline runs fine until an odd DeepVariant job fails (by that I mean that let's say 30 deepvariant jobs finish ok and the 31st fails). I can then restart the Snakemake run and the same job will run fine, followed by more jobs that will also run fine until another odd jobs fails. This is also particularly true when I use the --cluster command in Snakemake (i.e., send it to a SLURM job scheduler from the master node) - in this event every single job fails. I could of course run all my samples on a single interactive session, keep checking the log file and restart the run every time it fails but I guess that's less than optimal plus this way I can really only run one sample at the time. For the interactive sessions I request 180G and 64cpus (in my case it's: ```srsh --mem=180G --cpus-per-task=64 --partition=long```). . I would request same parameters when using --cluster so:; ```snakemake --cluster ""sbatch --mem=180G cpus-per-task=64"" --jobs 64 --profie profile/ ```(where profile holds singularity args etc.). Singularity image is deepvariant_1.4.0.sif. my Snakemake rule:. ```; rule deepvariant:; input:; bam=rules.apply_bqsr.output.bam,; ref='/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta'; output:; vcf=""results/deepvariant/{sample}.vcf.gz""; params:; model=""WES""; threads: ; 64; resources:; mem_mb=163840; log:; ""logs/deepvariant/{sample}/stdout.log""; singularity:; ""singularity/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:544,Energy Efficiency,schedul,scheduler,544,"Hi DeepVariant team,. I'm running DeepVariant via Singularity via Snakemake on a HPC cluster and overall, if I create an interactive session, my entire WES pipeline runs fine until an odd DeepVariant job fails (by that I mean that let's say 30 deepvariant jobs finish ok and the 31st fails). I can then restart the Snakemake run and the same job will run fine, followed by more jobs that will also run fine until another odd jobs fails. This is also particularly true when I use the --cluster command in Snakemake (i.e., send it to a SLURM job scheduler from the master node) - in this event every single job fails. I could of course run all my samples on a single interactive session, keep checking the log file and restart the run every time it fails but I guess that's less than optimal plus this way I can really only run one sample at the time. For the interactive sessions I request 180G and 64cpus (in my case it's: ```srsh --mem=180G --cpus-per-task=64 --partition=long```). . I would request same parameters when using --cluster so:; ```snakemake --cluster ""sbatch --mem=180G cpus-per-task=64"" --jobs 64 --profie profile/ ```(where profile holds singularity args etc.). Singularity image is deepvariant_1.4.0.sif. my Snakemake rule:. ```; rule deepvariant:; input:; bam=rules.apply_bqsr.output.bam,; ref='/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta'; output:; vcf=""results/deepvariant/{sample}.vcf.gz""; params:; model=""WES""; threads: ; 64; resources:; mem_mb=163840; log:; ""logs/deepvariant/{sample}/stdout.log""; singularity:; ""singularity/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:2294,Energy Efficiency,schedul,scheduler,2294,"le deepvariant:; input:; bam=rules.apply_bqsr.output.bam,; ref='/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta'; output:; vcf=""results/deepvariant/{sample}.vcf.gz""; params:; model=""WES""; threads: ; 64; resources:; mem_mb=163840; log:; ""logs/deepvariant/{sample}/stdout.log""; singularity:; ""singularity/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of the log file. I am happy to include the entire log file but there is nothing out of the ordinary between those lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided cores: 64; Rules claiming more threads will be scaled down.; Select jobs to execute... > [Wed Jan 4 18:30:51 2023]; > rule deepvariant:; > input: results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam, /mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta; > output: results/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2.vcf.gz; > log: logs/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2/stdout.log; > jobid: 0; > wildcards: sample=s534_EKDN210017195-1A_HTTJ3DSX2_L2; > threads: 64; > resources: mem_mb=163840, disk_mb=16401, tmpdir=/tmp/kmarians_4189323; > ; > Activating singularity image singularity/deepvariant_1.4.0.sif; > INFO: Convert SIF",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:3259,Modifiability,sandbox,sandbox,3259,"y run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided cores: 64; Rules claiming more threads will be scaled down.; Select jobs to execute... > [Wed Jan 4 18:30:51 2023]; > rule deepvariant:; > input: results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam, /mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta; > output: results/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2.vcf.gz; > log: logs/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2/stdout.log; > jobid: 0; > wildcards: sample=s534_EKDN210017195-1A_HTTJ3DSX2_L2; > threads: 64; > resources: mem_mb=163840, disk_mb=16401, tmpdir=/tmp/kmarians_4189323; > ; > Activating singularity image singularity/deepvariant_1.4.0.sif; > INFO: Convert SIF file to sandbox...; > I0104 18:31:03.183642 139718628308800 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/kmarians_4189323/tmpxrz5rqbp; > ; > ***** Intermediate results will be written to /tmp/kmarians_4189323/tmpxrz5rqbp in docker. ****; > ; > ; > ***** Running the command:*****; > time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta"" --reads ""results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam"" --examples ""/tmp/kmarians_4189323/tmpxrz5rqbp/make_examples.tfrecord@64.gz"" --channels ""insert_size"" --vsc_min_count_indels ""3"" --vsc_min_count_snps ""3"" --vsc_min_fraction_indels ""0.10"" --vsc_min_fraction_snps ""0.2"" --task {}. > *; > *; > *; > I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; > I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:6207,Modifiability,variab,variables,6207,"s_4189323/Bazel.runfiles_zims94rl/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; > tf.compat.v1.app.run(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run; > _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/absl_py/absl/app.py"", line 300, in run; > _run_main(main, args); > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/absl_py/absl/app.py"", line 251, in _run_main; > sys.exit(main(argv)); > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; > call_variants(; > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in call_variants; > init_op = tf.group(tf.compat.v1.global_variables_initializer(),; > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py"", line 3319, in global_variables_initializer; > return variables_initializer(global_variables()); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py"", line 3139, in global_variables; > return ops.get_collection(ops.GraphKeys.GLOBAL_VARIABLES, scope); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 6605, in get_collection; > return get_default_graph().get_collection(key, scope); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 6231, in get_default_graph; > return _default_graph_stack.get_default(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 5742, in get_default; > self._global_default_graph = Graph(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3113, in __init__; > self._scoped_c_graph = c_api_util.ScopedTFGraph(); > File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:6387,Modifiability,variab,variables,6387,"ist-packages/tensorflow/python/platform/app.py"", line 40, in run; > _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/absl_py/absl/app.py"", line 300, in run; > _run_main(main, args); > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/absl_py/absl/app.py"", line 251, in _run_main; > sys.exit(main(argv)); > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; > call_variants(; > File ""/tmp/kmarians_4189323/Bazel.runfiles_zims94rl/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in call_variants; > init_op = tf.group(tf.compat.v1.global_variables_initializer(),; > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py"", line 3319, in global_variables_initializer; > return variables_initializer(global_variables()); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py"", line 3139, in global_variables; > return ops.get_collection(ops.GraphKeys.GLOBAL_VARIABLES, scope); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 6605, in get_collection; > return get_default_graph().get_collection(key, scope); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 6231, in get_default_graph; > return _default_graph_stack.get_default(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 5742, in get_default; > self._global_default_graph = Graph(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3113, in __init__; > self._scoped_c_graph = c_api_util.ScopedTFGraph(); > File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/c_api_util.py"", line 50, in __init__; > self.graph = c_api.TF_NewGraph(); > RuntimeError: random_device::random_device(const std::string&): device not ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:704,Testability,log,log,704,"Hi DeepVariant team,. I'm running DeepVariant via Singularity via Snakemake on a HPC cluster and overall, if I create an interactive session, my entire WES pipeline runs fine until an odd DeepVariant job fails (by that I mean that let's say 30 deepvariant jobs finish ok and the 31st fails). I can then restart the Snakemake run and the same job will run fine, followed by more jobs that will also run fine until another odd jobs fails. This is also particularly true when I use the --cluster command in Snakemake (i.e., send it to a SLURM job scheduler from the master node) - in this event every single job fails. I could of course run all my samples on a single interactive session, keep checking the log file and restart the run every time it fails but I guess that's less than optimal plus this way I can really only run one sample at the time. For the interactive sessions I request 180G and 64cpus (in my case it's: ```srsh --mem=180G --cpus-per-task=64 --partition=long```). . I would request same parameters when using --cluster so:; ```snakemake --cluster ""sbatch --mem=180G cpus-per-task=64"" --jobs 64 --profie profile/ ```(where profile holds singularity args etc.). Singularity image is deepvariant_1.4.0.sif. my Snakemake rule:. ```; rule deepvariant:; input:; bam=rules.apply_bqsr.output.bam,; ref='/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta'; output:; vcf=""results/deepvariant/{sample}.vcf.gz""; params:; model=""WES""; threads: ; 64; resources:; mem_mb=163840; log:; ""logs/deepvariant/{sample}/stdout.log""; singularity:; ""singularity/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:1515,Testability,log,log,1515," in Snakemake (i.e., send it to a SLURM job scheduler from the master node) - in this event every single job fails. I could of course run all my samples on a single interactive session, keep checking the log file and restart the run every time it fails but I guess that's less than optimal plus this way I can really only run one sample at the time. For the interactive sessions I request 180G and 64cpus (in my case it's: ```srsh --mem=180G --cpus-per-task=64 --partition=long```). . I would request same parameters when using --cluster so:; ```snakemake --cluster ""sbatch --mem=180G cpus-per-task=64"" --jobs 64 --profie profile/ ```(where profile holds singularity args etc.). Singularity image is deepvariant_1.4.0.sif. my Snakemake rule:. ```; rule deepvariant:; input:; bam=rules.apply_bqsr.output.bam,; ref='/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta'; output:; vcf=""results/deepvariant/{sample}.vcf.gz""; params:; model=""WES""; threads: ; 64; resources:; mem_mb=163840; log:; ""logs/deepvariant/{sample}/stdout.log""; singularity:; ""singularity/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of the log file. I am happy to include the entire log file but there is nothing out of the ordinary between those lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:1522,Testability,log,logs,1522," in Snakemake (i.e., send it to a SLURM job scheduler from the master node) - in this event every single job fails. I could of course run all my samples on a single interactive session, keep checking the log file and restart the run every time it fails but I guess that's less than optimal plus this way I can really only run one sample at the time. For the interactive sessions I request 180G and 64cpus (in my case it's: ```srsh --mem=180G --cpus-per-task=64 --partition=long```). . I would request same parameters when using --cluster so:; ```snakemake --cluster ""sbatch --mem=180G cpus-per-task=64"" --jobs 64 --profie profile/ ```(where profile holds singularity args etc.). Singularity image is deepvariant_1.4.0.sif. my Snakemake rule:. ```; rule deepvariant:; input:; bam=rules.apply_bqsr.output.bam,; ref='/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta'; output:; vcf=""results/deepvariant/{sample}.vcf.gz""; params:; model=""WES""; threads: ; 64; resources:; mem_mb=163840; log:; ""logs/deepvariant/{sample}/stdout.log""; singularity:; ""singularity/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of the log file. I am happy to include the entire log file but there is nothing out of the ordinary between those lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:1555,Testability,log,log,1555,"in this event every single job fails. I could of course run all my samples on a single interactive session, keep checking the log file and restart the run every time it fails but I guess that's less than optimal plus this way I can really only run one sample at the time. For the interactive sessions I request 180G and 64cpus (in my case it's: ```srsh --mem=180G --cpus-per-task=64 --partition=long```). . I would request same parameters when using --cluster so:; ```snakemake --cluster ""sbatch --mem=180G cpus-per-task=64"" --jobs 64 --profie profile/ ```(where profile holds singularity args etc.). Singularity image is deepvariant_1.4.0.sif. my Snakemake rule:. ```; rule deepvariant:; input:; bam=rules.apply_bqsr.output.bam,; ref='/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta'; output:; vcf=""results/deepvariant/{sample}.vcf.gz""; params:; model=""WES""; threads: ; 64; resources:; mem_mb=163840; log:; ""logs/deepvariant/{sample}/stdout.log""; singularity:; ""singularity/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of the log file. I am happy to include the entire log file but there is nothing out of the ordinary between those lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:2006,Testability,log,log,2006,"d request same parameters when using --cluster so:; ```snakemake --cluster ""sbatch --mem=180G cpus-per-task=64"" --jobs 64 --profie profile/ ```(where profile holds singularity args etc.). Singularity image is deepvariant_1.4.0.sif. my Snakemake rule:. ```; rule deepvariant:; input:; bam=rules.apply_bqsr.output.bam,; ref='/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta'; output:; vcf=""results/deepvariant/{sample}.vcf.gz""; params:; model=""WES""; threads: ; 64; resources:; mem_mb=163840; log:; ""logs/deepvariant/{sample}/stdout.log""; singularity:; ""singularity/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of the log file. I am happy to include the entire log file but there is nothing out of the ordinary between those lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided cores: 64; Rules claiming more threads will be scaled down.; Select jobs to execute... > [Wed Jan 4 18:30:51 2023]; > rule deepvariant:; > input: results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam, /mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta; > output: results/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2.vcf.gz; > log: logs/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:2049,Testability,log,log,2049,"sk=64"" --jobs 64 --profie profile/ ```(where profile holds singularity args etc.). Singularity image is deepvariant_1.4.0.sif. my Snakemake rule:. ```; rule deepvariant:; input:; bam=rules.apply_bqsr.output.bam,; ref='/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta'; output:; vcf=""results/deepvariant/{sample}.vcf.gz""; params:; model=""WES""; threads: ; 64; resources:; mem_mb=163840; log:; ""logs/deepvariant/{sample}/stdout.log""; singularity:; ""singularity/deepvariant_1.4.0.sif""; # ""singularity/deepvariant_1.4.0-gpu.sif"" # for GPU; shell:; """"""; /opt/deepvariant/bin/run_deepvariant --model_type {params.model} --ref {input.ref} --reads {input.bam} --output_vcf {output.vcf} --num_shards {threads} --make_examples_extra_args='vsc_min_count_snps=3,vsc_min_fraction_snps=0.2,vsc_min_count_indels=3,vsc_min_fraction_indels=0.10'; """"""; ```. Below is the begening and end of the log file. I am happy to include the entire log file but there is nothing out of the ordinary between those lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided cores: 64; Rules claiming more threads will be scaled down.; Select jobs to execute... > [Wed Jan 4 18:30:51 2023]; > rule deepvariant:; > input: results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam, /mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta; > output: results/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2.vcf.gz; > log: logs/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2/stdout.log; > jobid: 0; > wildcards: sample=s534_EKDN210017195-1A_HTTJ3DSX2_L2; > threads: 64; > resourc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:2936,Testability,log,log,2936,"``. Below is the begening and end of the log file. I am happy to include the entire log file but there is nothing out of the ordinary between those lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided cores: 64; Rules claiming more threads will be scaled down.; Select jobs to execute... > [Wed Jan 4 18:30:51 2023]; > rule deepvariant:; > input: results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam, /mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta; > output: results/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2.vcf.gz; > log: logs/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2/stdout.log; > jobid: 0; > wildcards: sample=s534_EKDN210017195-1A_HTTJ3DSX2_L2; > threads: 64; > resources: mem_mb=163840, disk_mb=16401, tmpdir=/tmp/kmarians_4189323; > ; > Activating singularity image singularity/deepvariant_1.4.0.sif; > INFO: Convert SIF file to sandbox...; > I0104 18:31:03.183642 139718628308800 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/kmarians_4189323/tmpxrz5rqbp; > ; > ***** Intermediate results will be written to /tmp/kmarians_4189323/tmpxrz5rqbp in docker. ****; > ; > ; > ***** Running the command:*****; > time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta"" --reads ""results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam"" --examples ""/tmp/kmarians_4189323/tmpxrz5rqbp/make_examples.tfrecord@64.gz"" --channels ""insert_size"" --vsc_min_count_indels ""3"" --vsc_min_cou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:2941,Testability,log,logs,2941,"``. Below is the begening and end of the log file. I am happy to include the entire log file but there is nothing out of the ordinary between those lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided cores: 64; Rules claiming more threads will be scaled down.; Select jobs to execute... > [Wed Jan 4 18:30:51 2023]; > rule deepvariant:; > input: results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam, /mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta; > output: results/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2.vcf.gz; > log: logs/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2/stdout.log; > jobid: 0; > wildcards: sample=s534_EKDN210017195-1A_HTTJ3DSX2_L2; > threads: 64; > resources: mem_mb=163840, disk_mb=16401, tmpdir=/tmp/kmarians_4189323; > ; > Activating singularity image singularity/deepvariant_1.4.0.sif; > INFO: Convert SIF file to sandbox...; > I0104 18:31:03.183642 139718628308800 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/kmarians_4189323/tmpxrz5rqbp; > ; > ***** Intermediate results will be written to /tmp/kmarians_4189323/tmpxrz5rqbp in docker. ****; > ; > ; > ***** Running the command:*****; > time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta"" --reads ""results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam"" --examples ""/tmp/kmarians_4189323/tmpxrz5rqbp/make_examples.tfrecord@64.gz"" --channels ""insert_size"" --vsc_min_count_indels ""3"" --vsc_min_cou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:3000,Testability,log,log,3000,"e lines below (same output as for jobs that finished successfully). Could you please advise on what parameters to change to successfully run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided cores: 64; Rules claiming more threads will be scaled down.; Select jobs to execute... > [Wed Jan 4 18:30:51 2023]; > rule deepvariant:; > input: results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam, /mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta; > output: results/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2.vcf.gz; > log: logs/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2/stdout.log; > jobid: 0; > wildcards: sample=s534_EKDN210017195-1A_HTTJ3DSX2_L2; > threads: 64; > resources: mem_mb=163840, disk_mb=16401, tmpdir=/tmp/kmarians_4189323; > ; > Activating singularity image singularity/deepvariant_1.4.0.sif; > INFO: Convert SIF file to sandbox...; > I0104 18:31:03.183642 139718628308800 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/kmarians_4189323/tmpxrz5rqbp; > ; > ***** Intermediate results will be written to /tmp/kmarians_4189323/tmpxrz5rqbp in docker. ****; > ; > ; > ***** Running the command:*****; > time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta"" --reads ""results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam"" --examples ""/tmp/kmarians_4189323/tmpxrz5rqbp/make_examples.tfrecord@64.gz"" --channels ""insert_size"" --vsc_min_count_indels ""3"" --vsc_min_count_snps ""3"" --vsc_min_fraction_indels ""0.10"" --vsc_min_fraction_snps ""0.2"" --task {}. > *; > *; > *; > I0104 18:49:24.340415 140179943589696 make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/602:3259,Testability,sandbox,sandbox,3259,"y run DeepVariant by submitting it to the SLURM scheduler? ; I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task 13/64: Created 2879 examples. Building DAG of jobs...; Using shell: /usr/bin/bash; Provided cores: 64; Rules claiming more threads will be scaled down.; Select jobs to execute... > [Wed Jan 4 18:30:51 2023]; > rule deepvariant:; > input: results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam, /mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta; > output: results/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2.vcf.gz; > log: logs/deepvariant/s534_EKDN210017195-1A_HTTJ3DSX2_L2/stdout.log; > jobid: 0; > wildcards: sample=s534_EKDN210017195-1A_HTTJ3DSX2_L2; > threads: 64; > resources: mem_mb=163840, disk_mb=16401, tmpdir=/tmp/kmarians_4189323; > ; > Activating singularity image singularity/deepvariant_1.4.0.sif; > INFO: Convert SIF file to sandbox...; > I0104 18:31:03.183642 139718628308800 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/kmarians_4189323/tmpxrz5rqbp; > ; > ***** Intermediate results will be written to /tmp/kmarians_4189323/tmpxrz5rqbp in docker. ****; > ; > ; > ***** Running the command:*****; > time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/mnt/shared/scratch/kmarians/private/dyslexia_gatk/workflow/resources/genome.fasta"" --reads ""results/recal/s534_EKDN210017195-1A_HTTJ3DSX2_L2.bam"" --examples ""/tmp/kmarians_4189323/tmpxrz5rqbp/make_examples.tfrecord@64.gz"" --channels ""insert_size"" --vsc_min_count_indels ""3"" --vsc_min_count_snps ""3"" --vsc_min_fraction_indels ""0.10"" --vsc_min_fraction_snps ""0.2"" --task {}. > *; > *; > *; > I0104 18:49:24.340415 140179943589696 make_examples_core.py:243] Task 13/64: Found 2793 candidate variants; > I0104 18:49:24.340478 140179943589696 make_examples_core.py:243] Task",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/602
https://github.com/google/deepvariant/issues/603:772,Availability,Error,Error,772,"Hi,. I have encountered a somewhat unexpected behavior related to the sample name written to the output VCF (possibly caused by the presence of chrEBV?!). **Describe the issue:**; Sample name ""default"" is used in the output VCF for ""chrEBV"", all other chromosome VCFs contain correct sample name (chr1-chr22,chrX,chrY,chrM). **Setup**; - Operating system: CentOS; - DeepVariant version: v1.2; - Installation method (Docker, built from source, etc.): Singularity v3.5.2; - Type of data: PacBio HiFi, Sequel-II. **Steps to reproduce:**; - Command:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type=""PACBIO"" \; --regions ""$CHROM""; [ ... otherwise default options ...]; ```; - note: the input BAM alignment contains the sample name in the header (i.e. `SM:HG002`); - Error trace: (n/a - run finishes). **Does the quick start test work on your system?**; can't be used to reproduce the problem. **Any additional context:**; In the log for each chromosome run, I see that all chromosomes except chrEBV are listed in lines like this; ```; I0112 10:31:04.917984 47443049531200 \; make_examples_core.py:236] \; Task 6/12: Common contigs are [ HERE: list of all chromosomes except for chrEBV]; ```. Best,; Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/603
https://github.com/google/deepvariant/issues/603:395,Deployability,Install,Installation,395,"Hi,. I have encountered a somewhat unexpected behavior related to the sample name written to the output VCF (possibly caused by the presence of chrEBV?!). **Describe the issue:**; Sample name ""default"" is used in the output VCF for ""chrEBV"", all other chromosome VCFs contain correct sample name (chr1-chr22,chrX,chrY,chrM). **Setup**; - Operating system: CentOS; - DeepVariant version: v1.2; - Installation method (Docker, built from source, etc.): Singularity v3.5.2; - Type of data: PacBio HiFi, Sequel-II. **Steps to reproduce:**; - Command:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type=""PACBIO"" \; --regions ""$CHROM""; [ ... otherwise default options ...]; ```; - note: the input BAM alignment contains the sample name in the header (i.e. `SM:HG002`); - Error trace: (n/a - run finishes). **Does the quick start test work on your system?**; can't be used to reproduce the problem. **Any additional context:**; In the log for each chromosome run, I see that all chromosomes except chrEBV are listed in lines like this; ```; I0112 10:31:04.917984 47443049531200 \; make_examples_core.py:236] \; Task 6/12: Common contigs are [ HERE: list of all chromosomes except for chrEBV]; ```. Best,; Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/603
https://github.com/google/deepvariant/issues/603:830,Testability,test,test,830,"Hi,. I have encountered a somewhat unexpected behavior related to the sample name written to the output VCF (possibly caused by the presence of chrEBV?!). **Describe the issue:**; Sample name ""default"" is used in the output VCF for ""chrEBV"", all other chromosome VCFs contain correct sample name (chr1-chr22,chrX,chrY,chrM). **Setup**; - Operating system: CentOS; - DeepVariant version: v1.2; - Installation method (Docker, built from source, etc.): Singularity v3.5.2; - Type of data: PacBio HiFi, Sequel-II. **Steps to reproduce:**; - Command:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type=""PACBIO"" \; --regions ""$CHROM""; [ ... otherwise default options ...]; ```; - note: the input BAM alignment contains the sample name in the header (i.e. `SM:HG002`); - Error trace: (n/a - run finishes). **Does the quick start test work on your system?**; can't be used to reproduce the problem. **Any additional context:**; In the log for each chromosome run, I see that all chromosomes except chrEBV are listed in lines like this; ```; I0112 10:31:04.917984 47443049531200 \; make_examples_core.py:236] \; Task 6/12: Common contigs are [ HERE: list of all chromosomes except for chrEBV]; ```. Best,; Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/603
https://github.com/google/deepvariant/issues/603:935,Testability,log,log,935,"Hi,. I have encountered a somewhat unexpected behavior related to the sample name written to the output VCF (possibly caused by the presence of chrEBV?!). **Describe the issue:**; Sample name ""default"" is used in the output VCF for ""chrEBV"", all other chromosome VCFs contain correct sample name (chr1-chr22,chrX,chrY,chrM). **Setup**; - Operating system: CentOS; - DeepVariant version: v1.2; - Installation method (Docker, built from source, etc.): Singularity v3.5.2; - Type of data: PacBio HiFi, Sequel-II. **Steps to reproduce:**; - Command:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type=""PACBIO"" \; --regions ""$CHROM""; [ ... otherwise default options ...]; ```; - note: the input BAM alignment contains the sample name in the header (i.e. `SM:HG002`); - Error trace: (n/a - run finishes). **Does the quick start test work on your system?**; can't be used to reproduce the problem. **Any additional context:**; In the log for each chromosome run, I see that all chromosomes except chrEBV are listed in lines like this; ```; I0112 10:31:04.917984 47443049531200 \; make_examples_core.py:236] \; Task 6/12: Common contigs are [ HERE: list of all chromosomes except for chrEBV]; ```. Best,; Peter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/603
https://github.com/google/deepvariant/issues/604:181,Availability,error,error,181,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Had an issue with the quickstart tutorial where I received this error:; ```; /usr/bin/docker-current: Error parsing reference: ""docker.io/google/deepvariant:"" is not a valid repository/tag: invalid reference format.; See '/usr/bin/docker-current run --help'.; deepvariant_test.sh: line 11: make_examples: command not found; deepvariant_test.sh: line 11: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory; ```. The problem seemed to be that the [quickstart](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md) omits declaring `BIN_VERSION=""1.4.0""`, although it is declared on the [main page](https://github.com/google/deepvariant). **Solution**; ```; docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; -v ""${BIN_VERSION}"":; docker.io/google/deepvariant \; /opt/deepvariant/bin/run_deepvariant \; ...; ```; Should be ; ```; BIN_VERSION=""1.4.0""; docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; -v ""${BIN_VERSION}"":; docker.io/google/deepvariant \; /opt/deepvariant/bin/run_deepvariant \; ...; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/604
https://github.com/google/deepvariant/issues/604:219,Availability,Error,Error,219,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:. **Describe the issue:**; Had an issue with the quickstart tutorial where I received this error:; ```; /usr/bin/docker-current: Error parsing reference: ""docker.io/google/deepvariant:"" is not a valid repository/tag: invalid reference format.; See '/usr/bin/docker-current run --help'.; deepvariant_test.sh: line 11: make_examples: command not found; deepvariant_test.sh: line 11: --ref=/input/ucsc.hg19.chr20.unittest.fasta: No such file or directory; ```. The problem seemed to be that the [quickstart](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md) omits declaring `BIN_VERSION=""1.4.0""`, although it is declared on the [main page](https://github.com/google/deepvariant). **Solution**; ```; docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; -v ""${BIN_VERSION}"":; docker.io/google/deepvariant \; /opt/deepvariant/bin/run_deepvariant \; ...; ```; Should be ; ```; BIN_VERSION=""1.4.0""; docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; -v ""${BIN_VERSION}"":; docker.io/google/deepvariant \; /opt/deepvariant/bin/run_deepvariant \; ...; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/604
https://github.com/google/deepvariant/issues/605:224,Availability,avail,available,224,"Hello DeepVariant team,. I am currently interested in using your software for variant calling from RNA-sequencing data. After reading the [preprint](https://doi.org/10.1101/2022.10.16.512451) I understand that there are two available models for such purpose: ""DV RNA-seq [GTEx]"" and ""DV RNA-seq [GIAB]"". I see that ""DV RNA-seq [GIAB]"" is used in the [RNA-seq case study](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) and downloadable through the urls provided there, but I have not been able to find urls for the GTEx model. Is it yet to be made available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/605
https://github.com/google/deepvariant/issues/605:462,Availability,down,downloadable,462,"Hello DeepVariant team,. I am currently interested in using your software for variant calling from RNA-sequencing data. After reading the [preprint](https://doi.org/10.1101/2022.10.16.512451) I understand that there are two available models for such purpose: ""DV RNA-seq [GTEx]"" and ""DV RNA-seq [GIAB]"". I see that ""DV RNA-seq [GIAB]"" is used in the [RNA-seq case study](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) and downloadable through the urls provided there, but I have not been able to find urls for the GTEx model. Is it yet to be made available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/605
https://github.com/google/deepvariant/issues/605:587,Availability,avail,available,587,"Hello DeepVariant team,. I am currently interested in using your software for variant calling from RNA-sequencing data. After reading the [preprint](https://doi.org/10.1101/2022.10.16.512451) I understand that there are two available models for such purpose: ""DV RNA-seq [GTEx]"" and ""DV RNA-seq [GIAB]"". I see that ""DV RNA-seq [GIAB]"" is used in the [RNA-seq case study](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) and downloadable through the urls provided there, but I have not been able to find urls for the GTEx model. Is it yet to be made available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/605
https://github.com/google/deepvariant/issues/606:116,Availability,error,errors,116,"I tried to run the model on one of the Arabidopsis thaliana sample from 1001 genomes website. Without reporting any errors, the model ran perfectly fine (make_examples, call_variants, postprocess_variants). But when evaluating the results against the ground truth on all chromosomes, it returns error stating that records at specific positions disagree on what the reference bases should be. I attached the screenshot for reference to give you an idea. ; <img width=""1499"" alt=""Screenshot 2023-01-25 at 12 32 33"" src=""https://user-images.githubusercontent.com/75676816/214554128-84fd25af-90b4-4110-be27-c2344a840bc4.png"">",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/606
https://github.com/google/deepvariant/issues/606:295,Availability,error,error,295,"I tried to run the model on one of the Arabidopsis thaliana sample from 1001 genomes website. Without reporting any errors, the model ran perfectly fine (make_examples, call_variants, postprocess_variants). But when evaluating the results against the ground truth on all chromosomes, it returns error stating that records at specific positions disagree on what the reference bases should be. I attached the screenshot for reference to give you an idea. ; <img width=""1499"" alt=""Screenshot 2023-01-25 at 12 32 33"" src=""https://user-images.githubusercontent.com/75676816/214554128-84fd25af-90b4-4110-be27-c2344a840bc4.png"">",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/606
https://github.com/google/deepvariant/issues/607:167,Integrability,depend,dependencies,167,"Hello,. I am trying to build DeepVaraint with Tensorflow 2.11.0. I modified ""settings.h"" and ""build-prereq.sh"" to initialize the respective version of bazel and other dependencies. However, I am not able to build successfully. ; Could you please guide me towards upgrading Tensorflow to 2.11.0 and any required modifications to the source code? . Thanks,; Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/607
https://github.com/google/deepvariant/issues/607:246,Usability,guid,guide,246,"Hello,. I am trying to build DeepVaraint with Tensorflow 2.11.0. I modified ""settings.h"" and ""build-prereq.sh"" to initialize the respective version of bazel and other dependencies. However, I am not able to build successfully. ; Could you please guide me towards upgrading Tensorflow to 2.11.0 and any required modifications to the source code? . Thanks,; Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/607
https://github.com/google/deepvariant/issues/608:119,Availability,down,download,119,"I was able to build the docker image last week, but this week the build fails at binary creation, with bazel unable to download tf_runtime. . - Operating system: Ubuntu20.04; - DeepVariant version: 1.4.0; - Building docker image locally. **Steps to reproduce:**; - Command: `docker build .` in source directory (no modifications); - Error trace: ; ; ```; #16 1484.7 ========== [Mon Jan 30 21:50:56 UTC 2023] Stage 'build-prereq.sh complete' starting; #16 1484.7 Extracting Bazel installation...; #16 1487.8 Starting local Bazel server and connecting to it...; #16 1489.8 (21:51:01) WARNING: option '--distinct_host_configuration' was expanded to from both option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc) and option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc); #16 1489.8 (21:51:01) INFO: Options provided by the client:; #16 1489.8 Inherited 'common' options: --isatty=0 --terminal_columns=80; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:333,Availability,Error,Error,333,"I was able to build the docker image last week, but this week the build fails at binary creation, with bazel unable to download tf_runtime. . - Operating system: Ubuntu20.04; - DeepVariant version: 1.4.0; - Building docker image locally. **Steps to reproduce:**; - Command: `docker build .` in source directory (no modifications); - Error trace: ; ; ```; #16 1484.7 ========== [Mon Jan 30 21:50:56 UTC 2023] Stage 'build-prereq.sh complete' starting; #16 1484.7 Extracting Bazel installation...; #16 1487.8 Starting local Bazel server and connecting to it...; #16 1489.8 (21:51:01) WARNING: option '--distinct_host_configuration' was expanded to from both option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc) and option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc); #16 1489.8 (21:51:01) INFO: Options provided by the client:; #16 1489.8 Inherited 'common' options: --isatty=0 --terminal_columns=80; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5995,Availability,Down,Download,5995,".2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:6185,Availability,down,downloader,6185,"#16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:6282,Availability,Down,Download,6282,"/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:6451,Availability,down,downloader,6451,"rkspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:6666,Availability,ERROR,ERROR,6666,"l/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/W",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:6676,Availability,error,error,6676,"l/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/W",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:7007,Availability,Error,Error,7007,"ensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:7059,Availability,Error,Error,7059,"rchive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/6170",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:7065,Availability,down,downloading,7065,"rchive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/6170",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:8442,Availability,ERROR,ERROR,8442," was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:8503,Availability,Error,Error,8503,"6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ------; > [builder 6/6] RUN ./build-prere",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:8509,Availability,down,downloading,8509,"6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ------; > [builder 6/6] RUN ./build-prere",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:9320,Availability,ERROR,ERROR,9320,"80/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ------; > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:; ------; executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:479,Deployability,install,installation,479,"I was able to build the docker image last week, but this week the build fails at binary creation, with bazel unable to download tf_runtime. . - Operating system: Ubuntu20.04; - DeepVariant version: 1.4.0; - Building docker image locally. **Steps to reproduce:**; - Command: `docker build .` in source directory (no modifications); - Error trace: ; ; ```; #16 1484.7 ========== [Mon Jan 30 21:50:56 UTC 2023] Stage 'build-prereq.sh complete' starting; #16 1484.7 Extracting Bazel installation...; #16 1487.8 Starting local Bazel server and connecting to it...; #16 1489.8 (21:51:01) WARNING: option '--distinct_host_configuration' was expanded to from both option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc) and option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc); #16 1489.8 (21:51:01) INFO: Options provided by the client:; #16 1489.8 Inherited 'common' options: --isatty=0 --terminal_columns=80; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:887,Modifiability,Inherit,Inherited,887,"I was able to build the docker image last week, but this week the build fails at binary creation, with bazel unable to download tf_runtime. . - Operating system: Ubuntu20.04; - DeepVariant version: 1.4.0; - Building docker image locally. **Steps to reproduce:**; - Command: `docker build .` in source directory (no modifications); - Error trace: ; ; ```; #16 1484.7 ========== [Mon Jan 30 21:50:56 UTC 2023] Stage 'build-prereq.sh complete' starting; #16 1484.7 Extracting Bazel installation...; #16 1487.8 Starting local Bazel server and connecting to it...; #16 1489.8 (21:51:01) WARNING: option '--distinct_host_configuration' was expanded to from both option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc) and option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc); #16 1489.8 (21:51:01) INFO: Options provided by the client:; #16 1489.8 Inherited 'common' options: --isatty=0 --terminal_columns=80; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:1051,Modifiability,Inherit,Inherited,1051,"ry creation, with bazel unable to download tf_runtime. . - Operating system: Ubuntu20.04; - DeepVariant version: 1.4.0; - Building docker image locally. **Steps to reproduce:**; - Command: `docker build .` in source directory (no modifications); - Error trace: ; ; ```; #16 1484.7 ========== [Mon Jan 30 21:50:56 UTC 2023] Stage 'build-prereq.sh complete' starting; #16 1484.7 Extracting Bazel installation...; #16 1487.8 Starting local Bazel server and connecting to it...; #16 1489.8 (21:51:01) WARNING: option '--distinct_host_configuration' was expanded to from both option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc) and option '--enable_platform_specific_config' (source /opt/tensorflow/.bazelrc); #16 1489.8 (21:51:01) INFO: Options provided by the client:; #16 1489.8 Inherited 'common' options: --isatty=0 --terminal_columns=80; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:1666,Modifiability,config,config,1666,"zelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --act",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:1686,Modifiability,config,config,1686,"zelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --act",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:3266,Modifiability,config,config,3266,"rt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages --python_path=/usr/local/bin/python3; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/deepvariant/.bazelrc:; #16 1489.8 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:short_logs in file /opt/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:v2 in file /opt/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_gu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:3567,Modifiability,config,config,3567,"e_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages --python_path=/usr/local/bin/python3; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/deepvariant/.bazelrc:; #16 1489.8 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:short_logs in file /opt/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:v2 in file /opt/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:3718,Modifiability,config,config,3718,"ow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages --python_path=/usr/local/bin/python3; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/deepvariant/.bazelrc:; #16 1489.8 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:short_logs in file /opt/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:v2 in file /opt/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:3879,Modifiability,config,config,3879,or 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages --python_path=/usr/local/bin/python3; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/deepvariant/.bazelrc:; #16 1489.8 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:short_logs in file /opt/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:v2 in file /opt/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4033,Modifiability,config,config,4033,THON_LIB_PATH=/usr/local/lib/python3.8/dist-packages --python_path=/usr/local/bin/python3; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/deepvariant/.bazelrc:; #16 1489.8 'build' options: --jobs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:short_logs in file /opt/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:v2 in file /opt/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4307,Modifiability,config,config,4307,obs 128 --config=monolithic --show_timestamps --verbose_failures --define=use_fast_cpp_protos=true --copt=-Wno-maybe-uninitialized --copt=-Wno-unused-function --cxxopt=-std=c++17 --python_top=//:deepvariant_python_runtime --incompatible_use_python_toolchains=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:short_logs in file /opt/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:v2 in file /opt/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4460,Modifiability,config,config,4460,ime --incompatible_use_python_toolchains=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:short_logs in file /opt/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:v2 in file /opt/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4651,Modifiability,config,config,4651,H_ANYTHING; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:v2 in file /opt/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/61,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4830,Performance,Load,Loading,4830, #16 1489.8 (21:51:01) INFO: Found applicable config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4862,Performance,Load,Loading,4862,able config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44d,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4882,Performance,load,loaded,4882,able config definition build:monolithic in file /opt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44d,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4912,Performance,Load,Loading,4912,pt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/thi,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4932,Performance,load,loaded,4932,pt/tensorflow/.bazelrc: --define framework_shared_object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/thi,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4962,Performance,Load,Loading,4962,object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:4982,Performance,load,loaded,4982,object=false; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5012,Performance,Load,Loading,5012,plicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.t,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5032,Performance,load,loaded,5032,plicable config definition build:linux in file /opt/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.t,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5062,Performance,Load,Loading,5062,t/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archiv,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5082,Performance,load,loaded,5082,t/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archiv,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5112,Performance,Load,Loading,5112,define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5132,Performance,load,loaded,5132,define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5162,Performance,Load,Loading,5162,-define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5182,Performance,load,loaded,5182,-define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5337,Performance,cache,cache,5337,gainst_concurrent_changes; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:dynamic_kernels in file /opt/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5483,Performance,cache,cache,5483,ne=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS; #16 1489.8 (21:51:01) INFO: Found applicable config definition build:linux in file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab46,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5635,Performance,cache,cache,5635,file /opt/deepvariant/.bazelrc: --distinct_host_configuration=true; #16 1490.1 (21:51:01) INFO: Current date is 2023-01-30; #16 1490.1 (21:51:01) Loading:; #16 1490.1 (21:51:01) Loading: 0 packages loaded; #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error oc,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:5840,Performance,cache,cache,5840," #16 1491.1 (21:51:02) Loading: 0 packages loaded; #16 1492.2 (21:51:03) Loading: 0 packages loaded; #16 1493.2 (21:51:04) Loading: 0 packages loaded; #16 1494.2 (21:51:05) Loading: 0 packages loaded; #16 1495.2 (21:51:06) Loading: 0 packages loaded; #16 1496.2 (21:51:07) Loading: 0 packages loaded; #16 1497.0 (21:51:08) INFO: Repository tf_runtime instantiated at:; #16 1497.0 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:28:15: in workspace; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:6808,Performance,cache,cache,6808,"l_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:7299,Performance,cache,cache,7299,"b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:7750,Performance,cache,cache,7750,"/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:7895,Performance,cache,cache,7895,"ve_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:8041,Performance,cache,cache,8041,"r.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:8246,Performance,cache,cache,8246,"ot/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:8392,Performance,Load,Loading,8392,"92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:8412,Performance,load,loaded,8412,"92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:8743,Performance,cache,cache,8743,"80/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ------; > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:; ------; executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:9220,Performance,load,loaded,9220,"80/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ------; > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:; ------; executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:9307,Performance,load,loaded,9307,"80/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ------; > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:; ------; executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:6489,Security,Checksum,Checksum,6489,"orflow/third_party/tf_runtime/workspace.bzl:12:20: in repo; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.0 Repository rule _tf_http_archive defined at:; #16 1497.0 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.0 (21:51:08) WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found; #16 1497.0 (21:51:08) WARNING: Download from https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be93",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:7450,Security,Checksum,Checksum,7450,"d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.0 (21:51:08) ERROR: An error occurred during the fetch of repository 'tf_runtime':; #16 1497.0 Traceback (most recent call last):; #16 1497.0 File ""/root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl"", line 53, column 33, in _tf_http_archive_impl; #16 1497.0 ctx.download_and_extract(; #16 1497.0 Error in download_and_extract: java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.1 (21:51:08) INFO: Repository llvm-raw instantiated at:; #16 1497.1 /opt/deepvariant/WORKSPACE:102:14: in <toplevel>; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:8894,Security,Checksum,Checksum,8894,"80/external/org_tensorflow/tensorflow/workspace3.bzl:42:9: in workspace; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/llvm/workspace.bzl:10:20: in repo; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:113:21: in tf_http_archive; #16 1497.1 Repository rule _tf_http_archive defined at:; #16 1497.1 /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/org_tensorflow/third_party/repo.bzl:66:35: in <toplevel>; #16 1497.2 (21:51:08) Loading: 0 packages loaded; #16 1497.3 (21:51:08) ERROR: no such package '@tf_runtime//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz, https://github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz] to /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/external/tf_runtime/temp12516918929418979294/64c92c8013b557087351c91b5423b6046d10f206.tar.gz: Checksum was 8383b3247286016e450b0b20e805d26b88ab4638b4e4e3cc4a6923debaf7ad1e but wanted f16fcf09b34e0c7be9389f50652b4b4a14c5a8a96e7e15ad73e8f234d8d09ebe; #16 1497.3 (21:51:09) INFO: Elapsed time: 12.546s; #16 1497.3 (21:51:09) INFO: 0 processes.; #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 1497.3 (21:51:09) FAILED: Build did NOT complete successfully (0 packages loaded); #16 ERROR: executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ------; > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:; ------; executor failed running [/bin/sh -c ./build-prereq.sh && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel]: exit code: 1; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:1834,Testability,benchmark,benchmarks,1834,"zelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --act",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:2012,Testability,test,tests,2012,"zelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --act",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:2048,Testability,test,tests,2048,"zelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --act",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/608:2784,Testability,test,tests,2784,"zelrc:; #16 1489.8 Inherited 'common' options: --experimental_repo_remote_exec; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.bazelrc:; #16 1489.8 'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils; #16 1489.8 (21:51:01) INFO: Reading rc options for 'build' from /opt/tensorflow/.tf_configure.bazelrc:; #16 1489.8 'build' options: --action_env PYTHON_BIN_PATH=/usr/local/bin/python3 --act",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/608
https://github.com/google/deepvariant/issues/610:571,Availability,Error,Error,571,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**; Unable to run Singularity image despite prerequisites appearing satisfied. **Setup**; - Operating system: CentOS 7 ; - DeepVariant version: 1.4.0 (google/deepvariant:latest); - Installation method (Docker, built from source, etc.): `singularity pull docker://google/deepvariant:latest` and attempted execution via `singularity run`; - Type of data: N/A. **Steps to reproduce:**; - Command: `singularity run -B /home/ -B /scratch/ deepvariant.sif`; - Error trace:; ```; Traceback (most recent call last):; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 23, in <module>; from . import multiarray; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/multiarray.py"", line 10, in <module>; from . import overrides; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/overrides.py"", line 6, in <module>; from numpy.core._multiarray_umath import (; ImportError: libflexiblas.so.3: cannot open shared object file: No such file or directory. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:2122,Availability,error,error,2122,"r exception occurred:. Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!. Importing the numpy C-extensions failed. This error can happen for; many reasons, often due to issues with your setup or how NumPy was; installed. We have compiled some common reasons and troubleshooting tips at:. https://numpy.org/devdocs/user/troubleshooting-importerror.html. Please note and check the following:. * The Python version is: Python3.8 from ""/usr/bin/python3""; * The NumPy version is: ""1.23.0"". and make sure that they are the versions you expect.; Please carefully study the documentation linked above for further help. Original error was: libflexiblas.so.3: cannot open shared object file: No such file or directory; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? Any attempt to execute via `singularity run` leads to an error. **Any additional context:**; As far as I can tell, my environment meets the requirements for both Python and NumPy - though at the same time when I `singularity shell` int",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:2622,Availability,error,error,2622,"""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!. Importing the numpy C-extensions failed. This error can happen for; many reasons, often due to issues with your setup or how NumPy was; installed. We have compiled some common reasons and troubleshooting tips at:. https://numpy.org/devdocs/user/troubleshooting-importerror.html. Please note and check the following:. * The Python version is: Python3.8 from ""/usr/bin/python3""; * The NumPy version is: ""1.23.0"". and make sure that they are the versions you expect.; Please carefully study the documentation linked above for further help. Original error was: libflexiblas.so.3: cannot open shared object file: No such file or directory; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? Any attempt to execute via `singularity run` leads to an error. **Any additional context:**; As far as I can tell, my environment meets the requirements for both Python and NumPy - though at the same time when I `singularity shell` into the SIF file, its versioning seems semi-independent of my main environment (Python 3.8.10 regardless of my environment's version, but using the NumPy 1.23.0 provided by my computing cluster). I feel like I'm missing something really simple, but I've tried the NumPy troubleshooting page and can't seem to crack this error. If it helps, I'm attempting this with `singularity` version 3.8.4, which is the newest version available to me in my computing cluster.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:2991,Availability,error,error,2991,"""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!. Importing the numpy C-extensions failed. This error can happen for; many reasons, often due to issues with your setup or how NumPy was; installed. We have compiled some common reasons and troubleshooting tips at:. https://numpy.org/devdocs/user/troubleshooting-importerror.html. Please note and check the following:. * The Python version is: Python3.8 from ""/usr/bin/python3""; * The NumPy version is: ""1.23.0"". and make sure that they are the versions you expect.; Please carefully study the documentation linked above for further help. Original error was: libflexiblas.so.3: cannot open shared object file: No such file or directory; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? Any attempt to execute via `singularity run` leads to an error. **Any additional context:**; As far as I can tell, my environment meets the requirements for both Python and NumPy - though at the same time when I `singularity shell` into the SIF file, its versioning seems semi-independent of my main environment (Python 3.8.10 regardless of my environment's version, but using the NumPy 1.23.0 provided by my computing cluster). I feel like I'm missing something really simple, but I've tried the NumPy troubleshooting page and can't seem to crack this error. If it helps, I'm attempting this with `singularity` version 3.8.4, which is the newest version available to me in my computing cluster.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:3487,Availability,error,error,3487,"""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!. Importing the numpy C-extensions failed. This error can happen for; many reasons, often due to issues with your setup or how NumPy was; installed. We have compiled some common reasons and troubleshooting tips at:. https://numpy.org/devdocs/user/troubleshooting-importerror.html. Please note and check the following:. * The Python version is: Python3.8 from ""/usr/bin/python3""; * The NumPy version is: ""1.23.0"". and make sure that they are the versions you expect.; Please carefully study the documentation linked above for further help. Original error was: libflexiblas.so.3: cannot open shared object file: No such file or directory; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? Any attempt to execute via `singularity run` leads to an error. **Any additional context:**; As far as I can tell, my environment meets the requirements for both Python and NumPy - though at the same time when I `singularity shell` into the SIF file, its versioning seems semi-independent of my main environment (Python 3.8.10 regardless of my environment's version, but using the NumPy 1.23.0 provided by my computing cluster). I feel like I'm missing something really simple, but I've tried the NumPy troubleshooting page and can't seem to crack this error. If it helps, I'm attempting this with `singularity` version 3.8.4, which is the newest version available to me in my computing cluster.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:3589,Availability,avail,available,3589,"""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!. Importing the numpy C-extensions failed. This error can happen for; many reasons, often due to issues with your setup or how NumPy was; installed. We have compiled some common reasons and troubleshooting tips at:. https://numpy.org/devdocs/user/troubleshooting-importerror.html. Please note and check the following:. * The Python version is: Python3.8 from ""/usr/bin/python3""; * The NumPy version is: ""1.23.0"". and make sure that they are the versions you expect.; Please carefully study the documentation linked above for further help. Original error was: libflexiblas.so.3: cannot open shared object file: No such file or directory; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? Any attempt to execute via `singularity run` leads to an error. **Any additional context:**; As far as I can tell, my environment meets the requirements for both Python and NumPy - though at the same time when I `singularity shell` into the SIF file, its versioning seems semi-independent of my main environment (Python 3.8.10 regardless of my environment's version, but using the NumPy 1.23.0 provided by my computing cluster). I feel like I'm missing something really simple, but I've tried the NumPy troubleshooting page and can't seem to crack this error. If it helps, I'm attempting this with `singularity` version 3.8.4, which is the newest version available to me in my computing cluster.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:298,Deployability,Install,Installation,298,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**: Yes. **Describe the issue:**; Unable to run Singularity image despite prerequisites appearing satisfied. **Setup**; - Operating system: CentOS 7 ; - DeepVariant version: 1.4.0 (google/deepvariant:latest); - Installation method (Docker, built from source, etc.): `singularity pull docker://google/deepvariant:latest` and attempted execution via `singularity run`; - Type of data: N/A. **Steps to reproduce:**; - Command: `singularity run -B /home/ -B /scratch/ deepvariant.sif`; - Error trace:; ```; Traceback (most recent call last):; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 23, in <module>; from . import multiarray; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/multiarray.py"", line 10, in <module>; from . import overrides; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/overrides.py"", line 6, in <module>; from numpy.core._multiarray_umath import (; ImportError: libflexiblas.so.3: cannot open shared object file: No such file or directory. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:2212,Deployability,install,installed,2212,"r exception occurred:. Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>; from tensorflow.python.tools import module_util as _module_util; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>; from tensorflow.python.eager import context; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!. Importing the numpy C-extensions failed. This error can happen for; many reasons, often due to issues with your setup or how NumPy was; installed. We have compiled some common reasons and troubleshooting tips at:. https://numpy.org/devdocs/user/troubleshooting-importerror.html. Please note and check the following:. * The Python version is: Python3.8 from ""/usr/bin/python3""; * The NumPy version is: ""1.23.0"". and make sure that they are the versions you expect.; Please carefully study the documentation linked above for further help. Original error was: libflexiblas.so.3: cannot open shared object file: No such file or directory; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? Any attempt to execute via `singularity run` leads to an error. **Any additional context:**; As far as I can tell, my environment meets the requirements for both Python and NumPy - though at the same time when I `singularity shell` int",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:2739,Testability,test,test,2739,"""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!. Importing the numpy C-extensions failed. This error can happen for; many reasons, often due to issues with your setup or how NumPy was; installed. We have compiled some common reasons and troubleshooting tips at:. https://numpy.org/devdocs/user/troubleshooting-importerror.html. Please note and check the following:. * The Python version is: Python3.8 from ""/usr/bin/python3""; * The NumPy version is: ""1.23.0"". and make sure that they are the versions you expect.; Please carefully study the documentation linked above for further help. Original error was: libflexiblas.so.3: cannot open shared object file: No such file or directory; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? Any attempt to execute via `singularity run` leads to an error. **Any additional context:**; As far as I can tell, my environment meets the requirements for both Python and NumPy - though at the same time when I `singularity shell` into the SIF file, its versioning seems semi-independent of my main environment (Python 3.8.10 regardless of my environment's version, but using the NumPy 1.23.0 provided by my computing cluster). I feel like I'm missing something really simple, but I've tried the NumPy troubleshooting page and can't seem to crack this error. If it helps, I'm attempting this with `singularity` version 3.8.4, which is the newest version available to me in my computing cluster.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:2775,Testability,test,test,2775,"""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!. Importing the numpy C-extensions failed. This error can happen for; many reasons, often due to issues with your setup or how NumPy was; installed. We have compiled some common reasons and troubleshooting tips at:. https://numpy.org/devdocs/user/troubleshooting-importerror.html. Please note and check the following:. * The Python version is: Python3.8 from ""/usr/bin/python3""; * The NumPy version is: ""1.23.0"". and make sure that they are the versions you expect.; Please carefully study the documentation linked above for further help. Original error was: libflexiblas.so.3: cannot open shared object file: No such file or directory; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? Any attempt to execute via `singularity run` leads to an error. **Any additional context:**; As far as I can tell, my environment meets the requirements for both Python and NumPy - though at the same time when I `singularity shell` into the SIF file, its versioning seems semi-independent of my main environment (Python 3.8.10 regardless of my environment's version, but using the NumPy 1.23.0 provided by my computing cluster). I feel like I'm missing something really simple, but I've tried the NumPy troubleshooting page and can't seem to crack this error. If it helps, I'm attempting this with `singularity` version 3.8.4, which is the newest version available to me in my computing cluster.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/610:3404,Usability,simpl,simple,3404,"""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 30, in <module>; import numpy as np; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/__init__.py"", line 140, in <module>; from . import core; File ""/home/asherrar/.local/lib/python3.8/site-packages/numpy/core/__init__.py"", line 49, in <module>; raise ImportError(msg); ImportError:. IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!. Importing the numpy C-extensions failed. This error can happen for; many reasons, often due to issues with your setup or how NumPy was; installed. We have compiled some common reasons and troubleshooting tips at:. https://numpy.org/devdocs/user/troubleshooting-importerror.html. Please note and check the following:. * The Python version is: Python3.8 from ""/usr/bin/python3""; * The NumPy version is: ""1.23.0"". and make sure that they are the versions you expect.; Please carefully study the documentation linked above for further help. Original error was: libflexiblas.so.3: cannot open shared object file: No such file or directory; ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? Any attempt to execute via `singularity run` leads to an error. **Any additional context:**; As far as I can tell, my environment meets the requirements for both Python and NumPy - though at the same time when I `singularity shell` into the SIF file, its versioning seems semi-independent of my main environment (Python 3.8.10 regardless of my environment's version, but using the NumPy 1.23.0 provided by my computing cluster). I feel like I'm missing something really simple, but I've tried the NumPy troubleshooting page and can't seem to crack this error. If it helps, I'm attempting this with `singularity` version 3.8.4, which is the newest version available to me in my computing cluster.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/610
https://github.com/google/deepvariant/issues/611:78,Availability,checkpoint,checkpoints,78,"**Describe the issue:**. The `model_eval` command can't catch up and evaluate checkpoints in a directory other than the latest one. If it ever crashes or isn't started in time to actually witness training create a checkpoint, there's no way for the user to evaluate the checkpoints it missed, and the ""best"" checkpoint it finds won't actually necessarily be the best out of all the checkpoints in the directory. . **Setup**; - Operating system: Ubuntu 22.04; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: case study data. **Steps to reproduce:**. Loosely following https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-training-case-study.md#start-model_train-and-model_eval, I started the training Docker container using GPU 0:. ```; time docker run --rm --gpus 1 \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \; --train_dir=""${TRAINING_DIR}"" \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=32 \; --learning_rate=0.0005 \; --start_from_checkpoint=""gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt""; ```. Then I tried to start the `model_eval` evaluator in GPU mode with 1 GPU, but Docker was just giving it the *same* GPU as training was using, so it kept immediately running out of GPU memory. After about half an hour I hit on the right syntax to give it a distinct GPU, and managed to actually start `model_eval`:. ```; docker run --rm --gpus '""device=1""' \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_eval \; --dataset_config_pbtxt=""${OUTPUT_DIR}/validation_set.dataset_config.pbtxt"" \; --checkpoint_dir=""${TRAINING",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:214,Availability,checkpoint,checkpoint,214,"**Describe the issue:**. The `model_eval` command can't catch up and evaluate checkpoints in a directory other than the latest one. If it ever crashes or isn't started in time to actually witness training create a checkpoint, there's no way for the user to evaluate the checkpoints it missed, and the ""best"" checkpoint it finds won't actually necessarily be the best out of all the checkpoints in the directory. . **Setup**; - Operating system: Ubuntu 22.04; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: case study data. **Steps to reproduce:**. Loosely following https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-training-case-study.md#start-model_train-and-model_eval, I started the training Docker container using GPU 0:. ```; time docker run --rm --gpus 1 \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \; --train_dir=""${TRAINING_DIR}"" \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=32 \; --learning_rate=0.0005 \; --start_from_checkpoint=""gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt""; ```. Then I tried to start the `model_eval` evaluator in GPU mode with 1 GPU, but Docker was just giving it the *same* GPU as training was using, so it kept immediately running out of GPU memory. After about half an hour I hit on the right syntax to give it a distinct GPU, and managed to actually start `model_eval`:. ```; docker run --rm --gpus '""device=1""' \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_eval \; --dataset_config_pbtxt=""${OUTPUT_DIR}/validation_set.dataset_config.pbtxt"" \; --checkpoint_dir=""${TRAINING",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:270,Availability,checkpoint,checkpoints,270,"**Describe the issue:**. The `model_eval` command can't catch up and evaluate checkpoints in a directory other than the latest one. If it ever crashes or isn't started in time to actually witness training create a checkpoint, there's no way for the user to evaluate the checkpoints it missed, and the ""best"" checkpoint it finds won't actually necessarily be the best out of all the checkpoints in the directory. . **Setup**; - Operating system: Ubuntu 22.04; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: case study data. **Steps to reproduce:**. Loosely following https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-training-case-study.md#start-model_train-and-model_eval, I started the training Docker container using GPU 0:. ```; time docker run --rm --gpus 1 \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \; --train_dir=""${TRAINING_DIR}"" \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=32 \; --learning_rate=0.0005 \; --start_from_checkpoint=""gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt""; ```. Then I tried to start the `model_eval` evaluator in GPU mode with 1 GPU, but Docker was just giving it the *same* GPU as training was using, so it kept immediately running out of GPU memory. After about half an hour I hit on the right syntax to give it a distinct GPU, and managed to actually start `model_eval`:. ```; docker run --rm --gpus '""device=1""' \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_eval \; --dataset_config_pbtxt=""${OUTPUT_DIR}/validation_set.dataset_config.pbtxt"" \; --checkpoint_dir=""${TRAINING",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:308,Availability,checkpoint,checkpoint,308,"**Describe the issue:**. The `model_eval` command can't catch up and evaluate checkpoints in a directory other than the latest one. If it ever crashes or isn't started in time to actually witness training create a checkpoint, there's no way for the user to evaluate the checkpoints it missed, and the ""best"" checkpoint it finds won't actually necessarily be the best out of all the checkpoints in the directory. . **Setup**; - Operating system: Ubuntu 22.04; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: case study data. **Steps to reproduce:**. Loosely following https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-training-case-study.md#start-model_train-and-model_eval, I started the training Docker container using GPU 0:. ```; time docker run --rm --gpus 1 \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \; --train_dir=""${TRAINING_DIR}"" \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=32 \; --learning_rate=0.0005 \; --start_from_checkpoint=""gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt""; ```. Then I tried to start the `model_eval` evaluator in GPU mode with 1 GPU, but Docker was just giving it the *same* GPU as training was using, so it kept immediately running out of GPU memory. After about half an hour I hit on the right syntax to give it a distinct GPU, and managed to actually start `model_eval`:. ```; docker run --rm --gpus '""device=1""' \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_eval \; --dataset_config_pbtxt=""${OUTPUT_DIR}/validation_set.dataset_config.pbtxt"" \; --checkpoint_dir=""${TRAINING",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:382,Availability,checkpoint,checkpoints,382,"**Describe the issue:**. The `model_eval` command can't catch up and evaluate checkpoints in a directory other than the latest one. If it ever crashes or isn't started in time to actually witness training create a checkpoint, there's no way for the user to evaluate the checkpoints it missed, and the ""best"" checkpoint it finds won't actually necessarily be the best out of all the checkpoints in the directory. . **Setup**; - Operating system: Ubuntu 22.04; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: case study data. **Steps to reproduce:**. Loosely following https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-training-case-study.md#start-model_train-and-model_eval, I started the training Docker container using GPU 0:. ```; time docker run --rm --gpus 1 \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \; --train_dir=""${TRAINING_DIR}"" \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=32 \; --learning_rate=0.0005 \; --start_from_checkpoint=""gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt""; ```. Then I tried to start the `model_eval` evaluator in GPU mode with 1 GPU, but Docker was just giving it the *same* GPU as training was using, so it kept immediately running out of GPU memory. After about half an hour I hit on the right syntax to give it a distinct GPU, and managed to actually start `model_eval`:. ```; docker run --rm --gpus '""device=1""' \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_eval \; --dataset_config_pbtxt=""${OUTPUT_DIR}/validation_set.dataset_config.pbtxt"" \; --checkpoint_dir=""${TRAINING",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:2113,Availability,checkpoint,checkpoint,2113,"mber_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=32 \; --learning_rate=0.0005 \; --start_from_checkpoint=""gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt""; ```. Then I tried to start the `model_eval` evaluator in GPU mode with 1 GPU, but Docker was just giving it the *same* GPU as training was using, so it kept immediately running out of GPU memory. After about half an hour I hit on the right syntax to give it a distinct GPU, and managed to actually start `model_eval`:. ```; docker run --rm --gpus '""device=1""' \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_eval \; --dataset_config_pbtxt=""${OUTPUT_DIR}/validation_set.dataset_config.pbtxt"" \; --checkpoint_dir=""${TRAINING_DIR}"" \; --batch_size=512 \; --min_eval_interval_s=1 \; --eval_timeout=1000; ```. It evaluated the most recent checkpoint saves as of when it started up, and it is evaluating new checkpoints as they are created. But it doesn't seem interested in going back and evaluating all the checkpoints, other than the initial-latest one, that were created before it started. The directory in question looks like this:; ```; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*meta; output/models/model.ckpt-0.meta output/models/model.ckpt-19459.meta output/models/model.ckpt-31078.meta; output/models/model.ckpt-1000.meta output/models/model.ckpt-2000.meta output/models/model.ckpt-34008.meta; output/models/model.ckpt-10674.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-3400",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:2181,Availability,checkpoint,checkpoints,2181,"mber_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=32 \; --learning_rate=0.0005 \; --start_from_checkpoint=""gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt""; ```. Then I tried to start the `model_eval` evaluator in GPU mode with 1 GPU, but Docker was just giving it the *same* GPU as training was using, so it kept immediately running out of GPU memory. After about half an hour I hit on the right syntax to give it a distinct GPU, and managed to actually start `model_eval`:. ```; docker run --rm --gpus '""device=1""' \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_eval \; --dataset_config_pbtxt=""${OUTPUT_DIR}/validation_set.dataset_config.pbtxt"" \; --checkpoint_dir=""${TRAINING_DIR}"" \; --batch_size=512 \; --min_eval_interval_s=1 \; --eval_timeout=1000; ```. It evaluated the most recent checkpoint saves as of when it started up, and it is evaluating new checkpoints as they are created. But it doesn't seem interested in going back and evaluating all the checkpoints, other than the initial-latest one, that were created before it started. The directory in question looks like this:; ```; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*meta; output/models/model.ckpt-0.meta output/models/model.ckpt-19459.meta output/models/model.ckpt-31078.meta; output/models/model.ckpt-1000.meta output/models/model.ckpt-2000.meta output/models/model.ckpt-34008.meta; output/models/model.ckpt-10674.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-3400",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:2282,Availability,checkpoint,checkpoints,2282,"els/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt""; ```. Then I tried to start the `model_eval` evaluator in GPU mode with 1 GPU, but Docker was just giving it the *same* GPU as training was using, so it kept immediately running out of GPU memory. After about half an hour I hit on the right syntax to give it a distinct GPU, and managed to actually start `model_eval`:. ```; docker run --rm --gpus '""device=1""' \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_eval \; --dataset_config_pbtxt=""${OUTPUT_DIR}/validation_set.dataset_config.pbtxt"" \; --checkpoint_dir=""${TRAINING_DIR}"" \; --batch_size=512 \; --min_eval_interval_s=1 \; --eval_timeout=1000; ```. It evaluated the most recent checkpoint saves as of when it started up, and it is evaluating new checkpoints as they are created. But it doesn't seem interested in going back and evaluating all the checkpoints, other than the initial-latest one, that were created before it started. The directory in question looks like this:; ```; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*meta; output/models/model.ckpt-0.meta output/models/model.ckpt-19459.meta output/models/model.ckpt-31078.meta; output/models/model.ckpt-1000.meta output/models/model.ckpt-2000.meta output/models/model.ckpt-34008.meta; output/models/model.ckpt-10674.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-34008.metrics; output/models/current.metrics output/models/model.ckpt-31078.metrics; ```. But `model_eval` just sits there like this (until a new ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:3290,Availability,checkpoint,checkpoint,3290,"checkpoints, other than the initial-latest one, that were created before it started. The directory in question looks like this:; ```; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*meta; output/models/model.ckpt-0.meta output/models/model.ckpt-19459.meta output/models/model.ckpt-31078.meta; output/models/model.ckpt-1000.meta output/models/model.ckpt-2000.meta output/models/model.ckpt-34008.meta; output/models/model.ckpt-10674.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-34008.metrics; output/models/current.metrics output/models/model.ckpt-31078.metrics; ```. But `model_eval` just sits there like this (until a new checkpoint appears):; ```; I0210 17:42:06.700287 139846137329472 checkpoint_utils.py:140] Waiting for new checkpoint at /public/groups/cgl/graph-genomes/anovak/trash/output/models; ```. How do I get the missing `*metrics` files and determine if any of the checkpoints that were missed is actually the best one? Do I need to `touch` some particular files in the directory to get `model_eval` to be interested in them? Is there some other command besides `model_eval` that can process a single particular checkpoint at a time?. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. It doesn't look like model training is part of the quick start. **Any additional context:**. Eventually I might want a WDL workflow for training DeepVariant, and I'm not sure that managing two simultaneous DV processes in there is going to be worth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:3396,Availability,checkpoint,checkpoint,3396,"v) [anovak@phoenix-01 trash]$ ls output/models/*meta; output/models/model.ckpt-0.meta output/models/model.ckpt-19459.meta output/models/model.ckpt-31078.meta; output/models/model.ckpt-1000.meta output/models/model.ckpt-2000.meta output/models/model.ckpt-34008.meta; output/models/model.ckpt-10674.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-34008.metrics; output/models/current.metrics output/models/model.ckpt-31078.metrics; ```. But `model_eval` just sits there like this (until a new checkpoint appears):; ```; I0210 17:42:06.700287 139846137329472 checkpoint_utils.py:140] Waiting for new checkpoint at /public/groups/cgl/graph-genomes/anovak/trash/output/models; ```. How do I get the missing `*metrics` files and determine if any of the checkpoints that were missed is actually the best one? Do I need to `touch` some particular files in the directory to get `model_eval` to be interested in them? Is there some other command besides `model_eval` that can process a single particular checkpoint at a time?. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. It doesn't look like model training is part of the quick start. **Any additional context:**. Eventually I might want a WDL workflow for training DeepVariant, and I'm not sure that managing two simultaneous DV processes in there is going to be worth the engineering required; they'd have to be lumped together into one WDL task and they'd have to always fit simultaneously on one machine. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:3546,Availability,checkpoint,checkpoints,3546,"0.meta output/models/model.ckpt-34008.meta; output/models/model.ckpt-10674.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-34008.metrics; output/models/current.metrics output/models/model.ckpt-31078.metrics; ```. But `model_eval` just sits there like this (until a new checkpoint appears):; ```; I0210 17:42:06.700287 139846137329472 checkpoint_utils.py:140] Waiting for new checkpoint at /public/groups/cgl/graph-genomes/anovak/trash/output/models; ```. How do I get the missing `*metrics` files and determine if any of the checkpoints that were missed is actually the best one? Do I need to `touch` some particular files in the directory to get `model_eval` to be interested in them? Is there some other command besides `model_eval` that can process a single particular checkpoint at a time?. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. It doesn't look like model training is part of the quick start. **Any additional context:**. Eventually I might want a WDL workflow for training DeepVariant, and I'm not sure that managing two simultaneous DV processes in there is going to be worth the engineering required; they'd have to be lumped together into one WDL task and they'd have to always fit simultaneously on one machine. It would be much simpler for me to be able to run the training to the end, and then run all the evaluations afterward to select the best model. But it looks like if I tried that right now `model_eval` would just only evalu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:3793,Availability,checkpoint,checkpoint,3793,"0.meta output/models/model.ckpt-34008.meta; output/models/model.ckpt-10674.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-34008.metrics; output/models/current.metrics output/models/model.ckpt-31078.metrics; ```. But `model_eval` just sits there like this (until a new checkpoint appears):; ```; I0210 17:42:06.700287 139846137329472 checkpoint_utils.py:140] Waiting for new checkpoint at /public/groups/cgl/graph-genomes/anovak/trash/output/models; ```. How do I get the missing `*metrics` files and determine if any of the checkpoints that were missed is actually the best one? Do I need to `touch` some particular files in the directory to get `model_eval` to be interested in them? Is there some other command besides `model_eval` that can process a single particular checkpoint at a time?. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. It doesn't look like model training is part of the quick start. **Any additional context:**. Eventually I might want a WDL workflow for training DeepVariant, and I'm not sure that managing two simultaneous DV processes in there is going to be worth the engineering required; they'd have to be lumped together into one WDL task and they'd have to always fit simultaneously on one machine. It would be much simpler for me to be able to run the training to the end, and then run all the evaluations afterward to select the best model. But it looks like if I tried that right now `model_eval` would just only evalu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:4658,Availability,checkpoint,checkpoint,4658,"4.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-34008.metrics; output/models/current.metrics output/models/model.ckpt-31078.metrics; ```. But `model_eval` just sits there like this (until a new checkpoint appears):; ```; I0210 17:42:06.700287 139846137329472 checkpoint_utils.py:140] Waiting for new checkpoint at /public/groups/cgl/graph-genomes/anovak/trash/output/models; ```. How do I get the missing `*metrics` files and determine if any of the checkpoints that were missed is actually the best one? Do I need to `touch` some particular files in the directory to get `model_eval` to be interested in them? Is there some other command besides `model_eval` that can process a single particular checkpoint at a time?. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. It doesn't look like model training is part of the quick start. **Any additional context:**. Eventually I might want a WDL workflow for training DeepVariant, and I'm not sure that managing two simultaneous DV processes in there is going to be worth the engineering required; they'd have to be lumped together into one WDL task and they'd have to always fit simultaneously on one machine. It would be much simpler for me to be able to run the training to the end, and then run all the evaluations afterward to select the best model. But it looks like if I tried that right now `model_eval` would just only evaluate the last checkpoint and always confidently declare it to be the best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:491,Deployability,Install,Installation,491,"**Describe the issue:**. The `model_eval` command can't catch up and evaluate checkpoints in a directory other than the latest one. If it ever crashes or isn't started in time to actually witness training create a checkpoint, there's no way for the user to evaluate the checkpoints it missed, and the ""best"" checkpoint it finds won't actually necessarily be the best out of all the checkpoints in the directory. . **Setup**; - Operating system: Ubuntu 22.04; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: case study data. **Steps to reproduce:**. Loosely following https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-training-case-study.md#start-model_train-and-model_eval, I started the training Docker container using GPU 0:. ```; time docker run --rm --gpus 1 \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_train \; --dataset_config_pbtxt=""${OUTPUT_DIR}/training_set.dataset_config.pbtxt"" \; --train_dir=""${TRAINING_DIR}"" \; --model_name=""inception_v3"" \; --number_of_steps=50000 \; --save_interval_secs=300 \; --batch_size=32 \; --learning_rate=0.0005 \; --start_from_checkpoint=""gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt""; ```. Then I tried to start the `model_eval` evaluator in GPU mode with 1 GPU, but Docker was just giving it the *same* GPU as training was using, so it kept immediately running out of GPU memory. After about half an hour I hit on the right syntax to give it a distinct GPU, and managed to actually start `model_eval`:. ```; docker run --rm --gpus '""device=1""' \; -v ""${DATA_DIR}:${DATA_DIR}"" \; -v ""${OUTPUT_DIR}:${OUTPUT_DIR}"" \; -u $(id -u):$(id -g) \; google/deepvariant:1.4.0-gpu \; /opt/deepvariant/bin/model_eval \; --dataset_config_pbtxt=""${OUTPUT_DIR}/validation_set.dataset_config.pbtxt"" \; --checkpoint_dir=""${TRAINING",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:3839,Testability,test,test,3839,"4.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-34008.metrics; output/models/current.metrics output/models/model.ckpt-31078.metrics; ```. But `model_eval` just sits there like this (until a new checkpoint appears):; ```; I0210 17:42:06.700287 139846137329472 checkpoint_utils.py:140] Waiting for new checkpoint at /public/groups/cgl/graph-genomes/anovak/trash/output/models; ```. How do I get the missing `*metrics` files and determine if any of the checkpoints that were missed is actually the best one? Do I need to `touch` some particular files in the directory to get `model_eval` to be interested in them? Is there some other command besides `model_eval` that can process a single particular checkpoint at a time?. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. It doesn't look like model training is part of the quick start. **Any additional context:**. Eventually I might want a WDL workflow for training DeepVariant, and I'm not sure that managing two simultaneous DV processes in there is going to be worth the engineering required; they'd have to be lumped together into one WDL task and they'd have to always fit simultaneously on one machine. It would be much simpler for me to be able to run the training to the end, and then run all the evaluations afterward to select the best model. But it looks like if I tried that right now `model_eval` would just only evaluate the last checkpoint and always confidently declare it to be the best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:3875,Testability,test,test,3875,"4.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-34008.metrics; output/models/current.metrics output/models/model.ckpt-31078.metrics; ```. But `model_eval` just sits there like this (until a new checkpoint appears):; ```; I0210 17:42:06.700287 139846137329472 checkpoint_utils.py:140] Waiting for new checkpoint at /public/groups/cgl/graph-genomes/anovak/trash/output/models; ```. How do I get the missing `*metrics` files and determine if any of the checkpoints that were missed is actually the best one? Do I need to `touch` some particular files in the directory to get `model_eval` to be interested in them? Is there some other command besides `model_eval` that can process a single particular checkpoint at a time?. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. It doesn't look like model training is part of the quick start. **Any additional context:**. Eventually I might want a WDL workflow for training DeepVariant, and I'm not sure that managing two simultaneous DV processes in there is going to be worth the engineering required; they'd have to be lumped together into one WDL task and they'd have to always fit simultaneously on one machine. It would be much simpler for me to be able to run the training to the end, and then run all the evaluations afterward to select the best model. But it looks like if I tried that right now `model_eval` would just only evaluate the last checkpoint and always confidently declare it to be the best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/611:4440,Usability,simpl,simpler,4440,"4.meta output/models/model.ckpt-22355.meta output/models/model.ckpt-4814.meta; output/models/model.ckpt-13613.meta output/models/model.ckpt-25257.meta output/models/model.ckpt-7724.meta; output/models/model.ckpt-16546.meta output/models/model.ckpt-28168.meta; (dv_venv) [anovak@phoenix-01 trash]$ ls output/models/*metrics; output/models/best_checkpoint.metrics output/models/model.ckpt-28168.metrics output/models/model.ckpt-34008.metrics; output/models/current.metrics output/models/model.ckpt-31078.metrics; ```. But `model_eval` just sits there like this (until a new checkpoint appears):; ```; I0210 17:42:06.700287 139846137329472 checkpoint_utils.py:140] Waiting for new checkpoint at /public/groups/cgl/graph-genomes/anovak/trash/output/models; ```. How do I get the missing `*metrics` files and determine if any of the checkpoints that were missed is actually the best one? Do I need to `touch` some particular files in the directory to get `model_eval` to be interested in them? Is there some other command besides `model_eval` that can process a single particular checkpoint at a time?. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. It doesn't look like model training is part of the quick start. **Any additional context:**. Eventually I might want a WDL workflow for training DeepVariant, and I'm not sure that managing two simultaneous DV processes in there is going to be worth the engineering required; they'd have to be lumped together into one WDL task and they'd have to always fit simultaneously on one machine. It would be much simpler for me to be able to run the training to the end, and then run all the evaluations afterward to select the best model. But it looks like if I tried that right now `model_eval` would just only evaluate the last checkpoint and always confidently declare it to be the best.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/611
https://github.com/google/deepvariant/issues/612:1150,Availability,Error,Error,1150,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes; **Describe the issue:**; A potential denovo variant is filtered out due to mendelian violation. While found the deletion in the same sample via GATK and IGV (both raw BAM file and realigned BAM file from GATK HaplotypeCaller). Wonder how to loosen the criteria to increase the recall of denovo variants.; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - 150bp paired-end Illumina data. **Steps to reproduce:**; - Command: ; `/opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; --make_examples_extra_args=""normalize_reads=true"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp/${singularity_inter}"" \; --num_shards=${threads}`; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; Here is the IGV screenshot of the position where DeepVariant failed to identify one bp deletion (Upper panel illustrates the alignment from raw BAM file, lower panel illustrates the alignment from the realigned BAM file from GATK HaplotypeCaller):; ![image](https://user-images.githubusercontent.com/40780228/218404096-273ed999-6443-43c2-83b9-108661d738d4.png). P.S. Please consider granting a parameter of DeepVariant to let users generate the realigned BAM file from DeepVariant. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/612
https://github.com/google/deepvariant/issues/612:529,Deployability,Install,Installation,529,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes; **Describe the issue:**; A potential denovo variant is filtered out due to mendelian violation. While found the deletion in the same sample via GATK and IGV (both raw BAM file and realigned BAM file from GATK HaplotypeCaller). Wonder how to loosen the criteria to increase the recall of denovo variants.; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - 150bp paired-end Illumina data. **Steps to reproduce:**; - Command: ; `/opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; --make_examples_extra_args=""normalize_reads=true"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp/${singularity_inter}"" \; --num_shards=${threads}`; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; Here is the IGV screenshot of the position where DeepVariant failed to identify one bp deletion (Upper panel illustrates the alignment from raw BAM file, lower panel illustrates the alignment from the realigned BAM file from GATK HaplotypeCaller):; ![image](https://user-images.githubusercontent.com/40780228/218404096-273ed999-6443-43c2-83b9-108661d738d4.png). P.S. Please consider granting a parameter of DeepVariant to let users generate the realigned BAM file from DeepVariant. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/612
https://github.com/google/deepvariant/issues/612:1203,Testability,test,test,1203,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes; **Describe the issue:**; A potential denovo variant is filtered out due to mendelian violation. While found the deletion in the same sample via GATK and IGV (both raw BAM file and realigned BAM file from GATK HaplotypeCaller). Wonder how to loosen the criteria to increase the recall of denovo variants.; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - 150bp paired-end Illumina data. **Steps to reproduce:**; - Command: ; `/opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; --make_examples_extra_args=""normalize_reads=true"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp/${singularity_inter}"" \; --num_shards=${threads}`; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; Here is the IGV screenshot of the position where DeepVariant failed to identify one bp deletion (Upper panel illustrates the alignment from raw BAM file, lower panel illustrates the alignment from the realigned BAM file from GATK HaplotypeCaller):; ![image](https://user-images.githubusercontent.com/40780228/218404096-273ed999-6443-43c2-83b9-108661d738d4.png). P.S. Please consider granting a parameter of DeepVariant to let users generate the realigned BAM file from DeepVariant. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/612
https://github.com/google/deepvariant/issues/612:1239,Testability,test,test,1239,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes; **Describe the issue:**; A potential denovo variant is filtered out due to mendelian violation. While found the deletion in the same sample via GATK and IGV (both raw BAM file and realigned BAM file from GATK HaplotypeCaller). Wonder how to loosen the criteria to increase the recall of denovo variants.; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - 150bp paired-end Illumina data. **Steps to reproduce:**; - Command: ; `/opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; --make_examples_extra_args=""normalize_reads=true"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp/${singularity_inter}"" \; --num_shards=${threads}`; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; Here is the IGV screenshot of the position where DeepVariant failed to identify one bp deletion (Upper panel illustrates the alignment from raw BAM file, lower panel illustrates the alignment from the realigned BAM file from GATK HaplotypeCaller):; ![image](https://user-images.githubusercontent.com/40780228/218404096-273ed999-6443-43c2-83b9-108661d738d4.png). P.S. Please consider granting a parameter of DeepVariant to let users generate the realigned BAM file from DeepVariant. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/612
https://github.com/google/deepvariant/issues/612:405,Usability,clear,clear,405,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.4/docs/FAQ.md**:; Yes; **Describe the issue:**; A potential denovo variant is filtered out due to mendelian violation. While found the deletion in the same sample via GATK and IGV (both raw BAM file and realigned BAM file from GATK HaplotypeCaller). Wonder how to loosen the criteria to increase the recall of denovo variants.; (A clear and concise description of what the issue is.). **Setup**; - Operating system: CentOS7; - DeepVariant version: 1.4; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); - 150bp paired-end Illumina data. **Steps to reproduce:**; - Command: ; `/opt/deepvariant/bin/run_deepvariant \; --model_type=${model_type} \; --ref=""${ref_genome}"" \; --reads=""${bam_file}"" \; --make_examples_extra_args=""normalize_reads=true"" \; ${region_arg} \; --output_vcf=""${output_vcf}"" \; --output_gvcf=""${output_gvcf}"" \; --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp/${singularity_inter}"" \; --num_shards=${threads}`; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**; Here is the IGV screenshot of the position where DeepVariant failed to identify one bp deletion (Upper panel illustrates the alignment from raw BAM file, lower panel illustrates the alignment from the realigned BAM file from GATK HaplotypeCaller):; ![image](https://user-images.githubusercontent.com/40780228/218404096-273ed999-6443-43c2-83b9-108661d738d4.png). P.S. Please consider granting a parameter of DeepVariant to let users generate the realigned BAM file from DeepVariant. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/612
https://github.com/google/deepvariant/issues/613:16,Availability,error,error,16,"Hello, I got an error when running deepvariant. I've verified that the path `/path1/8_Environment/TMPDIR`exists.; I've googled all over and still can't solve the problem. please help me!. command：; ```; INPUT_DIR=/path1/4_Test/qingjiang/dpv; OUTPUT_DIR=/path1/4_Test/qingjiang/dpv. singularity run /path/dpv/deepvariant_1.4.0.sif /opt/deepvariant/bin/run_deepvariant \; --num_shards=3 \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/QJref.fa \; --reads=""${INPUT_DIR}""/input.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; ```; error：; ```; I0213 16:54:59.595547 140573030586176 run_deepvariant.py:342] Re-using the directory for intermediate results in /path/dpv/intermediate_results_dir. ***** Intermediate results will be written to /path/dpv/intermediate_results_dir in docker. ****. ***** Running the command:*****; time seq 0 2 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/path/dpv/QJref.fa"" --reads ""/path/dpv/input.bam"" --examples ""/dellfsq. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; Error in tempfile() using template /path1/8_Environment/TMPDIR/parXXXXX.par: Parent directory (/path1/8_Environment/TMPDIR/) does not exist at /usr/bin/parallel line 3889. real 0m3.019s; user 0m0.211s; sys 0m0.371s; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/613
https://github.com/google/deepvariant/issues/613:651,Availability,error,error,651,"Hello, I got an error when running deepvariant. I've verified that the path `/path1/8_Environment/TMPDIR`exists.; I've googled all over and still can't solve the problem. please help me!. command：; ```; INPUT_DIR=/path1/4_Test/qingjiang/dpv; OUTPUT_DIR=/path1/4_Test/qingjiang/dpv. singularity run /path/dpv/deepvariant_1.4.0.sif /opt/deepvariant/bin/run_deepvariant \; --num_shards=3 \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/QJref.fa \; --reads=""${INPUT_DIR}""/input.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; ```; error：; ```; I0213 16:54:59.595547 140573030586176 run_deepvariant.py:342] Re-using the directory for intermediate results in /path/dpv/intermediate_results_dir. ***** Intermediate results will be written to /path/dpv/intermediate_results_dir in docker. ****. ***** Running the command:*****; time seq 0 2 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/path/dpv/QJref.fa"" --reads ""/path/dpv/input.bam"" --examples ""/dellfsq. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; Error in tempfile() using template /path1/8_Environment/TMPDIR/parXXXXX.par: Parent directory (/path1/8_Environment/TMPDIR/) does not exist at /usr/bin/parallel line 3889. real 0m3.019s; user 0m0.211s; sys 0m0.371s; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/613
https://github.com/google/deepvariant/issues/613:1691,Availability,Error,Error,1691,"Hello, I got an error when running deepvariant. I've verified that the path `/path1/8_Environment/TMPDIR`exists.; I've googled all over and still can't solve the problem. please help me!. command：; ```; INPUT_DIR=/path1/4_Test/qingjiang/dpv; OUTPUT_DIR=/path1/4_Test/qingjiang/dpv. singularity run /path/dpv/deepvariant_1.4.0.sif /opt/deepvariant/bin/run_deepvariant \; --num_shards=3 \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/QJref.fa \; --reads=""${INPUT_DIR}""/input.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; ```; error：; ```; I0213 16:54:59.595547 140573030586176 run_deepvariant.py:342] Re-using the directory for intermediate results in /path/dpv/intermediate_results_dir. ***** Intermediate results will be written to /path/dpv/intermediate_results_dir in docker. ****. ***** Running the command:*****; time seq 0 2 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/path/dpv/QJref.fa"" --reads ""/path/dpv/input.bam"" --examples ""/dellfsq. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; Error in tempfile() using template /path1/8_Environment/TMPDIR/parXXXXX.par: Parent directory (/path1/8_Environment/TMPDIR/) does not exist at /usr/bin/parallel line 3889. real 0m3.019s; user 0m0.211s; sys 0m0.371s; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/613
https://github.com/google/deepvariant/issues/613:1321,Deployability,install,installed,1321,"Hello, I got an error when running deepvariant. I've verified that the path `/path1/8_Environment/TMPDIR`exists.; I've googled all over and still can't solve the problem. please help me!. command：; ```; INPUT_DIR=/path1/4_Test/qingjiang/dpv; OUTPUT_DIR=/path1/4_Test/qingjiang/dpv. singularity run /path/dpv/deepvariant_1.4.0.sif /opt/deepvariant/bin/run_deepvariant \; --num_shards=3 \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/QJref.fa \; --reads=""${INPUT_DIR}""/input.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; ```; error：; ```; I0213 16:54:59.595547 140573030586176 run_deepvariant.py:342] Re-using the directory for intermediate results in /path/dpv/intermediate_results_dir. ***** Intermediate results will be written to /path/dpv/intermediate_results_dir in docker. ****. ***** Running the command:*****; time seq 0 2 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/path/dpv/QJref.fa"" --reads ""/path/dpv/input.bam"" --examples ""/dellfsq. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; Error in tempfile() using template /path1/8_Environment/TMPDIR/parXXXXX.par: Parent directory (/path1/8_Environment/TMPDIR/) does not exist at /usr/bin/parallel line 3889. real 0m3.019s; user 0m0.211s; sys 0m0.371s; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/613
https://github.com/google/deepvariant/issues/613:1605,Deployability,install,installed,1605,"Hello, I got an error when running deepvariant. I've verified that the path `/path1/8_Environment/TMPDIR`exists.; I've googled all over and still can't solve the problem. please help me!. command：; ```; INPUT_DIR=/path1/4_Test/qingjiang/dpv; OUTPUT_DIR=/path1/4_Test/qingjiang/dpv. singularity run /path/dpv/deepvariant_1.4.0.sif /opt/deepvariant/bin/run_deepvariant \; --num_shards=3 \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/QJref.fa \; --reads=""${INPUT_DIR}""/input.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; ```; error：; ```; I0213 16:54:59.595547 140573030586176 run_deepvariant.py:342] Re-using the directory for intermediate results in /path/dpv/intermediate_results_dir. ***** Intermediate results will be written to /path/dpv/intermediate_results_dir in docker. ****. ***** Running the command:*****; time seq 0 2 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/path/dpv/QJref.fa"" --reads ""/path/dpv/input.bam"" --examples ""/dellfsq. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LC_CTYPE = ""C.UTF-8"",; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; Error in tempfile() using template /path1/8_Environment/TMPDIR/parXXXXX.par: Parent directory (/path1/8_Environment/TMPDIR/) does not exist at /usr/bin/parallel line 3889. real 0m3.019s; user 0m0.211s; sys 0m0.371s; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/613
https://github.com/google/deepvariant/issues/614:12763,Availability,error,error,12763,"6737.31s elapsed]; I0218 10:46:36.864049 23456243894080 make_examples_core.py:243] Task 19/64: Skip phasing: len(candidates[main_sample]) is 20526.; I0218 10:48:19.364838 23456243894080 make_examples_core.py:243] Task 2/64: 158555 candidates (173735 examples) [4091.74s elapsed]; I0218 10:48:45.881830 23456243894080 make_examples_core.py:243] Task 2/64: Skip phasing: len(candidates[main_sample]) is 14234.; I0218 10:49:31.045118 23456243894080 make_examples_core.py:243] Task 13/64: 113956 candidates (125182 examples) [6317.67s elapsed]; I0218 10:50:33.895329 23456243894080 make_examples_core.py:243] Task 13/64: Skip phasing: len(candidates[main_sample]) is 18414.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /scratch4/path.to.mydir/genomes/c_elegans.PRJNA13758.WS245.genomic.fa --reads /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam --examples /tmp/tmp1yvr59_z/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 28. real	879m59.515s; user	632m52.969s; sys	6m20.594s; INFO: Cleaning up image... ```. I also ran more jobs using different numbers of cpu and mem using different bam files. One using 48 cpu and --mem-per-cpu=6G simply fizzled without any error message. These jobs are taking considerable core-hours, so troubleshooting is hard. I also wonder if I am using Deepvariant efficiently. On a side note, I got many Deepvariant failures with error messages like:; ```; Detected 1372 oom-kill event(s) in StepId=12049020.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.; ```; This seems to have been resolved by asking for maximum allowable memory. I am still curious about the memory requirement for successfully running Deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:12945,Availability,failure,failures,12945,"6737.31s elapsed]; I0218 10:46:36.864049 23456243894080 make_examples_core.py:243] Task 19/64: Skip phasing: len(candidates[main_sample]) is 20526.; I0218 10:48:19.364838 23456243894080 make_examples_core.py:243] Task 2/64: 158555 candidates (173735 examples) [4091.74s elapsed]; I0218 10:48:45.881830 23456243894080 make_examples_core.py:243] Task 2/64: Skip phasing: len(candidates[main_sample]) is 14234.; I0218 10:49:31.045118 23456243894080 make_examples_core.py:243] Task 13/64: 113956 candidates (125182 examples) [6317.67s elapsed]; I0218 10:50:33.895329 23456243894080 make_examples_core.py:243] Task 13/64: Skip phasing: len(candidates[main_sample]) is 18414.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /scratch4/path.to.mydir/genomes/c_elegans.PRJNA13758.WS245.genomic.fa --reads /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam --examples /tmp/tmp1yvr59_z/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 28. real	879m59.515s; user	632m52.969s; sys	6m20.594s; INFO: Cleaning up image... ```. I also ran more jobs using different numbers of cpu and mem using different bam files. One using 48 cpu and --mem-per-cpu=6G simply fizzled without any error message. These jobs are taking considerable core-hours, so troubleshooting is hard. I also wonder if I am using Deepvariant efficiently. On a side note, I got many Deepvariant failures with error messages like:; ```; Detected 1372 oom-kill event(s) in StepId=12049020.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.; ```; This seems to have been resolved by asking for maximum allowable memory. I am still curious about the memory requirement for successfully running Deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:12959,Availability,error,error,12959,"6737.31s elapsed]; I0218 10:46:36.864049 23456243894080 make_examples_core.py:243] Task 19/64: Skip phasing: len(candidates[main_sample]) is 20526.; I0218 10:48:19.364838 23456243894080 make_examples_core.py:243] Task 2/64: 158555 candidates (173735 examples) [4091.74s elapsed]; I0218 10:48:45.881830 23456243894080 make_examples_core.py:243] Task 2/64: Skip phasing: len(candidates[main_sample]) is 14234.; I0218 10:49:31.045118 23456243894080 make_examples_core.py:243] Task 13/64: 113956 candidates (125182 examples) [6317.67s elapsed]; I0218 10:50:33.895329 23456243894080 make_examples_core.py:243] Task 13/64: Skip phasing: len(candidates[main_sample]) is 18414.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /scratch4/path.to.mydir/genomes/c_elegans.PRJNA13758.WS245.genomic.fa --reads /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam --examples /tmp/tmp1yvr59_z/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 28. real	879m59.515s; user	632m52.969s; sys	6m20.594s; INFO: Cleaning up image... ```. I also ran more jobs using different numbers of cpu and mem using different bam files. One using 48 cpu and --mem-per-cpu=6G simply fizzled without any error message. These jobs are taking considerable core-hours, so troubleshooting is hard. I also wonder if I am using Deepvariant efficiently. On a side note, I got many Deepvariant failures with error messages like:; ```; Detected 1372 oom-kill event(s) in StepId=12049020.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.; ```; This seems to have been resolved by asking for maximum allowable memory. I am still curious about the memory requirement for successfully running Deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:1658,Deployability,install,installed,1658,"ch4/path.to.mydir/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref c_elegans.PRJNA13758.WS245.genomic.fa \; --reads aln13448198.pbmm2.bam \; --output_vcf aln13448198.pbmm2.dv.vcf.gz \; --num_shards 64; ```. Here's a long snippet of slurm output:; ```; INFO: Using cached SIF image; INFO: Converting SIF file to temporary sandbox...; I0217 20:13:14.117354 23456243894080 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmp1yvr59_z. ***** Intermediate results will be written to /tmp/tmp1yvr59_z in docker. ****. ***** Running the command:*****; time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref [snipped]. #[snip]; # this part is likely unimportant. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C""). #[snip]. 2023-02-17 20:13:17.235641: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD	VN:1.6	SO:coordinate	pb:5.0.0; I0217 20:13:17.235805 23456243894080 genomics_reader.py:222] Reading /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam with NativeSamReader; I0217 20:13:17.268698 23456243894080 make_examples_core.py:243] Task 18/64: Preparing inputs; 2023-02-17 20:13:17.371669: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD	VN:1.6	SO:coordinate	pb:5.0.0; I0217 20:13:17.371811 23456243894080 genomics_reader.py:222] Reading /scratch4/jwan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:1946,Deployability,install,installed,1946,"t of slurm output:; ```; INFO: Using cached SIF image; INFO: Converting SIF file to temporary sandbox...; I0217 20:13:14.117354 23456243894080 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmp1yvr59_z. ***** Intermediate results will be written to /tmp/tmp1yvr59_z in docker. ****. ***** Running the command:*****; time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref [snipped]. #[snip]; # this part is likely unimportant. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C""). #[snip]. 2023-02-17 20:13:17.235641: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD	VN:1.6	SO:coordinate	pb:5.0.0; I0217 20:13:17.235805 23456243894080 genomics_reader.py:222] Reading /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam with NativeSamReader; I0217 20:13:17.268698 23456243894080 make_examples_core.py:243] Task 18/64: Preparing inputs; 2023-02-17 20:13:17.371669: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD	VN:1.6	SO:coordinate	pb:5.0.0; I0217 20:13:17.371811 23456243894080 genomics_reader.py:222] Reading /scratch4/jwang8/hoyon/pbmm2/aln13448198.pbmm2.bam with NativeSamReader; I0217 20:13:17.376646 23456243894080 make_examples_core.py:243] Task 18/64: Common contigs are ['I', 'II', 'III', 'IV', 'V', 'X', 'MtDNA']; I0217 20:13:17.383403 23456243894080 make_examples_core.py:243] Task 18/64: Starting from",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:12893,Energy Efficiency,efficient,efficiently,12893,"6737.31s elapsed]; I0218 10:46:36.864049 23456243894080 make_examples_core.py:243] Task 19/64: Skip phasing: len(candidates[main_sample]) is 20526.; I0218 10:48:19.364838 23456243894080 make_examples_core.py:243] Task 2/64: 158555 candidates (173735 examples) [4091.74s elapsed]; I0218 10:48:45.881830 23456243894080 make_examples_core.py:243] Task 2/64: Skip phasing: len(candidates[main_sample]) is 14234.; I0218 10:49:31.045118 23456243894080 make_examples_core.py:243] Task 13/64: 113956 candidates (125182 examples) [6317.67s elapsed]; I0218 10:50:33.895329 23456243894080 make_examples_core.py:243] Task 13/64: Skip phasing: len(candidates[main_sample]) is 18414.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /scratch4/path.to.mydir/genomes/c_elegans.PRJNA13758.WS245.genomic.fa --reads /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam --examples /tmp/tmp1yvr59_z/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 28. real	879m59.515s; user	632m52.969s; sys	6m20.594s; INFO: Cleaning up image... ```. I also ran more jobs using different numbers of cpu and mem using different bam files. One using 48 cpu and --mem-per-cpu=6G simply fizzled without any error message. These jobs are taking considerable core-hours, so troubleshooting is hard. I also wonder if I am using Deepvariant efficiently. On a side note, I got many Deepvariant failures with error messages like:; ```; Detected 1372 oom-kill event(s) in StepId=12049020.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.; ```; This seems to have been resolved by asking for maximum allowable memory. I am still curious about the memory requirement for successfully running Deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:12769,Integrability,message,message,12769,"6737.31s elapsed]; I0218 10:46:36.864049 23456243894080 make_examples_core.py:243] Task 19/64: Skip phasing: len(candidates[main_sample]) is 20526.; I0218 10:48:19.364838 23456243894080 make_examples_core.py:243] Task 2/64: 158555 candidates (173735 examples) [4091.74s elapsed]; I0218 10:48:45.881830 23456243894080 make_examples_core.py:243] Task 2/64: Skip phasing: len(candidates[main_sample]) is 14234.; I0218 10:49:31.045118 23456243894080 make_examples_core.py:243] Task 13/64: 113956 candidates (125182 examples) [6317.67s elapsed]; I0218 10:50:33.895329 23456243894080 make_examples_core.py:243] Task 13/64: Skip phasing: len(candidates[main_sample]) is 18414.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /scratch4/path.to.mydir/genomes/c_elegans.PRJNA13758.WS245.genomic.fa --reads /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam --examples /tmp/tmp1yvr59_z/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 28. real	879m59.515s; user	632m52.969s; sys	6m20.594s; INFO: Cleaning up image... ```. I also ran more jobs using different numbers of cpu and mem using different bam files. One using 48 cpu and --mem-per-cpu=6G simply fizzled without any error message. These jobs are taking considerable core-hours, so troubleshooting is hard. I also wonder if I am using Deepvariant efficiently. On a side note, I got many Deepvariant failures with error messages like:; ```; Detected 1372 oom-kill event(s) in StepId=12049020.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.; ```; This seems to have been resolved by asking for maximum allowable memory. I am still curious about the memory requirement for successfully running Deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:12965,Integrability,message,messages,12965,"6737.31s elapsed]; I0218 10:46:36.864049 23456243894080 make_examples_core.py:243] Task 19/64: Skip phasing: len(candidates[main_sample]) is 20526.; I0218 10:48:19.364838 23456243894080 make_examples_core.py:243] Task 2/64: 158555 candidates (173735 examples) [4091.74s elapsed]; I0218 10:48:45.881830 23456243894080 make_examples_core.py:243] Task 2/64: Skip phasing: len(candidates[main_sample]) is 14234.; I0218 10:49:31.045118 23456243894080 make_examples_core.py:243] Task 13/64: 113956 candidates (125182 examples) [6317.67s elapsed]; I0218 10:50:33.895329 23456243894080 make_examples_core.py:243] Task 13/64: Skip phasing: len(candidates[main_sample]) is 18414.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /scratch4/path.to.mydir/genomes/c_elegans.PRJNA13758.WS245.genomic.fa --reads /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam --examples /tmp/tmp1yvr59_z/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 28. real	879m59.515s; user	632m52.969s; sys	6m20.594s; INFO: Cleaning up image... ```. I also ran more jobs using different numbers of cpu and mem using different bam files. One using 48 cpu and --mem-per-cpu=6G simply fizzled without any error message. These jobs are taking considerable core-hours, so troubleshooting is hard. I also wonder if I am using Deepvariant efficiently. On a side note, I got many Deepvariant failures with error messages like:; ```; Detected 1372 oom-kill event(s) in StepId=12049020.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.; ```; This seems to have been resolved by asking for maximum allowable memory. I am still curious about the memory requirement for successfully running Deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:1039,Modifiability,sandbox,sandbox,1039,"Deepvariant fails without clear reason. . **Setup**; JHU Rockfish HPC; Singularity 3.8.7; singularity pull docker://google/deepvariant:1.4.0. Problematic data are PacBio (first gen). I have used Deepvariant with Illumina without problem, and I used PEPPER to process Ont data and PacBio Hifi data. I used pbmm2 to align fastq with all PacBio data. Command used to run:; ```; #!/bin/bash; #SBATCH --job-name=deep64_13448198; #SBATCH --time=24:00:00; #SBATCH --nodes=2; #SBATCH --ntasks-per-node=1; #SBATCH --cpus-per-task=32; #SBATCH --mem=0. ml anaconda; conda activate /data/path.to.mydir/deepvariant. singularity run --bind /scratch4/path.to.mydir/:/scratch4/path.to.mydir/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref c_elegans.PRJNA13758.WS245.genomic.fa \; --reads aln13448198.pbmm2.bam \; --output_vcf aln13448198.pbmm2.dv.vcf.gz \; --num_shards 64; ```. Here's a long snippet of slurm output:; ```; INFO: Using cached SIF image; INFO: Converting SIF file to temporary sandbox...; I0217 20:13:14.117354 23456243894080 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmp1yvr59_z. ***** Intermediate results will be written to /tmp/tmp1yvr59_z in docker. ****. ***** Running the command:*****; time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref [snipped]. #[snip]; # this part is likely unimportant. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:982,Performance,cache,cached,982,"Deepvariant fails without clear reason. . **Setup**; JHU Rockfish HPC; Singularity 3.8.7; singularity pull docker://google/deepvariant:1.4.0. Problematic data are PacBio (first gen). I have used Deepvariant with Illumina without problem, and I used PEPPER to process Ont data and PacBio Hifi data. I used pbmm2 to align fastq with all PacBio data. Command used to run:; ```; #!/bin/bash; #SBATCH --job-name=deep64_13448198; #SBATCH --time=24:00:00; #SBATCH --nodes=2; #SBATCH --ntasks-per-node=1; #SBATCH --cpus-per-task=32; #SBATCH --mem=0. ml anaconda; conda activate /data/path.to.mydir/deepvariant. singularity run --bind /scratch4/path.to.mydir/:/scratch4/path.to.mydir/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref c_elegans.PRJNA13758.WS245.genomic.fa \; --reads aln13448198.pbmm2.bam \; --output_vcf aln13448198.pbmm2.dv.vcf.gz \; --num_shards 64; ```. Here's a long snippet of slurm output:; ```; INFO: Using cached SIF image; INFO: Converting SIF file to temporary sandbox...; I0217 20:13:14.117354 23456243894080 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmp1yvr59_z. ***** Intermediate results will be written to /tmp/tmp1yvr59_z in docker. ****. ***** Running the command:*****; time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref [snipped]. #[snip]; # this part is likely unimportant. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:12986,Safety,Detect,Detected,12986,"6737.31s elapsed]; I0218 10:46:36.864049 23456243894080 make_examples_core.py:243] Task 19/64: Skip phasing: len(candidates[main_sample]) is 20526.; I0218 10:48:19.364838 23456243894080 make_examples_core.py:243] Task 2/64: 158555 candidates (173735 examples) [4091.74s elapsed]; I0218 10:48:45.881830 23456243894080 make_examples_core.py:243] Task 2/64: Skip phasing: len(candidates[main_sample]) is 14234.; I0218 10:49:31.045118 23456243894080 make_examples_core.py:243] Task 13/64: 113956 candidates (125182 examples) [6317.67s elapsed]; I0218 10:50:33.895329 23456243894080 make_examples_core.py:243] Task 13/64: Skip phasing: len(candidates[main_sample]) is 18414.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /scratch4/path.to.mydir/genomes/c_elegans.PRJNA13758.WS245.genomic.fa --reads /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam --examples /tmp/tmp1yvr59_z/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 28. real	879m59.515s; user	632m52.969s; sys	6m20.594s; INFO: Cleaning up image... ```. I also ran more jobs using different numbers of cpu and mem using different bam files. One using 48 cpu and --mem-per-cpu=6G simply fizzled without any error message. These jobs are taking considerable core-hours, so troubleshooting is hard. I also wonder if I am using Deepvariant efficiently. On a side note, I got many Deepvariant failures with error messages like:; ```; Detected 1372 oom-kill event(s) in StepId=12049020.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.; ```; This seems to have been resolved by asking for maximum allowable memory. I am still curious about the memory requirement for successfully running Deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:1039,Testability,sandbox,sandbox,1039,"Deepvariant fails without clear reason. . **Setup**; JHU Rockfish HPC; Singularity 3.8.7; singularity pull docker://google/deepvariant:1.4.0. Problematic data are PacBio (first gen). I have used Deepvariant with Illumina without problem, and I used PEPPER to process Ont data and PacBio Hifi data. I used pbmm2 to align fastq with all PacBio data. Command used to run:; ```; #!/bin/bash; #SBATCH --job-name=deep64_13448198; #SBATCH --time=24:00:00; #SBATCH --nodes=2; #SBATCH --ntasks-per-node=1; #SBATCH --cpus-per-task=32; #SBATCH --mem=0. ml anaconda; conda activate /data/path.to.mydir/deepvariant. singularity run --bind /scratch4/path.to.mydir/:/scratch4/path.to.mydir/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref c_elegans.PRJNA13758.WS245.genomic.fa \; --reads aln13448198.pbmm2.bam \; --output_vcf aln13448198.pbmm2.dv.vcf.gz \; --num_shards 64; ```. Here's a long snippet of slurm output:; ```; INFO: Using cached SIF image; INFO: Converting SIF file to temporary sandbox...; I0217 20:13:14.117354 23456243894080 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmp1yvr59_z. ***** Intermediate results will be written to /tmp/tmp1yvr59_z in docker. ****. ***** Running the command:*****; time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref [snipped]. #[snip]; # this part is likely unimportant. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:26,Usability,clear,clear,26,"Deepvariant fails without clear reason. . **Setup**; JHU Rockfish HPC; Singularity 3.8.7; singularity pull docker://google/deepvariant:1.4.0. Problematic data are PacBio (first gen). I have used Deepvariant with Illumina without problem, and I used PEPPER to process Ont data and PacBio Hifi data. I used pbmm2 to align fastq with all PacBio data. Command used to run:; ```; #!/bin/bash; #SBATCH --job-name=deep64_13448198; #SBATCH --time=24:00:00; #SBATCH --nodes=2; #SBATCH --ntasks-per-node=1; #SBATCH --cpus-per-task=32; #SBATCH --mem=0. ml anaconda; conda activate /data/path.to.mydir/deepvariant. singularity run --bind /scratch4/path.to.mydir/:/scratch4/path.to.mydir/ \; docker://google/deepvariant:1.4.0 \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref c_elegans.PRJNA13758.WS245.genomic.fa \; --reads aln13448198.pbmm2.bam \; --output_vcf aln13448198.pbmm2.dv.vcf.gz \; --num_shards 64; ```. Here's a long snippet of slurm output:; ```; INFO: Using cached SIF image; INFO: Converting SIF file to temporary sandbox...; I0217 20:13:14.117354 23456243894080 run_deepvariant.py:342] Re-using the directory for intermediate results in /tmp/tmp1yvr59_z. ***** Intermediate results will be written to /tmp/tmp1yvr59_z in docker. ****. ***** Running the command:*****; time seq 0 63 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref [snipped]. #[snip]; # this part is likely unimportant. perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; 	LANGUAGE = (unset),; 	LC_ALL = (unset),; 	LC_CTYPE = ""C.UTF-8"",; 	LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/614:12736,Usability,simpl,simply,12736,"6737.31s elapsed]; I0218 10:46:36.864049 23456243894080 make_examples_core.py:243] Task 19/64: Skip phasing: len(candidates[main_sample]) is 20526.; I0218 10:48:19.364838 23456243894080 make_examples_core.py:243] Task 2/64: 158555 candidates (173735 examples) [4091.74s elapsed]; I0218 10:48:45.881830 23456243894080 make_examples_core.py:243] Task 2/64: Skip phasing: len(candidates[main_sample]) is 14234.; I0218 10:49:31.045118 23456243894080 make_examples_core.py:243] Task 13/64: 113956 candidates (125182 examples) [6317.67s elapsed]; I0218 10:50:33.895329 23456243894080 make_examples_core.py:243] Task 13/64: Skip phasing: len(candidates[main_sample]) is 18414.; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /scratch4/path.to.mydir/genomes/c_elegans.PRJNA13758.WS245.genomic.fa --reads /scratch4/path.to.mydir/pbmm2/aln13448198.pbmm2.bam --examples /tmp/tmp1yvr59_z/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 28. real	879m59.515s; user	632m52.969s; sys	6m20.594s; INFO: Cleaning up image... ```. I also ran more jobs using different numbers of cpu and mem using different bam files. One using 48 cpu and --mem-per-cpu=6G simply fizzled without any error message. These jobs are taking considerable core-hours, so troubleshooting is hard. I also wonder if I am using Deepvariant efficiently. On a side note, I got many Deepvariant failures with error messages like:; ```; Detected 1372 oom-kill event(s) in StepId=12049020.batch cgroup. Some of your processes may have been killed by the cgroup out-of-memory handler.; ```; This seems to have been resolved by asking for maximum allowable memory. I am still curious about the memory requirement for successfully running Deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/614
https://github.com/google/deepvariant/issues/616:36,Availability,down,download,36,"Hello！ I run the rawdata of NA12878 download from [NCBI SRA](https://trace.ncbi.nlm.nih.gov/Traces/?view=run_browser&acc=ERR1905890&display=data-access) []() and I got it's capture kit is Agilent_V5.; First, I run the **oqfe protocol** to align, and the output CRAM as the input of Deepvariant.; I run Deepvariant in WES model **3 times**, the first one didn't have --region parameter, the second one use a adding **50** bp buffer on each side of the custom target regions in BED format, the last one is adding **100** bp.; Next, I got the **truth** Benchmarking variant calls form GIAB and it's confident call regions to run hap.py.; The final outcome is very good, but I find a detail didn't make sense: as the bed lengthened，the SNP performed better and better, but INDEL on the contrary that it's getting worse since the number is decreasing, but I think it is making sense that the number becomes more as the bed gets longer, just like SNP. As shown in the figure below.; ![image](https://user-images.githubusercontent.com/63234787/220512170-4506359f-8c72-44ff-8585-e4357f24c20b.png); Can you give me a detailed explanation of this detail？ Thank you very much！ ; Finally, thank you very much for developing such a great tool！",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/616
https://github.com/google/deepvariant/issues/616:225,Integrability,protocol,protocol,225,"Hello！ I run the rawdata of NA12878 download from [NCBI SRA](https://trace.ncbi.nlm.nih.gov/Traces/?view=run_browser&acc=ERR1905890&display=data-access) []() and I got it's capture kit is Agilent_V5.; First, I run the **oqfe protocol** to align, and the output CRAM as the input of Deepvariant.; I run Deepvariant in WES model **3 times**, the first one didn't have --region parameter, the second one use a adding **50** bp buffer on each side of the custom target regions in BED format, the last one is adding **100** bp.; Next, I got the **truth** Benchmarking variant calls form GIAB and it's confident call regions to run hap.py.; The final outcome is very good, but I find a detail didn't make sense: as the bed lengthened，the SNP performed better and better, but INDEL on the contrary that it's getting worse since the number is decreasing, but I think it is making sense that the number becomes more as the bed gets longer, just like SNP. As shown in the figure below.; ![image](https://user-images.githubusercontent.com/63234787/220512170-4506359f-8c72-44ff-8585-e4357f24c20b.png); Can you give me a detailed explanation of this detail？ Thank you very much！ ; Finally, thank you very much for developing such a great tool！",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/616
https://github.com/google/deepvariant/issues/616:736,Performance,perform,performed,736,"Hello！ I run the rawdata of NA12878 download from [NCBI SRA](https://trace.ncbi.nlm.nih.gov/Traces/?view=run_browser&acc=ERR1905890&display=data-access) []() and I got it's capture kit is Agilent_V5.; First, I run the **oqfe protocol** to align, and the output CRAM as the input of Deepvariant.; I run Deepvariant in WES model **3 times**, the first one didn't have --region parameter, the second one use a adding **50** bp buffer on each side of the custom target regions in BED format, the last one is adding **100** bp.; Next, I got the **truth** Benchmarking variant calls form GIAB and it's confident call regions to run hap.py.; The final outcome is very good, but I find a detail didn't make sense: as the bed lengthened，the SNP performed better and better, but INDEL on the contrary that it's getting worse since the number is decreasing, but I think it is making sense that the number becomes more as the bed gets longer, just like SNP. As shown in the figure below.; ![image](https://user-images.githubusercontent.com/63234787/220512170-4506359f-8c72-44ff-8585-e4357f24c20b.png); Can you give me a detailed explanation of this detail？ Thank you very much！ ; Finally, thank you very much for developing such a great tool！",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/616
https://github.com/google/deepvariant/issues/616:145,Security,access,access,145,"Hello！ I run the rawdata of NA12878 download from [NCBI SRA](https://trace.ncbi.nlm.nih.gov/Traces/?view=run_browser&acc=ERR1905890&display=data-access) []() and I got it's capture kit is Agilent_V5.; First, I run the **oqfe protocol** to align, and the output CRAM as the input of Deepvariant.; I run Deepvariant in WES model **3 times**, the first one didn't have --region parameter, the second one use a adding **50** bp buffer on each side of the custom target regions in BED format, the last one is adding **100** bp.; Next, I got the **truth** Benchmarking variant calls form GIAB and it's confident call regions to run hap.py.; The final outcome is very good, but I find a detail didn't make sense: as the bed lengthened，the SNP performed better and better, but INDEL on the contrary that it's getting worse since the number is decreasing, but I think it is making sense that the number becomes more as the bed gets longer, just like SNP. As shown in the figure below.; ![image](https://user-images.githubusercontent.com/63234787/220512170-4506359f-8c72-44ff-8585-e4357f24c20b.png); Can you give me a detailed explanation of this detail？ Thank you very much！ ; Finally, thank you very much for developing such a great tool！",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/616
https://github.com/google/deepvariant/issues/616:550,Testability,Benchmark,Benchmarking,550,"Hello！ I run the rawdata of NA12878 download from [NCBI SRA](https://trace.ncbi.nlm.nih.gov/Traces/?view=run_browser&acc=ERR1905890&display=data-access) []() and I got it's capture kit is Agilent_V5.; First, I run the **oqfe protocol** to align, and the output CRAM as the input of Deepvariant.; I run Deepvariant in WES model **3 times**, the first one didn't have --region parameter, the second one use a adding **50** bp buffer on each side of the custom target regions in BED format, the last one is adding **100** bp.; Next, I got the **truth** Benchmarking variant calls form GIAB and it's confident call regions to run hap.py.; The final outcome is very good, but I find a detail didn't make sense: as the bed lengthened，the SNP performed better and better, but INDEL on the contrary that it's getting worse since the number is decreasing, but I think it is making sense that the number becomes more as the bed gets longer, just like SNP. As shown in the figure below.; ![image](https://user-images.githubusercontent.com/63234787/220512170-4506359f-8c72-44ff-8585-e4357f24c20b.png); Can you give me a detailed explanation of this detail？ Thank you very much！ ; Finally, thank you very much for developing such a great tool！",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/616
https://github.com/google/deepvariant/issues/617:151,Testability,test,testing,151,"Thanks for the wonderful tool! It's exciting to know that DeepVariant supports ONT Duplex Data.; I wonder what tools you use to generate bam files for testing. Assuming you use minimap2, what parameters did you use to generate optimal input for DeepVariant? Given the high accuracy of Duplex data, the default setting should not work well anymore because that's for old ONT data.; Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/617
https://github.com/google/deepvariant/issues/618:1236,Availability,Error,Error,1236,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Hello,. Using WES model, deepvariant calls the following variant in the vcf file:; ```; NC_000001.11	84574341	.	CAGCAGCGCT	C,T	.	.	.	GT:GQ:DP:AD:VAF:PL	1/0:3:97:25,45,26:0.463918,0.268041:36,0,47,0,16,44; ```. For this variant, the genotype is 1/0, meaning that one allele is REF, and the other allele is C. ; What is confusing is that deepvariant also calls a T however this is not referenced anywhere in the GT field. What is the point of calling T if it does not occur in the sample?. Here is the screenshot of the original alignment:. ![dv1](https://user-images.githubusercontent.com/22151692/223809460-b6cdeed1-e332-4014-879d-8ee44123f793.png). And here is the screenshot for the realigned reads for this position:. ![dv2](https://user-images.githubusercontent.com/22151692/223808774-d63a161c-e9f9-4e54-9546-2be3b9d5f492.png). **Setup**; - Operating system: Ubuntu; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/618
https://github.com/google/deepvariant/issues/618:1024,Deployability,Install,Installation,1024,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Hello,. Using WES model, deepvariant calls the following variant in the vcf file:; ```; NC_000001.11	84574341	.	CAGCAGCGCT	C,T	.	.	.	GT:GQ:DP:AD:VAF:PL	1/0:3:97:25,45,26:0.463918,0.268041:36,0,47,0,16,44; ```. For this variant, the genotype is 1/0, meaning that one allele is REF, and the other allele is C. ; What is confusing is that deepvariant also calls a T however this is not referenced anywhere in the GT field. What is the point of calling T if it does not occur in the sample?. Here is the screenshot of the original alignment:. ![dv1](https://user-images.githubusercontent.com/22151692/223809460-b6cdeed1-e332-4014-879d-8ee44123f793.png). And here is the screenshot for the realigned reads for this position:. ![dv2](https://user-images.githubusercontent.com/22151692/223808774-d63a161c-e9f9-4e54-9546-2be3b9d5f492.png). **Setup**; - Operating system: Ubuntu; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/618
https://github.com/google/deepvariant/issues/618:1289,Testability,test,test,1289,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Hello,. Using WES model, deepvariant calls the following variant in the vcf file:; ```; NC_000001.11	84574341	.	CAGCAGCGCT	C,T	.	.	.	GT:GQ:DP:AD:VAF:PL	1/0:3:97:25,45,26:0.463918,0.268041:36,0,47,0,16,44; ```. For this variant, the genotype is 1/0, meaning that one allele is REF, and the other allele is C. ; What is confusing is that deepvariant also calls a T however this is not referenced anywhere in the GT field. What is the point of calling T if it does not occur in the sample?. Here is the screenshot of the original alignment:. ![dv1](https://user-images.githubusercontent.com/22151692/223809460-b6cdeed1-e332-4014-879d-8ee44123f793.png). And here is the screenshot for the realigned reads for this position:. ![dv2](https://user-images.githubusercontent.com/22151692/223808774-d63a161c-e9f9-4e54-9546-2be3b9d5f492.png). **Setup**; - Operating system: Ubuntu; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/618
https://github.com/google/deepvariant/issues/618:1325,Testability,test,test,1325,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Hello,. Using WES model, deepvariant calls the following variant in the vcf file:; ```; NC_000001.11	84574341	.	CAGCAGCGCT	C,T	.	.	.	GT:GQ:DP:AD:VAF:PL	1/0:3:97:25,45,26:0.463918,0.268041:36,0,47,0,16,44; ```. For this variant, the genotype is 1/0, meaning that one allele is REF, and the other allele is C. ; What is confusing is that deepvariant also calls a T however this is not referenced anywhere in the GT field. What is the point of calling T if it does not occur in the sample?. Here is the screenshot of the original alignment:. ![dv1](https://user-images.githubusercontent.com/22151692/223809460-b6cdeed1-e332-4014-879d-8ee44123f793.png). And here is the screenshot for the realigned reads for this position:. ![dv2](https://user-images.githubusercontent.com/22151692/223808774-d63a161c-e9f9-4e54-9546-2be3b9d5f492.png). **Setup**; - Operating system: Ubuntu; - DeepVariant version: 1.2.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/618
https://github.com/google/deepvariant/issues/619:549,Availability,Error,Error,549,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; 'CUDA_ERROR_UNKNOWN' using DeepVariant GPU version. **Setup**; - Operating system: CentOS Linux release 7.4.1708 (Core), Linux 5.10.150-1.el7.x86_64; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity image build from dockerhub; - Type of data: nothing special that is unlike the case studies. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --version; - Error trace: (if applicable); ```; tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5; DeepVariant version 1.4.0; ```; The `hostname` is privacy. **Does the quick start test work on your system?:** No. **Any additional context:** ; The GPU is NVIDIA GeForce 3090; The GPU Driver Version: 520.61.05; The CUDA version in the host is V11.8.89 as followings:; ![image](https://user-images.githubusercontent.com/43125963/225341539-aa2ee3c6-c376-4758-a582-c8fd871b0508.png); It seems that the Deepvariant v1.4.0 in the singularity image has already installed CUDA v11.3. ; ![image](https://user-images.githubusercontent.com/43125963/225343337-d0924a9b-4b9d-4b03-848f-e8e9753eb377.png). I don't know whether it causes the program crash.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/619
https://github.com/google/deepvariant/issues/619:687,Availability,error,error,687,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; 'CUDA_ERROR_UNKNOWN' using DeepVariant GPU version. **Setup**; - Operating system: CentOS Linux release 7.4.1708 (Core), Linux 5.10.150-1.el7.x86_64; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity image build from dockerhub; - Type of data: nothing special that is unlike the case studies. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --version; - Error trace: (if applicable); ```; tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5; DeepVariant version 1.4.0; ```; The `hostname` is privacy. **Does the quick start test work on your system?:** No. **Any additional context:** ; The GPU is NVIDIA GeForce 3090; The GPU Driver Version: 520.61.05; The CUDA version in the host is V11.8.89 as followings:; ![image](https://user-images.githubusercontent.com/43125963/225341539-aa2ee3c6-c376-4758-a582-c8fd871b0508.png); It seems that the Deepvariant v1.4.0 in the singularity image has already installed CUDA v11.3. ; ![image](https://user-images.githubusercontent.com/43125963/225343337-d0924a9b-4b9d-4b03-848f-e8e9753eb377.png). I don't know whether it causes the program crash.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/619
https://github.com/google/deepvariant/issues/619:217,Deployability,release,release,217,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; 'CUDA_ERROR_UNKNOWN' using DeepVariant GPU version. **Setup**; - Operating system: CentOS Linux release 7.4.1708 (Core), Linux 5.10.150-1.el7.x86_64; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity image build from dockerhub; - Type of data: nothing special that is unlike the case studies. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --version; - Error trace: (if applicable); ```; tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5; DeepVariant version 1.4.0; ```; The `hostname` is privacy. **Does the quick start test work on your system?:** No. **Any additional context:** ; The GPU is NVIDIA GeForce 3090; The GPU Driver Version: 520.61.05; The CUDA version in the host is V11.8.89 as followings:; ![image](https://user-images.githubusercontent.com/43125963/225341539-aa2ee3c6-c376-4758-a582-c8fd871b0508.png); It seems that the Deepvariant v1.4.0 in the singularity image has already installed CUDA v11.3. ; ![image](https://user-images.githubusercontent.com/43125963/225343337-d0924a9b-4b9d-4b03-848f-e8e9753eb377.png). I don't know whether it causes the program crash.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/619
https://github.com/google/deepvariant/issues/619:303,Deployability,Install,Installation,303,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; 'CUDA_ERROR_UNKNOWN' using DeepVariant GPU version. **Setup**; - Operating system: CentOS Linux release 7.4.1708 (Core), Linux 5.10.150-1.el7.x86_64; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity image build from dockerhub; - Type of data: nothing special that is unlike the case studies. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --version; - Error trace: (if applicable); ```; tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5; DeepVariant version 1.4.0; ```; The `hostname` is privacy. **Does the quick start test work on your system?:** No. **Any additional context:** ; The GPU is NVIDIA GeForce 3090; The GPU Driver Version: 520.61.05; The CUDA version in the host is V11.8.89 as followings:; ![image](https://user-images.githubusercontent.com/43125963/225341539-aa2ee3c6-c376-4758-a582-c8fd871b0508.png); It seems that the Deepvariant v1.4.0 in the singularity image has already installed CUDA v11.3. ; ![image](https://user-images.githubusercontent.com/43125963/225343337-d0924a9b-4b9d-4b03-848f-e8e9753eb377.png). I don't know whether it causes the program crash.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/619
https://github.com/google/deepvariant/issues/619:1601,Deployability,install,installed,1601,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; 'CUDA_ERROR_UNKNOWN' using DeepVariant GPU version. **Setup**; - Operating system: CentOS Linux release 7.4.1708 (Core), Linux 5.10.150-1.el7.x86_64; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity image build from dockerhub; - Type of data: nothing special that is unlike the case studies. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --version; - Error trace: (if applicable); ```; tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5; DeepVariant version 1.4.0; ```; The `hostname` is privacy. **Does the quick start test work on your system?:** No. **Any additional context:** ; The GPU is NVIDIA GeForce 3090; The GPU Driver Version: 520.61.05; The CUDA version in the host is V11.8.89 as followings:; ![image](https://user-images.githubusercontent.com/43125963/225341539-aa2ee3c6-c376-4758-a582-c8fd871b0508.png); It seems that the Deepvariant v1.4.0 in the singularity image has already installed CUDA v11.3. ; ![image](https://user-images.githubusercontent.com/43125963/225343337-d0924a9b-4b9d-4b03-848f-e8e9753eb377.png). I don't know whether it causes the program crash.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/619
https://github.com/google/deepvariant/issues/619:1227,Testability,test,test,1227,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; 'CUDA_ERROR_UNKNOWN' using DeepVariant GPU version. **Setup**; - Operating system: CentOS Linux release 7.4.1708 (Core), Linux 5.10.150-1.el7.x86_64; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): singularity image build from dockerhub; - Type of data: nothing special that is unlike the case studies. **Steps to reproduce:**; - Command: /opt/deepvariant/bin/run_deepvariant --version; - Error trace: (if applicable); ```; tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: ; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: INVALID_ARGUMENT: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver version; got ""1""; tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 520.61.5; DeepVariant version 1.4.0; ```; The `hostname` is privacy. **Does the quick start test work on your system?:** No. **Any additional context:** ; The GPU is NVIDIA GeForce 3090; The GPU Driver Version: 520.61.05; The CUDA version in the host is V11.8.89 as followings:; ![image](https://user-images.githubusercontent.com/43125963/225341539-aa2ee3c6-c376-4758-a582-c8fd871b0508.png); It seems that the Deepvariant v1.4.0 in the singularity image has already installed CUDA v11.3. ; ![image](https://user-images.githubusercontent.com/43125963/225343337-d0924a9b-4b9d-4b03-848f-e8e9753eb377.png). I don't know whether it causes the program crash.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/619
https://github.com/google/deepvariant/pull/621:55,Deployability,update,update,55,This is an internal pull request that is meant to only update the `gh_pages` branch.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/621
https://github.com/google/deepvariant/issues/624:44,Availability,avail,available,44,"Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```; # works ; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; # fails; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:88,Availability,down,download,88,"Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```; # works ; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; # fails; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:152,Availability,error,error,152,"Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```; # works ; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; # fails; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:230,Availability,avail,available,230,"Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```; # works ; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; # fails; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/624:100,Usability,simpl,simply,100,"Hi,. The RNA-seq model in the case-study is available for version 1.4.0, but trying the download by simply replacing with 1.5.0 raises a file not found error. . Is or will there be an RNA-seq model for v1.5.0, or was this only be available for v1.4.0? . ```; # works ; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; # fails; curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.5.0/DeepVariant-inception_v3-1.5.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/624
https://github.com/google/deepvariant/issues/625:105,Availability,error,error,105,"Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6].; Traceback (most recent call last):; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" &&",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1730,Availability,checkpoint,checkpoint,1730,"s_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1795,Availability,checkpoint,checkpoint,1795,"s_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:1828,Availability,checkpoint,checkpoint,1828,"s_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2872,Availability,checkpoint,checkpoint,2872,"all_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing?. Thanks,; Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:18,Testability,test,tested,18,"Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6].; Traceback (most recent call last):; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" &&",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:57,Testability,test,testdata,57,"Helo everyone,. I tested DeepVariant 1.5.0 on quickstart-testdata, using WGS model and got the following error in call_variants.py script:. I0405 09:07:48.961947 140199643854656 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 6], Channels of input examples: [1, 2, 3, 4, 5, 6].; Traceback (most recent call last):; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" &&",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2002,Testability,LOG,LOGDIR,2002,"f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2026,Testability,log,logs,2026,"f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2047,Testability,LOG,LOGDIR,2047,"f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2135,Testability,LOG,LOGDIR,2135,"f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2143,Testability,log,log,2143,"f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2157,Testability,LOG,LOGDIR,2157,"f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:2719,Testability,log,log,2719,"all_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing?. Thanks,; Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3000,Testability,log,log,3000,"all_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing?. Thanks,; Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/625:3337,Testability,log,log,3337,"all_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/f68a72a7-7df6-41e6-a9cf-96fe9f05de7f/deepvariant/Bazel.runfiles_yms6j76p/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 363, in call_variants; raise ValueError('The number of channels in examples and checkpoint '; ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 6. My command line looks like this:. export HOME=/root && N_SHARDS=32 && GVCF_TFRECORDS=""./gvcf.tfrecord@${N_SHARDS}.gz"" && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --gvcf ./gvcf.tfrecord@${N_SHARDS}.gz --add_hp_channel --noadd_hp_channel --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/NA12878_S1.chr20.10_10p1mb.bam --regions /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/test_nist.b37_chr20_100kbp_at_10mb.bed --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --sample_name NA12878_S1 --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/wgs/model.ckpt --use_openvino --batch_size 512 --include_debug_info --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/ucsc.hg19.chr20.unittest.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./NA12878_S1.vcf --nonvariant_site_tfrecord_path ""${GVCF_TFRECORDS}"" --gvcf_outfile ./NA12878_S1.gvcf.gz ) > ./postprocess_variants.log 2>&1. Is there something I am missing?. Thanks,; Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/625
https://github.com/google/deepvariant/issues/626:604,Availability,avail,available,604,"I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`; deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/626:10,Testability,benchmark,benchmarking,10,"I ran the benchmarking using RTGtool for BWA-MEM + deepvariant 1.5.0 with 35x Illumina WGS data of HG002 (used in pFDA challenge) and compared the results with pFDA v2 challenge submission (BSODP here https://doi.org/10.18434/mds2-2336). I observed that the deepvariant 1.5.0 that I run has improved precision but lower recall. . pFDA v2 submission: `Precision: 0.9940, Recall: 0.9982 and F-score:0.9961`; deepvariant v1.5.0: `Precison: 0.9991 , recall: 0.9934, and -score: 0.9962`. I am just wondering if the pFDA submission has any extra filtering used after running deepvariant. Is there any publicly available deepvaraint v1.5.0 vcf for HG002?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/626
https://github.com/google/deepvariant/issues/627:131,Availability,error,error,131,"Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**; - Operating system: Centos; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**; - Command: dv_make_examples.py -h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/627:227,Deployability,Install,Installation,227,"Upon running dv_make_examples.py -h , dv_call_variants.py -h , or dv_postprocess_variants.py -h , python told me there is a syntax error around a f-string. **Setup**; - Operating system: Centos; - DeepVariant version: 1.4.0; - Installation method (Docker, built from source, etc.): bioconda. **Steps to reproduce:**; - Command: dv_make_examples.py -h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/627
https://github.com/google/deepvariant/issues/628:100,Availability,error,error,100,"Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```; 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; Traceback (most recent call last):; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3319,Availability,checkpoint,checkpoint,3319,"sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this?. Thanks,; Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:247,Performance,optimiz,optimized,247,"Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```; 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; Traceback (most recent call last):; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:347,Performance,perform,performance-critical,347,"Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```; 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; Traceback (most recent call last):; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:7,Testability,test,tested,7,"Hi,. I tested DeepVariant 1.5.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. ```; 2023-04-07 15:47:02.393512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0407 15:47:04.372007 140275094697792 call_variants.py:317] From ./examples.tfrecord-00000-of-00032.gz.example_info.json: Shape of input examples: [100, 221, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0407 15:47:04.374644 140275094697792 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; Traceback (most recent call last):; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2527,Testability,LOG,LOGDIR,2527,"es/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2551,Testability,log,logs,2551,"es/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2572,Testability,LOG,LOGDIR,2572,"es/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2660,Testability,LOG,LOGDIR,2660,"es/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2668,Testability,log,log,2668,"es/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:2682,Testability,LOG,LOGDIR,2682,"es/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3166,Testability,log,log,3166,"sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this?. Thanks,; Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3414,Testability,log,log,3414,"sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this?. Thanks,; Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/628:3652,Testability,log,log,3652,"sys.exit(main(argv)); File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/workspaces/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/tasks/499fbb3f-82af-4cc5-825b-d0c6b15c72bd/deepvariant/Bazel.runfiles_ncuuffv4/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 374, in call_variants; raise ValueError(f'Shape mismatch in {example_info_json} and '; ValueError: Shape mismatch in ./examples.tfrecord-00000-of-00032.gz.example_info.json and /opt/models/pacbio/model.ckpt.example_info.json.; ```. My command line looks like this:; `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --add_hp_channel --add_hp_channel --alt_aligned_pileup diff_channels --downsample_fraction 0 --reads /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/HG002.merged.bam --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --realign_reads --regions 20 --sample_name HG002 --split_skip_reads --vsc_min_count_indels 2 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --batch_size 512 --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/b7b5cc2c-7194-40e7-8598-aeb7f670ad77/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes ok. Do you have some input on this?. Thanks,; Raisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/628
https://github.com/google/deepvariant/issues/629:478,Deployability,pipeline,pipeline,478,"I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news!. -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/629:107,Performance,perform,performing,107,"I noticed a mention of VG giraffe evaluation in the 1.5 changelog. . Has your team evaluated the impact of performing indel realignment prior to variant calling VG giraffe-generated bamfiles? This is what was done in the vg giraffe-DeepVariant paper. . In my hands, the indel realignment step significantly adds to run time. If your team does not think it meaningfully improves accuracy beyond make_example's built in realignment algorithm, then I could remove the step from my pipeline. That would be welcome news!. -Joe Lalli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/629
https://github.com/google/deepvariant/issues/630:298,Performance,perform,performs,298,"Hi, . Is it possible to provide the number of forward-strand and reverse-strand reads supporting the reference allele and the alternate allele for each variant locus?. In short, if I want to keep the variant loci supported by both forward and reverse strands, what should I do? Because DeepVariant performs realignment, there may be differences between the alignment of the original BAM file and the after realigned. Best,; Wenfei",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/630
https://github.com/google/deepvariant/issues/631:39579,Availability,error,error,39579,0908051506_s1_p0/18204/0_11826: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083564: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/128181/16776_21715: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083624: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_023026_42163R_c100791492550000001823175409091556_s1_p0/94463/13434_17465: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083666: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150205_114659_42163R_c100780092550000001823165208251532_s1_p0/41607/2555_6463: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083710: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150209_042724_42177R_c100779832550000001823165208251590_s1_p0/129762/7102_9303: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083973: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150309_153203_42156_c100797772550000001823175109091511_s1_p0/155759/0_8477: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.084070: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_151228_42163R_c100797832550000001823175109091520_s1_p0/45204/2004_7491: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.111139: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (1261 vs. 0); Fatal Python error: Aborted. cmd:; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref hs37d5.fasta \; --reads HG003_PacBio_GRCh37.bam \; --output_vcf HG003_PacBio.depv.vcf.gz \; --output_gvcf HG003_PacBio.depv.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir intermediate_results_dir; ; What can i do to fix it?; Looking forward to your reply. Thanks.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:380,Performance,optimiz,optimized,380,"**hello,; I tested DeepVariant 1.5.0 on pacbio public data.; The data link is:; https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam; But it failed.; The log :** ; 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir; ***** Intermediate results will be written to intermediate_results_dir in docker. ****; ***** Running the command:*****; time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimiz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:480,Performance,perform,performance-critical,480,"**hello,; I tested DeepVariant 1.5.0 on pacbio public data.; The data link is:; https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam; But it failed.; The log :** ; 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir; ***** Intermediate results will be written to intermediate_results_dir in docker. ****; ***** Running the command:*****; time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimiz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1631,Performance,optimiz,optimized,1631,"ults in intermediate_results_dir; ***** Intermediate results will be written to intermediate_results_dir in docker. ****; ***** Running the command:*****; time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1731,Performance,perform,performance-critical,1731,"ults in intermediate_results_dir; ***** Intermediate results will be written to intermediate_results_dir in docker. ****; ***** Running the command:*****; time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:1994,Performance,optimiz,optimized,1994,"mples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2094,Performance,perform,performance-critical,2094,"mples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2357,Performance,optimiz,optimized,2357,"_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2457,Performance,perform,performance-critical,2457,"_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2720,Performance,optimiz,optimized,2720,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:2820,Performance,perform,performance-critical,2820,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3083,Performance,optimiz,optimized,3083,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3183,Performance,perform,performance-critical,3183,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.431128: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3446,Performance,optimiz,optimized,3446,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3546,Performance,perform,performance-critical,3546,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.649384: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3809,Performance,optimiz,optimized,3809,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:3909,Performance,perform,performance-critical,3909,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.283502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4172,Performance,optimiz,optimized,4172,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4272,Performance,perform,performance-critical,4272,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.696454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4535,Performance,optimiz,optimized,4535,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4635,Performance,perform,performance-critical,4635,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.910042: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4898,Performance,optimiz,optimized,4898,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:4998,Performance,perform,performance-critical,4998,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.104699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5261,Performance,optimiz,optimized,5261,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5361,Performance,perform,performance-critical,5361,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:37.553518: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5624,Performance,optimiz,optimized,5624,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5724,Performance,perform,performance-critical,5724,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.222775: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:5987,Performance,optimiz,optimized,5987,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6087,Performance,perform,performance-critical,6087,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.003846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6350,Performance,optimiz,optimized,6350,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6450,Performance,perform,performance-critical,6450,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:38.914371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6713,Performance,optimiz,optimized,6713,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:6813,Performance,perform,performance-critical,6813,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.018427: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7076,Performance,optimiz,optimized,7076,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7176,Performance,perform,performance-critical,7176,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.422219: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7439,Performance,optimiz,optimized,7439,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7539,Performance,perform,performance-critical,7539,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.063431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7802,Performance,optimiz,optimized,7802,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:7902,Performance,perform,performance-critical,7902,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.062198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8165,Performance,optimiz,optimized,8165,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8265,Performance,perform,performance-critical,8265,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:39.979949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8528,Performance,optimiz,optimized,8528,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8628,Performance,perform,performance-critical,8628,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.478141: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8891,Performance,optimiz,optimized,8891,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:8991,Performance,perform,performance-critical,8991,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.621575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9254,Performance,optimiz,optimized,9254,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9354,Performance,perform,performance-critical,9354,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.375862: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9617,Performance,optimiz,optimized,9617,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9717,Performance,perform,performance-critical,9717,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.851554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:9980,Performance,optimiz,optimized,9980,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.598038 14030139717817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10080,Performance,perform,performance-critical,10080,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.520879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.598038 14030139717817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10343,Performance,optimiz,optimized,10343,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10443,Performance,perform,performance-critical,10443,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:40.835700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10706,Performance,optimiz,optimized,10706,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:10806,Performance,perform,performance-critical,10806,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.522882: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.200511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:41.688520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.598038 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:42.617601 140301397178176 make_examples_core.py:257] Task 0/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:42.913093 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:42.934488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12378,Performance,optimiz,optimized,12378,"34488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12478,Performance,perform,performance-critical,12478,"34488 140301397178176 make_examples_core.py:257] Task 0/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; I0413 03:58:43.149506 140301397178176 make_examples_core.py:257] Task 0/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12741,Performance,optimiz,optimized,12741," are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12841,Performance,perform,performance-critical,12841," are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2023-04-13 03:58:43.152070: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:43.528447 140301397178176 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13104,Performance,optimiz,optimized,13104,"2] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.143414 14013848112518",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13204,Performance,perform,performance-critical,13204,"2] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; 2023-04-13 03:58:42.555017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.143414 14013848112518",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13467,Performance,optimiz,optimized,13467,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13567,Performance,perform,performance-critical,13567,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.980837: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13830,Performance,optimiz,optimized,13830,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:13930,Performance,perform,performance-critical,13930,"rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.565788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.798464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:42.381208: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.143414 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.163062 140138481125184 make_examples_core.py:257] Task 6/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15241,Performance,optimiz,optimized,15241,"py:257] Task 6/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs; 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:15341,Performance,perform,performance-critical,15341,"py:257] Task 6/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.217749 140138481125184 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.238726 140138481125184 make_examples_core.py:257] Task 6/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:44.459303 140102426851136 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:44.479173 140102426851136 make_examples_core.py:257] Task 8/32: Preparing inputs; 2023-04-13 03:58:42.980890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:43.703165 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:43.723608 140193998387008 make_examples_core.py:257] Task 1/32: Preparing inputs; [W::hts_idx_load3] The index file is older than the data file: HG003_PacBio_GRCh37.bam.bai; I0413 03:58:43.837812 140193998387008 genomics_reader.py:222] Reading HG003_PacBio_GRCh37.bam with NativeSamReader; I0413 03:58:43.859502 140193998387008 make_examples_core.py:257] Task 1/32: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']; I0413 03:58:44.071241 140193998387008 make_examples_core.py:257] Task 1/32: Starting from v0.9.0, --use_ref_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:39586,Safety,Abort,Aborted,39586,0908051506_s1_p0/18204/0_11826: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083564: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m141207_021027_42177R_c100762112550000001823161707071506_s1_p0/128181/16776_21715: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083624: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_023026_42163R_c100791492550000001823175409091556_s1_p0/94463/13434_17465: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083666: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150205_114659_42163R_c100780092550000001823165208251532_s1_p0/41607/2555_6463: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083710: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150209_042724_42177R_c100779832550000001823165208251590_s1_p0/129762/7102_9303: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.083973: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150309_153203_42156_c100797772550000001823175109091511_s1_p0/155759/0_8477: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.084070: W third_party/nucleus/io/sam_reader.cc:599] Could not read base quality scores m150304_151228_42163R_c100797832550000001823175109091520_s1_p0/45204/2004_7491: NOT_FOUND: Could not read base quality scores; 2023-04-13 03:58:45.111139: F deepvariant/allelecounter.cc:198] Check failed: offset + len <= read.aligned_quality_size() (1261 vs. 0); Fatal Python error: Aborted. cmd:; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref hs37d5.fasta \; --reads HG003_PacBio_GRCh37.bam \; --output_vcf HG003_PacBio.depv.vcf.gz \; --output_gvcf HG003_PacBio.depv.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir intermediate_results_dir; ; What can i do to fix it?; Looking forward to your reply. Thanks.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:12,Testability,test,tested,12,"**hello,; I tested DeepVariant 1.5.0 on pacbio public data.; The data link is:; https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam; But it failed.; The log :** ; 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir; ***** Intermediate results will be written to intermediate_results_dir in docker. ****; ***** Running the command:*****; time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimiz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/631:263,Testability,log,log,263,"**hello,; I tested DeepVariant 1.5.0 on pacbio public data.; The data link is:; https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/AshkenazimTrio/HG003_NA24149_father/PacBio_MtSinai_NIST/PacBio_minimap2_bam/HG003_PacBio_GRCh37.bam; But it failed.; The log :** ; 2023-04-13 03:58:10.677743: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0413 03:58:12.505982 140621665130304 run_deepvariant.py:364] Re-using the directory for intermediate results in intermediate_results_dir; ***** Intermediate results will be written to intermediate_results_dir in docker. ****; ***** Running the command:*****; time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/sfs-GCS/ann-BIstorage/DB/data/sentieon/hs37d5/hs37d5.fasta"" --reads ""HG003_PacBio_GRCh37.bam"" --examples ""intermediate_results_dir/make_examples.tfrecord@32.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --gvcf ""intermediate_results_dir/gvcf.tfrecord@32.gz"" --max_reads_per_partition ""600"" --min_mapping_quality ""1"" --parse_sam_aux_fields --partition_size ""25000"" --phase_reads --pileup_image_width ""199"" --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels ""0.12"" --task {}; ; 2023-04-13 03:58:35.887616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-04-13 03:58:36.520424: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimiz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/631
https://github.com/google/deepvariant/issues/632:641,Availability,Error,Error,641,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**; - Operating system: Ubuntu 22.04, Docker 23+; - DeepVariant version: deeptrio-1.5.0-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; realtimegenomics/rtg-tools format \; -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta""; ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; -v ""${PWD}/output"":""/output"" \; realtimegenomics/rtg-tools mendelian \; -i ""/output/HG002_trio_merged.vcf.gz"" \; -o ""/output/HG002_trio_annotated.output.vcf.gz"" \; --pedigree=/reference/trio.ped \; -t /reference/GRCh38_no_alt_analysis_set.sdf \; | tee output/deepvariant.input_rtg_output.txt; ``` . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:689,Availability,Error,Error,689,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**; - Operating system: Ubuntu 22.04, Docker 23+; - DeepVariant version: deeptrio-1.5.0-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; realtimegenomics/rtg-tools format \; -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta""; ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; -v ""${PWD}/output"":""/output"" \; realtimegenomics/rtg-tools mendelian \; -i ""/output/HG002_trio_merged.vcf.gz"" \; -o ""/output/HG002_trio_annotated.output.vcf.gz"" \; --pedigree=/reference/trio.ped \; -t /reference/GRCh38_no_alt_analysis_set.sdf \; | tee output/deepvariant.input_rtg_output.txt; ``` . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1203,Availability,error,error,1203,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**; - Operating system: Ubuntu 22.04, Docker 23+; - DeepVariant version: deeptrio-1.5.0-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; realtimegenomics/rtg-tools format \; -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta""; ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; -v ""${PWD}/output"":""/output"" \; realtimegenomics/rtg-tools mendelian \; -i ""/output/HG002_trio_merged.vcf.gz"" \; -o ""/output/HG002_trio_annotated.output.vcf.gz"" \; --pedigree=/reference/trio.ped \; -t /reference/GRCh38_no_alt_analysis_set.sdf \; | tee output/deepvariant.input_rtg_output.txt; ``` . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1220,Availability,Error,Error,1220,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**; - Operating system: Ubuntu 22.04, Docker 23+; - DeepVariant version: deeptrio-1.5.0-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; realtimegenomics/rtg-tools format \; -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta""; ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; -v ""${PWD}/output"":""/output"" \; realtimegenomics/rtg-tools mendelian \; -i ""/output/HG002_trio_merged.vcf.gz"" \; -o ""/output/HG002_trio_annotated.output.vcf.gz"" \; --pedigree=/reference/trio.ped \; -t /reference/GRCh38_no_alt_analysis_set.sdf \; | tee output/deepvariant.input_rtg_output.txt; ``` . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:429,Deployability,Install,Installation,429,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**; - Operating system: Ubuntu 22.04, Docker 23+; - DeepVariant version: deeptrio-1.5.0-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; realtimegenomics/rtg-tools format \; -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta""; ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; -v ""${PWD}/output"":""/output"" \; realtimegenomics/rtg-tools mendelian \; -i ""/output/HG002_trio_merged.vcf.gz"" \; -o ""/output/HG002_trio_annotated.output.vcf.gz"" \; --pedigree=/reference/trio.ped \; -t /reference/GRCh38_no_alt_analysis_set.sdf \; | tee output/deepvariant.input_rtg_output.txt; ``` . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1690,Testability,test,test,1690,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**; - Operating system: Ubuntu 22.04, Docker 23+; - DeepVariant version: deeptrio-1.5.0-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; realtimegenomics/rtg-tools format \; -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta""; ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; -v ""${PWD}/output"":""/output"" \; realtimegenomics/rtg-tools mendelian \; -i ""/output/HG002_trio_merged.vcf.gz"" \; -o ""/output/HG002_trio_annotated.output.vcf.gz"" \; --pedigree=/reference/trio.ped \; -t /reference/GRCh38_no_alt_analysis_set.sdf \; | tee output/deepvariant.input_rtg_output.txt; ``` . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/632:1726,Testability,test,test,1726,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Having problem running deeptrio examples [https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md](https://github.com/google/deepvariant/blob/r1.5/docs/deeptrio-wgs-case-study.md) . **Setup**; - Operating system: Ubuntu 22.04, Docker 23+; - DeepVariant version: deeptrio-1.5.0-gpu; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). It always give ```Error: The directory ""/reference/GRCh38_no_alt_analysis_set.sdf"" already exists. Please remove it first or choose a different directory.``` even after I ensure that there are no GRCh38_no_alt_analysis_set.sdf exist in said directory; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; realtimegenomics/rtg-tools format \; -o /reference/GRCh38_no_alt_analysis_set.sdf ""/reference/GRCh38_no_alt_analysis_set.fasta""; ```. And that being said, this command also raises another error showing ```Error: An IO problem occurred: ""Not in GZIP format""```; ```; sudo docker run \; -v ""${PWD}/input"":""/input"" \; -v ""${PWD}/reference"":""/reference"" \; -v ""${PWD}/output"":""/output"" \; realtimegenomics/rtg-tools mendelian \; -i ""/output/HG002_trio_merged.vcf.gz"" \; -o ""/output/HG002_trio_annotated.output.vcf.gz"" \; --pedigree=/reference/trio.ped \; -t /reference/GRCh38_no_alt_analysis_set.sdf \; | tee output/deepvariant.input_rtg_output.txt; ``` . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start? **Quick start on single variant analysis is optimal**. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/632
https://github.com/google/deepvariant/issues/633:1344,Availability,down,downstream,1344,"variant and merged these with GLnexus as recommended. However, there seems to be an issue in the final merged VCF file. Many genotypes are called as 0/0 when they have very low or zero DP:; e.g. ; `; 1	1319056	1_1319056_A_G	A	G	51	.	AF=0.32848;AQ=51	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:3:29,6,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. ; So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you!. **Setup**; - Operating system: linux/cluster; - DeepVariant version: latest (1.5); - Installation method: Docker; - Type of data: ; Illumina WES data (.cram to .gvcf). **Steps to reproduce:**; - Command:; ```; glnexus_cli --config DeepVariant --bed ${regions} \; folder/*.g.vcf.gz > output.bcf; ```. - Error trace: no errors. This is the vcf header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##GLnexusVersion=v1.4.1-0-g68e25e5; ##GLnexusConfigName=DeepVariant; ##GLnexusConfigCRC32C=2932316105; ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1527,Availability,down,downstream,1527," have very low or zero DP:; e.g. ; `; 1	1319056	1_1319056_A_G	A	G	51	.	AF=0.32848;AQ=51	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:3:29,6,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. ; So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you!. **Setup**; - Operating system: linux/cluster; - DeepVariant version: latest (1.5); - Installation method: Docker; - Type of data: ; Illumina WES data (.cram to .gvcf). **Steps to reproduce:**; - Command:; ```; glnexus_cli --config DeepVariant --bed ${regions} \; folder/*.g.vcf.gz > output.bcf; ```. - Error trace: no errors. This is the vcf header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##GLnexusVersion=v1.4.1-0-g68e25e5; ##GLnexusConfigName=DeepVariant; ##GLnexusConfigCRC32C=2932316105; ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1963,Availability,Error,Error,1963,"II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. ; So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you!. **Setup**; - Operating system: linux/cluster; - DeepVariant version: latest (1.5); - Installation method: Docker; - Type of data: ; Illumina WES data (.cram to .gvcf). **Steps to reproduce:**; - Command:; ```; glnexus_cli --config DeepVariant --bed ${regions} \; folder/*.g.vcf.gz > output.bcf; ```. - Error trace: no errors. This is the vcf header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##GLnexusVersion=v1.4.1-0-g68e25e5; ##GLnexusConfigName=DeepVariant; ##GLnexusConfigCRC32C=2932316105; ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1979,Availability,error,errors,1979,"II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. ; So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you!. **Setup**; - Operating system: linux/cluster; - DeepVariant version: latest (1.5); - Installation method: Docker; - Type of data: ; Illumina WES data (.cram to .gvcf). **Steps to reproduce:**; - Command:; ```; glnexus_cli --config DeepVariant --bed ${regions} \; folder/*.g.vcf.gz > output.bcf; ```. - Error trace: no errors. This is the vcf header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##GLnexusVersion=v1.4.1-0-g68e25e5; ##GLnexusConfigName=DeepVariant; ##GLnexusConfigCRC32C=2932316105; ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,Type=Integer,Description=\""Approximate read depth (reads with MQ=255 or with bad mates are fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:269,Deployability,pipeline,pipeline,269,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yep. **Describe the issue:**; The issue is actually with GLnexus, however noone is replying there (people with same issues), and since it is recommended here in the deepvariant pipeline, I thought I would ask here. . I have produced a large set of gVCF files using deepvariant and merged these with GLnexus as recommended. However, there seems to be an issue in the final merged VCF file. Many genotypes are called as 0/0 when they have very low or zero DP:; e.g. ; `; 1	1319056	1_1319056_A_G	A	G	51	.	AF=0.32848;AQ=51	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,0,0:..	1/1:2:0,2:3:29,6,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. ; So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you!. **Setup**; - Operating system: linux/cluster; - DeepVariant version: latest (1.5); - Installation method: Docker; - Type of data: ; Illumina WES data (.cram to .gvcf). **Steps to reproduce:**; - Command:; ```; glnexus_cli --config DeepVariant --bed ${regions} \; folder/*.g.vcf.gz > output.bcf; ```. - Error trace: no errors. This is the vc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1746,Deployability,Install,Installation,1746,",0:II	0/1:2:0,2:1:12,2,0:..	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. ; So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you!. **Setup**; - Operating system: linux/cluster; - DeepVariant version: latest (1.5); - Installation method: Docker; - Type of data: ; Illumina WES data (.cram to .gvcf). **Steps to reproduce:**; - Command:; ```; glnexus_cli --config DeepVariant --bed ${regions} \; folder/*.g.vcf.gz > output.bcf; ```. - Error trace: no errors. This is the vcf header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##GLnexusVersion=v1.4.1-0-g68e25e5; ##GLnexusConfigName=DeepVariant; ##GLnexusConfigCRC32C=2932316105; ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_form",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:1885,Modifiability,config,config,1885,"29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:5:0,5:9:40,12,0:..	1/1:3:0,3:7:36,10,0:..	0/0:0:0,0:1:0,3,29:.`. This is messing with downstream analysis, and overall just looks like poor QC. Additionally, the annotation/filter field is missing. In the gVCFs there was still a ""PASS"" label. This is also required for downstream analysis. ; So I am wondering where I went wrong, or whether there is a more suitable software to merge gVCFs. Thank you!. **Setup**; - Operating system: linux/cluster; - DeepVariant version: latest (1.5); - Installation method: Docker; - Type of data: ; Illumina WES data (.cram to .gvcf). **Steps to reproduce:**; - Command:; ```; glnexus_cli --config DeepVariant --bed ${regions} \; folder/*.g.vcf.gz > output.bcf; ```. - Error trace: no errors. This is the vcf header:; ```; ##fileformat=VCFv4.2; ##FILTER=<ID=PASS,Description=""All filters passed"">; ##GLnexusVersion=v1.4.1-0-g68e25e5; ##GLnexusConfigName=DeepVariant; ##GLnexusConfigCRC32C=2932316105; ##GLnexusConfig={unifier_config: {drop_filtered: false, min_allele_copy_number: 1, min_AQ1: 10, min_AQ2: 10, min_GQ: 0, max_alleles_per_site: 32, monoallelic_sites_for_lost_alleles: true, preference: common}, genotyper_config: {revise_genotypes: true, min_assumed_allele_frequency: 9.99999975e-05, snv_prior_calibration: 0.600000024, indel_prior_calibration: 0.449999988, required_dp: 0, allow_partial_data: true, allele_dp_format: AD, ref_dp_format: MIN_DP, output_residuals: false, more_PL: true, squeeze: false, trim_uncalled_alleles: true, top_two_half_calls: false, output_format: BCF, liftover_fields: [{orig_names: [MIN_DP, DP], name: DP, description: ""##FORMAT=<ID=DP,Number=1,T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/633:4883,Testability,assert,assertion,4883,"non_variants: false}, {orig_names: [GQ], name: GQ, description: ""##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=\""Genotype Quality\"">"", type: int, number: basic, default_type: missing, count: 1, combi_method: min, ignore_non_variants: true}, {orig_names: [PL], name: PL, description: ""##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\""Phred-scaled genotype Likelihoods\"">"", type: int, number: genotype, default_type: missing, count: 0, combi_method: missing, ignore_non_variants: true}]}}; ##INFO=<ID=AF,Number=A,Type=Float,Description=""Allele Frequency estimate for each alternate allele"">; ##INFO=<ID=AQ,Number=A,Type=Integer,Description=""Allele Quality score reflecting evidence for each alternate allele (Phred scale)"">; ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes"">; ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">; ##FILTER=<ID=MONOALLELIC,Description=""Site represents one ALT allele in a region with multiple variants that could not be unified into non-overlapping multi-allelic sites"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=RNC,Number=2,Type=Character,Description=""Reason for No Call in GT: . = n/a, M = Missing data, P = Partial data, I = gVCF input site is non-called, D = insufficient Depth of coverage, - = unrepresentable overlapping deletion, L = Lost/unrepresentable allele (other than deletion), U = multiple Unphased variants present, O = multiple Overlapping variants present, 1 = site is Monoallelic, no assertion about presence of REF or ALT allele"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype Likelihoods"">; ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/633
https://github.com/google/deepvariant/issues/634:842,Availability,Error,Error,842,"- Command:#docker; BIN_VERSION=""1.5.0""; reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference; INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input; OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir; singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \; --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ; - Error trace: INFO: Using cached SIF image; WARNING: Could not find any nv files on this host!; 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>; from ._api.v2 import compat; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>; from . import v1; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>; from . import compat; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>; from . import v2; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:867,Performance,cache,cached,867,"- Command:#docker; BIN_VERSION=""1.5.0""; reference=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/reference; INPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/input; OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir; singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \; --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ; - Error trace: INFO: Using cached SIF image; WARNING: Could not find any nv files on this host!; 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>; from ._api.v2 import compat; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>; from . import v1; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>; from . import compat; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>; from . import v2; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1044,Performance,optimiz,optimized,1044,"ef_annotation_Geneset/11.variant_calling/deepvariant/input; OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir; singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \; --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ; - Error trace: INFO: Using cached SIF image; WARNING: Could not find any nv files on this host!; 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>; from ._api.v2 import compat; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>; from . import v1; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>; from . import compat; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>; from . import v2; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>; from tensorflow._api.v2.compat.v2 import __internal__; File ""/usr/local/lib/python3.8/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/634:1144,Performance,perform,performance-critical,1144,"ef_annotation_Geneset/11.variant_calling/deepvariant/input; OUTPUT_DIR=/home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/outdir; singularity run --nv -B /home/data/ref_annotation_Geneset/11.variant_calling/deepvariant/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=""${reference}""/GRCh38_no_alt_analysis_set.fasta \; --reads=""${INPUT_DIR}""/HG003.novaseq.wes_idt.100x.dedup.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \; --num_shards=1; ; - Error trace: INFO: Using cached SIF image; WARNING: Could not find any nv files on this host!; 2023-04-22 17:10:50.025707: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>; import tensorflow as tf; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 51, in <module>; from ._api.v2 import compat; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py"", line 37, in <module>; from . import v1; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py"", line 30, in <module>; from . import compat; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py"", line 38, in <module>; from . import v2; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py"", line 28, in <module>; from tensorflow._api.v2.compat.v2 import __internal__; File ""/usr/local/lib/python3.8/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/634
https://github.com/google/deepvariant/issues/635:13,Testability,test,testing,13,"hello,; I am testing RNA-seq data with deepvarian1.4. ; I have some questions about：; 1. Is GATK SplitNCigarReads necessary for input bam?; 2. Could you explain in detail what the parameter ""--make_examples_extra_args=""split_skip_reads=true, channels=''"" dose?; 3. Does the RNAseq model only apply to the CDS region?; Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/635
https://github.com/google/deepvariant/issues/636:635,Availability,error,error,635,"Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `; python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10; `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:705,Availability,checkpoint,checkpoint,705,"Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `; python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10; `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:942,Availability,checkpoint,checkpoints,942,". I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `; python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10; `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1075,Availability,checkpoint,checkpoint,1075,". I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `; python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10; `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2040,Availability,checkpoint,checkpoint,2040,"bove command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed; raise AssertionError(; AssertionError: Some objects had attributes which were not restored:; <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------; Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_.; Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_?. Thanks,; Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2051,Availability,checkpoint,checkpoint,2051,"bove command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed; raise AssertionError(; AssertionError: Some objects had attributes which were not restored:; <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------; Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_.; Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_?. Thanks,; Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2317,Availability,checkpoint,checkpoint,2317,"bove command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed; raise AssertionError(; AssertionError: Some objects had attributes which were not restored:; <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------; Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_.; Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_?. Thanks,; Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:76,Deployability,release,release,76,"Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `; python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10; `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:641,Integrability,message,message,641,"Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `; python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10; `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:1038,Integrability,message,message,1038,". I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `; python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10; `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:789,Modifiability,variab,variables,789,"Hello,. I tried running ""_run_deepvariant_keras.py_"" script from the latest release of deepvaraint and faced some issues while running the keras-based call variant module. . I used the following command to run:. `; python bazel-out/k8-opt/bin/deepvariant/run_deepvariant_keras.py --model_type=WGS --ref=ref.fa --reads=reads.bam --regions ""chr19"" --output_vcf=${OUTPUT_DIR}/output.vcf.gz --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz --intermediate_results_dir ${OUTPUT_DIR}/intermediate_results_dir --num_shards=10; `. The above command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2195,Modifiability,Variab,Variable,2195,"bove command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed; raise AssertionError(; AssertionError: Some objects had attributes which were not restored:; <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------; Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_.; Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_?. Thanks,; Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2104,Testability,Assert,AssertionError,2104,"bove command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed; raise AssertionError(; AssertionError: Some objects had attributes which were not restored:; <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------; Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_.; Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_?. Thanks,; Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/636:2121,Testability,Assert,AssertionError,2121,"bove command successfully ran for _make_example_ module and failed at _call_varaint_keras.py_ with the following error message.. -------------. _Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 399, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 312, in run_; _run_main(main, args); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 387, in main; call_variants(; File ""/tmp/Bazel.runfiles_004ga1wn/runfiles/com_google_deepvariant/deepvariant/call_variants_keras.py"", line 344, in call_variants; model.load_weights(checkpoint_path).expect_partial(); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed; raise AssertionError(; AssertionError: Some objects had attributes which were not restored:; <tf.Variable 'classification/kernel:0' shape=(2048, 3) dtype=float32, numpy=_. ------------; Please note that I used the same checkpoint path as I was using while running _run_deepvariant.py_.; Could you please help me to resolve the issue and suggest if I am missing anything while using _call_varaint_keras.py_?. Thanks,; Saurabh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/636
https://github.com/google/deepvariant/issues/639:379,Deployability,Install,Installation,379,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**; - Operating system: Linux; - DeepVariant version: 1.5; - Installation method (Docker, built from source, etc.): Docker; - Type of data: WES Data (Illumina). **Steps to reproduce:**; - Command:; - ; DeepVariant:. ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref ${ref} \; --reads ${cram_in} \; --regions ${regions} \; --output_gvcf ${sample}.g.vcf.gz \; --output_vcf ${sample}.vcf.gz \; --num_shards 8 \; ```. GLNexus:. ```; glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf; bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz; bcftools index Exomes.vcf.gz; ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):; ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29; 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0; 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29; 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0; 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29; 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0; 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,990,990,990; 1	69848	.	G	<*>	0	.	END=69920	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/639:782,Modifiability,config,config,782,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; I do not understand how Deepvariant decides if there is a call at sites with low/zero GQ/DP... below is an example of a merged VCF with GLNexus and the same sites in the individual gVCFs. . **Setup**; - Operating system: Linux; - DeepVariant version: 1.5; - Installation method (Docker, built from source, etc.): Docker; - Type of data: WES Data (Illumina). **Steps to reproduce:**; - Command:; - ; DeepVariant:. ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref ${ref} \; --reads ${cram_in} \; --regions ${regions} \; --output_gvcf ${sample}.g.vcf.gz \; --output_vcf ${sample}.vcf.gz \; --num_shards 8 \; ```. GLNexus:. ```; glnexus_cli --config DeepVariantWES --bed /work_beegfs/***/exomes/hg38_exomregions_withoutCHR.bed /work_beegfs/***/exomes/2_gvcf/*.g.vcf.gz > /work_beegfs/***/exomes/3_bcf/Exomes.bcf; bcftools view ../3_bcf/Exomes.bcf | bgzip -@ 4 -c > Exomes.vcf.gz; bcftools index Exomes.vcf.gz; ```. Merged VCF with GLNexus:. `1	69897	1_69897_T_C	T	C	48	.	AF=0.076465;AQ=48	GT:DP:AD:GQ:PL:RNC	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,3,29:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	0/0:0:0,0:1:0,0,0:..	1/1:3:0,3:15:31,19,0:..	0/0:0:0,0:1:0,3,29:..	./.:6:2,4:8:0,8,13:II	./.:1:1,0:0:29,3,0:II	1/1:2:0,2:7:13,11,0:..	./.:1:1,0:0:29,3,0:II`. Same site/samples gVCF (each line is one sample in same order as merged file above):; ```. 1	69792	.	T	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29; 1	69638	.	C	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0; 1	69850	.	C	<*>	0	.	END=69929	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29; 1	69897	.	T	<*>	0	.	END=69897	GT:GQ:MIN_DP:PL	./.:0:1:29,3,0; 1	69683	.	T	<*>	0	.	END=69911	GT:GQ:MIN_DP:PL	0/0:1:0:0,3,29; 1	69037	.	G	<*>	0	.	END=70036	GT:GQ:MIN_DP:PL	0/0:1:0:0,0,0; 1	69897	.	T	C,<*>	31.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:19:3:0,3,0:1,0:31,19,0,990,990,990; 1	69848	.	G	<*>	0	.	END=69920	GT:GQ:M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/639
https://github.com/google/deepvariant/issues/640:245,Availability,ERROR,ERROR,245,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**; (A clear and concise description of what the issue is.); CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**; - Operating system: Ubuntu 18.04 (bionic); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:; BIN_VERSION=""1.5.0""; singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); EXAMPLE DATA PROVIDED. **Steps to reproduce:**; - Command:. INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1519,Availability,Error,Error,1519,"to solve this problem. **Setup**; - Operating system: Ubuntu 18.04 (bionic); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:; BIN_VERSION=""1.5.0""; singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); EXAMPLE DATA PROVIDED. **Steps to reproduce:**; - Command:. INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:646,Deployability,Install,Installation,646,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**; (A clear and concise description of what the issue is.); CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**; - Operating system: Ubuntu 18.04 (bionic); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:; BIN_VERSION=""1.5.0""; singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); EXAMPLE DATA PROVIDED. **Steps to reproduce:**; - Command:. INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1849,Integrability,Message,Message,1849,"equencing instrument, reference genome, anything special that is unlike the case studies?); EXAMPLE DATA PROVIDED. **Steps to reproduce:**; - Command:. INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1966,Performance,optimiz,optimized,1966,"tart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:2066,Performance,perform,performance-critical,2066,"tart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3218,Performance,optimiz,optimized,3218," /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs; I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']; I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728; I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:3318,Performance,perform,performance-critical,3318," /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****; time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. 2023-05-02 14:41:58.436801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0502 14:42:09.254817 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0502 14:42:09.301696 140040320145216 make_examples_core.py:257] Preparing inputs; I0502 14:42:09.324342 140040320145216 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0502 14:42:09.328370 140040320145216 make_examples_core.py:257] Common contigs are ['chr20']; I0502 14:42:09.424478 140040320145216 make_examples_core.py:257] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; 2023-05-02 14:42:09.427029: I third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728; I0502 14:42:09.448862 140040320145216 genomics_reader.py:222] Reading /input/N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1034,Testability,test,testdata,1034,"com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**; (A clear and concise description of what the issue is.); CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**; - Operating system: Ubuntu 18.04 (bionic); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:; BIN_VERSION=""1.5.0""; singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); EXAMPLE DATA PROVIDED. **Steps to reproduce:**; - Command:. INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the followin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1582,Testability,test,test,1582,".04 (bionic); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:; BIN_VERSION=""1.5.0""; singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); EXAMPLE DATA PROVIDED. **Steps to reproduce:**; - Command:. INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****; time ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:1618,Testability,test,test,1618,".04 (bionic); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:; BIN_VERSION=""1.5.0""; singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); EXAMPLE DATA PROVIDED. **Steps to reproduce:**; - Command:. INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0502 14:40:56.961649 140501830911808 run_deepvariant.py:364] Re-using the directory for intermediate results in /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p. ***** Intermediate results will be written to /fh/scratch/delete90/furlan_s/targ_reseq/230117_Sami/AML_1101_merge/tmp_dir/tmpzz53zv8p in docker. ****. ***** Running the command:*****; time ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/640:124,Usability,clear,clear,124,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: YES. **Describe the issue:**; (A clear and concise description of what the issue is.); CANNOT RUN EXAMPLE DATA USING A SINGULARITY CONTAINER - GETTING AN ERROR: RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem. **Setup**; - Operating system: Ubuntu 18.04 (bionic); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): SINGULARITY sif made as follows:; BIN_VERSION=""1.5.0""; singularity pull deepvariant.sif docker://google/deepvariant:""${BIN_VERSION}""; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); EXAMPLE DATA PROVIDED. **Steps to reproduce:**; - Command:. INPUT_DIR=""${PWD}/quickstart-testdata""; OUTPUT_DIR=""${PWD}/quickstart-output"". singularity exec --bind ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"",/usr/lib/locale/:/usr/lib/locale/ \; /fh/fast/furlan_s/grp/sifs/deepvariant.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.chr20.unittest.fasta \; --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz. - Error trace: (if applicable) SEE BELOW. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. YES THIS IS WITH THE QUICK START EXAMPLE. **Any additional context:**. Message:. 2023-05-02 14:40:43.757041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/640
https://github.com/google/deepvariant/issues/641:86,Availability,down,download,86,"I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score; INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211; INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211; SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135; SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:898,Deployability,pipeline,pipeline,898,"I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score; INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211; INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211; SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135; SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/641:71,Testability,benchmark,benchmark,71,"I used DeepVariant to call SNPs and Indels with the HG002 Pacbio Revio benchmark data download from https://human-pangenomics.s3.amazonaws.com/submissions/80d00e88-7a92-46d8-88c7-48f1486e11ed--HG002_PACBIO_REVIO/, while the hap.py result showed Indels have very low precision (0.653927) and recall (0.884985) and SNPs seemed to be normal having 0.998 precision and recall. Type	Filter	TRUTH.TOTAL	TRUTH.TP	TRUTH.FN	QUERY.TOTAL	QUERY.FP	QUERY.UNK	FP.gtMETRIC.Recall	METRIC.Precision	METRIC.Frac_NA	METRIC.F1_Score; INDEL	ALL	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211; INDEL	PASS	523034	462877	60157	1215487	252834	484908	16813	0.884985	0.653927	0.398941	0.75211; SNP	ALL	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135; SNP	PASS	3352818	3349190	3628	3960152	8899	597545	864	0.998918	0.997354	0.150889	0.998135. I running the pipeline with aligner minimap2 v2.24 with parameters ""-L --MD -Y -a -x map-hifi --secondary=no"" and calling SNVs with deepVariant v1.3.0 with --model_type=PACBIO.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/641
https://github.com/google/deepvariant/issues/645:121,Availability,Down,Downstream,121,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**; - Operating system: Linux; - DeepVariant version: Latest; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**; - Command: . DeepVariant:; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref ${ref} \; --reads ${cram_in} \; --regions ${regions} \; --output_gvcf ${sample}.g.vcf.gz \; --output_vcf ${sample}.vcf.gz \; --num_shards 8 \. GLnexus:; glnexus_cli --config DeepVariantWES --bed ${regions} \; 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there!; Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file.; Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:1172,Availability,down,downstream,1172,"tion analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**; - Operating system: Linux; - DeepVariant version: Latest; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**; - Command: . DeepVariant:; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref ${ref} \; --reads ${cram_in} \; --regions ${regions} \; --output_gvcf ${sample}.g.vcf.gz \; --output_vcf ${sample}.vcf.gz \; --num_shards 8 \. GLnexus:; glnexus_cli --config DeepVariantWES --bed ${regions} \; 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there!; Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file.; Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0/0:0:0,0:1:0,0,0:..	0/0:33:33,0:50:0,123,1229:..	1/1:5:3,2:13:21,15,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	0/0:0:0,0:1:0,0,0:..	./",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:372,Deployability,Install,Installation,372,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**; - Operating system: Linux; - DeepVariant version: Latest; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**; - Command: . DeepVariant:; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref ${ref} \; --reads ${cram_in} \; --regions ${regions} \; --output_gvcf ${sample}.g.vcf.gz \; --output_vcf ${sample}.vcf.gz \; --num_shards 8 \. GLnexus:; glnexus_cli --config DeepVariantWES --bed ${regions} \; 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there!; Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file.; Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6660,Deployability,Configurat,Configuration,6660,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:844,Modifiability,config,config,844,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**: Yes. **Describe the issue:**; Downstream association analysis has yielded a high number of false positive findings, essentially a product of low quality data. It is crucial that these sites are filtered out. . **Setup**; - Operating system: Linux; - DeepVariant version: Latest; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Illumina WES. **Steps to reproduce:**; - Command: . DeepVariant:; /opt/deepvariant/bin/run_deepvariant \; --model_type WES \; --ref ${ref} \; --reads ${cram_in} \; --regions ${regions} \; --output_gvcf ${sample}.g.vcf.gz \; --output_vcf ${sample}.vcf.gz \; --num_shards 8 \. GLnexus:; glnexus_cli --config DeepVariantWES --bed ${regions} \; 2_gvcf/*.g.vcf.gz > 3_bcf/Exomes.bcf. **Any additional context:**. Hi there!; Apologies for bringing up another similar issue, but I would like some help with the correct filtering of my merged vcf file.; Essentially, I have identified a significant number of false positive sites in a downstream assoc. analysis, where MAF for these variants is widely different than the population average. This strongly suggests that these sites are of low quality and need to be filtered out. Here are some examples from the merged vcf file. For each variant I have only shown a handful of samples (total is over 5000):. False positive / bad site that needs filtering:. `1	1722625	1_1722625_A_T	A	T	48	.	AF=0.222894;AQ=48	GT:DP:AD:GQ:PL:RNC	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	1/1:7:0,7:42:44,47,0:..	0/0:0:0,0:1:0,0,0:..	1/1:6:0,6:36:38,38,0:..	0/1:12:3,9:0:19,2,0:..	./.:3:3,0:0:20,0,50:II	1/1:2:0,2:23:29,25,0:..	0/0:2:2,0:6:0,6,59:..	1/1:2:0,2:22:31,24,0:..	1/1:2:0,2:26:28,29,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,0,0:..	./.:1:1,0:0:29,3,0:II	1/1:7:0,7:40:43,42,0:..	./.:3:3,0:0:20,0,50:II	1/1:4:1,3:1:28,3,0:..	0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/645:6660,Modifiability,Config,Configuration,6660,":..	0/1:3:0,3:2:27,4,0:..	0/0:0:0,0:1:0,3,29:..	0/1:2:0,2:3:19,3,0:..	./.:1:1,0:0:29,3,0:II	./.:1:1,0:0:29,3,0:II	1/1:4:0,4:2:30,8,0:..	./.:1:1,0:0:29,3,0:II	0/0:0:0,0:1:0,3,29:..	1/1:8:0,8:12:41,18,0:..	0/1:2:0,2:2:22,4,0:..	1/1:6:0,6:6:30,12,0:..	0/1:2:0,2:2:16,4,0:..	0/1:2:0,2:3:15,3,0:..	./.:1:1,0:0:29,3,0:II`. The overall coverage of both these sites is really quite low... compared to a site such as this, which has good coverage and no ./. or gVCF generated 0/0:. `1	6633042	1_6633042_C_T	C	T	57	.	AF=0.025366;AQ=57	GT:DP:AD:GQ:PL:RNC	0/0:62:62,0:50:0,258,2579:..	0/0:50:50,0:50:0,180,1799:..	0/0:60:60,0:50:0,195,1949:..	0/0:57:57,0:50:0,252,2519:..	0/0:57:57,0:50:0,228,2279:..	0/0:39:39,0:50:0,159,1589:..	0/0:46:46,0:50:0,189,1889:..	0/0:23:23,0:48:0,69,689:..	0/0:25:25,0:50:0,75,749:..	0/0:23:23,0:50:0,69,689:..	0/0:40:40,0:50:0,189,1889:..	0/0:63:63,0:50:0,171,1949:..	0/0:56:56,0:50:0,213,2129:..	0/0:53:53,0:50:0,159,1589:..	0/0:60:60,0:50:0,213,2129:..	0/0:24:24,0:50:0,72,719:..	0/0:49:49,0:50:0,147,1469:..	0/0:27:27,0:50:0,51,749:..	0/0:40:40,0:50:0,156,1559:..	0/0:19:19,0:50:0,57,569:..	0/0:43:43,0:50:0,180,1799:..	0/0:21:21,0:50:0,66,659:..	0/0:69:69,0:50:0,207,2069:..	0/0:16:16,0:48:0,48,479:..	0/0:69:69,0:50:0,207,2069:..	0/0:46:46,0:50:0,138,1379:..	0/1:78:36,39:47:48,0,52:..	0/0:49:49,0:50:0,159,1589:..	0/0:25:25,0:50:0,81,809:..	0/0:101:101,0:50:0,300,2999:..	0/1:77:40,36:50:51,0,55:..	0/0:65:65,0:50:0,240,2399:..	0/0:22:22,0:48:0,66,659:..	0/0:55:55,0:50:0,219,2189:..	0/0:38:38,0:50:0,210,2099:..	0/0:56:56,0:50:0,171,1709:..	0/1:78:32,46:46:49,0,48:..`. It would be good to know the most appropriate way to remove the bad variants. As I understand the GQ field is the best place to start. If I am correct, the GLnexus command which I used filters by GQ > 20 ( see: https://github.com/dnanexus-rnd/GLnexus/wiki/Configuration ). Perhaps upping this GQ to > 30 or slightly higher would remove this sites? I am very appreciative of every input, thank you so much!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/645
https://github.com/google/deepvariant/issues/646:148,Availability,error,error,148,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. **Describe the issue:**; Run into Fatal python Bus error repeatedly. **Setup**; - Operating system: CentOS 7 ; - DeepVariant version: 1.4 (DeepTrio); - Installation method (Docker, built from source, etc.): singularity ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Illumina NovaSeq data, reference genome hg19. ; **Steps to reproduce:**; - Command:; - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`; - Error trace: (if applicable); `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1315,Availability,Error,Error,1315,"quencing instrument, reference genome, anything special that is unlike the case studies?); Illumina NovaSeq data, reference genome hg19. ; **Steps to reproduce:**; - Command:; - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`; - Error trace: (if applicable); `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1359,Availability,error,error,1359,"quencing instrument, reference genome, anything special that is unlike the case studies?); Illumina NovaSeq data, reference genome hg19. ; **Steps to reproduce:**; - Command:; - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`; - Error trace: (if applicable); `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:1370,Availability,error,error,1370,"quencing instrument, reference genome, anything special that is unlike the case studies?); Illumina NovaSeq data, reference genome hg19. ; **Steps to reproduce:**; - Command:; - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`; - Error trace: (if applicable); `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/variant_caller.py"", line 382 in calls_and_gvcfs; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1379 in candidates_in_region; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4798,Availability,error,error,4798,"paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>; parallel: This job failed:; /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s; user 287m31.460s; sys 2m20.121s; I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):; File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_; Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error; `. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:249,Deployability,Install,Installation,249,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. **Describe the issue:**; Run into Fatal python Bus error repeatedly. **Setup**; - Operating system: CentOS 7 ; - DeepVariant version: 1.4 (DeepTrio); - Installation method (Docker, built from source, etc.): singularity ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Illumina NovaSeq data, reference genome hg19. ; **Steps to reproduce:**; - Command:; - `/opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210124.deduped.bam --examples /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/make_examples.tfrecord@6.gz --sample_name A210124 --sample_name_parent1 A210126 --channels insert_size --gvcf /paedyl01/disk1/yangyxt/test_tmp/singularity_inter_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/gvcf.tfrecord@6.gz --normalize_reads --pileup_image_height_child 100 --pileup_image_height_parent 100 --regions /paedyl01/disk1/yangyxt/indexed_genome/hg19/ucsc.hg19.no_dad.bed --task 0`; - Error trace: (if applicable); `Fatal Python error: Bus error. Current thread 0x00002af3a27fa740 (most recent call first):; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 58 in <dictcomp>; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 57 in get_candidates; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4831,Testability,test,test,4831,"paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>; parallel: This job failed:; /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s; user 287m31.460s; sys 2m20.121s; I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):; File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_; Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error; `. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/646:4867,Testability,test,test,4867,"paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/absl_py/absl/app.py"", line 300 in run; File ""/paedyl01/disk1/yangyxt/test_tmp/singularity_run_aRMiURV3spzCOiBE1ojvo_fj2J05oPk1/Bazel.runfiles_dtfjmfk6/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 312 in <module>; parallel: This job failed:; /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref /paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta --reads_parent1 /paedyl01/disk1/yangyxt/wesplus/50_samples_20220304/aligned_results/A210126.deduped.bam --reads /paedyl01/disk1/yangyxt/wesplus/50_sampl. real 1154m27.406s; user 287m31.460s; sys 2m20.121s; I0509 05:42:42.322269 47221860157248 run_deeptrio.py:674] None. Traceback (most recent call last):; File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 5 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""/paedyl01/disk1/yangyxt/indexed_genome/ucsc.hg19.fasta"" --reads_parent1 ""/paedyl01/disk1/yangyxt/wesplus/50_samples_; Line 770: In function call_deeptrio_per_pair: Tue May 9 05:42:52 HKT 2023: Failed on running singularity DeepTrio. Quit with error; `. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/646
https://github.com/google/deepvariant/issues/650:269,Deployability,pipeline,pipeline,269,"**Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode.; Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode.; The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed.; So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below).; Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you!. Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:447,Performance,optimiz,optimizing,447,"**Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode.; Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode.; The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed.; So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below).; Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you!. Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:652,Testability,test,test,652,"**Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode.; Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode.; The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed.; So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below).; Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you!. Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:732,Testability,log,log,732,"**Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode.; Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode.; The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed.; So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below).; Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you!. Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:763,Testability,log,log,763,"**Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode.; Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode.; The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed.; So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below).; Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you!. Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:800,Testability,log,log,800,"**Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode.; Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode.; The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed.; So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below).; Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you!. Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:977,Testability,log,log,977,"**Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode.; Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode.; The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed.; So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below).; Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you!. Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/650:1050,Testability,log,log,1050,"**Describe the issue:**. Hi, I am wondering if there's been a study on the cost-benefit of running DV in the GPU mode.; Back in the days of PEPPER-DeepVariant-Margin, I remember trying to profile (not as a rigorous study) what benefits there'd be if we were to run the pipeline in the GPU mode.; The conclusion back then from my anecdotal runs is that it's not worth it (we can get the CPU version to <$100/sample with little to minimum effort on optimizing cloud resource allocations, but the GPU version is ~$200/sample with P100). Now given that DV has undergone quite a lot of changes since then, I wonder if the conclusion is changed.; So I did a test run on a PacBio Hifi 30X bam with DV 1.5.0, and collected the GPU resource log (using `gpustat -a -i 1 `, log attached below).; Looking at the log file, it doesn't look like GPU is used much still. So I wonder if you have done any study on this subject and if so, can share some insights. Thank you!. Steve. [gpu.usages.log.zip](https://github.com/google/deepvariant/files/11473421/gpu.usages.log.zip)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/650
https://github.com/google/deepvariant/issues/651:437,Availability,Error,Error,437,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/651
https://github.com/google/deepvariant/issues/651:232,Deployability,Install,Installation,232,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/651
https://github.com/google/deepvariant/issues/651:490,Testability,test,test,490,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/651
https://github.com/google/deepvariant/issues/651:526,Testability,test,test,526,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/651
https://github.com/google/deepvariant/issues/651:120,Usability,clear,clear,120,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/651
https://github.com/google/deepvariant/issues/653:529,Availability,error,error,529,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Hi developers,; I'd like to run `DeepVariant` for my `WGS` sequencing data. My sequencing data were from `BGI` platform and were preprocessed by `fastp, bwa+Hs37d5, MarkDuplicatesSpark`. I tried to use the 'sorted and deduplicated bam' file as input for `DeepVariant` in `singularity` mode. However, I always encountered the 'reference index' `not found` error. But my `reference` fasta file and `reference index` fai file does exist. Could you please help me figure it out?. **Setup**; - Operating system: Linux version 3.10.0-1127.el7.x86_64 (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39), Computation Node (one node of Clusters); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):; - ``` BIN_VERSION=""1.5.0""; docker pull; ; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; singularity build --fakeroot deepvariant.sif docker://google/deepvariant:1.5.0```; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); `BGI platform, WGS data, Hs37d5 reference, fastp QC, bwa-mem2 mapping, MarkDuplicatesSpark sort & dedup`; . **Steps to reproduce:**; - Command:; - 1. singularity run /lustre/Data/toolsDB//deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref_idx --reads=$dedupbam --output_vcf=$vcfout --output_gvcf=$gvcfout --num_shards=32 >$logx 2>&1; - Error trace: (if applicable); - ```I0522 08:40:36.823651 140633630893888 genomics_reader.py:222] Reading /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam with NativeSamReader; I0522 08:40:36.846348 140633630893888 make_examples_core.py:257] Task 27/32: Preparing inputs; [E::fai_load3_core] Failed to open FASTA index /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai: No such file or",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:1559,Availability,Error,Error,1559,"eference index' `not found` error. But my `reference` fasta file and `reference index` fai file does exist. Could you please help me figure it out?. **Setup**; - Operating system: Linux version 3.10.0-1127.el7.x86_64 (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39), Computation Node (one node of Clusters); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):; - ``` BIN_VERSION=""1.5.0""; docker pull; ; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; singularity build --fakeroot deepvariant.sif docker://google/deepvariant:1.5.0```; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); `BGI platform, WGS data, Hs37d5 reference, fastp QC, bwa-mem2 mapping, MarkDuplicatesSpark sort & dedup`; . **Steps to reproduce:**; - Command:; - 1. singularity run /lustre/Data/toolsDB//deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref_idx --reads=$dedupbam --output_vcf=$vcfout --output_gvcf=$gvcfout --num_shards=32 >$logx 2>&1; - Error trace: (if applicable); - ```I0522 08:40:36.823651 140633630893888 genomics_reader.py:222] Reading /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam with NativeSamReader; I0522 08:40:36.846348 140633630893888 make_examples_core.py:257] Task 27/32: Preparing inputs; [E::fai_load3_core] Failed to open FASTA index /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai: No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/com_google_deepvariant/deepvariant/make_examples.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:839,Deployability,Install,Installation,839,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Hi developers,; I'd like to run `DeepVariant` for my `WGS` sequencing data. My sequencing data were from `BGI` platform and were preprocessed by `fastp, bwa+Hs37d5, MarkDuplicatesSpark`. I tried to use the 'sorted and deduplicated bam' file as input for `DeepVariant` in `singularity` mode. However, I always encountered the 'reference index' `not found` error. But my `reference` fasta file and `reference index` fai file does exist. Could you please help me figure it out?. **Setup**; - Operating system: Linux version 3.10.0-1127.el7.x86_64 (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39), Computation Node (one node of Clusters); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):; - ``` BIN_VERSION=""1.5.0""; docker pull; ; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; singularity build --fakeroot deepvariant.sif docker://google/deepvariant:1.5.0```; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); `BGI platform, WGS data, Hs37d5 reference, fastp QC, bwa-mem2 mapping, MarkDuplicatesSpark sort & dedup`; . **Steps to reproduce:**; - Command:; - 1. singularity run /lustre/Data/toolsDB//deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref_idx --reads=$dedupbam --output_vcf=$vcfout --output_gvcf=$gvcfout --num_shards=32 >$logx 2>&1; - Error trace: (if applicable); - ```I0522 08:40:36.823651 140633630893888 genomics_reader.py:222] Reading /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam with NativeSamReader; I0522 08:40:36.846348 140633630893888 make_examples_core.py:257] Task 27/32: Preparing inputs; [E::fai_load3_core] Failed to open FASTA index /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai: No such file or",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:3183,Performance,load,load,3183,".runfiles_c22i4j8u/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2114, in make_examples_runner; regions, calling_regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2019, in processing_regions_from_options; ref_contigs = fasta.IndexedFastaReader(; File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__; self._reader = reference.IndexedFastaReader.from_file(; ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; I0522 08:40:37.063492 139925831092032 genomics_reader.py:222] Reading /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam with NativeSamReader; I0522 08:40:37.081499 139925831092032 make_examples_core.py:257] Task 6/32: Preparing inputs; [E::fai_load3_core] Failed to open FASTA index /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai: No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_luflf_op/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_luflf_op/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_luflf_op/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_luflf_op/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main; make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:5055,Performance,load,load,5055,"v)); File ""/tmp/Bazel.runfiles_luflf_op/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_luflf_op/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2114, in make_examples_runner; regions, calling_regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_luflf_op/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2019, in processing_regions_from_options; ref_contigs = fasta.IndexedFastaReader(; File ""/tmp/Bazel.runfiles_luflf_op/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__; self._reader = reference.IndexedFastaReader.from_file(; ****************; File ""/tmp/Bazel.runfiles_8r9pgqu5/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__; self._reader = reference.IndexedFastaReader.from_file(; ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; I0522 08:40:37.129531 140035375298368 make_examples_core.py:257] Task 7/32: Preparing inputs; [E::fai_load3_core] Failed to open FASTA index /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai: No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2114, in make_examples_runner; regions, c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:6537,Performance,load,load,6537,".runfiles_nkfcw9hw/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2114, in make_examples_runner; regions, calling_regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2019, in processing_regions_from_options; ref_contigs = fasta.IndexedFastaReader(; File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__; self._reader = reference.IndexedFastaReader.from_file(; ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa --reads /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam --examples /tmp/tmpfab4tpv7/make_examples.tfrecord@32.gz --channels insert_size --gvcf /tmp/tmpfab4tpv7/gvcf.tfrecord@32.gz --task 18. - ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Yes, the quick test run as normal.; ```. 3. reference index does; ```$ ls /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*; -rw-rw-r-- 1 zhoujianglin zhoujianglin 3189750467 Apr 26 14:53 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6274909010 Apr 26 15:23 /lustre/Data/tools",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:8415,Performance,optimiz,optimized,8415,"pr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 106669 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6924 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 10196727247 Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 2813 May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai; -rw-rw-r-- 1 zhoujianglin zhoujianglin 784363628 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac. ```. **************; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-05-19 16:22:21.555857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (o; neDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0519 16:22:23.193474 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.256151 139896863770432 make_examples_core.py:257] Task 10/32: Preparing inputs; I0519 16:22:23.258605 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.259495 139896863770432 make_examples_core.py:257] Task 10/32: Common contigs are ['chr20']; I0519 16:22:23.239336 140148036429632 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Pr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:8517,Performance,perform,performance-critical,8517,"pr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 106669 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6924 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 10196727247 Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 2813 May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai; -rw-rw-r-- 1 zhoujianglin zhoujianglin 784363628 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac. ```. **************; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-05-19 16:22:21.555857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (o; neDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0519 16:22:23.193474 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.256151 139896863770432 make_examples_core.py:257] Task 10/32: Preparing inputs; I0519 16:22:23.258605 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.259495 139896863770432 make_examples_core.py:257] Task 10/32: Common contigs are ['chr20']; I0519 16:22:23.239336 140148036429632 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Pr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:13267,Performance,optimiz,optimized,13267,"models/wgs/model.ckpt; I0519 16:22:48.504039 139665862911808 call_variants.py:462] Processed 1 examples in 1 batches [632.440 sec per 100]; I0519 16:22:48.735930 139665862911808 call_variants.py:468] Processed 305 examples in 1 batches [2.084 sec per 100]; I0519 16:22:48.736088 139665862911808 call_variants.py:471] Done calling variants from a total of 305 examples. real 0m8.934s; user 0m37.643s; sys 0m6.426s. ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/tmp6gzkras0/call_variants_output.tfrecord.gz"" --outfile ""singularity-output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmp6gzkras0/gvcf.tfrecord@32.gz"" --gvcf_outfile ""singularity-output/output.g.vcf.gz"". 2023-05-19 16:22:49.638487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0519 16:22:51.170790 140640470185792 postprocess_variants.py:972] Using sample name from call_variants output. Sample name: NA12878; 2023-05-19 16:22:51.171487: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmp6gzkras0/call_variants_output.tfrecord.gz; 2023-05-19 16:22:51.173038: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 305; I0519 16:22:51.173760 140640470185792 postprocess_variants.py:1037] CVO sorting took 3.902912139892578e-05 minutes; I0519 16:22:51.173915 140640470185792 postprocess_variants.py:1040] Transforming call_variants_output to variants.; I0519 16:22:51.204555 140640470185792 postprocess_variants.py:1080] Processing variants (and writing to temporary file) took 0.0005078872044881184 minutes; I0519 16:22:51.582558 140640470185792 postprocess_variants.py:1093] Finished writing V",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:13367,Performance,perform,performance-critical,13367,"models/wgs/model.ckpt; I0519 16:22:48.504039 139665862911808 call_variants.py:462] Processed 1 examples in 1 batches [632.440 sec per 100]; I0519 16:22:48.735930 139665862911808 call_variants.py:468] Processed 305 examples in 1 batches [2.084 sec per 100]; I0519 16:22:48.736088 139665862911808 call_variants.py:471] Done calling variants from a total of 305 examples. real 0m8.934s; user 0m37.643s; sys 0m6.426s. ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/tmp6gzkras0/call_variants_output.tfrecord.gz"" --outfile ""singularity-output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmp6gzkras0/gvcf.tfrecord@32.gz"" --gvcf_outfile ""singularity-output/output.g.vcf.gz"". 2023-05-19 16:22:49.638487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0519 16:22:51.170790 140640470185792 postprocess_variants.py:972] Using sample name from call_variants output. Sample name: NA12878; 2023-05-19 16:22:51.171487: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmp6gzkras0/call_variants_output.tfrecord.gz; 2023-05-19 16:22:51.173038: I deepvariant/postprocess_variants.cc:103] Total #entries in single_site_calls = 305; I0519 16:22:51.173760 140640470185792 postprocess_variants.py:1037] CVO sorting took 3.902912139892578e-05 minutes; I0519 16:22:51.173915 140640470185792 postprocess_variants.py:1040] Transforming call_variants_output to variants.; I0519 16:22:51.204555 140640470185792 postprocess_variants.py:1080] Processing variants (and writing to temporary file) took 0.0005078872044881184 minutes; I0519 16:22:51.582558 140640470185792 postprocess_variants.py:1093] Finished writing V",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:1546,Testability,log,logx,1546,"eference index' `not found` error. But my `reference` fasta file and `reference index` fai file does exist. Could you please help me figure it out?. **Setup**; - Operating system: Linux version 3.10.0-1127.el7.x86_64 (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39), Computation Node (one node of Clusters); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):; - ``` BIN_VERSION=""1.5.0""; docker pull; ; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; singularity build --fakeroot deepvariant.sif docker://google/deepvariant:1.5.0```; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); `BGI platform, WGS data, Hs37d5 reference, fastp QC, bwa-mem2 mapping, MarkDuplicatesSpark sort & dedup`; . **Steps to reproduce:**; - Command:; - 1. singularity run /lustre/Data/toolsDB//deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref_idx --reads=$dedupbam --output_vcf=$vcfout --output_gvcf=$gvcfout --num_shards=32 >$logx 2>&1; - Error trace: (if applicable); - ```I0522 08:40:36.823651 140633630893888 genomics_reader.py:222] Reading /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam with NativeSamReader; I0522 08:40:36.846348 140633630893888 make_examples_core.py:257] Task 27/32: Preparing inputs; [E::fai_load3_core] Failed to open FASTA index /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai: No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_c22i4j8u/runfiles/com_google_deepvariant/deepvariant/make_examples.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:7033,Testability,test,test,7033,"ples_runner; regions, calling_regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2019, in processing_regions_from_options; ref_contigs = fasta.IndexedFastaReader(; File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__; self._reader = reference.IndexedFastaReader.from_file(; ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa --reads /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam --examples /tmp/tmpfab4tpv7/make_examples.tfrecord@32.gz --channels insert_size --gvcf /tmp/tmpfab4tpv7/gvcf.tfrecord@32.gz --task 18. - ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Yes, the quick test run as normal.; ```. 3. reference index does; ```$ ls /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*; -rw-rw-r-- 1 zhoujianglin zhoujianglin 3189750467 Apr 26 14:53 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6274909010 Apr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 106669 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6924 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 10196727247 Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 2813 May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:7069,Testability,test,test,7069,"ples_runner; regions, calling_regions = processing_regions_from_options(options); File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2019, in processing_regions_from_options; ref_contigs = fasta.IndexedFastaReader(; File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__; self._reader = reference.IndexedFastaReader.from_file(; ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa --reads /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam --examples /tmp/tmpfab4tpv7/make_examples.tfrecord@32.gz --channels insert_size --gvcf /tmp/tmpfab4tpv7/gvcf.tfrecord@32.gz --task 18. - ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Yes, the quick test run as normal.; ```. 3. reference index does; ```$ ls /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*; -rw-rw-r-- 1 zhoujianglin zhoujianglin 3189750467 Apr 26 14:53 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6274909010 Apr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 106669 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6924 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 10196727247 Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 2813 May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:7244,Testability,test,test,7244,"/make_examples_core.py"", line 2019, in processing_regions_from_options; ref_contigs = fasta.IndexedFastaReader(; File ""/tmp/Bazel.runfiles_nkfcw9hw/runfiles/com_google_deepvariant/third_party/nucleus/io/fasta.py"", line 106, in __init__; self._reader = reference.IndexedFastaReader.from_file(; ValueError: NOT_FOUND: could not load fasta and/or fai for fasta /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa --reads /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam --examples /tmp/tmpfab4tpv7/make_examples.tfrecord@32.gz --channels insert_size --gvcf /tmp/tmpfab4tpv7/gvcf.tfrecord@32.gz --task 18. - ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Yes, the quick test run as normal.; ```. 3. reference index does; ```$ ls /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa*; -rw-rw-r-- 1 zhoujianglin zhoujianglin 3189750467 Apr 26 14:53 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6274909010 Apr 26 15:23 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.0123; -rw-rw-r-- 1 zhoujianglin zhoujianglin 106669 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.amb; -rw-rw-r-- 1 zhoujianglin zhoujianglin 6924 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 10196727247 Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 2813 May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai; -rw-rw-r-- 1 zhoujianglin zhoujianglin 784363628 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac. ```. *************",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:8754,Testability,test,testdata,8754,"in 6924 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.ann; -rw-rw-r-- 1 zhoujianglin zhoujianglin 10196727247 Apr 26 15:42 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.bwt.2bit.64; -rw-rw-r-- 1 zhoujianglin zhoujianglin 2813 May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai; -rw-rw-r-- 1 zhoujianglin zhoujianglin 784363628 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac. ```. **************; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-05-19 16:22:21.555857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (o; neDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0519 16:22:23.193474 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.256151 139896863770432 make_examples_core.py:257] Task 10/32: Preparing inputs; I0519 16:22:23.258605 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.259495 139896863770432 make_examples_core.py:257] Task 10/32: Common contigs are ['chr20']; I0519 16:22:23.239336 140148036429632 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Preparing inputs; I0519 16:22:23.239059 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.240968 140421750466368 make_examples_core.py:257] T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:8992,Testability,test,testdata,8992,"ujianglin 2813 May 19 17:15 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai; -rw-rw-r-- 1 zhoujianglin zhoujianglin 784363628 Apr 26 15:21 /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.pac. ```. **************; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-05-19 16:22:21.555857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (o; neDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0519 16:22:23.193474 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.256151 139896863770432 make_examples_core.py:257] Task 10/32: Preparing inputs; I0519 16:22:23.258605 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.259495 139896863770432 make_examples_core.py:257] Task 10/32: Common contigs are ['chr20']; I0519 16:22:23.239336 140148036429632 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Preparing inputs; I0519 16:22:23.239059 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.240968 140421750466368 make_examples_core.py:257] Task 21/32: Common contigs are ['chr20']; I0519 16:22:23.242177 140053689509696 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.227729 140555533080384 genomics_reader.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:9242,Testability,test,testdata,9242," operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-05-19 16:22:21.555857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (o; neDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0519 16:22:23.193474 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.256151 139896863770432 make_examples_core.py:257] Task 10/32: Preparing inputs; I0519 16:22:23.258605 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.259495 139896863770432 make_examples_core.py:257] Task 10/32: Common contigs are ['chr20']; I0519 16:22:23.239336 140148036429632 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Preparing inputs; I0519 16:22:23.239059 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.240968 140421750466368 make_examples_core.py:257] Task 21/32: Common contigs are ['chr20']; I0519 16:22:23.242177 140053689509696 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.227729 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.280361 140555533080384 make_examples_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Readi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:9385,Testability,test,testdata,9385,"cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (o; neDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0519 16:22:23.193474 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.256151 139896863770432 make_examples_core.py:257] Task 10/32: Preparing inputs; I0519 16:22:23.258605 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.259495 139896863770432 make_examples_core.py:257] Task 10/32: Common contigs are ['chr20']; I0519 16:22:23.239336 140148036429632 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Preparing inputs; I0519 16:22:23.239059 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.240968 140421750466368 make_examples_core.py:257] Task 21/32: Common contigs are ['chr20']; I0519 16:22:23.242177 140053689509696 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.227729 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.280361 140555533080384 make_examples_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.283533 140555533080384 make_examples_core.py:257] Ta",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:9623,Testability,test,testdata,9623,uild TensorFlow with the appropriate compiler flags.; I0519 16:22:23.193474 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.256151 139896863770432 make_examples_core.py:257] Task 10/32: Preparing inputs; I0519 16:22:23.258605 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.259495 139896863770432 make_examples_core.py:257] Task 10/32: Common contigs are ['chr20']; I0519 16:22:23.239336 140148036429632 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Preparing inputs; I0519 16:22:23.239059 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.240968 140421750466368 make_examples_core.py:257] Task 21/32: Common contigs are ['chr20']; I0519 16:22:23.242177 140053689509696 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.227729 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.280361 140555533080384 make_examples_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.283533 140555533080384 make_examples_core.py:257] Task 6/32: Common contigs are ['chr20']; I0519 16:22:23.228248 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.279789 140552972691264 make_examples_core,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:9873,Testability,test,testdata,9873,ore.py:257] Task 10/32: Preparing inputs; I0519 16:22:23.258605 139896863770432 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.259495 139896863770432 make_examples_core.py:257] Task 10/32: Common contigs are ['chr20']; I0519 16:22:23.239336 140148036429632 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Preparing inputs; I0519 16:22:23.239059 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.240968 140421750466368 make_examples_core.py:257] Task 21/32: Common contigs are ['chr20']; I0519 16:22:23.242177 140053689509696 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.227729 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.280361 140555533080384 make_examples_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.283533 140555533080384 make_examples_core.py:257] Task 6/32: Common contigs are ['chr20']; I0519 16:22:23.228248 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.279789 140552972691264 make_examples_core.py:257] Task 8/32: Preparing inputs; I0519 16:22:23.281702 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.282378 140552972691264 make_examples_core.py:257] Task,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:10016,Testability,test,testdata,10016,chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.259495 139896863770432 make_examples_core.py:257] Task 10/32: Common contigs are ['chr20']; I0519 16:22:23.239336 140148036429632 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Preparing inputs; I0519 16:22:23.239059 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.240968 140421750466368 make_examples_core.py:257] Task 21/32: Common contigs are ['chr20']; I0519 16:22:23.242177 140053689509696 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.227729 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.280361 140555533080384 make_examples_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.283533 140555533080384 make_examples_core.py:257] Task 6/32: Common contigs are ['chr20']; I0519 16:22:23.228248 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.279789 140552972691264 make_examples_core.py:257] Task 8/32: Preparing inputs; I0519 16:22:23.281702 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.282378 140552972691264 make_examples_core.py:257] Task 8/32: Common contigs are ['chr20']; I0519 16:22:23.271428 140087439025984 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:10253,Testability,test,testdata,10253,a/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192739 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.235120 140421750466368 make_examples_core.py:257] Task 21/32: Preparing inputs; I0519 16:22:23.239059 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.240968 140421750466368 make_examples_core.py:257] Task 21/32: Common contigs are ['chr20']; I0519 16:22:23.242177 140053689509696 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.227729 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.280361 140555533080384 make_examples_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.283533 140555533080384 make_examples_core.py:257] Task 6/32: Common contigs are ['chr20']; I0519 16:22:23.228248 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.279789 140552972691264 make_examples_core.py:257] Task 8/32: Preparing inputs; I0519 16:22:23.281702 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.282378 140552972691264 make_examples_core.py:257] Task 8/32: Common contigs are ['chr20']; I0519 16:22:23.271428 140087439025984 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192873 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.234176 139704511100736 make_examples_core.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:10502,Testability,test,testdata,10502,_core.py:257] Task 21/32: Preparing inputs; I0519 16:22:23.239059 140421750466368 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.240968 140421750466368 make_examples_core.py:257] Task 21/32: Common contigs are ['chr20']; I0519 16:22:23.242177 140053689509696 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.227729 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.280361 140555533080384 make_examples_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.283533 140555533080384 make_examples_core.py:257] Task 6/32: Common contigs are ['chr20']; I0519 16:22:23.228248 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.279789 140552972691264 make_examples_core.py:257] Task 8/32: Preparing inputs; I0519 16:22:23.281702 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.282378 140552972691264 make_examples_core.py:257] Task 8/32: Common contigs are ['chr20']; I0519 16:22:23.271428 140087439025984 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192873 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.234176 139704511100736 make_examples_core.py:257] Task 12/32: Preparing inputs; I0519 16:22:23.236589 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.237330 139704511100736 make_examples_core.py:257] Tas,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:10739,Testability,test,testdata,10739,s_core.py:257] Task 21/32: Common contigs are ['chr20']; I0519 16:22:23.242177 140053689509696 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.227729 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.280361 140555533080384 make_examples_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.283533 140555533080384 make_examples_core.py:257] Task 6/32: Common contigs are ['chr20']; I0519 16:22:23.228248 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.279789 140552972691264 make_examples_core.py:257] Task 8/32: Preparing inputs; I0519 16:22:23.281702 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.282378 140552972691264 make_examples_core.py:257] Task 8/32: Common contigs are ['chr20']; I0519 16:22:23.271428 140087439025984 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192873 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.234176 139704511100736 make_examples_core.py:257] Task 12/32: Preparing inputs; I0519 16:22:23.236589 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.237330 139704511100736 make_examples_core.py:257] Task 12/32: Common contigs are ['chr20']; I0519 16:22:23.237694 140638923466560 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.289134 140638923466560 make_examples_cor,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:10988,Testability,test,testdata,10988,ader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.280361 140555533080384 make_examples_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.283533 140555533080384 make_examples_core.py:257] Task 6/32: Common contigs are ['chr20']; I0519 16:22:23.228248 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.279789 140552972691264 make_examples_core.py:257] Task 8/32: Preparing inputs; I0519 16:22:23.281702 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.282378 140552972691264 make_examples_core.py:257] Task 8/32: Common contigs are ['chr20']; I0519 16:22:23.271428 140087439025984 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192873 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.234176 139704511100736 make_examples_core.py:257] Task 12/32: Preparing inputs; I0519 16:22:23.236589 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.237330 139704511100736 make_examples_core.py:257] Task 12/32: Common contigs are ['chr20']; I0519 16:22:23.237694 140638923466560 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.289134 140638923466560 make_examples_core.py:257] Task 29/32: Preparing inputs; I0519 16:22:23.215111 139798323177280 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.265897 139798323177280 make_examples_core.py:257] T,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:11131,Testability,test,testdata,11131,es_core.py:257] Task 6/32: Preparing inputs; I0519 16:22:23.282453 140555533080384 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.283533 140555533080384 make_examples_core.py:257] Task 6/32: Common contigs are ['chr20']; I0519 16:22:23.228248 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.279789 140552972691264 make_examples_core.py:257] Task 8/32: Preparing inputs; I0519 16:22:23.281702 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.282378 140552972691264 make_examples_core.py:257] Task 8/32: Common contigs are ['chr20']; I0519 16:22:23.271428 140087439025984 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192873 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.234176 139704511100736 make_examples_core.py:257] Task 12/32: Preparing inputs; I0519 16:22:23.236589 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.237330 139704511100736 make_examples_core.py:257] Task 12/32: Common contigs are ['chr20']; I0519 16:22:23.237694 140638923466560 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.289134 140638923466560 make_examples_core.py:257] Task 29/32: Preparing inputs; I0519 16:22:23.215111 139798323177280 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.265897 139798323177280 make_examples_core.py:257] Task 9/32: Preparing inputs; **********; I0519 16:22:46.781010 139665862911808 session_manager.py:529] Done running local_init_op.; INFO:tensorf,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:11369,Testability,test,testdata,11369,s_core.py:257] Task 6/32: Common contigs are ['chr20']; I0519 16:22:23.228248 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.279789 140552972691264 make_examples_core.py:257] Task 8/32: Preparing inputs; I0519 16:22:23.281702 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.282378 140552972691264 make_examples_core.py:257] Task 8/32: Common contigs are ['chr20']; I0519 16:22:23.271428 140087439025984 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192873 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.234176 139704511100736 make_examples_core.py:257] Task 12/32: Preparing inputs; I0519 16:22:23.236589 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.237330 139704511100736 make_examples_core.py:257] Task 12/32: Common contigs are ['chr20']; I0519 16:22:23.237694 140638923466560 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.289134 140638923466560 make_examples_core.py:257] Task 29/32: Preparing inputs; I0519 16:22:23.215111 139798323177280 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.265897 139798323177280 make_examples_core.py:257] Task 9/32: Preparing inputs; **********; I0519 16:22:46.781010 139665862911808 session_manager.py:529] Done running local_init_op.; INFO:tensorflow:Reloading EMA...; I0519 16:22:47.119282 139665862911808 modeling.py:418] Reloading EMA...; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0519 16:22:47.119841 139665862911808 saver.py:1410] Restoring parameters,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:11619,Testability,test,testdata,11619,_core.py:257] Task 8/32: Preparing inputs; I0519 16:22:23.281702 140552972691264 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.282378 140552972691264 make_examples_core.py:257] Task 8/32: Common contigs are ['chr20']; I0519 16:22:23.271428 140087439025984 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192873 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.234176 139704511100736 make_examples_core.py:257] Task 12/32: Preparing inputs; I0519 16:22:23.236589 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.237330 139704511100736 make_examples_core.py:257] Task 12/32: Common contigs are ['chr20']; I0519 16:22:23.237694 140638923466560 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.289134 140638923466560 make_examples_core.py:257] Task 29/32: Preparing inputs; I0519 16:22:23.215111 139798323177280 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.265897 139798323177280 make_examples_core.py:257] Task 9/32: Preparing inputs; **********; I0519 16:22:46.781010 139665862911808 session_manager.py:529] Done running local_init_op.; INFO:tensorflow:Reloading EMA...; I0519 16:22:47.119282 139665862911808 modeling.py:418] Reloading EMA...; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0519 16:22:47.119841 139665862911808 saver.py:1410] Restoring parameters from /opt/models/wgs/model.ckpt; I0519 16:22:48.504039 139665862911808 call_variants.py:462] Processed 1 examples in 1 batches [632.440 sec per 100]; I0519 16:22:48.735930 139665862911808 call_variants.py:468] Processed 305 examples in 1 batches [2.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:11857,Testability,test,testdata,11857,core.py:257] Task 8/32: Common contigs are ['chr20']; I0519 16:22:23.271428 140087439025984 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.192873 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.234176 139704511100736 make_examples_core.py:257] Task 12/32: Preparing inputs; I0519 16:22:23.236589 139704511100736 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.237330 139704511100736 make_examples_core.py:257] Task 12/32: Common contigs are ['chr20']; I0519 16:22:23.237694 140638923466560 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.289134 140638923466560 make_examples_core.py:257] Task 29/32: Preparing inputs; I0519 16:22:23.215111 139798323177280 genomics_reader.py:222] Reading quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.265897 139798323177280 make_examples_core.py:257] Task 9/32: Preparing inputs; **********; I0519 16:22:46.781010 139665862911808 session_manager.py:529] Done running local_init_op.; INFO:tensorflow:Reloading EMA...; I0519 16:22:47.119282 139665862911808 modeling.py:418] Reloading EMA...; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0519 16:22:47.119841 139665862911808 saver.py:1410] Restoring parameters from /opt/models/wgs/model.ckpt; I0519 16:22:48.504039 139665862911808 call_variants.py:462] Processed 1 examples in 1 batches [632.440 sec per 100]; I0519 16:22:48.735930 139665862911808 call_variants.py:468] Processed 305 examples in 1 batches [2.084 sec per 100]; I0519 16:22:48.736088 139665862911808 call_variants.py:471] Done calling variants from a total of 305 examples. real 0m8.934s; user 0m37.643s; sys 0m6.426s. ***** Running the command:*****; time /opt/deepvariant/bin/post,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:12889,Testability,test,testdata,12889,"quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader; I0519 16:22:23.265897 139798323177280 make_examples_core.py:257] Task 9/32: Preparing inputs; **********; I0519 16:22:46.781010 139665862911808 session_manager.py:529] Done running local_init_op.; INFO:tensorflow:Reloading EMA...; I0519 16:22:47.119282 139665862911808 modeling.py:418] Reloading EMA...; INFO:tensorflow:Restoring parameters from /opt/models/wgs/model.ckpt; I0519 16:22:47.119841 139665862911808 saver.py:1410] Restoring parameters from /opt/models/wgs/model.ckpt; I0519 16:22:48.504039 139665862911808 call_variants.py:462] Processed 1 examples in 1 batches [632.440 sec per 100]; I0519 16:22:48.735930 139665862911808 call_variants.py:468] Processed 305 examples in 1 batches [2.084 sec per 100]; I0519 16:22:48.736088 139665862911808 call_variants.py:471] Done calling variants from a total of 305 examples. real 0m8.934s; user 0m37.643s; sys 0m6.426s. ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/tmp/tmp6gzkras0/call_variants_output.tfrecord.gz"" --outfile ""singularity-output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/tmp6gzkras0/gvcf.tfrecord@32.gz"" --gvcf_outfile ""singularity-output/output.g.vcf.gz"". 2023-05-19 16:22:49.638487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0519 16:22:51.170790 140640470185792 postprocess_variants.py:972] Using sample name from call_variants output. Sample name: NA12878; 2023-05-19 16:22:51.171487: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmp6gzkras0/call_variants_output.tfrecord.gz; 2023-05-19 16:22:51.173038: I deepvariant/postprocess_vari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/issues/653:120,Usability,clear,clear,120,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.); Hi developers,; I'd like to run `DeepVariant` for my `WGS` sequencing data. My sequencing data were from `BGI` platform and were preprocessed by `fastp, bwa+Hs37d5, MarkDuplicatesSpark`. I tried to use the 'sorted and deduplicated bam' file as input for `DeepVariant` in `singularity` mode. However, I always encountered the 'reference index' `not found` error. But my `reference` fasta file and `reference index` fai file does exist. Could you please help me figure it out?. **Setup**; - Operating system: Linux version 3.10.0-1127.el7.x86_64 (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39), Computation Node (one node of Clusters); - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):; - ``` BIN_VERSION=""1.5.0""; docker pull; ; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; singularity build --fakeroot deepvariant.sif docker://google/deepvariant:1.5.0```; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); `BGI platform, WGS data, Hs37d5 reference, fastp QC, bwa-mem2 mapping, MarkDuplicatesSpark sort & dedup`; . **Steps to reproduce:**; - Command:; - 1. singularity run /lustre/Data/toolsDB//deepvariant.sif /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=$ref_idx --reads=$dedupbam --output_vcf=$vcfout --output_gvcf=$gvcfout --num_shards=32 >$logx 2>&1; - Error trace: (if applicable); - ```I0522 08:40:36.823651 140633630893888 genomics_reader.py:222] Reading /lustre/home/zhoujianglin/datasets/2304GQS_FSZ_SNP/mappinged_bams/2-13A_bwa2Hs37d5_sorted_dedup.bam with NativeSamReader; I0522 08:40:36.846348 140633630893888 make_examples_core.py:257] Task 27/32: Preparing inputs; [E::fai_load3_core] Failed to open FASTA index /lustre/Data/toolsDB/HostRefs/Human_hs37d5/hs37d5.fa.fai: No such file or",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/653
https://github.com/google/deepvariant/pull/654:52,Deployability,update,update,52,We are not taking pull requests at this time.; This update is pushed by the team member (pichuan@) to the gh-pages for https://goo.gl/deepvariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/654
https://github.com/google/deepvariant/issues/655:43,Availability,error,error,43,"hello,; I tested a NGS sample on DV1.4. An error occurred in calling a variant at a specific locus.The VCF results show that the genotype at this locus is 1/1, but the first-generation sequencing results did not reveal a homozygous mutation. I checked the BAM file, and I couldn't draw a conclusion about the homozygous mutation either. How was the 1/1 result determined? Can you explain the reasons and methods to avoid the error from happening?; ![image](https://github.com/google/deepvariant/assets/70870741/1c0710d4-f9a4-40ef-a2d7-c982e42eac1b); ![image](https://github.com/google/deepvariant/assets/70870741/4665a415-6236-46a2-ad0a-958ddf4ca2bf); ![image](https://github.com/google/deepvariant/assets/70870741/5433bce6-1b83-4d8a-88d3-8173708ac8ed); Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/655
https://github.com/google/deepvariant/issues/655:425,Availability,error,error,425,"hello,; I tested a NGS sample on DV1.4. An error occurred in calling a variant at a specific locus.The VCF results show that the genotype at this locus is 1/1, but the first-generation sequencing results did not reveal a homozygous mutation. I checked the BAM file, and I couldn't draw a conclusion about the homozygous mutation either. How was the 1/1 result determined? Can you explain the reasons and methods to avoid the error from happening?; ![image](https://github.com/google/deepvariant/assets/70870741/1c0710d4-f9a4-40ef-a2d7-c982e42eac1b); ![image](https://github.com/google/deepvariant/assets/70870741/4665a415-6236-46a2-ad0a-958ddf4ca2bf); ![image](https://github.com/google/deepvariant/assets/70870741/5433bce6-1b83-4d8a-88d3-8173708ac8ed); Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/655
https://github.com/google/deepvariant/issues/655:415,Safety,avoid,avoid,415,"hello,; I tested a NGS sample on DV1.4. An error occurred in calling a variant at a specific locus.The VCF results show that the genotype at this locus is 1/1, but the first-generation sequencing results did not reveal a homozygous mutation. I checked the BAM file, and I couldn't draw a conclusion about the homozygous mutation either. How was the 1/1 result determined? Can you explain the reasons and methods to avoid the error from happening?; ![image](https://github.com/google/deepvariant/assets/70870741/1c0710d4-f9a4-40ef-a2d7-c982e42eac1b); ![image](https://github.com/google/deepvariant/assets/70870741/4665a415-6236-46a2-ad0a-958ddf4ca2bf); ![image](https://github.com/google/deepvariant/assets/70870741/5433bce6-1b83-4d8a-88d3-8173708ac8ed); Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/655
https://github.com/google/deepvariant/issues/655:10,Testability,test,tested,10,"hello,; I tested a NGS sample on DV1.4. An error occurred in calling a variant at a specific locus.The VCF results show that the genotype at this locus is 1/1, but the first-generation sequencing results did not reveal a homozygous mutation. I checked the BAM file, and I couldn't draw a conclusion about the homozygous mutation either. How was the 1/1 result determined? Can you explain the reasons and methods to avoid the error from happening?; ![image](https://github.com/google/deepvariant/assets/70870741/1c0710d4-f9a4-40ef-a2d7-c982e42eac1b); ![image](https://github.com/google/deepvariant/assets/70870741/4665a415-6236-46a2-ad0a-958ddf4ca2bf); ![image](https://github.com/google/deepvariant/assets/70870741/5433bce6-1b83-4d8a-88d3-8173708ac8ed); Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/655
https://github.com/google/deepvariant/issues/657:6,Deployability,Install,Installing,6,"Goal: Installing deepvariant using Docker Desktop on a Mac (apple silicon - M1/M2). I have been troubleshooting for days and to build from source, but failed to do so. ; Now I ended up installing Ubuntu 20.04 using mac's UTM, but still facing a lot of problems. . Is there a detailed step-by-step instruction on how to install on a mac (apple silicon)?. You mentioned: ""It can likely be built and run on other unix-based systems with some minimal modifications to these scripts.""; from https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md; What is the ""minimal modifications"" in here? Changing everything about the build-prereq.sh, setting.sh, tools/build_clif.sh, and other .sh, proves to be a hard task. Otherwise, I can try to explain the problem of Ubuntu 20.04 using mac's UTM. Thank you for your help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/657
https://github.com/google/deepvariant/issues/657:185,Deployability,install,installing,185,"Goal: Installing deepvariant using Docker Desktop on a Mac (apple silicon - M1/M2). I have been troubleshooting for days and to build from source, but failed to do so. ; Now I ended up installing Ubuntu 20.04 using mac's UTM, but still facing a lot of problems. . Is there a detailed step-by-step instruction on how to install on a mac (apple silicon)?. You mentioned: ""It can likely be built and run on other unix-based systems with some minimal modifications to these scripts.""; from https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md; What is the ""minimal modifications"" in here? Changing everything about the build-prereq.sh, setting.sh, tools/build_clif.sh, and other .sh, proves to be a hard task. Otherwise, I can try to explain the problem of Ubuntu 20.04 using mac's UTM. Thank you for your help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/657
https://github.com/google/deepvariant/issues/657:319,Deployability,install,install,319,"Goal: Installing deepvariant using Docker Desktop on a Mac (apple silicon - M1/M2). I have been troubleshooting for days and to build from source, but failed to do so. ; Now I ended up installing Ubuntu 20.04 using mac's UTM, but still facing a lot of problems. . Is there a detailed step-by-step instruction on how to install on a mac (apple silicon)?. You mentioned: ""It can likely be built and run on other unix-based systems with some minimal modifications to these scripts.""; from https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md; What is the ""minimal modifications"" in here? Changing everything about the build-prereq.sh, setting.sh, tools/build_clif.sh, and other .sh, proves to be a hard task. Otherwise, I can try to explain the problem of Ubuntu 20.04 using mac's UTM. Thank you for your help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/657
https://github.com/google/deepvariant/issues/657:557,Testability,test,test,557,"Goal: Installing deepvariant using Docker Desktop on a Mac (apple silicon - M1/M2). I have been troubleshooting for days and to build from source, but failed to do so. ; Now I ended up installing Ubuntu 20.04 using mac's UTM, but still facing a lot of problems. . Is there a detailed step-by-step instruction on how to install on a mac (apple silicon)?. You mentioned: ""It can likely be built and run on other unix-based systems with some minimal modifications to these scripts.""; from https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-build-test.md; What is the ""minimal modifications"" in here? Changing everything about the build-prereq.sh, setting.sh, tools/build_clif.sh, and other .sh, proves to be a hard task. Otherwise, I can try to explain the problem of Ubuntu 20.04 using mac's UTM. Thank you for your help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/657
https://github.com/google/deepvariant/issues/659:1593,Availability,error,error,1593,"Hi i have deepvariant 1.5.0 version singularity SIF file,; I ran successfully from command line for PacBio data, but when i ran the same through NextFlow as below; #nextflow.config; ```; singularity {; process.container = '/data/shared/clinical/LongRead/DeepVariant/deepvariant.simg'; cacheDir = ""/data/shared/clinical/LongRead/cache/""; singularity.enabled = true; singularity.autoMounts = true; SINGULARITY_BINDPATH = ""/data""; }. conda; {; enabled = true; cacheDir = ""/data/shared/clinical/LongRead/Programs/""; }; params; {; path=""/data/shared/clinical/LongRead/""; ref_genome=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""; pbhg38_tdx=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.mmi""; at=18; st=6; data_input=""/data/shared/clinical/LongRead/Data/""; }; ```; #deepvariant.nf; ```; process pbc_varicall {; publishDir ""/data/shared/clinical/LongRead/Data/resources/""; container 'docker://google/deepvariant:1.5.0'. input:; path 'fa'; output:; file ""*""; path 'm84011_220902_175841_NF_sif.vcf.gz'. script:; """"""; run_deepvariant --model_type PACBIO --ref ${params.ref_genome} --reads ${params.data_input}/m84011_220902_175841_Aln.bam --output_vcf ${params.data_input}/Analysis/out_m84011_220902_175841_NF_sif.vcf.gz --num_shards 40; """"""; }. workflow {; fa=channel.fromPath(""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""); pbc_varicall(fa); }; ```; after running for several hours i do not get any output, instead during run , i get msg as; `TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: `; this is during `make_examples` step",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/659
https://github.com/google/deepvariant/issues/659:174,Modifiability,config,config,174,"Hi i have deepvariant 1.5.0 version singularity SIF file,; I ran successfully from command line for PacBio data, but when i ran the same through NextFlow as below; #nextflow.config; ```; singularity {; process.container = '/data/shared/clinical/LongRead/DeepVariant/deepvariant.simg'; cacheDir = ""/data/shared/clinical/LongRead/cache/""; singularity.enabled = true; singularity.autoMounts = true; SINGULARITY_BINDPATH = ""/data""; }. conda; {; enabled = true; cacheDir = ""/data/shared/clinical/LongRead/Programs/""; }; params; {; path=""/data/shared/clinical/LongRead/""; ref_genome=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""; pbhg38_tdx=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.mmi""; at=18; st=6; data_input=""/data/shared/clinical/LongRead/Data/""; }; ```; #deepvariant.nf; ```; process pbc_varicall {; publishDir ""/data/shared/clinical/LongRead/Data/resources/""; container 'docker://google/deepvariant:1.5.0'. input:; path 'fa'; output:; file ""*""; path 'm84011_220902_175841_NF_sif.vcf.gz'. script:; """"""; run_deepvariant --model_type PACBIO --ref ${params.ref_genome} --reads ${params.data_input}/m84011_220902_175841_Aln.bam --output_vcf ${params.data_input}/Analysis/out_m84011_220902_175841_NF_sif.vcf.gz --num_shards 40; """"""; }. workflow {; fa=channel.fromPath(""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""); pbc_varicall(fa); }; ```; after running for several hours i do not get any output, instead during run , i get msg as; `TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: `; this is during `make_examples` step",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/659
https://github.com/google/deepvariant/issues/659:285,Performance,cache,cacheDir,285,"Hi i have deepvariant 1.5.0 version singularity SIF file,; I ran successfully from command line for PacBio data, but when i ran the same through NextFlow as below; #nextflow.config; ```; singularity {; process.container = '/data/shared/clinical/LongRead/DeepVariant/deepvariant.simg'; cacheDir = ""/data/shared/clinical/LongRead/cache/""; singularity.enabled = true; singularity.autoMounts = true; SINGULARITY_BINDPATH = ""/data""; }. conda; {; enabled = true; cacheDir = ""/data/shared/clinical/LongRead/Programs/""; }; params; {; path=""/data/shared/clinical/LongRead/""; ref_genome=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""; pbhg38_tdx=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.mmi""; at=18; st=6; data_input=""/data/shared/clinical/LongRead/Data/""; }; ```; #deepvariant.nf; ```; process pbc_varicall {; publishDir ""/data/shared/clinical/LongRead/Data/resources/""; container 'docker://google/deepvariant:1.5.0'. input:; path 'fa'; output:; file ""*""; path 'm84011_220902_175841_NF_sif.vcf.gz'. script:; """"""; run_deepvariant --model_type PACBIO --ref ${params.ref_genome} --reads ${params.data_input}/m84011_220902_175841_Aln.bam --output_vcf ${params.data_input}/Analysis/out_m84011_220902_175841_NF_sif.vcf.gz --num_shards 40; """"""; }. workflow {; fa=channel.fromPath(""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""); pbc_varicall(fa); }; ```; after running for several hours i do not get any output, instead during run , i get msg as; `TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: `; this is during `make_examples` step",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/659
https://github.com/google/deepvariant/issues/659:328,Performance,cache,cache,328,"Hi i have deepvariant 1.5.0 version singularity SIF file,; I ran successfully from command line for PacBio data, but when i ran the same through NextFlow as below; #nextflow.config; ```; singularity {; process.container = '/data/shared/clinical/LongRead/DeepVariant/deepvariant.simg'; cacheDir = ""/data/shared/clinical/LongRead/cache/""; singularity.enabled = true; singularity.autoMounts = true; SINGULARITY_BINDPATH = ""/data""; }. conda; {; enabled = true; cacheDir = ""/data/shared/clinical/LongRead/Programs/""; }; params; {; path=""/data/shared/clinical/LongRead/""; ref_genome=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""; pbhg38_tdx=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.mmi""; at=18; st=6; data_input=""/data/shared/clinical/LongRead/Data/""; }; ```; #deepvariant.nf; ```; process pbc_varicall {; publishDir ""/data/shared/clinical/LongRead/Data/resources/""; container 'docker://google/deepvariant:1.5.0'. input:; path 'fa'; output:; file ""*""; path 'm84011_220902_175841_NF_sif.vcf.gz'. script:; """"""; run_deepvariant --model_type PACBIO --ref ${params.ref_genome} --reads ${params.data_input}/m84011_220902_175841_Aln.bam --output_vcf ${params.data_input}/Analysis/out_m84011_220902_175841_NF_sif.vcf.gz --num_shards 40; """"""; }. workflow {; fa=channel.fromPath(""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""); pbc_varicall(fa); }; ```; after running for several hours i do not get any output, instead during run , i get msg as; `TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: `; this is during `make_examples` step",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/659
https://github.com/google/deepvariant/issues/659:457,Performance,cache,cacheDir,457,"Hi i have deepvariant 1.5.0 version singularity SIF file,; I ran successfully from command line for PacBio data, but when i ran the same through NextFlow as below; #nextflow.config; ```; singularity {; process.container = '/data/shared/clinical/LongRead/DeepVariant/deepvariant.simg'; cacheDir = ""/data/shared/clinical/LongRead/cache/""; singularity.enabled = true; singularity.autoMounts = true; SINGULARITY_BINDPATH = ""/data""; }. conda; {; enabled = true; cacheDir = ""/data/shared/clinical/LongRead/Programs/""; }; params; {; path=""/data/shared/clinical/LongRead/""; ref_genome=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""; pbhg38_tdx=""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.mmi""; at=18; st=6; data_input=""/data/shared/clinical/LongRead/Data/""; }; ```; #deepvariant.nf; ```; process pbc_varicall {; publishDir ""/data/shared/clinical/LongRead/Data/resources/""; container 'docker://google/deepvariant:1.5.0'. input:; path 'fa'; output:; file ""*""; path 'm84011_220902_175841_NF_sif.vcf.gz'. script:; """"""; run_deepvariant --model_type PACBIO --ref ${params.ref_genome} --reads ${params.data_input}/m84011_220902_175841_Aln.bam --output_vcf ${params.data_input}/Analysis/out_m84011_220902_175841_NF_sif.vcf.gz --num_shards 40; """"""; }. workflow {; fa=channel.fromPath(""/data/shared/clinical/LongRead/Data/resources/Homo_sapiens_assembly38.fasta""); pbc_varicall(fa); }; ```; after running for several hours i do not get any output, instead during run , i get msg as; `TaskHandler[id: 1; name: pbc_varicall (1); status: RUNNING; exit: -; error: -; workDir: `; this is during `make_examples` step",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/659
https://github.com/google/deepvariant/issues/660:1364,Deployability,Install,Installation,1364,"Hi DeepVariant team,. I have been using DeepVariant （v1.1.0）to call small variants for a human genome with approximately 50X coverage of HiFi reads. During my analysis, I noticed that DeepVariant consistently reports some false positives in some regions. For example, at position chr10:89013075-89013077, there is a SNV (see the IGV snapshot of both Illumina and HiFi reads), but DeepVariant identifies three variants at that location. The vcf records by deepvariant:; ```; chr10 89013075 . T TC 31.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:63:35,28:0.444444:31,0,43; chr10 89013076 . CA C 28.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:27:63:35,28:0.444444:28,0,34; chr10 89013077 . A C 30.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:34:0,34:1:30,0,17; ```; The IGV snapshots:. ![image](https://github.com/google/deepvariant/assets/44404441/9618a4b9-7594-42e0-bb65-173761f803a8). I haven't identified any patterns in these regions. Have you encountered similar situations before? Could you please explain the possible reasons behind these false positive calls? I have provided three examples, including small BAM files, resulting VCF files, and my code, for you to replicate and investigate. . [deepvariant_fp.zip](https://github.com/google/deepvariant/files/11735375/deepvariant_fp.zip). Other information of my test: . - Operating system: Red Hat 4.8.5-36; - DeepVariant version: 1.1.0; - Installation method (Docker, built from source, etc.): Docker; - reference : GRCh38_full_analysis_set_plus_decoy_hla.fa; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); ~50x Human HiFi seuquencing data. Thank you very much for your attention and support. I look forward to your response. Best regards,; Peng Jia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/660
https://github.com/google/deepvariant/issues/660:1286,Testability,test,test,1286,"Hi DeepVariant team,. I have been using DeepVariant （v1.1.0）to call small variants for a human genome with approximately 50X coverage of HiFi reads. During my analysis, I noticed that DeepVariant consistently reports some false positives in some regions. For example, at position chr10:89013075-89013077, there is a SNV (see the IGV snapshot of both Illumina and HiFi reads), but DeepVariant identifies three variants at that location. The vcf records by deepvariant:; ```; chr10 89013075 . T TC 31.7 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:63:35,28:0.444444:31,0,43; chr10 89013076 . CA C 28.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:27:63:35,28:0.444444:28,0,34; chr10 89013077 . A C 30.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:34:0,34:1:30,0,17; ```; The IGV snapshots:. ![image](https://github.com/google/deepvariant/assets/44404441/9618a4b9-7594-42e0-bb65-173761f803a8). I haven't identified any patterns in these regions. Have you encountered similar situations before? Could you please explain the possible reasons behind these false positive calls? I have provided three examples, including small BAM files, resulting VCF files, and my code, for you to replicate and investigate. . [deepvariant_fp.zip](https://github.com/google/deepvariant/files/11735375/deepvariant_fp.zip). Other information of my test: . - Operating system: Red Hat 4.8.5-36; - DeepVariant version: 1.1.0; - Installation method (Docker, built from source, etc.): Docker; - reference : GRCh38_full_analysis_set_plus_decoy_hla.fa; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); ~50x Human HiFi seuquencing data. Thank you very much for your attention and support. I look forward to your response. Best regards,; Peng Jia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/660
https://github.com/google/deepvariant/issues/661:160,Deployability,release,release,160,"Hello, . I was wondering ... I know you have a mosquito model that seems to work for when there is a high heterozygosity, but I was wondering if you planned to release those mdels... We, who work with non-model organisms, would be really happy to use DeepVariant. . Sorry if this is out of place here, I didn't really know where to ask. Feel free to lock . Cheers. Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/661
https://github.com/google/deepvariant/issues/664:113,Availability,error,error,113,"Installed DeepVariant 1.5.0 from bioconda using micromamba. Running make examples command produces the following error:; ```; micromamba run --name dv /opt/conda/envs/dv/bin/python /opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip --mode calling --ref /data/dpipe/rundata/refdata/hg/hg19_no_chr6_hap.fasta --reads /data/dpipe/rundata/runs/run1/NA12878/NA12878.bam --sample_name NA12878 --examples /data/dpipe/rundata/runs/run1/dvout//NA12878.tfrecord@1.gz --task 0; Traceback (most recent call last):; File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 365, in Main; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 287, in call; with Popen(*popenargs, **kwargs) as p:; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 729, in __init__; restore_signals, start_new_session); File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 1364, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'; ```. I noticed inside the bazel .zip files the python binary is hard-coded:; /share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip Line 60: `PYTHON_BINARY = '/usr/bin/python3'`. Is there any way to override this value to select a different python binary? The micromamba python binary is not in the standard location and there is also multiple python binaries in this system. DeepVariant was installed using micromamba:. ```; micro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/664
https://github.com/google/deepvariant/issues/664:0,Deployability,Install,Installed,0,"Installed DeepVariant 1.5.0 from bioconda using micromamba. Running make examples command produces the following error:; ```; micromamba run --name dv /opt/conda/envs/dv/bin/python /opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip --mode calling --ref /data/dpipe/rundata/refdata/hg/hg19_no_chr6_hap.fasta --reads /data/dpipe/rundata/runs/run1/NA12878/NA12878.bam --sample_name NA12878 --examples /data/dpipe/rundata/runs/run1/dvout//NA12878.tfrecord@1.gz --task 0; Traceback (most recent call last):; File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 365, in Main; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 287, in call; with Popen(*popenargs, **kwargs) as p:; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 729, in __init__; restore_signals, start_new_session); File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 1364, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'; ```. I noticed inside the bazel .zip files the python binary is hard-coded:; /share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip Line 60: `PYTHON_BINARY = '/usr/bin/python3'`. Is there any way to override this value to select a different python binary? The micromamba python binary is not in the standard location and there is also multiple python binaries in this system. DeepVariant was installed using micromamba:. ```; micro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/664
https://github.com/google/deepvariant/issues/664:1962,Deployability,install,installed,1962,"epVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip --mode calling --ref /data/dpipe/rundata/refdata/hg/hg19_no_chr6_hap.fasta --reads /data/dpipe/rundata/runs/run1/NA12878/NA12878.bam --sample_name NA12878 --examples /data/dpipe/rundata/runs/run1/dvout//NA12878.tfrecord@1.gz --task 0; Traceback (most recent call last):; File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 365, in Main; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 287, in call; with Popen(*popenargs, **kwargs) as p:; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 729, in __init__; restore_signals, start_new_session); File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 1364, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'; ```. I noticed inside the bazel .zip files the python binary is hard-coded:; /share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip Line 60: `PYTHON_BINARY = '/usr/bin/python3'`. Is there any way to override this value to select a different python binary? The micromamba python binary is not in the standard location and there is also multiple python binaries in this system. DeepVariant was installed using micromamba:. ```; micromamba create -n dv && micromamba install -y -n dv -f /tmp/env_deepvariant.yaml; ``` ; With environment file:; ```; name: dv; channels:; - conda-forge; - bioconda; - defaults; dependencies:; - python=3.6; - deepvariant=1.5.0; ```. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/664
https://github.com/google/deepvariant/issues/664:2034,Deployability,install,install,2034,"epVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip --mode calling --ref /data/dpipe/rundata/refdata/hg/hg19_no_chr6_hap.fasta --reads /data/dpipe/rundata/runs/run1/NA12878/NA12878.bam --sample_name NA12878 --examples /data/dpipe/rundata/runs/run1/dvout//NA12878.tfrecord@1.gz --task 0; Traceback (most recent call last):; File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 365, in Main; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 287, in call; with Popen(*popenargs, **kwargs) as p:; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 729, in __init__; restore_signals, start_new_session); File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 1364, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'; ```. I noticed inside the bazel .zip files the python binary is hard-coded:; /share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip Line 60: `PYTHON_BINARY = '/usr/bin/python3'`. Is there any way to override this value to select a different python binary? The micromamba python binary is not in the standard location and there is also multiple python binaries in this system. DeepVariant was installed using micromamba:. ```; micromamba create -n dv && micromamba install -y -n dv -f /tmp/env_deepvariant.yaml; ``` ; With environment file:; ```; name: dv; channels:; - conda-forge; - bioconda; - defaults; dependencies:; - python=3.6; - deepvariant=1.5.0; ```. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/664
https://github.com/google/deepvariant/issues/664:2176,Integrability,depend,dependencies,2176,"epVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip --mode calling --ref /data/dpipe/rundata/refdata/hg/hg19_no_chr6_hap.fasta --reads /data/dpipe/rundata/runs/run1/NA12878/NA12878.bam --sample_name NA12878 --examples /data/dpipe/rundata/runs/run1/dvout//NA12878.tfrecord@1.gz --task 0; Traceback (most recent call last):; File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 193, in _run_module_as_main; ""__main__"", mod_spec); File ""/opt/conda/envs/dv/lib/python3.6/runpy.py"", line 85, in _run_code; exec(code, run_globals); File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 392, in <module>; File ""/opt/conda/envs/dv/share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip/__main__.py"", line 365, in Main; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 287, in call; with Popen(*popenargs, **kwargs) as p:; File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 729, in __init__; restore_signals, start_new_session); File ""/opt/conda/envs/dv/lib/python3.6/subprocess.py"", line 1364, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3': '/usr/bin/python3'; ```. I noticed inside the bazel .zip files the python binary is hard-coded:; /share/deepvariant-1.5.0-0/binaries/DeepVariant/1.5.0/DeepVariant-1.5.0/make_examples.zip Line 60: `PYTHON_BINARY = '/usr/bin/python3'`. Is there any way to override this value to select a different python binary? The micromamba python binary is not in the standard location and there is also multiple python binaries in this system. DeepVariant was installed using micromamba:. ```; micromamba create -n dv && micromamba install -y -n dv -f /tmp/env_deepvariant.yaml; ``` ; With environment file:; ```; name: dv; channels:; - conda-forge; - bioconda; - defaults; dependencies:; - python=3.6; - deepvariant=1.5.0; ```. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/664
https://github.com/google/deepvariant/issues/666:352,Availability,error,error,352,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. ; **Describe the issue:**; I followed the [PACBIO example](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md) and also added the flags from [this issue](https://github.com/google/deepvariant/issues/458). . ; This error indicates that Deepvariant is not able to find an index file for the bam file but the index file is there see :; ; ``` ; (base) ✔ /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam[master L|…5] ; 22:08 $ ls; GFX.bam GFX.bam.pbi GFX_hg19.bam GFX_hg19.bam.pbi readlength.txt tmp; ```; I also re-indexd the file using `pbindex` from [pbbam](https://github.com/pacificbiosciences/pbbam/). As one can see from the `ls` output I also tried to realign the bam file to some other reference panel using [pbmm2](https://github.com/PacificBiosciences/pbmm2/).; ; **Setup**; - Operating system: Linux Mint 21.1 x86_64 ; - Kernel: 5.15.0-69-generic ; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): Docker image run through Singularity; - Singularity Verion : singularity-ce version 3.11.3; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO CCS data aligned to GRCh37.fa reference genome. No special observations in the file can be reported. . ```; (base) ✔ /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam [master L|…5] ; 20:46 $ samtools flagstat GFX.bam ; ^[[1;5C940551 + 0 in total (QC-passed reads + QC-failed reads); 881297 + 0 primary; 0 + 0 secondary; 59254 + 0 supplementary; 0 + 0 duplicates; 0 + 0 primary duplicates; 940551 + 0 mapped (100.00% : N/A); 881297 + 0 primary mapped (100.00% : N/A); 0 + 0 paired in sequencing; 0 + 0 read1; 0 + 0 read2; 0 + 0 properly paired (N/A : N/A); 0 + 0 with itself and mate mapped; 0 + 0 singletons (N/A : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a diffe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/666:2834,Availability,Error,Error,2834," paired (N/A : N/A); 0 + 0 with itself and mate mapped; 0 + 0 singletons (N/A : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. ; **Steps to reproduce:**; - Command: Follow the [PACBIO example](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md) and install the mentioned singularity version. Then run . `singularity exec --bind /usr/lib/locale/,/media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/,/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/ docker://google/deepvariant:1.5.0 /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref /media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/hg19.fa --reads /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.bam --output_vcf /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.vcf.gz --num_shards 22 --dry_run=false --make_examples_extra_args='sort_by_haplotypes=false,parse_sam_aux_fields=false'`. - Error trace: . The error message including the pipeline call is :; ; ```; E::idx_find_and_load] Could not retrieve index file for '/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam/GFX.bam'; 2023-06-20 22:48:40.272832: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD	VN:1.6	SO:coordinate	pb:5.0.0; 2023-06-20 22:48:40.272881: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag BC: in RG line, ignoring: @RG	ID:408781da/26--26	PL:PACBIO	DS:READTYPE=CCS;BINDINGKIT=101-894-200;SEQUENCINGKIT=101-826-100;BASECALLERVERSION=5.0.0;FRAMERATEHZ=100.000000;BarcodeFile=m64023e_230515_162401.barcodes.fasta;BarcodeHash=86d73e586a6d3ede0295785b51105eea;BarcodeCount=96;BarcodeMode=Symmetric;BarcodeQuality=Score	LB:Pool_18_20_GFX0455704_GFX	PU:m64023e_230515_162401	SM:GFX; PM:SEQUELII	BC:TGACTGTAGCGAGTAT	CM:S/P5-C2/5.0-8M; 2023-06-20 22:48:40.272889: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag CM: in RG line, ignoring: @RG	ID:408781da/26--26	PL:PA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/666:2853,Availability,error,error,2853,"ate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. ; **Steps to reproduce:**; - Command: Follow the [PACBIO example](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md) and install the mentioned singularity version. Then run . `singularity exec --bind /usr/lib/locale/,/media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/,/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/ docker://google/deepvariant:1.5.0 /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref /media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/hg19.fa --reads /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.bam --output_vcf /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.vcf.gz --num_shards 22 --dry_run=false --make_examples_extra_args='sort_by_haplotypes=false,parse_sam_aux_fields=false'`. - Error trace: . The error message including the pipeline call is :; ; ```; E::idx_find_and_load] Could not retrieve index file for '/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam/GFX.bam'; 2023-06-20 22:48:40.272832: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD	VN:1.6	SO:coordinate	pb:5.0.0; 2023-06-20 22:48:40.272881: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag BC: in RG line, ignoring: @RG	ID:408781da/26--26	PL:PACBIO	DS:READTYPE=CCS;BINDINGKIT=101-894-200;SEQUENCINGKIT=101-826-100;BASECALLERVERSION=5.0.0;FRAMERATEHZ=100.000000;BarcodeFile=m64023e_230515_162401.barcodes.fasta;BarcodeHash=86d73e586a6d3ede0295785b51105eea;BarcodeCount=96;BarcodeMode=Symmetric;BarcodeQuality=Score	LB:Pool_18_20_GFX0455704_GFX	PU:m64023e_230515_162401	SM:GFX; PM:SEQUELII	BC:TGACTGTAGCGAGTAT	CM:S/P5-C2/5.0-8M; 2023-06-20 22:48:40.272889: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag CM: in RG line, ignoring: @RG	ID:408781da/26--26	PL:PACBIO	DS:READTYPE=CCS;BINDINGKIT=101-894-200;SEQUENCINGKIT=101-826-100;BASECALLERVERSION=5.0.0;FRA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/666:1034,Deployability,Install,Installation,1034,"pvariant/blob/r1.5/docs/FAQ.md**:; Yes. ; **Describe the issue:**; I followed the [PACBIO example](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md) and also added the flags from [this issue](https://github.com/google/deepvariant/issues/458). . ; This error indicates that Deepvariant is not able to find an index file for the bam file but the index file is there see :; ; ``` ; (base) ✔ /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam[master L|…5] ; 22:08 $ ls; GFX.bam GFX.bam.pbi GFX_hg19.bam GFX_hg19.bam.pbi readlength.txt tmp; ```; I also re-indexd the file using `pbindex` from [pbbam](https://github.com/pacificbiosciences/pbbam/). As one can see from the `ls` output I also tried to realign the bam file to some other reference panel using [pbmm2](https://github.com/PacificBiosciences/pbmm2/).; ; **Setup**; - Operating system: Linux Mint 21.1 x86_64 ; - Kernel: 5.15.0-69-generic ; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): Docker image run through Singularity; - Singularity Verion : singularity-ce version 3.11.3; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PACBIO CCS data aligned to GRCh37.fa reference genome. No special observations in the file can be reported. . ```; (base) ✔ /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam [master L|…5] ; 20:46 $ samtools flagstat GFX.bam ; ^[[1;5C940551 + 0 in total (QC-passed reads + QC-failed reads); 881297 + 0 primary; 0 + 0 secondary; 59254 + 0 supplementary; 0 + 0 duplicates; 0 + 0 primary duplicates; 940551 + 0 mapped (100.00% : N/A); 881297 + 0 primary mapped (100.00% : N/A); 0 + 0 paired in sequencing; 0 + 0 read1; 0 + 0 read2; 0 + 0 properly paired (N/A : N/A); 0 + 0 with itself and mate mapped; 0 + 0 singletons (N/A : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. ; **Steps to reproduce:**; - Com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/666:2189,Deployability,install,install,2189,"ng instrument, reference genome, anything special that is unlike the case studies?) PACBIO CCS data aligned to GRCh37.fa reference genome. No special observations in the file can be reported. . ```; (base) ✔ /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam [master L|…5] ; 20:46 $ samtools flagstat GFX.bam ; ^[[1;5C940551 + 0 in total (QC-passed reads + QC-failed reads); 881297 + 0 primary; 0 + 0 secondary; 59254 + 0 supplementary; 0 + 0 duplicates; 0 + 0 primary duplicates; 940551 + 0 mapped (100.00% : N/A); 881297 + 0 primary mapped (100.00% : N/A); 0 + 0 paired in sequencing; 0 + 0 read1; 0 + 0 read2; 0 + 0 properly paired (N/A : N/A); 0 + 0 with itself and mate mapped; 0 + 0 singletons (N/A : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. ; **Steps to reproduce:**; - Command: Follow the [PACBIO example](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md) and install the mentioned singularity version. Then run . `singularity exec --bind /usr/lib/locale/,/media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/,/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/ docker://google/deepvariant:1.5.0 /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref /media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/hg19.fa --reads /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.bam --output_vcf /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.vcf.gz --num_shards 22 --dry_run=false --make_examples_extra_args='sort_by_haplotypes=false,parse_sam_aux_fields=false'`. - Error trace: . The error message including the pipeline call is :; ; ```; E::idx_find_and_load] Could not retrieve index file for '/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam/GFX.bam'; 2023-06-20 22:48:40.272832: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD	VN:1.6	SO:coordinate	pb:5.0.0; 2023-06-20 22:48:40.27288",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/666:2881,Deployability,pipeline,pipeline,2881,"ate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. ; **Steps to reproduce:**; - Command: Follow the [PACBIO example](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md) and install the mentioned singularity version. Then run . `singularity exec --bind /usr/lib/locale/,/media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/,/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/ docker://google/deepvariant:1.5.0 /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref /media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/hg19.fa --reads /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.bam --output_vcf /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.vcf.gz --num_shards 22 --dry_run=false --make_examples_extra_args='sort_by_haplotypes=false,parse_sam_aux_fields=false'`. - Error trace: . The error message including the pipeline call is :; ; ```; E::idx_find_and_load] Could not retrieve index file for '/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam/GFX.bam'; 2023-06-20 22:48:40.272832: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD	VN:1.6	SO:coordinate	pb:5.0.0; 2023-06-20 22:48:40.272881: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag BC: in RG line, ignoring: @RG	ID:408781da/26--26	PL:PACBIO	DS:READTYPE=CCS;BINDINGKIT=101-894-200;SEQUENCINGKIT=101-826-100;BASECALLERVERSION=5.0.0;FRAMERATEHZ=100.000000;BarcodeFile=m64023e_230515_162401.barcodes.fasta;BarcodeHash=86d73e586a6d3ede0295785b51105eea;BarcodeCount=96;BarcodeMode=Symmetric;BarcodeQuality=Score	LB:Pool_18_20_GFX0455704_GFX	PU:m64023e_230515_162401	SM:GFX; PM:SEQUELII	BC:TGACTGTAGCGAGTAT	CM:S/P5-C2/5.0-8M; 2023-06-20 22:48:40.272889: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag CM: in RG line, ignoring: @RG	ID:408781da/26--26	PL:PACBIO	DS:READTYPE=CCS;BINDINGKIT=101-894-200;SEQUENCINGKIT=101-826-100;BASECALLERVERSION=5.0.0;FRA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/666:6953,Deployability,pipeline,pipeline,6953," _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2183, in make_examples_runner; runtimes) = region_processor.process(region); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1285, in process; sample_reads = self.region_reads_norealign(; File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1376, in region_reads_norealign; reads = itertools.chain(reads, sam_reader.query(region)); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 247, in query; return self._reader.query(region); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 250, in query; return self._reader.query(region); ValueError: FAILED_PRECONDITION: Cannot query without an index; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /media/nils/nils_ssd_01/Genomics_prac_guide/reference/GRCh37/hs37d5.fa --reads /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam/GFX.bam --examples /tmp/tmpwjk24y8t/make_examples.tfrecord@22.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --noparse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --nosort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 1; ; ```; ; **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Quickstart works. This issue also happens when I try to run the pipeline with docker-only.; ; **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/666:2859,Integrability,message,message,2859,"ate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. ; **Steps to reproduce:**; - Command: Follow the [PACBIO example](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md) and install the mentioned singularity version. Then run . `singularity exec --bind /usr/lib/locale/,/media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/,/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/ docker://google/deepvariant:1.5.0 /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref /media/nils/nils_ssd_01/Genomics_prac_guide/reference/unsorted/hg19.fa --reads /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.bam --output_vcf /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/GFX.vcf.gz --num_shards 22 --dry_run=false --make_examples_extra_args='sort_by_haplotypes=false,parse_sam_aux_fields=false'`. - Error trace: . The error message including the pipeline call is :; ; ```; E::idx_find_and_load] Could not retrieve index file for '/media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam/GFX.bam'; 2023-06-20 22:48:40.272832: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD	VN:1.6	SO:coordinate	pb:5.0.0; 2023-06-20 22:48:40.272881: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag BC: in RG line, ignoring: @RG	ID:408781da/26--26	PL:PACBIO	DS:READTYPE=CCS;BINDINGKIT=101-894-200;SEQUENCINGKIT=101-826-100;BASECALLERVERSION=5.0.0;FRAMERATEHZ=100.000000;BarcodeFile=m64023e_230515_162401.barcodes.fasta;BarcodeHash=86d73e586a6d3ede0295785b51105eea;BarcodeCount=96;BarcodeMode=Symmetric;BarcodeQuality=Score	LB:Pool_18_20_GFX0455704_GFX	PU:m64023e_230515_162401	SM:GFX; PM:SEQUELII	BC:TGACTGTAGCGAGTAT	CM:S/P5-C2/5.0-8M; 2023-06-20 22:48:40.272889: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag CM: in RG line, ignoring: @RG	ID:408781da/26--26	PL:PACBIO	DS:READTYPE=CCS;BINDINGKIT=101-894-200;SEQUENCINGKIT=101-826-100;BASECALLERVERSION=5.0.0;FRA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/666:6760,Testability,test,test,6760," _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2183, in make_examples_runner; runtimes) = region_processor.process(region); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1285, in process; sample_reads = self.region_reads_norealign(; File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1376, in region_reads_norealign; reads = itertools.chain(reads, sam_reader.query(region)); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 247, in query; return self._reader.query(region); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 250, in query; return self._reader.query(region); ValueError: FAILED_PRECONDITION: Cannot query without an index; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /media/nils/nils_ssd_01/Genomics_prac_guide/reference/GRCh37/hs37d5.fa --reads /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam/GFX.bam --examples /tmp/tmpwjk24y8t/make_examples.tfrecord@22.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --noparse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --nosort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 1; ; ```; ; **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Quickstart works. This issue also happens when I try to run the pipeline with docker-only.; ; **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/666:6796,Testability,test,test,6796," _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 186, in main; make_examples_core.make_examples_runner(options); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2183, in make_examples_runner; runtimes) = region_processor.process(region); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1285, in process; sample_reads = self.region_reads_norealign(; File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1376, in region_reads_norealign; reads = itertools.chain(reads, sam_reader.query(region)); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 247, in query; return self._reader.query(region); File ""/tmp/Bazel.runfiles_ztv_d7ra/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 250, in query; return self._reader.query(region); ValueError: FAILED_PRECONDITION: Cannot query without an index; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /media/nils/nils_ssd_01/Genomics_prac_guide/reference/GRCh37/hs37d5.fa --reads /media/nils/nils_ssd_01/Calling/HiFI_sequencing/data/bam/GFX.bam --examples /tmp/tmpwjk24y8t/make_examples.tfrecord@22.gz --add_hp_channel --alt_aligned_pileup diff_channels --max_reads_per_partition 600 --min_mapping_quality 1 --noparse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --nosort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 1; ; ```; ; **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Quickstart works. This issue also happens when I try to run the pipeline with docker-only.; ; **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/666
https://github.com/google/deepvariant/issues/667:55,Performance,perform,performing,55,"Hi deepvariant developer,; Is DeepVariant suitable for performing variation detection analysis, particularly **calling SNP and indel information**, using **bam formate** alignment results obtained from **vg software pan-genome analysis** and NGS resequencing data as input files?. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/667
https://github.com/google/deepvariant/issues/667:76,Safety,detect,detection,76,"Hi deepvariant developer,; Is DeepVariant suitable for performing variation detection analysis, particularly **calling SNP and indel information**, using **bam formate** alignment results obtained from **vg software pan-genome analysis** and NGS resequencing data as input files?. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/667
https://github.com/google/deepvariant/issues/668:257,Availability,error,error,257,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). I want to use singularity to install software **DeepVariant**, but it generates an error, is there some suggestion.thanks. **Setup**; - Operating system: linux（Centos）; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: **/projects/liming/Software/mambaforge-pypy3/envs/singularity/bin/singularity pull /projects/liming/Software/deepvariant/deepvariant.sif docker://google/deepvariant:""1.5.0""**; - Error trace: (if applicable); <img width=""953"" alt=""image"" src=""https://github.com/google/deepvariant/assets/26595839/035ed38c-3a15-45e8-8bb3-dc0e0cfc3200"">. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/668
https://github.com/google/deepvariant/issues/668:766,Availability,Error,Error,766,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). I want to use singularity to install software **DeepVariant**, but it generates an error, is there some suggestion.thanks. **Setup**; - Operating system: linux（Centos）; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: **/projects/liming/Software/mambaforge-pypy3/envs/singularity/bin/singularity pull /projects/liming/Software/deepvariant/deepvariant.sif docker://google/deepvariant:""1.5.0""**; - Error trace: (if applicable); <img width=""953"" alt=""image"" src=""https://github.com/google/deepvariant/assets/26595839/035ed38c-3a15-45e8-8bb3-dc0e0cfc3200"">. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/668
https://github.com/google/deepvariant/issues/668:203,Deployability,install,install,203,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). I want to use singularity to install software **DeepVariant**, but it generates an error, is there some suggestion.thanks. **Setup**; - Operating system: linux（Centos）; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: **/projects/liming/Software/mambaforge-pypy3/envs/singularity/bin/singularity pull /projects/liming/Software/deepvariant/deepvariant.sif docker://google/deepvariant:""1.5.0""**; - Error trace: (if applicable); <img width=""953"" alt=""image"" src=""https://github.com/google/deepvariant/assets/26595839/035ed38c-3a15-45e8-8bb3-dc0e0cfc3200"">. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/668
https://github.com/google/deepvariant/issues/668:375,Deployability,Install,Installation,375,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). I want to use singularity to install software **DeepVariant**, but it generates an error, is there some suggestion.thanks. **Setup**; - Operating system: linux（Centos）; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: **/projects/liming/Software/mambaforge-pypy3/envs/singularity/bin/singularity pull /projects/liming/Software/deepvariant/deepvariant.sif docker://google/deepvariant:""1.5.0""**; - Error trace: (if applicable); <img width=""953"" alt=""image"" src=""https://github.com/google/deepvariant/assets/26595839/035ed38c-3a15-45e8-8bb3-dc0e0cfc3200"">. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/668
https://github.com/google/deepvariant/issues/668:947,Testability,test,test,947,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). I want to use singularity to install software **DeepVariant**, but it generates an error, is there some suggestion.thanks. **Setup**; - Operating system: linux（Centos）; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: **/projects/liming/Software/mambaforge-pypy3/envs/singularity/bin/singularity pull /projects/liming/Software/deepvariant/deepvariant.sif docker://google/deepvariant:""1.5.0""**; - Error trace: (if applicable); <img width=""953"" alt=""image"" src=""https://github.com/google/deepvariant/assets/26595839/035ed38c-3a15-45e8-8bb3-dc0e0cfc3200"">. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/668
https://github.com/google/deepvariant/issues/668:983,Testability,test,test,983,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). I want to use singularity to install software **DeepVariant**, but it generates an error, is there some suggestion.thanks. **Setup**; - Operating system: linux（Centos）; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: **/projects/liming/Software/mambaforge-pypy3/envs/singularity/bin/singularity pull /projects/liming/Software/deepvariant/deepvariant.sif docker://google/deepvariant:""1.5.0""**; - Error trace: (if applicable); <img width=""953"" alt=""image"" src=""https://github.com/google/deepvariant/assets/26595839/035ed38c-3a15-45e8-8bb3-dc0e0cfc3200"">. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/668
https://github.com/google/deepvariant/issues/668:120,Usability,clear,clear,120,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). I want to use singularity to install software **DeepVariant**, but it generates an error, is there some suggestion.thanks. **Setup**; - Operating system: linux（Centos）; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.):singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command: **/projects/liming/Software/mambaforge-pypy3/envs/singularity/bin/singularity pull /projects/liming/Software/deepvariant/deepvariant.sif docker://google/deepvariant:""1.5.0""**; - Error trace: (if applicable); <img width=""953"" alt=""image"" src=""https://github.com/google/deepvariant/assets/26595839/035ed38c-3a15-45e8-8bb3-dc0e0cfc3200"">. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/668
https://github.com/google/deepvariant/issues/669:7,Deployability,install,installed,7,"Hi,; I installed deepvariant from conda. However, when I run dv_make_examples.py all jobs fail, and in their log is reported as:. ```; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_v62e2j9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>; from deepvariant import make_examples_core; File ""/tmp/Bazel.runfiles_v62e2j9f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 41, in <module>; from etils import epath; ModuleNotFoundError: No module named 'etils' . ```; Do you have any suggestions?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/669
https://github.com/google/deepvariant/issues/669:109,Testability,log,log,109,"Hi,; I installed deepvariant from conda. However, when I run dv_make_examples.py all jobs fail, and in their log is reported as:. ```; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_v62e2j9f/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>; from deepvariant import make_examples_core; File ""/tmp/Bazel.runfiles_v62e2j9f/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 41, in <module>; from etils import epath; ModuleNotFoundError: No module named 'etils' . ```; Do you have any suggestions?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/669
https://github.com/google/deepvariant/issues/670:9,Availability,down,download,9,"Hello; I download 40 sample in 1kgp, first I use oqfe to BWA; Then I send the CRAM to Deepvariant to call variants.; But recently, I had found a concern problem, these 40 samples execute same pipeline exactly. But the sample name of result vcf, some of it is right, last have a SRR suffix just as the next figure. And I confirm that this is the SRR suffix exactly as downloaded fastq SRR of per sample from 1KGP. And I also confirm that they all have right and same CRAM. I don't find the reason of this circumstances and I don't know there will lead to some error to my analysis?; So if someone give me some explain or advice?; very Thanks!; ![1687788687108](https://github.com/google/deepvariant/assets/63234787/2aea3b53-babd-4874-9351-e2024fbc81df)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/670
https://github.com/google/deepvariant/issues/670:367,Availability,down,downloaded,367,"Hello; I download 40 sample in 1kgp, first I use oqfe to BWA; Then I send the CRAM to Deepvariant to call variants.; But recently, I had found a concern problem, these 40 samples execute same pipeline exactly. But the sample name of result vcf, some of it is right, last have a SRR suffix just as the next figure. And I confirm that this is the SRR suffix exactly as downloaded fastq SRR of per sample from 1KGP. And I also confirm that they all have right and same CRAM. I don't find the reason of this circumstances and I don't know there will lead to some error to my analysis?; So if someone give me some explain or advice?; very Thanks!; ![1687788687108](https://github.com/google/deepvariant/assets/63234787/2aea3b53-babd-4874-9351-e2024fbc81df)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/670
https://github.com/google/deepvariant/issues/670:559,Availability,error,error,559,"Hello; I download 40 sample in 1kgp, first I use oqfe to BWA; Then I send the CRAM to Deepvariant to call variants.; But recently, I had found a concern problem, these 40 samples execute same pipeline exactly. But the sample name of result vcf, some of it is right, last have a SRR suffix just as the next figure. And I confirm that this is the SRR suffix exactly as downloaded fastq SRR of per sample from 1KGP. And I also confirm that they all have right and same CRAM. I don't find the reason of this circumstances and I don't know there will lead to some error to my analysis?; So if someone give me some explain or advice?; very Thanks!; ![1687788687108](https://github.com/google/deepvariant/assets/63234787/2aea3b53-babd-4874-9351-e2024fbc81df)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/670
https://github.com/google/deepvariant/issues/670:192,Deployability,pipeline,pipeline,192,"Hello; I download 40 sample in 1kgp, first I use oqfe to BWA; Then I send the CRAM to Deepvariant to call variants.; But recently, I had found a concern problem, these 40 samples execute same pipeline exactly. But the sample name of result vcf, some of it is right, last have a SRR suffix just as the next figure. And I confirm that this is the SRR suffix exactly as downloaded fastq SRR of per sample from 1KGP. And I also confirm that they all have right and same CRAM. I don't find the reason of this circumstances and I don't know there will lead to some error to my analysis?; So if someone give me some explain or advice?; very Thanks!; ![1687788687108](https://github.com/google/deepvariant/assets/63234787/2aea3b53-babd-4874-9351-e2024fbc81df)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/670
https://github.com/google/deepvariant/issues/672:190,Availability,error,error,190,"hello,; When analyzing PacBio data, I encountered some problems.; I tested the example data provided by DeepConsensus and aligned it using pbmm2(1.12.0). When I analyze with DV1.5, I got an error.; Data: gs://brain-genomics-public/research/deepconsensus/quickstart/v1.2/n1000.subreads.bam; My cmd:; 1. pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@RG\tID:test1\tSM:test1'; 2. /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref hs37d5.fasta \; --reads n1000.subreads_to_ccs_aligned.bam \; --output_vcf n1000.depv.vcf.gz \; --output_gvcf n1000.depv.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir intermediate_results_dir; Error:; ![1688017046760](https://github.com/google/deepvariant/assets/70870741/e5973e9a-c44b-4a12-9179-f4657f63f4bb). Could you help me to solve the problem?; Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:684,Availability,Error,Error,684,"hello,; When analyzing PacBio data, I encountered some problems.; I tested the example data provided by DeepConsensus and aligned it using pbmm2(1.12.0). When I analyze with DV1.5, I got an error.; Data: gs://brain-genomics-public/research/deepconsensus/quickstart/v1.2/n1000.subreads.bam; My cmd:; 1. pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@RG\tID:test1\tSM:test1'; 2. /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref hs37d5.fasta \; --reads n1000.subreads_to_ccs_aligned.bam \; --output_vcf n1000.depv.vcf.gz \; --output_gvcf n1000.depv.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir intermediate_results_dir; Error:; ![1688017046760](https://github.com/google/deepvariant/assets/70870741/e5973e9a-c44b-4a12-9179-f4657f63f4bb). Could you help me to solve the problem?; Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/672:68,Testability,test,tested,68,"hello,; When analyzing PacBio data, I encountered some problems.; I tested the example data provided by DeepConsensus and aligned it using pbmm2(1.12.0). When I analyze with DV1.5, I got an error.; Data: gs://brain-genomics-public/research/deepconsensus/quickstart/v1.2/n1000.subreads.bam; My cmd:; 1. pbmm2 align hs37d5.fasta fa.fofn n1000.subreads_to_ccs_aligned.bam --sort --rg '@RG\tID:test1\tSM:test1'; 2. /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref hs37d5.fasta \; --reads n1000.subreads_to_ccs_aligned.bam \; --output_vcf n1000.depv.vcf.gz \; --output_gvcf n1000.depv.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir intermediate_results_dir; Error:; ![1688017046760](https://github.com/google/deepvariant/assets/70870741/e5973e9a-c44b-4a12-9179-f4657f63f4bb). Could you help me to solve the problem?; Looking forward to your reply. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/672
https://github.com/google/deepvariant/issues/673:83,Availability,error,error,83,"Dear all,. I was trying to run deepvariant from singularity but I encountered this error:. time /opt/deepvariant/bin/call_variants --outfile ""deepvariant/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""deepvariant/interm; ediate_results_dir/make_examples.tfrecord@12.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". /mnt/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this ; version of SciPy (detected version 1.24.2; warnings.warn(f""A NumPy version >={np_minversion} and <{np_maxversion}""; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_nnuiry6u/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 45, in <module>; from deepvariant import modeling; File ""/tmp/Bazel.runfiles_nnuiry6u/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 56, in <module>; from tensorflow.python.tpu import tpu_config ; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_config.py"", line 18, in <module>; from tensorflow_estimator.python.estimator.tpu.tpu_config import *; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/__init__.py"", line 8, in <module>; from tensorflow_estimator._api.v1 import estimator; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py"", line 8, in <module>; from tensorflow_estimator._api.v1.estimator import experimental; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py"", line 8, in <module>; from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder; File ""/mnt.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py"", line 26, in <module>; from tensorflow_estimator.python.estimator import estimator; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 40, in <module>; from tensorflow.python.saved_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:296,Availability,checkpoint,checkpoint,296,"Dear all,. I was trying to run deepvariant from singularity but I encountered this error:. time /opt/deepvariant/bin/call_variants --outfile ""deepvariant/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""deepvariant/interm; ediate_results_dir/make_examples.tfrecord@12.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". /mnt/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this ; version of SciPy (detected version 1.24.2; warnings.warn(f""A NumPy version >={np_minversion} and <{np_maxversion}""; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_nnuiry6u/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 45, in <module>; from deepvariant import modeling; File ""/tmp/Bazel.runfiles_nnuiry6u/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 56, in <module>; from tensorflow.python.tpu import tpu_config ; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_config.py"", line 18, in <module>; from tensorflow_estimator.python.estimator.tpu.tpu_config import *; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/__init__.py"", line 8, in <module>; from tensorflow_estimator._api.v1 import estimator; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py"", line 8, in <module>; from tensorflow_estimator._api.v1.estimator import experimental; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py"", line 8, in <module>; from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder; File ""/mnt.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py"", line 26, in <module>; from tensorflow_estimator.python.estimator import estimator; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 40, in <module>; from tensorflow.python.saved_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:2234,Deployability,install,installed,2234,"; File ""/tmp/Bazel.runfiles_nnuiry6u/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 45, in <module>; from deepvariant import modeling; File ""/tmp/Bazel.runfiles_nnuiry6u/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 56, in <module>; from tensorflow.python.tpu import tpu_config ; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_config.py"", line 18, in <module>; from tensorflow_estimator.python.estimator.tpu.tpu_config import *; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/__init__.py"", line 8, in <module>; from tensorflow_estimator._api.v1 import estimator; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py"", line 8, in <module>; from tensorflow_estimator._api.v1.estimator import experimental; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py"", line 8, in <module>; from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder; File ""/mnt.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py"", line 26, in <module>; from tensorflow_estimator.python.estimator import estimator; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 40, in <module>; from tensorflow.python.saved_model import path_helpers; ImportError: cannot import name 'path_helpers' from 'tensorflow.python.saved_model' (/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_mode; l/__init__.py). Strangely, when I checked the Numpy installed in the conda environment it says 1.22.4.; - Command: singularity exec deepvariant.simg /opt/deepvariant/bin/run_deepvariant --model_type WES --ref ref.fasta --reads aln_sncr_fc.bam --output_vcf deepvariant/deepvariant_calls.vcf --num_shards 12 --intermediate_results_dir deepvariant/intermediate_results_dir . I am running it on a slurm cluster. . Thank you very much!; Best,; CW",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/673:491,Safety,detect,detected,491,"Dear all,. I was trying to run deepvariant from singularity but I encountered this error:. time /opt/deepvariant/bin/call_variants --outfile ""deepvariant/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""deepvariant/interm; ediate_results_dir/make_examples.tfrecord@12.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". /mnt/.local/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this ; version of SciPy (detected version 1.24.2; warnings.warn(f""A NumPy version >={np_minversion} and <{np_maxversion}""; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_nnuiry6u/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 45, in <module>; from deepvariant import modeling; File ""/tmp/Bazel.runfiles_nnuiry6u/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 56, in <module>; from tensorflow.python.tpu import tpu_config ; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_config.py"", line 18, in <module>; from tensorflow_estimator.python.estimator.tpu.tpu_config import *; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/__init__.py"", line 8, in <module>; from tensorflow_estimator._api.v1 import estimator; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/__init__.py"", line 8, in <module>; from tensorflow_estimator._api.v1.estimator import experimental; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/_api/v1/estimator/experimental/__init__.py"", line 8, in <module>; from tensorflow_estimator.python.estimator.canned.dnn import dnn_logit_fn_builder; File ""/mnt.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py"", line 26, in <module>; from tensorflow_estimator.python.estimator import estimator; File ""/mnt/.local/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py"", line 40, in <module>; from tensorflow.python.saved_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/673
https://github.com/google/deepvariant/issues/674:466,Energy Efficiency,allocate,allocate,466,"Hi,. I am running DV on CPU on a fragmented reference 3GB genome with pseudochromosomes + a very large number of small contigs. having these seems to eat up my RAM and I rapidly reach 250 of the 252 GB in use and my system freezes with oom. After adding a line to include only reference contigs larger than 500bps I got the command to work and it now uses only 100GB ram. ``--regions=/inref/${ref}_ge500.bed \``. I therefore edited this ticket (originally trying to allocate a max memory argument) and it this post can be closed and marked solved. best regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/674
https://github.com/google/deepvariant/issues/675:1002,Availability,Error,Error,1002,"Describe the issue:; I can't get vcf output after bind mount a root directory. Setup; - Operating system: Windows 11, but mount an Ubuntu VM through multipass; - Type of data: fasta, bam and vcf file. Steps to reproduce:; - Command:; #Configure the DeepVariant environment variables (missing input directory,...); BIN_VERSION=""1.5.0"". sudo apt -y update; sudo apt-get -y install docker.io; sudo docker pull google/deepvariant:""${BIN_VERSION}"". # Pull the image; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; PWD=/mountpoint/fastQ; INPUT_DIR=""${PWD}/testdata_input""; mkdir -p ${INPUT_DIR}; OUTPUT_DIR=""${PWD}/04.deepvariant_out""; mkdir -p ""${OUTPUT_DIR}"". sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/Homo_sapiens_assembly38.fasta \; --reads=/input/$FQ.align.sort.marked.bam \; --output_vcf=/output/$FQ.vcf.gz \; --output_gvcf=/output/$FQ.g.vcf.gz \; --num_shards=2 ; - Error trace: ; ; It displays: Task reading input the .bam file but it ends up with 0 candidates.; I suppose it can read the input files. Does the quick start test work on your system?; This the tutorial I've used: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:347,Deployability,update,update,347,"Describe the issue:; I can't get vcf output after bind mount a root directory. Setup; - Operating system: Windows 11, but mount an Ubuntu VM through multipass; - Type of data: fasta, bam and vcf file. Steps to reproduce:; - Command:; #Configure the DeepVariant environment variables (missing input directory,...); BIN_VERSION=""1.5.0"". sudo apt -y update; sudo apt-get -y install docker.io; sudo docker pull google/deepvariant:""${BIN_VERSION}"". # Pull the image; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; PWD=/mountpoint/fastQ; INPUT_DIR=""${PWD}/testdata_input""; mkdir -p ${INPUT_DIR}; OUTPUT_DIR=""${PWD}/04.deepvariant_out""; mkdir -p ""${OUTPUT_DIR}"". sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/Homo_sapiens_assembly38.fasta \; --reads=/input/$FQ.align.sort.marked.bam \; --output_vcf=/output/$FQ.vcf.gz \; --output_gvcf=/output/$FQ.g.vcf.gz \; --num_shards=2 ; - Error trace: ; ; It displays: Task reading input the .bam file but it ends up with 0 candidates.; I suppose it can read the input files. Does the quick start test work on your system?; This the tutorial I've used: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:371,Deployability,install,install,371,"Describe the issue:; I can't get vcf output after bind mount a root directory. Setup; - Operating system: Windows 11, but mount an Ubuntu VM through multipass; - Type of data: fasta, bam and vcf file. Steps to reproduce:; - Command:; #Configure the DeepVariant environment variables (missing input directory,...); BIN_VERSION=""1.5.0"". sudo apt -y update; sudo apt-get -y install docker.io; sudo docker pull google/deepvariant:""${BIN_VERSION}"". # Pull the image; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; PWD=/mountpoint/fastQ; INPUT_DIR=""${PWD}/testdata_input""; mkdir -p ${INPUT_DIR}; OUTPUT_DIR=""${PWD}/04.deepvariant_out""; mkdir -p ""${OUTPUT_DIR}"". sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/Homo_sapiens_assembly38.fasta \; --reads=/input/$FQ.align.sort.marked.bam \; --output_vcf=/output/$FQ.vcf.gz \; --output_gvcf=/output/$FQ.g.vcf.gz \; --num_shards=2 ; - Error trace: ; ; It displays: Task reading input the .bam file but it ends up with 0 candidates.; I suppose it can read the input files. Does the quick start test work on your system?; This the tutorial I've used: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:235,Modifiability,Config,Configure,235,"Describe the issue:; I can't get vcf output after bind mount a root directory. Setup; - Operating system: Windows 11, but mount an Ubuntu VM through multipass; - Type of data: fasta, bam and vcf file. Steps to reproduce:; - Command:; #Configure the DeepVariant environment variables (missing input directory,...); BIN_VERSION=""1.5.0"". sudo apt -y update; sudo apt-get -y install docker.io; sudo docker pull google/deepvariant:""${BIN_VERSION}"". # Pull the image; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; PWD=/mountpoint/fastQ; INPUT_DIR=""${PWD}/testdata_input""; mkdir -p ${INPUT_DIR}; OUTPUT_DIR=""${PWD}/04.deepvariant_out""; mkdir -p ""${OUTPUT_DIR}"". sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/Homo_sapiens_assembly38.fasta \; --reads=/input/$FQ.align.sort.marked.bam \; --output_vcf=/output/$FQ.vcf.gz \; --output_gvcf=/output/$FQ.g.vcf.gz \; --num_shards=2 ; - Error trace: ; ; It displays: Task reading input the .bam file but it ends up with 0 candidates.; I suppose it can read the input files. Does the quick start test work on your system?; This the tutorial I've used: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:273,Modifiability,variab,variables,273,"Describe the issue:; I can't get vcf output after bind mount a root directory. Setup; - Operating system: Windows 11, but mount an Ubuntu VM through multipass; - Type of data: fasta, bam and vcf file. Steps to reproduce:; - Command:; #Configure the DeepVariant environment variables (missing input directory,...); BIN_VERSION=""1.5.0"". sudo apt -y update; sudo apt-get -y install docker.io; sudo docker pull google/deepvariant:""${BIN_VERSION}"". # Pull the image; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; PWD=/mountpoint/fastQ; INPUT_DIR=""${PWD}/testdata_input""; mkdir -p ${INPUT_DIR}; OUTPUT_DIR=""${PWD}/04.deepvariant_out""; mkdir -p ""${OUTPUT_DIR}"". sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/Homo_sapiens_assembly38.fasta \; --reads=/input/$FQ.align.sort.marked.bam \; --output_vcf=/output/$FQ.vcf.gz \; --output_gvcf=/output/$FQ.g.vcf.gz \; --num_shards=2 ; - Error trace: ; ; It displays: Task reading input the .bam file but it ends up with 0 candidates.; I suppose it can read the input files. Does the quick start test work on your system?; This the tutorial I've used: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/675:1160,Testability,test,test,1160,"Describe the issue:; I can't get vcf output after bind mount a root directory. Setup; - Operating system: Windows 11, but mount an Ubuntu VM through multipass; - Type of data: fasta, bam and vcf file. Steps to reproduce:; - Command:; #Configure the DeepVariant environment variables (missing input directory,...); BIN_VERSION=""1.5.0"". sudo apt -y update; sudo apt-get -y install docker.io; sudo docker pull google/deepvariant:""${BIN_VERSION}"". # Pull the image; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; PWD=/mountpoint/fastQ; INPUT_DIR=""${PWD}/testdata_input""; mkdir -p ${INPUT_DIR}; OUTPUT_DIR=""${PWD}/04.deepvariant_out""; mkdir -p ""${OUTPUT_DIR}"". sudo docker run \; -v ""${INPUT_DIR}"":""/input"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/input/Homo_sapiens_assembly38.fasta \; --reads=/input/$FQ.align.sort.marked.bam \; --output_vcf=/output/$FQ.vcf.gz \; --output_gvcf=/output/$FQ.g.vcf.gz \; --num_shards=2 ; - Error trace: ; ; It displays: Task reading input the .bam file but it ends up with 0 candidates.; I suppose it can read the input files. Does the quick start test work on your system?; This the tutorial I've used: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-quick-start.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/675
https://github.com/google/deepvariant/issues/676:95,Availability,avail,available,95,**Describe the issue:**; nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04 docker image is no longer available to be used as a base-image. **Setup**; - Operating system: linux; - DeepVariant version: 1.5. **Steps to reproduce:**; - Command: docker pull nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04; - Error trace: Error response from daemon: manifest for nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04 not found: manifest unknown: manifest unknown; ; Do you have a recommendation for an alternative base-image that deepvariant docker could be built with GPU support?; Thanks!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/676:294,Availability,Error,Error,294,**Describe the issue:**; nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04 docker image is no longer available to be used as a base-image. **Setup**; - Operating system: linux; - DeepVariant version: 1.5. **Steps to reproduce:**; - Command: docker pull nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04; - Error trace: Error response from daemon: manifest for nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04 not found: manifest unknown: manifest unknown; ; Do you have a recommendation for an alternative base-image that deepvariant docker could be built with GPU support?; Thanks!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/676:307,Availability,Error,Error,307,**Describe the issue:**; nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04 docker image is no longer available to be used as a base-image. **Setup**; - Operating system: linux; - DeepVariant version: 1.5. **Steps to reproduce:**; - Command: docker pull nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04; - Error trace: Error response from daemon: manifest for nvidia/cuda:11.3.0-cudnn8-devel-ubuntu20.04 not found: manifest unknown: manifest unknown; ; Do you have a recommendation for an alternative base-image that deepvariant docker could be built with GPU support?; Thanks!,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/676
https://github.com/google/deepvariant/issues/677:114,Availability,error,error,114,"**Describe the issue:**; Hello everyone, i am trying to run a Pacbio Workflow with deepvariant in it but i get an error in the make example step ( Rule and log below) i allready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:301,Availability,error,error,301,"**Describe the issue:**; Hello everyone, i am trying to run a Pacbio Workflow with deepvariant in it but i get an error in the make example step ( Rule and log below) i allready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:378,Availability,error,error,378,"**Describe the issue:**; Hello everyone, i am trying to run a Pacbio Workflow with deepvariant in it but i get an error in the make example step ( Rule and log below) i allready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:2409,Availability,Error,Error,2409,"riant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \; --examples {params.examples} \; --gvcf {params.gvcf} \; --task {params.shard}) > {log} 2>&1; """""". ```; Error:. ```; 2023-07-12 15:19:55.926661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De>; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-12 15:19:59.038994: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.6 SO:>; 2023-07-12 15:19:59.039047: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag BC: in RG line, ignoring: @RG ID:d98f52ac>; 2023-07-12 15:19:59.039065: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag CM: in RG line, ignoring: @RG ID:d98f52ac>; I0712 15:19:59.039340 140472429422400 genomics_reader.py:222] Reading batches/Test349/D18757/aligned/D18757.hs37d5.bam with NativeS>; I0712 15:19:59.044630 140472429422400 make_examples_core.py:257] Task 32/96: Preparing inputs; 2023-07-12 15:19:59.049074: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.6 SO:>; 2023-07-12 15:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:552,Deployability,Install,Installation,552,"**Describe the issue:**; Hello everyone, i am trying to run a Pacbio Workflow with deepvariant in it but i get an error in the make example step ( Rule and log below) i allready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1734,Integrability,message,message,1734,"e}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \; --examples {params.examples} \; --gvcf {params.gvcf} \; --task {params.shard}) > {log} 2>&1; """""". ```; Error:. ```; 2023-07-12 15:19:55.926661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De>; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-12 15:19:59.038994: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:870,Modifiability,config,config,870,"**Describe the issue:**; Hello everyone, i am trying to run a Pacbio Workflow with deepvariant in it but i get an error in the make example step ( Rule and log below) i allready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1002,Modifiability,config,config,1002,"Describe the issue:**; Hello everyone, i am trying to run a Pacbio Workflow with deepvariant in it but i get an error in the make example step ( Rule and log below) i allready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=250",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1137,Modifiability,config,config,1137,"llready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1246,Modifiability,config,config,1246," its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode callin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1416,Modifiability,config,config,1416,"ny thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \; --examples {params.examples} \; --gvcf {params.gvcf} \; --task {params.shard}) > {log} 2>&1; """""". ```; Error:. ```; 2023",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1612,Modifiability,config,config,1612,"y; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \; --examples {params.examples} \; --gvcf {params.gvcf} \; --task {params.shard}) > {log} 2>&1; """""". ```; Error:. ```; 2023-07-12 15:19:55.926661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De>; To enable them in other operations, rebuild TensorFlow with t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1708,Modifiability,config,config,1708,"es:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \; --examples {params.examples} \; --gvcf {params.gvcf} \; --task {params.shard}) > {log} 2>&1; """""". ```; Error:. ```; 2023-07-12 15:19:55.926661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De>; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-12 15:19:59.038994: W third_party/nucleus/io/sam_reader.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:2529,Performance,optimiz,optimized,2529,"/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \; --examples {params.examples} \; --gvcf {params.gvcf} \; --task {params.shard}) > {log} 2>&1; """""". ```; Error:. ```; 2023-07-12 15:19:55.926661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De>; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-12 15:19:59.038994: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.6 SO:>; 2023-07-12 15:19:59.039047: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag BC: in RG line, ignoring: @RG ID:d98f52ac>; 2023-07-12 15:19:59.039065: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag CM: in RG line, ignoring: @RG ID:d98f52ac>; I0712 15:19:59.039340 140472429422400 genomics_reader.py:222] Reading batches/Test349/D18757/aligned/D18757.hs37d5.bam with NativeS>; I0712 15:19:59.044630 140472429422400 make_examples_core.py:257] Task 32/96: Preparing inputs; 2023-07-12 15:19:59.049074: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.6 SO:>; 2023-07-12 15:19:59.049123: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag BC: in RG line, ignoring: @RG ID:d98f52ac>; 2023-07-12 15:19:59.049140: W third_party/nucle",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:156,Testability,log,log,156,"**Describe the issue:**; Hello everyone, i am trying to run a Pacbio Workflow with deepvariant in it but i get an error in the make example step ( Rule and log below) i allready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1160,Testability,log,log,1160,"llready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1184,Testability,log,logs,1184,"llready have an open Issue on the Workflow but we are at the Point that we think its ether Nucleus or Tensorflow that produces the error PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1269,Testability,log,log,1269,"or PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1276,Testability,benchmark,benchmark,1276,"or PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:1306,Testability,benchmark,benchmarks,1306,"or PacificBiosciences/HiFiTargetEnrichment#4 , since i cant find what the error is and how to fix it i opend the Issue. Many thanks in advance. **Setup**; - Operating system: Ubuntu 20.04.6 LTS; - DeepVariant version: 1.5.0; - Tensorflow 2.11.0; - Installation method (Docker, built from source, etc.): singularity; - Type of data: PacBio HIFI reads. **Steps to reproduce:**; ```; rule deepvariant_make_examples:; input:; bam=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam"",; bai=f""batches/{batch}/{{sample}}/aligned/{{sample}}.{ref}.bam.bai"",; reference=config[""ref""][""fasta""],; output:; tfrecord=temp(; f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord-{{shard}}-of-{config['N_SHARDS']:05}.gz""; ),; nonvariant_site_tfrecord=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord-{{shard}}-of-{config['N_SHARDS']:0>; log:; f""batches/{batch}/logs/deepvariant/make_examples/{{sample}}.{ref}.{{shard}}-of-{config['N_SHARDS']:05}.log"",; benchmark:; f""batches/{batch}/benchmarks/deepvariant/{{sample}}.{{shard}}.dv_make_examples.tsv""; container:; f""docker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/677:2388,Testability,log,log,2388,"ker://google/deepvariant:{config['DEEPVARIANT_VERSION']}""; params:; vsc_min_fraction_indels=""0.12"",; pileup_image_width=199,; shard='{shard}',; examples=f""batches/{batch}/{{sample}}/deepvariant/examples/examples.tfrecord@{config['N_SHARDS']}.gz"",; gvcf=f""batches/{batch}/{{sample}}/deepvariant/examples/gvcf.tfrecord@{config['N_SHARDS']}.gz"",; message:; ""DeepVariant make_examples {wildcards.shard} for {input.bam}.""; shell:; """"""; sleep 180; (/opt/deepvariant/bin/make_examples \; --add_hp_channel \; --alt_aligned_pileup=diff_channels \; --min_mapping_quality=1 \; --parse_sam_aux_fields \; --partition_size=25000 \; --max_reads_per_partition=600 \; --phase_reads \; --pileup_image_width {params.pileup_image_width} \; --norealign_reads \; --sort_by_haplotypes \; --track_ref_reads \; --vsc_min_fraction_indels {params.vsc_min_fraction_indels} \; --mode calling \; --ref {input.reference} \; --reads {input.bam} \; --examples {params.examples} \; --gvcf {params.gvcf} \; --task {params.shard}) > {log} 2>&1; """""". ```; Error:. ```; 2023-07-12 15:19:55.926661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI De>; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-12 15:19:59.038994: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.6 SO:>; 2023-07-12 15:19:59.039047: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag BC: in RG line, ignoring: @RG ID:d98f52ac>; 2023-07-12 15:19:59.039065: W third_party/nucleus/io/sam_reader.cc:174] Unknown tag CM: in RG line, ignoring: @RG ID:d98f52ac>; I0712 15:19:59.039340 140472429422400 genomics_reader.py:222] Reading batches/Test349/D18757/aligned/D18757.hs37d5.bam with NativeS>; I0712 15:19:59.044630 140472429422400 make_examples_core.py:257] Task 32/96: Preparing inputs; 2023-07-12 15:19:59.049074: W third_party/nucleus/io/sam_reader.cc:131] Unknown tag pb: in header line, ignoring: @HD VN:1.6 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/677
https://github.com/google/deepvariant/issues/678:102,Availability,error,error,102,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. Same error msgs were observed. But I was lunching deepvariant with singularity; **Describe the issue:**; (A clear and concise description of what the issue is.); The same error msgs were observed just like described in FAQ. But this time I was lunching deepvariant and testing dataset with singularity.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable); module load singularity; BIN_VERSION=""1.5.0""; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; LABASE=""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools""; INPUT_DIR=""${LABASE}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${LABASE}/quickstart-output""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:268,Availability,error,error,268,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. Same error msgs were observed. But I was lunching deepvariant with singularity; **Describe the issue:**; (A clear and concise description of what the issue is.); The same error msgs were observed just like described in FAQ. But this time I was lunching deepvariant and testing dataset with singularity.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable); module load singularity; BIN_VERSION=""1.5.0""; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; LABASE=""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools""; INPUT_DIR=""${LABASE}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${LABASE}/quickstart-output""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:664,Availability,Error,Error,664,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. Same error msgs were observed. But I was lunching deepvariant with singularity; **Describe the issue:**; (A clear and concise description of what the issue is.); The same error msgs were observed just like described in FAQ. But this time I was lunching deepvariant and testing dataset with singularity.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable); module load singularity; BIN_VERSION=""1.5.0""; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; LABASE=""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools""; INPUT_DIR=""${LABASE}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${LABASE}/quickstart-output""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:2558,Availability,error,error,2558,"c.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --num_shards=1. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Here is the complete error msg:; #############################################; **Any additional context:**; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; 2023-07-13 21:50:44.574140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [E::hts_open_format] Failed to open file ""/N/project/Walker_lab/P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:459,Deployability,Install,Installation,459,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. Same error msgs were observed. But I was lunching deepvariant with singularity; **Describe the issue:**; (A clear and concise description of what the issue is.); The same error msgs were observed just like described in FAQ. But this time I was lunching deepvariant and testing dataset with singularity.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable); module load singularity; BIN_VERSION=""1.5.0""; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; LABASE=""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools""; INPUT_DIR=""${LABASE}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${LABASE}/quickstart-output""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:2821,Deployability,install,installed,2821,"ittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --num_shards=1. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Here is the complete error msg:; #############################################; **Any additional context:**; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; 2023-07-13 21:50:44.574140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [E::hts_open_format] Failed to open file ""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:3082,Deployability,install,installed,3082,"9.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --num_shards=1. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Here is the complete error msg:; #############################################; **Any additional context:**; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; 2023-07-13 21:50:44.574140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [E::hts_open_format] Failed to open file ""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:701,Performance,load,load,701,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. Same error msgs were observed. But I was lunching deepvariant with singularity; **Describe the issue:**; (A clear and concise description of what the issue is.); The same error msgs were observed just like described in FAQ. But this time I was lunching deepvariant and testing dataset with singularity.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable); module load singularity; BIN_VERSION=""1.5.0""; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; LABASE=""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools""; INPUT_DIR=""${LABASE}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${LABASE}/quickstart-output""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:3275,Performance,optimiz,optimized,3275,"e test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Here is the complete error msg:; #############################################; **Any additional context:**; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; 2023-07-13 21:50:44.574140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [E::hts_open_format] Failed to open file ""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:3375,Performance,perform,performance-critical,3375,"e test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Here is the complete error msg:; #############################################; **Any additional context:**; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; 2023-07-13 21:50:44.574140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [E::hts_open_format] Failed to open file ""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:366,Testability,test,testing,366,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. Same error msgs were observed. But I was lunching deepvariant with singularity; **Describe the issue:**; (A clear and concise description of what the issue is.); The same error msgs were observed just like described in FAQ. But this time I was lunching deepvariant and testing dataset with singularity.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable); module load singularity; BIN_VERSION=""1.5.0""; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; LABASE=""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools""; INPUT_DIR=""${LABASE}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${LABASE}/quickstart-output""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:906,Testability,test,testdata,906,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. Same error msgs were observed. But I was lunching deepvariant with singularity; **Describe the issue:**; (A clear and concise description of what the issue is.); The same error msgs were observed just like described in FAQ. But this time I was lunching deepvariant and testing dataset with singularity.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable); module load singularity; BIN_VERSION=""1.5.0""; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; LABASE=""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools""; INPUT_DIR=""${LABASE}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${LABASE}/quickstart-output""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:986,Testability,test,testdata,986,"github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. Same error msgs were observed. But I was lunching deepvariant with singularity; **Describe the issue:**; (A clear and concise description of what the issue is.); The same error msgs were observed just like described in FAQ. But this time I was lunching deepvariant and testing dataset with singularity.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable); module load singularity; BIN_VERSION=""1.5.0""; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; LABASE=""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools""; INPUT_DIR=""${LABASE}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${LABASE}/quickstart-output""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:2341,Testability,test,test,2341,"_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --num_shards=1. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Here is the complete error msg:; #############################################; **Any additional context:**; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; 2023-07-13 21:50:44.574140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:2377,Testability,test,test,2377,"_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \; --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --num_shards=1. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Here is the complete error msg:; #############################################; **Any additional context:**; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; 2023-07-13 21:50:44.574140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:3625,Testability,test,testdata,3625,"######################################; **Any additional context:**; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; perl: warning: Setting locale failed.; perl: warning: Please check that your locale settings:; LANGUAGE = (unset),; LC_ALL = (unset),; LANG = ""en_US.UTF-8""; are supported and installed on your system.; perl: warning: Falling back to the standard locale (""C"").; 2023-07-13 21:50:44.574140: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; [E::hts_open_format] Failed to open file ""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:5491,Testability,test,testdata,5491,"oject/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" : No such file or directory; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main; options = default_options(add_flags=True, flags_obj=FLAGS); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options; samples_in_order, sample_role_to_train = one_sample_from_flags(; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags; sample_name = make_examples_core.assign_sample_name(; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name; with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:; File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__; self._reader = self._native_reader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader; return NativeSamReader(input_path, **kwargs); File ""/tmp/Bazel.runfiles_u72sdm6v/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__; self._reader = sam_reader.SamReader.from_file(; ValueError: NOT_FOUND: Could not open /N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam; parallel: This job failed:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/678:205,Usability,clear,clear,205,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes. Same error msgs were observed. But I was lunching deepvariant with singularity; **Describe the issue:**; (A clear and concise description of what the issue is.); The same error msgs were observed just like described in FAQ. But this time I was lunching deepvariant and testing dataset with singularity.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable); module load singularity; BIN_VERSION=""1.5.0""; singularity pull docker://google/deepvariant:""${BIN_VERSION}""; LABASE=""/N/project/Walker_lab/PacBio_Revio_WGS/Human_HiFi_0623/tools""; INPUT_DIR=""${LABASE}/quickstart-testdata""; DATA_HTTP_DIR=""https://storage.googleapis.com/deepvariant/quickstart-testdata""; OUTPUT_DIR=""${LABASE}/quickstart-output""; mkdir -p ${INPUT_DIR}; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/NA12878_S1.chr20.10_10p1mb.bam.bai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.bed; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.fai; wget -P ${INPUT_DIR} ""${DATA_HTTP_DIR}""/ucsc.hg19.chr20.unittest.fasta.gz.gzi; ls -1 ${INPUT_DIR}; mkdir -p ${OUTPUT_DIR}; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/678
https://github.com/google/deepvariant/issues/679:95,Availability,error,error,95,"Dear all,. I was trying to run deepvariant from singularity in cluster, but I always meet same error, I don't know hou to fix it:. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp --bind /usr/lib/locale/:/usr/lib/locale/ --bind $ccsbam:$ccsbam --bind $ccsbam.bai:$ccsbam.bai --bind $fasta:$fasta --bind $fasta.fai:$fasta.fai --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20 --intermediate_results_dir=/tmp. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examples.tfrecord@20.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". 2023-07-15 14:06:58.063861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0715 14:07:10.199614 47821886322496 call_variants.py:317] From /tmp/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0715 14:07:10.205330 47821886322496 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1031,Availability,checkpoint,checkpoint,1031,"m singularity in cluster, but I always meet same error, I don't know hou to fix it:. /share/app/singularity/3.8.1/bin/singularity exec --containall --bind /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/tmp:/tmp --bind /usr/lib/locale/:/usr/lib/locale/ --bind $ccsbam:$ccsbam --bind $ccsbam.bai:$ccsbam.bai --bind $fasta:$fasta --bind $fasta.fai:$fasta.fai --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20 --intermediate_results_dir=/tmp. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examples.tfrecord@20.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". 2023-07-15 14:06:58.063861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0715 14:07:10.199614 47821886322496 call_variants.py:317] From /tmp/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0715 14:07:10.205330 47821886322496 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:8178,Availability,error,error,8178,"ges/tensorflow/python/training/monitored_session.py"", line 1464, in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1228, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 968, in run; result = self._run(None, fetches, feed_dict, options_ptr,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1191, in _run; results = self._do_run(handle, final_targets, final_fetches,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1371, in _do_run; return self._do_call(_run_fn, feeds, fetches, targets, options,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1397, in _do_call; raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter; tensorflow.python.framework.errors_impl.DataLossError: Graph execution error:. Detected at node 'IteratorGetNext' defined at (most recent call last):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:8056,Integrability,message,message,8056,"on.py"", line 1397, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1464, in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1228, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 968, in run; result = self._run(None, fetches, feed_dict, options_ptr,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1191, in _run; results = self._do_run(handle, final_targets, final_fetches,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1371, in _do_run; return self._do_call(_run_fn, feeds, fetches, targets, options,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1397, in _do_call; raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter; tensorflow.python.framework.errors_impl.DataLossError: Graph execution error:. Detected at node 'IteratorGetNext' defined at (most recent call last):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = se",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2726,Modifiability,config,config,2726,"f input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-15 14:07:10.223654: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2023-07-15 14:07:10.226851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpl_zjylv7; W0715 14:07:10.308488 47821886322496 estimator.py:1864] Using temporary folder as model directory: /tmp/tmpl_zjylv7; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 10000; I0715 14:07:10.309390 47821886322496 estimator.py:202] Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_c; I0715 14:07:10.309847 47821886322496 call_variants.py:446] Writing calls to /tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0715 14:07:10.758818 47821886322496 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0715 14:07:16.873909 47821886322496 estimator.py:1175] Done calling model_fn.; 2023-07",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2999,Modifiability,config,config,2999,"them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-15 14:07:10.223654: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2023-07-15 14:07:10.226851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpl_zjylv7; W0715 14:07:10.308488 47821886322496 estimator.py:1864] Using temporary folder as model directory: /tmp/tmpl_zjylv7; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 10000; I0715 14:07:10.309390 47821886322496 estimator.py:202] Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_c; I0715 14:07:10.309847 47821886322496 call_variants.py:446] Writing calls to /tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0715 14:07:10.758818 47821886322496 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0715 14:07:16.873909 47821886322496 estimator.py:1175] Done calling model_fn.; 2023-07-15 14:07:17.753203: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; INFO:tensorflow:Graph was finalized.; I0715 14:07:18.197918 47821886322496 monitored_session.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1182,Performance,optimiz,optimized,1182,"sr/lib/locale/ --bind $ccsbam:$ccsbam --bind $ccsbam.bai:$ccsbam.bai --bind $fasta:$fasta --bind $fasta.fai:$fasta.fai --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20 --intermediate_results_dir=/tmp. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examples.tfrecord@20.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". 2023-07-15 14:06:58.063861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0715 14:07:10.199614 47821886322496 call_variants.py:317] From /tmp/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0715 14:07:10.205330 47821886322496 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-15 14:07:10.223654: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread poo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1282,Performance,perform,performance-critical,1282,"sr/lib/locale/ --bind $ccsbam:$ccsbam --bind $ccsbam.bai:$ccsbam.bai --bind $fasta:$fasta --bind $fasta.fai:$fasta.fai --bind /hwfssz5/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/translatome/HCT116/PacBio/analysis/deepvariant.v3/T202302180201:/output /hwfssz1/ST_SUPERCELLS/P21Z10200N0125/zhanghaibo/software/deepvariant/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=$fasta --reads=$ccsbam --output_vcf=/output/T202302180201.deepvariant.vcf.gz --output_gvcf=/output/T202302180201.deepvariant.g.vcf.gz --num_shards=20 --intermediate_results_dir=/tmp. ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examples.tfrecord@20.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". 2023-07-15 14:06:58.063861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0715 14:07:10.199614 47821886322496 call_variants.py:317] From /tmp/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0715 14:07:10.205330 47821886322496 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-15 14:07:10.223654: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread poo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:1949,Performance,optimiz,optimized,1949," ""/opt/models/pacbio/model.ckpt"". 2023-07-15 14:06:58.063861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0715 14:07:10.199614 47821886322496 call_variants.py:317] From /tmp/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0715 14:07:10.205330 47821886322496 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-15 14:07:10.223654: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2023-07-15 14:07:10.226851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpl_zjylv7; W0715 14:07:10.308488 47821886322496 estimator.py:1864] Using temporary folder as model directory: /tmp/tmpl_zjylv7; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 10000; I0715 14:07:10.309390 47821886322496 estimator.py:202] Using config: {'_model_dir': '/tmp/tmpl_zjylv7',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2049,Performance,perform,performance-critical,2049," ""/opt/models/pacbio/model.ckpt"". 2023-07-15 14:06:58.063861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; I0715 14:07:10.199614 47821886322496 call_variants.py:317] From /tmp/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0715 14:07:10.205330 47821886322496 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-15 14:07:10.223654: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2023-07-15 14:07:10.226851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpl_zjylv7; W0715 14:07:10.308488 47821886322496 estimator.py:1864] Using temporary folder as model directory: /tmp/tmpl_zjylv7; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 10000; I0715 14:07:10.309390 47821886322496 estimator.py:202] Using config: {'_model_dir': '/tmp/tmpl_zjylv7',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2310,Performance,Tune,Tune,2310,"ons, rebuild TensorFlow with the appropriate compiler flags.; I0715 14:07:10.199614 47821886322496 call_variants.py:317] From /tmp/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0715 14:07:10.205330 47821886322496 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-15 14:07:10.223654: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2023-07-15 14:07:10.226851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpl_zjylv7; W0715 14:07:10.308488 47821886322496 estimator.py:1864] Using temporary folder as model directory: /tmp/tmpl_zjylv7; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 10000; I0715 14:07:10.309390 47821886322496 estimator.py:202] Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_c; I0715 14:07:10.309847 47821886322496 call_variants.py:446] Writing calls to /tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0715 14:07:10.758",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2359,Performance,perform,performance,2359,"ons, rebuild TensorFlow with the appropriate compiler flags.; I0715 14:07:10.199614 47821886322496 call_variants.py:317] From /tmp/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0715 14:07:10.205330 47821886322496 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-15 14:07:10.223654: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2023-07-15 14:07:10.226851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpl_zjylv7; W0715 14:07:10.308488 47821886322496 estimator.py:1864] Using temporary folder as model directory: /tmp/tmpl_zjylv7; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 10000; I0715 14:07:10.309390 47821886322496 estimator.py:202] Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_c; I0715 14:07:10.309847 47821886322496 call_variants.py:446] Writing calls to /tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0715 14:07:10.758",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:2473,Performance,optimiz,optimization,2473,": Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; I0715 14:07:10.205330 47821886322496 call_variants.py:317] From /opt/models/pacbio/model.ckpt.example_info.json: Shape of input examples: [100, 199, 9], Channels of input examples: [1, 2, 3, 4, 5, 6, 7, 9, 10].; 2023-07-15 14:07:10.211204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical oper; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; 2023-07-15 14:07:10.223654: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; 2023-07-15 14:07:10.226851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled; WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpl_zjylv7; W0715 14:07:10.308488 47821886322496 estimator.py:1864] Using temporary folder as model directory: /tmp/tmpl_zjylv7; INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 10000; I0715 14:07:10.309390 47821886322496 estimator.py:202] Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_c; I0715 14:07:10.309847 47821886322496 call_variants.py:446] Writing calls to /tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0715 14:07:10.758818 47821886322496 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3928,Performance,Tune,Tune,3928,"0 47821886322496 estimator.py:202] Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_c; I0715 14:07:10.309847 47821886322496 call_variants.py:446] Writing calls to /tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0715 14:07:10.758818 47821886322496 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0715 14:07:16.873909 47821886322496 estimator.py:1175] Done calling model_fn.; 2023-07-15 14:07:17.753203: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; INFO:tensorflow:Graph was finalized.; I0715 14:07:18.197918 47821886322496 monitored_session.py:240] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/pacbio/model.ckpt; I0715 14:07:18.198770 47821886322496 saver.py:1410] Restoring parameters from /opt/models/pacbio/model.ckpt; INFO:tensorflow:Running local_init_op.; I0715 14:07:20.793029 47821886322496 session_manager.py:526] Running local_init_op.; INFO:tensorflow:Done running local_init_op.; I0715 14:07:20.857252 47821886322496 session_manager.py:529] Done running local_init_op.; INFO:tensorflow:Reloading EMA...; I0715 14:07:21.417166 47821886322496 modeling.py:418] Reloading EMA...; INFO:tensorflow:Restoring parameters from /opt/models/pacbio/model.ckpt; I0715 14:07:21.417759 47821886322496 saver.py:1410] Restoring parameters from /opt/models/pacbio/model.ckpt; I0715 14:07:25.965068 47821886322496 call_variants.py:462] Processed 1 examples in 1 batches [1565.044 sec per 100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:3977,Performance,perform,performance,3977,"0 47821886322496 estimator.py:202] Using config: {'_model_dir': '/tmp/tmpl_zjylv7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_c; I0715 14:07:10.309847 47821886322496 call_variants.py:446] Writing calls to /tmp/call_variants_output.tfrecord.gz; INFO:tensorflow:Calling model_fn.; I0715 14:07:10.758818 47821886322496 estimator.py:1173] Calling model_fn.; /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.; warnings.warn('`layer.apply` is deprecated and '; INFO:tensorflow:Done calling model_fn.; I0715 14:07:16.873909 47821886322496 estimator.py:1175] Done calling model_fn.; 2023-07-15 14:07:17.753203: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.; INFO:tensorflow:Graph was finalized.; I0715 14:07:18.197918 47821886322496 monitored_session.py:240] Graph was finalized.; INFO:tensorflow:Restoring parameters from /opt/models/pacbio/model.ckpt; I0715 14:07:18.198770 47821886322496 saver.py:1410] Restoring parameters from /opt/models/pacbio/model.ckpt; INFO:tensorflow:Running local_init_op.; I0715 14:07:20.793029 47821886322496 session_manager.py:526] Running local_init_op.; INFO:tensorflow:Done running local_init_op.; I0715 14:07:20.857252 47821886322496 session_manager.py:529] Done running local_init_op.; INFO:tensorflow:Reloading EMA...; I0715 14:07:21.417166 47821886322496 modeling.py:418] Reloading EMA...; INFO:tensorflow:Restoring parameters from /opt/models/pacbio/model.ckpt; I0715 14:07:21.417759 47821886322496 saver.py:1410] Restoring parameters from /opt/models/pacbio/model.ckpt; I0715 14:07:25.965068 47821886322496 call_variants.py:462] Processed 1 examples in 1 batches [1565.044 sec per 100",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6499,Safety,predict,prediction,6499,"k.errors_impl.DataLossError: corrupted record at 484865306; [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict; preds_evaluated = mon_sess.run(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 778, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1307, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1397, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1464, in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1228, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6517,Safety,predict,predictions,6517,"k.errors_impl.DataLossError: corrupted record at 484865306; [[{{node IteratorGetNext}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict; preds_evaluated = mon_sess.run(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 778, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1307, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1397, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1464, in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1228, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6642,Safety,predict,predict,6642,"exception occurred:. Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict; preds_evaluated = mon_sess.run(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 778, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1307, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1397, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1464, in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1228, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 968, in run; result = self._run(None, fetches, feed_dict, options_ptr,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/cli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:6682,Safety,predict,predictions,6682,"ast):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 642, in predict; preds_evaluated = mon_sess.run(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 778, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1307, in run; return self._sess.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1397, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1464, in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1228, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 968, in run; result = self._run(None, fetches, feed_dict, options_ptr,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1191, in _run; results = self",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:8186,Safety,Detect,Detected,8186," in run; outputs = _WrappedSession.run(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1228, in run; return self._sess.run(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 968, in run; result = self._run(None, fetches, feed_dict, options_ptr,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1191, in _run; results = self._do_run(handle, final_targets, final_fetches,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1371, in _do_run; return self._do_call(_run_fn, feeds, fetches, targets, options,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1397, in _do_call; raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter; tensorflow.python.framework.errors_impl.DataLossError: Graph execution error:. Detected at node 'IteratorGetNext' defined at (most recent call last):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:8881,Safety,predict,prediction,8881,"tches, targets, options,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1397, in _do_call; raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter; tensorflow.python.framework.errors_impl.DataLossError: Graph execution error:. Detected at node 'IteratorGetNext' defined at (most recent call last):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); Node: 'IteratorGetNext'; corrupted record at 484865306; [[{{node IteratorGetNext}}]]. Original stack trace for 'IteratorGetNext':; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_und",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:8899,Safety,predict,predictions,8899,"tches, targets, options,; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1397, in _do_call; raise type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter; tensorflow.python.framework.errors_impl.DataLossError: Graph execution error:. Detected at node 'IteratorGetNext' defined at (most recent call last):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); Node: 'IteratorGetNext'; corrupted record at 484865306; [[{{node IteratorGetNext}}]]. Original stack trace for 'IteratorGetNext':; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_und",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:9024,Safety,predict,predict,9024,"type(e)(node_def, op, message) # pylint: disable=no-value-for-parameter; tensorflow.python.framework.errors_impl.DataLossError: Graph execution error:. Detected at node 'IteratorGetNext' defined at (most recent call last):; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); Node: 'IteratorGetNext'; corrupted record at 484865306; [[{{node IteratorGetNext}}]]. Original stack trace for 'IteratorGetNext':; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:10378,Safety,predict,prediction,10378,"ine 60, in parse_input_fn_result; result = iterator.get_next(); Node: 'IteratorGetNext'; corrupted record at 484865306; [[{{node IteratorGetNext}}]]. Original stack trace for 'IteratorGetNext':; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 445, in get_next; flat_ret = gen_dataset_ops.iterator_get_next(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 3037, in iterator_get_next; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 795",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:10396,Safety,predict,predictions,10396,"ine 60, in parse_input_fn_result; result = iterator.get_next(); Node: 'IteratorGetNext'; corrupted record at 484865306; [[{{node IteratorGetNext}}]]. Original stack trace for 'IteratorGetNext':; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 445, in get_next; flat_ret = gen_dataset_ops.iterator_get_next(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 3037, in iterator_get_next; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 795",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/679:10521,Safety,predict,predict,10521,"tNext}}]]. Original stack trace for 'IteratorGetNext':; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 513, in <module>; tf.compat.v1.app.run(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run; _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 494, in main; call_variants(; File ""/tmp/Bazel.runfiles_y5t4ngn_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 453, in call_variants; prediction = next(predictions); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 621, in predict; features, input_hooks = self._get_features_from_input_fn(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1019, in _get_features_from_input_fn; result, _, hooks = estimator_util.parse_input_fn_result(result); File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/util.py"", line 60, in parse_input_fn_result; result = iterator.get_next(); File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 445, in get_next; flat_ret = gen_dataset_ops.iterator_get_next(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 3037, in iterator_get_next; _, _, _op, _outputs = _op_def_library._apply_op_helper(; File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 795, in _apply_op_helper; op = g._create_op_internal(op_type_name, inputs, dtypes=None,; File ""/usr/local/lib/python3.8/dist-packages/tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/679
https://github.com/google/deepvariant/issues/682:141,Safety,detect,detect,141,"Hello. I am working on a clonal organism but we believe more and more it might not be so clonal. We have HiFi data and I want to use them to detect MAF. Is it possible with DeepVariant to detect that? Do you think the models are capable of that? I have asked the question over there to Clair3 people, they said the model was not conceived with this in mind so it might or might not work. Your opinion? . Thank you. Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/682:188,Safety,detect,detect,188,"Hello. I am working on a clonal organism but we believe more and more it might not be so clonal. We have HiFi data and I want to use them to detect MAF. Is it possible with DeepVariant to detect that? Do you think the models are capable of that? I have asked the question over there to Clair3 people, they said the model was not conceived with this in mind so it might or might not work. Your opinion? . Thank you. Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/682
https://github.com/google/deepvariant/issues/683:1465,Availability,Error,Error,1465,"urce, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Operating system:; Redhat enterprise v7.9, x86_64; **Steps to reproduce:**; - Command:; BIN_VERSION=""1.5.0""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/HG38.fa \; --reads=""${INPUT_DIR}""/0661-349-4156123_PDX_m15.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --num_shards=4 \; --intermediate_results_dir=""${OUTPUT_DIR}""/tmp_dir \; --make_examples_extra_args=""vsc_min_fraction_snps=0.2,vsc_min_fraction_indels=0.2""; I allocated 4 cores and 70GBs to run that program.; I added the VAF thresholds for SNPs and Indels because I read the reported issues:; https://github.com/google/deepvariant/issues/578; - Error trace: (if applicable); And here are some most recent results I got from stdout:; I0720 09:27:03.965433 47167827691328 make_examples_core.py:257] 7300984 candidates (8293381 examples) [14.77s elapsed]; I0720 09:27:18.676311 47167827691328 make_examples_core.py:257] 7302320 candidates (8294814 examples) [14.71s elapsed]; I0720 09:28:15.982849 47167827691328 make_examples_core.py:257] 7304006 candidates (8296543 examples) [57.31s elapsed]; I0720 09:30:09.747373 47167827691328 make_examples_core.py:257] 7306537 candidates (8299251 examples) [113.76s elapsed]; I0720 09:30:47.913182 47167827691328 make_examples_core.py:257] 7309312 candidates (8302162 examples) [38.17s elapsed]; I0720 09:30:54.306647 47167827691328 make_examples_core.py:257] 7310398 candidates (8303278 examples) [6.39s elapsed]; I0720 09:31:09.601874 47167827691328 make_examples_core.py:257] 7312009 candidates (8304925 examples) [15.30s elapsed]; I0720 09:31:26.455226 47167827691328 make_examples_core.py:257] 7314037 candidates (8306995 examples) [16",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:456,Deployability,Install,Installation,456,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes.; **Describe the issue:**; (A clear and concise description of what the issue is.); I have several human samples of PacBio HIFI reads with on average 20X depth. I was trying to call out small variants using deepvariant. However, it's been three days and the program is still at 'make_examples' stage.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Operating system:; Redhat enterprise v7.9, x86_64; **Steps to reproduce:**; - Command:; BIN_VERSION=""1.5.0""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/HG38.fa \; --reads=""${INPUT_DIR}""/0661-349-4156123_PDX_m15.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --num_shards=4 \; --intermediate_results_dir=""${OUTPUT_DIR}""/tmp_dir \; --make_examples_extra_args=""vsc_min_fraction_snps=0.2,vsc_min_fraction_indels=0.2""; I allocated 4 cores and 70GBs to run that program.; I added the VAF thresholds for SNPs and Indels because I read the reported issues:; https://github.com/google/deepvariant/issues/578; - Error trace: (if applicable); And here are some most recent results I got from stdout:; I0720 09:27:03.965433 47167827691328 make_examples_core.py:257] 7300984 candidates (8293381 examples) [14.77s elapsed]; I0720 09:27:18.676311 47167827691328 make_examples_core.py:257] 7302320 candidates (8294814 examples) [14.71s elapsed]; I0720 09:28:15.982849 47167827691328 make_examples_core.py:257] 7304006 candidates (8296543 examples) [57.31s elapsed]; I0720 09:30:09.747373 47167827691328 make_examples_core.py:257] 7306537 candidates (8299",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:1279,Energy Efficiency,allocate,allocated,1279,"ng deepvariant. However, it's been three days and the program is still at 'make_examples' stage.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Operating system:; Redhat enterprise v7.9, x86_64; **Steps to reproduce:**; - Command:; BIN_VERSION=""1.5.0""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/HG38.fa \; --reads=""${INPUT_DIR}""/0661-349-4156123_PDX_m15.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --num_shards=4 \; --intermediate_results_dir=""${OUTPUT_DIR}""/tmp_dir \; --make_examples_extra_args=""vsc_min_fraction_snps=0.2,vsc_min_fraction_indels=0.2""; I allocated 4 cores and 70GBs to run that program.; I added the VAF thresholds for SNPs and Indels because I read the reported issues:; https://github.com/google/deepvariant/issues/578; - Error trace: (if applicable); And here are some most recent results I got from stdout:; I0720 09:27:03.965433 47167827691328 make_examples_core.py:257] 7300984 candidates (8293381 examples) [14.77s elapsed]; I0720 09:27:18.676311 47167827691328 make_examples_core.py:257] 7302320 candidates (8294814 examples) [14.71s elapsed]; I0720 09:28:15.982849 47167827691328 make_examples_core.py:257] 7304006 candidates (8296543 examples) [57.31s elapsed]; I0720 09:30:09.747373 47167827691328 make_examples_core.py:257] 7306537 candidates (8299251 examples) [113.76s elapsed]; I0720 09:30:47.913182 47167827691328 make_examples_core.py:257] 7309312 candidates (8302162 examples) [38.17s elapsed]; I0720 09:30:54.306647 47167827691328 make_examples_core.py:257] 7310398 candidates (8303278 examples) [6.39s elapsed]; I0720 09:31:09.601874 47167",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:5124,Energy Efficiency,allocate,allocate,5124,9:34:11.184109 47167827691328 make_examples_core.py:257] 7332195 candidates (8325720 examples) [13.01s elapsed]; I0720 09:34:37.427601 47167827691328 make_examples_core.py:257] 7334598 candidates (8328193 examples) [26.24s elapsed]; I0720 09:34:53.436255 47167827691328 make_examples_core.py:257] 7336041 candidates (8329660 examples) [16.01s elapsed]; I0720 09:35:18.419953 47167827691328 make_examples_core.py:257] 7338676 candidates (8332321 examples) [24.98s elapsed]; I0720 09:35:32.331245 47167827691328 make_examples_core.py:257] 7340143 candidates (8333833 examples) [13.91s elapsed]; I0720 09:35:48.913797 47167827691328 make_examples_core.py:257] 7342460 candidates (8336192 examples) [16.58s elapsed]; I0720 09:36:05.716144 47167827691328 make_examples_core.py:257] 7344261 candidates (8338017 examples) [16.80s elapsed]; I0720 09:36:24.168858 47167827691328 make_examples_core.py:257] 7347004 candidates (8340828 examples) [18.45s elapsed]; I0720 09:36:42.921647 47167827691328 make_examples_core.py:257] 7349633 candidates (8343603 examples) [18.75s elapsed]; I0720 09:36:47.287455 47167827691328 make_examples_core.py:257] 7350149 candidates (8344123 examples) [4.37s elapsed]; I0720 09:37:06.694804 47167827691328 make_examples_core.py:257] 7352217 candidates (8346237 examples) [19.41s elapsed]; I0720 09:37:27.305462 47167827691328 make_examples_core.py:257] 7354095 candidates (8348169 examples) [20.61s elapsed]; I0720 09:37:48.644136 47167827691328 make_examples_core.py:257] 7356001 candidates (8350103 examples) [21.34s elapsed]. My question is: ; Is the long running time due to the complexity of my samples? Do I need to allocate more threads to speed up this process? As I recall make_examples is a single-thread program. . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Yes; **Any additional context:**,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:5251,Testability,test,test,5251,9:34:11.184109 47167827691328 make_examples_core.py:257] 7332195 candidates (8325720 examples) [13.01s elapsed]; I0720 09:34:37.427601 47167827691328 make_examples_core.py:257] 7334598 candidates (8328193 examples) [26.24s elapsed]; I0720 09:34:53.436255 47167827691328 make_examples_core.py:257] 7336041 candidates (8329660 examples) [16.01s elapsed]; I0720 09:35:18.419953 47167827691328 make_examples_core.py:257] 7338676 candidates (8332321 examples) [24.98s elapsed]; I0720 09:35:32.331245 47167827691328 make_examples_core.py:257] 7340143 candidates (8333833 examples) [13.91s elapsed]; I0720 09:35:48.913797 47167827691328 make_examples_core.py:257] 7342460 candidates (8336192 examples) [16.58s elapsed]; I0720 09:36:05.716144 47167827691328 make_examples_core.py:257] 7344261 candidates (8338017 examples) [16.80s elapsed]; I0720 09:36:24.168858 47167827691328 make_examples_core.py:257] 7347004 candidates (8340828 examples) [18.45s elapsed]; I0720 09:36:42.921647 47167827691328 make_examples_core.py:257] 7349633 candidates (8343603 examples) [18.75s elapsed]; I0720 09:36:47.287455 47167827691328 make_examples_core.py:257] 7350149 candidates (8344123 examples) [4.37s elapsed]; I0720 09:37:06.694804 47167827691328 make_examples_core.py:257] 7352217 candidates (8346237 examples) [19.41s elapsed]; I0720 09:37:27.305462 47167827691328 make_examples_core.py:257] 7354095 candidates (8348169 examples) [20.61s elapsed]; I0720 09:37:48.644136 47167827691328 make_examples_core.py:257] 7356001 candidates (8350103 examples) [21.34s elapsed]. My question is: ; Is the long running time due to the complexity of my samples? Do I need to allocate more threads to speed up this process? As I recall make_examples is a single-thread program. . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Yes; **Any additional context:**,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:5287,Testability,test,test,5287,9:34:11.184109 47167827691328 make_examples_core.py:257] 7332195 candidates (8325720 examples) [13.01s elapsed]; I0720 09:34:37.427601 47167827691328 make_examples_core.py:257] 7334598 candidates (8328193 examples) [26.24s elapsed]; I0720 09:34:53.436255 47167827691328 make_examples_core.py:257] 7336041 candidates (8329660 examples) [16.01s elapsed]; I0720 09:35:18.419953 47167827691328 make_examples_core.py:257] 7338676 candidates (8332321 examples) [24.98s elapsed]; I0720 09:35:32.331245 47167827691328 make_examples_core.py:257] 7340143 candidates (8333833 examples) [13.91s elapsed]; I0720 09:35:48.913797 47167827691328 make_examples_core.py:257] 7342460 candidates (8336192 examples) [16.58s elapsed]; I0720 09:36:05.716144 47167827691328 make_examples_core.py:257] 7344261 candidates (8338017 examples) [16.80s elapsed]; I0720 09:36:24.168858 47167827691328 make_examples_core.py:257] 7347004 candidates (8340828 examples) [18.45s elapsed]; I0720 09:36:42.921647 47167827691328 make_examples_core.py:257] 7349633 candidates (8343603 examples) [18.75s elapsed]; I0720 09:36:47.287455 47167827691328 make_examples_core.py:257] 7350149 candidates (8344123 examples) [4.37s elapsed]; I0720 09:37:06.694804 47167827691328 make_examples_core.py:257] 7352217 candidates (8346237 examples) [19.41s elapsed]; I0720 09:37:27.305462 47167827691328 make_examples_core.py:257] 7354095 candidates (8348169 examples) [20.61s elapsed]; I0720 09:37:48.644136 47167827691328 make_examples_core.py:257] 7356001 candidates (8350103 examples) [21.34s elapsed]. My question is: ; Is the long running time due to the complexity of my samples? Do I need to allocate more threads to speed up this process? As I recall make_examples is a single-thread program. . **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Yes; **Any additional context:**,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/683:126,Usability,clear,clear,126,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; Yes.; **Describe the issue:**; (A clear and concise description of what the issue is.); I have several human samples of PacBio HIFI reads with on average 20X depth. I was trying to call out small variants using deepvariant. However, it's been three days and the program is still at 'make_examples' stage.; **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Operating system:; Redhat enterprise v7.9, x86_64; **Steps to reproduce:**; - Command:; BIN_VERSION=""1.5.0""; singularity run -B /usr/lib/locale/:/usr/lib/locale/ --bind ${INPUT_DIR} --bind ${OUTPUT_DIR} \; docker://google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=PACBIO \; --ref=""${INPUT_DIR}""/HG38.fa \; --reads=""${INPUT_DIR}""/0661-349-4156123_PDX_m15.bam \; --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \; --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \; --num_shards=4 \; --intermediate_results_dir=""${OUTPUT_DIR}""/tmp_dir \; --make_examples_extra_args=""vsc_min_fraction_snps=0.2,vsc_min_fraction_indels=0.2""; I allocated 4 cores and 70GBs to run that program.; I added the VAF thresholds for SNPs and Indels because I read the reported issues:; https://github.com/google/deepvariant/issues/578; - Error trace: (if applicable); And here are some most recent results I got from stdout:; I0720 09:27:03.965433 47167827691328 make_examples_core.py:257] 7300984 candidates (8293381 examples) [14.77s elapsed]; I0720 09:27:18.676311 47167827691328 make_examples_core.py:257] 7302320 candidates (8294814 examples) [14.71s elapsed]; I0720 09:28:15.982849 47167827691328 make_examples_core.py:257] 7304006 candidates (8296543 examples) [57.31s elapsed]; I0720 09:30:09.747373 47167827691328 make_examples_core.py:257] 7306537 candidates (8299",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/683
https://github.com/google/deepvariant/issues/685:120,Availability,avail,avail,120,"Hello, . I am very sorry because this seems like a kind of s*** I could figure out but I have spent the afternoon to no avail. So, the following command WORKS in dry run mode, no error, but fails when in real operative mode. . ```; #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}""; INPUT_DIR=""${PWD}"". BIN_VERSION=""1.5.0"". OUTPUT_VCF=vaga_lab_hifi_standing_variation.vcf.gz; OUTPUT_GVCF=vaga_lab_hifi_standing_variation.vcf.gz; BAM=HiFi_vaga.sorted.bam. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref=/input/Adineta_vaga.fsa --make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12 --reads=/input/BAM --output_vcf=/output/OUTPUT_VCF --output_gvcf=/output/OUTPUT_GVCF --num_shards=$(nproc) --logging_dir=/output/logs) 2>&1 | tee -a generallog.log; ```; and the output tells me . ```; ValueError: NOT_FOUND: Could not open /input/BAM; [E::hts_open_format] Failed to open file ""/input/BAM"" : No such file or directory; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/Adineta_vaga.fsa --reads /input/BAM --examples /tmp/tmpbkwxdhbf/make_examples.tfrecord@48.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmpbkwxdhbf/gvcf.tfrecord@48.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_count_snps 2 --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.12 --task 15. ```; the bam file is there, 100% sure, at least to my eyes. But it seems docker fails to see it. Any idea? I have the full log available if needed. Again, I am sorry because it looks like some easy stuff, but my colleague and I can't find it. . Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:179,Availability,error,error,179,"Hello, . I am very sorry because this seems like a kind of s*** I could figure out but I have spent the afternoon to no avail. So, the following command WORKS in dry run mode, no error, but fails when in real operative mode. . ```; #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}""; INPUT_DIR=""${PWD}"". BIN_VERSION=""1.5.0"". OUTPUT_VCF=vaga_lab_hifi_standing_variation.vcf.gz; OUTPUT_GVCF=vaga_lab_hifi_standing_variation.vcf.gz; BAM=HiFi_vaga.sorted.bam. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref=/input/Adineta_vaga.fsa --make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12 --reads=/input/BAM --output_vcf=/output/OUTPUT_VCF --output_gvcf=/output/OUTPUT_GVCF --num_shards=$(nproc) --logging_dir=/output/logs) 2>&1 | tee -a generallog.log; ```; and the output tells me . ```; ValueError: NOT_FOUND: Could not open /input/BAM; [E::hts_open_format] Failed to open file ""/input/BAM"" : No such file or directory; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/Adineta_vaga.fsa --reads /input/BAM --examples /tmp/tmpbkwxdhbf/make_examples.tfrecord@48.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmpbkwxdhbf/gvcf.tfrecord@48.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_count_snps 2 --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.12 --task 15. ```; the bam file is there, 100% sure, at least to my eyes. But it seems docker fails to see it. Any idea? I have the full log available if needed. Again, I am sorry because it looks like some easy stuff, but my colleague and I can't find it. . Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:1741,Availability,avail,available,1741,"Hello, . I am very sorry because this seems like a kind of s*** I could figure out but I have spent the afternoon to no avail. So, the following command WORKS in dry run mode, no error, but fails when in real operative mode. . ```; #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}""; INPUT_DIR=""${PWD}"". BIN_VERSION=""1.5.0"". OUTPUT_VCF=vaga_lab_hifi_standing_variation.vcf.gz; OUTPUT_GVCF=vaga_lab_hifi_standing_variation.vcf.gz; BAM=HiFi_vaga.sorted.bam. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref=/input/Adineta_vaga.fsa --make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12 --reads=/input/BAM --output_vcf=/output/OUTPUT_VCF --output_gvcf=/output/OUTPUT_GVCF --num_shards=$(nproc) --logging_dir=/output/logs) 2>&1 | tee -a generallog.log; ```; and the output tells me . ```; ValueError: NOT_FOUND: Could not open /input/BAM; [E::hts_open_format] Failed to open file ""/input/BAM"" : No such file or directory; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/Adineta_vaga.fsa --reads /input/BAM --examples /tmp/tmpbkwxdhbf/make_examples.tfrecord@48.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmpbkwxdhbf/gvcf.tfrecord@48.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_count_snps 2 --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.12 --task 15. ```; the bam file is there, 100% sure, at least to my eyes. But it seems docker fails to see it. Any idea? I have the full log available if needed. Again, I am sorry because it looks like some easy stuff, but my colleague and I can't find it. . Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:839,Testability,log,logs,839,"Hello, . I am very sorry because this seems like a kind of s*** I could figure out but I have spent the afternoon to no avail. So, the following command WORKS in dry run mode, no error, but fails when in real operative mode. . ```; #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}""; INPUT_DIR=""${PWD}"". BIN_VERSION=""1.5.0"". OUTPUT_VCF=vaga_lab_hifi_standing_variation.vcf.gz; OUTPUT_GVCF=vaga_lab_hifi_standing_variation.vcf.gz; BAM=HiFi_vaga.sorted.bam. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref=/input/Adineta_vaga.fsa --make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12 --reads=/input/BAM --output_vcf=/output/OUTPUT_VCF --output_gvcf=/output/OUTPUT_GVCF --num_shards=$(nproc) --logging_dir=/output/logs) 2>&1 | tee -a generallog.log; ```; and the output tells me . ```; ValueError: NOT_FOUND: Could not open /input/BAM; [E::hts_open_format] Failed to open file ""/input/BAM"" : No such file or directory; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/Adineta_vaga.fsa --reads /input/BAM --examples /tmp/tmpbkwxdhbf/make_examples.tfrecord@48.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmpbkwxdhbf/gvcf.tfrecord@48.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_count_snps 2 --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.12 --task 15. ```; the bam file is there, 100% sure, at least to my eyes. But it seems docker fails to see it. Any idea? I have the full log available if needed. Again, I am sorry because it looks like some easy stuff, but my colleague and I can't find it. . Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:870,Testability,log,log,870,"Hello, . I am very sorry because this seems like a kind of s*** I could figure out but I have spent the afternoon to no avail. So, the following command WORKS in dry run mode, no error, but fails when in real operative mode. . ```; #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}""; INPUT_DIR=""${PWD}"". BIN_VERSION=""1.5.0"". OUTPUT_VCF=vaga_lab_hifi_standing_variation.vcf.gz; OUTPUT_GVCF=vaga_lab_hifi_standing_variation.vcf.gz; BAM=HiFi_vaga.sorted.bam. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref=/input/Adineta_vaga.fsa --make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12 --reads=/input/BAM --output_vcf=/output/OUTPUT_VCF --output_gvcf=/output/OUTPUT_GVCF --num_shards=$(nproc) --logging_dir=/output/logs) 2>&1 | tee -a generallog.log; ```; and the output tells me . ```; ValueError: NOT_FOUND: Could not open /input/BAM; [E::hts_open_format] Failed to open file ""/input/BAM"" : No such file or directory; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/Adineta_vaga.fsa --reads /input/BAM --examples /tmp/tmpbkwxdhbf/make_examples.tfrecord@48.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmpbkwxdhbf/gvcf.tfrecord@48.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_count_snps 2 --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.12 --task 15. ```; the bam file is there, 100% sure, at least to my eyes. But it seems docker fails to see it. Any idea? I have the full log available if needed. Again, I am sorry because it looks like some easy stuff, but my colleague and I can't find it. . Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/685:1737,Testability,log,log,1737,"Hello, . I am very sorry because this seems like a kind of s*** I could figure out but I have spent the afternoon to no avail. So, the following command WORKS in dry run mode, no error, but fails when in real operative mode. . ```; #!/usr/bin/zsh. OUTPUT_DIR=""${PWD}""; INPUT_DIR=""${PWD}"". BIN_VERSION=""1.5.0"". OUTPUT_VCF=vaga_lab_hifi_standing_variation.vcf.gz; OUTPUT_GVCF=vaga_lab_hifi_standing_variation.vcf.gz; BAM=HiFi_vaga.sorted.bam. time (docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type PACBIO --ref=/input/Adineta_vaga.fsa --make_examples_extra_args=vsc_min_count_snps=2,vsc_min_fraction_snps=0.12 --reads=/input/BAM --output_vcf=/output/OUTPUT_VCF --output_gvcf=/output/OUTPUT_GVCF --num_shards=$(nproc) --logging_dir=/output/logs) 2>&1 | tee -a generallog.log; ```; and the output tells me . ```; ValueError: NOT_FOUND: Could not open /input/BAM; [E::hts_open_format] Failed to open file ""/input/BAM"" : No such file or directory; parallel: This job failed:; /opt/deepvariant/bin/make_examples --mode calling --ref /input/Adineta_vaga.fsa --reads /input/BAM --examples /tmp/tmpbkwxdhbf/make_examples.tfrecord@48.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmpbkwxdhbf/gvcf.tfrecord@48.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_count_snps 2 --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.12 --task 15. ```; the bam file is there, 100% sure, at least to my eyes. But it seems docker fails to see it. Any idea? I have the full log available if needed. Again, I am sorry because it looks like some easy stuff, but my colleague and I can't find it. . Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/685
https://github.com/google/deepvariant/issues/687:49,Availability,error,error,49,"When running deeptrio with `--dry_run=true`, the error message ""FATAL Flags parsing error: Unknown command line flag 'dry_run'"" pops up and run exits. ; Here is part of the command I used:. `; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:deeptrio-""${BIN_VERSION}"" \; /opt/deepvariant/bin/deeptrio/run_deeptrio \; --model_type=WGS \; --ref=Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta \; --reads_parent1=markduplicates/S_500061.md.bam \; --reads_parent2=markduplicates/S_500062.md.bam \; --reads_child=markduplicates/S_500063.md.bam \; --output_vcf_parent1 output/S_500061.output.vcf.gz \; --output_vcf_parent2 output/S_500062.output.vcf.gz \; --output_vcf_child output/S_500063.output.vcf.gz \; --sample_name_parent1 'S_500061' \; --sample_name_parent2 'S_500062' \; --sample_name_child 'S_500063' \; --num_shards $(nproc) \; --intermediate_results_dir output/intermediate_results_dir \; --output_gvcf_parent1 output/S_500061.g.vcf.gz \; --output_gvcf_parent2 output/S_500062.g.vcf.gz \; --output_gvcf_child output/S_500063.g.vcf.gz \; --output_gvcf_merged output/FAM1.g.vcf.gz\; --dry_run=true \; --vcf_stats_report=true; `. Thanks for advice.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/687
https://github.com/google/deepvariant/issues/687:84,Availability,error,error,84,"When running deeptrio with `--dry_run=true`, the error message ""FATAL Flags parsing error: Unknown command line flag 'dry_run'"" pops up and run exits. ; Here is part of the command I used:. `; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:deeptrio-""${BIN_VERSION}"" \; /opt/deepvariant/bin/deeptrio/run_deeptrio \; --model_type=WGS \; --ref=Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta \; --reads_parent1=markduplicates/S_500061.md.bam \; --reads_parent2=markduplicates/S_500062.md.bam \; --reads_child=markduplicates/S_500063.md.bam \; --output_vcf_parent1 output/S_500061.output.vcf.gz \; --output_vcf_parent2 output/S_500062.output.vcf.gz \; --output_vcf_child output/S_500063.output.vcf.gz \; --sample_name_parent1 'S_500061' \; --sample_name_parent2 'S_500062' \; --sample_name_child 'S_500063' \; --num_shards $(nproc) \; --intermediate_results_dir output/intermediate_results_dir \; --output_gvcf_parent1 output/S_500061.g.vcf.gz \; --output_gvcf_parent2 output/S_500062.g.vcf.gz \; --output_gvcf_child output/S_500063.g.vcf.gz \; --output_gvcf_merged output/FAM1.g.vcf.gz\; --dry_run=true \; --vcf_stats_report=true; `. Thanks for advice.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/687
https://github.com/google/deepvariant/issues/687:55,Integrability,message,message,55,"When running deeptrio with `--dry_run=true`, the error message ""FATAL Flags parsing error: Unknown command line flag 'dry_run'"" pops up and run exits. ; Here is part of the command I used:. `; singularity run -B /usr/lib/locale/:/usr/lib/locale/ \; docker://google/deepvariant:deeptrio-""${BIN_VERSION}"" \; /opt/deepvariant/bin/deeptrio/run_deeptrio \; --model_type=WGS \; --ref=Sequence/WholeGenomeFasta/Homo_sapiens_assembly38.fasta \; --reads_parent1=markduplicates/S_500061.md.bam \; --reads_parent2=markduplicates/S_500062.md.bam \; --reads_child=markduplicates/S_500063.md.bam \; --output_vcf_parent1 output/S_500061.output.vcf.gz \; --output_vcf_parent2 output/S_500062.output.vcf.gz \; --output_vcf_child output/S_500063.output.vcf.gz \; --sample_name_parent1 'S_500061' \; --sample_name_parent2 'S_500062' \; --sample_name_child 'S_500063' \; --num_shards $(nproc) \; --intermediate_results_dir output/intermediate_results_dir \; --output_gvcf_parent1 output/S_500061.g.vcf.gz \; --output_gvcf_parent2 output/S_500062.g.vcf.gz \; --output_gvcf_child output/S_500063.g.vcf.gz \; --output_gvcf_merged output/FAM1.g.vcf.gz\; --dry_run=true \; --vcf_stats_report=true; `. Thanks for advice.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/687
https://github.com/google/deepvariant/issues/688:131,Testability,log,logging,131,"Hi there,. I have no problem running the CPU version but the GPU version was not function normally either through slurm request or logging in to the GPU node. I found no GPU process through $nvidia-smi with my codes attached as follow:. ```; singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \; --bind /cluster/home/cx/variant_calling/slurm/DV/in:/in \; --bind /cluster/home/cx/variant_calling/slurm/DV/out:/out \; docker://google/deepvariant:1.5.0-gpu \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WES \; --ref=/in/GRCh37_primary/GRCh37.primary_assembly.genome.fa \; --reads=/in/SRR2962694.sorted.bam \; --regions=/in/all_19.bed \; --output_vcf=/out/SRR2962694.vcf.gz; ```. Here is the GPU status after running the code above, no process on GPU is running.; ![微信图片_20230728102005](https://github.com/google/deepvariant/assets/80762999/ae17ac46-1c73-449e-9943-c627a9bc13a7)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/688
https://github.com/google/deepvariant/issues/689:964,Availability,echo,echo,964,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; yes，i have checked this FAQ document. ; **Describe the issue:**; I used Deeprio v1.4.0 version to perform family analysis on three samples, HG002, HG003, and HG004, and evaluated the accuracy of mutation detection using the GIAB database (NISTv4.2.1). I found that the evaluation results through GIAB were particularly unsatisfactory, but I used the same data and Deepvariant v1.5.0 for single sample analysis, and the evaluation results were very ideal, I don't quite understand why the analysis results of a single sample perform so well at the evaluation level compared to the results of family analysis, and why the results of family analysis are relatively poor. The following is my family analysis and analysis code for individual samples, as well as the evaluation results of the GIAB database, for developers to review:; Data comparison to reference genome:; ```; echo HG002.merged.fastq.gz > HG002.fofn ; pbmm2 align \; --preset HIFI \; genome/hg38.fa.mmi \; HG002.fofn \; --sample HG002 \; -j 10 \; HG002.aligned.tmp.bam ; samtools sort -@ 10 HG002.aligned.tmp.bam -O BAM -o HG002.aligned.tmp.sort.bam ; samtools index -@ 10 HG002.aligned.tmp.sort.bam ; chromosomes=(chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM) ; for chromosome in ""${chromosomes[@]}""; \; do \; samtools view -@ 2 -b -h HG002.aligned.tmp.sort.bam ""$chromosome"" --output HG002.aligned.$chromosome.tmp.bam & ; done ; wait ; samtools merge HG002.aligned.bam HG002.aligned.chr*.tmp.bam ; samtools sort -@ 10 HG002.aligned.bam -O BAM -o HG002.sort.bam ; samtools index -@ 10 HG002.sort.bam ; ```; Family analysis code:; ```; rm -rf chr20_GLnexus.DB tmp_ramdom_TrioDemo_chr20 ; samtools view --write-index --threads 10 -h -b -S HG002.sort.bam chr20 -O BAM -o HG002.chr20.sort.bam ; samtools view --write-index --threads 10 -h -b -S HG003.sort.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:6841,Availability,down,download,6841," 1831 | 0.993881 | 0.99258 | 0.467252 | 0.99323 | | | 1.489759281 | 2.02565724 |; | HG003 | SNP | PASS | 3327495 | 3323623 | 3872 | 4265460 | 4910 | 936912 | 1118 | 617 | 0.998836 | 0.998525 | 0.219651 | 0.998681 | 2.102574954 | 1.831128594 | 1.535137772 | 1.484295493 |; | HG004 | INDEL | PASS | 510519 | 507376 | 3143 | 1013737 | 4102 | 469356 | 1887 | 1729 | 0.993844 | 0.992465 | 0.462996 | 0.993154 | | | 1.516130736 | 2.075927402 |. analysising result：Using the same test data as the scattered samples, it can be found that the variation detection results of the HG002/3/4 family sample are relatively poor when tested using the GIAB standard set，but I don't understand the reason for this difference. **Setup**; - Operating system: image of singularity, transforming from docker image of deeptrio-1.4.0; - DeepVariant version:deeptrio-1.4.0; - Installation method (Docker, built from source, etc.):Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); HiFi data,those data download links follows:; * HG002:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/20kb/; * HG003:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/Google_15kb;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/HudsonAlpha_15kb; * HG004:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/Google_15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/HudsonAlpha_15kb/PBmixSequel733_2_B01_PBSU_30hours_15kbV2PD_70pM_HumanHG004_CCS/; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:7645,Availability,Error,Error,7645," 3872 | 4265460 | 4910 | 936912 | 1118 | 617 | 0.998836 | 0.998525 | 0.219651 | 0.998681 | 2.102574954 | 1.831128594 | 1.535137772 | 1.484295493 |; | HG004 | INDEL | PASS | 510519 | 507376 | 3143 | 1013737 | 4102 | 469356 | 1887 | 1729 | 0.993844 | 0.992465 | 0.462996 | 0.993154 | | | 1.516130736 | 2.075927402 |. analysising result：Using the same test data as the scattered samples, it can be found that the variation detection results of the HG002/3/4 family sample are relatively poor when tested using the GIAB standard set，but I don't understand the reason for this difference. **Setup**; - Operating system: image of singularity, transforming from docker image of deeptrio-1.4.0; - DeepVariant version:deeptrio-1.4.0; - Installation method (Docker, built from source, etc.):Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); HiFi data,those data download links follows:; * HG002:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/20kb/; * HG003:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/Google_15kb;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/HudsonAlpha_15kb; * HG004:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/Google_15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/HudsonAlpha_15kb/PBmixSequel733_2_B01_PBSU_30hours_15kbV2PD_70pM_HumanHG004_CCS/; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:6648,Deployability,Install,Installation,6648,"| 1.823839956 | 1.581195853 | 1.50423718 |; | HG003 | INDEL | PASS | 504501 | 501414 | 3087 | 1009147 | 3989 | 471526 | 1814 | 1831 | 0.993881 | 0.99258 | 0.467252 | 0.99323 | | | 1.489759281 | 2.02565724 |; | HG003 | SNP | PASS | 3327495 | 3323623 | 3872 | 4265460 | 4910 | 936912 | 1118 | 617 | 0.998836 | 0.998525 | 0.219651 | 0.998681 | 2.102574954 | 1.831128594 | 1.535137772 | 1.484295493 |; | HG004 | INDEL | PASS | 510519 | 507376 | 3143 | 1013737 | 4102 | 469356 | 1887 | 1729 | 0.993844 | 0.992465 | 0.462996 | 0.993154 | | | 1.516130736 | 2.075927402 |. analysising result：Using the same test data as the scattered samples, it can be found that the variation detection results of the HG002/3/4 family sample are relatively poor when tested using the GIAB standard set，but I don't understand the reason for this difference. **Setup**; - Operating system: image of singularity, transforming from docker image of deeptrio-1.4.0; - DeepVariant version:deeptrio-1.4.0; - Installation method (Docker, built from source, etc.):Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); HiFi data,those data download links follows:; * HG002:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/20kb/; * HG003:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/Google_15kb;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/HudsonAlpha_15kb; * HG004:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/Google_15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/HudsonAlpha_15kb/PBmixSequel733_2_B01_PBSU_30hours_15kbV2PD_70pM_HumanHG004_CCS/; **Steps to reproduce:**; - Command:; - Error trace: (if applicable",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:2936,Modifiability,config,config,2936,x --threads 10 -h -b -S HG003.sort.bam chr20 -O BAM -o HG003.chr20.sort.bam ; samtools view --write-index --threads 10 -h -b -S HG004.sort.bam chr20 -O BAM -o HG004.chr20.sort.bam ; /usr/bin/singularity exec --cleanenv -B /share/:/share/ Singularity/deepvariant.deeptrio-1.4.0.sif /opt/deepvariant/bin/deeptrio/run_deeptrio \; --model_type PACBIO \; --ref=genome/hg38.fa \; --reads_child HG002.chr20.sort.bam \; --reads_parent1 HG003.chr20.sort.bam \; --reads_parent2 HG004.chr20.sort.bam \; --output_vcf_child HG002.chr20.output.vcf.gz \; --output_vcf_parent1 HG003.chr20.output.vcf.gz \; --output_vcf_parent2 HG004.chr20.output.vcf.gz \; --sample_name_child 'HG002' \; --sample_name_parent1 'HG003' \; --sample_name_parent2 'HG004' \; --num_shards 10 \; --intermediate_results_dir tmp_ramdom_TrioDemo_chr20 \; --output_gvcf_child HG002.chr20.g.vcf.gz \; --output_gvcf_parent1 HG003.chr20.g.vcf.gz \; --output_gvcf_parent2 HG004.chr20.g.vcf.gz ; glnexus_cli_v1.4.1 \; --config DeepVariant_unfiltered \; --squeeze \; --dir chr20_GLnexus.DB \; HG002.chr20.g.vcf.gz HG003.chr20.g.vcf.gz HG004.chr20.g.vcf.gz \; --threads 10 | \; /opt/conda/envs/bio/bin/bcftools view \; --threads 10 -O z \; -o TrioDemo_chr20.trio_merged.vcf.gz - ; ```; The following is the code for single sample mutation detection:; ```; samtools view --threads 10 -h -b -S HG002.sort.bam chr20 > HG002/HG002.chr20.sort.bam ; samtools index -@ 10 HG002/HG002.chr20.sort.bam ; singularity run /share:/share Singularity/google-deepvariant.1.5.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref genome/hg38.fa \; --intermediate_results_dir HG002/tmp_ramdom_HG002_chr20 \; --reads HG002/HG002.chr20.sort.bam \; --output_vcf HG002/HG002.chr20.vcf.gz \; --num_shards 10 ; rm -fr HG002/tmp_ramdom_HG002_chr20; ```. The evaluation results of the trio family sample are as follows:. | HG002 | INDEL | PASS | 525469 | 190669 | 334800 | 361066 | 7821 | 151401 | 4826 | 2317 | 0.362855 | 0.962698 | 0.419317 | 0.527055 ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:190,Performance,perform,perform,190,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; yes，i have checked this FAQ document. ; **Describe the issue:**; I used Deeprio v1.4.0 version to perform family analysis on three samples, HG002, HG003, and HG004, and evaluated the accuracy of mutation detection using the GIAB database (NISTv4.2.1). I found that the evaluation results through GIAB were particularly unsatisfactory, but I used the same data and Deepvariant v1.5.0 for single sample analysis, and the evaluation results were very ideal, I don't quite understand why the analysis results of a single sample perform so well at the evaluation level compared to the results of family analysis, and why the results of family analysis are relatively poor. The following is my family analysis and analysis code for individual samples, as well as the evaluation results of the GIAB database, for developers to review:; Data comparison to reference genome:; ```; echo HG002.merged.fastq.gz > HG002.fofn ; pbmm2 align \; --preset HIFI \; genome/hg38.fa.mmi \; HG002.fofn \; --sample HG002 \; -j 10 \; HG002.aligned.tmp.bam ; samtools sort -@ 10 HG002.aligned.tmp.bam -O BAM -o HG002.aligned.tmp.sort.bam ; samtools index -@ 10 HG002.aligned.tmp.sort.bam ; chromosomes=(chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM) ; for chromosome in ""${chromosomes[@]}""; \; do \; samtools view -@ 2 -b -h HG002.aligned.tmp.sort.bam ""$chromosome"" --output HG002.aligned.$chromosome.tmp.bam & ; done ; wait ; samtools merge HG002.aligned.bam HG002.aligned.chr*.tmp.bam ; samtools sort -@ 10 HG002.aligned.bam -O BAM -o HG002.sort.bam ; samtools index -@ 10 HG002.sort.bam ; ```; Family analysis code:; ```; rm -rf chr20_GLnexus.DB tmp_ramdom_TrioDemo_chr20 ; samtools view --write-index --threads 10 -h -b -S HG002.sort.bam chr20 -O BAM -o HG002.chr20.sort.bam ; samtools view --write-index --threads 10 -h -b -S HG003.sort.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:616,Performance,perform,perform,616,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; yes，i have checked this FAQ document. ; **Describe the issue:**; I used Deeprio v1.4.0 version to perform family analysis on three samples, HG002, HG003, and HG004, and evaluated the accuracy of mutation detection using the GIAB database (NISTv4.2.1). I found that the evaluation results through GIAB were particularly unsatisfactory, but I used the same data and Deepvariant v1.5.0 for single sample analysis, and the evaluation results were very ideal, I don't quite understand why the analysis results of a single sample perform so well at the evaluation level compared to the results of family analysis, and why the results of family analysis are relatively poor. The following is my family analysis and analysis code for individual samples, as well as the evaluation results of the GIAB database, for developers to review:; Data comparison to reference genome:; ```; echo HG002.merged.fastq.gz > HG002.fofn ; pbmm2 align \; --preset HIFI \; genome/hg38.fa.mmi \; HG002.fofn \; --sample HG002 \; -j 10 \; HG002.aligned.tmp.bam ; samtools sort -@ 10 HG002.aligned.tmp.bam -O BAM -o HG002.aligned.tmp.sort.bam ; samtools index -@ 10 HG002.aligned.tmp.sort.bam ; chromosomes=(chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM) ; for chromosome in ""${chromosomes[@]}""; \; do \; samtools view -@ 2 -b -h HG002.aligned.tmp.sort.bam ""$chromosome"" --output HG002.aligned.$chromosome.tmp.bam & ; done ; wait ; samtools merge HG002.aligned.bam HG002.aligned.chr*.tmp.bam ; samtools sort -@ 10 HG002.aligned.bam -O BAM -o HG002.sort.bam ; samtools index -@ 10 HG002.sort.bam ; ```; Family analysis code:; ```; rm -rf chr20_GLnexus.DB tmp_ramdom_TrioDemo_chr20 ; samtools view --write-index --threads 10 -h -b -S HG002.sort.bam chr20 -O BAM -o HG002.chr20.sort.bam ; samtools view --write-index --threads 10 -h -b -S HG003.sort.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:296,Safety,detect,detection,296,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:; yes，i have checked this FAQ document. ; **Describe the issue:**; I used Deeprio v1.4.0 version to perform family analysis on three samples, HG002, HG003, and HG004, and evaluated the accuracy of mutation detection using the GIAB database (NISTv4.2.1). I found that the evaluation results through GIAB were particularly unsatisfactory, but I used the same data and Deepvariant v1.5.0 for single sample analysis, and the evaluation results were very ideal, I don't quite understand why the analysis results of a single sample perform so well at the evaluation level compared to the results of family analysis, and why the results of family analysis are relatively poor. The following is my family analysis and analysis code for individual samples, as well as the evaluation results of the GIAB database, for developers to review:; Data comparison to reference genome:; ```; echo HG002.merged.fastq.gz > HG002.fofn ; pbmm2 align \; --preset HIFI \; genome/hg38.fa.mmi \; HG002.fofn \; --sample HG002 \; -j 10 \; HG002.aligned.tmp.bam ; samtools sort -@ 10 HG002.aligned.tmp.bam -O BAM -o HG002.aligned.tmp.sort.bam ; samtools index -@ 10 HG002.aligned.tmp.sort.bam ; chromosomes=(chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM) ; for chromosome in ""${chromosomes[@]}""; \; do \; samtools view -@ 2 -b -h HG002.aligned.tmp.sort.bam ""$chromosome"" --output HG002.aligned.$chromosome.tmp.bam & ; done ; wait ; samtools merge HG002.aligned.bam HG002.aligned.chr*.tmp.bam ; samtools sort -@ 10 HG002.aligned.bam -O BAM -o HG002.sort.bam ; samtools index -@ 10 HG002.sort.bam ; ```; Family analysis code:; ```; rm -rf chr20_GLnexus.DB tmp_ramdom_TrioDemo_chr20 ; samtools view --write-index --threads 10 -h -b -S HG002.sort.bam chr20 -O BAM -o HG002.chr20.sort.bam ; samtools view --write-index --threads 10 -h -b -S HG003.sort.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:3253,Safety,detect,detection,3253,/deepvariant/bin/deeptrio/run_deeptrio \; --model_type PACBIO \; --ref=genome/hg38.fa \; --reads_child HG002.chr20.sort.bam \; --reads_parent1 HG003.chr20.sort.bam \; --reads_parent2 HG004.chr20.sort.bam \; --output_vcf_child HG002.chr20.output.vcf.gz \; --output_vcf_parent1 HG003.chr20.output.vcf.gz \; --output_vcf_parent2 HG004.chr20.output.vcf.gz \; --sample_name_child 'HG002' \; --sample_name_parent1 'HG003' \; --sample_name_parent2 'HG004' \; --num_shards 10 \; --intermediate_results_dir tmp_ramdom_TrioDemo_chr20 \; --output_gvcf_child HG002.chr20.g.vcf.gz \; --output_gvcf_parent1 HG003.chr20.g.vcf.gz \; --output_gvcf_parent2 HG004.chr20.g.vcf.gz ; glnexus_cli_v1.4.1 \; --config DeepVariant_unfiltered \; --squeeze \; --dir chr20_GLnexus.DB \; HG002.chr20.g.vcf.gz HG003.chr20.g.vcf.gz HG004.chr20.g.vcf.gz \; --threads 10 | \; /opt/conda/envs/bio/bin/bcftools view \; --threads 10 -O z \; -o TrioDemo_chr20.trio_merged.vcf.gz - ; ```; The following is the code for single sample mutation detection:; ```; samtools view --threads 10 -h -b -S HG002.sort.bam chr20 > HG002/HG002.chr20.sort.bam ; samtools index -@ 10 HG002/HG002.chr20.sort.bam ; singularity run /share:/share Singularity/google-deepvariant.1.5.0.sif \; /opt/deepvariant/bin/run_deepvariant \; --model_type PACBIO \; --ref genome/hg38.fa \; --intermediate_results_dir HG002/tmp_ramdom_HG002_chr20 \; --reads HG002/HG002.chr20.sort.bam \; --output_vcf HG002/HG002.chr20.vcf.gz \; --num_shards 10 ; rm -fr HG002/tmp_ramdom_HG002_chr20; ```. The evaluation results of the trio family sample are as follows:. | HG002 | INDEL | PASS | 525469 | 190669 | 334800 | 361066 | 7821 | 151401 | 4826 | 2317 | 0.362855 | 0.962698 | 0.419317 | 0.527055 | | | 1.528275734 | 1.988539738 |; |-------|-------|------|---------|---------|---------|---------|-------|--------|-------|------|----------|----------|----------|----------|-------------|------------|-------------|-------------|; | HG002 | SNP | PASS | 3365127 | 1236543 | 2128584 |,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:6341,Safety,detect,detection,6341,"--------|------|---------|------|--------|------|------|----------|----------|----------|----------|-------------|-------------|-------------|-------------|; | HG002 | SNP | PASS | 3365127 | 3361925 | 3202 | 4312006 | 7891 | 942045 | 1197 | 719 | 0.999048 | 0.997658 | 0.21847 | 0.998353 | 2.100128487 | 1.823839956 | 1.581195853 | 1.50423718 |; | HG003 | INDEL | PASS | 504501 | 501414 | 3087 | 1009147 | 3989 | 471526 | 1814 | 1831 | 0.993881 | 0.99258 | 0.467252 | 0.99323 | | | 1.489759281 | 2.02565724 |; | HG003 | SNP | PASS | 3327495 | 3323623 | 3872 | 4265460 | 4910 | 936912 | 1118 | 617 | 0.998836 | 0.998525 | 0.219651 | 0.998681 | 2.102574954 | 1.831128594 | 1.535137772 | 1.484295493 |; | HG004 | INDEL | PASS | 510519 | 507376 | 3143 | 1013737 | 4102 | 469356 | 1887 | 1729 | 0.993844 | 0.992465 | 0.462996 | 0.993154 | | | 1.516130736 | 2.075927402 |. analysising result：Using the same test data as the scattered samples, it can be found that the variation detection results of the HG002/3/4 family sample are relatively poor when tested using the GIAB standard set，but I don't understand the reason for this difference. **Setup**; - Operating system: image of singularity, transforming from docker image of deeptrio-1.4.0; - DeepVariant version:deeptrio-1.4.0; - Installation method (Docker, built from source, etc.):Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); HiFi data,those data download links follows:; * HG002:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/20kb/; * HG003:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/Google_15kb;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/HudsonAlpha_15kb; * HG004:https://s3-us-west-2.amazonaws.com/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:6270,Testability,test,test,6270,"--------|------|---------|------|--------|------|------|----------|----------|----------|----------|-------------|-------------|-------------|-------------|; | HG002 | SNP | PASS | 3365127 | 3361925 | 3202 | 4312006 | 7891 | 942045 | 1197 | 719 | 0.999048 | 0.997658 | 0.21847 | 0.998353 | 2.100128487 | 1.823839956 | 1.581195853 | 1.50423718 |; | HG003 | INDEL | PASS | 504501 | 501414 | 3087 | 1009147 | 3989 | 471526 | 1814 | 1831 | 0.993881 | 0.99258 | 0.467252 | 0.99323 | | | 1.489759281 | 2.02565724 |; | HG003 | SNP | PASS | 3327495 | 3323623 | 3872 | 4265460 | 4910 | 936912 | 1118 | 617 | 0.998836 | 0.998525 | 0.219651 | 0.998681 | 2.102574954 | 1.831128594 | 1.535137772 | 1.484295493 |; | HG004 | INDEL | PASS | 510519 | 507376 | 3143 | 1013737 | 4102 | 469356 | 1887 | 1729 | 0.993844 | 0.992465 | 0.462996 | 0.993154 | | | 1.516130736 | 2.075927402 |. analysising result：Using the same test data as the scattered samples, it can be found that the variation detection results of the HG002/3/4 family sample are relatively poor when tested using the GIAB standard set，but I don't understand the reason for this difference. **Setup**; - Operating system: image of singularity, transforming from docker image of deeptrio-1.4.0; - DeepVariant version:deeptrio-1.4.0; - Installation method (Docker, built from source, etc.):Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); HiFi data,those data download links follows:; * HG002:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/20kb/; * HG003:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/Google_15kb;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/HudsonAlpha_15kb; * HG004:https://s3-us-west-2.amazonaws.com/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:6415,Testability,test,tested,6415,"--------|------|---------|------|--------|------|------|----------|----------|----------|----------|-------------|-------------|-------------|-------------|; | HG002 | SNP | PASS | 3365127 | 3361925 | 3202 | 4312006 | 7891 | 942045 | 1197 | 719 | 0.999048 | 0.997658 | 0.21847 | 0.998353 | 2.100128487 | 1.823839956 | 1.581195853 | 1.50423718 |; | HG003 | INDEL | PASS | 504501 | 501414 | 3087 | 1009147 | 3989 | 471526 | 1814 | 1831 | 0.993881 | 0.99258 | 0.467252 | 0.99323 | | | 1.489759281 | 2.02565724 |; | HG003 | SNP | PASS | 3327495 | 3323623 | 3872 | 4265460 | 4910 | 936912 | 1118 | 617 | 0.998836 | 0.998525 | 0.219651 | 0.998681 | 2.102574954 | 1.831128594 | 1.535137772 | 1.484295493 |; | HG004 | INDEL | PASS | 510519 | 507376 | 3143 | 1013737 | 4102 | 469356 | 1887 | 1729 | 0.993844 | 0.992465 | 0.462996 | 0.993154 | | | 1.516130736 | 2.075927402 |. analysising result：Using the same test data as the scattered samples, it can be found that the variation detection results of the HG002/3/4 family sample are relatively poor when tested using the GIAB standard set，but I don't understand the reason for this difference. **Setup**; - Operating system: image of singularity, transforming from docker image of deeptrio-1.4.0; - DeepVariant version:deeptrio-1.4.0; - Installation method (Docker, built from source, etc.):Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); HiFi data,those data download links follows:; * HG002:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/20kb/; * HG003:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/Google_15kb;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/HudsonAlpha_15kb; * HG004:https://s3-us-west-2.amazonaws.com/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:7698,Testability,test,test,7698," 3872 | 4265460 | 4910 | 936912 | 1118 | 617 | 0.998836 | 0.998525 | 0.219651 | 0.998681 | 2.102574954 | 1.831128594 | 1.535137772 | 1.484295493 |; | HG004 | INDEL | PASS | 510519 | 507376 | 3143 | 1013737 | 4102 | 469356 | 1887 | 1729 | 0.993844 | 0.992465 | 0.462996 | 0.993154 | | | 1.516130736 | 2.075927402 |. analysising result：Using the same test data as the scattered samples, it can be found that the variation detection results of the HG002/3/4 family sample are relatively poor when tested using the GIAB standard set，but I don't understand the reason for this difference. **Setup**; - Operating system: image of singularity, transforming from docker image of deeptrio-1.4.0; - DeepVariant version:deeptrio-1.4.0; - Installation method (Docker, built from source, etc.):Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); HiFi data,those data download links follows:; * HG002:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/20kb/; * HG003:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/Google_15kb;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/HudsonAlpha_15kb; * HG004:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/Google_15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/HudsonAlpha_15kb/PBmixSequel733_2_B01_PBSU_30hours_15kbV2PD_70pM_HumanHG004_CCS/; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/689:7734,Testability,test,test,7734," 3872 | 4265460 | 4910 | 936912 | 1118 | 617 | 0.998836 | 0.998525 | 0.219651 | 0.998681 | 2.102574954 | 1.831128594 | 1.535137772 | 1.484295493 |; | HG004 | INDEL | PASS | 510519 | 507376 | 3143 | 1013737 | 4102 | 469356 | 1887 | 1729 | 0.993844 | 0.992465 | 0.462996 | 0.993154 | | | 1.516130736 | 2.075927402 |. analysising result：Using the same test data as the scattered samples, it can be found that the variation detection results of the HG002/3/4 family sample are relatively poor when tested using the GIAB standard set，but I don't understand the reason for this difference. **Setup**; - Operating system: image of singularity, transforming from docker image of deeptrio-1.4.0; - DeepVariant version:deeptrio-1.4.0; - Installation method (Docker, built from source, etc.):Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); HiFi data,those data download links follows:; * HG002:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG002/hpp_HG002_NA24385_son_v1/PacBio_HiFi/20kb/; * HG003:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/Google_15kb;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG003/PacBio_HiFi/HudsonAlpha_15kb; * HG004:https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/Google_15kb/;https://s3-us-west-2.amazonaws.com/human-pangenomics/NHGRI_UCSC_panel/HG004/PacBio_HiFi/HudsonAlpha_15kb/PBmixSequel733_2_B01_PBSU_30hours_15kbV2PD_70pM_HumanHG004_CCS/; **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/689
https://github.com/google/deepvariant/issues/690:566,Safety,detect,detected,566,"Hi,. I'm running DeepVariant via NVIDA docker image on Horizon sample (Detail of the sample dataset is here: https://horizondiscovery.com/en/reference-standards/products/truq-1-5-tier-reference-standard) . The result is not good as only 5 variants out of 13 expected variants are found, and among 5 found variants, only 1 variant has PASS filter and the other 4 variants have REFCALL filter. . I read the blog post of pileup image of Deepvaraint. Is there a way for me to see the pileup image of variants in my results. I want to know why the other variants are not detected event though I relaxed some of the parameters: vsc_min_fraction_snps = 0.03 instead of 0.12 as default, --min_base_quality=5 instead of 10 as default. Also, I want to see why the variants has REFCALL filter instead of expected PASS filter. . Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/690
https://github.com/google/deepvariant/issues/691:73,Safety,detect,detected,73,"Hello,. This may be a naive question but I have some variants which were detected as PASS by DeepVariant - however I cannot see this variants within the bam files?. Any ideas? I likely will have to filter these variants out anyway but wanted to double check if there could be reasons causing this. . For reference: HG38; Chr15:41570158 T>C; The depth is 14,9 from the VCF. This is the region in the bam:; ![Image 02-08-2023 at 16 38](https://github.com/google/deepvariant/assets/110385188/7df0492e-ec54-4330-ada0-cf758de1c75d). I know this is probably an IGV question but thought I would just ask incase!. Thanks!!; Amy",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/691
https://github.com/google/deepvariant/issues/695:611,Deployability,Install,Installation,611,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; When calling a bam file aligned to hs37d5_decoy.fasta so the hs37d5 version with decoys. The produced vcfs contains no decoys despite there are such reads in the file but instead those calls were aligned to chrY. This is problematic in several ways. Thereby one can't distinguish between chromosome Y and decoy and it is impossible to determining the sex of the sample using just the vcf. . **Setup**; - Operating system: Linux 5.15.0-78-generic #85-Ubuntu SMP; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; 1. Align any WGS sequencing reads to hs37d5 with decoys. Maybe this can be repeated with any GRCh38 reference fasta containing decoys as well but I did not test that. ; 2. Run deepvariant with default parameters to call the file.; 3. Open the vcf and see if the file contains decoy regions or not and observe if such calls were catched by chromosome Y; 4. ; **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/695
https://github.com/google/deepvariant/issues/695:965,Testability,test,test,965,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; When calling a bam file aligned to hs37d5_decoy.fasta so the hs37d5 version with decoys. The produced vcfs contains no decoys despite there are such reads in the file but instead those calls were aligned to chrY. This is problematic in several ways. Thereby one can't distinguish between chromosome Y and decoy and it is impossible to determining the sex of the sample using just the vcf. . **Setup**; - Operating system: Linux 5.15.0-78-generic #85-Ubuntu SMP; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; 1. Align any WGS sequencing reads to hs37d5 with decoys. Maybe this can be repeated with any GRCh38 reference fasta containing decoys as well but I did not test that. ; 2. Run deepvariant with default parameters to call the file.; 3. Open the vcf and see if the file contains decoy regions or not and observe if such calls were catched by chromosome Y; 4. ; **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/695
https://github.com/google/deepvariant/issues/695:1190,Testability,test,test,1190,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; When calling a bam file aligned to hs37d5_decoy.fasta so the hs37d5 version with decoys. The produced vcfs contains no decoys despite there are such reads in the file but instead those calls were aligned to chrY. This is problematic in several ways. Thereby one can't distinguish between chromosome Y and decoy and it is impossible to determining the sex of the sample using just the vcf. . **Setup**; - Operating system: Linux 5.15.0-78-generic #85-Ubuntu SMP; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; 1. Align any WGS sequencing reads to hs37d5 with decoys. Maybe this can be repeated with any GRCh38 reference fasta containing decoys as well but I did not test that. ; 2. Run deepvariant with default parameters to call the file.; 3. Open the vcf and see if the file contains decoy regions or not and observe if such calls were catched by chromosome Y; 4. ; **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/695
https://github.com/google/deepvariant/issues/695:1226,Testability,test,test,1226,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; When calling a bam file aligned to hs37d5_decoy.fasta so the hs37d5 version with decoys. The produced vcfs contains no decoys despite there are such reads in the file but instead those calls were aligned to chrY. This is problematic in several ways. Thereby one can't distinguish between chromosome Y and decoy and it is impossible to determining the sex of the sample using just the vcf. . **Setup**; - Operating system: Linux 5.15.0-78-generic #85-Ubuntu SMP; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): Docker; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; 1. Align any WGS sequencing reads to hs37d5 with decoys. Maybe this can be repeated with any GRCh38 reference fasta containing decoys as well but I did not test that. ; 2. Run deepvariant with default parameters to call the file.; 3. Open the vcf and see if the file contains decoy regions or not and observe if such calls were catched by chromosome Y; 4. ; **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/695
https://github.com/google/deepvariant/issues/696:133,Availability,down,download,133,"Hi,. I'm testing running DeepVariant on some of our genomic datasets. . I found out through reading the quick start guide that I can download the docker image of Deepvariant and run this docker image on AWS EC2 instance. In the guideline, it uses t2.medium EC2 instance, I tested and was able to run using the test files. This works with t2.medium because the test cases don't go through the first step, which require GPU to make examples. I want to know that for the real cases with bigger memory requirement, what is the **recommended EC2 instance type** I should use in order to run DeepVariant? . Also, if I want to start with fastq sequencing file, is there an existing tool in the docker image to convert from .fastq to .bam?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/696
https://github.com/google/deepvariant/issues/696:9,Testability,test,testing,9,"Hi,. I'm testing running DeepVariant on some of our genomic datasets. . I found out through reading the quick start guide that I can download the docker image of Deepvariant and run this docker image on AWS EC2 instance. In the guideline, it uses t2.medium EC2 instance, I tested and was able to run using the test files. This works with t2.medium because the test cases don't go through the first step, which require GPU to make examples. I want to know that for the real cases with bigger memory requirement, what is the **recommended EC2 instance type** I should use in order to run DeepVariant? . Also, if I want to start with fastq sequencing file, is there an existing tool in the docker image to convert from .fastq to .bam?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/696
https://github.com/google/deepvariant/issues/696:273,Testability,test,tested,273,"Hi,. I'm testing running DeepVariant on some of our genomic datasets. . I found out through reading the quick start guide that I can download the docker image of Deepvariant and run this docker image on AWS EC2 instance. In the guideline, it uses t2.medium EC2 instance, I tested and was able to run using the test files. This works with t2.medium because the test cases don't go through the first step, which require GPU to make examples. I want to know that for the real cases with bigger memory requirement, what is the **recommended EC2 instance type** I should use in order to run DeepVariant? . Also, if I want to start with fastq sequencing file, is there an existing tool in the docker image to convert from .fastq to .bam?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/696
https://github.com/google/deepvariant/issues/696:310,Testability,test,test,310,"Hi,. I'm testing running DeepVariant on some of our genomic datasets. . I found out through reading the quick start guide that I can download the docker image of Deepvariant and run this docker image on AWS EC2 instance. In the guideline, it uses t2.medium EC2 instance, I tested and was able to run using the test files. This works with t2.medium because the test cases don't go through the first step, which require GPU to make examples. I want to know that for the real cases with bigger memory requirement, what is the **recommended EC2 instance type** I should use in order to run DeepVariant? . Also, if I want to start with fastq sequencing file, is there an existing tool in the docker image to convert from .fastq to .bam?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/696
https://github.com/google/deepvariant/issues/696:360,Testability,test,test,360,"Hi,. I'm testing running DeepVariant on some of our genomic datasets. . I found out through reading the quick start guide that I can download the docker image of Deepvariant and run this docker image on AWS EC2 instance. In the guideline, it uses t2.medium EC2 instance, I tested and was able to run using the test files. This works with t2.medium because the test cases don't go through the first step, which require GPU to make examples. I want to know that for the real cases with bigger memory requirement, what is the **recommended EC2 instance type** I should use in order to run DeepVariant? . Also, if I want to start with fastq sequencing file, is there an existing tool in the docker image to convert from .fastq to .bam?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/696
https://github.com/google/deepvariant/issues/696:116,Usability,guid,guide,116,"Hi,. I'm testing running DeepVariant on some of our genomic datasets. . I found out through reading the quick start guide that I can download the docker image of Deepvariant and run this docker image on AWS EC2 instance. In the guideline, it uses t2.medium EC2 instance, I tested and was able to run using the test files. This works with t2.medium because the test cases don't go through the first step, which require GPU to make examples. I want to know that for the real cases with bigger memory requirement, what is the **recommended EC2 instance type** I should use in order to run DeepVariant? . Also, if I want to start with fastq sequencing file, is there an existing tool in the docker image to convert from .fastq to .bam?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/696
https://github.com/google/deepvariant/issues/696:228,Usability,guid,guideline,228,"Hi,. I'm testing running DeepVariant on some of our genomic datasets. . I found out through reading the quick start guide that I can download the docker image of Deepvariant and run this docker image on AWS EC2 instance. In the guideline, it uses t2.medium EC2 instance, I tested and was able to run using the test files. This works with t2.medium because the test cases don't go through the first step, which require GPU to make examples. I want to know that for the real cases with bigger memory requirement, what is the **recommended EC2 instance type** I should use in order to run DeepVariant? . Also, if I want to start with fastq sequencing file, is there an existing tool in the docker image to convert from .fastq to .bam?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/696
https://github.com/google/deepvariant/issues/697:18,Testability,test,test,18,"Hi,. I'm tring to test Deepvariant in my own panel data and set --regins to the interest regin, but something happend in my output. I provided reference gene hg19 and index it with samtools index, and provided .bam file with index named .bam.bai, when i run following commend, it's can work and create files :. BIN_VERSION=""1.5.0""; ; INPUT_DIR=""${PWD}/test_input""; OUTPUT_DIR=""${PWD}/test_output""; mkdir -p ""${OUTPUT_DIR}""; ; docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.fasta \; --reads=/input/my_test.bam \; --regions chx:xxxxx-xxxxxx \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=1 \. The following figure is my question: when i run the test files provided by Deepvariant, it can work rightly, but if i run it on my own dataset, it create this .html file:; ![image](https://github.com/google/deepvariant/assets/139957165/9fd3f9d2-9a33-4aa1-a7b8-d54d75af7163); I checked the Depth item in the website, it's 1091, and I use command ""samtools view xxxx | wc -l"" it prints 1174, so maybe Deepvariant recognize all reads and count them rightly , but why it doesn't output right indel, genotypes and other items? Why they are empyt?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/697
https://github.com/google/deepvariant/issues/697:842,Testability,test,test,842,"Hi,. I'm tring to test Deepvariant in my own panel data and set --regins to the interest regin, but something happend in my output. I provided reference gene hg19 and index it with samtools index, and provided .bam file with index named .bam.bai, when i run following commend, it's can work and create files :. BIN_VERSION=""1.5.0""; ; INPUT_DIR=""${PWD}/test_input""; OUTPUT_DIR=""${PWD}/test_output""; mkdir -p ""${OUTPUT_DIR}""; ; docker run \; -v ""${INPUT_DIR}"":""/input"" \; -v ""${OUTPUT_DIR}"":""/output"" \; google/deepvariant:""${BIN_VERSION}"" \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/ucsc.hg19.fasta \; --reads=/input/my_test.bam \; --regions chx:xxxxx-xxxxxx \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=1 \. The following figure is my question: when i run the test files provided by Deepvariant, it can work rightly, but if i run it on my own dataset, it create this .html file:; ![image](https://github.com/google/deepvariant/assets/139957165/9fd3f9d2-9a33-4aa1-a7b8-d54d75af7163); I checked the Depth item in the website, it's 1091, and I use command ""samtools view xxxx | wc -l"" it prints 1174, so maybe Deepvariant recognize all reads and count them rightly , but why it doesn't output right indel, genotypes and other items? Why they are empyt?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/697
https://github.com/google/deepvariant/issues/698:261,Security,validat,validation,261,"I'm interested in retraining DeepVariant to work on our dataset with low allele fraction variants. In this [tutorial](https://github.com/google/deepvariant/blob/ab068c4588a02e2167051bd9e74c0c9579462b51/docs/deepvariant-training-case-study.md), the training and validation set only target one chromosome region, chromosome 1 and 21 respectively. I want to create training samples on all chromosome regions in .BAM files with parameters to select for low fraction variants (using --downsample_fraction and vsc_min_fraction_snps). Is it a good way to do or do you suggest I break the training examples into different chromosome regions? ; Also if I use one BAM file and create training set on all chr regions of that file, should I use another BAM file to create the validation set?. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/698
https://github.com/google/deepvariant/issues/698:764,Security,validat,validation,764,"I'm interested in retraining DeepVariant to work on our dataset with low allele fraction variants. In this [tutorial](https://github.com/google/deepvariant/blob/ab068c4588a02e2167051bd9e74c0c9579462b51/docs/deepvariant-training-case-study.md), the training and validation set only target one chromosome region, chromosome 1 and 21 respectively. I want to create training samples on all chromosome regions in .BAM files with parameters to select for low fraction variants (using --downsample_fraction and vsc_min_fraction_snps). Is it a good way to do or do you suggest I break the training examples into different chromosome regions? ; Also if I use one BAM file and create training set on all chr regions of that file, should I use another BAM file to create the validation set?. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/698
https://github.com/google/deepvariant/issues/701:718,Deployability,Install,Installation,718,"**Describe the issue:**; I am observing some weird genotypes calls, when I call variants from RNA-seq data. I've followed the nicely written tutorial, the only thing I changed was a minimum coverage of 5X (instead of 3X). Below I have some examples (GT, AD and PL). | GT | AD | PL | QUAL | GQ | ; | ------------- | ------------- | ------------- | ------------- | ------------- |; | 1/1 | 117,86 | 58,42,0 | 42 | 42; | 0/1 | 88,13 | 2,0,13 | 4 | 4. Why is the first SNP called as homozygous ALT, even if I have more reads for the REF compared to ALT (117 vs 86)?. From what I've read, the AD values is calculated by chunks. **Setup**; - Operating system: CentOS 8; - DeepVariant version: 1.5.0, with 1.4.0 RNA model; - Installation method (Docker, built from source, etc.): Singularity; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) RNA-seq",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/701
https://github.com/google/deepvariant/issues/702:110,Security,validat,validation,110,"The principle of PL, and sometimes the genotype and mutation ratio may not match, and after one generation of validation, some genotype results are incorrect.How should I handle it?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/702
https://github.com/google/deepvariant/issues/703:291,Deployability,update,update,291,"Hello,. Deepvariant is reported to work well with WGS data from the Element AVITI™ System.; #623 ; https://www.biorxiv.org/content/10.1101/2023.08.11.553043v1.full.pdf. How does Deepvariant perform with AVITI WES data?; Is it possible to use the current WES model or is it still required to update the WES model?. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/703
https://github.com/google/deepvariant/issues/703:190,Performance,perform,perform,190,"Hello,. Deepvariant is reported to work well with WGS data from the Element AVITI™ System.; #623 ; https://www.biorxiv.org/content/10.1101/2023.08.11.553043v1.full.pdf. How does Deepvariant perform with AVITI WES data?; Is it possible to use the current WES model or is it still required to update the WES model?. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/703
https://github.com/google/deepvariant/issues/704:34,Deployability,pipeline,pipeline,34,"I ran my DeepVariant and Deeptrio pipeline following the ""quick start"" guidance, and I noticed that in my real trio case analysis, the variants called by Deeptrio outnumbers those called by DeepVariant (especially the RefCalls), for both the parents and child. Why did this happen? And I also noticed that in issue #699 your team recommand to perform trio analysis either through DeepVariant+GLnexus or Deeptrio with truth sets to be compared. I wonder how to use ""truth set"" (and what does the truth set means? like dataset from GIAB?) to check my Deeptrio results? And which method will you consider as the best in both accuracy and time cost in trio analysis? Really appreciate that if your team could answer these questions!. **Setup**; - Operating system: linux; - DeepVariant version: 1.5.0 (in Deeptrio as well); - Installation method: Singularity version; - Type of data: WES",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/704
https://github.com/google/deepvariant/issues/704:822,Deployability,Install,Installation,822,"I ran my DeepVariant and Deeptrio pipeline following the ""quick start"" guidance, and I noticed that in my real trio case analysis, the variants called by Deeptrio outnumbers those called by DeepVariant (especially the RefCalls), for both the parents and child. Why did this happen? And I also noticed that in issue #699 your team recommand to perform trio analysis either through DeepVariant+GLnexus or Deeptrio with truth sets to be compared. I wonder how to use ""truth set"" (and what does the truth set means? like dataset from GIAB?) to check my Deeptrio results? And which method will you consider as the best in both accuracy and time cost in trio analysis? Really appreciate that if your team could answer these questions!. **Setup**; - Operating system: linux; - DeepVariant version: 1.5.0 (in Deeptrio as well); - Installation method: Singularity version; - Type of data: WES",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/704
https://github.com/google/deepvariant/issues/704:343,Performance,perform,perform,343,"I ran my DeepVariant and Deeptrio pipeline following the ""quick start"" guidance, and I noticed that in my real trio case analysis, the variants called by Deeptrio outnumbers those called by DeepVariant (especially the RefCalls), for both the parents and child. Why did this happen? And I also noticed that in issue #699 your team recommand to perform trio analysis either through DeepVariant+GLnexus or Deeptrio with truth sets to be compared. I wonder how to use ""truth set"" (and what does the truth set means? like dataset from GIAB?) to check my Deeptrio results? And which method will you consider as the best in both accuracy and time cost in trio analysis? Really appreciate that if your team could answer these questions!. **Setup**; - Operating system: linux; - DeepVariant version: 1.5.0 (in Deeptrio as well); - Installation method: Singularity version; - Type of data: WES",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/704
https://github.com/google/deepvariant/issues/704:71,Usability,guid,guidance,71,"I ran my DeepVariant and Deeptrio pipeline following the ""quick start"" guidance, and I noticed that in my real trio case analysis, the variants called by Deeptrio outnumbers those called by DeepVariant (especially the RefCalls), for both the parents and child. Why did this happen? And I also noticed that in issue #699 your team recommand to perform trio analysis either through DeepVariant+GLnexus or Deeptrio with truth sets to be compared. I wonder how to use ""truth set"" (and what does the truth set means? like dataset from GIAB?) to check my Deeptrio results? And which method will you consider as the best in both accuracy and time cost in trio analysis? Really appreciate that if your team could answer these questions!. **Setup**; - Operating system: linux; - DeepVariant version: 1.5.0 (in Deeptrio as well); - Installation method: Singularity version; - Type of data: WES",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/704
https://github.com/google/deepvariant/issues/706:424,Testability,log,log,424,"Hi,. I want to create training examples for multiple samples (specifically HG001 to HG007). Each sample has different coverages. For this command below, do I have to repeat this command for each of the .BAM file I have, or can I have multiple `--reads` for .BAM files of the same sample with different coverages. What would be a good approach here?; `( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \; sudo nvidia-docker run \; -v ${HOME}:${HOME} \; google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/make_examples \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM_CHR1}"" \; --examples ""${OUTPUT_DIR}/training_set.with_label.tfrecord@${N_SHARDS}.gz"" \; --truth_variants ""${TRUTH_VCF}"" \; --confident_regions ""${TRUTH_BED}"" \; --task {} \; --regions ""'chr1'"" \; ) >""${LOG_DIR}/training_set.with_label.make_examples.log"" 2>&1; `. Also in the shuffling step, what is a correct way to shuffle training examples: shuffling all examples of each sample file (e.g HG001) or shuffling all examples of all sample files once?. Thank",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/706
https://github.com/google/deepvariant/issues/706:881,Testability,log,log,881,"Hi,. I want to create training examples for multiple samples (specifically HG001 to HG007). Each sample has different coverages. For this command below, do I have to repeat this command for each of the .BAM file I have, or can I have multiple `--reads` for .BAM files of the same sample with different coverages. What would be a good approach here?; `( time seq 0 $((N_SHARDS-1)) | \; parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \; sudo nvidia-docker run \; -v ${HOME}:${HOME} \; google/deepvariant:""${BIN_VERSION}-gpu"" \; /opt/deepvariant/bin/make_examples \; --mode training \; --ref ""${REF}"" \; --reads ""${BAM_CHR1}"" \; --examples ""${OUTPUT_DIR}/training_set.with_label.tfrecord@${N_SHARDS}.gz"" \; --truth_variants ""${TRUTH_VCF}"" \; --confident_regions ""${TRUTH_BED}"" \; --task {} \; --regions ""'chr1'"" \; ) >""${LOG_DIR}/training_set.with_label.make_examples.log"" 2>&1; `. Also in the shuffling step, what is a correct way to shuffle training examples: shuffling all examples of each sample file (e.g HG001) or shuffling all examples of all sample files once?. Thank",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/706
https://github.com/google/deepvariant/issues/709:233,Usability,clear,clear,233,"Hello Team,. Congratulations on the [nice haplotagging paper](https://www.biorxiv.org/content/10.1101/2023.09.07.556731v1)! I have looked through the paper, algorithm and code, and there are some things that could be made a bit more clear in the paper. Let me know if you would like me to help you with the paper. Best regards,; Paul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/709
https://github.com/google/deepvariant/issues/710:135,Availability,error,error,135,"I used deepvariant to call variant on HIFI and ONT sequencing data, and merged the generated gvcf files. When I used gatk to merge, an error occurred. When using glnexus to merge gvcf, its config options are only DeepVariantWGS and DeepVariantWES. Can you provide me with some help and suggestions about merging gvcf files? grateful.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/710
https://github.com/google/deepvariant/issues/710:189,Modifiability,config,config,189,"I used deepvariant to call variant on HIFI and ONT sequencing data, and merged the generated gvcf files. When I used gatk to merge, an error occurred. When using glnexus to merge gvcf, its config options are only DeepVariantWGS and DeepVariantWES. Can you provide me with some help and suggestions about merging gvcf files? grateful.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/710
https://github.com/google/deepvariant/issues/711:207,Availability,error,error,207,"Hello,. I'm trying to run DeepVariant using ultima data (cram file).; I get information that deepvariant tool provides --enable_joint_realignment and --p_error in DeepVariant 1.5.0 release page.; But, I got error message when I am trying to use --enable_joint_realignment options.. Can I get some advice which custom channels or options I should use to run deepvariant using ultima data?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/711
https://github.com/google/deepvariant/issues/711:181,Deployability,release,release,181,"Hello,. I'm trying to run DeepVariant using ultima data (cram file).; I get information that deepvariant tool provides --enable_joint_realignment and --p_error in DeepVariant 1.5.0 release page.; But, I got error message when I am trying to use --enable_joint_realignment options.. Can I get some advice which custom channels or options I should use to run deepvariant using ultima data?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/711
https://github.com/google/deepvariant/issues/711:213,Integrability,message,message,213,"Hello,. I'm trying to run DeepVariant using ultima data (cram file).; I get information that deepvariant tool provides --enable_joint_realignment and --p_error in DeepVariant 1.5.0 release page.; But, I got error message when I am trying to use --enable_joint_realignment options.. Can I get some advice which custom channels or options I should use to run deepvariant using ultima data?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/711
https://github.com/google/deepvariant/issues/712:571,Usability,guid,guidance,571,"Hi,. Sorry this is more of a question than an issue but I just want to understand that I am using Deepvariant correctly.; I read in #704 you said ""Direct phasing is happening internally from version 1.4 of DeepVariant, so it's only necessary for DeepTrio (with the additional --use_hp_information flag following whatshap processing), while DeepVariant -> GLnexus should work as is."". I am trying to run trios using Deepvariant/Deeptrio for the first time. With the above statement are you recommending running Trios with DeepVariant -> GLnexus?. Could you also give some guidance as to how we ""or the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". Does this mean if we have a trio with son we have to remove Dad's X?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/712
https://github.com/google/deepvariant/issues/713:506,Modifiability,config,config,506,"I'm sorry to bother you again, but I have a few more questions for you. . At present, the sequencing data we used are pacbio clr and ont r9.4. Can deepvariant be used to call varinat? If so, what should be selected for the --model_type parameter (HIFI / PACBIO ONT_R104). There is another question mentioned above. According to your reply, my understanding is as follows: When merging gvcf with glnexus, regardless of what deepvatriant's --model_type parameter selects (WGS,PACBIO,HIFI, etc.), glnexus's --config can select DeepVariantWGS. If not, please correct. Thank you again and look forward to your reply",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/713
https://github.com/google/deepvariant/issues/714:245,Usability,intuit,intuitive,245,"RE: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-gvcf-support.md. That documents that the GQ value reported in a gVCF reference band is the lowest GQ out of all the positions covered by the reference band -- this is nice and intuitive along with MIN_DP. It would be nice to document how to think about the PL vector in a reference band as well. since it's a vector, it's not so obvious how one would combine information from all the covered positions. In `variant_caller.make_gvcfs()`:. https://github.com/google/deepvariant/blob/ab068c4588a02e2167051bd9e74c0c9579462b51/deepvariant/variant_caller.py#L308-L314. I *think* this code says to fill in the PL just from the *first* position of the reference band; which seems slightly weird (unless please correct me if I misread!). I don't think this is a significant problem, to be clear, since the quantities are in any case not very useful from reference bands, and (I often argue) essentially a waste of storage space. Main interest here is just documenting what in fact occurs!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/714
https://github.com/google/deepvariant/issues/714:849,Usability,clear,clear,849,"RE: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-gvcf-support.md. That documents that the GQ value reported in a gVCF reference band is the lowest GQ out of all the positions covered by the reference band -- this is nice and intuitive along with MIN_DP. It would be nice to document how to think about the PL vector in a reference band as well. since it's a vector, it's not so obvious how one would combine information from all the covered positions. In `variant_caller.make_gvcfs()`:. https://github.com/google/deepvariant/blob/ab068c4588a02e2167051bd9e74c0c9579462b51/deepvariant/variant_caller.py#L308-L314. I *think* this code says to fill in the PL just from the *first* position of the reference band; which seems slightly weird (unless please correct me if I misread!). I don't think this is a significant problem, to be clear, since the quantities are in any case not very useful from reference bands, and (I often argue) essentially a waste of storage space. Main interest here is just documenting what in fact occurs!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/714
https://github.com/google/deepvariant/issues/715:25,Deployability,update,updated,25,"Hello,. Will DeepTrio be updated for use with Oxford Nanopore data ?. Thank you, regards.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/715
https://github.com/google/deepvariant/issues/716:421,Energy Efficiency,power,powerful,421,"Hello, ; I think the answer is ""yes I could"". To be quick ... I have 25 datasets of high-coverage illumina data. But mapping them on the rotifer genomes is a nightmare, it seems there are many mismappings. But ... we finally start to have enough material to get long ONT precise reads (the very last one that is accurate at 99.99%, just like a giant PCR); those are much less likely to mismap, and Clair3 seems extremely powerful and precise to call. Therefore, we could consider the call from long reads as a ""truth set"". . My point is if I give deep variant the ONT ""truth set"" and then the mapping of short illumina reads. Could it be retrained to understand the mapping and calling issues with this kind of genome? I don't have a ""rule"" such as Mendelian violation because my organism is clonal. Therefore, the only possibility of having a ""truth set"" is to trust long reads mapping (Sanger sequencing doesn't work well either; we don't know why). . Is it something doable? I could use other things, such as Python random forests, as suggested by a colleague, but since you have spent a lot of time trying to help me, before, I found it gentlemanly to ask if we can use Deepvariant.; I think the answer is ""Yes, I could"". To be quick ... I have 25 datasets of high-coverage Illumina data. And I'm not sure I will get those datasets resequenced in long reads with enough coverage and N50 (for another reason we don't understand well, DNA extraction is harrowing in rotifers; it often fails or yields highly damaged DNA). Therefore, if I could retrain a model to use the Illumina datasets, that would be great. . My worries are: what does it take in terms of hardware to retrain Deepvariant? I don't have access to a huge GPU. . I found this tutorial: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md . but I am not sure if it is adapted to my case, streamlined, or can be done here, if I understand well this example relies on using Google machines, right?. E",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/716
https://github.com/google/deepvariant/issues/716:1871,Energy Efficiency,adapt,adapted,1871,"tart to have enough material to get long ONT precise reads (the very last one that is accurate at 99.99%, just like a giant PCR); those are much less likely to mismap, and Clair3 seems extremely powerful and precise to call. Therefore, we could consider the call from long reads as a ""truth set"". . My point is if I give deep variant the ONT ""truth set"" and then the mapping of short illumina reads. Could it be retrained to understand the mapping and calling issues with this kind of genome? I don't have a ""rule"" such as Mendelian violation because my organism is clonal. Therefore, the only possibility of having a ""truth set"" is to trust long reads mapping (Sanger sequencing doesn't work well either; we don't know why). . Is it something doable? I could use other things, such as Python random forests, as suggested by a colleague, but since you have spent a lot of time trying to help me, before, I found it gentlemanly to ask if we can use Deepvariant.; I think the answer is ""Yes, I could"". To be quick ... I have 25 datasets of high-coverage Illumina data. And I'm not sure I will get those datasets resequenced in long reads with enough coverage and N50 (for another reason we don't understand well, DNA extraction is harrowing in rotifers; it often fails or yields highly damaged DNA). Therefore, if I could retrain a model to use the Illumina datasets, that would be great. . My worries are: what does it take in terms of hardware to retrain Deepvariant? I don't have access to a huge GPU. . I found this tutorial: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md . but I am not sure if it is adapted to my case, streamlined, or can be done here, if I understand well this example relies on using Google machines, right?. EDIT: to be perfectly clear it seems to me I need some discussion to understand what you take as a truth set and how you define a bed file with the confidence region. I also would like to know if everything can be done locally",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/716
https://github.com/google/deepvariant/issues/716:1871,Modifiability,adapt,adapted,1871,"tart to have enough material to get long ONT precise reads (the very last one that is accurate at 99.99%, just like a giant PCR); those are much less likely to mismap, and Clair3 seems extremely powerful and precise to call. Therefore, we could consider the call from long reads as a ""truth set"". . My point is if I give deep variant the ONT ""truth set"" and then the mapping of short illumina reads. Could it be retrained to understand the mapping and calling issues with this kind of genome? I don't have a ""rule"" such as Mendelian violation because my organism is clonal. Therefore, the only possibility of having a ""truth set"" is to trust long reads mapping (Sanger sequencing doesn't work well either; we don't know why). . Is it something doable? I could use other things, such as Python random forests, as suggested by a colleague, but since you have spent a lot of time trying to help me, before, I found it gentlemanly to ask if we can use Deepvariant.; I think the answer is ""Yes, I could"". To be quick ... I have 25 datasets of high-coverage Illumina data. And I'm not sure I will get those datasets resequenced in long reads with enough coverage and N50 (for another reason we don't understand well, DNA extraction is harrowing in rotifers; it often fails or yields highly damaged DNA). Therefore, if I could retrain a model to use the Illumina datasets, that would be great. . My worries are: what does it take in terms of hardware to retrain Deepvariant? I don't have access to a huge GPU. . I found this tutorial: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md . but I am not sure if it is adapted to my case, streamlined, or can be done here, if I understand well this example relies on using Google machines, right?. EDIT: to be perfectly clear it seems to me I need some discussion to understand what you take as a truth set and how you define a bed file with the confidence region. I also would like to know if everything can be done locally",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/716
https://github.com/google/deepvariant/issues/716:1707,Security,access,access,1707,"tart to have enough material to get long ONT precise reads (the very last one that is accurate at 99.99%, just like a giant PCR); those are much less likely to mismap, and Clair3 seems extremely powerful and precise to call. Therefore, we could consider the call from long reads as a ""truth set"". . My point is if I give deep variant the ONT ""truth set"" and then the mapping of short illumina reads. Could it be retrained to understand the mapping and calling issues with this kind of genome? I don't have a ""rule"" such as Mendelian violation because my organism is clonal. Therefore, the only possibility of having a ""truth set"" is to trust long reads mapping (Sanger sequencing doesn't work well either; we don't know why). . Is it something doable? I could use other things, such as Python random forests, as suggested by a colleague, but since you have spent a lot of time trying to help me, before, I found it gentlemanly to ask if we can use Deepvariant.; I think the answer is ""Yes, I could"". To be quick ... I have 25 datasets of high-coverage Illumina data. And I'm not sure I will get those datasets resequenced in long reads with enough coverage and N50 (for another reason we don't understand well, DNA extraction is harrowing in rotifers; it often fails or yields highly damaged DNA). Therefore, if I could retrain a model to use the Illumina datasets, that would be great. . My worries are: what does it take in terms of hardware to retrain Deepvariant? I don't have access to a huge GPU. . I found this tutorial: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md . but I am not sure if it is adapted to my case, streamlined, or can be done here, if I understand well this example relies on using Google machines, right?. EDIT: to be perfectly clear it seems to me I need some discussion to understand what you take as a truth set and how you define a bed file with the confidence region. I also would like to know if everything can be done locally",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/716
https://github.com/google/deepvariant/issues/716:2022,Usability,clear,clear,2022,"tart to have enough material to get long ONT precise reads (the very last one that is accurate at 99.99%, just like a giant PCR); those are much less likely to mismap, and Clair3 seems extremely powerful and precise to call. Therefore, we could consider the call from long reads as a ""truth set"". . My point is if I give deep variant the ONT ""truth set"" and then the mapping of short illumina reads. Could it be retrained to understand the mapping and calling issues with this kind of genome? I don't have a ""rule"" such as Mendelian violation because my organism is clonal. Therefore, the only possibility of having a ""truth set"" is to trust long reads mapping (Sanger sequencing doesn't work well either; we don't know why). . Is it something doable? I could use other things, such as Python random forests, as suggested by a colleague, but since you have spent a lot of time trying to help me, before, I found it gentlemanly to ask if we can use Deepvariant.; I think the answer is ""Yes, I could"". To be quick ... I have 25 datasets of high-coverage Illumina data. And I'm not sure I will get those datasets resequenced in long reads with enough coverage and N50 (for another reason we don't understand well, DNA extraction is harrowing in rotifers; it often fails or yields highly damaged DNA). Therefore, if I could retrain a model to use the Illumina datasets, that would be great. . My worries are: what does it take in terms of hardware to retrain Deepvariant? I don't have access to a huge GPU. . I found this tutorial: https://github.com/google/deepvariant/blob/r1.5/docs/deepvariant-training-case-study.md . but I am not sure if it is adapted to my case, streamlined, or can be done here, if I understand well this example relies on using Google machines, right?. EDIT: to be perfectly clear it seems to me I need some discussion to understand what you take as a truth set and how you define a bed file with the confidence region. I also would like to know if everything can be done locally",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/716
https://github.com/google/deepvariant/issues/717:1712,Availability,Error,Error,1712,DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflo,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:249,Deployability,Install,Installation,249,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Slurm based ; - DeepVariant version: deepvariant_1.5.0.sif; - Installation method : singularity image ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command:. projDir=/home1/***/***/deepvaraint/; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:2793,Performance,optimiz,optimized,2793,"n c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); Launcher: Job 7 completed in 0 seconds.; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for **/opt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:2893,Performance,perform,performance-critical,2893,"n c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); Launcher: Job 7 completed in 0 seconds.; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for **/opt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:720,Testability,test,test,720,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Slurm based ; - DeepVariant version: deepvariant_1.5.0.sif; - Installation method : singularity image ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command:. projDir=/home1/***/***/deepvaraint/; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:806,Testability,test,test,806,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Slurm based ; - DeepVariant version: deepvariant_1.5.0.sif; - Installation method : singularity image ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command:. projDir=/home1/***/***/deepvaraint/; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:890,Testability,test,test,890,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Slurm based ; - DeepVariant version: deepvariant_1.5.0.sif; - Installation method : singularity image ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command:. projDir=/home1/***/***/deepvaraint/; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:976,Testability,test,test,976,"m/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Slurm based ; - DeepVariant version: deepvariant_1.5.0.sif; - Installation method : singularity image ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command:. projDir=/home1/***/***/deepvaraint/; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-01",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:1054,Testability,test,test,1054,"m/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Slurm based ; - DeepVariant version: deepvariant_1.5.0.sif; - Installation method : singularity image ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command:. projDir=/home1/***/***/deepvaraint/; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-01",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:1337,Testability,test,test,1337,"ment, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command:. projDir=/home1/***/***/deepvaraint/; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarke",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:1423,Testability,test,test,1423,s to reproduce:**; - Command:. projDir=/home1/***/***/deepvaraint/; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:1507,Testability,test,test,1507,-bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:1593,Testability,test,test,1593,/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/*,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:1671,Testability,test,test,1671,/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/*,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:2312,Testability,test,test,2312,"ds /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:2398,Testability,test,test,2398,"t_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/D",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:2482,Testability,test,test,2482,"_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:2568,Testability,test,test,2568,"-intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:2646,Testability,test,test,2646,"-intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds.; Launcher: Task 2 running job 3 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:3378,Testability,test,test,3378,"cratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); Launcher: Job 7 completed in 0 seconds.; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for **/opt/deepvariant/bin/run_deepvariant: lstat /opt/deepvariant:** no such file or directory; Launcher: Job 8 completed in 0 seconds.; Launcher: Task 0 done. Exiting.; Launcher: Task 1 done. Exiting.; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /sc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:3464,Testability,test,test,3464,"scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); Launcher: Job 7 completed in 0 seconds.; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for **/opt/deepvariant/bin/run_deepvariant: lstat /opt/deepvariant:** no such file or directory; Launcher: Job 8 completed in 0 seconds.; Launcher: Task 0 done. Exiting.; Launcher: Task 1 done. Exiting.; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test. **Any additional context:**. How to",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:3548,Testability,test,test,3548,"_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); Launcher: Job 7 completed in 0 seconds.; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for **/opt/deepvariant/bin/run_deepvariant: lstat /opt/deepvariant:** no such file or directory; Launcher: Job 8 completed in 0 seconds.; Launcher: Task 0 done. Exiting.; Launcher: Task 1 done. Exiting.; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test. **Any additional context:**. How to run deepvariant for multiple bam files parallelly in a slurm based HPC cluster",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:3634,Testability,test,test,3634,"_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); Launcher: Job 7 completed in 0 seconds.; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for **/opt/deepvariant/bin/run_deepvariant: lstat /opt/deepvariant:** no such file or directory; Launcher: Job 8 completed in 0 seconds.; Launcher: Task 0 done. Exiting.; Launcher: Task 1 done. Exiting.; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test. **Any additional context:**. How to run deepvariant for multiple bam files parallelly in a slurm based HPC cluster",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:3712,Testability,test,test,3712,"_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); Launcher: Job 7 completed in 0 seconds.; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for **/opt/deepvariant/bin/run_deepvariant: lstat /opt/deepvariant:** no such file or directory; Launcher: Job 8 completed in 0 seconds.; Launcher: Task 0 done. Exiting.; Launcher: Task 1 done. Exiting.; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test. **Any additional context:**. How to run deepvariant for multiple bam files parallelly in a slurm based HPC cluster",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:4233,Testability,test,test,4233,"_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); Launcher: Job 7 completed in 0 seconds.; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for **/opt/deepvariant/bin/run_deepvariant: lstat /opt/deepvariant:** no such file or directory; Launcher: Job 8 completed in 0 seconds.; Launcher: Task 0 done. Exiting.; Launcher: Task 1 done. Exiting.; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test. **Any additional context:**. How to run deepvariant for multiple bam files parallelly in a slurm based HPC cluster",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:4397,Testability,test,test,4397,"_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); 2023-10-14 18:52:03.562000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 FMA; To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.; Launcher: Job 6 completed in 0 seconds.; Launcher: Task 0 running job 7 on c304-012.ls6.tacc.utexas.edu (apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1); Launcher: Job 7 completed in 0 seconds.; FATAL: could not open image /opt/deepvariant/bin/run_deepvariant: failed to retrieve path for **/opt/deepvariant/bin/run_deepvariant: lstat /opt/deepvariant:** no such file or directory; Launcher: Job 8 completed in 0 seconds.; Launcher: Task 0 done. Exiting.; Launcher: Task 1 done. Exiting.; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test; I1014 18:52:08.193618 23054196500288 run_deepvariant.py:364] Re-using the directory for intermediate results in /scratch/***/***/deepvariant_test/test/output_test. **Any additional context:**. How to run deepvariant for multiple bam files parallelly in a slurm based HPC cluster",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/717:120,Usability,clear,clear,120,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.5/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Slurm based ; - DeepVariant version: deepvariant_1.5.0.sif; - Installation method : singularity image ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . **Steps to reproduce:**; - Command:. projDir=/home1/***/***/deepvaraint/; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL2.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL2.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1; apptainer exec --bind $projDir /home1/***/***/deepvaraint/deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /work/***/***/data/common/human/b37/human_g1k_v37_decoy.fasta --reads /scratch/***/***/deepvariant_test/test/DupMarkedBams/FPL3.DupsMarked.bam --output_vcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.vcf.gz --output_gvcf /scratch/***/***/deepvariant_test/test/output_test/FPL3.output.g.vcf.gz --logging_dir /scratch/***/***/deepvariant_test/test/output_test --intermediate_results_dir /scratch/***/***/deepvariant_test/test/output_test --num_shards 16 2>&1. - Error trace: (if applicable). Launcher: Task 2 running job 1 on c304-012.ls6.tacc.utexas.edu (#!/bin/bash); Launcher: Job 1 completed in 0 seconds.; Launcher: Task 2 running job 2 on c304-012.ls6.tacc.utexas.edu (projDir=/home1/***/***/deepvaraint/); Launcher: Job 2 completed in 0 seconds",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/717
https://github.com/google/deepvariant/issues/718:161,Availability,error,error,161,"Hello, ; I have tested PacBio data on version 1.5 of the deepTrio image. I have performed pbmm2 and whatshap haplotag on the BAM file. However, I encountered an error message stating that the parameter ""use_hp_information"" is missing. What could be the reason for this?. `docker pull google/deepvariant:deeptrio-1.5.0`; ![1697527223540](https://github.com/google/deepvariant/assets/70870741/bd8eca89-b44b-464d-acbd-5889f9e408a8). Looking forward to your reply.; Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/718
https://github.com/google/deepvariant/issues/718:167,Integrability,message,message,167,"Hello, ; I have tested PacBio data on version 1.5 of the deepTrio image. I have performed pbmm2 and whatshap haplotag on the BAM file. However, I encountered an error message stating that the parameter ""use_hp_information"" is missing. What could be the reason for this?. `docker pull google/deepvariant:deeptrio-1.5.0`; ![1697527223540](https://github.com/google/deepvariant/assets/70870741/bd8eca89-b44b-464d-acbd-5889f9e408a8). Looking forward to your reply.; Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/718
https://github.com/google/deepvariant/issues/718:80,Performance,perform,performed,80,"Hello, ; I have tested PacBio data on version 1.5 of the deepTrio image. I have performed pbmm2 and whatshap haplotag on the BAM file. However, I encountered an error message stating that the parameter ""use_hp_information"" is missing. What could be the reason for this?. `docker pull google/deepvariant:deeptrio-1.5.0`; ![1697527223540](https://github.com/google/deepvariant/assets/70870741/bd8eca89-b44b-464d-acbd-5889f9e408a8). Looking forward to your reply.; Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/718
https://github.com/google/deepvariant/issues/718:16,Testability,test,tested,16,"Hello, ; I have tested PacBio data on version 1.5 of the deepTrio image. I have performed pbmm2 and whatshap haplotag on the BAM file. However, I encountered an error message stating that the parameter ""use_hp_information"" is missing. What could be the reason for this?. `docker pull google/deepvariant:deeptrio-1.5.0`; ![1697527223540](https://github.com/google/deepvariant/assets/70870741/bd8eca89-b44b-464d-acbd-5889f9e408a8). Looking forward to your reply.; Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/718
https://github.com/google/deepvariant/issues/720:86,Availability,error,error,86,"hello, ; I tested PacBio data on version 1.4 of the deepTrio image. But I received an error message after more than 100 minutes. parallel: This job failed:; /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref hs37d5.fasta --reads_parent1 HG003.haplotagged.bam --reads_parent2 HG004.haplotagged.bam --reads HG002.haplotagged.bam --examples intermediate_results_dir/[make_examples.tfrecord@32.gz](mailto:make_examples.tfrecord@32.gz) --sample_name HG002 --sample_name_parent1 HG003 --sample_name_parent2 HG004 --add_hp_channel --alt_aligned_pileup diff_channels --gvcf intermediate_results_dir/[gvcf.tfrecord@32.gz](mailto:gvcf.tfrecord@32.gz) --parse_sam_aux_fields --pileup_image_height_child 60 --pileup_image_height_parent 40 --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 0. real 113m56.944s; user 112m32.542s; sys 0m37.407s; I1020 05:16:02.013775 140329939375936 run_deeptrio.py:674] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""hs37d5.fasta"" --reads_parent1 ""HG003.haplotagged.bam"" --reads_parent2 ""HG004.haplotagged.bam"" --reads ""HG002.haplotagged.bam"" --examples ""intermediate_results_dir/[make_examples.tfrecord@32.gz](mailto:make_examples.tfrecord@32.gz)"" --sample_name ""HG002"" --sample_name_parent1 ""HG003"" --sample_name_parent2 ""HG00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/720
https://github.com/google/deepvariant/issues/720:92,Integrability,message,message,92,"hello, ; I tested PacBio data on version 1.4 of the deepTrio image. But I received an error message after more than 100 minutes. parallel: This job failed:; /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref hs37d5.fasta --reads_parent1 HG003.haplotagged.bam --reads_parent2 HG004.haplotagged.bam --reads HG002.haplotagged.bam --examples intermediate_results_dir/[make_examples.tfrecord@32.gz](mailto:make_examples.tfrecord@32.gz) --sample_name HG002 --sample_name_parent1 HG003 --sample_name_parent2 HG004 --add_hp_channel --alt_aligned_pileup diff_channels --gvcf intermediate_results_dir/[gvcf.tfrecord@32.gz](mailto:gvcf.tfrecord@32.gz) --parse_sam_aux_fields --pileup_image_height_child 60 --pileup_image_height_parent 40 --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 0. real 113m56.944s; user 112m32.542s; sys 0m37.407s; I1020 05:16:02.013775 140329939375936 run_deeptrio.py:674] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""hs37d5.fasta"" --reads_parent1 ""HG003.haplotagged.bam"" --reads_parent2 ""HG004.haplotagged.bam"" --reads ""HG002.haplotagged.bam"" --examples ""intermediate_results_dir/[make_examples.tfrecord@32.gz](mailto:make_examples.tfrecord@32.gz)"" --sample_name ""HG002"" --sample_name_parent1 ""HG003"" --sample_name_parent2 ""HG00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/720
https://github.com/google/deepvariant/issues/720:11,Testability,test,tested,11,"hello, ; I tested PacBio data on version 1.4 of the deepTrio image. But I received an error message after more than 100 minutes. parallel: This job failed:; /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref hs37d5.fasta --reads_parent1 HG003.haplotagged.bam --reads_parent2 HG004.haplotagged.bam --reads HG002.haplotagged.bam --examples intermediate_results_dir/[make_examples.tfrecord@32.gz](mailto:make_examples.tfrecord@32.gz) --sample_name HG002 --sample_name_parent1 HG003 --sample_name_parent2 HG004 --add_hp_channel --alt_aligned_pileup diff_channels --gvcf intermediate_results_dir/[gvcf.tfrecord@32.gz](mailto:gvcf.tfrecord@32.gz) --parse_sam_aux_fields --pileup_image_height_child 60 --pileup_image_height_parent 40 --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 0. real 113m56.944s; user 112m32.542s; sys 0m37.407s; I1020 05:16:02.013775 140329939375936 run_deeptrio.py:674] None; Traceback (most recent call last):; File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 688, in; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/deeptrio/run_deeptrio.py"", line 672, in main; subprocess.check_call(command, shell=True, executable='/bin/bash'); File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command 'time seq 0 31 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/deeptrio/make_examples --mode calling --ref ""hs37d5.fasta"" --reads_parent1 ""HG003.haplotagged.bam"" --reads_parent2 ""HG004.haplotagged.bam"" --reads ""HG002.haplotagged.bam"" --examples ""intermediate_results_dir/[make_examples.tfrecord@32.gz](mailto:make_examples.tfrecord@32.gz)"" --sample_name ""HG002"" --sample_name_parent1 ""HG003"" --sample_name_parent2 ""HG00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/720
https://github.com/google/deepvariant/issues/722:89,Availability,error,error,89,"Dear developers,. When trying to train my own data with the latest 1.6.0, there are some error messages popped up:. It seems like some necessary libraries are missing. W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:946,Availability,mainten,maintenance,946,"Dear developers,. When trying to train my own data with the latest 1.6.0, there are some error messages popped up:. It seems like some necessary libraries are missing. W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:1031,Availability,down,downstream,1031,"0, there are some error messages popped up:. It seems like some necessary libraries are missing. W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:1196,Availability,error,error,1196,"mpiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detectin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2004,Availability,checkpoint,checkpoints,2004,"ife in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2127,Availability,checkpoint,checkpoints,2127,"nd Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2221,Availability,Checkpoint,Checkpoint,2221,"RNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2447,Availability,Checkpoint,Checkpoint,2447,"mpiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.dec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2574,Availability,checkpoint,checkpoint,2574,"cs` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2639,Availability,Checkpoint,Checkpoint,2639,"save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2865,Availability,Checkpoint,Checkpoint,2865,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2982,Availability,checkpoint,checkpoint,2982,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3097,Availability,checkpoint,checkpoint,3097,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3125,Availability,checkpoint,checkpoint,3125,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3230,Availability,checkpoint,checkpoint,3230,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3360,Availability,checkpoint,checkpoint,3360,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3388,Availability,checkpoint,checkpoint,3388,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3508,Availability,checkpoint,checkpoint,3508,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3641,Availability,checkpoint,checkpoint,3641,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3669,Availability,checkpoint,checkpoint,3669,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:721,Deployability,install,installed,721,"Dear developers,. When trying to train my own data with the latest 1.6.0, there are some error messages popped up:. It seems like some necessary libraries are missing. W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:962,Deployability,release,release,962,"Dear developers,. When trying to train my own data with the latest 1.6.0, there are some error messages popped up:. It seems like some necessary libraries are missing. W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:95,Integrability,message,messages,95,"Dear developers,. When trying to train my own data with the latest 1.6.0, there are some error messages popped up:. It seems like some necessary libraries are missing. W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:1060,Integrability,depend,dependencies,1060,"0, there are some error messages popped up:. It seems like some necessary libraries are missing. W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:255,Performance,load,load,255,"Dear developers,. When trying to train my own data with the latest 1.6.0, there are some error messages popped up:. It seems like some necessary libraries are missing. W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:1276,Performance,load,loaded,1276,"lugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/.singularity.d/libs; 2023-10-25 17:00:55.064391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the followin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:1487,Performance,load,loaded,1487,"orflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.; /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object return",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:1943,Performance,load,loading,1943,"TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3043,Performance,optimiz,optimizer,3043,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3186,Performance,optimiz,optimizer,3186,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3291,Performance,optimiz,optimizer,3291,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3449,Performance,optimiz,optimizer,3449,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3569,Performance,optimiz,optimizer,3569,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:3730,Performance,optimiz,optimizer,3730,"ion_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; ..... In the final check point folder, there is nothing in the assets folder. Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2175,Safety,Detect,Detecting,2175,"nd Keras-NLP). Then when finishing, I got this error:. Saving model using saved_model format.; WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2593,Safety,Detect,Detecting,2593,"uate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2291,Testability,log,logs,2291,"iled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:01:58.210216 140172092593984 saving_utils.py:359] Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.; W1025 22:02:31.766536 140172092593984 save.py:271] Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/722:2709,Testability,log,logs,2709,"led_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.; INFO:tensorflow:Assets written to: /home/train_new/checkpoints/ckpt-150/assets; I1025 22:02:39.405452 140172092593984 builder_impl.py:797] Assets written to: /home/train_new/checkpoints/ckpt-150/assets; WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; W1025 22:02:44.960290 140172092593984 checkpoint.py:205] Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter; W1025 22:02:44.960591 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.iter; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; W1025 22:02:44.960684 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.decay; WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.awg_optimizer.momentum; W1025 22:02:44.960754 140172092593984 checkpoint.py:214] Value in checkpoint could not be found in the restored objec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/722
https://github.com/google/deepvariant/issues/724:177,Availability,fault,fault,177,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:; Yes. **Describe the issue:**; DeepTrio v1.6 crashes reproducibly with a segmentation fault. **Setup**; - Operating system:; Linux 3.10.0-1160.81.1.el7.x86_64; - DeepVariant version:; 1.6; - Installation method (Docker, built from source, etc.):; Docker image converted to apptainer image which can be downloaded [here](https://downloads.molgeniscloud.org/downloads/vip/images/deepvariant_deeptrio-1.6.0.sif); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Nanopore data derived from [GIAB](https://github.com/genome-in-a-bottle/giab_data_indexes) HG002 mapped to GRCh38. The data subsampled resulting in a 80MB .bam file. **Steps to reproduce:**; - Command:; ```; local args=(); args+=(""--model_type"" ""ONT""); args+=(""--ref"" ""GCA_000001405.15_GRCh38_no_alt_analysis_set.fna""); args+=(""--reads_child"" ""i_am_my_father_HG002_validated.bam""); args+=(""--reads_parent1"" ""i_am_my_father_HG002_copy_validated.bam""); args+=(""--sample_name_child"" ""HG002""); args+=(""--sample_name_parent1"" ""HG002_copy""); args+=(""--output_gvcf_child"" ""i_am_my_father_HG002_chunk_8_snv.g.vcf.gz""); args+=(""--output_gvcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.g.vcf.gz""); args+=(""--num_shards"" ""6""); args+=(""--regions"" ""regions_chunk_8.bed""); args+=(""--intermediate_results_dir"" ""intermediate_results""); args+=(""--output_vcf_child"" ""i_am_my_father_HG002_chunk_8_snv.vcf.gz""); args+=(""--output_vcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.vcf.gz""). ${CMD_DEEPVARIANT_DEEPTRIO} ""${args[@]}""; ```; content of .bed file:; ```; $ cat regions_chunk_8.bed; chr9 0 138394717; ```. stats of .bam file:; ```; chr1 248956422 1319 0; chr2 242193529 929 0; chr3 198295559 749 0; chr4 190214555 1042 0; chr5 181538259 649 0; chr6 170805979 667 0; chr7 159345973 613 0; chr8 145138636 622 0; chr9 138394717 586 0; chr10 133797422 622 0; chr11 135086622 538 0; chr12 133275309 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/724:393,Availability,down,downloaded,393,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:; Yes. **Describe the issue:**; DeepTrio v1.6 crashes reproducibly with a segmentation fault. **Setup**; - Operating system:; Linux 3.10.0-1160.81.1.el7.x86_64; - DeepVariant version:; 1.6; - Installation method (Docker, built from source, etc.):; Docker image converted to apptainer image which can be downloaded [here](https://downloads.molgeniscloud.org/downloads/vip/images/deepvariant_deeptrio-1.6.0.sif); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Nanopore data derived from [GIAB](https://github.com/genome-in-a-bottle/giab_data_indexes) HG002 mapped to GRCh38. The data subsampled resulting in a 80MB .bam file. **Steps to reproduce:**; - Command:; ```; local args=(); args+=(""--model_type"" ""ONT""); args+=(""--ref"" ""GCA_000001405.15_GRCh38_no_alt_analysis_set.fna""); args+=(""--reads_child"" ""i_am_my_father_HG002_validated.bam""); args+=(""--reads_parent1"" ""i_am_my_father_HG002_copy_validated.bam""); args+=(""--sample_name_child"" ""HG002""); args+=(""--sample_name_parent1"" ""HG002_copy""); args+=(""--output_gvcf_child"" ""i_am_my_father_HG002_chunk_8_snv.g.vcf.gz""); args+=(""--output_gvcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.g.vcf.gz""); args+=(""--num_shards"" ""6""); args+=(""--regions"" ""regions_chunk_8.bed""); args+=(""--intermediate_results_dir"" ""intermediate_results""); args+=(""--output_vcf_child"" ""i_am_my_father_HG002_chunk_8_snv.vcf.gz""); args+=(""--output_vcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.vcf.gz""). ${CMD_DEEPVARIANT_DEEPTRIO} ""${args[@]}""; ```; content of .bed file:; ```; $ cat regions_chunk_8.bed; chr9 0 138394717; ```. stats of .bam file:; ```; chr1 248956422 1319 0; chr2 242193529 929 0; chr3 198295559 749 0; chr4 190214555 1042 0; chr5 181538259 649 0; chr6 170805979 667 0; chr7 159345973 613 0; chr8 145138636 622 0; chr9 138394717 586 0; chr10 133797422 622 0; chr11 135086622 538 0; chr12 133275309 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/724:419,Availability,down,downloads,419,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:; Yes. **Describe the issue:**; DeepTrio v1.6 crashes reproducibly with a segmentation fault. **Setup**; - Operating system:; Linux 3.10.0-1160.81.1.el7.x86_64; - DeepVariant version:; 1.6; - Installation method (Docker, built from source, etc.):; Docker image converted to apptainer image which can be downloaded [here](https://downloads.molgeniscloud.org/downloads/vip/images/deepvariant_deeptrio-1.6.0.sif); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Nanopore data derived from [GIAB](https://github.com/genome-in-a-bottle/giab_data_indexes) HG002 mapped to GRCh38. The data subsampled resulting in a 80MB .bam file. **Steps to reproduce:**; - Command:; ```; local args=(); args+=(""--model_type"" ""ONT""); args+=(""--ref"" ""GCA_000001405.15_GRCh38_no_alt_analysis_set.fna""); args+=(""--reads_child"" ""i_am_my_father_HG002_validated.bam""); args+=(""--reads_parent1"" ""i_am_my_father_HG002_copy_validated.bam""); args+=(""--sample_name_child"" ""HG002""); args+=(""--sample_name_parent1"" ""HG002_copy""); args+=(""--output_gvcf_child"" ""i_am_my_father_HG002_chunk_8_snv.g.vcf.gz""); args+=(""--output_gvcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.g.vcf.gz""); args+=(""--num_shards"" ""6""); args+=(""--regions"" ""regions_chunk_8.bed""); args+=(""--intermediate_results_dir"" ""intermediate_results""); args+=(""--output_vcf_child"" ""i_am_my_father_HG002_chunk_8_snv.vcf.gz""); args+=(""--output_vcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.vcf.gz""). ${CMD_DEEPVARIANT_DEEPTRIO} ""${args[@]}""; ```; content of .bed file:; ```; $ cat regions_chunk_8.bed; chr9 0 138394717; ```. stats of .bam file:; ```; chr1 248956422 1319 0; chr2 242193529 929 0; chr3 198295559 749 0; chr4 190214555 1042 0; chr5 181538259 649 0; chr6 170805979 667 0; chr7 159345973 613 0; chr8 145138636 622 0; chr9 138394717 586 0; chr10 133797422 622 0; chr11 135086622 538 0; chr12 133275309 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/724:447,Availability,down,downloads,447,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:; Yes. **Describe the issue:**; DeepTrio v1.6 crashes reproducibly with a segmentation fault. **Setup**; - Operating system:; Linux 3.10.0-1160.81.1.el7.x86_64; - DeepVariant version:; 1.6; - Installation method (Docker, built from source, etc.):; Docker image converted to apptainer image which can be downloaded [here](https://downloads.molgeniscloud.org/downloads/vip/images/deepvariant_deeptrio-1.6.0.sif); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Nanopore data derived from [GIAB](https://github.com/genome-in-a-bottle/giab_data_indexes) HG002 mapped to GRCh38. The data subsampled resulting in a 80MB .bam file. **Steps to reproduce:**; - Command:; ```; local args=(); args+=(""--model_type"" ""ONT""); args+=(""--ref"" ""GCA_000001405.15_GRCh38_no_alt_analysis_set.fna""); args+=(""--reads_child"" ""i_am_my_father_HG002_validated.bam""); args+=(""--reads_parent1"" ""i_am_my_father_HG002_copy_validated.bam""); args+=(""--sample_name_child"" ""HG002""); args+=(""--sample_name_parent1"" ""HG002_copy""); args+=(""--output_gvcf_child"" ""i_am_my_father_HG002_chunk_8_snv.g.vcf.gz""); args+=(""--output_gvcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.g.vcf.gz""); args+=(""--num_shards"" ""6""); args+=(""--regions"" ""regions_chunk_8.bed""); args+=(""--intermediate_results_dir"" ""intermediate_results""); args+=(""--output_vcf_child"" ""i_am_my_father_HG002_chunk_8_snv.vcf.gz""); args+=(""--output_vcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.vcf.gz""). ${CMD_DEEPVARIANT_DEEPTRIO} ""${args[@]}""; ```; content of .bed file:; ```; $ cat regions_chunk_8.bed; chr9 0 138394717; ```. stats of .bam file:; ```; chr1 248956422 1319 0; chr2 242193529 929 0; chr3 198295559 749 0; chr4 190214555 1042 0; chr5 181538259 649 0; chr6 170805979 667 0; chr7 159345973 613 0; chr8 145138636 622 0; chr9 138394717 586 0; chr10 133797422 622 0; chr11 135086622 538 0; chr12 133275309 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/724:7291,Availability,Error,Error,7291,1 6504 0 0; chrUn_KI270588v1 6158 0 0; chrUn_KI270593v1 3041 0 0; chrUn_KI270591v1 5796 0 0; chrUn_KI270330v1 1652 0 0; chrUn_KI270329v1 1040 0 0; chrUn_KI270334v1 1368 0 0; chrUn_KI270333v1 2699 4 0; chrUn_KI270335v1 1048 0 0; chrUn_KI270338v1 1428 0 0; chrUn_KI270340v1 1428 0 0; chrUn_KI270336v1 1026 1 0; chrUn_KI270337v1 1121 0 0; chrUn_KI270363v1 1803 0 0; chrUn_KI270364v1 2855 0 0; chrUn_KI270362v1 3530 0 0; chrUn_KI270366v1 8320 0 0; chrUn_KI270378v1 1048 0 0; chrUn_KI270379v1 1045 0 0; chrUn_KI270389v1 1298 0 0; chrUn_KI270390v1 2387 0 0; chrUn_KI270387v1 1537 0 0; chrUn_KI270395v1 1143 0 0; chrUn_KI270396v1 1880 0 0; chrUn_KI270388v1 1216 0 0; chrUn_KI270394v1 970 0 0; chrUn_KI270386v1 1788 0 0; chrUn_KI270391v1 1484 0 0; chrUn_KI270383v1 1750 0 0; chrUn_KI270393v1 1308 0 0; chrUn_KI270384v1 1658 0 0; chrUn_KI270392v1 971 0 0; chrUn_KI270381v1 1930 0 0; chrUn_KI270385v1 990 0 0; chrUn_KI270382v1 4215 0 0; chrUn_KI270376v1 1136 0 0; chrUn_KI270374v1 2656 0 0; chrUn_KI270372v1 1650 0 0; chrUn_KI270373v1 1451 0 0; chrUn_KI270375v1 2378 0 0; chrUn_KI270371v1 2805 0 0; chrUn_KI270448v1 7992 0 0; chrUn_KI270521v1 7642 0 0; chrUn_GL000195v1 182896 4 0; chrUn_GL000219v1 179198 2 0; chrUn_GL000220v1 161802 37 0; chrUn_GL000224v1 179693 6 0; chrUn_KI270741v1 157432 1 0; chrUn_GL000226v1 15008 48 0; chrUn_GL000213v1 164239 1 0; chrUn_KI270743v1 210658 3 0; chrUn_KI270744v1 168472 13 0; chrUn_KI270745v1 41891 0 0; chrUn_KI270746v1 66486 2 0; chrUn_KI270747v1 198735 2 0; chrUn_KI270748v1 93321 2 0; chrUn_KI270749v1 158759 0 0; chrUn_KI270750v1 148850 0 0; chrUn_KI270751v1 150742 4 0; chrUn_KI270752v1 27745 0 0; chrUn_KI270753v1 62944 1 0; chrUn_KI270754v1 40191 0 0; chrUn_KI270755v1 36723 0 0; chrUn_KI270756v1 79590 3 0; chrUn_KI270757v1 71251 2 0; chrUn_GL000214v1 137718 9 0; chrUn_KI270742v1 186739 9 0; chrUn_GL000216v2 176608 17 0; chrUn_GL000218v1 161147 3 0; chrEBV 171823 10 0; * 0 0 0; ```; - Error trace: (if applicable); ```; Fatal Python error: Segmentation fault.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/724:7339,Availability,error,error,7339,1 6504 0 0; chrUn_KI270588v1 6158 0 0; chrUn_KI270593v1 3041 0 0; chrUn_KI270591v1 5796 0 0; chrUn_KI270330v1 1652 0 0; chrUn_KI270329v1 1040 0 0; chrUn_KI270334v1 1368 0 0; chrUn_KI270333v1 2699 4 0; chrUn_KI270335v1 1048 0 0; chrUn_KI270338v1 1428 0 0; chrUn_KI270340v1 1428 0 0; chrUn_KI270336v1 1026 1 0; chrUn_KI270337v1 1121 0 0; chrUn_KI270363v1 1803 0 0; chrUn_KI270364v1 2855 0 0; chrUn_KI270362v1 3530 0 0; chrUn_KI270366v1 8320 0 0; chrUn_KI270378v1 1048 0 0; chrUn_KI270379v1 1045 0 0; chrUn_KI270389v1 1298 0 0; chrUn_KI270390v1 2387 0 0; chrUn_KI270387v1 1537 0 0; chrUn_KI270395v1 1143 0 0; chrUn_KI270396v1 1880 0 0; chrUn_KI270388v1 1216 0 0; chrUn_KI270394v1 970 0 0; chrUn_KI270386v1 1788 0 0; chrUn_KI270391v1 1484 0 0; chrUn_KI270383v1 1750 0 0; chrUn_KI270393v1 1308 0 0; chrUn_KI270384v1 1658 0 0; chrUn_KI270392v1 971 0 0; chrUn_KI270381v1 1930 0 0; chrUn_KI270385v1 990 0 0; chrUn_KI270382v1 4215 0 0; chrUn_KI270376v1 1136 0 0; chrUn_KI270374v1 2656 0 0; chrUn_KI270372v1 1650 0 0; chrUn_KI270373v1 1451 0 0; chrUn_KI270375v1 2378 0 0; chrUn_KI270371v1 2805 0 0; chrUn_KI270448v1 7992 0 0; chrUn_KI270521v1 7642 0 0; chrUn_GL000195v1 182896 4 0; chrUn_GL000219v1 179198 2 0; chrUn_GL000220v1 161802 37 0; chrUn_GL000224v1 179693 6 0; chrUn_KI270741v1 157432 1 0; chrUn_GL000226v1 15008 48 0; chrUn_GL000213v1 164239 1 0; chrUn_KI270743v1 210658 3 0; chrUn_KI270744v1 168472 13 0; chrUn_KI270745v1 41891 0 0; chrUn_KI270746v1 66486 2 0; chrUn_KI270747v1 198735 2 0; chrUn_KI270748v1 93321 2 0; chrUn_KI270749v1 158759 0 0; chrUn_KI270750v1 148850 0 0; chrUn_KI270751v1 150742 4 0; chrUn_KI270752v1 27745 0 0; chrUn_KI270753v1 62944 1 0; chrUn_KI270754v1 40191 0 0; chrUn_KI270755v1 36723 0 0; chrUn_KI270756v1 79590 3 0; chrUn_KI270757v1 71251 2 0; chrUn_GL000214v1 137718 9 0; chrUn_KI270742v1 186739 9 0; chrUn_GL000216v2 176608 17 0; chrUn_GL000218v1 161147 3 0; chrEBV 171823 10 0; * 0 0 0; ```; - Error trace: (if applicable); ```; Fatal Python error: Segmentation fault.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/724:7359,Availability,fault,fault,7359,1 6504 0 0; chrUn_KI270588v1 6158 0 0; chrUn_KI270593v1 3041 0 0; chrUn_KI270591v1 5796 0 0; chrUn_KI270330v1 1652 0 0; chrUn_KI270329v1 1040 0 0; chrUn_KI270334v1 1368 0 0; chrUn_KI270333v1 2699 4 0; chrUn_KI270335v1 1048 0 0; chrUn_KI270338v1 1428 0 0; chrUn_KI270340v1 1428 0 0; chrUn_KI270336v1 1026 1 0; chrUn_KI270337v1 1121 0 0; chrUn_KI270363v1 1803 0 0; chrUn_KI270364v1 2855 0 0; chrUn_KI270362v1 3530 0 0; chrUn_KI270366v1 8320 0 0; chrUn_KI270378v1 1048 0 0; chrUn_KI270379v1 1045 0 0; chrUn_KI270389v1 1298 0 0; chrUn_KI270390v1 2387 0 0; chrUn_KI270387v1 1537 0 0; chrUn_KI270395v1 1143 0 0; chrUn_KI270396v1 1880 0 0; chrUn_KI270388v1 1216 0 0; chrUn_KI270394v1 970 0 0; chrUn_KI270386v1 1788 0 0; chrUn_KI270391v1 1484 0 0; chrUn_KI270383v1 1750 0 0; chrUn_KI270393v1 1308 0 0; chrUn_KI270384v1 1658 0 0; chrUn_KI270392v1 971 0 0; chrUn_KI270381v1 1930 0 0; chrUn_KI270385v1 990 0 0; chrUn_KI270382v1 4215 0 0; chrUn_KI270376v1 1136 0 0; chrUn_KI270374v1 2656 0 0; chrUn_KI270372v1 1650 0 0; chrUn_KI270373v1 1451 0 0; chrUn_KI270375v1 2378 0 0; chrUn_KI270371v1 2805 0 0; chrUn_KI270448v1 7992 0 0; chrUn_KI270521v1 7642 0 0; chrUn_GL000195v1 182896 4 0; chrUn_GL000219v1 179198 2 0; chrUn_GL000220v1 161802 37 0; chrUn_GL000224v1 179693 6 0; chrUn_KI270741v1 157432 1 0; chrUn_GL000226v1 15008 48 0; chrUn_GL000213v1 164239 1 0; chrUn_KI270743v1 210658 3 0; chrUn_KI270744v1 168472 13 0; chrUn_KI270745v1 41891 0 0; chrUn_KI270746v1 66486 2 0; chrUn_KI270747v1 198735 2 0; chrUn_KI270748v1 93321 2 0; chrUn_KI270749v1 158759 0 0; chrUn_KI270750v1 148850 0 0; chrUn_KI270751v1 150742 4 0; chrUn_KI270752v1 27745 0 0; chrUn_KI270753v1 62944 1 0; chrUn_KI270754v1 40191 0 0; chrUn_KI270755v1 36723 0 0; chrUn_KI270756v1 79590 3 0; chrUn_KI270757v1 71251 2 0; chrUn_GL000214v1 137718 9 0; chrUn_KI270742v1 186739 9 0; chrUn_GL000216v2 176608 17 0; chrUn_GL000218v1 161147 3 0; chrEBV 171823 10 0; * 0 0 0; ```; - Error trace: (if applicable); ```; Fatal Python error: Segmentation fault.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/724:282,Deployability,Install,Installation,282,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:; Yes. **Describe the issue:**; DeepTrio v1.6 crashes reproducibly with a segmentation fault. **Setup**; - Operating system:; Linux 3.10.0-1160.81.1.el7.x86_64; - DeepVariant version:; 1.6; - Installation method (Docker, built from source, etc.):; Docker image converted to apptainer image which can be downloaded [here](https://downloads.molgeniscloud.org/downloads/vip/images/deepvariant_deeptrio-1.6.0.sif); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); Nanopore data derived from [GIAB](https://github.com/genome-in-a-bottle/giab_data_indexes) HG002 mapped to GRCh38. The data subsampled resulting in a 80MB .bam file. **Steps to reproduce:**; - Command:; ```; local args=(); args+=(""--model_type"" ""ONT""); args+=(""--ref"" ""GCA_000001405.15_GRCh38_no_alt_analysis_set.fna""); args+=(""--reads_child"" ""i_am_my_father_HG002_validated.bam""); args+=(""--reads_parent1"" ""i_am_my_father_HG002_copy_validated.bam""); args+=(""--sample_name_child"" ""HG002""); args+=(""--sample_name_parent1"" ""HG002_copy""); args+=(""--output_gvcf_child"" ""i_am_my_father_HG002_chunk_8_snv.g.vcf.gz""); args+=(""--output_gvcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.g.vcf.gz""); args+=(""--num_shards"" ""6""); args+=(""--regions"" ""regions_chunk_8.bed""); args+=(""--intermediate_results_dir"" ""intermediate_results""); args+=(""--output_vcf_child"" ""i_am_my_father_HG002_chunk_8_snv.vcf.gz""); args+=(""--output_vcf_parent1"" ""i_am_my_father_HG002_copy_chunk_8_snv.vcf.gz""). ${CMD_DEEPVARIANT_DEEPTRIO} ""${args[@]}""; ```; content of .bed file:; ```; $ cat regions_chunk_8.bed; chr9 0 138394717; ```. stats of .bam file:; ```; chr1 248956422 1319 0; chr2 242193529 929 0; chr3 198295559 749 0; chr4 190214555 1042 0; chr5 181538259 649 0; chr6 170805979 667 0; chr7 159345973 613 0; chr8 145138636 622 0; chr9 138394717 586 0; chr10 133797422 622 0; chr11 135086622 538 0; chr12 133275309 4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/724:8400,Testability,test,test,8400,"270744v1 168472 13 0; chrUn_KI270745v1 41891 0 0; chrUn_KI270746v1 66486 2 0; chrUn_KI270747v1 198735 2 0; chrUn_KI270748v1 93321 2 0; chrUn_KI270749v1 158759 0 0; chrUn_KI270750v1 148850 0 0; chrUn_KI270751v1 150742 4 0; chrUn_KI270752v1 27745 0 0; chrUn_KI270753v1 62944 1 0; chrUn_KI270754v1 40191 0 0; chrUn_KI270755v1 36723 0 0; chrUn_KI270756v1 79590 3 0; chrUn_KI270757v1 71251 2 0; chrUn_GL000214v1 137718 9 0; chrUn_KI270742v1 186739 9 0; chrUn_GL000216v2 176608 17 0; chrUn_GL000218v1 161147 3 0; chrEBV 171823 10 0; * 0 0 0; ```; - Error trace: (if applicable); ```; Fatal Python error: Segmentation fault. Current thread 0x00002b91584d7740 (most recent call first):; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 67 in get_candidate_positions; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2047 in candidates_in_region; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 424 in main; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/absl_py/absl/app.py"", line 258 in _run_main; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/absl_py/absl/app.py"", line 312 in run; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 434 in <module>; ```; **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Unfortunately I cannot run Docker on my environment. **Any additional context:**; The issue cannot be reproduced with `WES` model and Illumina WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/724:8436,Testability,test,test,8436,"270744v1 168472 13 0; chrUn_KI270745v1 41891 0 0; chrUn_KI270746v1 66486 2 0; chrUn_KI270747v1 198735 2 0; chrUn_KI270748v1 93321 2 0; chrUn_KI270749v1 158759 0 0; chrUn_KI270750v1 148850 0 0; chrUn_KI270751v1 150742 4 0; chrUn_KI270752v1 27745 0 0; chrUn_KI270753v1 62944 1 0; chrUn_KI270754v1 40191 0 0; chrUn_KI270755v1 36723 0 0; chrUn_KI270756v1 79590 3 0; chrUn_KI270757v1 71251 2 0; chrUn_GL000214v1 137718 9 0; chrUn_KI270742v1 186739 9 0; chrUn_GL000216v2 176608 17 0; chrUn_GL000218v1 161147 3 0; chrEBV 171823 10 0; * 0 0 0; ```; - Error trace: (if applicable); ```; Fatal Python error: Segmentation fault. Current thread 0x00002b91584d7740 (most recent call first):; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deepvariant/very_sensitive_caller.py"", line 67 in get_candidate_positions; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2047 in candidates_in_region; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 424 in main; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/absl_py/absl/app.py"", line 258 in _run_main; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/absl_py/absl/app.py"", line 312 in run; File ""/tmp/Bazel.runfiles_n9w2sjmt/runfiles/com_google_deepvariant/deeptrio/make_examples.py"", line 434 in <module>; ```; **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?; Unfortunately I cannot run Docker on my environment. **Any additional context:**; The issue cannot be reproduced with `WES` model and Illumina WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/724
https://github.com/google/deepvariant/issues/725:88,Availability,error,error,88,"Hello,; I tested the T7 model on WGS data using DV1.6, but I keep getting the following error message. I generated the test data using the T7 platform for sequencing. Could you please tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:559,Availability,Error,Error,559,"Hello,; I tested the T7 model on WGS data using DV1.6, but I keep getting the following error message. I generated the test data using the T7 platform for sequencing. Could you please tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:808,Availability,checkpoint,checkpoint,808,"Hello,; I tested the T7 model on WGS data using DV1.6, but I keep getting the following error message. I generated the test data using the T7 platform for sequencing. Could you please tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:1056,Availability,mainten,maintenance,1056,"e following error message. I generated the test data using the T7 platform for sequencing. Could you please tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:1141,Availability,down,downstream,1141,"se tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels.; input_shape = imagenet_utils.obtain_input_shape(; Traceback (most recent call last):; F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:3954,Availability,error,error,3954,"_exoaulhd/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 555, in call_variants; model = modeling.inceptionv3(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 312, in inceptionv3; backbone = add_l2_regularizers(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 99, in add_l2_regularizers; model.save_weights(tmp_weights_path); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 562, in __init__; fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 241, in make_fid; fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 122, in h5py.h5f.create; OSError: [Errno 5] Unable to synchronously create file (unable to lock file, errno = 5, error message = 'Input/output error'); Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 711, in main; for line in proc.stdout:; KeyboardInterrupt; ```; Looking forward to your reply.; Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:3984,Availability,error,error,3984,"_exoaulhd/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 555, in call_variants; model = modeling.inceptionv3(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 312, in inceptionv3; backbone = add_l2_regularizers(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 99, in add_l2_regularizers; model.save_weights(tmp_weights_path); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 562, in __init__; fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 241, in make_fid; fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 122, in h5py.h5f.create; OSError: [Errno 5] Unable to synchronously create file (unable to lock file, errno = 5, error message = 'Input/output error'); Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 711, in main; for line in proc.stdout:; KeyboardInterrupt; ```; Looking forward to your reply.; Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:1072,Deployability,release,release,1072,"e following error message. I generated the test data using the T7 platform for sequencing. Could you please tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:94,Integrability,message,message,94,"Hello,; I tested the T7 model on WGS data using DV1.6, but I keep getting the following error message. I generated the test data using the T7 platform for sequencing. Could you please tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:565,Integrability,message,message,565,"Hello,; I tested the T7 model on WGS data using DV1.6, but I keep getting the following error message. I generated the test data using the T7 platform for sequencing. Could you please tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:1170,Integrability,depend,dependencies,1170,"se tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels.; input_shape = imagenet_utils.obtain_input_shape(; Traceback (most recent call last):; F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:3735,Integrability,wrap,wrapper,3735,"_exoaulhd/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 555, in call_variants; model = modeling.inceptionv3(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 312, in inceptionv3; backbone = add_l2_regularizers(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 99, in add_l2_regularizers; model.save_weights(tmp_weights_path); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 562, in __init__; fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 241, in make_fid; fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 122, in h5py.h5f.create; OSError: [Errno 5] Unable to synchronously create file (unable to lock file, errno = 5, error message = 'Input/output error'); Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 711, in main; for line in proc.stdout:; KeyboardInterrupt; ```; Looking forward to your reply.; Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:3806,Integrability,wrap,wrapper,3806,"_exoaulhd/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 555, in call_variants; model = modeling.inceptionv3(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 312, in inceptionv3; backbone = add_l2_regularizers(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 99, in add_l2_regularizers; model.save_weights(tmp_weights_path); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 562, in __init__; fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 241, in make_fid; fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 122, in h5py.h5f.create; OSError: [Errno 5] Unable to synchronously create file (unable to lock file, errno = 5, error message = 'Input/output error'); Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 711, in main; for line in proc.stdout:; KeyboardInterrupt; ```; Looking forward to your reply.; Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:3960,Integrability,message,message,3960,"_exoaulhd/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 555, in call_variants; model = modeling.inceptionv3(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 312, in inceptionv3; backbone = add_l2_regularizers(; File ""/work/tmp_dir/Bazel.runfiles_exoaulhd/runfiles/com_google_deepvariant/deepvariant/keras_modeling.py"", line 99, in add_l2_regularizers; model.save_weights(tmp_weights_path); File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler; raise e.with_traceback(filtered_tb) from None; File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 562, in __init__; fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr); File ""/usr/local/lib/python3.8/dist-packages/h5py/_hl/files.py"", line 241, in make_fid; fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl); File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper; File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper; File ""h5py/h5f.pyx"", line 122, in h5py.h5f.create; OSError: [Errno 5] Unable to synchronously create file (unable to lock file, errno = 5, error message = 'Input/output error'); Traceback (most recent call last):; File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>; app.run(main); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run; _run_main(main, args); File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/opt/deepvariant/bin/run_deepvariant.py"", line 711, in main; for line in proc.stdout:; KeyboardInterrupt; ```; Looking forward to your reply.; Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:10,Testability,test,tested,10,"Hello,; I tested the T7 model on WGS data using DV1.6, but I keep getting the following error message. I generated the test data using the T7 platform for sequencing. Could you please tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/725:119,Testability,test,test,119,"Hello,; I tested the T7 model on WGS data using DV1.6, but I keep getting the following error message. I generated the test data using the T7 platform for sequencing. Could you please tell me what went wrong?; My cmd:; ```; /opt/deepvariant/bin/run_deepvariant \; --model_type WGS \; --ref ${fasta} \; --reads ${Input.bam} \; --output_vcf output/output.vcf.gz \; --output_gvcf output/output.g.vcf.gz \; --num_shards 32 \; --intermediate_results_dir output/intermediate_results_dir \; --regions chr20 \; --customized_model model/weights-51-0.995354.ckpt; ```. Error message:; ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""output/intermediate_results_dir/make_examples.tfreco; rd@42.gz"" --checkpoint ""model/weights-51-0.995354.ckpt"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; I1102 03:54:58.936793 139651363960640 call_variants.py:471] Total 1 writing processes started.; I1102 03:55:00.378331 139651363960640 dv_utils.py:365] From output/intermediate_results_dir/make_examples.tfrecord-00000-of-00042.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19].; I1102 03:55:00.378495 139651363960640 call_variants.py:506] Shape of input examples: [100, 221, 7]; I1102 03:55:00.381343 139651363960640 call_variants.py:510] Use saved model: False; /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/725
https://github.com/google/deepvariant/issues/726:204,Availability,error,error,204,"Dear Developers,. I compared the Snp calling results between V1.5 and V1.6 with a trio from a non-model species (a pair of parents and offspring). I used percentages of sites with violations of Mendelian error as a proxy. Results from V1.5 (WGS default model): 24%; Results from V1.6 (WGS default model): 40%. Also, results from V1.6 with the SLIM model (WGS default) from V1.5 show 24% of Mendelian errors. All other parameters and settings are the same except for the version.; It seems the newly trained model from V1.6 has a huge influence, and I'm not sure if this is a good sign (with significantly more Mendelian errors). Could you please look into this?. Any help and discussion would be appreciated. Thank you; Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/726
https://github.com/google/deepvariant/issues/726:400,Availability,error,errors,400,"Dear Developers,. I compared the Snp calling results between V1.5 and V1.6 with a trio from a non-model species (a pair of parents and offspring). I used percentages of sites with violations of Mendelian error as a proxy. Results from V1.5 (WGS default model): 24%; Results from V1.6 (WGS default model): 40%. Also, results from V1.6 with the SLIM model (WGS default) from V1.5 show 24% of Mendelian errors. All other parameters and settings are the same except for the version.; It seems the newly trained model from V1.6 has a huge influence, and I'm not sure if this is a good sign (with significantly more Mendelian errors). Could you please look into this?. Any help and discussion would be appreciated. Thank you; Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/726
https://github.com/google/deepvariant/issues/726:620,Availability,error,errors,620,"Dear Developers,. I compared the Snp calling results between V1.5 and V1.6 with a trio from a non-model species (a pair of parents and offspring). I used percentages of sites with violations of Mendelian error as a proxy. Results from V1.5 (WGS default model): 24%; Results from V1.6 (WGS default model): 40%. Also, results from V1.6 with the SLIM model (WGS default) from V1.5 show 24% of Mendelian errors. All other parameters and settings are the same except for the version.; It seems the newly trained model from V1.6 has a huge influence, and I'm not sure if this is a good sign (with significantly more Mendelian errors). Could you please look into this?. Any help and discussion would be appreciated. Thank you; Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/726
https://github.com/google/deepvariant/issues/727:238,Availability,error,error,238,"I want to change the source code of DeepVariant on Ubuntu 20.04, so I need to build it from source. I run the ./build-prereq.sh and meet the question. My user is root. Does anyone can help me, thank you very much. The question is below:. error: subprocess-exited-with-error; ; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [57 lines of output]; [proxychains] DLL init: proxychains-ng 4.16; Running from numpy source directory.; setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates; run_build = parse_setuppy_commands(); [proxychains] DLL init: proxychains-ng 4.16; [proxychains] DLL init: proxychains-ng 4.16; ; Error compiling Cython file:; ------------------------------------------------------------; ...; for i in range(1, RK_STATE_LEN):; self.rng_state.key[i] = val[i]; self.rng_state.pos = i; ; self._bitgen.state = &self.rng_state; self._bitgen.next_uint64 = &mt19937_uint64; ^; ------------------------------------------------------------; ; _mt19937.pyx:138:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to type 'uint64_t (void *) except? -1 nogil'.; Processing numpy/random/_bounded_integers.pxd.in; Processing numpy/random/_mt19937.pyx; Traceback (most recent call last):; File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 235, in <module>; main(); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 231, in main; find_process_files(root_dir); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 222, in find_process_files; process(root_dir, fromfile, tofile, function, hash_db); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 188, in process; processor_function(fromfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:268,Availability,error,error,268,"I want to change the source code of DeepVariant on Ubuntu 20.04, so I need to build it from source. I run the ./build-prereq.sh and meet the question. My user is root. Does anyone can help me, thank you very much. The question is below:. error: subprocess-exited-with-error; ; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [57 lines of output]; [proxychains] DLL init: proxychains-ng 4.16; Running from numpy source directory.; setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates; run_build = parse_setuppy_commands(); [proxychains] DLL init: proxychains-ng 4.16; [proxychains] DLL init: proxychains-ng 4.16; ; Error compiling Cython file:; ------------------------------------------------------------; ...; for i in range(1, RK_STATE_LEN):; self.rng_state.key[i] = val[i]; self.rng_state.pos = i; ; self._bitgen.state = &self.rng_state; self._bitgen.next_uint64 = &mt19937_uint64; ^; ------------------------------------------------------------; ; _mt19937.pyx:138:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to type 'uint64_t (void *) except? -1 nogil'.; Processing numpy/random/_bounded_integers.pxd.in; Processing numpy/random/_mt19937.pyx; Traceback (most recent call last):; File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 235, in <module>; main(); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 231, in main; find_process_files(root_dir); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 222, in find_process_files; process(root_dir, fromfile, tofile, function, hash_db); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 188, in process; processor_function(fromfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:724,Availability,Error,Error,724,"I want to change the source code of DeepVariant on Ubuntu 20.04, so I need to build it from source. I run the ./build-prereq.sh and meet the question. My user is root. Does anyone can help me, thank you very much. The question is below:. error: subprocess-exited-with-error; ; × Preparing metadata (pyproject.toml) did not run successfully.; │ exit code: 1; ╰─> [57 lines of output]; [proxychains] DLL init: proxychains-ng 4.16; Running from numpy source directory.; setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates; run_build = parse_setuppy_commands(); [proxychains] DLL init: proxychains-ng 4.16; [proxychains] DLL init: proxychains-ng 4.16; ; Error compiling Cython file:; ------------------------------------------------------------; ...; for i in range(1, RK_STATE_LEN):; self.rng_state.key[i] = val[i]; self.rng_state.pos = i; ; self._bitgen.state = &self.rng_state; self._bitgen.next_uint64 = &mt19937_uint64; ^; ------------------------------------------------------------; ; _mt19937.pyx:138:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to type 'uint64_t (void *) except? -1 nogil'.; Processing numpy/random/_bounded_integers.pxd.in; Processing numpy/random/_mt19937.pyx; Traceback (most recent call last):; File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 235, in <module>; main(); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 231, in main; find_process_files(root_dir); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 222, in find_process_files; process(root_dir, fromfile, tofile, function, hash_db); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 188, in process; processor_function(fromfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:3795,Availability,error,error,3795,"unction(fromfile, tofile); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 77, in process_pyx; subprocess.check_call(; File ""/opt/miniconda3/lib/python3.9/subprocess.py"", line 373, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/opt/miniconda3/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_mt19937.c', '_mt19937.pyx']' returned non-zero exit status 1.; Cythonizing sources; Traceback (most recent call last):; File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>; main(); File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main; json_out['return_val'] = hook(**hook_input['kwargs']); File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel; return hook(metadata_directory, config_settings); File ""/tmp/pip-build-env-6gh6ol84/overlay/lib/python3.9/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel; self.run_setup(); File ""/tmp/pip-build-env-6gh6ol84/overlay/lib/python3.9/site-packages/setuptools/build_meta.py"", line 248, in run_setup; super(_BuildMetaLegacyBackend,; File ""/tmp/pip-build-env-6gh6ol84/overlay/lib/python3.9/site-packages/setuptools/build_meta.py"", line 142, in run_setup; exec(compile(code, __file__, 'exec'), locals()); File ""setup.py"", line 499, in <module>; setup_package(); File ""setup.py"", line 479, in setup_package; generate_cython(); File ""setup.py"", line 274, in generate_cython; raise RuntimeError(""Running cythonize failed!""); RuntimeError: Running cythonize failed!; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:3870,Availability,error,error,3870,"unction(fromfile, tofile); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 77, in process_pyx; subprocess.check_call(; File ""/opt/miniconda3/lib/python3.9/subprocess.py"", line 373, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/opt/miniconda3/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_mt19937.c', '_mt19937.pyx']' returned non-zero exit status 1.; Cythonizing sources; Traceback (most recent call last):; File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>; main(); File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main; json_out['return_val'] = hook(**hook_input['kwargs']); File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel; return hook(metadata_directory, config_settings); File ""/tmp/pip-build-env-6gh6ol84/overlay/lib/python3.9/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel; self.run_setup(); File ""/tmp/pip-build-env-6gh6ol84/overlay/lib/python3.9/site-packages/setuptools/build_meta.py"", line 248, in run_setup; super(_BuildMetaLegacyBackend,; File ""/tmp/pip-build-env-6gh6ol84/overlay/lib/python3.9/site-packages/setuptools/build_meta.py"", line 142, in run_setup; exec(compile(code, __file__, 'exec'), locals()); File ""setup.py"", line 499, in <module>; setup_package(); File ""setup.py"", line 479, in setup_package; generate_cython(); File ""setup.py"", line 274, in generate_cython; raise RuntimeError(""Running cythonize failed!""); RuntimeError: Running cythonize failed!; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:3919,Availability,error,error,3919,"unction(fromfile, tofile); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 77, in process_pyx; subprocess.check_call(; File ""/opt/miniconda3/lib/python3.9/subprocess.py"", line 373, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/opt/miniconda3/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_mt19937.c', '_mt19937.pyx']' returned non-zero exit status 1.; Cythonizing sources; Traceback (most recent call last):; File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>; main(); File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main; json_out['return_val'] = hook(**hook_input['kwargs']); File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel; return hook(metadata_directory, config_settings); File ""/tmp/pip-build-env-6gh6ol84/overlay/lib/python3.9/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel; self.run_setup(); File ""/tmp/pip-build-env-6gh6ol84/overlay/lib/python3.9/site-packages/setuptools/build_meta.py"", line 248, in run_setup; super(_BuildMetaLegacyBackend,; File ""/tmp/pip-build-env-6gh6ol84/overlay/lib/python3.9/site-packages/setuptools/build_meta.py"", line 142, in run_setup; exec(compile(code, __file__, 'exec'), locals()); File ""setup.py"", line 499, in <module>; setup_package(); File ""setup.py"", line 479, in setup_package; generate_cython(); File ""setup.py"", line 274, in generate_cython; raise RuntimeError(""Running cythonize failed!""); RuntimeError: Running cythonize failed!; [end of output]; ; note: This error originates from a subprocess, and is likely not a problem with pip.; error: metadata-generation-failed. × Encountered error while generating package metadata.; ╰─> See above for output.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:1431,Deployability,install,install-,1431,"om numpy source directory.; setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates; run_build = parse_setuppy_commands(); [proxychains] DLL init: proxychains-ng 4.16; [proxychains] DLL init: proxychains-ng 4.16; ; Error compiling Cython file:; ------------------------------------------------------------; ...; for i in range(1, RK_STATE_LEN):; self.rng_state.key[i] = val[i]; self.rng_state.pos = i; ; self._bitgen.state = &self.rng_state; self._bitgen.next_uint64 = &mt19937_uint64; ^; ------------------------------------------------------------; ; _mt19937.pyx:138:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to type 'uint64_t (void *) except? -1 nogil'.; Processing numpy/random/_bounded_integers.pxd.in; Processing numpy/random/_mt19937.pyx; Traceback (most recent call last):; File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 235, in <module>; main(); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 231, in main; find_process_files(root_dir); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 222, in find_process_files; process(root_dir, fromfile, tofile, function, hash_db); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 188, in process; processor_function(fromfile, tofile); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 77, in process_pyx; subprocess.check_call(; File ""/opt/miniconda3/lib/python3.9/subprocess.py"", line 373, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/opt/miniconda3/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_mt19937.c', '_mt19937.pyx']' returned non-zero exit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:1554,Deployability,install,install-,1554,"rces and expanding templates; run_build = parse_setuppy_commands(); [proxychains] DLL init: proxychains-ng 4.16; [proxychains] DLL init: proxychains-ng 4.16; ; Error compiling Cython file:; ------------------------------------------------------------; ...; for i in range(1, RK_STATE_LEN):; self.rng_state.key[i] = val[i]; self.rng_state.pos = i; ; self._bitgen.state = &self.rng_state; self._bitgen.next_uint64 = &mt19937_uint64; ^; ------------------------------------------------------------; ; _mt19937.pyx:138:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to type 'uint64_t (void *) except? -1 nogil'.; Processing numpy/random/_bounded_integers.pxd.in; Processing numpy/random/_mt19937.pyx; Traceback (most recent call last):; File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 235, in <module>; main(); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 231, in main; find_process_files(root_dir); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 222, in find_process_files; process(root_dir, fromfile, tofile, function, hash_db); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 188, in process; processor_function(fromfile, tofile); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 77, in process_pyx; subprocess.check_call(; File ""/opt/miniconda3/lib/python3.9/subprocess.py"", line 373, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/opt/miniconda3/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_mt19937.c', '_mt19937.pyx']' returned non-zero exit status 1.; Cythonizing sources; Traceback (most recent call last):; File ""/root/.local/lib/python3.9/site-packages/pip/_vendo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:1695,Deployability,install,install-,1695,"nit: proxychains-ng 4.16; ; Error compiling Cython file:; ------------------------------------------------------------; ...; for i in range(1, RK_STATE_LEN):; self.rng_state.key[i] = val[i]; self.rng_state.pos = i; ; self._bitgen.state = &self.rng_state; self._bitgen.next_uint64 = &mt19937_uint64; ^; ------------------------------------------------------------; ; _mt19937.pyx:138:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to type 'uint64_t (void *) except? -1 nogil'.; Processing numpy/random/_bounded_integers.pxd.in; Processing numpy/random/_mt19937.pyx; Traceback (most recent call last):; File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 235, in <module>; main(); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 231, in main; find_process_files(root_dir); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 222, in find_process_files; process(root_dir, fromfile, tofile, function, hash_db); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 188, in process; processor_function(fromfile, tofile); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 77, in process_pyx; subprocess.check_call(; File ""/opt/miniconda3/lib/python3.9/subprocess.py"", line 373, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/opt/miniconda3/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_mt19937.c', '_mt19937.pyx']' returned non-zero exit status 1.; Cythonizing sources; Traceback (most recent call last):; File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>; main(); File ""/root/.local/lib/python3.9/site-packages/pip/_ve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:1876,Deployability,install,install-,1876,"lf.rng_state.key[i] = val[i]; self.rng_state.pos = i; ; self._bitgen.state = &self.rng_state; self._bitgen.next_uint64 = &mt19937_uint64; ^; ------------------------------------------------------------; ; _mt19937.pyx:138:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to type 'uint64_t (void *) except? -1 nogil'.; Processing numpy/random/_bounded_integers.pxd.in; Processing numpy/random/_mt19937.pyx; Traceback (most recent call last):; File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 235, in <module>; main(); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 231, in main; find_process_files(root_dir); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 222, in find_process_files; process(root_dir, fromfile, tofile, function, hash_db); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 188, in process; processor_function(fromfile, tofile); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 77, in process_pyx; subprocess.check_call(; File ""/opt/miniconda3/lib/python3.9/subprocess.py"", line 373, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/opt/miniconda3/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_mt19937.c', '_mt19937.pyx']' returned non-zero exit status 1.; Cythonizing sources; Traceback (most recent call last):; File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>; main(); File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main; json_out['return_val'] = hook(**hook_input['kwargs']); File ""/root/.local/lib/python3.9/site",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/727:2028,Deployability,install,install-,2028,"----------------------------------; ; _mt19937.pyx:138:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to type 'uint64_t (void *) except? -1 nogil'.; Processing numpy/random/_bounded_integers.pxd.in; Processing numpy/random/_mt19937.pyx; Traceback (most recent call last):; File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 235, in <module>; main(); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 231, in main; find_process_files(root_dir); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 222, in find_process_files; process(root_dir, fromfile, tofile, function, hash_db); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 188, in process; processor_function(fromfile, tofile); File ""/tmp/pip-install-jpvzz1fb/numpy_99473a9ff1d94f3fae4c587acb96b3c1/tools/cythonize.py"", line 77, in process_pyx; subprocess.check_call(; File ""/opt/miniconda3/lib/python3.9/subprocess.py"", line 373, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/opt/miniconda3/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_mt19937.c', '_mt19937.pyx']' returned non-zero exit status 1.; Cythonizing sources; Traceback (most recent call last):; File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>; main(); File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main; json_out['return_val'] = hook(**hook_input['kwargs']); File ""/root/.local/lib/python3.9/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel; return hook(metadata_directory, config_settings); Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/727
https://github.com/google/deepvariant/issues/730:306,Deployability,install,install,306,"Traceback (most recent call last):; File ""get-pip.py"", line 32992, in <module>; main(); File ""get-pip.py"", line 135, in main; bootstrap(tmpdir=tmpdir); File ""get-pip.py"", line 111, in bootstrap; monkeypatch_for_cert(tmpdir); File ""get-pip.py"", line 92, in monkeypatch_for_cert; from pip._internal.commands.install import InstallCommand; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/commands/__init__.py"", line 9, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/base_command.py"", line 15, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/cmdoptions.py"", line 24, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/parser.py"", line 12, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/configuration.py"", line 26, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/logging.py"", line 29, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/misc.py"", line 44, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/__init__.py"", line 66, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/_distutils.py"", line 20, in <module>; ModuleNotFoundError: No module named 'distutils.cmd'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/730
https://github.com/google/deepvariant/issues/730:321,Deployability,Install,InstallCommand,321,"Traceback (most recent call last):; File ""get-pip.py"", line 32992, in <module>; main(); File ""get-pip.py"", line 135, in main; bootstrap(tmpdir=tmpdir); File ""get-pip.py"", line 111, in bootstrap; monkeypatch_for_cert(tmpdir); File ""get-pip.py"", line 92, in monkeypatch_for_cert; from pip._internal.commands.install import InstallCommand; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/commands/__init__.py"", line 9, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/base_command.py"", line 15, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/cmdoptions.py"", line 24, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/parser.py"", line 12, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/configuration.py"", line 26, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/logging.py"", line 29, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/misc.py"", line 44, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/__init__.py"", line 66, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/_distutils.py"", line 20, in <module>; ModuleNotFoundError: No module named 'distutils.cmd'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/730
https://github.com/google/deepvariant/issues/730:995,Deployability,configurat,configuration,995,"Traceback (most recent call last):; File ""get-pip.py"", line 32992, in <module>; main(); File ""get-pip.py"", line 135, in main; bootstrap(tmpdir=tmpdir); File ""get-pip.py"", line 111, in bootstrap; monkeypatch_for_cert(tmpdir); File ""get-pip.py"", line 92, in monkeypatch_for_cert; from pip._internal.commands.install import InstallCommand; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/commands/__init__.py"", line 9, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/base_command.py"", line 15, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/cmdoptions.py"", line 24, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/parser.py"", line 12, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/configuration.py"", line 26, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/logging.py"", line 29, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/misc.py"", line 44, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/__init__.py"", line 66, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/_distutils.py"", line 20, in <module>; ModuleNotFoundError: No module named 'distutils.cmd'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/730
https://github.com/google/deepvariant/issues/730:995,Modifiability,config,configuration,995,"Traceback (most recent call last):; File ""get-pip.py"", line 32992, in <module>; main(); File ""get-pip.py"", line 135, in main; bootstrap(tmpdir=tmpdir); File ""get-pip.py"", line 111, in bootstrap; monkeypatch_for_cert(tmpdir); File ""get-pip.py"", line 92, in monkeypatch_for_cert; from pip._internal.commands.install import InstallCommand; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/commands/__init__.py"", line 9, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/base_command.py"", line 15, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/cmdoptions.py"", line 24, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/parser.py"", line 12, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/configuration.py"", line 26, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/logging.py"", line 29, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/misc.py"", line 44, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/__init__.py"", line 66, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/_distutils.py"", line 20, in <module>; ModuleNotFoundError: No module named 'distutils.cmd'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/730
https://github.com/google/deepvariant/issues/730:1140,Testability,log,logging,1140,"Traceback (most recent call last):; File ""get-pip.py"", line 32992, in <module>; main(); File ""get-pip.py"", line 135, in main; bootstrap(tmpdir=tmpdir); File ""get-pip.py"", line 111, in bootstrap; monkeypatch_for_cert(tmpdir); File ""get-pip.py"", line 92, in monkeypatch_for_cert; from pip._internal.commands.install import InstallCommand; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/commands/__init__.py"", line 9, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/base_command.py"", line 15, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/cmdoptions.py"", line 24, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/cli/parser.py"", line 12, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/configuration.py"", line 26, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/logging.py"", line 29, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/utils/misc.py"", line 44, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/__init__.py"", line 66, in <module>; File ""<frozen zipimport>"", line 259, in load_module; File ""/tmp/tmpwq54m3sg/pip.zip/pip/_internal/locations/_distutils.py"", line 20, in <module>; ModuleNotFoundError: No module named 'distutils.cmd'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/730
https://github.com/google/deepvariant/issues/733:350,Availability,error,error,350,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**: yes. **Describe the issue:** ; (A clear and concise description of what the issue is.). Hi, I am trying to set up DeepVariant on our server and would like to use udocker. It runs fine for the make_examples but It gets stuck with call_variants. I get the same error with both my data and the quick start. If I enable intermediate_results_dir, I can actually see the files being generated as expected. Could you please help me? . **Setup**; - Operating system: Red Hat Enterprise Linux 8.6; - DeepVariant version: 1.6.0; - Installation method (Docker, built from source, etc.): Docker (run via udocker); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) data from the quick start . **Steps to reproduce:**; - Command:. ```; udocker run \; -v ${INPUT_DIR}:""/input"" \; -v ${OUTPUT_DIR}:""/output"" \; DeepVariant \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/""ucsc.hg19.chr20.unittest.fasta"" \; --reads=/input/""NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=16; ```. - Error trace: (if applicable). ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpz5qvn8j2/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpz5qvn8j2/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/wgs"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:1266,Availability,Error,Error,1266,"the make_examples but It gets stuck with call_variants. I get the same error with both my data and the quick start. If I enable intermediate_results_dir, I can actually see the files being generated as expected. Could you please help me? . **Setup**; - Operating system: Red Hat Enterprise Linux 8.6; - DeepVariant version: 1.6.0; - Installation method (Docker, built from source, etc.): Docker (run via udocker); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) data from the quick start . **Steps to reproduce:**; - Command:. ```; udocker run \; -v ${INPUT_DIR}:""/input"" \; -v ${OUTPUT_DIR}:""/output"" \; DeepVariant \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/""ucsc.hg19.chr20.unittest.fasta"" \; --reads=/input/""NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=16; ```. - Error trace: (if applicable). ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpz5qvn8j2/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpz5qvn8j2/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/wgs"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:1497,Availability,checkpoint,checkpoint,1497,"help me? . **Setup**; - Operating system: Red Hat Enterprise Linux 8.6; - DeepVariant version: 1.6.0; - Installation method (Docker, built from source, etc.): Docker (run via udocker); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) data from the quick start . **Steps to reproduce:**; - Command:. ```; udocker run \; -v ${INPUT_DIR}:""/input"" \; -v ${OUTPUT_DIR}:""/output"" \; DeepVariant \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/""ucsc.hg19.chr20.unittest.fasta"" \; --reads=/input/""NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=16; ```. - Error trace: (if applicable). ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpz5qvn8j2/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpz5qvn8j2/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/wgs"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:1730,Availability,mainten,maintenance,1730," anything special that is unlike the case studies?) data from the quick start . **Steps to reproduce:**; - Command:. ```; udocker run \; -v ${INPUT_DIR}:""/input"" \; -v ${OUTPUT_DIR}:""/output"" \; DeepVariant \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/""ucsc.hg19.chr20.unittest.fasta"" \; --reads=/input/""NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=16; ```. - Error trace: (if applicable). ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpz5qvn8j2/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpz5qvn8j2/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/wgs"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:1815,Availability,down,downstream,1815,"- Command:. ```; udocker run \; -v ${INPUT_DIR}:""/input"" \; -v ${OUTPUT_DIR}:""/output"" \; DeepVariant \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/""ucsc.hg19.chr20.unittest.fasta"" \; --reads=/input/""NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=16; ```. - Error trace: (if applicable). ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpz5qvn8j2/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpz5qvn8j2/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/wgs"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:3654,Availability,error,error,3654," 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory. real 0m41.958s; user 0m6.224s; sys 0m3.683s. ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the error happens with the quick start. . **Any additional context:**. Files generated with intermediate_results_dir. ```; gvcf.tfrecord-00000-of-00016.gz make_examples.tfrecord-00000-of-00016.gz make_examples.tfrecord-00008-of-00016.gz; gvcf.tfrecord-00001-of-00016.gz make_examples.tfrecord-00000-of-00016.gz.example_info.json make_examples.tfrecord-00008-of-00016.gz.example_info.json; gvcf.tfrecord-00002-of-00016.gz make_examples.tfrecord-00001-of-00016.gz make_examples.tfrecord-00009-of-00016.gz; gvcf.tfrecord-00003-of-00016.gz make_examples.tfrecord-00001-of-00016.gz.example_info.json make_examples.tfrecord-00009-of-00016.gz.example_info.json; gvcf.tfrecord-00004-of-00016.gz make_examples.tfrecord-00002-of-00016.gz make_examples.tfrecord-00010-of-00016.gz; gvcf.tfrecord-00005-of-00016.gz make_examples.tfrecord-00002-of-00016.gz.example_info.json make_examples.tfrecord-00010-of-00016.gz.example_info.json; gvcf.tfrecord-00006-of-00016.gz make_examples.tfrecord-00003-of-00016.gz make_examples.tfrecord-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:612,Deployability,Install,Installation,612,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**: yes. **Describe the issue:** ; (A clear and concise description of what the issue is.). Hi, I am trying to set up DeepVariant on our server and would like to use udocker. It runs fine for the make_examples but It gets stuck with call_variants. I get the same error with both my data and the quick start. If I enable intermediate_results_dir, I can actually see the files being generated as expected. Could you please help me? . **Setup**; - Operating system: Red Hat Enterprise Linux 8.6; - DeepVariant version: 1.6.0; - Installation method (Docker, built from source, etc.): Docker (run via udocker); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) data from the quick start . **Steps to reproduce:**; - Command:. ```; udocker run \; -v ${INPUT_DIR}:""/input"" \; -v ${OUTPUT_DIR}:""/output"" \; DeepVariant \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/""ucsc.hg19.chr20.unittest.fasta"" \; --reads=/input/""NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=16; ```. - Error trace: (if applicable). ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpz5qvn8j2/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpz5qvn8j2/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/wgs"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:1746,Deployability,release,release,1746," anything special that is unlike the case studies?) data from the quick start . **Steps to reproduce:**; - Command:. ```; udocker run \; -v ${INPUT_DIR}:""/input"" \; -v ${OUTPUT_DIR}:""/output"" \; DeepVariant \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/""ucsc.hg19.chr20.unittest.fasta"" \; --reads=/input/""NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=16; ```. - Error trace: (if applicable). ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpz5qvn8j2/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpz5qvn8j2/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/wgs"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:1844,Integrability,depend,dependencies,1844,"- Command:. ```; udocker run \; -v ${INPUT_DIR}:""/input"" \; -v ${OUTPUT_DIR}:""/output"" \; DeepVariant \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/""ucsc.hg19.chr20.unittest.fasta"" \; --reads=/input/""NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=16; ```. - Error trace: (if applicable). ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpz5qvn8j2/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpz5qvn8j2/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/wgs"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:3102,Integrability,synchroniz,synchronize,3102,"es_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory. real 0m41.958s; user 0m6.224s; sys 0m3.683s. ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the error happens with the quick start. . **Any additional context:**. Files generated with intermediate_results_dir. ```; gvcf.tfrecord-00000-of-00016.gz make_examples.tfrecord-00000-of-00016.gz make_examples.tfrecord-00008-of-00016.gz; gvcf.tfrecord-00001-of-00016.gz make_examples.tfrecord-00000-of-00016.gz.example_info.json make_examples.tfrecord-00008-of-00016.gz.example_info.json; gvcf.tfrecord-00002-of-00016.gz make_examples.tfrecord-00001",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:3233,Integrability,synchroniz,synchronize,3233,"unfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory. real 0m41.958s; user 0m6.224s; sys 0m3.683s. ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the error happens with the quick start. . **Any additional context:**. Files generated with intermediate_results_dir. ```; gvcf.tfrecord-00000-of-00016.gz make_examples.tfrecord-00000-of-00016.gz make_examples.tfrecord-00008-of-00016.gz; gvcf.tfrecord-00001-of-00016.gz make_examples.tfrecord-00000-of-00016.gz.example_info.json make_examples.tfrecord-00008-of-00016.gz.example_info.json; gvcf.tfrecord-00002-of-00016.gz make_examples.tfrecord-00001-of-00016.gz make_examples.tfrecord-00009-of-00016.gz; gvcf.tfrecord-00003-of-00016.gz make_examples.tfrecord-00001-of-00016.gz.exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:2721,Performance,Queue,Queue,2721,"ance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory. real 0m41.958s; user 0m6.224s; sys 0m3.683s. ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the error happens with the quick start. . **Any additional context:**. Files generated ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:2797,Performance,Queue,Queue,2797," modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory. real 0m41.958s; user 0m6.224s; sys 0m3.683s. ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the error happens with the quick start. . **Any additional context:**. Files generated with intermediate_results_dir. ```; gvcf.tfrecord-00000-of-00016.gz ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:2811,Performance,Queue,Queue,2811," modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory. real 0m41.958s; user 0m6.224s; sys 0m3.683s. ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the error happens with the quick start. . **Any additional context:**. Files generated with intermediate_results_dir. ```; gvcf.tfrecord-00000-of-00016.gz ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:2892,Performance,queue,queues,2892,"r TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(; Traceback (most recent call last):; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>; app.run(main); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory. real 0m41.958s; user 0m6.224s; sys 0m3.683s. ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the error happens with the quick start. . **Any additional context:**. Files generated with intermediate_results_dir. ```; gvcf.tfrecord-00000-of-00016.gz make_examples.tfrecord-00000-of-00016.gz make_examples.tfrecord-00008-of-00016.gz;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:3449,Testability,test,test,3449,"unfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory. real 0m41.958s; user 0m6.224s; sys 0m3.683s. ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the error happens with the quick start. . **Any additional context:**. Files generated with intermediate_results_dir. ```; gvcf.tfrecord-00000-of-00016.gz make_examples.tfrecord-00000-of-00016.gz make_examples.tfrecord-00008-of-00016.gz; gvcf.tfrecord-00001-of-00016.gz make_examples.tfrecord-00000-of-00016.gz.example_info.json make_examples.tfrecord-00008-of-00016.gz.example_info.json; gvcf.tfrecord-00002-of-00016.gz make_examples.tfrecord-00001-of-00016.gz make_examples.tfrecord-00009-of-00016.gz; gvcf.tfrecord-00003-of-00016.gz make_examples.tfrecord-00001-of-00016.gz.example_info.json make_examples.tfrecord-00009-of-00016.gz.example_info.json; gvcf.tfrecord-00004-of-00016.gz make_examples.tfrecord-00002-of-00016.gz make_examples.tfrecord-00010-of-00016.gz; gvcf.tfrecord-00005-of-00016.gz make_examples.tf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:3485,Testability,test,test,3485,"unfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main; call_variants(; File ""/tmp/Bazel.runfiles_3accq8qt/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 430, in call_variants; output_queue = multiprocessing.Queue(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 103, in Queue; return Queue(maxsize, ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 42, in __init__; self._rlock = ctx.Lock(); File ""/usr/lib/python3.8/multiprocessing/context.py"", line 68, in Lock; return Lock(ctx=self.get_context()); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 162, in __init__; SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx); File ""/usr/lib/python3.8/multiprocessing/synchronize.py"", line 57, in __init__; sl = self._semlock = _multiprocessing.SemLock(; FileNotFoundError: [Errno 2] No such file or directory. real 0m41.958s; user 0m6.224s; sys 0m3.683s. ```. **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. Yes, the error happens with the quick start. . **Any additional context:**. Files generated with intermediate_results_dir. ```; gvcf.tfrecord-00000-of-00016.gz make_examples.tfrecord-00000-of-00016.gz make_examples.tfrecord-00008-of-00016.gz; gvcf.tfrecord-00001-of-00016.gz make_examples.tfrecord-00000-of-00016.gz.example_info.json make_examples.tfrecord-00008-of-00016.gz.example_info.json; gvcf.tfrecord-00002-of-00016.gz make_examples.tfrecord-00001-of-00016.gz make_examples.tfrecord-00009-of-00016.gz; gvcf.tfrecord-00003-of-00016.gz make_examples.tfrecord-00001-of-00016.gz.example_info.json make_examples.tfrecord-00009-of-00016.gz.example_info.json; gvcf.tfrecord-00004-of-00016.gz make_examples.tfrecord-00002-of-00016.gz make_examples.tfrecord-00010-of-00016.gz; gvcf.tfrecord-00005-of-00016.gz make_examples.tf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/733:125,Usability,clear,clear,125,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**: yes. **Describe the issue:** ; (A clear and concise description of what the issue is.). Hi, I am trying to set up DeepVariant on our server and would like to use udocker. It runs fine for the make_examples but It gets stuck with call_variants. I get the same error with both my data and the quick start. If I enable intermediate_results_dir, I can actually see the files being generated as expected. Could you please help me? . **Setup**; - Operating system: Red Hat Enterprise Linux 8.6; - DeepVariant version: 1.6.0; - Installation method (Docker, built from source, etc.): Docker (run via udocker); - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) data from the quick start . **Steps to reproduce:**; - Command:. ```; udocker run \; -v ${INPUT_DIR}:""/input"" \; -v ${OUTPUT_DIR}:""/output"" \; DeepVariant \; /opt/deepvariant/bin/run_deepvariant \; --model_type=WGS \; --ref=/input/""ucsc.hg19.chr20.unittest.fasta"" \; --reads=/input/""NA12878_S1.chr20.10_10p1mb.bam"" \; --regions ""chr20:10,000,000-10,010,000"" \; --output_vcf=/output/output.vcf.gz \; --output_gvcf=/output/output.g.vcf.gz \; --num_shards=16; ```. - Error trace: (if applicable). ```; ***** Running the command:*****; time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpz5qvn8j2/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpz5qvn8j2/make_examples.tfrecord@16.gz"" --checkpoint ""/opt/models/wgs"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features.; TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.; Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/733
https://github.com/google/deepvariant/issues/735:328,Deployability,Install,Installation,328,"I've been trying to replicate the runtime of a WES sample using the same BAMs as the ones specified in https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/inference_deepvariant.sh . - Operating system: google cloud vertex AI jupyer notebook ; n1-standard-64 - 64v CPUs - 240GB RAM; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): docker deepvariant ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); BAMs: https://storage.googleapis.com/deepvariant/exome-case-study-testdata/HG003.novaseq.wes_idt.100x.dedup.bam. - Command:; export BIN_VERSION=""1.5.0""; export INPUT_DIR=""/home/jupyter/input""; export REF=""GCA_000001405.15_GRCh38_no_alt_analysis_set.fna""; export BAM=""HG003.novaseq.wes_idt.100x.dedup.bam""; export OUTPUT_DIR=""/home/jupyter/output""; export OUTPUT_VCF=""HG003.deepvariant.vcf.gz""; export OUTPUT_GVCF=""HG003.deepvariant.g.vcf.gz"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/input/${REF}"" --reads=""/input/${BAM}"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=64. its taking 53 mins to finish running when it should take 8mins according to https://github.com/google/deepvariant/blob/r1.6/docs/metrics.md; ; I've also tried to run a WES sample of 23GB with the same cloud configuration, but it takes close to 2hrs to complete. ; Is there a reason for the differences in runtime? ; ; Is there another way to decrease runtime and match the runtimes specified https://github.com/google/deepvariant/blob/r1.6/docs/metrics.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/735
https://github.com/google/deepvariant/issues/735:1460,Deployability,configurat,configuration,1460,"I've been trying to replicate the runtime of a WES sample using the same BAMs as the ones specified in https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/inference_deepvariant.sh . - Operating system: google cloud vertex AI jupyer notebook ; n1-standard-64 - 64v CPUs - 240GB RAM; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): docker deepvariant ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); BAMs: https://storage.googleapis.com/deepvariant/exome-case-study-testdata/HG003.novaseq.wes_idt.100x.dedup.bam. - Command:; export BIN_VERSION=""1.5.0""; export INPUT_DIR=""/home/jupyter/input""; export REF=""GCA_000001405.15_GRCh38_no_alt_analysis_set.fna""; export BAM=""HG003.novaseq.wes_idt.100x.dedup.bam""; export OUTPUT_DIR=""/home/jupyter/output""; export OUTPUT_VCF=""HG003.deepvariant.vcf.gz""; export OUTPUT_GVCF=""HG003.deepvariant.g.vcf.gz"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/input/${REF}"" --reads=""/input/${BAM}"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=64. its taking 53 mins to finish running when it should take 8mins according to https://github.com/google/deepvariant/blob/r1.6/docs/metrics.md; ; I've also tried to run a WES sample of 23GB with the same cloud configuration, but it takes close to 2hrs to complete. ; Is there a reason for the differences in runtime? ; ; Is there another way to decrease runtime and match the runtimes specified https://github.com/google/deepvariant/blob/r1.6/docs/metrics.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/735
https://github.com/google/deepvariant/issues/735:1460,Modifiability,config,configuration,1460,"I've been trying to replicate the runtime of a WES sample using the same BAMs as the ones specified in https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/inference_deepvariant.sh . - Operating system: google cloud vertex AI jupyer notebook ; n1-standard-64 - 64v CPUs - 240GB RAM; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): docker deepvariant ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); BAMs: https://storage.googleapis.com/deepvariant/exome-case-study-testdata/HG003.novaseq.wes_idt.100x.dedup.bam. - Command:; export BIN_VERSION=""1.5.0""; export INPUT_DIR=""/home/jupyter/input""; export REF=""GCA_000001405.15_GRCh38_no_alt_analysis_set.fna""; export BAM=""HG003.novaseq.wes_idt.100x.dedup.bam""; export OUTPUT_DIR=""/home/jupyter/output""; export OUTPUT_VCF=""HG003.deepvariant.vcf.gz""; export OUTPUT_GVCF=""HG003.deepvariant.g.vcf.gz"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/input/${REF}"" --reads=""/input/${BAM}"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=64. its taking 53 mins to finish running when it should take 8mins according to https://github.com/google/deepvariant/blob/r1.6/docs/metrics.md; ; I've also tried to run a WES sample of 23GB with the same cloud configuration, but it takes close to 2hrs to complete. ; Is there a reason for the differences in runtime? ; ; Is there another way to decrease runtime and match the runtimes specified https://github.com/google/deepvariant/blob/r1.6/docs/metrics.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/735
https://github.com/google/deepvariant/issues/735:580,Testability,test,testdata,580,"I've been trying to replicate the runtime of a WES sample using the same BAMs as the ones specified in https://raw.githubusercontent.com/google/deepvariant/r1.6/scripts/inference_deepvariant.sh . - Operating system: google cloud vertex AI jupyer notebook ; n1-standard-64 - 64v CPUs - 240GB RAM; - DeepVariant version: 1.5.0; - Installation method (Docker, built from source, etc.): docker deepvariant ; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?); BAMs: https://storage.googleapis.com/deepvariant/exome-case-study-testdata/HG003.novaseq.wes_idt.100x.dedup.bam. - Command:; export BIN_VERSION=""1.5.0""; export INPUT_DIR=""/home/jupyter/input""; export REF=""GCA_000001405.15_GRCh38_no_alt_analysis_set.fna""; export BAM=""HG003.novaseq.wes_idt.100x.dedup.bam""; export OUTPUT_DIR=""/home/jupyter/output""; export OUTPUT_VCF=""HG003.deepvariant.vcf.gz""; export OUTPUT_GVCF=""HG003.deepvariant.g.vcf.gz"". docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/input/${REF}"" --reads=""/input/${BAM}"" --output_vcf=""/output/${OUTPUT_VCF}"" --output_gvcf=""/output/${OUTPUT_GVCF}"" --num_shards=64. its taking 53 mins to finish running when it should take 8mins according to https://github.com/google/deepvariant/blob/r1.6/docs/metrics.md; ; I've also tried to run a WES sample of 23GB with the same cloud configuration, but it takes close to 2hrs to complete. ; Is there a reason for the differences in runtime? ; ; Is there another way to decrease runtime and match the runtimes specified https://github.com/google/deepvariant/blob/r1.6/docs/metrics.md",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/735
https://github.com/google/deepvariant/issues/736:265,Availability,down,down,265,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:298,Availability,avail,available,298,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:469,Availability,Error,Error,469,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:1423,Availability,avail,available,1423,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:1557,Availability,error,error,1557,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:39,Deployability,install,install,39,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:320,Deployability,Install,Installation,320,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:433,Deployability,install,install,433,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:622,Deployability,install,installable,622,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:1021,Deployability,install,installed,1021,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:1396,Deployability,install,install,1396,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:1480,Deployability,release,releases,1480,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:145,Integrability,depend,dependencies,145,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/736:1318,Testability,test,test,1318,"**Describe the issue:**; Attempting to install deepvariant using conda and python 3 fails due to missing `tensorflow` and `tensorflow-estimator` dependencies. **Setup**; - Operating system: Amazon Linux 2023; - DeepVariant version: N/A, but we can narrow the focus down to 1.5, which is the latest available on conda; - Installation method (Docker, built from source, etc.): Conda (mamba). **Steps to reproduce:**; - Command: `mamba install deepvariant -c bioconda`; - Error trace: ; ```; Pinned packages:; - python 3.10.*. Could not solve for environment specs; The following packages are incompatible; └─ deepvariant is installable with the potential options; ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require; │ └─ tensorflow 1.12.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.10.0|1.0.0] would require; │ └─ tensorflow 2.0.* , which does not exist (perhaps a missing channel);; ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require; │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;; ├─ deepvariant [0.7.1|0.7.2] would require; │ └─ tensorflow 1.11.* , which does not exist (perhaps a missing channel);; └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require; └─ tensorflow-estimator 2.0.* , which does not exist (perhaps a missing channel).; ```. **Does the quick start test work on your system?**; N/A. **Any additional context:**; My goal was to install the latest version available (1.5.0). Looking at the `tensorflow-estimator` releases on conda-forge, version 2.0 is skipped entirely, which explains the error. https://anaconda.org/conda-forge/tensorflow-estimator/files?page=8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/736
https://github.com/google/deepvariant/issues/737:291,Availability,echo,echo,291,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:1279,Availability,Error,Error,1279,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:94,Deployability,install,installing,94,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:184,Deployability,install,installed,184,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:1343,Integrability,message,message,1343,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:1173,Modifiability,config,config,1173,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:732,Safety,Detect,Detecting,732,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:766,Safety,Detect,Detecting,766,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:807,Safety,Detect,Detecting,807,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:840,Safety,Detect,Detecting,840,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:987,Safety,Detect,Detecting,987,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:1023,Safety,Detect,Detecting,1023,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:1066,Safety,Detect,Detecting,1066,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/737:1101,Safety,Detect,Detecting,1101,"My environment is Ubuntu20.04, python3.8. I look up for it, and find this problem happened at installing clif library, but the former sentences are successful, the protobuf3.13.0 have installed, I wonder how it happen and what can i do?. ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/737
https://github.com/google/deepvariant/issues/739:953,Availability,ERROR,ERROR,953,"e are some problems while running the ./build-prereq.sh:; ```; + python3.8 -m pip install absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objects: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:3487,Availability,echo,echo,3487,"f84f5b608633a2d7 ]]; + git checkout 9ec44bde4f7f40de342a1286f84f5b608633a2d7; Note: switching to '9ec44bde4f7f40de342a1286f84f5b608633a2d7'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check fo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:3663,Availability,echo,echo,3663,"r) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4651,Availability,Error,Error,4651,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:86,Deployability,install,install,86,"There are some problems while running the ./build-prereq.sh:; ```; + python3.8 -m pip install absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:759,Deployability,Install,Installing,759,"There are some problems while running the ./build-prereq.sh:; ```; + python3.8 -m pip install absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:849,Deployability,install,installation,849,"There are some problems while running the ./build-prereq.sh:; ```; + python3.8 -m pip install absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:1049,Deployability,install,installed,1049,"e are some problems while running the ./build-prereq.sh:; ```; + python3.8 -m pip install absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objects: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:1394,Deployability,install,installed,1394,"l/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objects: 100% (700/700), done.; remote: Compressing objects: 100% (111/111), done.; remote: Total 5846 (delta 618), reused 625 (delta 585), pack-reused 5146; Receiving objects: 100% (5846/5846), 1.69 MiB | 1.11 MiB/s, done.; Resolving deltas: 100% (4683/4683), done.; + cd clif; + [[ ! -z 9ec44bde4f7f40de342a1286f84f5b608633a2d7 ]]; + git checkout 9ec44bde4f7f40de342a1286f84f5b608633a2d7; Note: switc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:3042,Deployability,INSTALL,INSTALL,3042,"ng objects: 100% (111/111), done.; remote: Total 5846 (delta 618), reused 625 (delta 585), pack-reused 5146; Receiving objects: 100% (5846/5846), 1.69 MiB | 1.11 MiB/s, done.; Resolving deltas: 100% (4683/4683), done.; + cd clif; + [[ ! -z 9ec44bde4f7f40de342a1286f84f5b608633a2d7 ]]; + git checkout 9ec44bde4f7f40de342a1286f84f5b608633a2d7; Note: switching to '9ec44bde4f7f40de342a1286f84f5b608633a2d7'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:3068,Deployability,INSTALL,INSTALL,3068,", done.; remote: Total 5846 (delta 618), reused 625 (delta 585), pack-reused 5146; Receiving objects: 100% (5846/5846), 1.69 MiB | 1.11 MiB/s, done.; Resolving deltas: 100% (4683/4683), done.; + cd clif; + [[ ! -z 9ec44bde4f7f40de342a1286f84f5b608633a2d7 ]]; + git checkout 9ec44bde4f7f40de342a1286f84f5b608633a2d7; Note: switching to '9ec44bde4f7f40de342a1286f84f5b608633a2d7'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:966,Integrability,depend,dependency,966,"e are some problems while running the ./build-prereq.sh:; ```; + python3.8 -m pip install absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objects: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:1106,Integrability,depend,dependency,1106," absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objects: 100% (700/700), done.; remote: Compressing objects: 100% (111/111), done.; remote: Total",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4715,Integrability,message,message,4715,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:102,Modifiability,parameteriz,parameterized,102,"There are some problems while running the ./build-prereq.sh:; ```; + python3.8 -m pip install absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:272,Modifiability,parameteriz,parameterized,272,"There are some problems while running the ./build-prereq.sh:; ```; + python3.8 -m pip install absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:2918,Modifiability,config,config,2918,"05.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objects: 100% (700/700), done.; remote: Compressing objects: 100% (111/111), done.; remote: Total 5846 (delta 618), reused 625 (delta 585), pack-reused 5146; Receiving objects: 100% (5846/5846), 1.69 MiB | 1.11 MiB/s, done.; Resolving deltas: 100% (4683/4683), done.; + cd clif; + [[ ! -z 9ec44bde4f7f40de342a1286f84f5b608633a2d7 ]]; + git checkout 9ec44bde4f7f40de342a1286f84f5b608633a2d7; Note: switching to '9ec44bde4f7f40de342a1286f84f5b608633a2d7'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:2925,Modifiability,variab,variable,2925,"05.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objects: 100% (700/700), done.; remote: Compressing objects: 100% (111/111), done.; remote: Total 5846 (delta 618), reused 625 (delta 585), pack-reused 5146; Receiving objects: 100% (5846/5846), 1.69 MiB | 1.11 MiB/s, done.; Resolving deltas: 100% (4683/4683), done.; + cd clif; + [[ ! -z 9ec44bde4f7f40de342a1286f84f5b608633a2d7 ]]; + git checkout 9ec44bde4f7f40de342a1286f84f5b608633a2d7; Note: switching to '9ec44bde4f7f40de342a1286f84f5b608633a2d7'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4545,Modifiability,config,config,4545,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:472,Performance,cache,cached,472,"There are some problems while running the ./build-prereq.sh:; ```; + python3.8 -m pip install absl-py parameterized protobuf==3.13.0 pyparsing==2.2.0; Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (1.4.0); Requirement already satisfied: parameterized in /usr/local/lib/python3.8/dist-packages (0.9.0); Requirement already satisfied: protobuf==3.13.0 in /usr/local/lib/python3.8/dist-packages (3.13.0); Collecting pyparsing==2.2.0; Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB); Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (1.16.0); Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from protobuf==3.13.0) (69.0.2); Installing collected packages: pyparsing; Attempting uninstall: pyparsing; Found existing installation: pyparsing 3.1.1; Uninstalling pyparsing-3.1.1:; Successfully uninstalled pyparsing-3.1.1; ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.; httplib2 0.21.0 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible.; matplotlib 3.7.3 requires pyparsing>=2.3.1, but you have pyparsing 2.2.0 which is incompatible.; Successfully installed pyparsing-2.2.0; WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv; + DV_PLATFORM=ubuntu-20.04; + ln -sf /usr/bin/python3.8 /usr/local/bin/python3; + cd; + rm -rf clif; + proxychains git clone https://github.com/google/clif.git; ProxyChains-3.1 (http://proxychains.sf.net); Cloning into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4104,Safety,Detect,Detecting,4104,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4138,Safety,Detect,Detecting,4138,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4179,Safety,Detect,Detecting,4179,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4212,Safety,Detect,Detecting,4212,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4359,Safety,Detect,Detecting,4359,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4395,Safety,Detect,Detecting,4395,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4438,Safety,Detect,Detecting,4438,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:4473,Safety,Detect,Detecting,4473,"9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHON_EXECUTABLE=/usr/local/bin/python3 /root/clif; -- The C compiler identification is GNU 9.4.0; -- The CXX compiler identification is GNU 9.4.0; -- Check for working C compiler: /usr/bin/cc; -- Check for working C compiler: /usr/bin/cc -- works; -- Detecting C compiler ABI info; -- Detecting C compiler ABI info - done; -- Detecting C compile features; -- Detecting C compile features - done; -- Check for working CXX compiler: /usr/bin/c++; -- Check for working CXX compiler: /usr/bin/c++ -- works; -- Detecting CXX compiler ABI info; -- Detecting CXX compiler ABI info - done; -- Detecting CXX compile features; -- Detecting CXX compile features - done; -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1""); -- Checking for module 'protobuf'; -- No package 'protobuf' found; CMake Error at /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:463 (message):; A required package was not found; Call Stack (most recent call first):; /usr/share/cmake-3.16/Modules/FindPkgConfig.cmake:643 (_pkg_check_modules_internal); clif/cmake/modules/CLIFUtils.cmake:31 (pkg_check_modules); clif/CMakeLists.txt:22 (include); ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/739:2845,Usability,undo,undo,2845,"g into 'clif'...; |S-chain|-<>-10.68.50.55:7890-<><>-20.205.243.166:443-<><>-OK; remote: Enumerating objects: 5846, done.; remote: Counting objects: 100% (700/700), done.; remote: Compressing objects: 100% (111/111), done.; remote: Total 5846 (delta 618), reused 625 (delta 585), pack-reused 5146; Receiving objects: 100% (5846/5846), 1.69 MiB | 1.11 MiB/s, done.; Resolving deltas: 100% (4683/4683), done.; + cd clif; + [[ ! -z 9ec44bde4f7f40de342a1286f84f5b608633a2d7 ]]; + git checkout 9ec44bde4f7f40de342a1286f84f5b608633a2d7; Note: switching to '9ec44bde4f7f40de342a1286f84f5b608633a2d7'. You are in 'detached HEAD' state. You can look around, make experimental; changes and commit them, and you can discard any commits you make in this; state without impacting any branches by switching back to a branch. If you want to create a new branch to retain commits you create, you may; do so (now or later) by using -c with the switch command. Example:. git switch -c <new-branch-name>. Or undo this operation with:. git switch -. Turn off this advice by setting config variable advice.detachedHead to false. HEAD is now at 9ec44bd Replace C++ `#import <...>` with `#include <...>`; + ./INSTALL.sh; +++ dirname ./INSTALL.sh; ++ cd .; ++ pwd; + CLIFSRC_DIR=/root/clif; + BUILD_DIR=/root/clif/build; + declare -a CMAKE_G_FLAG; + declare -a MAKE_PARALLELISM; + which ninja; + CMAKE_G_FLAGS=(); + MAKE_OR_NINJA=make; + MAKE_PARALLELISM=(-j 2); + [[ -r /proc/cpuinfo ]]; ++ cat /proc/cpuinfo; ++ grep -c '^processor'; + N_CPUS=32; + [[ 32 -gt 0 ]]; + MAKE_PARALLELISM=(-j $N_CPUS); + MAKE_INSTALL_PARALLELISM=(${MAKE_PARALLELISM[@]}); + echo 'Using make for the clif backend build.'; Using make for the clif backend build.; + [[ '' =~ ^-?-h ]]; + [[ -n '' ]]; ++ which python3; + PYTHON=/usr/local/bin/python3; + echo -n 'Using Python interpreter: /usr/local/bin/python3'; Using Python interpreter: /usr/local/bin/python3+ [[ '' -eq 1 ]]; + mkdir -p /root/clif/build; + cd /root/clif/build; + cmake -DPYTHO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/739
https://github.com/google/deepvariant/issues/740:394,Availability,avail,available,394,"Sorry it's not an issue of the package per se, but is it possible for you to supply the shell scripts below for building the package on RedHat systems? I tried to install the package with conda on a RedHat system, but it didn't work. When I tried to build the package from the sources, I ran into some issues. Many system libraries and utilities, such as zlib1g-dev, python3-distutils, are not available or possible in different names. Without or not familiar with a Ubuntu system, it's hard to figure out what would be the equivalent. It'd be enough to have the scripts working for one version of RedHat and it'd be much easier for people familiar with RedHat to modify the scripts for a different version of RedHat. Thanks. build_and_test.sh; build-prereq.sh; build_release_binaries.sh; run-prereq.sh; settings.sh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/740
https://github.com/google/deepvariant/issues/740:163,Deployability,install,install,163,"Sorry it's not an issue of the package per se, but is it possible for you to supply the shell scripts below for building the package on RedHat systems? I tried to install the package with conda on a RedHat system, but it didn't work. When I tried to build the package from the sources, I ran into some issues. Many system libraries and utilities, such as zlib1g-dev, python3-distutils, are not available or possible in different names. Without or not familiar with a Ubuntu system, it's hard to figure out what would be the equivalent. It'd be enough to have the scripts working for one version of RedHat and it'd be much easier for people familiar with RedHat to modify the scripts for a different version of RedHat. Thanks. build_and_test.sh; build-prereq.sh; build_release_binaries.sh; run-prereq.sh; settings.sh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/740
https://github.com/google/deepvariant/issues/741:338,Availability,error,error,338,"Hi,. There appears to be a regression in v1.6 compared to v1.5 for handling cram input. The reference is set in the `make_examples` call, but does not seem to propagate to nucleus. The [code](https://github.com/google/deepvariant/blob/764bad20cbfa178d757ae81bbe05860640f2d5d4/third_party/nucleus/io/clif_postproc.py#L141) that raises the error ""ValueError: DATA_LOSS: Failed to parse SAM record"" is 4 years old, so must be some intermediate flag not working. The log in v1.6 looks like; ```; make_examples_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; genomics_reader.py:222] Reading sample.cram with NativeSamReader. ```. while in v1.5 it has 2 extra lines for setting the CRAM reference.; ```; make_examples_core.py:257] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728; third_party/nucleus/io/sam_reader.cc:764] Setting CRAM reference path to 'reference.fa'; genomics_reader.py:222] Reading sample.cram with NativeSamReader; ```. the `nucleus/io/sam_reader.cc` file had changes in b8d6d11, but it still looks correct so not sure what is happening. For completeness, I tried converting the cram to bam and rerun with v1.6, and that did worked, so this is somehow localised to cram support. Best,; Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/741
https://github.com/google/deepvariant/issues/741:463,Testability,log,log,463,"Hi,. There appears to be a regression in v1.6 compared to v1.5 for handling cram input. The reference is set in the `make_examples` call, but does not seem to propagate to nucleus. The [code](https://github.com/google/deepvariant/blob/764bad20cbfa178d757ae81bbe05860640f2d5d4/third_party/nucleus/io/clif_postproc.py#L141) that raises the error ""ValueError: DATA_LOSS: Failed to parse SAM record"" is 4 years old, so must be some intermediate flag not working. The log in v1.6 looks like; ```; make_examples_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; genomics_reader.py:222] Reading sample.cram with NativeSamReader. ```. while in v1.5 it has 2 extra lines for setting the CRAM reference.; ```; make_examples_core.py:257] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref; third_party/nucleus/io/sam_reader.cc:736] Setting HTS_OPT_BLOCK_SIZE to 134217728; third_party/nucleus/io/sam_reader.cc:764] Setting CRAM reference path to 'reference.fa'; genomics_reader.py:222] Reading sample.cram with NativeSamReader; ```. the `nucleus/io/sam_reader.cc` file had changes in b8d6d11, but it still looks correct so not sure what is happening. For completeness, I tried converting the cram to bam and rerun with v1.6, and that did worked, so this is somehow localised to cram support. Best,; Alex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/741
https://github.com/google/deepvariant/issues/742:36,Availability,error,errors,36,"Hi DeepVariant,; I am getting below errors on running DeepTrio on the provided PacBio samples using singularity:. ```; ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""./reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""./output/intermediate_results_dir/call_variants_output_child.tfrecord.gz"" --outfile ""./output/HG002.output.vcf.gz"" --cpus 0 --nonvariant_site_tfrecord_path ""./output/intermediate_results_dir/gvcf_child.tfrecord@128.gz"" --gvcf_outfile ""./output/HG002.g.vcf.gz"". ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""./reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""./output/intermediate_results_dir/call_variants_output_parent1.tfrecord.gz"" --outfile ""./output/HG003.output.vcf.gz"" --cpus 0 --nonvariant_site_tfrecord_path ""./output/intermediate_results_dir/gvcf_parent1.tfrecord@128.gz"" --gvcf_outfile ""./output/HG003.g.vcf.gz"". ***** Running the command:*****; time /opt/deepvariant/bin/postprocess_variants --ref ""./reference/GRCh38_no_alt_analysis_set.fasta"" --infile ""./output/intermediate_results_dir/call_variants_output_parent2.tfrecord.gz"" --outfile ""./output/HG004.output.vcf.gz"" --cpus 0 --nonvariant_site_tfrecord_path ""./output/intermediate_results_dir/gvcf_parent2.tfrecord@128.gz"" --gvcf_outfile ""./output/HG004.g.vcf.gz"". Traceback (most recent call last):; File ""/var/tmp/Bazel.runfiles_m2211dcw/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>; app.run(main); File ""/var/tmp/Bazel.runfiles_m2211dcw/runfiles/absl_py/absl/app.py"", line 312, in run; _run_main(main, args); File ""/var/tmp/Bazel.runfiles_m2211dcw/runfiles/absl_py/absl/app.py"", line 258, in _run_main; sys.exit(main(argv)); File ""/var/tmp/Bazel.runfiles_m2211dcw/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main; sample_name = get_sample_name(); File ""/var/tmp/Bazel.runfiles_m2211dcw/runfiles/com_google_deepvariant/deepvariant/postpr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/742
https://github.com/google/deepvariant/issues/743:437,Availability,Error,Error,437,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/743
https://github.com/google/deepvariant/issues/743:232,Deployability,Install,Installation,232,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/743
https://github.com/google/deepvariant/issues/743:490,Testability,test,test,490,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/743
https://github.com/google/deepvariant/issues/743:526,Testability,test,test,526,"**Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md**:. **Describe the issue:**; (A clear and concise description of what the issue is.). **Setup**; - Operating system:; - DeepVariant version:; - Installation method (Docker, built from source, etc.):; - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**; - Command:; - Error trace: (if applicable). **Does the quick start test work on your system?**; Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md.; Is there any way to reproduce the issue by using the quick start?. **Any additional context:**",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/743
