filename,ext,element_type,constant,constant.name,constant.value,embedding,author,repo_name,tag,import,import.from,import.name,function.name,function.parameters,import.path,class.name,method.name,method.parameters,class.field,class.instance_field,method.type,function.type,function.docstring,field.name,class.base,field.default,method.decorator
setup.py,python,constant,VERSION = {},VERSION,{},Constant: VERSION = {},allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
setup.py,python,import,,,,Import: setup from setuptools,allenai,scispacy,v0.5.4,"from setuptools import setup, find_packages",setuptools,setup,,,,,,,,,,,,,,,
setup.py,python,import,,,,Import: find_packages from setuptools,allenai,scispacy,v0.5.4,"from setuptools import setup, find_packages",setuptools,find_packages,,,,,,,,,,,,,,,
setup.py,python,,,,,File: .,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
setup.py,python,,,,,Directory: setup.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
evaluate_linker.py,python,function,,,,Function: main(),allenai,scispacy,v0.5.4,,,,main,(),,,,,,,,,,,,,
evaluate_linker.py,python,constant,EVALUATION_FOLDER_PATH = os.path.dirname(os.path.abspath(__file__)),EVALUATION_FOLDER_PATH,os.path.dirname(os.path.abspath(__file__)),Constant: EVALUATION_FOLDER_PATH = os.path.dirname(os.path.abspath(__file__)),allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
evaluate_linker.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
evaluate_linker.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
evaluate_linker.py,python,import,,,,Import: tqdm from tqdm,allenai,scispacy,v0.5.4,from tqdm import tqdm,tqdm,tqdm,,,,,,,,,,,,,,,
evaluate_linker.py,python,local_import,,,,Import: EntityLinker from scispacy.linking,allenai,scispacy,v0.5.4,from scispacy.linking import EntityLinker,scispacy.linking,EntityLinker,,,scispacy.linking,,,,,,,,,,,,
evaluate_linker.py,python,local_import,,,,Import: read_full_med_mentions from scispacy.data_util,allenai,scispacy,v0.5.4,from scispacy.data_util import read_full_med_mentions,scispacy.data_util,read_full_med_mentions,,,scispacy.data_util,,,,,,,,,,,,
evaluate_linker.py,python,,,,,File: evaluation,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
evaluate_linker.py,python,,,,,Directory: evaluation\evaluate_linker.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,function,,,,"Function: evaluate_sentence_splitting(model_path: str,
                                data_directory: str,
                                rule_segmenter: bool = False,
                                custom_tokenizer: bool = False,
                                citation_data_path: str = None)",allenai,scispacy,v0.5.4,,,,evaluate_sentence_splitting,"(model_path: str,
                                data_directory: str,
                                rule_segmenter: bool = False,
                                custom_tokenizer: bool = False,
                                citation_data_path: str = None)",,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,import,,,,Import: argparse,allenai,scispacy,v0.5.4,import argparse,,argparse,,,,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,import,,,,Import: sys,allenai,scispacy,v0.5.4,import sys,,sys,,,,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,import,,,,Import: json,allenai,scispacy,v0.5.4,import json,,json,,,,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,local_import,,,,Import: combined_rule_sentence_segmenter from scispacy.custom_sentence_segmenter,allenai,scispacy,v0.5.4,from scispacy.custom_sentence_segmenter import combined_rule_sentence_segmenter,scispacy.custom_sentence_segmenter,combined_rule_sentence_segmenter,,,scispacy.custom_sentence_segmenter,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,local_import,,,,Import: remove_new_lines from scispacy.custom_tokenizer,allenai,scispacy,v0.5.4,"from scispacy.custom_tokenizer import remove_new_lines, combined_rule_tokenizer",scispacy.custom_tokenizer,remove_new_lines,,,scispacy.custom_tokenizer,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,local_import,,,,Import: combined_rule_tokenizer from scispacy.custom_tokenizer,allenai,scispacy,v0.5.4,"from scispacy.custom_tokenizer import remove_new_lines, combined_rule_tokenizer",scispacy.custom_tokenizer,combined_rule_tokenizer,,,scispacy.custom_tokenizer,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,,,,,File: evaluation,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
sentence_splitting_evaluation.py,python,,,,,Directory: evaluation\sentence_splitting_evaluation.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
abbreviation.py,python,class_field,,,,Class field: [instance] AbbreviationDetector.matcher = Matcher(nlp.vocab),allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,__init__,"(
        self,
        nlp: Language,
        name: str = ""abbreviation_detector"",
        make_serializable: bool = False,
    )",self.matcher = Matcher(nlp.vocab),self.matcher = Matcher(nlp.vocab),,,,,,,
abbreviation.py,python,class_field,,,,"Class field: [instance] AbbreviationDetector.matcher.add(""parenthesis"", [[{""ORTH"": ""(""}, {""OP"": ""+""}, {""ORTH"": "")""}]])",allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,__init__,"(
        self,
        nlp: Language,
        name: str = ""abbreviation_detector"",
        make_serializable: bool = False,
    )","self.matcher.add(""parenthesis"", [[{""ORTH"": ""(""}, {""OP"": ""+""}, {""ORTH"": "")""}]])","self.matcher.add(""parenthesis"", [[{""ORTH"": ""(""}, {""OP"": ""+""}, {""ORTH"": "")""}]])",,,,,,,
abbreviation.py,python,class_field,,,,Class field: [instance] AbbreviationDetector.make_serializable = make_serializable,allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,__init__,"(
        self,
        nlp: Language,
        name: str = ""abbreviation_detector"",
        make_serializable: bool = False,
    )",self.make_serializable = make_serializable,self.make_serializable = make_serializable,,,,,,,
abbreviation.py,python,class_field,,,,Class field: [instance] AbbreviationDetector.global_matcher = Matcher(nlp.vocab),allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,__init__,"(
        self,
        nlp: Language,
        name: str = ""abbreviation_detector"",
        make_serializable: bool = False,
    )",self.global_matcher = Matcher(nlp.vocab),self.global_matcher = Matcher(nlp.vocab),,,,,,,
abbreviation.py,python,class_method,,,,"Class method: AbbreviationDetector.__init__(
        self,
        nlp: Language,
        name: str = ""abbreviation_detector"",
        make_serializable: bool = False,
    ) -> None",allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,__init__,"(
        self,
        nlp: Language,
        name: str = ""abbreviation_detector"",
        make_serializable: bool = False,
    )",,,None,,,,,,
abbreviation.py,python,class_method,,,,"Class method: AbbreviationDetector.find(self, span: Span, doc: Doc) -> Tuple[Span, Set[Span]]",allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,find,"(self, span: Span, doc: Doc)",,,"Tuple[Span, Set[Span]]",,,,,,
abbreviation.py,python,class_method,,,,"Class method: AbbreviationDetector.__call__(self, doc: Doc) -> Doc",allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,__call__,"(self, doc: Doc)",,,Doc,,,,,,
abbreviation.py,python,class_method,,,,"Class method: AbbreviationDetector.find_matches_for(
        self, filtered: List[Tuple[Span, Span]], doc: Doc
    ) -> List[Tuple[Span, Set[Span]]]",allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,find_matches_for,"(
        self, filtered: List[Tuple[Span, Span]], doc: Doc
    )",,,"List[Tuple[Span, Set[Span]]]",,,,,,
abbreviation.py,python,class_method,,,,"Class method: AbbreviationDetector.make_short_form_serializable(self, abbreviation: Span)",allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,make_short_form_serializable,"(self, abbreviation: Span)",,,,,,,,,
abbreviation.py,python,class,,,,Class: AbbreviationDetector,allenai,scispacy,v0.5.4,,,,,,,AbbreviationDetector,,,,,,,,,,,
abbreviation.py,python,function,,,,"Function: find_abbreviation(
    long_form_candidate: Span, short_form_candidate: Span
) -> Tuple[Span, Optional[Span]]",allenai,scispacy,v0.5.4,,,,find_abbreviation,"(
    long_form_candidate: Span, short_form_candidate: Span
)",,,,,,,,"Tuple[Span, Optional[Span]]",,,,,
abbreviation.py,python,function,,,,Function: span_contains_unbalanced_parentheses(span: Span) -> bool,allenai,scispacy,v0.5.4,,,,span_contains_unbalanced_parentheses,(span: Span),,,,,,,,bool,,,,,
abbreviation.py,python,function,,,,"Function: filter_matches(
    matcher_output: List[Tuple[int, int, int]], doc: Doc
) -> List[Tuple[Span, Span]]",allenai,scispacy,v0.5.4,,,,filter_matches,"(
    matcher_output: List[Tuple[int, int, int]], doc: Doc
)",,,,,,,,"List[Tuple[Span, Span]]","# Filter into two cases:",,,,
abbreviation.py,python,function,,,,"Function: filter_matches(
    matcher_output: List[Tuple[int, int, int]], doc: Doc
) -> List[Tuple[Span, Span]]",allenai,scispacy,v0.5.4,,,,filter_matches,"(
    matcher_output: List[Tuple[int, int, int]], doc: Doc
)",,,,,,,,"List[Tuple[Span, Span]]","# 1. <Short Form> ( <Long Form> )",,,,
abbreviation.py,python,function,,,,"Function: filter_matches(
    matcher_output: List[Tuple[int, int, int]], doc: Doc
) -> List[Tuple[Span, Span]]",allenai,scispacy,v0.5.4,,,,filter_matches,"(
    matcher_output: List[Tuple[int, int, int]], doc: Doc
)",,,,,,,,"List[Tuple[Span, Span]]","# 2. <Long Form> (<Short Form>) [this case is most common].",,,,
abbreviation.py,python,function,,,,Function: short_form_filter(span: Span) -> bool,allenai,scispacy,v0.5.4,,,,short_form_filter,(span: Span),,,,,,,,bool,"# All words are between length 2 and 10",,,,
abbreviation.py,python,import,,,,Import: Tuple from typing,allenai,scispacy,v0.5.4,"from typing import Tuple, List, Optional, Set, Dict",typing,Tuple,,,,,,,,,,,,,,,
abbreviation.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,"from typing import Tuple, List, Optional, Set, Dict",typing,List,,,,,,,,,,,,,,,
abbreviation.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,"from typing import Tuple, List, Optional, Set, Dict",typing,Optional,,,,,,,,,,,,,,,
abbreviation.py,python,import,,,,Import: Set from typing,allenai,scispacy,v0.5.4,"from typing import Tuple, List, Optional, Set, Dict",typing,Set,,,,,,,,,,,,,,,
abbreviation.py,python,import,,,,Import: Dict from typing,allenai,scispacy,v0.5.4,"from typing import Tuple, List, Optional, Set, Dict",typing,Dict,,,,,,,,,,,,,,,
abbreviation.py,python,import,,,,Import: defaultdict from collections,allenai,scispacy,v0.5.4,from collections import defaultdict,collections,defaultdict,,,,,,,,,,,,,,,
abbreviation.py,python,local_import,,,,Import: Span from spacy.tokens,allenai,scispacy,v0.5.4,"from spacy.tokens import Span, Doc",spacy.tokens,Span,,,spacy.tokens,,,,,,,,,,,,
abbreviation.py,python,local_import,,,,Import: Doc from spacy.tokens,allenai,scispacy,v0.5.4,"from spacy.tokens import Span, Doc",spacy.tokens,Doc,,,spacy.tokens,,,,,,,,,,,,
abbreviation.py,python,local_import,,,,Import: Matcher from spacy.matcher,allenai,scispacy,v0.5.4,from spacy.matcher import Matcher,spacy.matcher,Matcher,,,spacy.matcher,,,,,,,,,,,,
abbreviation.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
abbreviation.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
abbreviation.py,python,,,,,Directory: scispacy\abbreviation.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
base_project_code.py,python,function,,,,"Function: iter_sample(iterable: Iterable, sample_percent: float) -> Iterator",allenai,scispacy,v0.5.4,,,,iter_sample,"(iterable: Iterable, sample_percent: float)",,,,,,,,Iterator,,,,,
base_project_code.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,"from typing import Optional, Callable, Iterable, Iterator",typing,Optional,,,,,,,,,,,,,,,
base_project_code.py,python,import,,,,Import: Callable from typing,allenai,scispacy,v0.5.4,"from typing import Optional, Callable, Iterable, Iterator",typing,Callable,,,,,,,,,,,,,,,
base_project_code.py,python,import,,,,Import: Iterable from typing,allenai,scispacy,v0.5.4,"from typing import Optional, Callable, Iterable, Iterator",typing,Iterable,,,,,,,,,,,,,,,
base_project_code.py,python,import,,,,Import: Iterator from typing,allenai,scispacy,v0.5.4,"from typing import Optional, Callable, Iterable, Iterator",typing,Iterator,,,,,,,,,,,,,,,
base_project_code.py,python,import,,,,Import: Path from pathlib,allenai,scispacy,v0.5.4,from pathlib import Path,pathlib,Path,,,,,,,,,,,,,,,
base_project_code.py,python,import,,,,Import: random,allenai,scispacy,v0.5.4,import random,,random,,,,,,,,,,,,,,,
base_project_code.py,python,import,,,,Import: itertools,allenai,scispacy,v0.5.4,import itertools,,itertools,,,,,,,,,,,,,,,
base_project_code.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
base_project_code.py,python,import,,,,Import: warnings,allenai,scispacy,v0.5.4,import warnings,,warnings,,,,,,,,,,,,,,,
base_project_code.py,python,local_import,,,,Import: Corpus from spacy.training,allenai,scispacy,v0.5.4,"from spacy.training import Corpus, Example",spacy.training,Corpus,,,spacy.training,,,,,,,,,,,,
base_project_code.py,python,local_import,,,,Import: Example from spacy.training,allenai,scispacy,v0.5.4,"from spacy.training import Corpus, Example",spacy.training,Example,,,spacy.training,,,,,,,,,,,,
base_project_code.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
base_project_code.py,python,local_import,,,,Import: combined_rule_tokenizer from scispacy.custom_tokenizer,allenai,scispacy,v0.5.4,from scispacy.custom_tokenizer import combined_rule_tokenizer,scispacy.custom_tokenizer,combined_rule_tokenizer,,,scispacy.custom_tokenizer,,,,,,,,,,,,
base_project_code.py,python,local_import,,,,Import: read_full_med_mentions from scispacy.data_util,allenai,scispacy,v0.5.4,"from scispacy.data_util import read_full_med_mentions, read_ner_from_tsv",scispacy.data_util,read_full_med_mentions,,,scispacy.data_util,,,,,,,,,,,,
base_project_code.py,python,local_import,,,,Import: read_ner_from_tsv from scispacy.data_util,allenai,scispacy,v0.5.4,"from scispacy.data_util import read_full_med_mentions, read_ner_from_tsv",scispacy.data_util,read_ner_from_tsv,,,scispacy.data_util,,,,,,,,,,,,
base_project_code.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
base_project_code.py,python,,,,,Directory: scispacy\base_project_code.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
candidate_generation.py,python,class_field,,,,Class field: LinkerPaths.ann_index: str,allenai,scispacy,v0.5.4,,,,,,,LinkerPaths,,,ann_index: str,,,,,ann_index,,,
candidate_generation.py,python,class_field,,,,Class field: LinkerPaths.tfidf_vectorizer: str,allenai,scispacy,v0.5.4,,,,,,,LinkerPaths,,,tfidf_vectorizer: str,,,,,tfidf_vectorizer,,,
candidate_generation.py,python,class_field,,,,Class field: LinkerPaths.tfidf_vectors: str,allenai,scispacy,v0.5.4,,,,,,,LinkerPaths,,,tfidf_vectors: str,,,,,tfidf_vectors,,,
candidate_generation.py,python,class_field,,,,Class field: LinkerPaths.concept_aliases_list: str,allenai,scispacy,v0.5.4,,,,,,,LinkerPaths,,,concept_aliases_list: str,,,,,concept_aliases_list,,,
candidate_generation.py,python,class_field,,,,Class field: MentionCandidate.concept_id: str,allenai,scispacy,v0.5.4,,,,,,,MentionCandidate,,,concept_id: str,,,,,concept_id,,,
candidate_generation.py,python,class_field,,,,Class field: MentionCandidate.aliases: List[str],allenai,scispacy,v0.5.4,,,,,,,MentionCandidate,,,aliases: List[str],,,,,aliases,,,
candidate_generation.py,python,class_field,,,,Class field: MentionCandidate.similarities: List[float],allenai,scispacy,v0.5.4,,,,,,,MentionCandidate,,,similarities: List[float],,,,,similarities,,,
candidate_generation.py,python,class_field,,,,"Class field: [instance] CandidateGenerator.ann_index = ann_index or load_approximate_nearest_neighbours_index(
            linker_paths=linker_paths, ef_search=ef_search
        )",allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,__init__,"(
        self,
        ann_index: Optional[FloatIndex] = None,
        tfidf_vectorizer: Optional[TfidfVectorizer] = None,
        ann_concept_aliases_list: Optional[List[str]] = None,
        kb: Optional[KnowledgeBase] = None,
        verbose: bool = False,
        ef_search: int = 200,
        name: Optional[str] = None,
    )","self.ann_index = ann_index or load_approximate_nearest_neighbours_index(
            linker_paths=linker_paths, ef_search=ef_search
        )","self.ann_index = ann_index or load_approximate_nearest_neighbours_index(
            linker_paths=linker_paths, ef_search=ef_search
        )",,,,,,,
candidate_generation.py,python,class_field,,,,"Class field: [instance] CandidateGenerator.vectorizer = tfidf_vectorizer or joblib.load(
            cached_path(linker_paths.tfidf_vectorizer)
        )",allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,__init__,"(
        self,
        ann_index: Optional[FloatIndex] = None,
        tfidf_vectorizer: Optional[TfidfVectorizer] = None,
        ann_concept_aliases_list: Optional[List[str]] = None,
        kb: Optional[KnowledgeBase] = None,
        verbose: bool = False,
        ef_search: int = 200,
        name: Optional[str] = None,
    )","self.vectorizer = tfidf_vectorizer or joblib.load(
            cached_path(linker_paths.tfidf_vectorizer)
        )","self.vectorizer = tfidf_vectorizer or joblib.load(
            cached_path(linker_paths.tfidf_vectorizer)
        )",,,,,,,
candidate_generation.py,python,class_field,,,,"Class field: [instance] CandidateGenerator.ann_concept_aliases_list = ann_concept_aliases_list or json.load(
            open(cached_path(linker_paths.concept_aliases_list))
        )",allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,__init__,"(
        self,
        ann_index: Optional[FloatIndex] = None,
        tfidf_vectorizer: Optional[TfidfVectorizer] = None,
        ann_concept_aliases_list: Optional[List[str]] = None,
        kb: Optional[KnowledgeBase] = None,
        verbose: bool = False,
        ef_search: int = 200,
        name: Optional[str] = None,
    )","self.ann_concept_aliases_list = ann_concept_aliases_list or json.load(
            open(cached_path(linker_paths.concept_aliases_list))
        )","self.ann_concept_aliases_list = ann_concept_aliases_list or json.load(
            open(cached_path(linker_paths.concept_aliases_list))
        )",,,,,,,
candidate_generation.py,python,class_field,,,,Class field: [instance] CandidateGenerator.kb = kb or DEFAULT_KNOWLEDGE_BASES[name](),allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,__init__,"(
        self,
        ann_index: Optional[FloatIndex] = None,
        tfidf_vectorizer: Optional[TfidfVectorizer] = None,
        ann_concept_aliases_list: Optional[List[str]] = None,
        kb: Optional[KnowledgeBase] = None,
        verbose: bool = False,
        ef_search: int = 200,
        name: Optional[str] = None,
    )",self.kb = kb or DEFAULT_KNOWLEDGE_BASES[name](),self.kb = kb or DEFAULT_KNOWLEDGE_BASES[name](),,,,,,,
candidate_generation.py,python,class_field,,,,Class field: [instance] CandidateGenerator.verbose = verbose,allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,__init__,"(
        self,
        ann_index: Optional[FloatIndex] = None,
        tfidf_vectorizer: Optional[TfidfVectorizer] = None,
        ann_concept_aliases_list: Optional[List[str]] = None,
        kb: Optional[KnowledgeBase] = None,
        verbose: bool = False,
        ef_search: int = 200,
        name: Optional[str] = None,
    )",self.verbose = verbose,self.verbose = verbose,,,,,,,
candidate_generation.py,python,class_field,,,,Class field: [instance] CandidateGenerator.umls = kb,allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,__init__,"(
        self,
        ann_index: Optional[FloatIndex] = None,
        tfidf_vectorizer: Optional[TfidfVectorizer] = None,
        ann_concept_aliases_list: Optional[List[str]] = None,
        kb: Optional[KnowledgeBase] = None,
        verbose: bool = False,
        ef_search: int = 200,
        name: Optional[str] = None,
    )",self.umls = self.kb,self.umls = self.kb,,,,,,,
candidate_generation.py,python,class_method,,,,"Class method: CandidateGenerator.__init__(
        self,
        ann_index: Optional[FloatIndex] = None,
        tfidf_vectorizer: Optional[TfidfVectorizer] = None,
        ann_concept_aliases_list: Optional[List[str]] = None,
        kb: Optional[KnowledgeBase] = None,
        verbose: bool = False,
        ef_search: int = 200,
        name: Optional[str] = None,
    ) -> None",allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,__init__,"(
        self,
        ann_index: Optional[FloatIndex] = None,
        tfidf_vectorizer: Optional[TfidfVectorizer] = None,
        ann_concept_aliases_list: Optional[List[str]] = None,
        kb: Optional[KnowledgeBase] = None,
        verbose: bool = False,
        ef_search: int = 200,
        name: Optional[str] = None,
    )",,,None,,,,,,
candidate_generation.py,python,class_method,,,,"Class method: CandidateGenerator.nmslib_knn_with_zero_vectors(
        self, vectors: numpy.ndarray, k: int
    ) -> Tuple[numpy.ndarray, numpy.ndarray]",allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,nmslib_knn_with_zero_vectors,"(
        self, vectors: numpy.ndarray, k: int
    )",,,"Tuple[numpy.ndarray, numpy.ndarray]",,,,,,
candidate_generation.py,python,class_method,,,,"Class method: CandidateGenerator.__call__(
        self, mention_texts: List[str], k: int
    ) -> List[List[MentionCandidate]]",allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,__call__,"(
        self, mention_texts: List[str], k: int
    )",,,List[List[MentionCandidate]],,,,,,
candidate_generation.py,python,class,,,,Class: LinkerPaths(NamedTuple),allenai,scispacy,v0.5.4,,,,,,,LinkerPaths,,,,,,,,,(NamedTuple),,
candidate_generation.py,python,class,,,,Class: MentionCandidate(NamedTuple),allenai,scispacy,v0.5.4,,,,,,,MentionCandidate,,,,,,,,,(NamedTuple),,
candidate_generation.py,python,class,,,,Class: CandidateGenerator,allenai,scispacy,v0.5.4,,,,,,,CandidateGenerator,,,,,,,,,,,
candidate_generation.py,python,function,,,,"Function: load_approximate_nearest_neighbours_index(
    linker_paths: LinkerPaths,
    ef_search: int = 200,
) -> FloatIndex",allenai,scispacy,v0.5.4,,,,load_approximate_nearest_neighbours_index,"(
    linker_paths: LinkerPaths,
    ef_search: int = 200,
)",,,,,,,,FloatIndex,,,,,
candidate_generation.py,python,function,,,,"Function: create_tfidf_ann_index(
    out_path: str, kb: Optional[KnowledgeBase] = None
) -> Tuple[List[str], TfidfVectorizer, FloatIndex]",allenai,scispacy,v0.5.4,,,,create_tfidf_ann_index,"(
    out_path: str, kb: Optional[KnowledgeBase] = None
)",,,,,,,,"Tuple[List[str], TfidfVectorizer, FloatIndex]",,,,,
candidate_generation.py,python,constant,"UmlsLinkerPaths = LinkerPaths(
    ann_index=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/concept_aliases.json"",  # noqa
)",UmlsLinkerPaths,"LinkerPaths(
    ann_index=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/concept_aliases.json"",  # noqa
)","Constant: UmlsLinkerPaths = LinkerPaths(
    ann_index=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/linkers/2023-04-23/umls/concept_aliases.json"",  # noqa
)",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
candidate_generation.py,python,constant,"MeshLinkerPaths = LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/concept_aliases.json"",  # noqa
)",MeshLinkerPaths,"LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/concept_aliases.json"",  # noqa
)","Constant: MeshLinkerPaths = LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/mesh/concept_aliases.json"",  # noqa
)",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
candidate_generation.py,python,constant,"GeneOntologyLinkerPaths = LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/concept_aliases.json"",  # noqa
)",GeneOntologyLinkerPaths,"LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/concept_aliases.json"",  # noqa
)","Constant: GeneOntologyLinkerPaths = LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/go/concept_aliases.json"",  # noqa
)",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
candidate_generation.py,python,constant,"HumanPhenotypeOntologyLinkerPaths = LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/concept_aliases.json"",  # noqa
)",HumanPhenotypeOntologyLinkerPaths,"LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/concept_aliases.json"",  # noqa
)","Constant: HumanPhenotypeOntologyLinkerPaths = LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/hpo/concept_aliases.json"",  # noqa
)",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
candidate_generation.py,python,constant,"RxNormLinkerPaths = LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/concept_aliases.json"",  # noqa
)",RxNormLinkerPaths,"LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/concept_aliases.json"",  # noqa
)","Constant: RxNormLinkerPaths = LinkerPaths(
    ann_index=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/nmslib_index.bin"",  # noqa
    tfidf_vectorizer=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/tfidf_vectorizer.joblib"",  # noqa
    tfidf_vectors=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/tfidf_vectors_sparse.npz"",  # noqa
    concept_aliases_list=""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/linkers/2023-04-23/rxnorm/concept_aliases.json"",  # noqa
)",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
candidate_generation.py,python,constant,"DEFAULT_PATHS: Dict[str, LinkerPaths] = {
    ""umls"": UmlsLinkerPaths,
    ""mesh"": MeshLinkerPaths,
    ""go"": GeneOntologyLinkerPaths,
    ""hpo"": HumanPhenotypeOntologyLinkerPaths,
    ""rxnorm"": RxNormLinkerPaths,
}",DEFAULT_PATHS,"{
    ""umls"": UmlsLinkerPaths,
    ""mesh"": MeshLinkerPaths,
    ""go"": GeneOntologyLinkerPaths,
    ""hpo"": HumanPhenotypeOntologyLinkerPaths,
    ""rxnorm"": RxNormLinkerPaths,
}","Constant: DEFAULT_PATHS: Dict[str, LinkerPaths] = {
    ""umls"": UmlsLinkerPaths,
    ""mesh"": MeshLinkerPaths,
    ""go"": GeneOntologyLinkerPaths,
    ""hpo"": HumanPhenotypeOntologyLinkerPaths,
    ""rxnorm"": RxNormLinkerPaths,
}",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
candidate_generation.py,python,constant,"DEFAULT_KNOWLEDGE_BASES: Dict[str, Type[KnowledgeBase]] = {
    ""umls"": UmlsKnowledgeBase,
    ""mesh"": Mesh,
    ""go"": GeneOntology,
    ""hpo"": HumanPhenotypeOntology,
    ""rxnorm"": RxNorm,
}",DEFAULT_KNOWLEDGE_BASES,"{
    ""umls"": UmlsKnowledgeBase,
    ""mesh"": Mesh,
    ""go"": GeneOntology,
    ""hpo"": HumanPhenotypeOntology,
    ""rxnorm"": RxNorm,
}","Constant: DEFAULT_KNOWLEDGE_BASES: Dict[str, Type[KnowledgeBase]] = {
    ""umls"": UmlsKnowledgeBase,
    ""mesh"": Mesh,
    ""go"": GeneOntology,
    ""hpo"": HumanPhenotypeOntology,
    ""rxnorm"": RxNorm,
}",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,"from typing import Optional, List, Dict, Tuple, NamedTuple, Type",typing,Optional,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,"from typing import Optional, List, Dict, Tuple, NamedTuple, Type",typing,List,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: Dict from typing,allenai,scispacy,v0.5.4,"from typing import Optional, List, Dict, Tuple, NamedTuple, Type",typing,Dict,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: Tuple from typing,allenai,scispacy,v0.5.4,"from typing import Optional, List, Dict, Tuple, NamedTuple, Type",typing,Tuple,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: NamedTuple from typing,allenai,scispacy,v0.5.4,"from typing import Optional, List, Dict, Tuple, NamedTuple, Type",typing,NamedTuple,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: Type from typing,allenai,scispacy,v0.5.4,"from typing import Optional, List, Dict, Tuple, NamedTuple, Type",typing,Type,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: json,allenai,scispacy,v0.5.4,import json,,json,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: datetime,allenai,scispacy,v0.5.4,import datetime,,datetime,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: defaultdict from collections,allenai,scispacy,v0.5.4,from collections import defaultdict,collections,defaultdict,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: scipy,allenai,scispacy,v0.5.4,import scipy,,scipy,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: numpy,allenai,scispacy,v0.5.4,import numpy,,numpy,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: joblib,allenai,scispacy,v0.5.4,import joblib,,joblib,,,,,,,,,,,,,,,
candidate_generation.py,python,import,,,,Import: nmslib,allenai,scispacy,v0.5.4,import nmslib,,nmslib,,,,,,,,,,,,,,,
candidate_generation.py,python,local_import,,,,Import: TfidfVectorizer from sklearn.feature_extraction.text,allenai,scispacy,v0.5.4,from sklearn.feature_extraction.text import TfidfVectorizer,sklearn.feature_extraction.text,TfidfVectorizer,,,sklearn.feature_extraction.text,,,,,,,,,,,,
candidate_generation.py,python,local_import,,,,Import: FloatIndex from nmslib.dist,allenai,scispacy,v0.5.4,from nmslib.dist import FloatIndex,nmslib.dist,FloatIndex,,,nmslib.dist,,,,,,,,,,,,
candidate_generation.py,python,local_import,,,,Import: cached_path from scispacy.file_cache,allenai,scispacy,v0.5.4,from scispacy.file_cache import cached_path,scispacy.file_cache,cached_path,,,scispacy.file_cache,,,,,,,,,,,,
candidate_generation.py,python,local_import,,,,Import: KnowledgeBase from scispacy.linking_utils,allenai,scispacy,v0.5.4,"from scispacy.linking_utils import (
    KnowledgeBase,
    UmlsKnowledgeBase,
    Mesh,
    GeneOntology,
    RxNorm,
    HumanPhenotypeOntology,
)",scispacy.linking_utils,KnowledgeBase,,,scispacy.linking_utils,,,,,,,,,,,,
candidate_generation.py,python,local_import,,,,Import: UmlsKnowledgeBase from scispacy.linking_utils,allenai,scispacy,v0.5.4,"from scispacy.linking_utils import (
    KnowledgeBase,
    UmlsKnowledgeBase,
    Mesh,
    GeneOntology,
    RxNorm,
    HumanPhenotypeOntology,
)",scispacy.linking_utils,UmlsKnowledgeBase,,,scispacy.linking_utils,,,,,,,,,,,,
candidate_generation.py,python,local_import,,,,Import: Mesh from scispacy.linking_utils,allenai,scispacy,v0.5.4,"from scispacy.linking_utils import (
    KnowledgeBase,
    UmlsKnowledgeBase,
    Mesh,
    GeneOntology,
    RxNorm,
    HumanPhenotypeOntology,
)",scispacy.linking_utils,Mesh,,,scispacy.linking_utils,,,,,,,,,,,,
candidate_generation.py,python,local_import,,,,Import: GeneOntology from scispacy.linking_utils,allenai,scispacy,v0.5.4,"from scispacy.linking_utils import (
    KnowledgeBase,
    UmlsKnowledgeBase,
    Mesh,
    GeneOntology,
    RxNorm,
    HumanPhenotypeOntology,
)",scispacy.linking_utils,GeneOntology,,,scispacy.linking_utils,,,,,,,,,,,,
candidate_generation.py,python,local_import,,,,Import: RxNorm from scispacy.linking_utils,allenai,scispacy,v0.5.4,"from scispacy.linking_utils import (
    KnowledgeBase,
    UmlsKnowledgeBase,
    Mesh,
    GeneOntology,
    RxNorm,
    HumanPhenotypeOntology,
)",scispacy.linking_utils,RxNorm,,,scispacy.linking_utils,,,,,,,,,,,,
candidate_generation.py,python,local_import,,,,Import: HumanPhenotypeOntology from scispacy.linking_utils,allenai,scispacy,v0.5.4,"from scispacy.linking_utils import (
    KnowledgeBase,
    UmlsKnowledgeBase,
    Mesh,
    GeneOntology,
    RxNorm,
    HumanPhenotypeOntology,
)",scispacy.linking_utils,HumanPhenotypeOntology,,,scispacy.linking_utils,,,,,,,,,,,,
candidate_generation.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
candidate_generation.py,python,,,,,Directory: scispacy\candidate_generation.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
consts.py,python,constant,"ABBREVIATIONS: List[str] = [
    ""sec."",
    ""secs."",
    ""Sec."",
    ""Secs."",
    ""fig."",
    ""figs."",
    ""Fig."",
    ""Figs."",
    ""eq."",
    ""eqs."",
    ""Eq."",
    ""Eqs."",
    ""no."",
    ""nos."",
    ""No."",
    ""Nos."",
    ""al."",
    ""gen."",
    ""sp."",
    ""nov."",
]",ABBREVIATIONS,"[
    ""sec."",
    ""secs."",
    ""Sec."",
    ""Secs."",
    ""fig."",
    ""figs."",
    ""Fig."",
    ""Figs."",
    ""eq."",
    ""eqs."",
    ""Eq."",
    ""Eqs."",
    ""no."",
    ""nos."",
    ""No."",
    ""Nos."",
    ""al."",
    ""gen."",
    ""sp."",
    ""nov."",
]","Constant: ABBREVIATIONS: List[str] = [
    ""sec."",
    ""secs."",
    ""Sec."",
    ""Secs."",
    ""fig."",
    ""figs."",
    ""Fig."",
    ""Figs."",
    ""eq."",
    ""eqs."",
    ""Eq."",
    ""Eqs."",
    ""no."",
    ""nos."",
    ""No."",
    ""Nos."",
    ""al."",
    ""gen."",
    ""sp."",
    ""nov."",
]",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
consts.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,from typing import List,typing,List,,,,,,,,,,,,,,,
consts.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
consts.py,python,,,,,Directory: scispacy\consts.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
custom_sentence_segmenter.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,from typing import List,typing,List,,,,,,,,,,,,,,,
custom_sentence_segmenter.py,python,import,,,,Import: pysbd,allenai,scispacy,v0.5.4,import pysbd,,pysbd,,,,,,,,,,,,,,,
custom_sentence_segmenter.py,python,local_import,,,,Import: Doc from spacy.tokens,allenai,scispacy,v0.5.4,from spacy.tokens import Doc,spacy.tokens,Doc,,,spacy.tokens,,,,,,,,,,,,
custom_sentence_segmenter.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
custom_sentence_segmenter.py,python,local_import,,,,Import: TextSpan from pysbd.utils,allenai,scispacy,v0.5.4,from pysbd.utils import TextSpan,pysbd.utils,TextSpan,,,pysbd.utils,,,,,,,,,,,,
custom_sentence_segmenter.py,python,local_import,,,,Import: ABBREVIATIONS from scispacy.consts,allenai,scispacy,v0.5.4,from scispacy.consts import ABBREVIATIONS,scispacy.consts,ABBREVIATIONS,,,scispacy.consts,,,,,,,,,,,,
custom_sentence_segmenter.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
custom_sentence_segmenter.py,python,,,,,Directory: scispacy\custom_sentence_segmenter.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
custom_tokenizer.py,python,function,,,,Function: remove_new_lines(text: str) -> str,allenai,scispacy,v0.5.4,,,,remove_new_lines,(text: str),,,,,,,,str,,,,,
custom_tokenizer.py,python,function,,,,Function: combined_rule_prefixes() -> List[str],allenai,scispacy,v0.5.4,,,,combined_rule_prefixes,(),,,,,,,,List[str],,,,,
custom_tokenizer.py,python,function,,,,Function: combined_rule_tokenizer(nlp: Language) -> Tokenizer,allenai,scispacy,v0.5.4,,,,combined_rule_tokenizer,(nlp: Language),,,,,,,,Tokenizer,,,,,
custom_tokenizer.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,from typing import List,typing,List,,,,,,,,,,,,,,,
custom_tokenizer.py,python,local_import,,,,Import: char_classes from spacy.lang,allenai,scispacy,v0.5.4,from spacy.lang import char_classes,spacy.lang,char_classes,,,spacy.lang,,,,,,,,,,,,
custom_tokenizer.py,python,local_import,,,,Import: ORTH from spacy.symbols,allenai,scispacy,v0.5.4,from spacy.symbols import ORTH,spacy.symbols,ORTH,,,spacy.symbols,,,,,,,,,,,,
custom_tokenizer.py,python,local_import,,,,Import: Tokenizer from spacy.tokenizer,allenai,scispacy,v0.5.4,from spacy.tokenizer import Tokenizer,spacy.tokenizer,Tokenizer,,,spacy.tokenizer,,,,,,,,,,,,
custom_tokenizer.py,python,local_import,,,,Import: compile_prefix_regex from spacy.util,allenai,scispacy,v0.5.4,"from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex",spacy.util,compile_prefix_regex,,,spacy.util,,,,,,,,,,,,
custom_tokenizer.py,python,local_import,,,,Import: compile_infix_regex from spacy.util,allenai,scispacy,v0.5.4,"from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex",spacy.util,compile_infix_regex,,,spacy.util,,,,,,,,,,,,
custom_tokenizer.py,python,local_import,,,,Import: compile_suffix_regex from spacy.util,allenai,scispacy,v0.5.4,"from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex",spacy.util,compile_suffix_regex,,,spacy.util,,,,,,,,,,,,
custom_tokenizer.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
custom_tokenizer.py,python,local_import,,,,Import: ABBREVIATIONS from scispacy.consts,allenai,scispacy,v0.5.4,from scispacy.consts import ABBREVIATIONS,scispacy.consts,ABBREVIATIONS,,,scispacy.consts,,,,,,,,,,,,
custom_tokenizer.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
custom_tokenizer.py,python,,,,,Directory: scispacy\custom_tokenizer.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
data_util.py,python,class_field,,,,Class field: MedMentionEntity.start: int,allenai,scispacy,v0.5.4,,,,,,,MedMentionEntity,,,start: int,,,,,start,,,
data_util.py,python,class_field,,,,Class field: MedMentionEntity.end: int,allenai,scispacy,v0.5.4,,,,,,,MedMentionEntity,,,end: int,,,,,end,,,
data_util.py,python,class_field,,,,Class field: MedMentionEntity.mention_text: str,allenai,scispacy,v0.5.4,,,,,,,MedMentionEntity,,,mention_text: str,,,,,mention_text,,,
data_util.py,python,class_field,,,,Class field: MedMentionEntity.mention_type: str,allenai,scispacy,v0.5.4,,,,,,,MedMentionEntity,,,mention_type: str,,,,,mention_type,,,
data_util.py,python,class_field,,,,Class field: MedMentionEntity.umls_id: str,allenai,scispacy,v0.5.4,,,,,,,MedMentionEntity,,,umls_id: str,,,,,umls_id,,,
data_util.py,python,class_field,,,,Class field: MedMentionExample.title: str,allenai,scispacy,v0.5.4,,,,,,,MedMentionExample,,,title: str,,,,,title,,,
data_util.py,python,class_field,,,,Class field: MedMentionExample.abstract: str,allenai,scispacy,v0.5.4,,,,,,,MedMentionExample,,,abstract: str,,,,,abstract,,,
data_util.py,python,class_field,,,,Class field: MedMentionExample.text: str,allenai,scispacy,v0.5.4,,,,,,,MedMentionExample,,,text: str,,,,,text,,,
data_util.py,python,class_field,,,,Class field: MedMentionExample.pubmed_id: str,allenai,scispacy,v0.5.4,,,,,,,MedMentionExample,,,pubmed_id: str,,,,,pubmed_id,,,
data_util.py,python,class_field,,,,Class field: MedMentionExample.entities: List[MedMentionEntity],allenai,scispacy,v0.5.4,,,,,,,MedMentionExample,,,entities: List[MedMentionEntity],,,,,entities,,,
data_util.py,python,class,,,,Class: MedMentionEntity(NamedTuple),allenai,scispacy,v0.5.4,,,,,,,MedMentionEntity,,,,,,,,,(NamedTuple),,
data_util.py,python,class,,,,Class: MedMentionExample(NamedTuple),allenai,scispacy,v0.5.4,,,,,,,MedMentionExample,,,,,,,,,(NamedTuple),,
data_util.py,python,function,,,,Function: process_example(lines: List[str]) -> MedMentionExample,allenai,scispacy,v0.5.4,,,,process_example,(lines: List[str]),,,,,,,,MedMentionExample,,,,,
data_util.py,python,function,,,,Function: med_mentions_example_iterator(filename: str) -> Iterator[MedMentionExample],allenai,scispacy,v0.5.4,,,,med_mentions_example_iterator,(filename: str),,,,,,,,Iterator[MedMentionExample],,,,,
data_util.py,python,function,,,,"Function: select_subset_of_overlapping_chain(
    chain: List[Tuple[int, int, str]]
) -> List[Tuple[int, int, str]]",allenai,scispacy,v0.5.4,,,,select_subset_of_overlapping_chain,"(
    chain: List[Tuple[int, int, str]]
)",,,,,,,,"List[Tuple[int, int, str]]",,,,,
data_util.py,python,function,,,,"Function: remove_overlapping_entities(
    sorted_spacy_format_entities: List[Tuple[int, int, str]]
) -> List[Tuple[int, int, str]]",allenai,scispacy,v0.5.4,,,,remove_overlapping_entities,"(
    sorted_spacy_format_entities: List[Tuple[int, int, str]]
)",,,,,,,,"List[Tuple[int, int, str]]",,,,,
data_util.py,python,function,,,,"Function: read_full_med_mentions(
    directory_path: str,
    label_mapping: Optional[Dict[str, str]] = None,
    span_only: bool = False,
    spacy_format: bool = True,
    use_umls_ids: bool = False,
)",allenai,scispacy,v0.5.4,,,,read_full_med_mentions,"(
    directory_path: str,
    label_mapping: Optional[Dict[str, str]] = None,
    span_only: bool = False,
    spacy_format: bool = True,
    use_umls_ids: bool = False,
)",,,,,,,,,,,,,
data_util.py,python,function,,,,"Function: _handle_sentence(examples: List[Tuple[str, str]]) -> SpacyNerExample",allenai,scispacy,v0.5.4,,,,_handle_sentence,"(examples: List[Tuple[str, str]])",,,,,,,,SpacyNerExample,,,,,
data_util.py,python,function,,,,Function: read_ner_from_tsv(filename: str) -> List[SpacyNerExample],allenai,scispacy,v0.5.4,,,,read_ner_from_tsv,(filename: str),,,,,,,,List[SpacyNerExample],,,,,
data_util.py,python,constant,"SpacyNerExample = Tuple[str, Dict[str, List[Tuple[int, int, str]]]]",SpacyNerExample,"Tuple[str, Dict[str, List[Tuple[int, int, str]]]]","Constant: SpacyNerExample = Tuple[str, Dict[str, List[Tuple[int, int, str]]]]",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,"from typing import Optional, NamedTuple, List, Iterator, Dict, Tuple",typing,Optional,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: NamedTuple from typing,allenai,scispacy,v0.5.4,"from typing import Optional, NamedTuple, List, Iterator, Dict, Tuple",typing,NamedTuple,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,"from typing import Optional, NamedTuple, List, Iterator, Dict, Tuple",typing,List,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: Iterator from typing,allenai,scispacy,v0.5.4,"from typing import Optional, NamedTuple, List, Iterator, Dict, Tuple",typing,Iterator,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: Dict from typing,allenai,scispacy,v0.5.4,"from typing import Optional, NamedTuple, List, Iterator, Dict, Tuple",typing,Dict,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: Tuple from typing,allenai,scispacy,v0.5.4,"from typing import Optional, NamedTuple, List, Iterator, Dict, Tuple",typing,Tuple,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: tarfile,allenai,scispacy,v0.5.4,import tarfile,,tarfile,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: atexit,allenai,scispacy,v0.5.4,import atexit,,atexit,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: shutil,allenai,scispacy,v0.5.4,import shutil,,shutil,,,,,,,,,,,,,,,
data_util.py,python,import,,,,Import: tempfile,allenai,scispacy,v0.5.4,import tempfile,,tempfile,,,,,,,,,,,,,,,
data_util.py,python,local_import,,,,Import: cached_path from scispacy.file_cache,allenai,scispacy,v0.5.4,from scispacy.file_cache import cached_path,scispacy.file_cache,cached_path,,,scispacy.file_cache,,,,,,,,,,,,
data_util.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
data_util.py,python,,,,,Directory: scispacy\data_util.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
file_cache.py,python,function,,,,"Function: cached_path(
    url_or_filename: Union[str, Path], cache_dir: Optional[str] = None
) -> str",allenai,scispacy,v0.5.4,,,,cached_path,"(
    url_or_filename: Union[str, Path], cache_dir: Optional[str] = None
)",,,,,,,,str,,,,,
file_cache.py,python,function,,,,"Function: url_to_filename(url: str, etag: Optional[str] = None) -> str",allenai,scispacy,v0.5.4,,,,url_to_filename,"(url: str, etag: Optional[str] = None)",,,,,,,,str,,,,,
file_cache.py,python,function,,,,"Function: filename_to_url(filename: str, cache_dir: Optional[str] = None) -> Tuple[str, str]",allenai,scispacy,v0.5.4,,,,filename_to_url,"(filename: str, cache_dir: Optional[str] = None)",,,,,,,,"Tuple[str, str]",,,,,
file_cache.py,python,function,,,,"Function: http_get(url: str, temp_file: IO) -> None",allenai,scispacy,v0.5.4,,,,http_get,"(url: str, temp_file: IO)",,,,,,,,None,,,,,
file_cache.py,python,function,,,,"Function: get_from_cache(url: str, cache_dir: Optional[str] = None) -> str",allenai,scispacy,v0.5.4,,,,get_from_cache,"(url: str, cache_dir: Optional[str] = None)",,,,,,,,str,,,,,
file_cache.py,python,constant,"CACHE_ROOT = Path(os.getenv(""SCISPACY_CACHE"", str(Path.home() / "".scispacy"")))",CACHE_ROOT,"Path(os.getenv(""SCISPACY_CACHE"", str(Path.home() / "".scispacy"")))","Constant: CACHE_ROOT = Path(os.getenv(""SCISPACY_CACHE"", str(Path.home() / "".scispacy"")))",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
file_cache.py,python,constant,"DATASET_CACHE = str(CACHE_ROOT / ""datasets"")",DATASET_CACHE,"str(CACHE_ROOT / ""datasets"")","Constant: DATASET_CACHE = str(CACHE_ROOT / ""datasets"")",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: shutil,allenai,scispacy,v0.5.4,import shutil,,shutil,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: tempfile,allenai,scispacy,v0.5.4,import tempfile,,tempfile,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: json,allenai,scispacy,v0.5.4,import json,,json,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: Path from pathlib,allenai,scispacy,v0.5.4,from pathlib import Path,pathlib,Path,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,"from typing import Optional, Tuple, Union, IO",typing,Optional,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: Tuple from typing,allenai,scispacy,v0.5.4,"from typing import Optional, Tuple, Union, IO",typing,Tuple,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: Union from typing,allenai,scispacy,v0.5.4,"from typing import Optional, Tuple, Union, IO",typing,Union,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: IO from typing,allenai,scispacy,v0.5.4,"from typing import Optional, Tuple, Union, IO",typing,IO,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: sha256 from hashlib,allenai,scispacy,v0.5.4,from hashlib import sha256,hashlib,sha256,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: requests,allenai,scispacy,v0.5.4,import requests,,requests,,,,,,,,,,,,,,,
file_cache.py,python,import,,,,Import: tqdm from tqdm,allenai,scispacy,v0.5.4,from tqdm import tqdm,tqdm,tqdm,,,,,,,,,,,,,,,
file_cache.py,python,local_import,,,,Import: urlparse from urllib.parse,allenai,scispacy,v0.5.4,from urllib.parse import urlparse,urllib.parse,urlparse,,,urllib.parse,,,,,,,,,,,,
file_cache.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
file_cache.py,python,,,,,Directory: scispacy\file_cache.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hearst_patterns.py,python,constant,"hypernym = {""POS"": {""IN"": [""NOUN"", ""PROPN"", ""PRON""]}}",hypernym,"{""POS"": {""IN"": [""NOUN"", ""PROPN"", ""PRON""]}}","Constant: hypernym = {""POS"": {""IN"": [""NOUN"", ""PROPN"", ""PRON""]}}",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hearst_patterns.py,python,constant,"hyponym = {""POS"": {""IN"": [""NOUN"", ""PROPN"", ""PRON""]}}",hyponym,"{""POS"": {""IN"": [""NOUN"", ""PROPN"", ""PRON""]}}","Constant: hyponym = {""POS"": {""IN"": [""NOUN"", ""PROPN"", ""PRON""]}}",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hearst_patterns.py,python,constant,"punct = {""IS_PUNCT"": True, ""OP"": ""?""}",punct,"{""IS_PUNCT"": True, ""OP"": ""?""}","Constant: punct = {""IS_PUNCT"": True, ""OP"": ""?""}",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hearst_patterns.py,python,constant,"det = {""ORTH"": ""*"", ""OP"": ""*""}",det,"{""ORTH"": ""*"", ""OP"": ""*""}","Constant: det = {""ORTH"": ""*"", ""OP"": ""*""}",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hearst_patterns.py,python,constant,"BASE_PATTERNS: List[Dict[str, Any]] = [
    # '(NP_\\w+ (, )?such as (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""such_as"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""such""}, {""LEMMA"": ""as""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?include (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""include"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""include""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?especially (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""especially"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""especially""}, det, hyponym],
        ""position"": ""first"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?other NP_\\w+)', 'last'
    {
        ""label"": ""other"",
        ""pattern"": [
            hyponym,
            punct,
            {""LEMMA"": {""IN"": [""and"", ""or""]}},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
]",BASE_PATTERNS,"[
    # '(NP_\\w+ (, )?such as (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""such_as"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""such""}, {""LEMMA"": ""as""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?include (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""include"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""include""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?especially (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""especially"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""especially""}, det, hyponym],
        ""position"": ""first"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?other NP_\\w+)', 'last'
    {
        ""label"": ""other"",
        ""pattern"": [
            hyponym,
            punct,
            {""LEMMA"": {""IN"": [""and"", ""or""]}},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
]","Constant: BASE_PATTERNS: List[Dict[str, Any]] = [
    # '(NP_\\w+ (, )?such as (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""such_as"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""such""}, {""LEMMA"": ""as""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?include (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""include"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""include""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?especially (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""especially"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""especially""}, det, hyponym],
        ""position"": ""first"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?other NP_\\w+)', 'last'
    {
        ""label"": ""other"",
        ""pattern"": [
            hyponym,
            punct,
            {""LEMMA"": {""IN"": [""and"", ""or""]}},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
]",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hearst_patterns.py,python,constant,"EXTENDED_PATTERNS = [
    # '(NP_\\w+ (, )?which may include (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""which_may_include"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""may""},
            {""LEMMA"": ""include""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?which be similar to (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""which_be_similar_to"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""be""},
            {""LEMMA"": ""similar""},
            {""LEMMA"": ""to""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?example of this be (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""example_of_this_be"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""example""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""this""},
            {""LEMMA"": ""be""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?type (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""type"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""type""}, punct, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?mainly (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""mainly"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""mainly""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?mostly (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""mostly"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""mostly""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?notably (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""notably"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""notably""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?particularly (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""particularly"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""particularly""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?principally (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""principally"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""principally""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?in particular (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""in_particular"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""in""},
            {""LEMMA"": ""particular""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?except (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""except"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""except""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?other than (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""other_than"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            {""LEMMA"": ""than""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?e.g. (, )?(NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""eg"",
        ""pattern"": [hypernym, punct, {""LEMMA"": {""IN"": [""e.g."", ""eg""]}}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?i.e. (, )?(NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""ie"",
        ""pattern"": [hypernym, punct, {""LEMMA"": {""IN"": [""i.e."", ""ie""]}}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?for example (, )?(NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""for_example"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""for""},
            {""LEMMA"": ""example""},
            punct,
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # 'example of (NP_\\w+ (, )?be (NP_\\w+ ? '(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""example_of_be"",
        ""pattern"": [
            {""LEMMA"": ""example""},
            {""LEMMA"": ""of""},
            hypernym,
            punct,
            {""LEMMA"": ""be""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?like (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""like"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""like""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # 'such (NP_\\w+ (, )?as (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""such_NOUN_as"",
        ""pattern"": [
            {""LEMMA"": ""such""},
            hypernym,
            punct,
            {""LEMMA"": ""as""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?whether (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""whether"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""whether""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?compare to (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""compare_to"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""compare""},
            {""LEMMA"": ""to""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?among -PRON- (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""among_-PRON-"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""among""},
            {""LEMMA"": ""-PRON-""},
            det,
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )? (NP_\\w+ ? (, )?(and |or )?)+ for instance)', 'first'
    {
        ""label"": ""for_instance"",
        ""pattern"": [
            hypernym,
            punct,
            det,
            hyponym,
            {""LEMMA"": ""for""},
            {""LEMMA"": ""instance""},
        ],
        ""position"": ""first"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?any other NP_\\w+)', 'last'
    {
        ""label"": ""and-or_any_other"",
        ""pattern"": [
            det,
            hyponym,
            punct,
            {""DEP"": ""cc""},
            {""LEMMA"": ""any""},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?some other NP_\\w+)', 'last'
    {
        ""label"": ""some_other"",
        ""pattern"": [
            det,
            hyponym,
            punct,
            {""DEP"": ""cc"", ""OP"": ""?""},
            {""LEMMA"": ""some""},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?be a NP_\\w+)', 'last'
    {
        ""label"": ""be_a"",
        ""pattern"": [
            det,
            hyponym,
            punct,
            {""LEMMA"": ""be""},
            {""LEMMA"": ""a""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""like_other"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?like other NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""like""},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""one_of_the"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?one of the NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""one""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""the""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""one_of_these"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?one of these NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""one""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""these""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""one_of_those"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?one of those NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""DEP"": ""cc"", ""OP"": ""?""},
            {""LEMMA"": ""one""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""those""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""be_example_of"",
        ""pattern"": [
            # '((NP_\\w+ ?(, )?)+(and |or )?be example of NP_\\w+)',
            # added optional ""an"" to spaCy pattern for singular vs. plural
            # 'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""be""},
            {""LEMMA"": ""an"", ""OP"": ""?""},
            {""LEMMA"": ""example""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""which_be_call"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which be call NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""be""},
            {""LEMMA"": ""call""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    #
    {
        ""label"": ""which_be_name"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which be name NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""be""},
            {""LEMMA"": ""name""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""a_kind_of"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and|or)? a kind of NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""a""},
            {""LEMMA"": ""kind""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    #                     '((NP_\\w+ ?(, )?)+(and|or)? kind of NP_\\w+)', - combined with above
    #                     'last'
    {
        ""label"": ""form_of"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and|or)? form of NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""a"", ""OP"": ""?""},
            {""LEMMA"": ""form""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""which_look_like"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which look like NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""look""},
            {""LEMMA"": ""like""},
            hyponym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""which_sound_like"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which sound like NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""sound""},
            {""LEMMA"": ""like""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""type"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )? NP_\\w+ type)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""type""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""compare_with"",
        ""pattern"": [
            #                     '(compare (NP_\\w+ ?(, )?)+(and |or )?with NP_\\w+)',
            #                     'last'
            {""LEMMA"": ""compare""},
            det,
            hyponym,
            punct,
            {""LEMMA"": ""with""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    #             {""label"" : ""as"", ""pattern"" : [
    # #                     '((NP_\\w+ ?(, )?)+(and |or )?as NP_\\w+)',
    # #                     'last'
    #                 hyponym, punct, {""LEMMA"" : ""as""}, hypernym
    #             ], ""position"" : ""last""},
    {
        ""label"": ""sort_of"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and|or)? sort of NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""sort""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
]",EXTENDED_PATTERNS,"[
    # '(NP_\\w+ (, )?which may include (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""which_may_include"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""may""},
            {""LEMMA"": ""include""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?which be similar to (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""which_be_similar_to"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""be""},
            {""LEMMA"": ""similar""},
            {""LEMMA"": ""to""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?example of this be (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""example_of_this_be"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""example""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""this""},
            {""LEMMA"": ""be""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?type (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""type"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""type""}, punct, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?mainly (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""mainly"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""mainly""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?mostly (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""mostly"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""mostly""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?notably (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""notably"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""notably""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?particularly (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""particularly"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""particularly""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?principally (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""principally"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""principally""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?in particular (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""in_particular"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""in""},
            {""LEMMA"": ""particular""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?except (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""except"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""except""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?other than (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""other_than"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            {""LEMMA"": ""than""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?e.g. (, )?(NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""eg"",
        ""pattern"": [hypernym, punct, {""LEMMA"": {""IN"": [""e.g."", ""eg""]}}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?i.e. (, )?(NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""ie"",
        ""pattern"": [hypernym, punct, {""LEMMA"": {""IN"": [""i.e."", ""ie""]}}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?for example (, )?(NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""for_example"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""for""},
            {""LEMMA"": ""example""},
            punct,
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # 'example of (NP_\\w+ (, )?be (NP_\\w+ ? '(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""example_of_be"",
        ""pattern"": [
            {""LEMMA"": ""example""},
            {""LEMMA"": ""of""},
            hypernym,
            punct,
            {""LEMMA"": ""be""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?like (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""like"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""like""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # 'such (NP_\\w+ (, )?as (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""such_NOUN_as"",
        ""pattern"": [
            {""LEMMA"": ""such""},
            hypernym,
            punct,
            {""LEMMA"": ""as""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?whether (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""whether"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""whether""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?compare to (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""compare_to"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""compare""},
            {""LEMMA"": ""to""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?among -PRON- (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""among_-PRON-"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""among""},
            {""LEMMA"": ""-PRON-""},
            det,
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )? (NP_\\w+ ? (, )?(and |or )?)+ for instance)', 'first'
    {
        ""label"": ""for_instance"",
        ""pattern"": [
            hypernym,
            punct,
            det,
            hyponym,
            {""LEMMA"": ""for""},
            {""LEMMA"": ""instance""},
        ],
        ""position"": ""first"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?any other NP_\\w+)', 'last'
    {
        ""label"": ""and-or_any_other"",
        ""pattern"": [
            det,
            hyponym,
            punct,
            {""DEP"": ""cc""},
            {""LEMMA"": ""any""},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?some other NP_\\w+)', 'last'
    {
        ""label"": ""some_other"",
        ""pattern"": [
            det,
            hyponym,
            punct,
            {""DEP"": ""cc"", ""OP"": ""?""},
            {""LEMMA"": ""some""},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?be a NP_\\w+)', 'last'
    {
        ""label"": ""be_a"",
        ""pattern"": [
            det,
            hyponym,
            punct,
            {""LEMMA"": ""be""},
            {""LEMMA"": ""a""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""like_other"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?like other NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""like""},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""one_of_the"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?one of the NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""one""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""the""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""one_of_these"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?one of these NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""one""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""these""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""one_of_those"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?one of those NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""DEP"": ""cc"", ""OP"": ""?""},
            {""LEMMA"": ""one""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""those""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""be_example_of"",
        ""pattern"": [
            # '((NP_\\w+ ?(, )?)+(and |or )?be example of NP_\\w+)',
            # added optional ""an"" to spaCy pattern for singular vs. plural
            # 'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""be""},
            {""LEMMA"": ""an"", ""OP"": ""?""},
            {""LEMMA"": ""example""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""which_be_call"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which be call NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""be""},
            {""LEMMA"": ""call""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    #
    {
        ""label"": ""which_be_name"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which be name NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""be""},
            {""LEMMA"": ""name""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""a_kind_of"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and|or)? a kind of NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""a""},
            {""LEMMA"": ""kind""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    #                     '((NP_\\w+ ?(, )?)+(and|or)? kind of NP_\\w+)', - combined with above
    #                     'last'
    {
        ""label"": ""form_of"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and|or)? form of NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""a"", ""OP"": ""?""},
            {""LEMMA"": ""form""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""which_look_like"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which look like NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""look""},
            {""LEMMA"": ""like""},
            hyponym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""which_sound_like"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which sound like NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""sound""},
            {""LEMMA"": ""like""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""type"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )? NP_\\w+ type)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""type""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""compare_with"",
        ""pattern"": [
            #                     '(compare (NP_\\w+ ?(, )?)+(and |or )?with NP_\\w+)',
            #                     'last'
            {""LEMMA"": ""compare""},
            det,
            hyponym,
            punct,
            {""LEMMA"": ""with""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    #             {""label"" : ""as"", ""pattern"" : [
    # #                     '((NP_\\w+ ?(, )?)+(and |or )?as NP_\\w+)',
    # #                     'last'
    #                 hyponym, punct, {""LEMMA"" : ""as""}, hypernym
    #             ], ""position"" : ""last""},
    {
        ""label"": ""sort_of"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and|or)? sort of NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""sort""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
]","Constant: EXTENDED_PATTERNS = [
    # '(NP_\\w+ (, )?which may include (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""which_may_include"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""may""},
            {""LEMMA"": ""include""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?which be similar to (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""which_be_similar_to"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""be""},
            {""LEMMA"": ""similar""},
            {""LEMMA"": ""to""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?example of this be (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""example_of_this_be"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""example""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""this""},
            {""LEMMA"": ""be""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?type (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""type"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""type""}, punct, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?mainly (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""mainly"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""mainly""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?mostly (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""mostly"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""mostly""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?notably (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""notably"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""notably""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?particularly (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""particularly"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""particularly""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?principally (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""principally"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""principally""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?in particular (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""in_particular"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""in""},
            {""LEMMA"": ""particular""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?except (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""except"",
        ""pattern"": [hypernym, punct, {""LEMMA"": ""except""}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?other than (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""other_than"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            {""LEMMA"": ""than""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?e.g. (, )?(NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""eg"",
        ""pattern"": [hypernym, punct, {""LEMMA"": {""IN"": [""e.g."", ""eg""]}}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?i.e. (, )?(NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""ie"",
        ""pattern"": [hypernym, punct, {""LEMMA"": {""IN"": [""i.e."", ""ie""]}}, det, hyponym],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?for example (, )?(NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""for_example"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""for""},
            {""LEMMA"": ""example""},
            punct,
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # 'example of (NP_\\w+ (, )?be (NP_\\w+ ? '(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""example_of_be"",
        ""pattern"": [
            {""LEMMA"": ""example""},
            {""LEMMA"": ""of""},
            hypernym,
            punct,
            {""LEMMA"": ""be""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?like (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""like"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""like""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # 'such (NP_\\w+ (, )?as (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""such_NOUN_as"",
        ""pattern"": [
            {""LEMMA"": ""such""},
            hypernym,
            punct,
            {""LEMMA"": ""as""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?whether (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""whether"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""whether""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?compare to (NP_\\w+ ? (, )?(and |or )?)+)', 'first'
    {
        ""label"": ""compare_to"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""compare""},
            {""LEMMA"": ""to""},
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )?among -PRON- (NP_\\w+ ?(, )?(and |or )?)+)', 'first'
    {
        ""label"": ""among_-PRON-"",
        ""pattern"": [
            hypernym,
            punct,
            {""LEMMA"": ""among""},
            {""LEMMA"": ""-PRON-""},
            det,
            det,
            hyponym,
        ],
        ""position"": ""first"",
    },
    # '(NP_\\w+ (, )? (NP_\\w+ ? (, )?(and |or )?)+ for instance)', 'first'
    {
        ""label"": ""for_instance"",
        ""pattern"": [
            hypernym,
            punct,
            det,
            hyponym,
            {""LEMMA"": ""for""},
            {""LEMMA"": ""instance""},
        ],
        ""position"": ""first"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?any other NP_\\w+)', 'last'
    {
        ""label"": ""and-or_any_other"",
        ""pattern"": [
            det,
            hyponym,
            punct,
            {""DEP"": ""cc""},
            {""LEMMA"": ""any""},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?some other NP_\\w+)', 'last'
    {
        ""label"": ""some_other"",
        ""pattern"": [
            det,
            hyponym,
            punct,
            {""DEP"": ""cc"", ""OP"": ""?""},
            {""LEMMA"": ""some""},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
    # '((NP_\\w+ ?(, )?)+(and |or )?be a NP_\\w+)', 'last'
    {
        ""label"": ""be_a"",
        ""pattern"": [
            det,
            hyponym,
            punct,
            {""LEMMA"": ""be""},
            {""LEMMA"": ""a""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""like_other"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?like other NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""like""},
            {""LEMMA"": {""IN"": [""other"", ""oth""]}},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""one_of_the"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?one of the NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""one""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""the""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""one_of_these"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?one of these NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""one""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""these""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""one_of_those"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?one of those NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""DEP"": ""cc"", ""OP"": ""?""},
            {""LEMMA"": ""one""},
            {""LEMMA"": ""of""},
            {""LEMMA"": ""those""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""be_example_of"",
        ""pattern"": [
            # '((NP_\\w+ ?(, )?)+(and |or )?be example of NP_\\w+)',
            # added optional ""an"" to spaCy pattern for singular vs. plural
            # 'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""be""},
            {""LEMMA"": ""an"", ""OP"": ""?""},
            {""LEMMA"": ""example""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""which_be_call"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which be call NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""be""},
            {""LEMMA"": ""call""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    #
    {
        ""label"": ""which_be_name"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which be name NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""be""},
            {""LEMMA"": ""name""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""a_kind_of"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and|or)? a kind of NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""a""},
            {""LEMMA"": ""kind""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    #                     '((NP_\\w+ ?(, )?)+(and|or)? kind of NP_\\w+)', - combined with above
    #                     'last'
    {
        ""label"": ""form_of"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and|or)? form of NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""a"", ""OP"": ""?""},
            {""LEMMA"": ""form""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""which_look_like"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which look like NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""look""},
            {""LEMMA"": ""like""},
            hyponym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""which_sound_like"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )?which sound like NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""which""},
            {""LEMMA"": ""sound""},
            {""LEMMA"": ""like""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""type"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and |or )? NP_\\w+ type)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""type""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    {
        ""label"": ""compare_with"",
        ""pattern"": [
            #                     '(compare (NP_\\w+ ?(, )?)+(and |or )?with NP_\\w+)',
            #                     'last'
            {""LEMMA"": ""compare""},
            det,
            hyponym,
            punct,
            {""LEMMA"": ""with""},
            hypernym,
        ],
        ""position"": ""last"",
    },
    #             {""label"" : ""as"", ""pattern"" : [
    # #                     '((NP_\\w+ ?(, )?)+(and |or )?as NP_\\w+)',
    # #                     'last'
    #                 hyponym, punct, {""LEMMA"" : ""as""}, hypernym
    #             ], ""position"" : ""last""},
    {
        ""label"": ""sort_of"",
        ""pattern"": [
            #                     '((NP_\\w+ ?(, )?)+(and|or)? sort of NP_\\w+)',
            #                     'last'
            det,
            hyponym,
            punct,
            {""LEMMA"": ""sort""},
            {""LEMMA"": ""of""},
            hypernym,
        ],
        ""position"": ""last"",
    },
]",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hearst_patterns.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,"from typing import List, Dict, Any",typing,List,,,,,,,,,,,,,,,
hearst_patterns.py,python,import,,,,Import: Dict from typing,allenai,scispacy,v0.5.4,"from typing import List, Dict, Any",typing,Dict,,,,,,,,,,,,,,,
hearst_patterns.py,python,import,,,,Import: Any from typing,allenai,scispacy,v0.5.4,"from typing import List, Dict, Any",typing,Any,,,,,,,,,,,,,,,
hearst_patterns.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hearst_patterns.py,python,,,,,Directory: scispacy\hearst_patterns.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hyponym_detector.py,python,class_field,,,,Class field: [instance] HyponymDetector.nlp = nlp,allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,__init__,"(
        self, nlp: Language, name: str = ""hyponym_detector"", extended: bool = False
    )",self.nlp = nlp,self.nlp = nlp,,,,,,,
hyponym_detector.py,python,class_field,,,,Class field: [instance] HyponymDetector.patterns = BASE_PATTERNS,allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,__init__,"(
        self, nlp: Language, name: str = ""hyponym_detector"", extended: bool = False
    )",self.patterns = BASE_PATTERNS,self.patterns = BASE_PATTERNS,,,,,,,
hyponym_detector.py,python,class_field,,,,Class field: [instance] HyponymDetector.matcher = Matcher(nlp.vocab),allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,__init__,"(
        self, nlp: Language, name: str = ""hyponym_detector"", extended: bool = False
    )",self.matcher = Matcher(self.nlp.vocab),self.matcher = Matcher(self.nlp.vocab),,,,,,,
hyponym_detector.py,python,class_field,,,,Class field: [instance] HyponymDetector.first = set(),allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,__init__,"(
        self, nlp: Language, name: str = ""hyponym_detector"", extended: bool = False
    )",self.first = set(),self.first = set(),,,,,,,
hyponym_detector.py,python,class_field,,,,Class field: [instance] HyponymDetector.last = set(),allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,__init__,"(
        self, nlp: Language, name: str = ""hyponym_detector"", extended: bool = False
    )",self.last = set(),self.last = set(),,,,,,,
hyponym_detector.py,python,class_method,,,,"Class method: HyponymDetector.__init__(
        self, nlp: Language, name: str = ""hyponym_detector"", extended: bool = False
    )",allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,__init__,"(
        self, nlp: Language, name: str = ""hyponym_detector"", extended: bool = False
    )",,,,,,,,,
hyponym_detector.py,python,class_method,,,,"Class method: HyponymDetector.expand_to_noun_compound(self, token: Token, doc: Doc)",allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,expand_to_noun_compound,"(self, token: Token, doc: Doc)",,,,,,,,,
hyponym_detector.py,python,class_method,,,,"Class method: HyponymDetector.find_noun_compound_head(self, token: Token)",allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,find_noun_compound_head,"(self, token: Token)",,,,,,,,,
hyponym_detector.py,python,class_method,,,,"Class method: HyponymDetector.__call__(self, doc: Doc)",allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,__call__,"(self, doc: Doc)",,,,,,,,,
hyponym_detector.py,python,class,,,,Class: HyponymDetector,allenai,scispacy,v0.5.4,,,,,,,HyponymDetector,,,,,,,,,,,
hyponym_detector.py,python,local_import,,,,Import: Matcher from spacy.matcher,allenai,scispacy,v0.5.4,from spacy.matcher import Matcher,spacy.matcher,Matcher,,,spacy.matcher,,,,,,,,,,,,
hyponym_detector.py,python,local_import,,,,Import: Token from spacy.tokens,allenai,scispacy,v0.5.4,"from spacy.tokens import Token, Doc",spacy.tokens,Token,,,spacy.tokens,,,,,,,,,,,,
hyponym_detector.py,python,local_import,,,,Import: Doc from spacy.tokens,allenai,scispacy,v0.5.4,"from spacy.tokens import Token, Doc",spacy.tokens,Doc,,,spacy.tokens,,,,,,,,,,,,
hyponym_detector.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
hyponym_detector.py,python,local_import,,,,Import: BASE_PATTERNS from scispacy.hearst_patterns,allenai,scispacy,v0.5.4,"from scispacy.hearst_patterns import BASE_PATTERNS, EXTENDED_PATTERNS",scispacy.hearst_patterns,BASE_PATTERNS,,,scispacy.hearst_patterns,,,,,,,,,,,,
hyponym_detector.py,python,local_import,,,,Import: EXTENDED_PATTERNS from scispacy.hearst_patterns,allenai,scispacy,v0.5.4,"from scispacy.hearst_patterns import BASE_PATTERNS, EXTENDED_PATTERNS",scispacy.hearst_patterns,EXTENDED_PATTERNS,,,scispacy.hearst_patterns,,,,,,,,,,,,
hyponym_detector.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
hyponym_detector.py,python,,,,,Directory: scispacy\hyponym_detector.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
linking.py,python,class_field,,,,"Class field: [instance] EntityLinker.candidate_generator = candidate_generator or CandidateGenerator(
            name=linker_name
        )",allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__init__,"(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )","self.candidate_generator = candidate_generator or CandidateGenerator(
            name=linker_name
        )","self.candidate_generator = candidate_generator or CandidateGenerator(
            name=linker_name
        )",,,,,,,
linking.py,python,class_field,,,,Class field: [instance] EntityLinker.resolve_abbreviations = resolve_abbreviations,allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__init__,"(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )",self.resolve_abbreviations = resolve_abbreviations,self.resolve_abbreviations = resolve_abbreviations,,,,,,,
linking.py,python,class_field,,,,Class field: [instance] EntityLinker.k = k,allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__init__,"(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )",self.k = k,self.k = k,,,,,,,
linking.py,python,class_field,,,,Class field: [instance] EntityLinker.threshold = threshold,allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__init__,"(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )",self.threshold = threshold,self.threshold = threshold,,,,,,,
linking.py,python,class_field,,,,Class field: [instance] EntityLinker.no_definition_threshold = no_definition_threshold,allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__init__,"(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )",self.no_definition_threshold = no_definition_threshold,self.no_definition_threshold = no_definition_threshold,,,,,,,
linking.py,python,class_field,,,,Class field: [instance] EntityLinker.kb = candidate_generator.kb,allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__init__,"(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )",self.kb = self.candidate_generator.kb,self.kb = self.candidate_generator.kb,,,,,,,
linking.py,python,class_field,,,,Class field: [instance] EntityLinker.filter_for_definitions = filter_for_definitions,allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__init__,"(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )",self.filter_for_definitions = filter_for_definitions,self.filter_for_definitions = filter_for_definitions,,,,,,,
linking.py,python,class_field,,,,Class field: [instance] EntityLinker.max_entities_per_mention = max_entities_per_mention,allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__init__,"(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )",self.max_entities_per_mention = max_entities_per_mention,self.max_entities_per_mention = max_entities_per_mention,,,,,,,
linking.py,python,class_method,,,,"Class method: EntityLinker.__init__(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )",allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__init__,"(
        self,
        nlp: Optional[Language] = None,
        name: str = ""scispacy_linker"",
        candidate_generator: Optional[CandidateGenerator] = None,
        resolve_abbreviations: bool = True,
        k: int = 30,
        threshold: float = 0.7,
        no_definition_threshold: float = 0.95,
        filter_for_definitions: bool = True,
        max_entities_per_mention: int = 5,
        linker_name: Optional[str] = None,
    )",,,,,,,,,
linking.py,python,class_method,,,,"Class method: EntityLinker.__call__(self, doc: Doc) -> Doc",allenai,scispacy,v0.5.4,,,,,,,EntityLinker,__call__,"(self, doc: Doc)",,,Doc,,,,,,
linking.py,python,class,,,,Class: EntityLinker,allenai,scispacy,v0.5.4,,,,,,,EntityLinker,,,,,,,,,,,
linking.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,from typing import Optional,typing,Optional,,,,,,,,,,,,,,,
linking.py,python,local_import,,,,Import: Doc from spacy.tokens,allenai,scispacy,v0.5.4,from spacy.tokens import Doc,spacy.tokens,Doc,,,spacy.tokens,,,,,,,,,,,,
linking.py,python,local_import,,,,Import: Span from spacy.tokens,allenai,scispacy,v0.5.4,from spacy.tokens import Span,spacy.tokens,Span,,,spacy.tokens,,,,,,,,,,,,
linking.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
linking.py,python,local_import,,,,Import: CandidateGenerator from scispacy.candidate_generation,allenai,scispacy,v0.5.4,from scispacy.candidate_generation import CandidateGenerator,scispacy.candidate_generation,CandidateGenerator,,,scispacy.candidate_generation,,,,,,,,,,,,
linking.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
linking.py,python,,,,,Directory: scispacy\linking.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
linking_utils.py,python,class_field,,,,Class field: Entity.concept_id: str,allenai,scispacy,v0.5.4,,,,,,,Entity,,,concept_id: str,,,,,concept_id,,,
linking_utils.py,python,class_field,,,,Class field: Entity.canonical_name: str,allenai,scispacy,v0.5.4,,,,,,,Entity,,,canonical_name: str,,,,,canonical_name,,,
linking_utils.py,python,class_field,,,,Class field: Entity.aliases: List[str],allenai,scispacy,v0.5.4,,,,,,,Entity,,,aliases: List[str],,,,,aliases,,,
linking_utils.py,python,class_field,,,,Class field: Entity.types: List[str] = [],allenai,scispacy,v0.5.4,,,,,,,Entity,,,types: List[str] = [],,,,,types,,[],
linking_utils.py,python,class_field,,,,Class field: Entity.definition: Optional[str] = None,allenai,scispacy,v0.5.4,,,,,,,Entity,,,definition: Optional[str] = None,,,,,definition,,None,
linking_utils.py,python,class_field,,,,"Class field: [instance] KnowledgeBase.cui_to_entity: Dict[str, Entity] = {}",allenai,scispacy,v0.5.4,,,,,,,KnowledgeBase,__init__,"(
        self,
        file_path: Optional[str] = None,
    )","self.cui_to_entity: Dict[str, Entity] = {}","self.cui_to_entity: Dict[str, Entity] = {}",,,,,,,
linking_utils.py,python,class_field,,,,"Class field: [instance] KnowledgeBase.alias_to_cuis: Dict[str, Set[str]] = {**alias_to_cuis}",allenai,scispacy,v0.5.4,,,,,,,KnowledgeBase,__init__,"(
        self,
        file_path: Optional[str] = None,
    )","self.alias_to_cuis: Dict[str, Set[str]] = {**alias_to_cuis}","self.alias_to_cuis: Dict[str, Set[str]] = {**alias_to_cuis}",,,,,,,
linking_utils.py,python,class_field,,,,"Class field: [instance] UmlsKnowledgeBase.semantic_type_tree: UmlsSemanticTypeTree = construct_umls_tree_from_tsv(
            types_file_path
        )",allenai,scispacy,v0.5.4,,,,,,,UmlsKnowledgeBase,__init__,"(
        self,
        file_path: str = DEFAULT_UMLS_PATH,
        types_file_path: str = DEFAULT_UMLS_TYPES_PATH,
    )","self.semantic_type_tree: UmlsSemanticTypeTree = construct_umls_tree_from_tsv(
            types_file_path
        )","self.semantic_type_tree: UmlsSemanticTypeTree = construct_umls_tree_from_tsv(
            types_file_path
        )",,,,,,,
linking_utils.py,python,class_method,,,,Class method: Entity.__repr__(self),allenai,scispacy,v0.5.4,,,,,,,Entity,__repr__,(self),,,,,,,,,
linking_utils.py,python,class_method,,,,"Class method: KnowledgeBase.__init__(
        self,
        file_path: Optional[str] = None,
    )",allenai,scispacy,v0.5.4,,,,,,,KnowledgeBase,__init__,"(
        self,
        file_path: Optional[str] = None,
    )",,,,,,,,,
linking_utils.py,python,class_method,,,,"Class method: UmlsKnowledgeBase.__init__(
        self,
        file_path: str = DEFAULT_UMLS_PATH,
        types_file_path: str = DEFAULT_UMLS_TYPES_PATH,
    )",allenai,scispacy,v0.5.4,,,,,,,UmlsKnowledgeBase,__init__,"(
        self,
        file_path: str = DEFAULT_UMLS_PATH,
        types_file_path: str = DEFAULT_UMLS_TYPES_PATH,
    )",,,,,,,,,
linking_utils.py,python,class_method,,,,"Class method: Mesh.__init__(
        self,
        file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/kbs/2023-04-23/umls_mesh_2022.jsonl"",  # noqa
    )",allenai,scispacy,v0.5.4,,,,,,,Mesh,__init__,"(
        self,
        file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/kbs/2023-04-23/umls_mesh_2022.jsonl"",  # noqa
    )",,,,,,,,,
linking_utils.py,python,class_method,,,,"Class method: GeneOntology.__init__(
        self,
        file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/kbs/2023-04-23/umls_go_2022.jsonl"",  # noqa
    )",allenai,scispacy,v0.5.4,,,,,,,GeneOntology,__init__,"(
        self,
        file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/kbs/2023-04-23/umls_go_2022.jsonl"",  # noqa
    )",,,,,,,,,
linking_utils.py,python,class_method,,,,"Class method: HumanPhenotypeOntology.__init__(
        self,
        file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/kbs/2023-04-23/umls_hpo_2022.jsonl"",  # noqa
    )",allenai,scispacy,v0.5.4,,,,,,,HumanPhenotypeOntology,__init__,"(
        self,
        file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/kbs/2023-04-23/umls_hpo_2022.jsonl"",  # noqa
    )",,,,,,,,,
linking_utils.py,python,class_method,,,,"Class method: RxNorm.__init__(
        self,
        file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/kbs/2023-04-23/umls_rxnorm_2022.jsonl"",  # noqa
    )",allenai,scispacy,v0.5.4,,,,,,,RxNorm,__init__,"(
        self,
        file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/kbs/2023-04-23/umls_rxnorm_2022.jsonl"",  # noqa
    )",,,,,,,,,
linking_utils.py,python,class,,,,Class: Entity(NamedTuple),allenai,scispacy,v0.5.4,,,,,,,Entity,,,,,,,,,(NamedTuple),,
linking_utils.py,python,class,,,,Class: KnowledgeBase,allenai,scispacy,v0.5.4,,,,,,,KnowledgeBase,,,,,,,,,,,
linking_utils.py,python,class,,,,Class: UmlsKnowledgeBase(KnowledgeBase),allenai,scispacy,v0.5.4,,,,,,,UmlsKnowledgeBase,,,,,,,,,(KnowledgeBase),,
linking_utils.py,python,class,,,,Class: Mesh(KnowledgeBase),allenai,scispacy,v0.5.4,,,,,,,Mesh,,,,,,,,,(KnowledgeBase),,
linking_utils.py,python,class,,,,Class: GeneOntology(KnowledgeBase),allenai,scispacy,v0.5.4,,,,,,,GeneOntology,,,,,,,,,(KnowledgeBase),,
linking_utils.py,python,class,,,,Class: HumanPhenotypeOntology(KnowledgeBase),allenai,scispacy,v0.5.4,,,,,,,HumanPhenotypeOntology,,,,,,,,,(KnowledgeBase),,
linking_utils.py,python,class,,,,Class: RxNorm(KnowledgeBase),allenai,scispacy,v0.5.4,,,,,,,RxNorm,,,,,,,,,(KnowledgeBase),,
linking_utils.py,python,constant,"DEFAULT_UMLS_PATH = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/kbs/2023-04-23/umls_2022_ab_cat0129.jsonl""",DEFAULT_UMLS_PATH,"""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/kbs/2023-04-23/umls_2022_ab_cat0129.jsonl""","Constant: DEFAULT_UMLS_PATH = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/kbs/2023-04-23/umls_2022_ab_cat0129.jsonl""",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
linking_utils.py,python,constant,"DEFAULT_UMLS_TYPES_PATH = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/umls_semantic_type_tree.tsv""",DEFAULT_UMLS_TYPES_PATH,"""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/umls_semantic_type_tree.tsv""","Constant: DEFAULT_UMLS_TYPES_PATH = ""https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/data/umls_semantic_type_tree.tsv""",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
linking_utils.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,"from typing import List, Dict, NamedTuple, Optional, Set",typing,List,,,,,,,,,,,,,,,
linking_utils.py,python,import,,,,Import: Dict from typing,allenai,scispacy,v0.5.4,"from typing import List, Dict, NamedTuple, Optional, Set",typing,Dict,,,,,,,,,,,,,,,
linking_utils.py,python,import,,,,Import: NamedTuple from typing,allenai,scispacy,v0.5.4,"from typing import List, Dict, NamedTuple, Optional, Set",typing,NamedTuple,,,,,,,,,,,,,,,
linking_utils.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,"from typing import List, Dict, NamedTuple, Optional, Set",typing,Optional,,,,,,,,,,,,,,,
linking_utils.py,python,import,,,,Import: Set from typing,allenai,scispacy,v0.5.4,"from typing import List, Dict, NamedTuple, Optional, Set",typing,Set,,,,,,,,,,,,,,,
linking_utils.py,python,import,,,,Import: json,allenai,scispacy,v0.5.4,import json,,json,,,,,,,,,,,,,,,
linking_utils.py,python,import,,,,Import: defaultdict from collections,allenai,scispacy,v0.5.4,from collections import defaultdict,collections,defaultdict,,,,,,,,,,,,,,,
linking_utils.py,python,local_import,,,,Import: cached_path from scispacy.file_cache,allenai,scispacy,v0.5.4,from scispacy.file_cache import cached_path,scispacy.file_cache,cached_path,,,scispacy.file_cache,,,,,,,,,,,,
linking_utils.py,python,local_import,,,,Import: UmlsSemanticTypeTree from scispacy.umls_semantic_type_tree,allenai,scispacy,v0.5.4,"from scispacy.umls_semantic_type_tree import (
    UmlsSemanticTypeTree,
    construct_umls_tree_from_tsv,
)",scispacy.umls_semantic_type_tree,UmlsSemanticTypeTree,,,scispacy.umls_semantic_type_tree,,,,,,,,,,,,
linking_utils.py,python,local_import,,,,Import: construct_umls_tree_from_tsv from scispacy.umls_semantic_type_tree,allenai,scispacy,v0.5.4,"from scispacy.umls_semantic_type_tree import (
    UmlsSemanticTypeTree,
    construct_umls_tree_from_tsv,
)",scispacy.umls_semantic_type_tree,construct_umls_tree_from_tsv,,,scispacy.umls_semantic_type_tree,,,,,,,,,,,,
linking_utils.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
linking_utils.py,python,,,,,Directory: scispacy\linking_utils.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
per_class_scorer.py,python,class_field,,,,"Class field: [instance] PerClassScorer._true_positives: Dict[str, int] = defaultdict(int)",allenai,scispacy,v0.5.4,,,,,,,PerClassScorer,__init__,(self),"self._true_positives: Dict[str, int] = defaultdict(int)","self._true_positives: Dict[str, int] = defaultdict(int)",,,,,,,
per_class_scorer.py,python,class_field,,,,"Class field: [instance] PerClassScorer._false_positives: Dict[str, int] = defaultdict(int)",allenai,scispacy,v0.5.4,,,,,,,PerClassScorer,__init__,(self),"self._false_positives: Dict[str, int] = defaultdict(int)","self._false_positives: Dict[str, int] = defaultdict(int)",,,,,,,
per_class_scorer.py,python,class_field,,,,"Class field: [instance] PerClassScorer._false_negatives: Dict[str, int] = defaultdict(int)",allenai,scispacy,v0.5.4,,,,,,,PerClassScorer,__init__,(self),"self._false_negatives: Dict[str, int] = defaultdict(int)","self._false_negatives: Dict[str, int] = defaultdict(int)",,,,,,,
per_class_scorer.py,python,class_method,,,,Class method: PerClassScorer.__init__(self),allenai,scispacy,v0.5.4,,,,,,,PerClassScorer,__init__,(self),,,,,,,,,
per_class_scorer.py,python,class_method,,,,"Class method: PerClassScorer.__call__(
        self,
        predicted_spans: List[Tuple[int, int, str]],
        gold_spans: List[Tuple[int, int, str]],
    ) -> None",allenai,scispacy,v0.5.4,,,,,,,PerClassScorer,__call__,"(
        self,
        predicted_spans: List[Tuple[int, int, str]],
        gold_spans: List[Tuple[int, int, str]],
    )",,,None,,,,,,
per_class_scorer.py,python,class_method,,,,"Class method: PerClassScorer.get_metric(self, reset: bool = False)",allenai,scispacy,v0.5.4,,,,,,,PerClassScorer,get_metric,"(self, reset: bool = False)",,,,,,,,,
per_class_scorer.py,python,class_method,,,,"Class method: [staticmethod] PerClassScorer._compute_metrics(
        true_positives: int, false_positives: int, false_negatives: int
    )",allenai,scispacy,v0.5.4,,,,,,,PerClassScorer,_compute_metrics,"(
        true_positives: int, false_positives: int, false_negatives: int
    )",,,,,,,,,staticmethod
per_class_scorer.py,python,class_method,,,,Class method: PerClassScorer.reset(self),allenai,scispacy,v0.5.4,,,,,,,PerClassScorer,reset,(self),,,,,,,,,
per_class_scorer.py,python,class,,,,Class: PerClassScorer,allenai,scispacy,v0.5.4,,,,,,,PerClassScorer,,,,,,,,,,,
per_class_scorer.py,python,import,,,,Import: Dict from typing,allenai,scispacy,v0.5.4,"from typing import Dict, List, Tuple, Set",typing,Dict,,,,,,,,,,,,,,,
per_class_scorer.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,"from typing import Dict, List, Tuple, Set",typing,List,,,,,,,,,,,,,,,
per_class_scorer.py,python,import,,,,Import: Tuple from typing,allenai,scispacy,v0.5.4,"from typing import Dict, List, Tuple, Set",typing,Tuple,,,,,,,,,,,,,,,
per_class_scorer.py,python,import,,,,Import: Set from typing,allenai,scispacy,v0.5.4,"from typing import Dict, List, Tuple, Set",typing,Set,,,,,,,,,,,,,,,
per_class_scorer.py,python,import,,,,Import: defaultdict from collections,allenai,scispacy,v0.5.4,from collections import defaultdict,collections,defaultdict,,,,,,,,,,,,,,,
per_class_scorer.py,python,import,,,,Import: copy,allenai,scispacy,v0.5.4,import copy,,copy,,,,,,,,,,,,,,,
per_class_scorer.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
per_class_scorer.py,python,,,,,Directory: scispacy\per_class_scorer.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
train_utils.py,python,function,,,,"Function: evaluate_ner(
    nlp: Language, eval_data, dump_path: Optional[str] = None, verbose: bool = False
) -> PerClassScorer",allenai,scispacy,v0.5.4,,,,evaluate_ner,"(
    nlp: Language, eval_data, dump_path: Optional[str] = None, verbose: bool = False
)",,,,,,,,PerClassScorer,,,,,
train_utils.py,python,import,,,,Import: json,allenai,scispacy,v0.5.4,import json,,json,,,,,,,,,,,,,,,
train_utils.py,python,import,,,,Import: tqdm,allenai,scispacy,v0.5.4,import tqdm,,tqdm,,,,,,,,,,,,,,,
train_utils.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,from typing import Optional,typing,Optional,,,,,,,,,,,,,,,
train_utils.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
train_utils.py,python,local_import,,,,Import: PerClassScorer from scispacy.per_class_scorer,allenai,scispacy,v0.5.4,from scispacy.per_class_scorer import PerClassScorer,scispacy.per_class_scorer,PerClassScorer,,,scispacy.per_class_scorer,,,,,,,,,,,,
train_utils.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
train_utils.py,python,,,,,Directory: scispacy\train_utils.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
umls_linking.py,python,local_import,,,,Import: EntityLinker from scispacy.linking,allenai,scispacy,v0.5.4,from scispacy.linking import EntityLinker as UmlsEntityLinker,scispacy.linking,EntityLinker,,,scispacy.linking,,,,,,,,,,,,
umls_linking.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
umls_linking.py,python,,,,,Directory: scispacy\umls_linking.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
umls_semantic_type_tree.py,python,class_field,,,,Class field: SemanticTypeNode.type_id: str,allenai,scispacy,v0.5.4,,,,,,,SemanticTypeNode,,,type_id: str,,,,,type_id,,,
umls_semantic_type_tree.py,python,class_field,,,,Class field: SemanticTypeNode.full_name: str,allenai,scispacy,v0.5.4,,,,,,,SemanticTypeNode,,,full_name: str,,,,,full_name,,,
umls_semantic_type_tree.py,python,class_field,,,,Class field: SemanticTypeNode.children: List[Any],allenai,scispacy,v0.5.4,,,,,,,SemanticTypeNode,,,children: List[Any],,,,,children,,,
umls_semantic_type_tree.py,python,class_field,,,,Class field: SemanticTypeNode.level: int,allenai,scispacy,v0.5.4,,,,,,,SemanticTypeNode,,,level: int,,,,,level,,,
umls_semantic_type_tree.py,python,class_field,,,,Class field: [instance] UmlsSemanticTypeTree.flat_nodes: List[SemanticTypeNode] = children,allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,__init__,"(self, root: SemanticTypeNode)",self.flat_nodes: List[SemanticTypeNode] = children,self.flat_nodes: List[SemanticTypeNode] = children,,,,,,,
umls_semantic_type_tree.py,python,class_field,,,,Class field: [instance] UmlsSemanticTypeTree.type_id_to_node = {node.type_id: node for node in flat_nodes},allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,__init__,"(self, root: SemanticTypeNode)",self.type_id_to_node = {node.type_id: node for node in self.flat_nodes},self.type_id_to_node = {node.type_id: node for node in self.flat_nodes},,,,,,,
umls_semantic_type_tree.py,python,class_field,,,,Class field: [instance] UmlsSemanticTypeTree.depth = max([node.level for node in flat_nodes]),allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,__init__,"(self, root: SemanticTypeNode)",self.depth = max([node.level for node in self.flat_nodes]),self.depth = max([node.level for node in self.flat_nodes]),,,,,,,
umls_semantic_type_tree.py,python,class_method,,,,"Class method: UmlsSemanticTypeTree.__init__(self, root: SemanticTypeNode) -> None",allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,__init__,"(self, root: SemanticTypeNode)",,,None,,,,,,
umls_semantic_type_tree.py,python,class_method,,,,"Class method: UmlsSemanticTypeTree.get_node_from_id(self, type_id: str) -> SemanticTypeNode",allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,get_node_from_id,"(self, type_id: str)",,,SemanticTypeNode,,,,,,
umls_semantic_type_tree.py,python,class_method,,,,"Class method: UmlsSemanticTypeTree.get_canonical_name(self, type_id: str) -> str",allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,get_canonical_name,"(self, type_id: str)",,,str,,,,,,
umls_semantic_type_tree.py,python,class_method,,,,"Class method: UmlsSemanticTypeTree.get_nodes_at_depth(self, level: int) -> List[SemanticTypeNode]",allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,get_nodes_at_depth,"(self, level: int)",,,List[SemanticTypeNode],,,,,,
umls_semantic_type_tree.py,python,class_method,,,,"Class method: UmlsSemanticTypeTree.get_children(self, node: SemanticTypeNode) -> List[SemanticTypeNode]",allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,get_children,"(self, node: SemanticTypeNode)",,,List[SemanticTypeNode],,,,,,
umls_semantic_type_tree.py,python,class_method,,,,"Class method: UmlsSemanticTypeTree.get_parent(self, node: SemanticTypeNode) -> Optional[SemanticTypeNode]",allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,get_parent,"(self, node: SemanticTypeNode)",,,Optional[SemanticTypeNode],,,,,,
umls_semantic_type_tree.py,python,class_method,,,,"Class method: UmlsSemanticTypeTree.get_collapsed_type_id_map_at_level(self, level: int) -> Dict[str, str]",allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,get_collapsed_type_id_map_at_level,"(self, level: int)",,,"Dict[str, str]",,,,,,
umls_semantic_type_tree.py,python,class,,,,Class: SemanticTypeNode(NamedTuple),allenai,scispacy,v0.5.4,,,,,,,SemanticTypeNode,,,,,,,,,(NamedTuple),,
umls_semantic_type_tree.py,python,class,,,,Class: UmlsSemanticTypeTree,allenai,scispacy,v0.5.4,,,,,,,UmlsSemanticTypeTree,,,,,,,,,,,
umls_semantic_type_tree.py,python,function,,,,Function: construct_umls_tree_from_tsv(filepath: str) -> UmlsSemanticTypeTree,allenai,scispacy,v0.5.4,,,,construct_umls_tree_from_tsv,(filepath: str),,,,,,,,UmlsSemanticTypeTree,,,,,
umls_semantic_type_tree.py,python,import,,,,Import: NamedTuple from typing,allenai,scispacy,v0.5.4,"from typing import NamedTuple, List, Dict, Deque, Any, Optional",typing,NamedTuple,,,,,,,,,,,,,,,
umls_semantic_type_tree.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,"from typing import NamedTuple, List, Dict, Deque, Any, Optional",typing,List,,,,,,,,,,,,,,,
umls_semantic_type_tree.py,python,import,,,,Import: Dict from typing,allenai,scispacy,v0.5.4,"from typing import NamedTuple, List, Dict, Deque, Any, Optional",typing,Dict,,,,,,,,,,,,,,,
umls_semantic_type_tree.py,python,import,,,,Import: Deque from typing,allenai,scispacy,v0.5.4,"from typing import NamedTuple, List, Dict, Deque, Any, Optional",typing,Deque,,,,,,,,,,,,,,,
umls_semantic_type_tree.py,python,import,,,,Import: Any from typing,allenai,scispacy,v0.5.4,"from typing import NamedTuple, List, Dict, Deque, Any, Optional",typing,Any,,,,,,,,,,,,,,,
umls_semantic_type_tree.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,"from typing import NamedTuple, List, Dict, Deque, Any, Optional",typing,Optional,,,,,,,,,,,,,,,
umls_semantic_type_tree.py,python,import,,,,Import: deque from collections,allenai,scispacy,v0.5.4,from collections import deque,collections,deque,,,,,,,,,,,,,,,
umls_semantic_type_tree.py,python,local_import,,,,Import: cached_path from scispacy.file_cache,allenai,scispacy,v0.5.4,from scispacy.file_cache import cached_path,scispacy.file_cache,cached_path,,,scispacy.file_cache,,,,,,,,,,,,
umls_semantic_type_tree.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
umls_semantic_type_tree.py,python,,,,,Directory: scispacy\umls_semantic_type_tree.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
umls_utils.py,python,function,,,,"Function: read_umls_file_headers(meta_path: str, filename: str) -> List[str]",allenai,scispacy,v0.5.4,,,,read_umls_file_headers,"(meta_path: str, filename: str)",,,,,,,,List[str],,,,,
umls_utils.py,python,function,,,,"Function: read_umls_concepts(
    meta_path: str,
    concept_details: Dict,
    source: Optional[str] = None,
    lang: str = ""ENG"",
    non_suppressed: bool = True,
)",allenai,scispacy,v0.5.4,,,,read_umls_concepts,"(
    meta_path: str,
    concept_details: Dict,
    source: Optional[str] = None,
    lang: str = ""ENG"",
    non_suppressed: bool = True,
)",,,,,,,,,,,,,
umls_utils.py,python,function,,,,"Function: read_umls_types(meta_path: str, concept_details: Dict)",allenai,scispacy,v0.5.4,,,,read_umls_types,"(meta_path: str, concept_details: Dict)",,,,,,,,,,,,,
umls_utils.py,python,function,,,,"Function: read_umls_definitions(meta_path: str, concept_details: Dict)",allenai,scispacy,v0.5.4,,,,read_umls_definitions,"(meta_path: str, concept_details: Dict)",,,,,,,,,,,,,
umls_utils.py,python,constant,"DEF_SOURCES_PREFERRED = {""NCI_BRIDG"", ""NCI_NCI-GLOSS"", ""NCI"", ""GO"", ""MSH"", ""NCI_FDA""}",DEF_SOURCES_PREFERRED,"{""NCI_BRIDG"", ""NCI_NCI-GLOSS"", ""NCI"", ""GO"", ""MSH"", ""NCI_FDA""}","Constant: DEF_SOURCES_PREFERRED = {""NCI_BRIDG"", ""NCI_NCI-GLOSS"", ""NCI"", ""GO"", ""MSH"", ""NCI_FDA""}",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
umls_utils.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,"from typing import Optional, List, Dict",typing,Optional,,,,,,,,,,,,,,,
umls_utils.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,"from typing import Optional, List, Dict",typing,List,,,,,,,,,,,,,,,
umls_utils.py,python,import,,,,Import: Dict from typing,allenai,scispacy,v0.5.4,"from typing import Optional, List, Dict",typing,Dict,,,,,,,,,,,,,,,
umls_utils.py,python,local_import,,,,Import: Entity from scispacy.linking_utils,allenai,scispacy,v0.5.4,"from scispacy.linking_utils import Entity as UmlsEntity, UmlsKnowledgeBase",scispacy.linking_utils,Entity,,,scispacy.linking_utils,,,,,,,,,,,,
umls_utils.py,python,local_import,,,,Import: UmlsKnowledgeBase from scispacy.linking_utils,allenai,scispacy,v0.5.4,"from scispacy.linking_utils import Entity as UmlsEntity, UmlsKnowledgeBase",scispacy.linking_utils,UmlsKnowledgeBase,,,scispacy.linking_utils,,,,,,,,,,,,
umls_utils.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
umls_utils.py,python,,,,,Directory: scispacy\umls_utils.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
util.py,python,class_field,,,,Class field: [instance] WhitespaceTokenizer.vocab = vocab,allenai,scispacy,v0.5.4,,,,,,,WhitespaceTokenizer,__init__,"(self, vocab)",self.vocab = vocab,self.vocab = vocab,,,,,,,
util.py,python,class_method,,,,"Class method: WhitespaceTokenizer.__init__(self, vocab)",allenai,scispacy,v0.5.4,,,,,,,WhitespaceTokenizer,__init__,"(self, vocab)",,,,,,,,,
util.py,python,class_method,,,,"Class method: WhitespaceTokenizer.__call__(self, text)",allenai,scispacy,v0.5.4,,,,,,,WhitespaceTokenizer,__call__,"(self, text)",,,,,,,,,
util.py,python,class,,,,Class: WhitespaceTokenizer,allenai,scispacy,v0.5.4,,,,,,,WhitespaceTokenizer,,,,,,,,,,,
util.py,python,function,,,,"Function: save_model(nlp: Language, output_path: str)",allenai,scispacy,v0.5.4,,,,save_model,"(nlp: Language, output_path: str)",,,,,,,,,,,,,
util.py,python,function,,,,Function: create_combined_rule_model() -> Language,allenai,scispacy,v0.5.4,,,,create_combined_rule_model,(),,,,,,,,Language,,,,,
util.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
util.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
util.py,python,local_import,,,,Import: Doc from spacy.tokens,allenai,scispacy,v0.5.4,from spacy.tokens import Doc,spacy.tokens,Doc,,,spacy.tokens,,,,,,,,,,,,
util.py,python,local_import,,,,Import: pysbd_sentencizer from scispacy.custom_sentence_segmenter,allenai,scispacy,v0.5.4,from scispacy.custom_sentence_segmenter import pysbd_sentencizer,scispacy.custom_sentence_segmenter,pysbd_sentencizer,,,scispacy.custom_sentence_segmenter,,,,,,,,,,,,
util.py,python,local_import,,,,Import: combined_rule_tokenizer from scispacy.custom_tokenizer,allenai,scispacy,v0.5.4,from scispacy.custom_tokenizer import combined_rule_tokenizer,scispacy.custom_tokenizer,combined_rule_tokenizer,,,scispacy.custom_tokenizer,,,,,,,,,,,,
util.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
util.py,python,,,,,Directory: scispacy\util.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
version.py,python,constant,"_MAJOR = ""0""",_MAJOR,"""0""","Constant: _MAJOR = ""0""",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
version.py,python,constant,"_MINOR = ""5""",_MINOR,"""5""","Constant: _MINOR = ""5""",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
version.py,python,constant,"_REVISION = ""4""",_REVISION,"""4""","Constant: _REVISION = ""4""",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
version.py,python,constant,"VERSION_SHORT = ""{0}.{1}"".format(_MAJOR, _MINOR)",VERSION_SHORT,"""{0}.{1}"".format(_MAJOR, _MINOR)","Constant: VERSION_SHORT = ""{0}.{1}"".format(_MAJOR, _MINOR)",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
version.py,python,constant,"VERSION = ""{0}.{1}.{2}"".format(_MAJOR, _MINOR, _REVISION)",VERSION,"""{0}.{1}.{2}"".format(_MAJOR, _MINOR, _REVISION)","Constant: VERSION = ""{0}.{1}.{2}"".format(_MAJOR, _MINOR, _REVISION)",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
version.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
version.py,python,,,,,Directory: scispacy\version.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
__init__.py,python,local_import,,,,Import: VERSION from scispacy.version,allenai,scispacy,v0.5.4,from scispacy.version import VERSION as __version__,scispacy.version,VERSION,,,scispacy.version,,,,,,,,,,,,
__init__.py,python,,,,,File: scispacy,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
__init__.py,python,,,,,Directory: scispacy\__init__.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
convert_freqs.py,python,function,,,,"Function: read_freqs(freqs_loc, max_length=100, min_doc_freq=5, min_freq=50)",allenai,scispacy,v0.5.4,,,,read_freqs,"(freqs_loc, max_length=100, min_doc_freq=5, min_freq=50)",,,,,,,,,,,,,
convert_freqs.py,python,function,,,,"Function: main(input_path: str, output_path: str, min_word_frequency: int)",allenai,scispacy,v0.5.4,,,,main,"(input_path: str, output_path: str, min_word_frequency: int)",,,,,,,,,,,,,
convert_freqs.py,python,import,,,,Import: argparse,allenai,scispacy,v0.5.4,import argparse,,argparse,,,,,,,,,,,,,,,
convert_freqs.py,python,import,,,,Import: math,allenai,scispacy,v0.5.4,import math,,math,,,,,,,,,,,,,,,
convert_freqs.py,python,import,,,,Import: json,allenai,scispacy,v0.5.4,import json,,json,,,,,,,,,,,,,,,
convert_freqs.py,python,import,,,,Import: literal_eval from ast,allenai,scispacy,v0.5.4,from ast import literal_eval,ast,literal_eval,,,,,,,,,,,,,,,
convert_freqs.py,python,import,,,,Import: tqdm from tqdm,allenai,scispacy,v0.5.4,from tqdm import tqdm,tqdm,tqdm,,,,,,,,,,,,,,,
convert_freqs.py,python,local_import,,,,Import: PreshCounter from preshed.counter,allenai,scispacy,v0.5.4,from preshed.counter import PreshCounter,preshed.counter,PreshCounter,,,preshed.counter,,,,,,,,,,,,
convert_freqs.py,python,local_import,,,,Import: ensure_path from spacy.util,allenai,scispacy,v0.5.4,from spacy.util import ensure_path,spacy.util,ensure_path,,,spacy.util,,,,,,,,,,,,
convert_freqs.py,python,local_import,,,,Import: cached_path from scispacy.file_cache,allenai,scispacy,v0.5.4,from scispacy.file_cache import cached_path,scispacy.file_cache,cached_path,,,scispacy.file_cache,,,,,,,,,,,,
convert_freqs.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
convert_freqs.py,python,,,,,Directory: scripts\convert_freqs.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
count_word_frequencies.py,python,function,,,,"Function: count_frequencies(language_class: Language, input_path: Path)",allenai,scispacy,v0.5.4,,,,count_frequencies,"(language_class: Language, input_path: Path)",,,,,,,,,,,,,
count_word_frequencies.py,python,function,,,,"Function: parallelize(func, iterator, n_jobs)",allenai,scispacy,v0.5.4,,,,parallelize,"(func, iterator, n_jobs)",,,,,,,,,,,,,
count_word_frequencies.py,python,function,,,,"Function: merge_counts(frequencies: List[Tuple[Counter, Counter]], output_path: str)",allenai,scispacy,v0.5.4,,,,merge_counts,"(frequencies: List[Tuple[Counter, Counter]], output_path: str)",,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: List from typing,allenai,scispacy,v0.5.4,"from typing import List, Tuple",typing,List,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: Tuple from typing,allenai,scispacy,v0.5.4,"from typing import List, Tuple",typing,Tuple,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: io,allenai,scispacy,v0.5.4,import io,,io,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: sys,allenai,scispacy,v0.5.4,import sys,,sys,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: tempfile,allenai,scispacy,v0.5.4,import tempfile,,tempfile,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: shutil,allenai,scispacy,v0.5.4,import shutil,,shutil,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: Counter from collections,allenai,scispacy,v0.5.4,from collections import Counter,collections,Counter,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: Path from pathlib,allenai,scispacy,v0.5.4,from pathlib import Path,pathlib,Path,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: Pool from multiprocessing,allenai,scispacy,v0.5.4,from multiprocessing import Pool,multiprocessing,Pool,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: plac,allenai,scispacy,v0.5.4,import plac,,plac,,,,,,,,,,,,,,,
count_word_frequencies.py,python,import,,,,Import: spacy.util,allenai,scispacy,v0.5.4,import spacy.util,,spacy.util,,,,,,,,,,,,,,,
count_word_frequencies.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
count_word_frequencies.py,python,local_import,,,,Import: combined_rule_tokenizer from scispacy.custom_tokenizer,allenai,scispacy,v0.5.4,from scispacy.custom_tokenizer import combined_rule_tokenizer,scispacy.custom_tokenizer,combined_rule_tokenizer,,,scispacy.custom_tokenizer,,,,,,,,,,,,
count_word_frequencies.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
count_word_frequencies.py,python,,,,,Directory: scripts\count_word_frequencies.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
create_linker.py,python,function,,,,"Function: main(kb_path: str, output_path: str)",allenai,scispacy,v0.5.4,,,,main,"(kb_path: str, output_path: str)",,,,,,,,,,,,,
create_linker.py,python,import,,,,Import: argparse,allenai,scispacy,v0.5.4,import argparse,,argparse,,,,,,,,,,,,,,,
create_linker.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
create_linker.py,python,local_import,,,,Import: create_tfidf_ann_index from scispacy.candidate_generation,allenai,scispacy,v0.5.4,from scispacy.candidate_generation import create_tfidf_ann_index,scispacy.candidate_generation,create_tfidf_ann_index,,,scispacy.candidate_generation,,,,,,,,,,,,
create_linker.py,python,local_import,,,,Import: KnowledgeBase from scispacy.linking_utils,allenai,scispacy,v0.5.4,from scispacy.linking_utils import KnowledgeBase,scispacy.linking_utils,KnowledgeBase,,,scispacy.linking_utils,,,,,,,,,,,,
create_linker.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
create_linker.py,python,,,,,Directory: scripts\create_linker.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
evaluate_ner.py,python,function,,,,"Function: main(model_path: str, dataset: str, output_path: str, code: Optional[str], med_mentions_folder_path: Optional[str], gpu_id: Optional[int])",allenai,scispacy,v0.5.4,,,,main,"(model_path: str, dataset: str, output_path: str, code: Optional[str], med_mentions_folder_path: Optional[str], gpu_id: Optional[int])",,,,,,,,,,,,,
evaluate_ner.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,from typing import Optional,typing,Optional,,,,,,,,,,,,,,,
evaluate_ner.py,python,import,,,,Import: argparse,allenai,scispacy,v0.5.4,import argparse,,argparse,,,,,,,,,,,,,,,
evaluate_ner.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
evaluate_ner.py,python,import,,,,Import: importlib,allenai,scispacy,v0.5.4,import importlib,,importlib,,,,,,,,,,,,,,,
evaluate_ner.py,python,local_import,,,,Import: require_gpu from thinc.api,allenai,scispacy,v0.5.4,from thinc.api import require_gpu,thinc.api,require_gpu,,,thinc.api,,,,,,,,,,,,
evaluate_ner.py,python,local_import,,,,Import: read_full_med_mentions from scispacy.data_util,allenai,scispacy,v0.5.4,"from scispacy.data_util import read_full_med_mentions, read_ner_from_tsv",scispacy.data_util,read_full_med_mentions,,,scispacy.data_util,,,,,,,,,,,,
evaluate_ner.py,python,local_import,,,,Import: read_ner_from_tsv from scispacy.data_util,allenai,scispacy,v0.5.4,"from scispacy.data_util import read_full_med_mentions, read_ner_from_tsv",scispacy.data_util,read_ner_from_tsv,,,scispacy.data_util,,,,,,,,,,,,
evaluate_ner.py,python,local_import,,,,Import: evaluate_ner from scispacy.train_utils,allenai,scispacy,v0.5.4,from scispacy.train_utils import evaluate_ner,scispacy.train_utils,evaluate_ner,,,scispacy.train_utils,,,,,,,,,,,,
evaluate_ner.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
evaluate_ner.py,python,,,,,Directory: scripts\evaluate_ner.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
export_umls_json.py,python,function,,,,"Function: main(meta_path: str, output_path: str, lang: str = None, source: str = None)",allenai,scispacy,v0.5.4,,,,main,"(meta_path: str, output_path: str, lang: str = None, source: str = None)",,,,,,,,,,,,,
export_umls_json.py,python,import,,,,Import: json,allenai,scispacy,v0.5.4,import json,,json,,,,,,,,,,,,,,,
export_umls_json.py,python,import,,,,Import: argparse,allenai,scispacy,v0.5.4,import argparse,,argparse,,,,,,,,,,,,,,,
export_umls_json.py,python,import,,,,Import: umls_utils from scispacy,allenai,scispacy,v0.5.4,from scispacy import umls_utils,scispacy,umls_utils,,,,,,,,,,,,,,,
export_umls_json.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
export_umls_json.py,python,,,,,Directory: scripts\export_umls_json.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
install_local_packages.py,python,function,,,,Function: main(),allenai,scispacy,v0.5.4,,,,main,(),,,,,,,,,,,,,
install_local_packages.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
install_local_packages.py,python,local_import,,,,Import: VERSION from scispacy.version,allenai,scispacy,v0.5.4,from scispacy.version import VERSION,scispacy.version,VERSION,,,scispacy.version,,,,,,,,,,,,
install_local_packages.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
install_local_packages.py,python,,,,,Directory: scripts\install_local_packages.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
install_remote_packages.py,python,function,,,,Function: main(),allenai,scispacy,v0.5.4,,,,main,(),,,,,,,,,,,,,
install_remote_packages.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
install_remote_packages.py,python,local_import,,,,Import: VERSION from scispacy.version,allenai,scispacy,v0.5.4,from scispacy.version import VERSION,scispacy.version,VERSION,,,scispacy.version,,,,,,,,,,,,
install_remote_packages.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
install_remote_packages.py,python,,,,,Directory: scripts\install_remote_packages.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
print_out_metrics.py,python,function,,,,Function: main(),allenai,scispacy,v0.5.4,,,,main,(),,,,,,,,,,,,,
print_out_metrics.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
print_out_metrics.py,python,import,,,,Import: json,allenai,scispacy,v0.5.4,import json,,json,,,,,,,,,,,,,,,
print_out_metrics.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
print_out_metrics.py,python,,,,,Directory: scripts\print_out_metrics.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
smoke_test.py,python,function,,,,Function: main(),allenai,scispacy,v0.5.4,,,,main,(),,,,,,,,,,,,,
smoke_test.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
smoke_test.py,python,import,,,,Import: tqdm from tqdm,allenai,scispacy,v0.5.4,from tqdm import tqdm,tqdm,tqdm,,,,,,,,,,,,,,,
smoke_test.py,python,local_import,,,,Import: AbbreviationDetector from scispacy.abbreviation,allenai,scispacy,v0.5.4,from scispacy.abbreviation import AbbreviationDetector,scispacy.abbreviation,AbbreviationDetector,,,scispacy.abbreviation,,,,,,,,,,,,
smoke_test.py,python,local_import,,,,Import: EntityLinker from scispacy.linking,allenai,scispacy,v0.5.4,from scispacy.linking import EntityLinker,scispacy.linking,EntityLinker,,,scispacy.linking,,,,,,,,,,,,
smoke_test.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
smoke_test.py,python,,,,,Directory: scripts\smoke_test.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
uninstall_local_packages.py,python,function,,,,Function: main(),allenai,scispacy,v0.5.4,,,,main,(),,,,,,,,,,,,,
uninstall_local_packages.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
uninstall_local_packages.py,python,local_import,,,,Import: VERSION from scispacy.version,allenai,scispacy,v0.5.4,from scispacy.version import VERSION,scispacy.version,VERSION,,,scispacy.version,,,,,,,,,,,,
uninstall_local_packages.py,python,,,,,File: scripts,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
uninstall_local_packages.py,python,,,,,Directory: scripts\uninstall_local_packages.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
conftest.py,python,function,,,,"Function: get_spacy_model(
    spacy_model_name: str,
    pos_tags: bool,
    parse: bool,
    ner: bool,
    with_custom_tokenizer: bool = False,
    with_sentence_segmenter: bool = False,
    with_serializable_abbreviation_detector: Optional[bool] = None,
) -> SpacyModelType",allenai,scispacy,v0.5.4,,,,get_spacy_model,"(
    spacy_model_name: str,
    pos_tags: bool,
    parse: bool,
    ner: bool,
    with_custom_tokenizer: bool = False,
    with_sentence_segmenter: bool = False,
    with_serializable_abbreviation_detector: Optional[bool] = None,
)",,,,,,,,SpacyModelType,,,,,
conftest.py,python,constant,"LOADED_SPACY_MODELS: Dict[Tuple[str, bool, bool, bool], SpacyModelType] = {}",LOADED_SPACY_MODELS,{},"Constant: LOADED_SPACY_MODELS: Dict[Tuple[str, bool, bool, bool], SpacyModelType] = {}",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
conftest.py,python,import,,,,Import: Dict from typing,allenai,scispacy,v0.5.4,"from typing import Dict, Tuple, Optional",typing,Dict,,,,,,,,,,,,,,,
conftest.py,python,import,,,,Import: Tuple from typing,allenai,scispacy,v0.5.4,"from typing import Dict, Tuple, Optional",typing,Tuple,,,,,,,,,,,,,,,
conftest.py,python,import,,,,Import: Optional from typing,allenai,scispacy,v0.5.4,"from typing import Dict, Tuple, Optional",typing,Optional,,,,,,,,,,,,,,,
conftest.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
conftest.py,python,import,,,,Import: pytest,allenai,scispacy,v0.5.4,import pytest,,pytest,,,,,,,,,,,,,,,
conftest.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
conftest.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language as SpacyModelType,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
conftest.py,python,local_import,,,,Import: download from spacy.cli.download,allenai,scispacy,v0.5.4,from spacy.cli.download import download as spacy_download,spacy.cli.download,download,,,spacy.cli.download,,,,,,,,,,,,
conftest.py,python,local_import,,,,Import: pysbd_sentencizer from scispacy.custom_sentence_segmenter,allenai,scispacy,v0.5.4,from scispacy.custom_sentence_segmenter import pysbd_sentencizer,scispacy.custom_sentence_segmenter,pysbd_sentencizer,,,scispacy.custom_sentence_segmenter,,,,,,,,,,,,
conftest.py,python,local_import,,,,Import: combined_rule_tokenizer from scispacy.custom_tokenizer,allenai,scispacy,v0.5.4,"from scispacy.custom_tokenizer import combined_rule_tokenizer, combined_rule_prefixes, remove_new_lines",scispacy.custom_tokenizer,combined_rule_tokenizer,,,scispacy.custom_tokenizer,,,,,,,,,,,,
conftest.py,python,local_import,,,,Import: combined_rule_prefixes from scispacy.custom_tokenizer,allenai,scispacy,v0.5.4,"from scispacy.custom_tokenizer import combined_rule_tokenizer, combined_rule_prefixes, remove_new_lines",scispacy.custom_tokenizer,combined_rule_prefixes,,,scispacy.custom_tokenizer,,,,,,,,,,,,
conftest.py,python,local_import,,,,Import: remove_new_lines from scispacy.custom_tokenizer,allenai,scispacy,v0.5.4,"from scispacy.custom_tokenizer import combined_rule_tokenizer, combined_rule_prefixes, remove_new_lines",scispacy.custom_tokenizer,remove_new_lines,,,scispacy.custom_tokenizer,,,,,,,,,,,,
conftest.py,python,local_import,,,,Import: AbbreviationDetector from scispacy.abbreviation,allenai,scispacy,v0.5.4,from scispacy.abbreviation import AbbreviationDetector,scispacy.abbreviation,AbbreviationDetector,,,scispacy.abbreviation,,,,,,,,,,,,
conftest.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
conftest.py,python,,,,,Directory: tests\conftest.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.setUp(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,setUp,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_find_abbreviation(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_find_abbreviation,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_filter_matches(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_filter_matches,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_abbreviation_detection(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_abbreviation_detection,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_find(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_find,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_issue_158(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_issue_158,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_issue_192(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_issue_192,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_issue_161(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_issue_161,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_empty_span(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_empty_span,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_space_issue(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_space_issue,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_multiple_spaces(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_multiple_spaces,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: TestAbbreviationDetector.test_issue_441(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_issue_441,(self),,,,,,,,,
test_abbreviation_detection.py,python,class_method,,,,Class method: [pytest.mark.xfail] TestAbbreviationDetector.test_difficult_cases(self),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,test_difficult_cases,(self),,,,,,,,,pytest.mark.xfail
test_abbreviation_detection.py,python,class,,,,Class: TestAbbreviationDetector(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestAbbreviationDetector,,,,,,,,,(unittest.TestCase),,
test_abbreviation_detection.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_abbreviation_detection.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
test_abbreviation_detection.py,python,import,,,,Import: pytest,allenai,scispacy,v0.5.4,import pytest,,pytest,,,,,,,,,,,,,,,
test_abbreviation_detection.py,python,local_import,,,,Import: AbbreviationDetector from scispacy.abbreviation,allenai,scispacy,v0.5.4,"from scispacy.abbreviation import (
    AbbreviationDetector,
    find_abbreviation,
    filter_matches,
)",scispacy.abbreviation,AbbreviationDetector,,,scispacy.abbreviation,,,,,,,,,,,,
test_abbreviation_detection.py,python,local_import,,,,Import: find_abbreviation from scispacy.abbreviation,allenai,scispacy,v0.5.4,"from scispacy.abbreviation import (
    AbbreviationDetector,
    find_abbreviation,
    filter_matches,
)",scispacy.abbreviation,find_abbreviation,,,scispacy.abbreviation,,,,,,,,,,,,
test_abbreviation_detection.py,python,local_import,,,,Import: filter_matches from scispacy.abbreviation,allenai,scispacy,v0.5.4,"from scispacy.abbreviation import (
    AbbreviationDetector,
    find_abbreviation,
    filter_matches,
)",scispacy.abbreviation,filter_matches,,,scispacy.abbreviation,,,,,,,,,,,,
test_abbreviation_detection.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_abbreviation_detection.py,python,,,,,Directory: tests\test_abbreviation_detection.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_candidate_generation.py,python,class_method,,,,Class method: TestCandidateGeneration.test_create_index(self),allenai,scispacy,v0.5.4,,,,,,,TestCandidateGeneration,test_create_index,(self),,,,,,,,,
test_candidate_generation.py,python,class_method,,,,Class method: TestCandidateGeneration.test_candidate_generation(self),allenai,scispacy,v0.5.4,,,,,,,TestCandidateGeneration,test_candidate_generation,(self),,,,,,,,,
test_candidate_generation.py,python,class_method,,,,Class method: TestCandidateGeneration.test_empty_list(self),allenai,scispacy,v0.5.4,,,,,,,TestCandidateGeneration,test_empty_list,(self),,,,,,,,,
test_candidate_generation.py,python,class,,,,Class: TestCandidateGeneration(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestCandidateGeneration,,,,,,,,,(unittest.TestCase),,
test_candidate_generation.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_candidate_generation.py,python,import,,,,Import: tempfile,allenai,scispacy,v0.5.4,import tempfile,,tempfile,,,,,,,,,,,,,,,
test_candidate_generation.py,python,local_import,,,,Import: CandidateGenerator from scispacy.candidate_generation,allenai,scispacy,v0.5.4,"from scispacy.candidate_generation import CandidateGenerator, create_tfidf_ann_index, MentionCandidate",scispacy.candidate_generation,CandidateGenerator,,,scispacy.candidate_generation,,,,,,,,,,,,
test_candidate_generation.py,python,local_import,,,,Import: create_tfidf_ann_index from scispacy.candidate_generation,allenai,scispacy,v0.5.4,"from scispacy.candidate_generation import CandidateGenerator, create_tfidf_ann_index, MentionCandidate",scispacy.candidate_generation,create_tfidf_ann_index,,,scispacy.candidate_generation,,,,,,,,,,,,
test_candidate_generation.py,python,local_import,,,,Import: MentionCandidate from scispacy.candidate_generation,allenai,scispacy,v0.5.4,"from scispacy.candidate_generation import CandidateGenerator, create_tfidf_ann_index, MentionCandidate",scispacy.candidate_generation,MentionCandidate,,,scispacy.candidate_generation,,,,,,,,,,,,
test_candidate_generation.py,python,local_import,,,,Import: UmlsKnowledgeBase from scispacy.umls_utils,allenai,scispacy,v0.5.4,from scispacy.umls_utils import UmlsKnowledgeBase,scispacy.umls_utils,UmlsKnowledgeBase,,,scispacy.umls_utils,,,,,,,,,,,,
test_candidate_generation.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_candidate_generation.py,python,,,,,Directory: tests\test_candidate_generation.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_data_util.py,python,class_method,,,,Class method: TestDataUtil.setUp(self),allenai,scispacy,v0.5.4,,,,,,,TestDataUtil,setUp,(self),,,,,,,,,
test_data_util.py,python,class_method,,,,Class method: TestDataUtil.tearDown(self),allenai,scispacy,v0.5.4,,,,,,,TestDataUtil,tearDown,(self),,,,,,,,,
test_data_util.py,python,class_method,,,,Class method: TestDataUtil.test_example_iterator(self),allenai,scispacy,v0.5.4,,,,,,,TestDataUtil,test_example_iterator,(self),,,,,,,,,
test_data_util.py,python,class_method,,,,Class method: TestDataUtil.test_remove_overlaps(self),allenai,scispacy,v0.5.4,,,,,,,TestDataUtil,test_remove_overlaps,(self),,,,,,,,,
test_data_util.py,python,class_method,,,,Class method: TestDataUtil.test_read_ner_from_tsv(self),allenai,scispacy,v0.5.4,,,,,,,TestDataUtil,test_read_ner_from_tsv,(self),,,,,,,,,
test_data_util.py,python,class,,,,Class: TestDataUtil(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestDataUtil,,,,,,,,,(unittest.TestCase),,
test_data_util.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
test_data_util.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_data_util.py,python,import,,,,Import: shutil,allenai,scispacy,v0.5.4,import shutil,,shutil,,,,,,,,,,,,,,,
test_data_util.py,python,local_import,,,,Import: read_full_med_mentions from scispacy.data_util,allenai,scispacy,v0.5.4,"from scispacy.data_util import read_full_med_mentions, med_mentions_example_iterator, remove_overlapping_entities",scispacy.data_util,read_full_med_mentions,,,scispacy.data_util,,,,,,,,,,,,
test_data_util.py,python,local_import,,,,Import: med_mentions_example_iterator from scispacy.data_util,allenai,scispacy,v0.5.4,"from scispacy.data_util import read_full_med_mentions, med_mentions_example_iterator, remove_overlapping_entities",scispacy.data_util,med_mentions_example_iterator,,,scispacy.data_util,,,,,,,,,,,,
test_data_util.py,python,local_import,,,,Import: remove_overlapping_entities from scispacy.data_util,allenai,scispacy,v0.5.4,"from scispacy.data_util import read_full_med_mentions, med_mentions_example_iterator, remove_overlapping_entities",scispacy.data_util,remove_overlapping_entities,,,scispacy.data_util,,,,,,,,,,,,
test_data_util.py,python,local_import,,,,Import: read_ner_from_tsv from scispacy.data_util,allenai,scispacy,v0.5.4,from scispacy.data_util import read_ner_from_tsv,scispacy.data_util,read_ner_from_tsv,,,scispacy.data_util,,,,,,,,,,,,
test_data_util.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_data_util.py,python,,,,,Directory: tests\test_data_util.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_file_cache.py,python,class_method,,,,Class method: TestFileUtils.setUp(self),allenai,scispacy,v0.5.4,,,,,,,TestFileUtils,setUp,(self),,,,,,,,,
test_file_cache.py,python,class_method,,,,Class method: TestFileUtils.tearDown(self),allenai,scispacy,v0.5.4,,,,,,,TestFileUtils,tearDown,(self),,,,,,,,,
test_file_cache.py,python,class_method,,,,Class method: TestFileUtils.test_url_to_filename(self),allenai,scispacy,v0.5.4,,,,,,,TestFileUtils,test_url_to_filename,(self),,,,,,,,,
test_file_cache.py,python,class_method,,,,Class method: TestFileUtils.test_url_to_filename_with_etags(self),allenai,scispacy,v0.5.4,,,,,,,TestFileUtils,test_url_to_filename_with_etags,(self),,,,,,,,,
test_file_cache.py,python,class_method,,,,Class method: TestFileUtils.test_url_to_filename_with_etags_eliminates_quotes(self),allenai,scispacy,v0.5.4,,,,,,,TestFileUtils,test_url_to_filename_with_etags_eliminates_quotes,(self),,,,,,,,,
test_file_cache.py,python,class,,,,Class: TestFileUtils(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestFileUtils,,,,,,,,,(unittest.TestCase),,
test_file_cache.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
test_file_cache.py,python,import,,,,Import: pathlib,allenai,scispacy,v0.5.4,import pathlib,,pathlib,,,,,,,,,,,,,,,
test_file_cache.py,python,import,,,,Import: json,allenai,scispacy,v0.5.4,import json,,json,,,,,,,,,,,,,,,
test_file_cache.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_file_cache.py,python,import,,,,Import: shutil,allenai,scispacy,v0.5.4,import shutil,,shutil,,,,,,,,,,,,,,,
test_file_cache.py,python,import,,,,Import: pytest,allenai,scispacy,v0.5.4,import pytest,,pytest,,,,,,,,,,,,,,,
test_file_cache.py,python,local_import,,,,Import: filename_to_url from scispacy.file_cache,allenai,scispacy,v0.5.4,"from scispacy.file_cache import filename_to_url, url_to_filename",scispacy.file_cache,filename_to_url,,,scispacy.file_cache,,,,,,,,,,,,
test_file_cache.py,python,local_import,,,,Import: url_to_filename from scispacy.file_cache,allenai,scispacy,v0.5.4,"from scispacy.file_cache import filename_to_url, url_to_filename",scispacy.file_cache,url_to_filename,,,scispacy.file_cache,,,,,,,,,,,,
test_file_cache.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_file_cache.py,python,,,,,Directory: tests\test_file_cache.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_hyponym_detector.py,python,class_method,,,,Class method: TestHyponymDetector.setUp(self),allenai,scispacy,v0.5.4,,,,,,,TestHyponymDetector,setUp,(self),,,,,,,,,
test_hyponym_detector.py,python,class_method,,,,Class method: TestHyponymDetector.test_sentences(self),allenai,scispacy,v0.5.4,,,,,,,TestHyponymDetector,test_sentences,(self),,,,,,,,,
test_hyponym_detector.py,python,class_method,,,,Class method: TestHyponymDetector.test_find_noun_compound_head(self),allenai,scispacy,v0.5.4,,,,,,,TestHyponymDetector,test_find_noun_compound_head,(self),,,,,,,,,
test_hyponym_detector.py,python,class_method,,,,Class method: TestHyponymDetector.test_expand_noun_phrase(self),allenai,scispacy,v0.5.4,,,,,,,TestHyponymDetector,test_expand_noun_phrase,(self),,,,,,,,,
test_hyponym_detector.py,python,class,,,,Class: TestHyponymDetector(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestHyponymDetector,,,,,,,,,(unittest.TestCase),,
test_hyponym_detector.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_hyponym_detector.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
test_hyponym_detector.py,python,local_import,,,,Import: HyponymDetector from scispacy.hyponym_detector,allenai,scispacy,v0.5.4,from scispacy.hyponym_detector import HyponymDetector,scispacy.hyponym_detector,HyponymDetector,,,scispacy.hyponym_detector,,,,,,,,,,,,
test_hyponym_detector.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_hyponym_detector.py,python,,,,,Directory: tests\test_hyponym_detector.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_linking.py,python,class_method,,,,Class method: TestLinker.setUp(self),allenai,scispacy,v0.5.4,,,,,,,TestLinker,setUp,(self),,,,,,,,,
test_linking.py,python,class_method,,,,Class method: TestLinker.test_naive_entity_linking(self),allenai,scispacy,v0.5.4,,,,,,,TestLinker,test_naive_entity_linking,(self),,,,,,,,,
test_linking.py,python,class_method,,,,Class method: TestLinker.test_linker_resolves_abbreviations(self),allenai,scispacy,v0.5.4,,,,,,,TestLinker,test_linker_resolves_abbreviations,(self),,,,,,,,,
test_linking.py,python,class_method,,,,Class method: TestLinker.test_linker_has_types(self),allenai,scispacy,v0.5.4,,,,,,,TestLinker,test_linker_has_types,(self),,,,,,,,,
test_linking.py,python,class,,,,Class: TestLinker(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestLinker,,,,,,,,,(unittest.TestCase),,
test_linking.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_linking.py,python,import,,,,Import: tempfile,allenai,scispacy,v0.5.4,import tempfile,,tempfile,,,,,,,,,,,,,,,
test_linking.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
test_linking.py,python,local_import,,,,Import: CandidateGenerator from scispacy.candidate_generation,allenai,scispacy,v0.5.4,"from scispacy.candidate_generation import CandidateGenerator, create_tfidf_ann_index",scispacy.candidate_generation,CandidateGenerator,,,scispacy.candidate_generation,,,,,,,,,,,,
test_linking.py,python,local_import,,,,Import: create_tfidf_ann_index from scispacy.candidate_generation,allenai,scispacy,v0.5.4,"from scispacy.candidate_generation import CandidateGenerator, create_tfidf_ann_index",scispacy.candidate_generation,create_tfidf_ann_index,,,scispacy.candidate_generation,,,,,,,,,,,,
test_linking.py,python,local_import,,,,Import: EntityLinker from scispacy.linking,allenai,scispacy,v0.5.4,from scispacy.linking import EntityLinker,scispacy.linking,EntityLinker,,,scispacy.linking,,,,,,,,,,,,
test_linking.py,python,local_import,,,,Import: UmlsKnowledgeBase from scispacy.umls_utils,allenai,scispacy,v0.5.4,from scispacy.umls_utils import UmlsKnowledgeBase,scispacy.umls_utils,UmlsKnowledgeBase,,,scispacy.umls_utils,,,,,,,,,,,,
test_linking.py,python,local_import,,,,Import: AbbreviationDetector from scispacy.abbreviation,allenai,scispacy,v0.5.4,from scispacy.abbreviation import AbbreviationDetector,scispacy.abbreviation,AbbreviationDetector,,,scispacy.abbreviation,,,,,,,,,,,,
test_linking.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_linking.py,python,,,,,Directory: tests\test_linking.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_per_class_scorer.py,python,class_method,,,,Class method: TestPerClassScorer.test_per_class_scorer_counts_correctly(self),allenai,scispacy,v0.5.4,,,,,,,TestPerClassScorer,test_per_class_scorer_counts_correctly,(self),,,,,,,,,
test_per_class_scorer.py,python,class,,,,Class: TestPerClassScorer(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestPerClassScorer,,,,,,,,,(unittest.TestCase),,
test_per_class_scorer.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_per_class_scorer.py,python,local_import,,,,Import: PerClassScorer from scispacy.per_class_scorer,allenai,scispacy,v0.5.4,from scispacy.per_class_scorer import PerClassScorer,scispacy.per_class_scorer,PerClassScorer,,,scispacy.per_class_scorer,,,,,,,,,,,,
test_per_class_scorer.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_per_class_scorer.py,python,,,,,Directory: tests\test_per_class_scorer.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_umls_semantic_type_tree.py,python,class_method,,,,Class method: TestUmlsSemanticTypeTree.setUp(self),allenai,scispacy,v0.5.4,,,,,,,TestUmlsSemanticTypeTree,setUp,(self),,,,,,,,,
test_umls_semantic_type_tree.py,python,class_method,,,,Class method: TestUmlsSemanticTypeTree.test_tree_can_be_read_from_file(self),allenai,scispacy,v0.5.4,,,,,,,TestUmlsSemanticTypeTree,test_tree_can_be_read_from_file,(self),,,,,,,,,
test_umls_semantic_type_tree.py,python,class_method,,,,Class method: TestUmlsSemanticTypeTree.test_tree_can_collapse_nodes(self),allenai,scispacy,v0.5.4,,,,,,,TestUmlsSemanticTypeTree,test_tree_can_collapse_nodes,(self),,,,,,,,,
test_umls_semantic_type_tree.py,python,class_method,,,,Class method: TestUmlsSemanticTypeTree.test_get_parent_root(self),allenai,scispacy,v0.5.4,,,,,,,TestUmlsSemanticTypeTree,test_get_parent_root,(self),,,,,,,,,
test_umls_semantic_type_tree.py,python,class_method,,,,Class method: TestUmlsSemanticTypeTree.test_get_parent(self),allenai,scispacy,v0.5.4,,,,,,,TestUmlsSemanticTypeTree,test_get_parent,(self),,,,,,,,,
test_umls_semantic_type_tree.py,python,class,,,,Class: TestUmlsSemanticTypeTree(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestUmlsSemanticTypeTree,,,,,,,,,(unittest.TestCase),,
test_umls_semantic_type_tree.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_umls_semantic_type_tree.py,python,local_import,,,,Import: construct_umls_tree_from_tsv from scispacy.umls_semantic_type_tree,allenai,scispacy,v0.5.4,from scispacy.umls_semantic_type_tree import construct_umls_tree_from_tsv,scispacy.umls_semantic_type_tree,construct_umls_tree_from_tsv,,,scispacy.umls_semantic_type_tree,,,,,,,,,,,,
test_umls_semantic_type_tree.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_umls_semantic_type_tree.py,python,,,,,Directory: tests\test_umls_semantic_type_tree.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_umls_utils.py,python,class_field,,,,"Class field: TestUtil.expected_concepts = [
            {'concept_id': 'C0000005', 'canonical_name': '(131)I-Macroaggregated Albumin',
             'types': ['T116'], 'aliases': ['(131)I-MAA']},
            {'concept_id': 'C0000039', 'aliases': ['1,2-Dipalmitoylphosphatidylcholine'],
             'types': ['T109', 'T121'], 'definition':
             'Synthetic phospholipid used in liposomes and lipid bilayers to study biological membranes.'}
    ]",allenai,scispacy,v0.5.4,,,,,,,TestUtil,,,"expected_concepts = [
            {'concept_id': 'C0000005', 'canonical_name': '(131)I-Macroaggregated Albumin',
             'types': ['T116'], 'aliases': ['(131)I-MAA']},
            {'concept_id': 'C0000039', 'aliases': ['1,2-Dipalmitoylphosphatidylcholine'],
             'types': ['T109', 'T121'], 'definition':
             'Synthetic phospholipid used in liposomes and lipid bilayers to study biological membranes.'}
    ]",,,,,expected_concepts,,"[
            {'concept_id': 'C0000005', 'canonical_name': '(131)I-Macroaggregated Albumin',
             'types': ['T116'], 'aliases': ['(131)I-MAA']},
            {'concept_id': 'C0000039', 'aliases': ['1,2-Dipalmitoylphosphatidylcholine'],
             'types': ['T109', 'T121'], 'definition':
             'Synthetic phospholipid used in liposomes and lipid bilayers to study biological membranes.'}
    ]",
test_umls_utils.py,python,class_method,,,,Class method: TestUtil.test_read_umls_concepts(self),allenai,scispacy,v0.5.4,,,,,,,TestUtil,test_read_umls_concepts,(self),,,,,,,,,
test_umls_utils.py,python,class_method,,,,Class method: TestUtil.test_read_umls_types(self),allenai,scispacy,v0.5.4,,,,,,,TestUtil,test_read_umls_types,(self),,,,,,,,,
test_umls_utils.py,python,class_method,,,,Class method: TestUtil.test_read_umls_definitions(self),allenai,scispacy,v0.5.4,,,,,,,TestUtil,test_read_umls_definitions,(self),,,,,,,,,
test_umls_utils.py,python,class,,,,Class: TestUtil(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestUtil,,,,,,,,,(unittest.TestCase),,
test_umls_utils.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_umls_utils.py,python,import,,,,Import: umls_utils from scispacy,allenai,scispacy,v0.5.4,from scispacy import umls_utils,scispacy,umls_utils,,,,,,,,,,,,,,,
test_umls_utils.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_umls_utils.py,python,,,,,Directory: tests\test_umls_utils.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_util.py,python,class_method,,,,Class method: TestUtil.setUp(self),allenai,scispacy,v0.5.4,,,,,,,TestUtil,setUp,(self),,,,,,,,,
test_util.py,python,class_method,,,,Class method: TestUtil.test_whitespace_tokenizer(self),allenai,scispacy,v0.5.4,,,,,,,TestUtil,test_whitespace_tokenizer,(self),,,,,,,,,
test_util.py,python,class,,,,Class: TestUtil(unittest.TestCase),allenai,scispacy,v0.5.4,,,,,,,TestUtil,,,,,,,,,(unittest.TestCase),,
test_util.py,python,import,,,,Import: unittest,allenai,scispacy,v0.5.4,import unittest,,unittest,,,,,,,,,,,,,,,
test_util.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
test_util.py,python,local_import,,,,Import: WhitespaceTokenizer from scispacy.util,allenai,scispacy,v0.5.4,from scispacy.util import WhitespaceTokenizer,scispacy.util,WhitespaceTokenizer,,,scispacy.util,,,,,,,,,,,,
test_util.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_util.py,python,,,,,Directory: tests\test_util.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
__init__.py,python,,,,,File: tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
__init__.py,python,,,,,Directory: tests\__init__.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_all_model.py,python,function,,,,Function: test_custom_segmentation(combined_all_model_fixture),allenai,scispacy,v0.5.4,,,,test_custom_segmentation,(combined_all_model_fixture),,,,,,,,,,,,,
test_all_model.py,python,function,,,,Function: test_full_pipe_serializable(combined_all_model_fixture),allenai,scispacy,v0.5.4,,,,test_full_pipe_serializable,(combined_all_model_fixture),,,,,,,,,,,,,
test_all_model.py,python,function,,,,Function: test_full_pipe_not_serializable(combined_all_model_fixture_non_serializable_abbrev),allenai,scispacy,v0.5.4,,,,test_full_pipe_not_serializable,(combined_all_model_fixture_non_serializable_abbrev),,,,,,,,,,,,,
test_all_model.py,python,import,,,,Import: os,allenai,scispacy,v0.5.4,import os,,os,,,,,,,,,,,,,,,
test_all_model.py,python,import,,,,Import: sys,allenai,scispacy,v0.5.4,import sys,,sys,,,,,,,,,,,,,,,
test_all_model.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
test_all_model.py,python,import,,,,Import: shutil,allenai,scispacy,v0.5.4,import shutil,,shutil,,,,,,,,,,,,,,,
test_all_model.py,python,import,,,,Import: pytest,allenai,scispacy,v0.5.4,import pytest,,pytest,,,,,,,,,,,,,,,
test_all_model.py,python,local_import,,,,Import: Vocab from spacy.vocab,allenai,scispacy,v0.5.4,from spacy.vocab import Vocab,spacy.vocab,Vocab,,,spacy.vocab,,,,,,,,,,,,
test_all_model.py,python,,,,,File: tests\custom_tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_all_model.py,python,,,,,Directory: tests\custom_tests\test_all_model.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_custom_segmentation.py,python,function,,,,Function: test_segmenter(en_with_combined_rule_tokenizer_and_segmenter_fixture),allenai,scispacy,v0.5.4,,,,test_segmenter,(en_with_combined_rule_tokenizer_and_segmenter_fixture),,,,,,,,,"# this text used to crash pysbd",,,,
test_custom_segmentation.py,python,constant,"TEST_CASES = [
    (
        ""LSTM networks, which we preview in Sec. 2, have been successfully"",
        [""LSTM networks, which we preview in Sec. 2, have been successfully""],
    ),
    (
        ""When the tree is simply a chain, both Eqs. 28 and Eqs. 914 reduce to the standard LSTM transitions, Eqs. 1."",
        [
            ""When the tree is simply a chain, both Eqs. 28 and Eqs. 914 reduce to the standard LSTM transitions, Eqs. 1.""
        ],
    ),
    (
        ""We used fluorescence time-lapse microscopy (Fig. 1D; fig. S1 and movies S1 and S2) and computational"",
        [
            ""We used fluorescence time-lapse microscopy (Fig. 1D; fig. S1 and movies S1 and S2) and computational""
        ],
    ),
    (
        ""Hill functions indeed fit the data well (Fig. 3A and Table 1)."",
        [""Hill functions indeed fit the data well (Fig. 3A and Table 1).""],
    ),
    (
        ""In order to produce sentence representations that fully capture the semantics of natural language, order-insensitive models are insufficient due to their inability to account for differences in meaning as a result of differences in word order or syntactic structure (e.g., cats climb trees vs. trees climb cats)."",
        [
            ""In order to produce sentence representations that fully capture the semantics of natural language, order-insensitive models are insufficient due to their inability to account for differences in meaning as a result of differences in word order or syntactic structure (e.g., cats climb trees vs. trees climb cats).""
        ],
    ),
    (
        ""There is an average exact sparsity (fraction of zeros) of the hidden layers of 83.40% on MNIST and 72.00% on CIFAR10. Figure 3 (left) provides a better understanding of the influence of sparsity."",
        [
            ""There is an average exact sparsity (fraction of zeros) of the hidden layers of 83.40% on MNIST and 72.00% on CIFAR10."",
            ""Figure 3 (left) provides a better understanding of the influence of sparsity."",
        ],
    ),
    (
        ""Sparsity has become a concept of interest, not only in computational neuroscience and machine learning but also in statistics and signal processing (Candes and Tao, 2005). It was first introduced in computational neuroscience in the context of sparse coding in the visual system (Olshausen and Field, 1997)."",
        [
            ""Sparsity has become a concept of interest, not only in computational neuroscience and machine learning but also in statistics and signal processing (Candes and Tao, 2005)."",
            ""It was first introduced in computational neuroscience in the context of sparse coding in the visual system (Olshausen and Field, 1997)."",
        ],
    ),
    (
        ""1) The first item. 2) The second item."",
        [""1) The first item."", ""2) The second item.""],
    ),
    (
        ""two of these stages (in areas V1 and V2 of visual cortex) (Lee et al., 2008), and that they"",
        [
            ""two of these stages (in areas V1 and V2 of visual cortex) (Lee et al., 2008), and that they""
        ],
    ),
    pytest.param(
        ""all neu-\nrons fire at"", [""all neu-\nrons fire at""], marks=pytest.mark.xfail
    ),
    (
        ""the support of the Defense Advanced Resarch Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract"",
        [
            ""the support of the Defense Advanced Resarch Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract""
        ],
    ),
    (
        ""While proprietary environments such as Microsoft Robotics Studio [9] and Webots [10] have many commendable attributes, we feel there is no substitute for a fully open platform."",
        [
            ""While proprietary environments such as Microsoft Robotics Studio [9] and Webots [10] have many commendable attributes, we feel there is no substitute for a fully open platform.""
        ],
    ),
    (
        ""We first produce sentence representations hL and hR for each sentence in the pair using a Tree-LSTM model over each sentences parse tree."",
        [
            ""We first produce sentence representations hL and hR for each sentence in the pair using a Tree-LSTM model over each sentences parse tree.""
        ],
    ),
    (
        ""LSTM networks, which we review in Sec. 2, have been successfully applied to a variety of sequence modeling and prediction tasks, notably machine translation (Bahdanau et al., 2014; Sutskever et al., 2014), speech recognition (Graves et al., 2013), image caption generation (Vinyals et al., 2014), and program execution (Zaremba and Sutskever, 2014)."",
        [
            ""LSTM networks, which we review in Sec. 2, have been successfully applied to a variety of sequence modeling and prediction tasks, notably machine translation (Bahdanau et al., 2014; Sutskever et al., 2014), speech recognition (Graves et al., 2013), image caption generation (Vinyals et al., 2014), and program execution (Zaremba and Sutskever, 2014).""
        ],
    ),
    (
        ""1 Introduction\n\nMost models for distributed representations of phrases and sentencesthat is, models where realvalued vectors are used to represent meaningfall into one of three classes: bag-of-words models, sequence models, and tree-structured models."",
        [
            ""1 Introduction\n\n"",
            ""Most models for distributed representations of phrases and sentencesthat is, models where realvalued vectors are used to represent meaningfall into one of three classes: bag-of-words models, sequence models, and tree-structured models."",
        ],
    ),
    (
        ""In this section, we will elaborate these philosophies and shows how they influenced the design and implementation of ROS.\n\nA. Peer-to-Peer\n\nA system built using ROS consists of a number of processes, potentially on a number of different"",
        [
            ""In this section, we will elaborate these philosophies and shows how they influenced the design and implementation of ROS.\n\n"",
            ""A. Peer-to-Peer\n\n"",
            ""A system built using ROS consists of a number of processes, potentially on a number of different"",
        ],
    ),
    (
        ""\n\n2 Long Short-Term Memory Networks\n\n\n\n2.1 Overview\n\nRecurrent neural networks (RNNs) are able to process input sequences of arbitrary length via the recursive application of a transition function on a hidden state vector ht."",
        [
            ""\n\n2 Long Short-Term Memory Networks\n\n\n\n"",
            ""2.1 Overview\n\n"",
            ""Recurrent neural networks (RNNs) are able to process input sequences of arbitrary length via the recursive application of a transition function on a hidden state vector ht."",
        ],
    ),
    (
        ""In order to address all three aspects, it is necessary to observe gene regulation in individual cells over time. Therefore, we built Bl-cascade[ strains of Escherichia coli, containing the l repressor and a downstream gene, such that both the amount of the repressor protein and the rate of expression of its target gene could be monitored simultaneously in individual cells (Fig. 1B). These strains incorporate a yellow fluorescent repressor fusion protein (cI-yfp) and a chromosomally integrated target promoter (P R ) controlling cyan fluorescent protein (cfp)."",
        [
            ""In order to address all three aspects, it is necessary to observe gene regulation in individual cells over time."",
            ""Therefore, we built Bl-cascade[ strains of Escherichia coli, containing the l repressor and a downstream gene, such that both the amount of the repressor protein and the rate of expression of its target gene could be monitored simultaneously in individual cells (Fig. 1B)."",
            ""These strains incorporate a yellow fluorescent repressor fusion protein (cI-yfp) and a chromosomally integrated target promoter (P R ) controlling cyan fluorescent protein (cfp)."",
        ],
    ),
    (
        ""This is a sentence. (This is an interjected sentence.) This is also a sentence."",
        [
            ""This is a sentence."",
            ""(This is an interjected sentence.)"",
            ""This is also a sentence."",
        ],
    ),
    (
        ""Thus, we first compute EMC 3 's response time-i.e., the duration from the initial of a call (from/to a participant in the target region) to the time when the decision of task assignment is made; and then, based on the computed response time, we estimate EMC 3 maximum throughput [28]-i.e., the maximum number of mobile users allowed in the MCS system. EMC 3 algorithm is implemented with the Java SE platform and is running on a Java HotSpot(TM) 64-Bit Server VM; and the implementation details are given in Appendix, available in the online supplemental material."",
        [
            ""Thus, we first compute EMC 3 's response time-i.e., the duration from the initial of a call (from/to a participant in the target region) to the time when the decision of task assignment is made; and then, based on the computed response time, we estimate EMC 3 maximum throughput [28]-i.e., the maximum number of mobile users allowed in the MCS system."",
            ""EMC 3 algorithm is implemented with the Java SE platform and is running on a Java HotSpot(TM) 64-Bit Server VM; and the implementation details are given in Appendix, available in the online supplemental material."",
        ],
    ),
    (
        ""Random walk models (Skellam, 1951;Turchin, 1998) received a lot of attention and were then extended to several more mathematically and statistically sophisticated approaches to interpret movement data such as State-Space Models (SSM) (Jonsen et al., 2003(Jonsen et al., , 2005 and Brownian Bridge Movement Model (BBMM) (Horne et al., 2007). Nevertheless, these models require heavy computational resources (Patterson et al., 2008) and unrealistic structural a priori hypotheses about movement, such as homogeneous movement behavior. A fundamental property of animal movements is behavioral heterogeneity (Gurarie et al., 2009) and these models poorly performed in highlighting behavioral changes in animal movements through space and time (Kranstauber et al., 2012)."",
        [
            ""Random walk models (Skellam, 1951;Turchin, 1998) received a lot of attention and were then extended to several more mathematically and statistically sophisticated approaches to interpret movement data such as State-Space Models (SSM) (Jonsen et al., 2003(Jonsen et al., , 2005 and Brownian Bridge Movement Model (BBMM) (Horne et al., 2007)."",
            ""Nevertheless, these models require heavy computational resources (Patterson et al., 2008) and unrealistic structural a priori hypotheses about movement, such as homogeneous movement behavior."",
            ""A fundamental property of animal movements is behavioral heterogeneity (Gurarie et al., 2009) and these models poorly performed in highlighting behavioral changes in animal movements through space and time (Kranstauber et al., 2012)."",
        ],
    ),
    ("". . ."", ["". . .""]),
    (
        ""IF condition and goalCondition THEN action condition relates to the current state and goalCondition to the goal state. If variable bindings exist such that predicates in condition match with the current state, and predicates in goalCondition match with the goal state then the action may be performed. Note that the action's precondition as specified in the domain model must also be satisfied. Figure 5 presents an outline of the system. Each iteration starts with a population of policies (line(2)). Current L2Plan settings are such that the individuals comprising the (1) Create initial population (2) WHILE termination criterion false (3) Determine n% fittest polices (4) Perform local search on policies (5) Insert improved policies in new generation (6) WHILE new generation not full (7) SET Pol to empty policy (8) Select two parents (9) IF crossover (10) Perform crossover (11) Pol := fittest of parents & offspring (12) ELSE (13) Pol := fittest of parents (14) ENDIF (15) IF mutation (16) Perform mutation on Pol (17) ENDIF (18) Perform local search on Pol (19) Insert Pol in new generation (20) ENDWHILE (21) (5)). Note that the evaluation of policies is implied when the fittest policy or policies is/are required."",
        [
            ""IF condition and goalCondition THEN action condition relates to the current state and goalCondition to the goal state."",
            ""If variable bindings exist such that predicates in condition match with the current state, and predicates in goalCondition match with the goal state then the action may be performed."",
            ""Note that the action's precondition as specified in the domain model must also be satisfied."",
            ""Figure 5 presents an outline of the system."",
            ""Each iteration starts with a population of policies (line(2))."",
            ""Current L2Plan settings are such that the individuals comprising the (1) Create initial population (2) WHILE termination criterion false (3) Determine n% fittest polices (4) Perform local search on policies (5) Insert improved policies in new generation (6) WHILE new generation not full (7) SET Pol to empty policy (8) Select two parents (9) IF crossover (10) Perform crossover (11) Pol := fittest of parents & offspring (12) ELSE (13) Pol := fittest of parents (14) ENDIF (15) IF mutation (16) Perform mutation on Pol (17) ENDIF (18) Perform local search on Pol (19) Insert Pol in new generation (20) ENDWHILE (21) (5))."",
            ""Note that the evaluation of policies is implied when the fittest policy or policies is/are required."",
        ],
    ),
    (
        ""MCC summarizes these four quantities into one score and is regarded as a balanced measure; it takes values between -1 and 1, with higher values indicating better performance (see e.g. Baldi et al. (2000) for further details). Since the convergence threshold in the glasso algorithm is 10 4 , we take entries ij in estimated precision matrices to be non-zero if | ij | > 10 3 . Since cluster assignments can only be identified up to permutation, in all cases labels were permuted to maximize agreement with true cluster assignments before calculating these quantities. Figure 2 shows MCC plotted against per-cluster sample size n k and Supplementary Figure S1 shows corresponding plots for TPR and FPR. Due to selection of smaller tuning parameter values, BIC discovers fewer non-zeroes in the precision matrices than train/test, resulting in both fewer true positives and false positives. Under MCC, BIC, with either the  = 1 mixture model (B1) or the non-mixture approach (Bh), leads to the best network reconstruction (except at small sample sizes with p = 25) and outperforms all other regimes at larger sample sizes."",
        [
            ""MCC summarizes these four quantities into one score and is regarded as a balanced measure; it takes values between -1 and 1, with higher values indicating better performance (see e.g. Baldi et al. (2000) for further details)."",
            ""Since the convergence threshold in the glasso algorithm is 10 4 , we take entries ij in estimated precision matrices to be non-zero if | ij | > 10 3 ."",
            ""Since cluster assignments can only be identified up to permutation, in all cases labels were permuted to maximize agreement with true cluster assignments before calculating these quantities."",
            ""Figure 2 shows MCC plotted against per-cluster sample size n k and Supplementary Figure S1 shows corresponding plots for TPR and FPR."",
            ""Due to selection of smaller tuning parameter values, BIC discovers fewer non-zeroes in the precision matrices than train/test, resulting in both fewer true positives and false positives."",
            ""Under MCC, BIC, with either the  = 1 mixture model (B1) or the non-mixture approach (Bh), leads to the best network reconstruction (except at small sample sizes with p = 25) and outperforms all other regimes at larger sample sizes."",
        ],
    ),
    (
        'Societal impact measurements are mostly commissioned by governments which argue that measuring the impact on science little says about real-world benefits of research (Cohen et al., 2015). Nightingale and Scott (2007) summarize this argumentation in the following pointedly sentence: ""Research that is highly cited or published in top journals may be good for the academic discipline but not for society"" (p. 547). Governments are interested to know the importance of public-funded research (1) for the private and public sectors (e.g. health care), (2) to tackle societal challenges (e.g. climate change), and (3) for education and training of the next generations (ERiC, 2010;Grimson, 2014). The impact model of Cleary, Siegfried, Jackson, and Hunt (2013) additionally highlights the policy enactment of research, in which the impact on policies, laws, and regulations is of special interest. The current study seizes upon this additional issue by investigating a possible source for measuring policy enactment of research.',
        [
            ""Societal impact measurements are mostly commissioned by governments which argue that measuring the impact on science little says about real-world benefits of research (Cohen et al., 2015)."",
            'Nightingale and Scott (2007) summarize this argumentation in the following pointedly sentence: ""Research that is highly cited or published in top journals may be good for the academic discipline but not for society"" (p. 547).',
            ""Governments are interested to know the importance of public-funded research (1) for the private and public sectors (e.g. health care), (2) to tackle societal challenges (e.g. climate change), and (3) for education and training of the next generations (ERiC, 2010;Grimson, 2014)."",
            ""The impact model of Cleary, Siegfried, Jackson, and Hunt (2013) additionally highlights the policy enactment of research, in which the impact on policies, laws, and regulations is of special interest."",
            ""The current study seizes upon this additional issue by investigating a possible source for measuring policy enactment of research."",
        ],
    ),
    (
        ""CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA. Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation."",
        [
            ""CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA."",
            ""Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation."",
        ],
    ),
    (
        ""In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun."",
        [
            ""In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun.""
        ],
    ),
    (
        ""A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site."",
        [
            ""A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB."",
            ""We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site."",
        ],
    ),
    pytest.param(
        ""Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner."",
        [
            ""Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B."",
            ""Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner."",
        ],
        marks=pytest.mark.xfail,
    ),
    (
        ""There are p50.c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation."",
        [
            ""There are p50.c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation.""
        ],
    ),
    (
        ""This sentence mentions Eqs. 1-4 and should not be split."",
        [""This sentence mentions Eqs. 1-4 and should not be split.""],
    ),
    (
        ""This sentence ends with part an abbreviation that is part of a word material. It also has another sentence after it."",
        [
            ""This sentence ends with part an abbreviation that is part of a word material."",
            ""It also has another sentence after it."",
        ],
    ),
    (
        ""It also has a sentence before it. This sentence mentions Eqs. 1-4 and should not be split. It also has another sentence after it."",
        [
            ""It also has a sentence before it."",
            ""This sentence mentions Eqs. 1-4 and should not be split."",
            ""It also has another sentence after it."",
        ],
    ),
    (
        ""This sentence is the last segment and ends with an abbreviation that is part of a word material."",
        [
            ""This sentence is the last segment and ends with an abbreviation that is part of a word material.""
        ],
    ),
    (
        ""PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/- 86 pg/ml)."",
        [
            ""PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/- 86 pg/ml).""
        ],
    ),
    (
        ""    This document starts with whitespaces. Next sentence."",
        [""    "", ""This document starts with whitespaces."", ""Next sentence.""],
    ),
    pytest.param(
        ""How about tomorrow?We can meet at eden garden."",
        [""How about tomorrow?"", ""We can meet at eden garden.""],
        marks=pytest.mark.xfail,
    ),
]",TEST_CASES,"[
    (
        ""LSTM networks, which we preview in Sec. 2, have been successfully"",
        [""LSTM networks, which we preview in Sec. 2, have been successfully""],
    ),
    (
        ""When the tree is simply a chain, both Eqs. 28 and Eqs. 914 reduce to the standard LSTM transitions, Eqs. 1."",
        [
            ""When the tree is simply a chain, both Eqs. 28 and Eqs. 914 reduce to the standard LSTM transitions, Eqs. 1.""
        ],
    ),
    (
        ""We used fluorescence time-lapse microscopy (Fig. 1D; fig. S1 and movies S1 and S2) and computational"",
        [
            ""We used fluorescence time-lapse microscopy (Fig. 1D; fig. S1 and movies S1 and S2) and computational""
        ],
    ),
    (
        ""Hill functions indeed fit the data well (Fig. 3A and Table 1)."",
        [""Hill functions indeed fit the data well (Fig. 3A and Table 1).""],
    ),
    (
        ""In order to produce sentence representations that fully capture the semantics of natural language, order-insensitive models are insufficient due to their inability to account for differences in meaning as a result of differences in word order or syntactic structure (e.g., cats climb trees vs. trees climb cats)."",
        [
            ""In order to produce sentence representations that fully capture the semantics of natural language, order-insensitive models are insufficient due to their inability to account for differences in meaning as a result of differences in word order or syntactic structure (e.g., cats climb trees vs. trees climb cats).""
        ],
    ),
    (
        ""There is an average exact sparsity (fraction of zeros) of the hidden layers of 83.40% on MNIST and 72.00% on CIFAR10. Figure 3 (left) provides a better understanding of the influence of sparsity."",
        [
            ""There is an average exact sparsity (fraction of zeros) of the hidden layers of 83.40% on MNIST and 72.00% on CIFAR10."",
            ""Figure 3 (left) provides a better understanding of the influence of sparsity."",
        ],
    ),
    (
        ""Sparsity has become a concept of interest, not only in computational neuroscience and machine learning but also in statistics and signal processing (Candes and Tao, 2005). It was first introduced in computational neuroscience in the context of sparse coding in the visual system (Olshausen and Field, 1997)."",
        [
            ""Sparsity has become a concept of interest, not only in computational neuroscience and machine learning but also in statistics and signal processing (Candes and Tao, 2005)."",
            ""It was first introduced in computational neuroscience in the context of sparse coding in the visual system (Olshausen and Field, 1997)."",
        ],
    ),
    (
        ""1) The first item. 2) The second item."",
        [""1) The first item."", ""2) The second item.""],
    ),
    (
        ""two of these stages (in areas V1 and V2 of visual cortex) (Lee et al., 2008), and that they"",
        [
            ""two of these stages (in areas V1 and V2 of visual cortex) (Lee et al., 2008), and that they""
        ],
    ),
    pytest.param(
        ""all neu-\nrons fire at"", [""all neu-\nrons fire at""], marks=pytest.mark.xfail
    ),
    (
        ""the support of the Defense Advanced Resarch Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract"",
        [
            ""the support of the Defense Advanced Resarch Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract""
        ],
    ),
    (
        ""While proprietary environments such as Microsoft Robotics Studio [9] and Webots [10] have many commendable attributes, we feel there is no substitute for a fully open platform."",
        [
            ""While proprietary environments such as Microsoft Robotics Studio [9] and Webots [10] have many commendable attributes, we feel there is no substitute for a fully open platform.""
        ],
    ),
    (
        ""We first produce sentence representations hL and hR for each sentence in the pair using a Tree-LSTM model over each sentences parse tree."",
        [
            ""We first produce sentence representations hL and hR for each sentence in the pair using a Tree-LSTM model over each sentences parse tree.""
        ],
    ),
    (
        ""LSTM networks, which we review in Sec. 2, have been successfully applied to a variety of sequence modeling and prediction tasks, notably machine translation (Bahdanau et al., 2014; Sutskever et al., 2014), speech recognition (Graves et al., 2013), image caption generation (Vinyals et al., 2014), and program execution (Zaremba and Sutskever, 2014)."",
        [
            ""LSTM networks, which we review in Sec. 2, have been successfully applied to a variety of sequence modeling and prediction tasks, notably machine translation (Bahdanau et al., 2014; Sutskever et al., 2014), speech recognition (Graves et al., 2013), image caption generation (Vinyals et al., 2014), and program execution (Zaremba and Sutskever, 2014).""
        ],
    ),
    (
        ""1 Introduction\n\nMost models for distributed representations of phrases and sentencesthat is, models where realvalued vectors are used to represent meaningfall into one of three classes: bag-of-words models, sequence models, and tree-structured models."",
        [
            ""1 Introduction\n\n"",
            ""Most models for distributed representations of phrases and sentencesthat is, models where realvalued vectors are used to represent meaningfall into one of three classes: bag-of-words models, sequence models, and tree-structured models."",
        ],
    ),
    (
        ""In this section, we will elaborate these philosophies and shows how they influenced the design and implementation of ROS.\n\nA. Peer-to-Peer\n\nA system built using ROS consists of a number of processes, potentially on a number of different"",
        [
            ""In this section, we will elaborate these philosophies and shows how they influenced the design and implementation of ROS.\n\n"",
            ""A. Peer-to-Peer\n\n"",
            ""A system built using ROS consists of a number of processes, potentially on a number of different"",
        ],
    ),
    (
        ""\n\n2 Long Short-Term Memory Networks\n\n\n\n2.1 Overview\n\nRecurrent neural networks (RNNs) are able to process input sequences of arbitrary length via the recursive application of a transition function on a hidden state vector ht."",
        [
            ""\n\n2 Long Short-Term Memory Networks\n\n\n\n"",
            ""2.1 Overview\n\n"",
            ""Recurrent neural networks (RNNs) are able to process input sequences of arbitrary length via the recursive application of a transition function on a hidden state vector ht."",
        ],
    ),
    (
        ""In order to address all three aspects, it is necessary to observe gene regulation in individual cells over time. Therefore, we built Bl-cascade[ strains of Escherichia coli, containing the l repressor and a downstream gene, such that both the amount of the repressor protein and the rate of expression of its target gene could be monitored simultaneously in individual cells (Fig. 1B). These strains incorporate a yellow fluorescent repressor fusion protein (cI-yfp) and a chromosomally integrated target promoter (P R ) controlling cyan fluorescent protein (cfp)."",
        [
            ""In order to address all three aspects, it is necessary to observe gene regulation in individual cells over time."",
            ""Therefore, we built Bl-cascade[ strains of Escherichia coli, containing the l repressor and a downstream gene, such that both the amount of the repressor protein and the rate of expression of its target gene could be monitored simultaneously in individual cells (Fig. 1B)."",
            ""These strains incorporate a yellow fluorescent repressor fusion protein (cI-yfp) and a chromosomally integrated target promoter (P R ) controlling cyan fluorescent protein (cfp)."",
        ],
    ),
    (
        ""This is a sentence. (This is an interjected sentence.) This is also a sentence."",
        [
            ""This is a sentence."",
            ""(This is an interjected sentence.)"",
            ""This is also a sentence."",
        ],
    ),
    (
        ""Thus, we first compute EMC 3 's response time-i.e., the duration from the initial of a call (from/to a participant in the target region) to the time when the decision of task assignment is made; and then, based on the computed response time, we estimate EMC 3 maximum throughput [28]-i.e., the maximum number of mobile users allowed in the MCS system. EMC 3 algorithm is implemented with the Java SE platform and is running on a Java HotSpot(TM) 64-Bit Server VM; and the implementation details are given in Appendix, available in the online supplemental material."",
        [
            ""Thus, we first compute EMC 3 's response time-i.e., the duration from the initial of a call (from/to a participant in the target region) to the time when the decision of task assignment is made; and then, based on the computed response time, we estimate EMC 3 maximum throughput [28]-i.e., the maximum number of mobile users allowed in the MCS system."",
            ""EMC 3 algorithm is implemented with the Java SE platform and is running on a Java HotSpot(TM) 64-Bit Server VM; and the implementation details are given in Appendix, available in the online supplemental material."",
        ],
    ),
    (
        ""Random walk models (Skellam, 1951;Turchin, 1998) received a lot of attention and were then extended to several more mathematically and statistically sophisticated approaches to interpret movement data such as State-Space Models (SSM) (Jonsen et al., 2003(Jonsen et al., , 2005 and Brownian Bridge Movement Model (BBMM) (Horne et al., 2007). Nevertheless, these models require heavy computational resources (Patterson et al., 2008) and unrealistic structural a priori hypotheses about movement, such as homogeneous movement behavior. A fundamental property of animal movements is behavioral heterogeneity (Gurarie et al., 2009) and these models poorly performed in highlighting behavioral changes in animal movements through space and time (Kranstauber et al., 2012)."",
        [
            ""Random walk models (Skellam, 1951;Turchin, 1998) received a lot of attention and were then extended to several more mathematically and statistically sophisticated approaches to interpret movement data such as State-Space Models (SSM) (Jonsen et al., 2003(Jonsen et al., , 2005 and Brownian Bridge Movement Model (BBMM) (Horne et al., 2007)."",
            ""Nevertheless, these models require heavy computational resources (Patterson et al., 2008) and unrealistic structural a priori hypotheses about movement, such as homogeneous movement behavior."",
            ""A fundamental property of animal movements is behavioral heterogeneity (Gurarie et al., 2009) and these models poorly performed in highlighting behavioral changes in animal movements through space and time (Kranstauber et al., 2012)."",
        ],
    ),
    ("". . ."", ["". . .""]),
    (
        ""IF condition and goalCondition THEN action condition relates to the current state and goalCondition to the goal state. If variable bindings exist such that predicates in condition match with the current state, and predicates in goalCondition match with the goal state then the action may be performed. Note that the action's precondition as specified in the domain model must also be satisfied. Figure 5 presents an outline of the system. Each iteration starts with a population of policies (line(2)). Current L2Plan settings are such that the individuals comprising the (1) Create initial population (2) WHILE termination criterion false (3) Determine n% fittest polices (4) Perform local search on policies (5) Insert improved policies in new generation (6) WHILE new generation not full (7) SET Pol to empty policy (8) Select two parents (9) IF crossover (10) Perform crossover (11) Pol := fittest of parents & offspring (12) ELSE (13) Pol := fittest of parents (14) ENDIF (15) IF mutation (16) Perform mutation on Pol (17) ENDIF (18) Perform local search on Pol (19) Insert Pol in new generation (20) ENDWHILE (21) (5)). Note that the evaluation of policies is implied when the fittest policy or policies is/are required."",
        [
            ""IF condition and goalCondition THEN action condition relates to the current state and goalCondition to the goal state."",
            ""If variable bindings exist such that predicates in condition match with the current state, and predicates in goalCondition match with the goal state then the action may be performed."",
            ""Note that the action's precondition as specified in the domain model must also be satisfied."",
            ""Figure 5 presents an outline of the system."",
            ""Each iteration starts with a population of policies (line(2))."",
            ""Current L2Plan settings are such that the individuals comprising the (1) Create initial population (2) WHILE termination criterion false (3) Determine n% fittest polices (4) Perform local search on policies (5) Insert improved policies in new generation (6) WHILE new generation not full (7) SET Pol to empty policy (8) Select two parents (9) IF crossover (10) Perform crossover (11) Pol := fittest of parents & offspring (12) ELSE (13) Pol := fittest of parents (14) ENDIF (15) IF mutation (16) Perform mutation on Pol (17) ENDIF (18) Perform local search on Pol (19) Insert Pol in new generation (20) ENDWHILE (21) (5))."",
            ""Note that the evaluation of policies is implied when the fittest policy or policies is/are required."",
        ],
    ),
    (
        ""MCC summarizes these four quantities into one score and is regarded as a balanced measure; it takes values between -1 and 1, with higher values indicating better performance (see e.g. Baldi et al. (2000) for further details). Since the convergence threshold in the glasso algorithm is 10 4 , we take entries ij in estimated precision matrices to be non-zero if | ij | > 10 3 . Since cluster assignments can only be identified up to permutation, in all cases labels were permuted to maximize agreement with true cluster assignments before calculating these quantities. Figure 2 shows MCC plotted against per-cluster sample size n k and Supplementary Figure S1 shows corresponding plots for TPR and FPR. Due to selection of smaller tuning parameter values, BIC discovers fewer non-zeroes in the precision matrices than train/test, resulting in both fewer true positives and false positives. Under MCC, BIC, with either the  = 1 mixture model (B1) or the non-mixture approach (Bh), leads to the best network reconstruction (except at small sample sizes with p = 25) and outperforms all other regimes at larger sample sizes."",
        [
            ""MCC summarizes these four quantities into one score and is regarded as a balanced measure; it takes values between -1 and 1, with higher values indicating better performance (see e.g. Baldi et al. (2000) for further details)."",
            ""Since the convergence threshold in the glasso algorithm is 10 4 , we take entries ij in estimated precision matrices to be non-zero if | ij | > 10 3 ."",
            ""Since cluster assignments can only be identified up to permutation, in all cases labels were permuted to maximize agreement with true cluster assignments before calculating these quantities."",
            ""Figure 2 shows MCC plotted against per-cluster sample size n k and Supplementary Figure S1 shows corresponding plots for TPR and FPR."",
            ""Due to selection of smaller tuning parameter values, BIC discovers fewer non-zeroes in the precision matrices than train/test, resulting in both fewer true positives and false positives."",
            ""Under MCC, BIC, with either the  = 1 mixture model (B1) or the non-mixture approach (Bh), leads to the best network reconstruction (except at small sample sizes with p = 25) and outperforms all other regimes at larger sample sizes."",
        ],
    ),
    (
        'Societal impact measurements are mostly commissioned by governments which argue that measuring the impact on science little says about real-world benefits of research (Cohen et al., 2015). Nightingale and Scott (2007) summarize this argumentation in the following pointedly sentence: ""Research that is highly cited or published in top journals may be good for the academic discipline but not for society"" (p. 547). Governments are interested to know the importance of public-funded research (1) for the private and public sectors (e.g. health care), (2) to tackle societal challenges (e.g. climate change), and (3) for education and training of the next generations (ERiC, 2010;Grimson, 2014). The impact model of Cleary, Siegfried, Jackson, and Hunt (2013) additionally highlights the policy enactment of research, in which the impact on policies, laws, and regulations is of special interest. The current study seizes upon this additional issue by investigating a possible source for measuring policy enactment of research.',
        [
            ""Societal impact measurements are mostly commissioned by governments which argue that measuring the impact on science little says about real-world benefits of research (Cohen et al., 2015)."",
            'Nightingale and Scott (2007) summarize this argumentation in the following pointedly sentence: ""Research that is highly cited or published in top journals may be good for the academic discipline but not for society"" (p. 547).',
            ""Governments are interested to know the importance of public-funded research (1) for the private and public sectors (e.g. health care), (2) to tackle societal challenges (e.g. climate change), and (3) for education and training of the next generations (ERiC, 2010;Grimson, 2014)."",
            ""The impact model of Cleary, Siegfried, Jackson, and Hunt (2013) additionally highlights the policy enactment of research, in which the impact on policies, laws, and regulations is of special interest."",
            ""The current study seizes upon this additional issue by investigating a possible source for measuring policy enactment of research."",
        ],
    ),
    (
        ""CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA. Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation."",
        [
            ""CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA."",
            ""Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation."",
        ],
    ),
    (
        ""In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun."",
        [
            ""In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun.""
        ],
    ),
    (
        ""A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site."",
        [
            ""A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB."",
            ""We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site."",
        ],
    ),
    pytest.param(
        ""Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner."",
        [
            ""Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B."",
            ""Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner."",
        ],
        marks=pytest.mark.xfail,
    ),
    (
        ""There are p50.c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation."",
        [
            ""There are p50.c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation.""
        ],
    ),
    (
        ""This sentence mentions Eqs. 1-4 and should not be split."",
        [""This sentence mentions Eqs. 1-4 and should not be split.""],
    ),
    (
        ""This sentence ends with part an abbreviation that is part of a word material. It also has another sentence after it."",
        [
            ""This sentence ends with part an abbreviation that is part of a word material."",
            ""It also has another sentence after it."",
        ],
    ),
    (
        ""It also has a sentence before it. This sentence mentions Eqs. 1-4 and should not be split. It also has another sentence after it."",
        [
            ""It also has a sentence before it."",
            ""This sentence mentions Eqs. 1-4 and should not be split."",
            ""It also has another sentence after it."",
        ],
    ),
    (
        ""This sentence is the last segment and ends with an abbreviation that is part of a word material."",
        [
            ""This sentence is the last segment and ends with an abbreviation that is part of a word material.""
        ],
    ),
    (
        ""PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/- 86 pg/ml)."",
        [
            ""PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/- 86 pg/ml).""
        ],
    ),
    (
        ""    This document starts with whitespaces. Next sentence."",
        [""    "", ""This document starts with whitespaces."", ""Next sentence.""],
    ),
    pytest.param(
        ""How about tomorrow?We can meet at eden garden."",
        [""How about tomorrow?"", ""We can meet at eden garden.""],
        marks=pytest.mark.xfail,
    ),
]","Constant: TEST_CASES = [
    (
        ""LSTM networks, which we preview in Sec. 2, have been successfully"",
        [""LSTM networks, which we preview in Sec. 2, have been successfully""],
    ),
    (
        ""When the tree is simply a chain, both Eqs. 28 and Eqs. 914 reduce to the standard LSTM transitions, Eqs. 1."",
        [
            ""When the tree is simply a chain, both Eqs. 28 and Eqs. 914 reduce to the standard LSTM transitions, Eqs. 1.""
        ],
    ),
    (
        ""We used fluorescence time-lapse microscopy (Fig. 1D; fig. S1 and movies S1 and S2) and computational"",
        [
            ""We used fluorescence time-lapse microscopy (Fig. 1D; fig. S1 and movies S1 and S2) and computational""
        ],
    ),
    (
        ""Hill functions indeed fit the data well (Fig. 3A and Table 1)."",
        [""Hill functions indeed fit the data well (Fig. 3A and Table 1).""],
    ),
    (
        ""In order to produce sentence representations that fully capture the semantics of natural language, order-insensitive models are insufficient due to their inability to account for differences in meaning as a result of differences in word order or syntactic structure (e.g., cats climb trees vs. trees climb cats)."",
        [
            ""In order to produce sentence representations that fully capture the semantics of natural language, order-insensitive models are insufficient due to their inability to account for differences in meaning as a result of differences in word order or syntactic structure (e.g., cats climb trees vs. trees climb cats).""
        ],
    ),
    (
        ""There is an average exact sparsity (fraction of zeros) of the hidden layers of 83.40% on MNIST and 72.00% on CIFAR10. Figure 3 (left) provides a better understanding of the influence of sparsity."",
        [
            ""There is an average exact sparsity (fraction of zeros) of the hidden layers of 83.40% on MNIST and 72.00% on CIFAR10."",
            ""Figure 3 (left) provides a better understanding of the influence of sparsity."",
        ],
    ),
    (
        ""Sparsity has become a concept of interest, not only in computational neuroscience and machine learning but also in statistics and signal processing (Candes and Tao, 2005). It was first introduced in computational neuroscience in the context of sparse coding in the visual system (Olshausen and Field, 1997)."",
        [
            ""Sparsity has become a concept of interest, not only in computational neuroscience and machine learning but also in statistics and signal processing (Candes and Tao, 2005)."",
            ""It was first introduced in computational neuroscience in the context of sparse coding in the visual system (Olshausen and Field, 1997)."",
        ],
    ),
    (
        ""1) The first item. 2) The second item."",
        [""1) The first item."", ""2) The second item.""],
    ),
    (
        ""two of these stages (in areas V1 and V2 of visual cortex) (Lee et al., 2008), and that they"",
        [
            ""two of these stages (in areas V1 and V2 of visual cortex) (Lee et al., 2008), and that they""
        ],
    ),
    pytest.param(
        ""all neu-\nrons fire at"", [""all neu-\nrons fire at""], marks=pytest.mark.xfail
    ),
    (
        ""the support of the Defense Advanced Resarch Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract"",
        [
            ""the support of the Defense Advanced Resarch Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Program under Air Force Research Laboratory (AFRL) contract""
        ],
    ),
    (
        ""While proprietary environments such as Microsoft Robotics Studio [9] and Webots [10] have many commendable attributes, we feel there is no substitute for a fully open platform."",
        [
            ""While proprietary environments such as Microsoft Robotics Studio [9] and Webots [10] have many commendable attributes, we feel there is no substitute for a fully open platform.""
        ],
    ),
    (
        ""We first produce sentence representations hL and hR for each sentence in the pair using a Tree-LSTM model over each sentences parse tree."",
        [
            ""We first produce sentence representations hL and hR for each sentence in the pair using a Tree-LSTM model over each sentences parse tree.""
        ],
    ),
    (
        ""LSTM networks, which we review in Sec. 2, have been successfully applied to a variety of sequence modeling and prediction tasks, notably machine translation (Bahdanau et al., 2014; Sutskever et al., 2014), speech recognition (Graves et al., 2013), image caption generation (Vinyals et al., 2014), and program execution (Zaremba and Sutskever, 2014)."",
        [
            ""LSTM networks, which we review in Sec. 2, have been successfully applied to a variety of sequence modeling and prediction tasks, notably machine translation (Bahdanau et al., 2014; Sutskever et al., 2014), speech recognition (Graves et al., 2013), image caption generation (Vinyals et al., 2014), and program execution (Zaremba and Sutskever, 2014).""
        ],
    ),
    (
        ""1 Introduction\n\nMost models for distributed representations of phrases and sentencesthat is, models where realvalued vectors are used to represent meaningfall into one of three classes: bag-of-words models, sequence models, and tree-structured models."",
        [
            ""1 Introduction\n\n"",
            ""Most models for distributed representations of phrases and sentencesthat is, models where realvalued vectors are used to represent meaningfall into one of three classes: bag-of-words models, sequence models, and tree-structured models."",
        ],
    ),
    (
        ""In this section, we will elaborate these philosophies and shows how they influenced the design and implementation of ROS.\n\nA. Peer-to-Peer\n\nA system built using ROS consists of a number of processes, potentially on a number of different"",
        [
            ""In this section, we will elaborate these philosophies and shows how they influenced the design and implementation of ROS.\n\n"",
            ""A. Peer-to-Peer\n\n"",
            ""A system built using ROS consists of a number of processes, potentially on a number of different"",
        ],
    ),
    (
        ""\n\n2 Long Short-Term Memory Networks\n\n\n\n2.1 Overview\n\nRecurrent neural networks (RNNs) are able to process input sequences of arbitrary length via the recursive application of a transition function on a hidden state vector ht."",
        [
            ""\n\n2 Long Short-Term Memory Networks\n\n\n\n"",
            ""2.1 Overview\n\n"",
            ""Recurrent neural networks (RNNs) are able to process input sequences of arbitrary length via the recursive application of a transition function on a hidden state vector ht."",
        ],
    ),
    (
        ""In order to address all three aspects, it is necessary to observe gene regulation in individual cells over time. Therefore, we built Bl-cascade[ strains of Escherichia coli, containing the l repressor and a downstream gene, such that both the amount of the repressor protein and the rate of expression of its target gene could be monitored simultaneously in individual cells (Fig. 1B). These strains incorporate a yellow fluorescent repressor fusion protein (cI-yfp) and a chromosomally integrated target promoter (P R ) controlling cyan fluorescent protein (cfp)."",
        [
            ""In order to address all three aspects, it is necessary to observe gene regulation in individual cells over time."",
            ""Therefore, we built Bl-cascade[ strains of Escherichia coli, containing the l repressor and a downstream gene, such that both the amount of the repressor protein and the rate of expression of its target gene could be monitored simultaneously in individual cells (Fig. 1B)."",
            ""These strains incorporate a yellow fluorescent repressor fusion protein (cI-yfp) and a chromosomally integrated target promoter (P R ) controlling cyan fluorescent protein (cfp)."",
        ],
    ),
    (
        ""This is a sentence. (This is an interjected sentence.) This is also a sentence."",
        [
            ""This is a sentence."",
            ""(This is an interjected sentence.)"",
            ""This is also a sentence."",
        ],
    ),
    (
        ""Thus, we first compute EMC 3 's response time-i.e., the duration from the initial of a call (from/to a participant in the target region) to the time when the decision of task assignment is made; and then, based on the computed response time, we estimate EMC 3 maximum throughput [28]-i.e., the maximum number of mobile users allowed in the MCS system. EMC 3 algorithm is implemented with the Java SE platform and is running on a Java HotSpot(TM) 64-Bit Server VM; and the implementation details are given in Appendix, available in the online supplemental material."",
        [
            ""Thus, we first compute EMC 3 's response time-i.e., the duration from the initial of a call (from/to a participant in the target region) to the time when the decision of task assignment is made; and then, based on the computed response time, we estimate EMC 3 maximum throughput [28]-i.e., the maximum number of mobile users allowed in the MCS system."",
            ""EMC 3 algorithm is implemented with the Java SE platform and is running on a Java HotSpot(TM) 64-Bit Server VM; and the implementation details are given in Appendix, available in the online supplemental material."",
        ],
    ),
    (
        ""Random walk models (Skellam, 1951;Turchin, 1998) received a lot of attention and were then extended to several more mathematically and statistically sophisticated approaches to interpret movement data such as State-Space Models (SSM) (Jonsen et al., 2003(Jonsen et al., , 2005 and Brownian Bridge Movement Model (BBMM) (Horne et al., 2007). Nevertheless, these models require heavy computational resources (Patterson et al., 2008) and unrealistic structural a priori hypotheses about movement, such as homogeneous movement behavior. A fundamental property of animal movements is behavioral heterogeneity (Gurarie et al., 2009) and these models poorly performed in highlighting behavioral changes in animal movements through space and time (Kranstauber et al., 2012)."",
        [
            ""Random walk models (Skellam, 1951;Turchin, 1998) received a lot of attention and were then extended to several more mathematically and statistically sophisticated approaches to interpret movement data such as State-Space Models (SSM) (Jonsen et al., 2003(Jonsen et al., , 2005 and Brownian Bridge Movement Model (BBMM) (Horne et al., 2007)."",
            ""Nevertheless, these models require heavy computational resources (Patterson et al., 2008) and unrealistic structural a priori hypotheses about movement, such as homogeneous movement behavior."",
            ""A fundamental property of animal movements is behavioral heterogeneity (Gurarie et al., 2009) and these models poorly performed in highlighting behavioral changes in animal movements through space and time (Kranstauber et al., 2012)."",
        ],
    ),
    ("". . ."", ["". . .""]),
    (
        ""IF condition and goalCondition THEN action condition relates to the current state and goalCondition to the goal state. If variable bindings exist such that predicates in condition match with the current state, and predicates in goalCondition match with the goal state then the action may be performed. Note that the action's precondition as specified in the domain model must also be satisfied. Figure 5 presents an outline of the system. Each iteration starts with a population of policies (line(2)). Current L2Plan settings are such that the individuals comprising the (1) Create initial population (2) WHILE termination criterion false (3) Determine n% fittest polices (4) Perform local search on policies (5) Insert improved policies in new generation (6) WHILE new generation not full (7) SET Pol to empty policy (8) Select two parents (9) IF crossover (10) Perform crossover (11) Pol := fittest of parents & offspring (12) ELSE (13) Pol := fittest of parents (14) ENDIF (15) IF mutation (16) Perform mutation on Pol (17) ENDIF (18) Perform local search on Pol (19) Insert Pol in new generation (20) ENDWHILE (21) (5)). Note that the evaluation of policies is implied when the fittest policy or policies is/are required."",
        [
            ""IF condition and goalCondition THEN action condition relates to the current state and goalCondition to the goal state."",
            ""If variable bindings exist such that predicates in condition match with the current state, and predicates in goalCondition match with the goal state then the action may be performed."",
            ""Note that the action's precondition as specified in the domain model must also be satisfied."",
            ""Figure 5 presents an outline of the system."",
            ""Each iteration starts with a population of policies (line(2))."",
            ""Current L2Plan settings are such that the individuals comprising the (1) Create initial population (2) WHILE termination criterion false (3) Determine n% fittest polices (4) Perform local search on policies (5) Insert improved policies in new generation (6) WHILE new generation not full (7) SET Pol to empty policy (8) Select two parents (9) IF crossover (10) Perform crossover (11) Pol := fittest of parents & offspring (12) ELSE (13) Pol := fittest of parents (14) ENDIF (15) IF mutation (16) Perform mutation on Pol (17) ENDIF (18) Perform local search on Pol (19) Insert Pol in new generation (20) ENDWHILE (21) (5))."",
            ""Note that the evaluation of policies is implied when the fittest policy or policies is/are required."",
        ],
    ),
    (
        ""MCC summarizes these four quantities into one score and is regarded as a balanced measure; it takes values between -1 and 1, with higher values indicating better performance (see e.g. Baldi et al. (2000) for further details). Since the convergence threshold in the glasso algorithm is 10 4 , we take entries ij in estimated precision matrices to be non-zero if | ij | > 10 3 . Since cluster assignments can only be identified up to permutation, in all cases labels were permuted to maximize agreement with true cluster assignments before calculating these quantities. Figure 2 shows MCC plotted against per-cluster sample size n k and Supplementary Figure S1 shows corresponding plots for TPR and FPR. Due to selection of smaller tuning parameter values, BIC discovers fewer non-zeroes in the precision matrices than train/test, resulting in both fewer true positives and false positives. Under MCC, BIC, with either the  = 1 mixture model (B1) or the non-mixture approach (Bh), leads to the best network reconstruction (except at small sample sizes with p = 25) and outperforms all other regimes at larger sample sizes."",
        [
            ""MCC summarizes these four quantities into one score and is regarded as a balanced measure; it takes values between -1 and 1, with higher values indicating better performance (see e.g. Baldi et al. (2000) for further details)."",
            ""Since the convergence threshold in the glasso algorithm is 10 4 , we take entries ij in estimated precision matrices to be non-zero if | ij | > 10 3 ."",
            ""Since cluster assignments can only be identified up to permutation, in all cases labels were permuted to maximize agreement with true cluster assignments before calculating these quantities."",
            ""Figure 2 shows MCC plotted against per-cluster sample size n k and Supplementary Figure S1 shows corresponding plots for TPR and FPR."",
            ""Due to selection of smaller tuning parameter values, BIC discovers fewer non-zeroes in the precision matrices than train/test, resulting in both fewer true positives and false positives."",
            ""Under MCC, BIC, with either the  = 1 mixture model (B1) or the non-mixture approach (Bh), leads to the best network reconstruction (except at small sample sizes with p = 25) and outperforms all other regimes at larger sample sizes."",
        ],
    ),
    (
        'Societal impact measurements are mostly commissioned by governments which argue that measuring the impact on science little says about real-world benefits of research (Cohen et al., 2015). Nightingale and Scott (2007) summarize this argumentation in the following pointedly sentence: ""Research that is highly cited or published in top journals may be good for the academic discipline but not for society"" (p. 547). Governments are interested to know the importance of public-funded research (1) for the private and public sectors (e.g. health care), (2) to tackle societal challenges (e.g. climate change), and (3) for education and training of the next generations (ERiC, 2010;Grimson, 2014). The impact model of Cleary, Siegfried, Jackson, and Hunt (2013) additionally highlights the policy enactment of research, in which the impact on policies, laws, and regulations is of special interest. The current study seizes upon this additional issue by investigating a possible source for measuring policy enactment of research.',
        [
            ""Societal impact measurements are mostly commissioned by governments which argue that measuring the impact on science little says about real-world benefits of research (Cohen et al., 2015)."",
            'Nightingale and Scott (2007) summarize this argumentation in the following pointedly sentence: ""Research that is highly cited or published in top journals may be good for the academic discipline but not for society"" (p. 547).',
            ""Governments are interested to know the importance of public-funded research (1) for the private and public sectors (e.g. health care), (2) to tackle societal challenges (e.g. climate change), and (3) for education and training of the next generations (ERiC, 2010;Grimson, 2014)."",
            ""The impact model of Cleary, Siegfried, Jackson, and Hunt (2013) additionally highlights the policy enactment of research, in which the impact on policies, laws, and regulations is of special interest."",
            ""The current study seizes upon this additional issue by investigating a possible source for measuring policy enactment of research."",
        ],
    ),
    (
        ""CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA. Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation."",
        [
            ""CONCLUSIONS: This study demonstrates that TF activation, occurring in mononuclear cells of cardiac transplant recipients, is inhibited by treatment with CsA."",
            ""Inhibition of monocyte TF induction by CsA may contribute to its successful use in cardiac transplant medicine and might be useful in managing further settings of vascular pathology also known to involve TF expression and NF-kappaB activation."",
        ],
    ),
    (
        ""In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun."",
        [
            ""In contrast, anti-AIM mAb did not induce any change in the binding activity of NF-kappa B, a transcription factor whose activity is also regulated by protein kinase C. The increase in AP-1-binding activity was accompanied by the marked stimulation of the transcription of c-fos but not that of c-jun.""
        ],
    ),
    (
        ""A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB. We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site."",
        [
            ""A mutant Tax protein deficient in transactivation of genes by the nuclear factor (NF)-kappaB pathway was unable to induce transcriptional activity of IL-1alpha promoter-CAT constructs, but was rescued by exogenous provision of p65/p50 NF-kappaB."",
            ""We found that two IL-1alpha kappaB-like sites (positions -1,065 to -1,056 and +646 to +655) specifically formed a complex with NF-kappaB-containing nuclear extract from MT-2 cells and that NF-kappaB bound with higher affinity to the 3' NF-kappaB binding site than to the 5' NF-kappaB site."",
        ],
    ),
    pytest.param(
        ""Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B. Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner."",
        [
            ""Protein kinase C inhibitor staurosporine, but not cyclic nucleotide-dependent protein kinase inhibitor HA-1004, also dramatically reduced constitutive levels of nuclear NF kappa B."",
            ""Finally, TPA addition to monocytes infected with HIV-1 inhibited HIV-1 replication, as determined by reverse transcriptase assays, in a concentration-dependent manner."",
        ],
        marks=pytest.mark.xfail,
    ),
    (
        ""There are p50.c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation."",
        [
            ""There are p50.c-rel heterodimers were also detected bound to this sequence at early time points (7-16 h; early), and both remained active at later time points (40 h; late) after activation.""
        ],
    ),
    (
        ""This sentence mentions Eqs. 1-4 and should not be split."",
        [""This sentence mentions Eqs. 1-4 and should not be split.""],
    ),
    (
        ""This sentence ends with part an abbreviation that is part of a word material. It also has another sentence after it."",
        [
            ""This sentence ends with part an abbreviation that is part of a word material."",
            ""It also has another sentence after it."",
        ],
    ),
    (
        ""It also has a sentence before it. This sentence mentions Eqs. 1-4 and should not be split. It also has another sentence after it."",
        [
            ""It also has a sentence before it."",
            ""This sentence mentions Eqs. 1-4 and should not be split."",
            ""It also has another sentence after it."",
        ],
    ),
    (
        ""This sentence is the last segment and ends with an abbreviation that is part of a word material."",
        [
            ""This sentence is the last segment and ends with an abbreviation that is part of a word material.""
        ],
    ),
    (
        ""PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/- 86 pg/ml)."",
        [
            ""PDBu + iono induced equally high IL-2 levels in both groups and, when stimulated with plate-bound anti-CD3 monoclonal antibody (mAb), the IL-2 secretion by neonatal cells was undetectable and adult cells produced low amounts of IL-2 (mean 331 +/- 86 pg/ml).""
        ],
    ),
    (
        ""    This document starts with whitespaces. Next sentence."",
        [""    "", ""This document starts with whitespaces."", ""Next sentence.""],
    ),
    pytest.param(
        ""How about tomorrow?We can meet at eden garden."",
        [""How about tomorrow?"", ""We can meet at eden garden.""],
        marks=pytest.mark.xfail,
    ),
]",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_custom_segmentation.py,python,import,,,,Import: pytest,allenai,scispacy,v0.5.4,import pytest,,pytest,,,,,,,,,,,,,,,
test_custom_segmentation.py,python,,,,,File: tests\custom_tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_custom_segmentation.py,python,,,,,Directory: tests\custom_tests\test_custom_segmentation.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_custom_tokenizer.py,python,constant,"TEST_CASES = [(""using a bag-of-words model"", [""using"", ""a"", ""bag-of-words"", ""model""]),
              (""activators of cAMP- and cGMP-dependent protein"", [""activators"", ""of"", ""cAMP-"", ""and"", ""cGMP-dependent"", ""protein""]),
              (""phorbol 12-myristate 13-acetate, caused almost"", [""phorbol"", ""12-myristate"", ""13-acetate"", "","", ""caused"", ""almost""]),
              pytest.param(""let C(j) denote"", [""let"", ""C(j)"", ""denote""], marks=pytest.mark.xfail),
              pytest.param(""let (C(j)) denote"", [""let"", ""("", ""C(j)"", "")"", ""denote""], marks=pytest.mark.xfail),
              pytest.param(""let C{j} denote"", [""let"", ""C{j}"", ""denote""], marks=pytest.mark.xfail),
              pytest.param(""for the camera(s) and manipulator(s)"", [""for"", ""the"", ""camera(s)"", ""and"", ""manipulator(s)""], marks=pytest.mark.xfail),
              (""the (TRAP)-positive genes"", [""the"", ""(TRAP)-positive"", ""genes""]),
              (""the {TRAP}-positive genes"", [""the"", ""{TRAP}-positive"", ""genes""]),
              (""for [Ca2+]i protein"", [""for"", ""[Ca2+]i"", ""protein""]),
              pytest.param(""for pyrilamine[3H] protein"", [""for"", ""pyrilamine[3H]"", ""protein""], marks=pytest.mark.xfail),
              (""this is (normal) parens"", [""this"", ""is"", ""("", ""normal"", "")"", ""parens""]),
              (""this is [normal] brackets"", [""this"", ""is"", ""["", ""normal"", ""]"", ""brackets""]),
              (""this is {normal} braces"", [""this"", ""is"", ""{"", ""normal"", ""}"", ""braces""]),
              (""in the lan-\nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""in the lan-\n\nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""in the lan- \nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""in the lan- \n\nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""a 28 28 image"", [""a"", ""28"", """", ""28"", ""image""]),
              (""a 2828 image"", [""a"", ""28"", """", ""28"", ""image""]),
              (""a 28  28 image"", [""a"", ""28"", """", ""28"", ""image""]),
              (""the neurons activation"", [""the"", ""neurons"", """", ""activation""]),
              (""the neurons' activation"", [""the"", ""neurons"", ""'"", ""activation""]),
              pytest.param(""H3G 1Y6"", [""H3G"", ""1Y6""], marks=pytest.mark.xfail),
              (""HFG 1Y6"", [""HFG"", ""1Y6""]),
              pytest.param(""H3g 1Y6"", [""H3g"", ""1Y6""], marks=pytest.mark.xfail),
              pytest.param(""h3g 1Y6"", [""h3g"", ""1Y6""], marks=pytest.mark.xfail),
              pytest.param(""h36g 1Y6"", [""h36g"", ""1Y6""], marks=pytest.mark.xfail),
              (""h3gh 1Y6"", [""h3gh"", ""1Y6""]),
              (""h3g3 1Y6"", [""h3g3"", ""1Y6""]),
              (""3g"", [""3"", ""g""]),
              (""(3g)"", [""("", ""3"", ""g"", "")""]),
              (""This can be seen in Figure 1D. Therefore"", [""This"", ""can"", ""be"", ""seen"", ""in"", ""Figure"", ""1D"", ""."", ""Therefore""]),
              (""This can be seen in Figure 1d. Therefore"", [""This"", ""can"", ""be"", ""seen"", ""in"", ""Figure"", ""1d"", ""."", ""Therefore""]),
              (""This is a sentence."", [""This"", ""is"", ""a"", ""sentence"", "".""]),
              (""result of 1.345 is good"", [""result"", ""of"", ""1.345"", ""is"", ""good""]),
              (""This sentence ends with a single 1."", [""This"", ""sentence"", ""ends"", ""with"", ""a"", ""single"", ""1"", "".""]),
              (""This sentence ends with a single 1. This is the next sentence."", [""This"", ""sentence"", ""ends"", ""with"", ""a"", ""single"", ""1"", ""."", ""This"", ""is"", ""the"", ""next"", ""sentence"", "".""]),
              (""sec. secs. Sec. Secs. fig. figs. Fig. Figs. eq. eqs. Eq. Eqs. no. nos. No. Nos. al."", [""sec."", ""secs."", ""Sec."", ""Secs."", ""fig."", ""figs."", ""Fig."", ""Figs."", ""eq."", ""eqs."", ""Eq."", ""Eqs."", ""no."", ""nos."", ""No."", ""Nos."", ""al.""]),
              (""in the Gq/G11 protein"", [""in"", ""the"", ""Gq/G11"", ""protein""]),
              (""in the G1/G11 protein"", [""in"", ""the"", ""G1/G11"", ""protein""]),
              (""in the G1/11 protein"", [""in"", ""the"", ""G1/11"", ""protein""]),
              (""in the Gq/11 protein"", [""in"", ""the"", ""Gq/11"", ""protein""]),
              (""This is a sentence.This is another."", [""This"", ""is"", ""a"", ""sentence"", ""."", ""This"", ""is"", ""another"", "".""]),
              (""This number 1.456 should not be tokenized."", [""This"", ""number"", ""1.456"", ""should"", ""not"", ""be"", ""tokenized"", "".""]),
             ]",TEST_CASES,"[(""using a bag-of-words model"", [""using"", ""a"", ""bag-of-words"", ""model""]),
              (""activators of cAMP- and cGMP-dependent protein"", [""activators"", ""of"", ""cAMP-"", ""and"", ""cGMP-dependent"", ""protein""]),
              (""phorbol 12-myristate 13-acetate, caused almost"", [""phorbol"", ""12-myristate"", ""13-acetate"", "","", ""caused"", ""almost""]),
              pytest.param(""let C(j) denote"", [""let"", ""C(j)"", ""denote""], marks=pytest.mark.xfail),
              pytest.param(""let (C(j)) denote"", [""let"", ""("", ""C(j)"", "")"", ""denote""], marks=pytest.mark.xfail),
              pytest.param(""let C{j} denote"", [""let"", ""C{j}"", ""denote""], marks=pytest.mark.xfail),
              pytest.param(""for the camera(s) and manipulator(s)"", [""for"", ""the"", ""camera(s)"", ""and"", ""manipulator(s)""], marks=pytest.mark.xfail),
              (""the (TRAP)-positive genes"", [""the"", ""(TRAP)-positive"", ""genes""]),
              (""the {TRAP}-positive genes"", [""the"", ""{TRAP}-positive"", ""genes""]),
              (""for [Ca2+]i protein"", [""for"", ""[Ca2+]i"", ""protein""]),
              pytest.param(""for pyrilamine[3H] protein"", [""for"", ""pyrilamine[3H]"", ""protein""], marks=pytest.mark.xfail),
              (""this is (normal) parens"", [""this"", ""is"", ""("", ""normal"", "")"", ""parens""]),
              (""this is [normal] brackets"", [""this"", ""is"", ""["", ""normal"", ""]"", ""brackets""]),
              (""this is {normal} braces"", [""this"", ""is"", ""{"", ""normal"", ""}"", ""braces""]),
              (""in the lan-\nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""in the lan-\n\nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""in the lan- \nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""in the lan- \n\nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""a 28 28 image"", [""a"", ""28"", """", ""28"", ""image""]),
              (""a 2828 image"", [""a"", ""28"", """", ""28"", ""image""]),
              (""a 28  28 image"", [""a"", ""28"", """", ""28"", ""image""]),
              (""the neurons activation"", [""the"", ""neurons"", """", ""activation""]),
              (""the neurons' activation"", [""the"", ""neurons"", ""'"", ""activation""]),
              pytest.param(""H3G 1Y6"", [""H3G"", ""1Y6""], marks=pytest.mark.xfail),
              (""HFG 1Y6"", [""HFG"", ""1Y6""]),
              pytest.param(""H3g 1Y6"", [""H3g"", ""1Y6""], marks=pytest.mark.xfail),
              pytest.param(""h3g 1Y6"", [""h3g"", ""1Y6""], marks=pytest.mark.xfail),
              pytest.param(""h36g 1Y6"", [""h36g"", ""1Y6""], marks=pytest.mark.xfail),
              (""h3gh 1Y6"", [""h3gh"", ""1Y6""]),
              (""h3g3 1Y6"", [""h3g3"", ""1Y6""]),
              (""3g"", [""3"", ""g""]),
              (""(3g)"", [""("", ""3"", ""g"", "")""]),
              (""This can be seen in Figure 1D. Therefore"", [""This"", ""can"", ""be"", ""seen"", ""in"", ""Figure"", ""1D"", ""."", ""Therefore""]),
              (""This can be seen in Figure 1d. Therefore"", [""This"", ""can"", ""be"", ""seen"", ""in"", ""Figure"", ""1d"", ""."", ""Therefore""]),
              (""This is a sentence."", [""This"", ""is"", ""a"", ""sentence"", "".""]),
              (""result of 1.345 is good"", [""result"", ""of"", ""1.345"", ""is"", ""good""]),
              (""This sentence ends with a single 1."", [""This"", ""sentence"", ""ends"", ""with"", ""a"", ""single"", ""1"", "".""]),
              (""This sentence ends with a single 1. This is the next sentence."", [""This"", ""sentence"", ""ends"", ""with"", ""a"", ""single"", ""1"", ""."", ""This"", ""is"", ""the"", ""next"", ""sentence"", "".""]),
              (""sec. secs. Sec. Secs. fig. figs. Fig. Figs. eq. eqs. Eq. Eqs. no. nos. No. Nos. al."", [""sec."", ""secs."", ""Sec."", ""Secs."", ""fig."", ""figs."", ""Fig."", ""Figs."", ""eq."", ""eqs."", ""Eq."", ""Eqs."", ""no."", ""nos."", ""No."", ""Nos."", ""al.""]),
              (""in the Gq/G11 protein"", [""in"", ""the"", ""Gq/G11"", ""protein""]),
              (""in the G1/G11 protein"", [""in"", ""the"", ""G1/G11"", ""protein""]),
              (""in the G1/11 protein"", [""in"", ""the"", ""G1/11"", ""protein""]),
              (""in the Gq/11 protein"", [""in"", ""the"", ""Gq/11"", ""protein""]),
              (""This is a sentence.This is another."", [""This"", ""is"", ""a"", ""sentence"", ""."", ""This"", ""is"", ""another"", "".""]),
              (""This number 1.456 should not be tokenized."", [""This"", ""number"", ""1.456"", ""should"", ""not"", ""be"", ""tokenized"", "".""]),
             ]","Constant: TEST_CASES = [(""using a bag-of-words model"", [""using"", ""a"", ""bag-of-words"", ""model""]),
              (""activators of cAMP- and cGMP-dependent protein"", [""activators"", ""of"", ""cAMP-"", ""and"", ""cGMP-dependent"", ""protein""]),
              (""phorbol 12-myristate 13-acetate, caused almost"", [""phorbol"", ""12-myristate"", ""13-acetate"", "","", ""caused"", ""almost""]),
              pytest.param(""let C(j) denote"", [""let"", ""C(j)"", ""denote""], marks=pytest.mark.xfail),
              pytest.param(""let (C(j)) denote"", [""let"", ""("", ""C(j)"", "")"", ""denote""], marks=pytest.mark.xfail),
              pytest.param(""let C{j} denote"", [""let"", ""C{j}"", ""denote""], marks=pytest.mark.xfail),
              pytest.param(""for the camera(s) and manipulator(s)"", [""for"", ""the"", ""camera(s)"", ""and"", ""manipulator(s)""], marks=pytest.mark.xfail),
              (""the (TRAP)-positive genes"", [""the"", ""(TRAP)-positive"", ""genes""]),
              (""the {TRAP}-positive genes"", [""the"", ""{TRAP}-positive"", ""genes""]),
              (""for [Ca2+]i protein"", [""for"", ""[Ca2+]i"", ""protein""]),
              pytest.param(""for pyrilamine[3H] protein"", [""for"", ""pyrilamine[3H]"", ""protein""], marks=pytest.mark.xfail),
              (""this is (normal) parens"", [""this"", ""is"", ""("", ""normal"", "")"", ""parens""]),
              (""this is [normal] brackets"", [""this"", ""is"", ""["", ""normal"", ""]"", ""brackets""]),
              (""this is {normal} braces"", [""this"", ""is"", ""{"", ""normal"", ""}"", ""braces""]),
              (""in the lan-\nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""in the lan-\n\nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""in the lan- \nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""in the lan- \n\nguage of the"", [""in"", ""the"", ""language"", ""of"", ""the""]),
              (""a 28 28 image"", [""a"", ""28"", """", ""28"", ""image""]),
              (""a 2828 image"", [""a"", ""28"", """", ""28"", ""image""]),
              (""a 28  28 image"", [""a"", ""28"", """", ""28"", ""image""]),
              (""the neurons activation"", [""the"", ""neurons"", """", ""activation""]),
              (""the neurons' activation"", [""the"", ""neurons"", ""'"", ""activation""]),
              pytest.param(""H3G 1Y6"", [""H3G"", ""1Y6""], marks=pytest.mark.xfail),
              (""HFG 1Y6"", [""HFG"", ""1Y6""]),
              pytest.param(""H3g 1Y6"", [""H3g"", ""1Y6""], marks=pytest.mark.xfail),
              pytest.param(""h3g 1Y6"", [""h3g"", ""1Y6""], marks=pytest.mark.xfail),
              pytest.param(""h36g 1Y6"", [""h36g"", ""1Y6""], marks=pytest.mark.xfail),
              (""h3gh 1Y6"", [""h3gh"", ""1Y6""]),
              (""h3g3 1Y6"", [""h3g3"", ""1Y6""]),
              (""3g"", [""3"", ""g""]),
              (""(3g)"", [""("", ""3"", ""g"", "")""]),
              (""This can be seen in Figure 1D. Therefore"", [""This"", ""can"", ""be"", ""seen"", ""in"", ""Figure"", ""1D"", ""."", ""Therefore""]),
              (""This can be seen in Figure 1d. Therefore"", [""This"", ""can"", ""be"", ""seen"", ""in"", ""Figure"", ""1d"", ""."", ""Therefore""]),
              (""This is a sentence."", [""This"", ""is"", ""a"", ""sentence"", "".""]),
              (""result of 1.345 is good"", [""result"", ""of"", ""1.345"", ""is"", ""good""]),
              (""This sentence ends with a single 1."", [""This"", ""sentence"", ""ends"", ""with"", ""a"", ""single"", ""1"", "".""]),
              (""This sentence ends with a single 1. This is the next sentence."", [""This"", ""sentence"", ""ends"", ""with"", ""a"", ""single"", ""1"", ""."", ""This"", ""is"", ""the"", ""next"", ""sentence"", "".""]),
              (""sec. secs. Sec. Secs. fig. figs. Fig. Figs. eq. eqs. Eq. Eqs. no. nos. No. Nos. al."", [""sec."", ""secs."", ""Sec."", ""Secs."", ""fig."", ""figs."", ""Fig."", ""Figs."", ""eq."", ""eqs."", ""Eq."", ""Eqs."", ""no."", ""nos."", ""No."", ""Nos."", ""al.""]),
              (""in the Gq/G11 protein"", [""in"", ""the"", ""Gq/G11"", ""protein""]),
              (""in the G1/G11 protein"", [""in"", ""the"", ""G1/G11"", ""protein""]),
              (""in the G1/11 protein"", [""in"", ""the"", ""G1/11"", ""protein""]),
              (""in the Gq/11 protein"", [""in"", ""the"", ""Gq/11"", ""protein""]),
              (""This is a sentence.This is another."", [""This"", ""is"", ""a"", ""sentence"", ""."", ""This"", ""is"", ""another"", "".""]),
              (""This number 1.456 should not be tokenized."", [""This"", ""number"", ""1.456"", ""should"", ""not"", ""be"", ""tokenized"", "".""]),
             ]",allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_custom_tokenizer.py,python,import,,,,Import: pytest,allenai,scispacy,v0.5.4,import pytest,,pytest,,,,,,,,,,,,,,,
test_custom_tokenizer.py,python,,,,,File: tests\custom_tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_custom_tokenizer.py,python,,,,,Directory: tests\custom_tests\test_custom_tokenizer.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_whitespace.py,python,class_field,,,,"Class field: TestWhitespace.nlp = spacy.load(""en_core_sci_sm"")",allenai,scispacy,v0.5.4,,,,,,,TestWhitespace,,,"nlp = spacy.load(""en_core_sci_sm"")",,,,,nlp,,"spacy.load(""en_core_sci_sm"")",
test_whitespace.py,python,class_method,,,,"Class method: [pytest.mark.parametrize(""text"", [""lorem ipsum""])] TestWhitespace.test_tokenizer_splits_single_space(self, text)",allenai,scispacy,v0.5.4,,,,,,,TestWhitespace,test_tokenizer_splits_single_space,"(self, text)",,,,,,,,,"pytest.mark.parametrize(""text"", [""lorem ipsum""])"
test_whitespace.py,python,class_method,,,,"Class method: [pytest.mark.parametrize(""text"", [""lorem  ipsum""])] TestWhitespace.test_tokenizer_splits_double_space(self, text)",allenai,scispacy,v0.5.4,,,,,,,TestWhitespace,test_tokenizer_splits_double_space,"(self, text)",,,,,,,,,"pytest.mark.parametrize(""text"", [""lorem  ipsum""])"
test_whitespace.py,python,class_method,,,,"Class method: [pytest.mark.parametrize(""text"", [""lorem ipsum  ""])] TestWhitespace.test_tokenizer_handles_double_trainling_ws(self, text)",allenai,scispacy,v0.5.4,,,,,,,TestWhitespace,test_tokenizer_handles_double_trainling_ws,"(self, text)",,,,,,,,,"pytest.mark.parametrize(""text"", [""lorem ipsum  ""])"
test_whitespace.py,python,class_method,,,,"Class method: [pytest.mark.parametrize(""text"", [""lorem\nipsum""])] TestWhitespace.test_tokenizer_splits_newline(self, text)",allenai,scispacy,v0.5.4,,,,,,,TestWhitespace,test_tokenizer_splits_newline,"(self, text)",,,,,,,,,"pytest.mark.parametrize(""text"", [""lorem\nipsum""])"
test_whitespace.py,python,class_method,,,,"Class method: [pytest.mark.parametrize(""text"", [""lorem \nipsum""])] TestWhitespace.test_tokenizer_splits_newline_space(self, text)",allenai,scispacy,v0.5.4,,,,,,,TestWhitespace,test_tokenizer_splits_newline_space,"(self, text)",,,,,,,,,"pytest.mark.parametrize(""text"", [""lorem \nipsum""])"
test_whitespace.py,python,class_method,,,,"Class method: [pytest.mark.parametrize(""text"", [""lorem  \nipsum""])] TestWhitespace.test_tokenizer_splits_newline_double_space(self, text)",allenai,scispacy,v0.5.4,,,,,,,TestWhitespace,test_tokenizer_splits_newline_double_space,"(self, text)",,,,,,,,,"pytest.mark.parametrize(""text"", [""lorem  \nipsum""])"
test_whitespace.py,python,class_method,,,,"Class method: [pytest.mark.parametrize(""text"", [""lorem \n ipsum""])] TestWhitespace.test_tokenizer_splits_newline_space_wrap(self, text)",allenai,scispacy,v0.5.4,,,,,,,TestWhitespace,test_tokenizer_splits_newline_space_wrap,"(self, text)",,,,,,,,,"pytest.mark.parametrize(""text"", [""lorem \n ipsum""])"
test_whitespace.py,python,class,,,,Class: TestWhitespace,allenai,scispacy,v0.5.4,,,,,,,TestWhitespace,,,,,,,,,,,
test_whitespace.py,python,import,,,,Import: pytest,allenai,scispacy,v0.5.4,import pytest,,pytest,,,,,,,,,,,,,,,
test_whitespace.py,python,import,,,,Import: spacy,allenai,scispacy,v0.5.4,import spacy,,spacy,,,,,,,,,,,,,,,
test_whitespace.py,python,local_import,,,,Import: Language from spacy.language,allenai,scispacy,v0.5.4,from spacy.language import Language as SpacyModelType,spacy.language,Language,,,spacy.language,,,,,,,,,,,,
test_whitespace.py,python,local_import,,,,Import: pysbd_sentencizer from scispacy.custom_sentence_segmenter,allenai,scispacy,v0.5.4,from scispacy.custom_sentence_segmenter import pysbd_sentencizer,scispacy.custom_sentence_segmenter,pysbd_sentencizer,,,scispacy.custom_sentence_segmenter,,,,,,,,,,,,
test_whitespace.py,python,,,,,File: tests\custom_tests,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
test_whitespace.py,python,,,,,Directory: tests\custom_tests\test_whitespace.py,allenai,scispacy,v0.5.4,,,,,,,,,,,,,,,,,,
