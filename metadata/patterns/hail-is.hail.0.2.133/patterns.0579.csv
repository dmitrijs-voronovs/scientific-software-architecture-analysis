filename,type,author,repo,version,wiki,url,patterns,purpose,summary
datasets/load/load.GTEx_v7_RNA_seq.py,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/load/load.GTEx_v7_RNA_seq.py,"[{'name': 'MatrixTableImport', 'match_type': 'partial', 'implemented_parts': ['Importing data from tab-separated value files', 'Annotating rows and columns', 'Adding metadata to the imported table'], 'confidence': 0.95, 'evidence': ['import_matrix_table function call', 'row_fields and row_key arguments', 'annotate_rows and annotate_cols methods']}, {'name': 'AnnotationFromExternalSources', 'match_type': 'partial', 'implemented_parts': ['Retrieving gene annotations from external sources', 'Adding annotations as row metadata', 'Handling missing annotations gracefully'], 'confidence': 0.9, 'evidence': ['ht_genes dictionary definition', 'annotate_rows method call with gene_id as key', ""handling of missing values with ' ' (space)""]}]","This code imports junction read counts data from a TSV file, annotates rows and columns, and adds metadata to the resulting matrix table.","{'constants': ['Reference genome and build information'], 'types': ['MatrixTable object'], 'classes': ['Junction read counts data structure'], 'functions': ['Importing and manipulating data from external files']}"
datasets/load/load.LDSC_baselineLD_v2.2_annotations.GRCh37.py,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/load/load.LDSC_baselineLD_v2.2_annotations.GRCh37.py,"[{'name': 'DataImport', 'match_type': 'partial', 'implemented_parts': ['table import', 'annotation processing'], 'confidence': 0.9, 'evidence': ['import_table function', 'annotate_globals method', 'locus annotation']}, {'name': 'DataManipulation', 'match_type': 'partial', 'implemented_parts': ['column dropping', 'key transformation'], 'confidence': 0.8, 'evidence': ['drop function', 'key_by method']}]",This file imports genomic data from a TSV file and adds annotations to it.,"{'constants': ['Defines paths to datasets'], 'types': ['Table type for genomic data'], 'classes': ['None'], 'functions': ['Import data from external source', 'Add annotations to existing data']}"
datasets/load/load.LDSC_baselineLD_v2.2_ld_scores.GRCh37.py,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/load/load.LDSC_baselineLD_v2.2_ld_scores.GRCh37.py,"[{'name': 'Importing and Annotating LD Scores', 'match_type': 'partial', 'implemented_parts': ['Importing data from CSV files', 'Annotating rows with locus information', 'Annotating entries with x values'], 'confidence': 0.95, 'evidence': ['use of hl.import_matrix_table function', 'locus creation from Chr and BP fields', 'use of annotate_entries function']}, {'name': 'Joining with Annotation Tables', 'match_type': 'partial', 'implemented_parts': ['Importing two annotation tables', 'Joining with the main table on annotation field', 'Annotating with M and M_5_50 values'], 'confidence': 0.9, 'evidence': ['use of hl.import_table function', 'join on the annotation field', 'use of annotate_cols function']}, {'name': 'Writing to Hail Table', 'match_type': 'partial', 'implemented_parts': ['Adding metadata and writing to Hail table'], 'confidence': 0.85, 'evidence': ['use of annotate_globals function', 'writing to specified Hail table location']}]","This Hail script imports LD scores, annotates them with additional information, and joins them with two annotation tables.","{'constants': ['GRCh37 reference genome'], 'types': ['Hail data structures for matrix and annotations'], 'classes': ['None'], 'functions': ['Hail functions for importing, annotating, and writing data']}"
datasets/load/load.LDSC_baselineLD_v2.2_ld_scores.py,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/load/load.LDSC_baselineLD_v2.2_ld_scores.py,"[{'name': 'Iterator', 'match_type': 'partial', 'implemented_parts': ['iterates over elements', 'accepts elements as input'], 'confidence': 0.9, 'evidence': ['for loop', 'element argument in methods']}, {'name': 'StatefulObject', 'match_type': 'partial', 'implemented_parts': ['stores state', 'updates state during iteration'], 'confidence': 0.8, 'evidence': ['locus variable', 'annotated values based on locus']}]",This file loads and annotates LDSC baseline genotype-level scores.,"{'constants': ['Dataset paths'], 'types': ['Table type for genotype data'], 'classes': ['Hail table manipulation functions'], 'functions': ['import_table', 'annotate', 'drop', 'key_by', 'write']}"
datasets/load/load.LDSC_baseline_v1.1_bed_files.py,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/load/load.LDSC_baseline_v1.1_bed_files.py,"[{'name': 'Validation of locus interval', 'match_type': 'partial', 'implemented_parts': ['Start and end validation', 'Inclusion of start/end within interval', 'Reference genome compatibility'], 'confidence': 0.9, 'evidence': ['`start_locus` function checks interval boundaries', '`hl.bool` operator evaluates interval inclusion criteria', 'Reference genome is specified in the function call']}, {'name': 'Annotation of locus intervals', 'match_type': 'full', 'implemented_parts': ['Annotates intervals with user-defined annotations', 'Imputes missing values', 'Handles interval overlap and reference genome compatibility'], 'confidence': 1.0, 'evidence': ['`annotate` function takes interval and annotation as input', '`include_start` and `include_end` flags control inclusion boundaries', 'Reference genome is explicitly specified in the function call']}]",This code performs validation and annotation of locus intervals based on user-defined annotations.,"{'constants': ['Defines constants for interval validation'], 'types': ['Custom types for locus intervals and annotations'], 'classes': ['Functions for validating and annotating intervals'], 'functions': ['Validation and annotation functions']}"
datasets/load/load.LDSC_baseline_v1.1_ld_scores.GRCh37.py,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/load/load.LDSC_baseline_v1.1_ld_scores.GRCh37.py,"[{'name': 'Import and Annotate LDSC Scores', 'match_type': 'partial', 'implemented_parts': ['Importing LDSC scores from a TSV file', 'Annotating entries with x values', 'Annotating rows with locus information'], 'confidence': 0.9, 'evidence': ['ImportingMatrixTable function call', 'annotate_entries method call with x value', 'annotate_rows method call with locus information']}, {'name': 'Joining with M Table', 'match_type': 'partial', 'implemented_parts': ['Importing M table from a TSV file', 'Joining LDSC scores with M table based on annotation', 'Annotating rows with additional scores'], 'confidence': 0.85, 'evidence': ['ImportingTable function call', 'Joining on annotation key', 'Annotating rows with imported values']}, {'name': 'Metadata Annotations', 'match_type': 'partial', 'implemented_parts': ['Calculating row and column counts', 'Annotating metadata with file information'], 'confidence': 0.95, 'evidence': ['Count methods call', 'AnnotateGlobals function call with metadata']}]",This Hail script imports LDSC baseline v1.1 allele-level scores and joins them with the M table of genetic annotations.,"{'constants': ['Reference genome: GRCh37'], 'types': ['Custom types for LDSC scores and annotations'], 'classes': ['Hail data structures for storing LDSC scores and annotations'], 'functions': ['Importing and annotating data functions']}"
datasets/load/load.UK_Biobank_Rapid_GWAS.py,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/load/load.UK_Biobank_Rapid_GWAS.py,"[{'name': 'Data Loader', 'match_type': 'partial', 'implemented_parts': ['Reads data from a GCS location', 'Creates a Hail MatrixTable object', 'Adds metadata annotations'], 'confidence': 0.95, 'evidence': ['gs://hail-datasets-raw-data/UK_Biobank_Rapid_GWAS', 'read_matrix_table function', 'annotate_globals method']}, {'name': 'Data Saver', 'match_type': 'partial', 'implemented_parts': ['Writes MatrixTable data to a GCS location', 'Reads the saved data back into a Hail MatrixTable object'], 'confidence': 0.9, 'evidence': ['gs://hail-datasets-hail-data', 'write function', 'read_matrix_table function']}]",This file loads UK Biobank Rapid GWAS dataset into Hail and saves it to a specific location.,"{'constants': ['Data roots'], 'types': ['MatrixTable'], 'classes': [], 'functions': ['read_matrix_table', 'write']}"
datasets/load,FileType.DIR,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/load,"[{'name': 'Data Loader', 'match_type': 'partial', 'implemented_parts': ['Reads data from a GCS location', 'Creates a Hail MatrixTable object', 'Adds metadata annotations'], 'confidence': 0.95, 'evidence': ['gs://hail-datasets-raw-data/UK_Biobank_Rapid_GWAS', 'read_matrix_table function', 'annotate_globals method']}, {'name': 'Data Saver', 'match_type': 'partial', 'implemented_parts': ['Writes MatrixTable data to a GCS location', 'Reads the saved data back into a Hail MatrixTable object'], 'confidence': 0.9, 'evidence': ['gs://hail-datasets-hail-data', 'write function', 'read_matrix_table function']}, {'name': 'Metadata Annotations', 'match_type': 'partial', 'implemented_parts': ['Calculating row and column counts', 'Annotating metadata with file information'], 'confidence': 0.95, 'evidence': ['Count methods call', 'AnnotateGlobals function call with metadata']}, {'name': 'Annotating Rows', 'match_type': 'partial', 'implemented_parts': ['ImportingTable function call', 'Joining on annotation key', 'Annotating rows with imported values'], 'confidence': 0.85, 'evidence': ['ImportingTable function call', 'Joining on annotation key', 'Annotating rows with imported values']}]",This Hail script imports LDSC baseline v1.1 allele-level scores and joins them with the M table of genetic annotations.,"{'constants': ['Reference genome: GRCh37'], 'types': ['Custom types for LDSC scores and annotations'], 'classes': ['Hail data structures for storing LDSC scores and annotations'], 'functions': ['Importing and annotating data functions']}"
datasets/notebooks/1kg_NYGC_30x_datasets.ipynb,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/1kg_NYGC_30x_datasets.ipynb,"[{'name': 'Code block analysis', 'match_type': 'full', 'implemented_parts': ['Schema extraction', 'Context analysis'], 'confidence': 0.95, 'evidence': ['code-block syntax', 'schema definition']}, {'name': 'Schema introspection', 'match_type': 'partial', 'implemented_parts': ['Schema field extraction', 'Type inference'], 'confidence': 0.85, 'evidence': ['field names', 'data types']}]",This code block analyzes the schema of a dataset to extract relevant information.,"{'constants': ['Dataset-related constants'], 'types': ['Schema data types'], 'classes': ['Schema class represents dataset structure'], 'functions': ['Schema introspection methods']}"
datasets/notebooks/CADD_datasets.ipynb,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/CADD_datasets.ipynb,[],"Reads and describes two Hail tables, one for GRCh37 and one for GRCh38.","{'functions': ['Reads Hail tables', 'Describes table metadata', 'Prints table descriptions'], 'data_structures': ['Hail tables']}"
datasets/notebooks/dbSNP_datasets.ipynb,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/dbSNP_datasets.ipynb,"[{'name': 'Caching', 'match_type': 'partial', 'implemented_parts': ['Cache object', 'get method', 'update method'], 'confidence': 0.9, 'evidence': ['cache object initialized with data', 'get method retrieves cached data', 'update method modifies cached data']}, {'name': 'Serialization', 'match_type': 'full', 'implemented_parts': ['Serialization and deserialization functions'], 'confidence': 1.0, 'evidence': ['data converted to string before storage', 'data retrieved from string after storage']}]",This file implements a caching system for efficient data retrieval.,"{'constants': ['Defines caching-related constants'], 'types': ['Cache object'], 'classes': ['Cache class handles caching logic'], 'functions': ['Serialize and deserialize data for caching']}"
datasets/notebooks/GENCODE.ipynb,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/GENCODE.ipynb,"[{'name': 'Data import', 'match_type': 'partial', 'implemented_parts': ['Downloading and reading annotations from S3'], 'confidence': 0.95, 'evidence': ['gs://hail-datasets-us/GENCODE/v35/GRCh38/annotation.ht', 'spark_conf authentication']}, {'name': 'Data transformation', 'match_type': 'partial', 'implemented_parts': ['Writing annotations to a different S3 location'], 'confidence': 0.85, 'evidence': ['s3a://hail-datasets-us-east-1/GENCODE/v35/GRCh38/annotation.ht']}]","This code snippet downloads genomic annotations from S3, performs some transformations, and writes them back to a different location in S3.","{'constants': ['S3 paths for annotations'], 'types': ['Spark DataFrame for annotations'], 'classes': ['SparkSession for interacting with Spark'], 'functions': ['read_table', 'write']}"
datasets/notebooks/giant_datasets.ipynb,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/giant_datasets.ipynb,"[{'name': 'Schema Definition', 'match_type': 'partial', 'implemented_parts': ['Dataset Context', 'Version and Reference Genome Management', 'Schema Description Indentation'], 'confidence': 0.9, 'evidence': ['name variable assigned to dataset', 'loop iterating over versions and reference genomes', 'description text wrapped with indentation']}]",This code defines a schema for a dataset.,"{'constants': [], 'types': [], 'classes': [], 'functions': []}"
datasets/notebooks/GTEx_MatrixTables.ipynb,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/GTEx_MatrixTables.ipynb,"[{'name': 'Variant Annotation Dataset', 'match_type': 'full', 'implemented_parts': ['Column handling', 'Row handling', 'Entry handling', 'Indexing'], 'confidence': 1.0, 'evidence': ['Data structure definition with column, row, and entry fields', 'Column key and row key definitions', ""Indexing of column 'tissue'""]}]",This dataset stores variant annotations derived from multiple samples.,"{'constants': [], 'types': [], 'classes': [], 'functions': []}"
datasets/notebooks/GTEx_Tables.ipynb,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/GTEx_Tables.ipynb,"[{'name': 'Code Block Schema', 'match_type': 'full', 'implemented_parts': ['Dataset context', 'Schema definition', 'Output generation'], 'confidence': 1.0, 'evidence': ['dataset name extraction', 'schema indentation', 'output file generation']}]",This code defines a schema for generating documentation from code blocks.,"{'constants': [], 'types': [], 'classes': [], 'functions': []}"
datasets/notebooks/reformat_buckets.ipynb,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/reformat_buckets.ipynb,"[{'name': 'URL Retrieval', 'match_type': 'full', 'implemented_parts': ['Version parsing', 'URL retrieval based on platform'], 'confidence': 1.0, 'evidence': [""version['url'] dictionary extraction"", 'platform-specific URL handling']}, {'name': 'Data Reading', 'match_type': 'full', 'implemented_parts': ['Table reading', 'Matrix table reading', 'Block matrix reading'], 'confidence': 0.95, 'evidence': ['Conditional reading based on file extension', 'Specific methods for different data formats']}]",This code fetches and reads data from different sources based on the platform and file format.,"{'constants': ['Platform-specific URLs'], 'types': ['Data structures for different formats'], 'classes': [], 'functions': ['read_table', 'read_matrix_table', 'linalg.BlockMatrix.read']}"
datasets/notebooks/reformat_buckets.txt,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/reformat_buckets.txt,"[{'name': 'CTSA Variant Annotation', 'match_type': 'partial', 'implemented_parts': ['Annotation of ClinVar variants', 'Integration of gene-specific summaries', 'Fetching of GENCODE annotations'], 'confidence': 0.95, 'evidence': ['gsutil command for ClinVar annotations', 'gsutil command for gene-specific summaries', 'gsutil command for GENCODE annotations']}]",This code fetches and integrates variant annotations from multiple sources.,"{'constants': ['Base URLs for datasets'], 'types': ['Variant annotations', 'Gene summaries', 'Gene annotations'], 'classes': ['Annotation loader', 'Variant annoter'], 'functions': ['Load annotations from various sources', 'Annotate variants based on criteria']}"
datasets/notebooks/reformat_buckets_mappings.json,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks/reformat_buckets_mappings.json,"[{'name': 'Giant W-All Dataset', 'match_type': 'full', 'implemented_parts': ['Dataset loading and preprocessing for W-ALL samples'], 'confidence': 1.0, 'evidence': ['Dataset paths for W-ALL exome data', 'Loading and processing methods']}, {'name': 'Variant Annotation', 'match_type': 'partial', 'implemented_parts': ['LoF metrics calculation', 'Variant summarization'], 'confidence': 0.9, 'evidence': ['Gnomad v2.1.1 LOF metrics', 'ClinVar variant summaries']}]",This file contains datasets and annotations for Giant W-ALL exome sequencing data.,"{'constants': ['Defined constants for dataset paths'], 'types': ['Variants in GRCh37 and GRCh38'], 'classes': ['Variant annotations'], 'functions': ['Loading and processing datasets', 'Calculating LoF metrics']}"
datasets/notebooks,FileType.DIR,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/notebooks,"[{'name': 'CTSA Variant Annotation', 'match_type': 'partial', 'implemented_parts': ['Annotation of ClinVar variants', 'Integration of gene-specific summaries', 'Fetching of GENCODE annotations'], 'confidence': 0.95, 'evidence': ['gsutil command for ClinVar annotations', 'gsutil command for gene-specific summaries', 'gsutil command for GENCODE annotations']}, {'name': 'Giant W-All Dataset', 'match_type': 'full', 'implemented_parts': ['Dataset loading and preprocessing for W-ALL samples'], 'confidence': 1.0, 'evidence': ['Dataset paths for W-ALL exome data', 'Loading and processing methods']}, {'name': 'Variant Annotation', 'match_type': 'partial', 'implemented_parts': ['LoF metrics calculation', 'Variant summarization'], 'confidence': 0.9, 'evidence': ['Gnomad v2.1.1 LOF metrics', 'ClinVar variant summaries']}]",This code fetches and integrates variant annotations from multiple sources.,"{'constants': ['Base URLs for datasets'], 'types': ['Variant annotations', 'Gene summaries', 'Gene annotations'], 'classes': ['Annotation loader', 'Variant annoter'], 'functions': ['Load annotations from various sources', 'Annotate variants based on criteria']}"
datasets/annotation_ui.json,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/annotation_ui.json,[],This dataset contains various genomics and clinical data related to UK Biobank participants.,"{'datasets': [{'name': 'UK_Biobank_Rapid_GWAS_both_sexes', 'description': 'Rapid GWAS data for both sexes'}, {'name': 'GTEx_RNA_seq_junction_read_counts', 'description': 'Junction read counts from RNA-seq data from the GTEx project'}, {'name': 'Ensembl_homo_sapiens_reference_genome', 'description': 'Homo sapiens reference genome from Ensembl'}, {'name': 'Ensembl_homo_sapiens_low_complexity_regions', 'description': 'Low-complexity regions of the human genome from Ensembl'}, {'name': 'gencode', 'description': 'Gene annotations from Gencode'}, {'name': 'gnomad', 'description': 'Variants from the Genome Aggregation Database of Mutations'}]}"
