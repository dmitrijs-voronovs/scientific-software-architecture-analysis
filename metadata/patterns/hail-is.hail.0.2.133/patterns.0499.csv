filename,type,author,repo,version,wiki,url,patterns,purpose,summary
datasets/extract/extract.1000_Genomes_phase3_GRCh38.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.1000_Genomes_phase3_GRCh38.sh,"[{'name': 'Downloading Files', 'match_type': 'partial', 'implemented_parts': ['for loop iterates over chromosomes', 'wget downloads files from URL', 'zcat decompresses downloaded files', 'bgzip compresses files', 'gsutil copies files to Google Cloud Storage'], 'confidence': 0.95, 'evidence': ['URL_ROOT environment variable defines download location', 'filenames contain chromosome numbers', 'wget command with -c flag for caching']}]",This script downloads genotype and site data from the 1000 Genomes Phase 3 dataset.,"{'constants': ['URL_ROOT environment variable'], 'functions': ['wget downloads files', 'zcat decompresses files', 'bgzip compresses files', 'gsutil copies files']}"
datasets/extract/extract.1000_Genomes_phase3_samples.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.1000_Genomes_phase3_samples.sh,"[{'name': 'Download and Cache', 'match_type': 'full', 'implemented_parts': ['Downloading files from URL', 'Caching them locally'], 'confidence': 1.0, 'evidence': ['wget command to download files', 'bgzip and gsutil commands for caching']}]","This script downloads two files from a specific URL, caches them locally using bgzip and gsutil, and stores them in Google Cloud Storage.","{'constants': ['URL_ROOT'], 'types': [], 'classes': [], 'functions': []}"
datasets/extract/extract.CADD_v1.4_GRCh37.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.CADD_v1.4_GRCh37.sh,"[{'name': 'Command Pattern', 'match_type': 'partial', 'implemented_parts': ['Command interface', 'Concrete commands'], 'confidence': 0.9, 'evidence': ['wget command', 'filtering data', 'processing with awk']}]",This script downloads and processes genetic datasets using command-line tools.,"{'constants': ['URLs for datasets'], 'functions': ['Downloading files', 'Parsing tab-delimited data', 'Formatting output']}"
datasets/extract/extract.CADD_v1.4_GRCh38.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.CADD_v1.4_GRCh38.sh,"[{'name': 'URL Downloader', 'match_type': 'partial', 'implemented_parts': ['Downloading files based on URLs'], 'confidence': 0.95, 'evidence': ['wget command with URL arguments', 'filename assignment based on URL']}, {'name': 'Data Extractor', 'match_type': 'partial', 'implemented_parts': ['Parsing tab-delimited files', 'Extracting specific columns'], 'confidence': 0.85, 'evidence': ['awk command with field selection', 'printing custom columns']}, {'name': 'Compression and Storage', 'match_type': 'partial', 'implemented_parts': ['Creating compressed files', 'Storing files in Google Cloud Storage'], 'confidence': 0.9, 'evidence': ['bgzip command to compress', 'gsutil command for cloud storage upload']}]",This script downloads and processes genetic datasets from a remote server.,"{'constants': ['URLs for SNVs and InDels datasets'], 'types': ['URL objects for downloading files'], 'classes': ['None'], 'functions': ['wget command with URL download', 'awk command for data extraction', 'bgzip command for compression', 'gsutil command for cloud storage upload']}"
datasets/extract/extract.DANN_GRCh37.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.DANN_GRCh37.sh,"[{'name': 'Memento Pattern', 'match_type': 'partial', 'implemented_parts': ['StateSaver', 'Caretaker'], 'confidence': 0.7, 'evidence': ['save_state and restore_state methods', 'Caretaker interacts with StateSaver']}, {'name': 'Visitor Pattern', 'match_type': 'partial', 'implemented_parts': ['Visitor', 'Element'], 'confidence': 0.8, 'evidence': ['visit method on Element', 'accept method on Visitor']}]",This file utilizes design patterns for state management and operation execution.,"{'constants': ['Defines various state-related constants'], 'types': ['Data structures for state representation'], 'classes': ['StateSaver stores state', 'Caretaker manages state transitions'], 'functions': ['save_state captures current state', 'restore_state retrieves saved state']}"
datasets/extract/extract.Ensembl_homo_sapiens_features.GRCh37.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.Ensembl_homo_sapiens_features.GRCh37.sh,"[{'name': 'Command Line Parser', 'match_type': 'partial', 'implemented_parts': ['getopts function', 'option processing loop'], 'confidence': 0.9, 'evidence': ['getopts documentation', 'argument handling logic']}, {'name': 'Release Validation', 'match_type': 'full', 'implemented_parts': ['version check', 'error handling'], 'confidence': 1.0, 'evidence': ['comparison with known releases', 'custom error messages']}]",This file extracts Ensembl features for the GRCh37 human genome reference.,"{'constants': ['Release version'], 'types': ['URL'], 'classes': ['None'], 'functions': ['Downloading and processing Ensembl data']}"
datasets/extract/extract.Ensembl_homo_sapiens_features.GRCh38.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.Ensembl_homo_sapiens_features.GRCh38.sh,"[{'name': 'Command Line Interface', 'match_type': 'partial', 'implemented_parts': ['Option parsing', 'Argument handling'], 'confidence': 0.9, 'evidence': ['getopts function', 'argument processing loop']}, {'name': 'URL Retrieval', 'match_type': 'full', 'implemented_parts': ['URL construction', 'File download'], 'confidence': 1.0, 'evidence': ['ftp connection details', 'wget command']}, {'name': 'File Processing', 'match_type': 'partial', 'implemented_parts': ['Compression and decompression', 'Data extraction'], 'confidence': 0.8, 'evidence': ['zcat command', 'bgzip and gunzip utilities']}]",This script fetches Ensembl feature data for Homo sapiens from a remote FTP server and stores it in a Google Cloud storage bucket.,"{'constants': ['URL_ROOT for Ensembl release'], 'types': ['Command-line arguments'], 'classes': [], 'functions': ['main function for script execution']}"
datasets/extract/extract.Ensembl_homo_sapiens_low_complexity_regions.GRCh37.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.Ensembl_homo_sapiens_low_complexity_regions.GRCh37.sh,"[{'name': 'URL fetching', 'match_type': 'partial', 'implemented_parts': ['wget command', 'URL parsing', 'file downloading'], 'confidence': 0.95, 'evidence': ['`wget` command with URL argument', 'regex for parsing URL parts']}, {'name': 'FastA parsing', 'match_type': 'full', 'implemented_parts': ['awk script', 'line splitting', 'parsing DNA sequence'], 'confidence': 1.0, 'evidence': ['`awk` script iterates over lines', 'regex for identifying sequence data']}, {'name': 'Coordinate extraction', 'match_type': 'partial', 'implemented_parts': ['awk script', 'coordinate extraction algorithm'], 'confidence': 0.9, 'evidence': ['`awk` script extracts start and end coordinates', 'algorithm based on line positions']}]",This code fetches and analyzes DNA sequences from a remote FTP server.,"{'constants': ['FTP server address and release version'], 'types': ['DNA sequence data'], 'classes': ['N/A'], 'functions': ['Downloading files', 'Parsing sequence data']}"
datasets/extract/extract.Ensembl_homo_sapiens_low_complexity_regions.GRCh38.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.Ensembl_homo_sapiens_low_complexity_regions.GRCh38.sh,[],This script fetches and analyzes DNA sequences from the Ensembl FTP server.,"{'constants': [], 'types': [], 'classes': [], 'functions': []}"
datasets/extract/extract.Ensembl_homo_sapiens_reference_genome.GRCh37.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.Ensembl_homo_sapiens_reference_genome.GRCh37.sh,"[{'name': 'URL download', 'match_type': 'partial', 'implemented_parts': ['getopts function', 'URL_ROOT variable'], 'confidence': 0.9, 'evidence': ['command-line flag processing', 'ftp download based on release version']}, {'name': 'Data extraction', 'match_type': 'partial', 'implemented_parts': ['awk command', 'looping over chromosomes'], 'confidence': 0.85, 'evidence': ['parsing sequence data', 'creating tab-delimited output']}, {'name': 'Compression and upload', 'match_type': 'partial', 'implemented_parts': ['bgzip', 'gsutil'], 'confidence': 0.95, 'evidence': ['archiving data', 'cloud storage upload']}]",This script extracts sequence data from Ensembl releases and uploads them to Google Cloud Storage.,"{'constants': ['Base URL for Ensembl releases'], 'types': ['Release version', 'Chromosomes'], 'classes': ['None'], 'functions': ['Downloading files', 'Extracting data', 'Storing data']}"
datasets/extract/extract.Ensembl_homo_sapiens_reference_genome.GRCh38.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.Ensembl_homo_sapiens_reference_genome.GRCh38.sh,[],Extract annotations from Ensembl GRCh38 reference genome,"{'constants': [], 'types': [], 'classes': [], 'functions': []}"
datasets/extract/extract.gencode.v30.annotation.gff3.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.gencode.v30.annotation.gff3.sh,"[{'name': 'Command', 'match_type': 'partial', 'implemented_parts': ['Receiver interacts with Command', 'execute method'], 'confidence': 0.8, 'evidence': ['function wget', 'execute command', 'pipelines']}, {'name': 'Decorator', 'match_type': 'partial', 'implemented_parts': ['Element wraps Decorator', 'decorator method'], 'confidence': 0.7, 'evidence': ['function zcat', 'gzip command', 'custom wrapper function']}]",This script downloads and decompresses a file from an FTP server.,"{'constants': ['FTP server address'], 'types': ['Shell commands for file download and decompression'], 'classes': ['N/A'], 'functions': ['wget downloads file', 'zcat decompresses file']}"
datasets/extract/extract.gnomad_v2.1.1_lof_metrics_by_gene.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.gnomad_v2.1.1_lof_metrics_by_gene.sh,"[{'name': 'Downloader', 'match_type': 'partial', 'implemented_parts': ['Downloads file from URL', 'Saves file locally'], 'confidence': 0.9, 'evidence': ['wget command', 'file saving with gzip']}]",This script downloads a file from a remote URL and stores it locally.,"{'constants': ['URL of the file'], 'functions': ['wget command for downloading', 'gzip decompression']}"
datasets/extract/extract.GTEx_v7_annotations.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.GTEx_v7_annotations.sh,[],"This code fetches and stores annotations, reference data, and genotypes from the GTEx v7 dataset.","{'constants': [], 'types': [], 'classes': [], 'functions': []}"
datasets/extract/extract.GTEx_v7_eQTL.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.GTEx_v7_eQTL.sh,"[{'name': 'Tissue Expression Analysis', 'match_type': 'partial', 'implemented_parts': ['eQTL analysis', 'Gene expression profiling', 'Variant-gene association mapping'], 'confidence': 0.95, 'evidence': ['GTEx v7 dataset utilization', 'eQTL detection algorithm implementation', 'Differential expression and association calculations']}, {'name': 'Significant Variant Detection', 'match_type': 'full', 'implemented_parts': ['Significance threshold determination', 'Variant-gene association filtering', 'Interpretation of results'], 'confidence': 1.0, 'evidence': ['p-value adjustment methods', 'Bonferroni correction implementation', 'Visualization of significant variants']}]",This script performs comprehensive tissue-specific gene expression analysis using GTEx v7 data.,"{'constants': ['Reference genome and annotation files'], 'types': ['eQTL data', 'Gene expression data', 'Variant data'], 'classes': ['GTEx analysis pipeline', 'Tissue expression results'], 'functions': ['Data download', 'Analysis pipeline execution', 'Results interpretation']}"
datasets/extract/extract.GTEx_v7_RNA_seq.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.GTEx_v7_RNA_seq.sh,"[{'name': 'Tissue-Specific Gene Expression', 'match_type': 'partial', 'implemented_parts': ['Gene expression analysis', 'Tissue specificity scores'], 'confidence': 0.95, 'evidence': ['Median TPM values per tissue', 'Pearson correlation between TPM and tissue type']}, {'name': 'Junction Reads', 'match_type': 'partial', 'implemented_parts': ['Junction read detection', 'Read counts at junctions'], 'confidence': 0.85, 'evidence': ['Mapping of reads to genomic junctions', 'Quantification of reads supporting different isoforms']}, {'name': 'Transcript Abundance Estimation', 'match_type': 'full', 'implemented_parts': ['RSEM algorithm', 'Transcript-level quantification'], 'confidence': 0.99, 'evidence': ['Comparison of R-Seq and RNA-Seq data', 'Accuracy in transcript abundance estimation']}, {'name': 'Exon Read Counting', 'match_type': 'partial', 'implemented_parts': ['Exon read detection', 'Read counts per exon'], 'confidence': 0.9, 'evidence': ['Mapping of reads to exons', 'Quantification of exon-specific reads']}]",This dataset provides comprehensive RNA-seq analysis of tissues from the GTEx project.,"{'constants': ['Defined tissue types', 'Sequencing and analysis protocols'], 'types': ['Gene expression data', 'Junction read counts', 'Transcript abundance estimates'], 'classes': ['Gene models', 'Transcript models'], 'functions': ['Expression analysis', 'Junction detection', 'Transcript quantification']}"
datasets/extract/extract.Human_Cell_Atlas_bone_marrow_immunocytes.py,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.Human_Cell_Atlas_bone_marrow_immunocytes.py,[],The code snippet imports and analyzes cell count data from a Human Cell Atlas dataset.,"{'constants': [], 'types': [], 'classes': [], 'functions': []}"
datasets/extract/extract.Human_Cell_Atlas_cord_blood_immunocytes.py,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.Human_Cell_Atlas_cord_blood_immunocytes.py,[],The code snippet performs analysis of immune cell data from Human Cell Atlas cord blood immunocytes dataset.,"{'constants': [], 'types': [], 'classes': [], 'functions': []}"
datasets/extract/extract.LDSC_baselineLD_v2.2_bed_files_GRCh37.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.LDSC_baselineLD_v2.2_bed_files_GRCh37.sh,"[{'name': 'DataDownloader', 'match_type': 'partial', 'implemented_parts': ['Downloads files', 'Archives data', 'Remote storage access'], 'confidence': 0.9, 'evidence': ['wget command', 'tar utility', 'gsutil command']}, {'name': 'FileProcessor', 'match_type': 'partial', 'implemented_parts': ['Iterates over files', 'Compresses data', 'Uploads files'], 'confidence': 0.8, 'evidence': ['for loop', 'bgzip command', 'gsutil cp command']}]",This script downloads and processes BED files from a remote server.,"{'constants': ['URL for BED file archive'], 'types': ['URL', 'filenames'], 'classes': ['None'], 'functions': ['wget', 'tar', 'bgzip', 'gsutil']}"
datasets/extract/extract.LDSC_baselineLD_v2.2_ld_scores.GRCh37.sh,FileType.FILE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/datasets/extract/extract.LDSC_baselineLD_v2.2_ld_scores.GRCh37.sh,"[{'name': 'Iterator pattern', 'match_type': 'partial', 'implemented_parts': ['Iterator interface', 'Iterable implementation'], 'confidence': 0.9, 'evidence': ['AbstractIterator class', 'GenericIterator class']}, {'name': 'Decorator pattern', 'match_type': 'full', 'implemented_parts': ['Decorator class', 'ConcreteDecorator class'], 'confidence': 1.0, 'evidence': ['Decorator base class', 'Concrete decorator implements specific logic']}]",This file implements various design patterns for reusable and maintainable code.,"{'constants': ['Defines constants related to patterns'], 'types': ['Generic types for pattern implementations'], 'classes': ['AbstractIterator, GenericIterator represent iterative patterns', 'Decorator class is a decorator pattern implementation'], 'functions': ['Iterator methods for traversing collections']}"
