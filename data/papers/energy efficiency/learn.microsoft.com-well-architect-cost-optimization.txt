Recommendations for aligning billing and usage - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for aligning usage to billing increments
Article
2023-11-15
5 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:06
Align usage to billing increments. You should understand billing increments (meters) and align resource usage to those increments. Modify the service to align with billing increments, or modify resource usage to align with billing increments. Consider using a proof of concept to validate billing knowledge and design choices for major cost drivers and to reveal ways to align billing and resource usage.
This guide describes the recommendations for aligning resource usage to billing increments. Resources are billed at specific increments, such as per hour or per instance. To optimize costs, you need to align your usage to those increments. You must either adapt a resource to your workload usage or adapt your workload to the resource billing increments, also called
meters
. Implement the following guidance so you can ensure that your workload derives the maximum value from each resource. If you fail to align billing and design, you might incur unnecessary charges.
Definitions
Term
Definition
Billing increment
A usage amount that incurs a cost (
meter
), such as a unit of time, number of instances, or size of data.
Billing factor
The type of usage that incurs costs, such as time, storage amount, data transfer amount, or number of requests.
Key design strategies
Aligning resource usage to billing increments is about making sure that your resource consumption closely matches the intervals or quantities that you're charged for. For instance, if a service charges by the hour but you use it only for a fraction of that time, you can adjust operations to maximize the use of that hour.
To save money, ensure that you understand how you're billed for a service. You need to understand specific increments like hourly rates, per gigabyte charges, or per request costs. Adjust the service's configuration or how you consume the service to fit the billing increments and ensure that you don't incur unnecessary costs. Evaluate your workload's specific needs and understand how you're billed for various resources. Based on your findings, adjust the usage or the resource to optimize costs.
Determine billing factors
Billing factors differ among services. Billing factors include the instance number, time, transaction rate, and transaction size. They also include availability zone, location, storage amount, ingress data, and egress data. Familiarize yourself with the pricing thresholds of the services that you use. You can align your usage to maximize the value of the resource and only run incur charges when necessary.
Here are some common billing factors:
Runtime:
The runtime refers to the duration that a resource actively runs or is utilized. Runtime is typically measured in hours, days, or months. The runtime helps you analyze the cost implications of resource usage over time. It's important for cost optimization because you can identify opportunities to minimize resource usage and associated costs.
Data transfer:
Data transfer refers to the movement of data into and out of a resource. Data transfer costs can vary based on the volume of data. Understand data transfer costs, so you can optimize data transfer patterns, select appropriate network configurations, and minimize costs associated with data movement.
Specialized services:
Specialized services are services or features that you use with other resources. These services can include specialized databases, AI services, or other advanced capabilities. Evaluate the cost implications of specialized services because they might have separate pricing models or incur extra charges.
Virtual CPUs (vCPUs):
The utilization of vCPUs within a resource is the vCPU usage. Resources such as virtual machines are often billed based on the number of vCPUs allocated to them. Monitor and optimize vCPU usage, so you can ensure efficient utilization of resources and minimize unnecessary costs.
Uptime guarantees:
Uptime guarantees refer to the service-level agreements (SLAs) that cloud providers offer on the availability and reliability of their services. Uptime guarantees aren't directly related to billing, but they're important to consider when you want to optimize costs. Higher uptime guarantees can coincide with higher costs. Evaluate the tradeoff between the cost and the service availability.
Determine billing increments
Billing increments determine how resource usage is measured and billed. For each billing factor, there's a billing increment. Familiarize yourself with the billing increments of each service, so you can align resource usage to these billing increments.
Here are some common types of billing increments:
Time:
* Resources are billed based on the duration of usage, such as per second, hour, or day.
Per request:
Some resources, particularly in serverless or event-driven architectures, are billed based on the number of requests or invocations. Minimize unnecessary requests and optimize the design of applications to reduce the number of billable requests.
Data transfer increments:
Data transfer costs are measured in increments, such as gigabytes (GB) or terabytes (TB).
Storage increments:
Storage costs are often measured in increments, such as GB or TB.
Map usage to billing increments
Mapping usage to billing increments is an exercise to identify where resource consumption doesn't align with the billing increments. This mapping involves analyzing resource usage against billing increments in each billing factor to spot inefficiencies. At this step, you're only identifying areas where usage and billing increment aren't aligned. Later, you implement the changes. Consider the following guidance when mapping usage to billing increments:
Create an inventory of resources
. List the resources in the workload, such as compute, storage, and networking.
Understand usage patterns
. Use monitoring tools or past-usage data to identify the resource consumption patterns for the workload. Note periods of high and low usage.
Use pricing calculators
. Input the information that you gather into an online pricing calculator to get a detailed breakdown of costs, segmented by billing factors and increments.
Analyze billing increments
. If the calculator provides billing granularity for each component, align your actual or expected usage with the billing increments (hourly, daily, or per request).
Simulate scenarios
. Use the pricing calculator to simulate usage scenarios in order to understand how resource usage affects costs.
Consider building a proof of concept (POC)
A proof of concept is a concrete way to validate your understanding of billing factors and billing increments. A POC helps you see the effects of design decisions on cost. It can help you refine your workload design to align with billing increments. A POC is important for leading cost drivers, such as the application platform and resources that scale.
If you're unsure about your billing knowledge or want to gain more confidence in understanding cost implications, a POC can provide a hands-on experience. You can validate your assumptions and test various scenarios to ensure that you have a clear understanding of the billing aspects. Consider the following guidance when you build a POC for cost optimization:
Define POC scope:
Clearly define the scope of the POC, including the specific workload or application that you want to optimize for cost and the resources involved. Include factors such as usage time, usage patterns, per instance charges, data transfer, storage, compute, and any other cost-driving components. Consider billing increments when you delineate the scope to ensure that cost factors are thoroughly addressed.
Emulate production:
Design the POC to emulate the production environment, ensuring realistic cost estimations. You should evaluate cost drivers, such as the effect of scalability, operational decisions (stopping and starting resources), and storage costs. Align the POC design with billing threshold knowledge to ensure that the simulated environment accurately reflects potential cost scenarios.
Limit POC duration:
Limit the lifespan of the POC, so you can gather conclusive evidence, but you don't incur unnecessary costs. Extend the POC slightly beyond a billing threshold to guarantee a comprehensive understanding of costs. For instance, if a resource is billed hourly, the POC might run for just over an hour or however long it takes to capture how costs accrue at the threshold. After you have the corroborating evidence, you can confidently make decisions based on your findings. When the POC provides a clear picture of billing implications, use the findings to make informed financial decisions for the actual environment.
Align usage to maximize resource value
Aligning usage to maximize resource value involves implementing the changes identified in the mapping exercise to realign resource usage with billing increments. This step is about making adjustments to how resources are consumed. There are two primary options for aligning usage to billing increments:
Modify the service.
Modifying the services means using different configurations, service tiers, or services to align the workload to billing thresholds. For example, your workload might move 5 TB of data daily, but you’re charged in 4-TB increments. You can find a different service tier or configuration, so you can transfer the data at a cheaper or faster rate.
Modify usage.
Modifying usage is about redesigning the usage pattern workload to align with a billing increment. For example, you can compress the 5-TB data to 4 TB before transferring. You can also extend the usage to the billing increment. For example, if you need to transfer 2 TB of data each day, you can modify the schedule to transfer 4 TBs of data every other day.
If neither option is feasible, you need to accept the extra cost. Rework the budgets as needed if the extra cost isn’t included in the budget.
Risk
: Cost optimization decisions shouldn't compromise security requirements or compliance regulations. If you opt for cheaper solutions without adequate security measures, you can expose the workload to potential vulnerabilities.
Azure facilitation
Determining billing factors and increments
: Azure has product pricing details for every
Azure product
. Search for the products in your workload and catalog the different billing factors and increments for each billing factor. You can also use the
Azure pricing calculator
to estimate the cost of different increments.
Mapping usage to billing increments
: You can use your
Azure bill
to analyze resource usage patterns and identify areas of high consumption. You can
view and download your Azure invoice
. These features help you understand how resources are utilized, so you can make informed decisions about optimizing their usage and minimizing unnecessary costs.
You can get a quick overview of your
invoiced usage and charges
on the Subscriptions page in the Azure portal. It's important to
understand the terms in your Azure usage and charges file
.
Aligning usage to maximize value
:
Microsoft Cost Management and Billing
and Azure Advisor provide optimization recommendations that are based on usage and cost data. These recommendations help you identify opportunities for cost savings. With this data, you can determine if resources are over-provisioned or underutilized, and right-size them to match the workload requirements. Right-sizing resources can help align to billing increments.
Product SKUs represent the service tiers in Azure products. Azure offers various SKUs within each service. Switching SKUs can help you align billing increments with usage patterns. You can use the
Azure product pricing pages
to compare the different tiers for each product.
With Azure, you can set up cost alerts and budgets.
Cost alerts
notify you when consumption reaches predefined thresholds, allowing you to proactively monitor spending.
Budgets
help you set limits and track the burn rate of your resources, which helps ensure cost control.
Next steps
Recommendations for collecting and reviewing cost data
Recommendations for optimizing data costs
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Design review checklist for Cost Optimization - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Design review checklist for Cost Optimization
Article
2023-11-15
2 contributors
Feedback
In this article
This checklist presents a set of recommendations about cost optimization for your workload to help you achieve a high return on investment (ROI) based on the business value that your workload delivers. Cost optimization balances actual costs versus perceived value, team efficiency, focus, and effort, while meeting the defined functional and nonfunctional requirements of your workload.
Every workload has direct and indirect costs, and every workload is designed to deliver value. If you don't incorporate the recommendations in this article and consider the tradeoffs, your design might not make the best use of your time and money. Carefully consider the points covered in the following checklist to instill confidence in your design's success.
Cost optimization is a continuous process in which you optimize workload costs and align your workload with the broader governance discipline of cost management. What's important today might not be important tomorrow. Technology choices or options and features that your platform offers today might be different. Learn from production and nonproduction environments, be aware of platform changes, and apply your findings to your workload and your workload's dependencies.
Checklist
Code
Recommendation
☐
CO:01
Create a culture of financial responsibility.
Regularly train personnel so technical skills remain sharp. Foster creativity and spending accountability in the work environment. Invest in tooling and implementing automation.
☐
CO:02
Create and maintain a cost model.
A cost model should estimate the initial cost, run rates, and ongoing costs. Negotiate a budget that covers a cost model and has a buffer for unplanned spending.
☐
CO:03
Collect and review cost data.
Data collection should capture daily costs. In cost reports, include incurred costs (metered), prepaid costs (amortized), trends, and forecasts. Stakeholders should regularly review spending against the budget and cost model. Automate alerts to trigger notifications at key thresholds and detect anomalies to indicate deviations from trend baselines.
☐
CO:04
Set spending guardrails.
Guardrails should include release gates, governance policies, resource limits, and access controls. Prioritize platform automation over manual processes.
☐
CO:05
Get the best rates from providers.
You should find and use the best rates for cloud resources and licenses. Regularly review cost savings. Cost reviews should include regional pricing, pricing tiers, pricing models (consumption or commitment-based), license portability, corporate purchasing plans, and price sheets.
☐
CO:06
Align usage to billing increments.
You should understand billing increments (meters) and align resource usage to those increments. Modify the service to align with billing increments, or modify resource usage to align with billing increments. Consider using a proof-of-concept to validate billing knowledge and design choices for major cost drivers and to reveal ways to align billing and resource usage.
☐
CO:07
Optimize component costs.
Regularly remove or optimize legacy, unneeded, and underutilized workload components, including application features, platform features, and resources.
☐
CO:08
Optimize environment costs.
Align spending to prioritize preproduction, production, operations, and disaster recovery environments. For each environment, consider the required availability, licensing, operating hours and conditions, and security. Nonproduction environments should emulate the production environment. Implement strategic tradeoffs into nonproduction environments.
☐
CO:09
Optimize flow costs.
Align the cost of each flow with flow priority. When you prioritize flows, consider the features, functionality, and nonfunctional requirements of each flow. Optimizing flow spend often requires strategic compromises.
☐
CO:10
Optimize data costs.
Data spending with data priority. Data optimization should include improvements to data management (tiering and retention), volume, replication, backups, file formats, and storage solutions.
☐
CO:11
Optimize code costs.
Evaluate and modify code to meet functional and nonfunctional requirements with fewer or cheaper resources.
☐
CO:12
Optimize scaling costs.
Evaluate alternative scaling within your scale units. Consider alternative scaling configurations, and align with the cost model. Considerations should include utilization against the inherit limits of every instance, resource, and scale unit boundary. Use strategies for controlling demand and supply.
☐
CO:13
Optimize personnel time.
Align the time personnel spends on tasks with the priority of the task. The goal is to reduce the time spent on tasks without degrading the outcome. Optimization efforts should include minimizing noise, reducing build times, high fidelity debugging, and production mocking.
☐
CO:14
Consolidate resources and responsibility.
Look within the workload for ways to consolidate resources and increase density. Outside the workload, use existing centralized resources and services that enable you to consolidate workload responsibilities.
Next steps
We recommend that you review the Cost Optimization tradeoffs to explore other concepts.
Cost Optimization tradeoffs
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for collecting and reviewing cost data - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for collecting and reviewing cost data
Article
2023-11-15
5 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:03
Collect and review cost data. Data collection should capture daily costs. In cost reports, include incurred costs (metered), prepaid costs (amortized), trends, and forecasts. Stakeholders should regularly review spending against the budget and cost model. Automate alerts to trigger notifications at key thresholds and detect anomalies to indicate deviations from trend baselines.
This guide describes the recommendations for collecting and reviewing cost data for your workload. Gather cost data to paint a holistic picture of your workload and ensure spending is optimized. Data collection includes all indicators of cost optimization, like billing data, resource utilization, and usage patterns.
Collected data allows you to understand the cost of architecture decisions and business drivers like costs per user or unit. This data gives you a clearer understanding of where money goes and how to optimize spending. Failure to collect and review cost data can lead to budget overruns, no baseline for spending, and a lack of understanding of the financial health of your cloud workloads.
Definitions
Term
Definition
Billing boundary
The scope of what a bill includes.
Chargeback
An accounting model in which you charge departments for their workload usage and receive payments from them.
Resource utilization
The amount of resource capacity a workload uses.
Showback
An accounting model in which you show departments the cost of their workload usage, and you don't receive payment from them.
Key design strategies
Data collection is essential for identifying cost-saving opportunities, accounting (
showback
and
chargeback
), and for efficient resource usage. You must prioritize the collection and review of cost data from all relevant sources. You should centralize the collected data for streamlined analysis and regular review, assign resource owners, and automate alerts where possible.
Collect cost data
Effective cost management of cloud workloads requires a comprehensive grasp of associated expenses, from computing to network usage. Data collected provides a granular view of where and how resources are being consumed. It allows you to identify inefficiencies, make informed decisions about resource allocation, and ultimately optimize costs to ensure you're getting the best value for your investment.
Enable data collection
. Data collection should include all sources of workload cost, such as compute, storage, network usage, and any other services or features the workload uses. The data should include invoiced and metered data. Invoiced data is
real
. It reflects actual billed expenses. Metered data is a predictive form of data based on the billing plans for services. While still valuable, daily slices of metered data are considered
good estimates
rather than precise figures. Recognizing the distinctions between invoiced and metered data in these components can provide more accuracy in financial planning and analysis.
Use all available collection methods
. To collect cost data, use all available tools and methods at your disposal like service provider's cost monitoring and utilities to monitor workload expenses. While these tools typically offer detailed insights into cost breakdowns, usage trends, and optimization suggestions, they might not capture everything. Understand their default capabilities, like data dictionaries and taxonomies.
Design custom views if they're required for your specific workload. Beyond native tools, if your service provider offers APIs, tap into them to programmatically retrieve cost data. APIs facilitate automated cost reporting and seamlessly integrate with your existing management systems. Remember, the goal is to gather cost details from every possible source. Whether that means pulling data via an API, manually entering costs, or syncing with your financial systems, it's vital to ensure a centralized and comprehensive cost overview.
Centralize cost data
. Centralized cost data allows for easier management and analysis of that data. It ensures you have a unified view, through a common data schema, of all workload costs and enables better cost optimization strategies. You need to combine usage data, and the data should flow into a central analytical sink. You can use a cost management tool provided by your cloud provider or integrate the data with third-party cost management solutions. The goal is to have a low-cost solution that's easily accessible by authorized stakeholders and provides robust data analysis capabilities.
Tradeoff
: Retaining cost data for longer periods enables historical analysis and trend identification. However, storing data can be costly. To minimize cost, store older data as aggregated data points without the granularity of newer data. Also, determine the best retention period based on your analysis needs.
Group data
Grouping data allows you to gain better insights to manage costs effectively. You can break down costs based on different dimensions, such as departments or projects, allowing you to accurately allocate costs to the respective stakeholders. Grouping data promotes transparency, accountability, and cost awareness.
Group cost data into meaningful categories such as resources, services, environments, regions, departments, projects, or teams. For example, understanding the cost breakdown at the resource and service level can help you make informed decisions about resource allocation, scaling, or even decommissioning. When you group cost data by environment, such as production, disaster recovery, or quality assurance, it can help you identify cost discrepancies and optimize resource usage based on the specific needs of each environment. When you group workload data, consider the following recommendations:
Collect usage and component data.
Collect detailed information about the usage and cost of each component in your workload. You can analyze costs from different angles and gain insights into the cost breakdown by capturing this data.
See different dimensions.
Break down your daily expenses by technical dimensions (for example, resource types or service categories), resource organization dimensions (for example, departments or teams), and business model dimensions (for example, projects or cost centers). This breakdown allows you to analyze costs based on the dimensions that matter the most to your specific problem or scenario.
Apply metadata.
Metadata can be used to group data and help generate meaningful cost reports. It enables you to identify areas of high cost and implement accountability measures or cost optimization strategies at the department or project level. Using metadata, you can design a mechanism to group costs in a way that reflects your application's core business model. For example, tagging resources with tenant identifiers instead of shared resources in a multitenant solution. The ability to pivot cost data based on your application's pricing model can deliver key insights.
Generate cost reports
After collecting cost data, you need to use it to generate cost reports. Cost reports provide visibility into spending and facilitate the analysis of your workload spending patterns. You can identify areas where cost optimization is needed and make informed decisions to optimize your spending. Cost reports enable you to allocate costs to different teams, departments, or projects. This allocation helps in understanding distribution and facilitates accurate chargeback or showback.
Address common scenarios
. When generating cost reports for workload costs, you want to be able to address common cost concerns. Gathering data in common concern areas helps ensure that the necessary data sets, such as costs, metrics, and usage, are interpreted cooperatively. Common concern areas include:
Granular costs
: Cost reports should provide information on the amount allocated per user and the cost per device.
Resource utilization
: Cost reports should help assess if current resources are fully utilized and identify potential savings.
Alternative solutions
: Cost reports should compare the costs and potential savings of transitioning to a new solution. They should also evaluate the feasibility of switching to a dynamic solution.
Return on investment
: Cost reports should help determine what percentage of revenue goes into system operation. If the system doesn't boost revenue, other ROI metrics should be measured.
Spending patterns
: Cost reports should analyze spending patterns to identify trends and patterns in costs over time. Spending patterns help in making informed decisions about cost optimization and budget planning.
Align to accounting standards
. Cost reports should accommodate your internal accounting standards. Common systems are showback and chargeback. Showback is about visibility, and chargeback is about accountability.
Showback
refers to providing cost visibility throughout an organization without charging individual teams or departments for their cloud costs. You can use cost reports to generate showback statements that showcase the costs incurred by each team or department. For example, the marketing team utilized $15,000, while the engineering department incurred costs of $25,000 for a combined workload expenditure of $40,000. Showback provides each department with a breakdown of costs, allowing each team to review and optimize their resource consumption. These reports provide transparency and enable stakeholders to understand their usage and associated costs.
Chargeback
involves billing internal teams or departments for their respective cloud costs based on their actual usage. Chargeback is dual-faceted. You can charge others and others can charge you based on resource consumption and services rendered. For example, your workload uses centralized security services. For one month, the security team billed you $10,000 for their services. But you charged the sales and marketing departments $7,000 and $8,000, respectively, for using your workload. All chargeback transactions, both credits and debits, are integrated into your centralized cost data sink. Chargeback ensures every expense is accounted for and incorporated into your organization's financial management. It provides a holistic view and promoting optimization of interdepartmental costs.
Provide comprehensive reports
. Cost reports should include the cost of cloud services and vendors. The report should include costs incurred (invoiced), prepaid costs (amortized), trends, forecasts, credits, and cost variance. In both showback and chargeback systems, cost reports should include the following elements:
Incurred costs
: Incurred costs refer to the actual costs accrued based on metered usage. These costs are calculated based on the consumption of resources or services within a specific billing period.
Prepaid costs
: Prepaid costs are expenses paid in advance and are spread out over a specific period of time. These costs are typically amortized or allocated evenly over the duration of the prepaid period.
Trends
: Analyzing cost trends involves examining the historical data to identify patterns and changes in spending over time. This analysis helps you understand how costs fluctuate and identify any underlying factors.
Forecasts
: Cost forecasts predict future spending based on historical data and trends, allowing you to estimate future costs and plan accordingly. Forecasts can be generated using various techniques such as machine learning algorithms.
Credits
: Service providers often provide credits (free utilization) on services. Cost reports should include credit balances and usage to properly understand spending needs.
Cost variance
: Cost variance in a cost report refers to the difference between the actual costs incurred and the expected or budgeted costs. It helps you identify deviations from the planned costs and understand the reasons behind them.
Assign resource owners
Each cost item should have a directly responsible individual (DRI) as the
resource owner
. Assigning a resource owner to each cost item ensures clear accountability for the associated costs. It helps identify who is responsible for managing and optimizing the usage and cost of specific resources or services. Resource owners are important for:
Cost allocation
: Having a resource owner assigned to each cost item enables accurate cost allocation. Resource owners ensure cost attribution to the appropriate teams, departments, or projects, facilitating financial transparency and budget management.
Communication
: Assigning resource owners promotes effective communication and collaboration within a workload team and organization. It facilitates discussions about cost management, encourages sharing of best practices, and enables resource owners to work together to optimize costs collectively.
Decision-making
: Resource owners play a crucial role in decision-making related to resource provisioning, scaling, and optimization. They have the necessary insights and ownership to make informed decisions that align with business objectives and cost optimization goals. Resource owners can actively monitor and analyze the costs associated with their resources. They can identify cost-saving opportunities, optimize resource usage, and make decisions to control and reduce costs.
Review cost data
Regularly review spending against the budget and cost model with stakeholders. Regular reviews help in identifying cost trends, outliers, and areas for optimization. It's important to involve stakeholders such as finance teams, operations teams, and decision-makers in these reviews to drive cost optimization initiatives. Reviews ensure that costs are aligned with expectations and allow for adjustments if necessary. Monitor changes in usage patterns, adjust resource allocations as needed, and implement cost-saving measures based on ongoing analysis of cost data.
Analyze cost data
Review the cost data collected from your workload to gain insights into your spending patterns. Reviews can include analyzing resource utilization, identifying cost drivers, and understanding the distribution of costs across different components of your workload. You should also notice increases and decreases in costs, for example, in compute usage and network transfer costs. Look for areas where you can optimize costs without sacrificing performance or functionality. For example, identify underutilized resources, rightsizing instances, or cost-saving features provided by your cloud provider.
Review architectural choices
When examining the architectural decisions of your workload, it's essential to focus on cost implications. Utilizing alternative patterns or cloud-native offerings can lead to significant cost savings. Opting for platform as a service (PaaS) or software as a service (SaaS) over infrastructure as a service (IaaS) can be more economical. With PaaS, not only are infrastructure expenses part of the service's pricing, but the platform also simplifies the provisioning and management of these resources under a unified cost. For instance, deploying a lower tier virtual machine as a jump box might introduce extra costs for storage, server management, and public IP configuration. In contrast, PaaS handles these complexities, offering a consolidated cost that often encompasses enhanced security.
Automate cost alerts
Implementing automated alerts can trigger budget notifications at key thresholds. These alerts can be set up to notify stakeholders and DRIs when costs exceed predefined limits or when there are significant deviations from expected spending patterns. Budget alerts and forecast alerts are two different types of cost alerts used for automating cost alerts.
Use budget alerts.
Budget alerts allow you to set a budget amount and define thresholds for actual costs. When the actual costs exceed the specified thresholds, budget alerts are triggered. These alerts help you monitor your spending and notify you when you're approaching or exceeding your budget. Budget alerts are based on the actual costs you accrued. Workload spend tends to vary. You should, at minimum, set alerts for the target budget at the anticipated costs (100 percent), ideal spend (90 percent), and less than ideal spend (110 percent).
Use forecast alerts.
Forecast alerts provide advanced notification when your spending trends are likely to exceed your budget. These alerts are generated based on forecasted cost predictions. When the forecasted cost exceeds the set threshold, forecast alerts are triggered. Forecast alerts help you anticipate potential cost overruns so you can take proactive measures to control your spending. You should set the forecast alert at 110 percent of the target budget.
Use anomaly detection.
Anomaly detection helps identify unexpected or abnormal patterns in cost data, allowing you to detect and address cost anomalies promptly. Utilize anomaly detection techniques to identify deviations from trend baselines, such as unexpected spikes or drops in costs, and take appropriate action. You should tune anomaly detection to catch fluctuations that your spending guardrails can't or intermittently don't prevent.
Based on the analysis of cost anomalies, determine the necessary actions to address the situation. Action plans might involve optimizing resource utilization, resizing virtual machines, implementing Azure Policy controls, or adjusting budgets. It's important to align cost control measures with business values and obtain the necessary approvals for budget adjustments.
Implement automated processes to identify and address cost variances in real-time. Options include automatically scaling resources, automating shutdowns, or establishing workflows for investigation and mitigation of cost anomalies. Establish key performance indicators (KPIs) to measure the accuracy of cost forecasts, cost versus budget, the number of unexpected anomalies, and the time to react to forecast alerts. Regularly review forecasts, track variance, and ensure alignment with budget expectations.
Risk
: Automating the collection and review of cost data can save time and effort. However, relying solely on automation might overlook certain cost optimization opportunities that require manual review and analysis. Finding the right balance between automation and manual review is crucial.
Azure facilitation
Collecting and grouping cost data
: Azure provides services like
Cost analysis
and Azure Advisor that help track and analyze your Azure spending and usage. These services capture the necessary data to calculate costs accurately. Use Azure tags to group costs to align with different business units, engineering environments, and cost departments. Tags provide the visibility needed for businesses to manage and allocate costs across different groups.
Generating cost reports
:
Cost analysis
offers customizable reports that provide insights into your incurred costs, prepaid costs, trends, and forecasts. These reports can be tailored to your specific requirements and provide a comprehensive view of your costs.
Reviewing cost data
:
Microsoft Power BI
can help with collecting and reviewing cost data. Power BI provides a comprehensive solution for collecting, reviewing, and analyzing cost data. It enables you to gain insights, track trends, and optimize costs effectively. It integrates with Cost Management and allows you to import cost data into Power BI.
For smaller cost data sets, you can use
Usage Details API
to get programmatic retrieval of raw, unaggregated cost data that corresponds to your Azure bill.
Reviewing architecture design choices
: Azure provides a wide range of PaaS resources. Here are some examples of when you might consider PaaS options:
Task
Use
Host a web server
Azure App Service
instead of setting up IIS servers.
Indexing and querying heterogenous data
Azure Cognitive Search
instead of ElasticSearch.
Host a database server
Azure offers many SQL and no-SQL options such as Azure SQL Database and Azure Cosmos DB.
Secure access to virtual machine
Azure Bastion
instead of virtual machines as jump boxes.
Network security
Azure Firewall
instead of virtual network appliances.
Automating alerts
: Cost Management enables you to set up
automated alerts and actions
based on spending thresholds or budgets. These alerts can trigger notifications to stakeholders when costs exceed predefined limits or deviate from expected patterns. You should use
Cost analysis
to view and respond to cost anomalies. This feature can highlight unexpected spikes or drops in costs, allowing for timely investigation and action.
Related links
Group and filter options in cost analysis and budgets
Monitor usage and spending with cost alerts in Cost Management
Azure billing and cost management budget scenario
Group and allocate costs using tag inheritance
.
Allocate Azure costs
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for consolidation - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for consolidation
Article
2023-11-15
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:14
Consolidate resources and responsibility. In a workload, determine ways to consolidate resources and increase density. Outside a workload, use existing centralized resources and services, so you can consolidate workload responsibilities.
This guide describes the recommendations for consolidating resources and responsibilities to optimize workload costs. Consolidating resources is a nuanced task that differs from simply eliminating waste. Consolidation involves combining components of a workload, such as servers, databases, applications, and responsibilities.
Consolidation can reduce redundant resources and licenses, and increase density. Look for opportunities to consolidate your workload responsibilities. Use centralized resources or teams to optimize costs. If you don't consolidate resources and responsibilities by using shared resources and optimizing economies of scale, you might miss opportunities for cost savings.
Definitions
Term
Definition
Centralized resource
A shared resource that multiple components use, rather than each component having its own dedicated resource.
Change control
A structured methodology for managing and implementing changes.
Consolidate
The act of combining components to optimally meet workload requirements.
Resource density
A measure of logical separation within a resource. Increased density typically equates to higher utilization due to the collocation of disparate components, consumers, or environments.
Key design strategies
The primary objective of consolidation is optimization, not reduction. Consolidation involves restructuring workloads, resources, and team roles to achieve maximum cost efficiency. Unlike
optimizing component costs
, consolidation is a process that requires careful consideration.
Almost every consolidation effort has tradeoffs and potential risks but can significantly reduce costs. It's important to analyze the potential benefits and associated tradeoffs. All consolidation strategies follow these steps:
Assessment
: Perform a thorough evaluation to identify areas where consolidation might be advantageous.
Identification and evaluation
: Pinpoint and assess potential consolidation targets to determine whether potential cost benefits and tradeoffs justify the effort of consolidating.
Communication and implementation
: If you determine that consolidation is beneficial, announce the impending changes and apply them.
Consolidate resources
Consolidating resources involves combining resources within a workload. You can collocate functionalities or consumers. For example, you might consolidate three web servers into a single server or three databases into a single database server. You might consolidate multiple firewalls into a single firewall that serves multiple environments.
The aim is to increase resource density, so you can maximize the cost efficiency of each resource. Expand the use of a resource and minimize resource redundancy.
Common types of services that you can consolidate include application platforms, databases, network appliances, gateways, and distributed denial-of-service (DDoS) protection. To consolidate resources within a workload, consider the following recommendations:
Assess the workload resources.
Assess the existing workload and its resource utilization. Analyze factors such as CPU usage, memory usage, storage capacity, and network bandwidth. Identify areas in which consolidation might be beneficial. Consolidation might involve optimizing resource allocation, eliminating redundant or underutilized resources, or reconfiguring the workload to run more efficiently. Consider factors such as workload dependencies, performance requirements, and scalability.
Identify a consolidation target.
Choose a resource to consolidate. It can be an existing resource or a new resource created within the workload. Identify existing resources that you might use for consolidation. For example, you might have servers that can accommodate some of the workload components. If no existing resources meet the consolidation requirements or if it's more beneficial to consolidate a new resource, consider creating a new resource.
Evaluate the consolidation viability.
Ensure functional and technical requirements, such as CPU, memory, and growth, support consolidation. Avoid compromising requirements like performance, reliability, and security. For example, don't create an undesired cross-regional dependency or consolidate resources across preproduction and production environments.
Estimate the cost.
Determine the effort and potential complications of consolidation. You should calculate costs, including resource, licensing, and operational expenses. Consider the implications, such as potential challenges in resource monitoring due to consolidation.
Communicate and coordinate with your team.
Ensure that you inform all stakeholders about upcoming changes and necessary actions that they need to take. Coordinate with teams to avoid conflicts and ensure a smooth implementation.
Risk
: Consider the effects of resource density, such as noisy neighbors, scale-unit effects, and reduced redundancy. Resource consolidation is often too risky for mission-critical and business-critical workload flows.
Tradeoffs
:
Resource consolidation reduces isolation and can create a noisy neighbor scenario in a workload. Find other ways to implement logical isolation and increased capacity for the hosting environment. For example, increase firewall capacity if it supports multiple workloads.
Consolidation eliminates segmentation and can increase security risk, which makes it easier for attackers to move horizontally. It also makes some compliance standards hard to achieve. Prioritize compliance over consolidation.
Resource consolidation results in less redundancy. Carefully plan to ensure that you have the proper amount of reliability in the workload.
Consolidate responsibilities
The goal of consolidating workload responsibilities is to reduce the workload team's responsibilities. It’s a strategic cost optimization effort that requires organizational awareness and collaboration outside the workload team.
There are two principal ways to consolidate your workload team's responsibilities. You can use external shared or centralized resources and not run that resource in the workload environment. You can also offload workload responsibilities to other teams in your organization, so your team isn't directly responsible for those tasks or personnel.
Use external centralized resources
External centralized resources refer to shared resources outside the workload environment. For example, an organization might have a centralized gateway that serves multiple workloads. The goal of external centralized resources is to minimize duplication and overhead. Instead of having a dedicated resource for your workload, you can use a shared resource to optimize costs. Consider the following recommendations:
Assess the workload resources
. Evaluate the current state of the workload, and identify areas in which consolidation might be beneficial.
Find external opportunities
. Survey your organization for pre-existing centralized resources. These resources might be potential solutions for your workload. For example, you can use a shared security information and event management (SIEM) instead of setting up an independent SIEM tool.
Consider change control
. Understand the process of managing changes to the centralized resource. Consider the approval workflow, testing protocols, and deployment methods. Analyze potential challenges if you reduced control of resource modifications.
Estimate the cost
. Before you implement centralized resources, clearly quantify the expected savings against the costs that are associated with a transition. Weigh the cost-saving benefits against risks to make an informed decision.
Communicate and coordinate with your team
. Establish a mechanism for continuous feedback among teams to address concerns, improve collaboration, and refine processes.
Document and track changes
. Maintain detailed documentation of all approved changes, including their scope, implementation steps, and associated risks or issues. Use a centralized system or change-management tool to track and monitor the status of changes throughout their lifecycle.
Tradeoff
: Over-consolidation can result in resource contention, which can lead to performance issues. Consolidation might limit the flexibility and agility of individual teams and workloads because they must adhere to centralized standards that can inhibit customization.
Offload responsibilities to external teams
Offloading workload responsibilities to external teams refers to using expert centralized teams that perform specialized services such as a security operations team. You can offload responsibilities to existing teams to help optimize costs and delegate expertise for specific functions.
Evaluate team skills
. Assess the current skill set of your team. Identify skill gaps or areas in which a centralized team optimizes costs.
Find available opportunities
. Explore your organization for available services, such as the services of a security operations team. Ensure that the centralized team can accommodate the added responsibilities without compromising quality.
Consider change control
. Familiarize yourself with how the centralized team handles changes, like approval workflows, testing protocols, and deployment strategies. Determine potential challenges that might arise if you have less direct control of these functions.
Communicate and coordinate with your team
. Ensure that teams are familiar with each other's processes, tools, and expectations. Consider a phased transition or pilot period to ease the shift and identify potential challenges early.
Document and track changes
. Maintain detailed documentation of all approved changes, including their scope, implementation steps, and associated risks or issues. Use a centralized system or change-management tool to track and monitor the status of changes throughout their lifecycle.
Azure facilitation
Density support
: Many Azure services support increased resource density. The following table shows a sampling of these services.
Azure service
Segmentation control
Azure Front Door
Customer domains and URL paths
Azure Firewall
Network and application rules
Azure Application Gateway
Listeners, URL path-based routing
API Management
API policies
Azure Kubernetes Service (AKS)
Namespaces, node pools
Azure App Service
Multiple web apps and APIs on an App Service plan
Azure SQL Database
Multiple databases on a server
Resource observability:
Azure Monitor
provides a centralized platform for monitoring and managing the performance and health of your Azure resources. You can collect and analyze telemetry data, set up alerts, and gain insight into resource utilization and opportunities for consolidation.
Log Analytics provides centralized log management and analysis. You can collect, analyze, and visualize log data from various Azure resources, which helps to identify issues, troubleshoot problems, and gain operational insight.
Related links
Azure Monitor
Recommendations for optimizing component costs
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for creating a cost model - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for creating a cost model
Article
2023-11-15
5 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:02
Create and maintain a cost model. A cost model should estimate the initial cost, run rates, and ongoing costs. Negotiate a budget that covers a cost model and has a buffer for unplanned spending.
This guide describes the best practices for creating a cost model for your workload. A cost model is an estimate that predicts the combined costs of services and their associated expenses. It's foundational for expense forecasting and budget planning. A cost model provides scenario analysis, which allows you to assess the cost implications of potential workload changes. Without a cost model, you risk unforeseen expenses, budget overruns, and missed opportunities for cost optimization.
Definitions
Term
Definition
Chargeback
An accounting model in which you charge departments for their workload usage and receive payments from them.
Cost model
The estimated cost of a workload. It captures all the dimensions of billing, including operations.
Cost meter
A tracking mechanism that you use to measure the usage of resources over time. It tracks usage, such as compute hours, data transfer, and input-output operations. It emits the records that are used to calculate the bill for each resource based on its associated meter.
Showback
An accounting model in which you show departments the cost of their workload usage, and you don't receive payment from them.
Key design strategies
A cost model provides a projection of the workload cost based on existing data. The purpose of a cost model isn't to gain visibility into expenses or control them. The goal is to forecast the predicted expenses, considering all available known factors. From that prediction, you determine the best solution for your workload. The best solution aligns spending to workload priorities. A cost model enables you to establish a workload budget, ensure alignment with this budget, and allocate funds for cloud resources.
Conduct workload assessment
Conducting a workload assessment involves systematically evaluating and analyzing the workload. A workload assessment helps identify workload characteristics that can inform cost optimization strategies, such as choosing the most suitable discount options based on usage patterns. You need to assess the workload characteristics to determine which available discounts are most suitable for your workload. For example, if your workload has predictable usage patterns, you might consider using a commitment-based model (reservations) to optimize costs. When you assess a workload, consider these recommendations:
Analyze key components
: Analyze the key components of your workload, including essential resources such as servers, databases, networks, and licenses. This identification allows for precise cost allocation within the model.
Understand characteristics
: Understand the workload's stability, predictability, and sensitivity to external factors like downtime and degraded performance. Such insights help anticipate fluctuating costs based on workload behavior.
Understand requirements
: Assess the specific requirements of your workload like performance, scalability, observability, backup, and disaster recovery. Recognizing these requirements ensures the model accounts for all potential expenses.
Understand supporting services.
Services that support observability, security, and governance incur costs and play a pivotal role in the operation of your workload. Observability solutions, such as monitoring tools and logging mechanisms, offer insights into workload usage and performance. Robust security measures, like encryption or access controls and regular security audits, safeguard your workload and ensure regulation compliance. Governance practices and policies ensure compliance and efficient resource utilization. Incorporate the expenses for these supporting services into your budget.
If you include these often-forgotten factors in your budgeting early on, your cost modeling will be thorough, effective, and prevent future unexpected expenses.
Estimate workload costs
Estimating workload costs involves assessing all potential expenditures and savings linked to the workload. It encompasses direct vendor costs, operational maintenance expenses, billing model choices, and potential savings from customer or enterprise agreements. By evaluating these factors, you can create a robust cost model, enabling precise forecasting and budgeting. To estimate workload costs, consider the following strategies:
Select the best billing model.
A billing model determines how the cloud service provider charges for their services. Billing models include consumption-based (pay-as-you-go), commitment-based plans (reservations), and spot pricing. Identify the most suitable and cost-effective billing model by understanding the specific requirements and usage patterns of each model. Each billing model has advantages and disadvantages of cost structure and flexibility. For example, pay-as-you-go might provide flexibility but might be more expensive over time compared to commitment-base plans instances.
Use customer agreements.
Cloud service providers offer customer agreements or enterprise agreements for customers. Some agreements offer discounts through available programs or allow you to use your existing licenses to save money. Implement these cost optimization strategies to maximize the value of your resources and reduce your overall expenses.
Estimate license costs.
Calculate estimates for license costs to create an accurate cost model. To find the best deal, contact the software provider or the software reseller. If you're an existing customer, use existing licensing benefits and discounts.
Estimate service costs.
Cloud service providers provide many services to support your workload. Choose services that help you meet your short-term and long-term cost objectives. For example, you might want to move an on-premises workload to the cloud with minimal changes to your workload. Choose a cloud service that supports your workload goals and provides the greatest return on your investment. Use the cloud platform's cost calculator to estimate your workload's resource costs. These tools help you understand the different cost meters in a resource and the billing model cost implications.
Consider the cost advantages and disadvantages of each service. Service-level objectives (SLOs) and platform features have cost implications. For example, downtime might cost your organization a considerable amount of money. If you invest more money into reaching higher SLOs, you can generate revenue by avoiding downtime and increasing customer satisfaction. Use built-in features as a cost-efficient alternative to building custom features that you need to develop and maintain.
Estimate resiliency costs.
To estimate resiliency costs, consider factors such as infrastructure, maintenance, data replication, data storage, disaster recovery, and performance. Consider the specific requirements and goals of your application or system. It could include the required level of resiliency, the desired SLOs, and the availability goals for each dependency on the critical path. The costs vary based on the cloud services and technologies that you choose.
Estimate operational costs.
To estimate the cost of workload maintenance, consider the ongoing operational expenses for monitoring, testing, and maintenance of the infrastructure. These costs include monitoring the performance and health of the infrastructure. It should include monitoring tools and services to help track system metrics, detect issues, and ensure availability.
You should estimate the cost of regular testing activities such as load testing, security testing, and performance testing. These tests are essential for maintaining the integrity of your workload. Include the resources and tools that are required for testing the system's resilience, scalability, and security. You also need to include Regular maintenance tasks, such as applying software patches, updates, and security fixes, are necessary to keep the system up to date. Routine tasks like data backup, system optimization, and configuration management contribute to ongoing maintenance costs.
Develop the cost model
The cost model is an estimate of all costs associated with the workload. These costs include infrastructure, software licenses, personnel, maintenance, and support costs.
Align estimates to cost drivers
Cost drivers are specific factors or variables that influence the overall cost. It includes any factors that have a direct impact on the cost of resources, services, or operations within the workload. These drivers can include variables such as usage volume, the number of customers served, storage capacity.
Assign quantitative values to the identified cost drivers, such as estimating usage volumes or determining the number of customers or resources. Quantify the effect of each cost driver by using methods such as estimating usage volumes or determining the number of customers or resources. Based on the cost categories and drivers, establish mathematical models or formulas that relate the cost drivers to the associated costs. These models can include simple linear relationships or complex calculations, depending on the cost category.
Associate costs with business metrics
Associating costs with business metrics means linking workload expenses to specific business indicators, like cost per customer served or cost per transaction processed. This practice provides a clearer understanding of how the workload consumes resources. It allows you to anticipate costs related to workload fluctuations and ensures efficient resource utilization based on demand. For example, if you expect the number of customers to grow, you can estimate how much it costs to support those customers.
You should emphasize clear visibility in the workload cost models. While it can make the model more intricate, it also allows for adaptability. Such a flexible cost model aids in scenario analysis, helping to predict expenses tied to workload or business shifts. To estimate the cost associated with each customer, divide the total workload cost by the number of customers. For a precise cost per customer, account for specific resources and services they utilize, like cloud services or software licenses.
Publish the cost model
Document the cost categories, drivers, and mathematical relationships that are used to calculate the costs. Create comprehensive and easily understood documentation for stakeholders. Ensure that the cost model is accessible to all relevant stakeholders. Publish the cost model in a format or on a platform that allows for seamless data exchange and enables efficient collaboration between stakeholders.
Set a budget
The cost model provides a foundation for negotiating your workload budget. The cost model is an estimate. The budget is a reality. Sometimes you have to negotiate to align the two. It's important that everyone understands how the workload supports business objectives. Present the cost model in alignment with business objectives to help clarify the value of the workload.
Share the cost model
: When you share the cost model with stakeholders, make sure the estimates are clear. Stakeholders should be able to see the cost distribution, cost variables, and optimization efforts.
Modify the cost model to fit the budget
: Stakeholders might not agree to the proposed budget and they might offer a budget that's less than the cost model. It's important that stakeholders know how the budget affects the workload. Create a second cost model that fits the budget and includes a buffer. Explain any functionality loss with the reduced budget.
The resulting budget should be realistic, but include a buffer for predicted usage changes over the budget period. The cost model helps predict these changes. A budget should also include a small and reasonable buffer for unplanned overages that result from a mistake or an unplanned business change.
Set budget caps and quotas
: Define budget caps and quotas to control costs and limit spending. This practice ensures that you don't exceed the allocated budget for your workload. By setting budget caps and quotas, you can monitor and manage your spending effectively.
Set budget alerts
: Implement alerts for cost management. Set up alerts to notify you when spending reaches certain thresholds. This practice allows you to take immediate action and make necessary adjustments to stay within the budget. Monitor usage and set alerts to help identify trends, peak usage times, and opportunities for cost optimization.
Use the cost model
A cost model isn't just an analytical tool. It's a decision-making aid. Use the cost model for budgeting, scenario analysis, and resource optimization. To maximize the use of the cost model, consider these strategies:
Use the cost model for budgeting
: Use the cost model to project future expenses, allocate funds effectively, and avoid financial pitfalls. Regularly compare actual expenses against the budget and make adjustments if there are deviations.
Use cost model for scenario analysis
: Using the cost model for scenario analysis involves considering different scenarios and the associated costs with each one. Scenario analysis can help stakeholders understand the financial implications of business model changes, such as modifications to pricing, product offerings, or revenue streams. Scenario analysis also enables you to anticipate how changes in customer acquisition, retention, or churn rates might affect costs. You can forecast increased expenses and plan for scaling.
Use cost model for resource optimization
: Use the cost model to help identify areas where cloud resources are underutilized and make adjustments for significant cost savings. The cost model can also forecast the financial implications of scaling up resources in response to increased customer traffic or processing needs. It also helps compare the costs that are associated with cloud providers’ billing models, which allows you to choose the most economical option.
Maintain the cost model
It's important to regularly update the cost model to reflect the latest data, business conditions, and any changes in the external environment. You should engage stakeholders, including product owners and the technical team, in discussions around the cost model to ensure its relevance and alignment with different teams' needs. Run simulations and review the findings to inform decision-making. Educate all team members on how to use the cost model to foster a culture of data-driven decision-making. Consider the following recommendations:
Track resource usage.
Monitor the usage of resources in your workload. Tracking resource usage is critical for adjusting cost models and identifying opportunities for cost optimization. Conduct utilization audits to identify underutilized resources and adjust cost estimates accordingly.
Generate and review forecasts.
Utilize usage data to generate forecasts and project the cost of the workload. Update forecasts regularly and view them often. Investigate any forecasts that deviate significantly from the current cost model. When you find an issue, update the cost model accordingly. The definition of a significant deviation from the cost model is different for each workload. The deviation might be due to changes in workload usage patterns, resource requirements, or pricing changes. By using a forecast, you can foresee exceeding your budget and make changes to the budget or workload design.
Update the cost model.
Review the cost model periodically to ensure that the workload receives the budget it needs. Use the metrics from the workload in production to inform budget reviews. The potential effect of services or technology changes can create the need for review. As services and technologies evolve, you might need to make changes to the workload design to optimize costs or take advantage of new features. Regular review ensures that the cost model remains aligned with the changing landscape. Review the cost model before and after workload design changes.
Update the cost model whenever you change services. Use the cloud platform's calculator to estimate the cost of the cloud resources that your workload needs. For new workloads, some of the cost variables, such as data transfer and storage amount, can be difficult to estimate. A business target can help you generate estimates. For example, to create a customer-based estimation, divide the daily revenue target ($100,000) by the average purchase per visitor ($100) to get the estimated number of daily visitors that you need to support (1,000).
Azure facilitation
Estimating workload costs and developing a cost model
: The Azure
pricing overview
provides pricing information for all Azure services. It shows a comprehensive view of the costs that are associated with different Azure services.
The Azure
pricing calculator
is a tool that allows you to estimate the hourly or monthly costs of your workload. Input the services that you plan to use to generate an estimate of the associated costs. This estimate helps you plan and budget for your Azure usage.
The
total cost of ownership (TCO) calculator
helps you estimate the cost savings of migrating your workload to Azure. It takes into account factors such as infrastructure, management, and labor costs to provide an estimate of the total cost of ownership. This estimate helps you make informed decisions about the financial aspects of your Azure migration.
Azure Hybrid Benefit
is a program that cloud service providers, like Azure, offer. It allows customers to use their own licenses for certain software products on the cloud. Use your own license to take advantage of discounted pricing for using that software on the cloud platform. Sometimes Azure Hybrid Benefit is part of the customer agreement between the cloud service provider and the customer. This agreement outlines the terms and conditions for utilizing the benefit and the eligible software products that are covered under it.
When you extend your existing investments in software licenses to the cloud, you save on costs. Instead of paying the full price for using the software on the cloud, you benefit from the discounted pricing that Azure Hybrid Benefit offers.
Setting a budget
: Azure provides tools that allow you to
create and manage budgets
. Budgets help you proactively inform others about their spending, manage costs, and monitor spending over time. You can set budget thresholds, receive alerts, and track expenses to ensure cost control and optimization.
Maintaining a cost model
: Azure automatically provides
cost forecasts
, which enable you to plan and budget for your Azure usage. These forecasts help you understand the projected costs based on your current usage patterns and allow you to make proactive decisions to optimize costs.
Azure allows you to use tag inheritance to
group and allocate costs
. Tags are metadata that you can assign to Azure resources. With tag inheritance, you can track and manage costs for different teams or projects within your organization to help with cost allocation and analysis.
Related links
Measure unit costs
View and download Azure usage and charges
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for creating a culture of financial responsibility - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for creating a culture of financial responsibility
Article
2023-11-15
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected-Framework Cost Optimization checklist recommendation:
CO:01
Create a culture of financial responsibility. Regularly train personnel so technical skills remain sharp. Foster creativity and spending accountability in the work environment. Invest in tooling and implementing automation.
This guide describes the recommendations for creating a culture of financial responsibility in an organization. Creating a culture of financial responsibility is where the workload team is equipped and motivated to make prudent financial decisions. It drives the team to proactively seek out and implement strategies that enhance efficiency and reduce unnecessary expenses.
Without this culture, there's often a disconnect between resource utilization and project goals. It can lead to budget overruns and diminished return on investment for the workload.
Definitions
Term
Definition
Financial responsibility
The sense of shared ownership of cost outcomes.
Microsoft learning partner
An organization that meets program requirements to teach training content developed by Microsoft and that employs Microsoft Certified Trainers to deliver content.
Key design strategies
Creating a culture of financial responsibility involves cost transparency, skill development, and clear communication. Be open about budgets and costs with the team. Hold regular workshops to teach cost-saving strategies. Invest in training for skills like budgeting and cloud cost management. Finally, set clear financial goals and encourage open communication for sharing ideas on cost optimization.
Make budgets and costs transparent
Making budgets and costs transparent requires openly communicating financial information about a workload or project with stakeholders. It helps cultivate an environment of trust and accountability, where everyone understands the financial implications of their actions and works collaboratively towards cost optimization. To make costs transparent, consider these strategies:
Involve everyone
: Ensure that everyone involved in the project or workload has access to budget information. Include team members, managers, and decision-makers. Sharing the budget information makes everyone feel accountable for their actions and decisions by fostering a sense of ownership.
Share budget details
: Consider sharing the allocated budget, cost breakdowns, and financial goals for the workload or project with stakeholders.
Share workload costs
: Strive for maximum transparency in the cost of the workload. Consider providing detailed information about the expenses for various aspects of the project, such as infrastructure costs, software licenses, and operational expenses. The more transparent the cost information is, the better it is for facilitating cost optimization efforts.
A benefit of sharing cost details is early detection of overspending. Transparent budgets provide a clear threshold for spending. If a team is approaching or exceeding a budget, it can take corrective actions early to avoid overspending.
Encourage continuous improvement
Encouraging a culture of continuous improvement is about fostering an environment where the workload team is empowered to explore and propose cost-saving measures. It requires open dialog, training, and team-building focused on cost optimization. With this mindset, the workload team is more likely to be proactive in identifying and implementing cost optimization strategies. To encourage continuous improvement, consider these suggestions:
Cost workshops
: Conduct workshops or training sessions to help leaders enhance their understanding of financial responsibility and its importance. These workshops can cover topics such as budgeting, cost management, and financial decision-making.
Evaluate the current financial practices and culture in the organization. Identify areas that require improvement to determine the specific interventions that address those areas. Collaborate with subject matter experts or external consultants, if necessary, to design and develop engaging and informative workshop content.
Team-building activities
: Organize team-building activities that focus on financial responsibility. These activities can include group exercises, case studies, or simulations that encourage collaboration and problem-solving in financial matters.
Foster a culture of knowledge sharing. Encourage the workload team to share its expertise and best practices with colleagues through internal forums, presentations, or mentoring programs.
Open dialog
: Create an environment where personnel feel comfortable speaking up about cost optimization ideas. Encourage open discussions, provide a platform for feedback, and welcome alternative suggestions. This environment helps create a culture of continuous improvement and innovation.
Empowerment:
Give the workload team the authority and responsibility to evaluate and propose the adoption of new technologies. The workload team should assess the suitability of new tools and technologies for their specific workload. They should consider factors such as compatibility, scalability, ease of integration, and potential cost savings.
Develop skills in-house
Developing skills in-house means investing in training the workload team. The goal is for the team to gain the necessary expertise to optimize costs within a workload.
This effort involves providing training programs, resources, and support to enhance the skills and capabilities of employees in the organization. It allows you to use the existing talent pool and empower employees to take ownership of cost optimization initiatives. Consider following these strategies:
Assess skills
: Evaluate the existing skills and knowledge of the workload team to identify areas that need improvement in terms of workload cost optimization.
Define training objectives
: Determine the specific skills and expertise that are required to optimize costs within the workload. Include topics such as cloud cost management, resource optimization techniques, budgeting, and data analysis.
Provide training and resources
: Offer training programs, workshops, and resources to enhance skills in the identified areas. Include both internal training sessions and external training programs provided by vendors or industry experts.
Gather or create learning resources such as documentation, tutorials, videos, and case studies to support the training. These resources should provide step-by-step guidance on optimizing costs in the workload.
Give hands-on experience
: Provide opportunities for employees to apply their newly acquired skills in real-world scenarios. Assign them to cost optimization projects, or give them responsibilities that allow them to refine their skills.
Create a workspace or sandbox where employees can explore, practice, and learn new concepts related to cost optimization. Allocate a budget for experimentation to encourage employees to think about the financial effects of their actions.
Set aside time (a day or a week) for people to explore new technologies, build new tools, and express their creative thinking. Employees are closest to the challenges they face daily. They often find ways to optimize their time when they're given space to think about it.
Encourage continuous learning
: Encourage employees to attend conferences, webinars, and industry events, and to participate in online communities and forums. Arrange opportunities for employees to shadow and learn from experienced individuals who have a deep understanding of cost optimization practices. This practical experience can provide valuable insights and guidance.
Communicate financial expectations
Communicating financial expectations to a workload team involves conveying financial goals and establishing open channels for exchanging cost-saving ideas and knowledge. This process includes reshaping organizational values to emphasize financial responsibility, clear goals, and cross-functional communication. Consider these recommendations:
Reshape values
: Review and update values and mission statements to include financial responsibility. Ensure that these values are communicated and reinforced throughout the organization, and that they're aligned with the overall business objectives.
Recognize and reward individuals and teams who demonstrate financial responsibility and contribute to cost optimization efforts. Use performance evaluations, incentives, or other recognition programs.
Establish expectations
: Set clear expectations and goals for all stakeholders who are aligned with the mission. Encourage accountability and responsibility for all actions taken. Establish and promote success metrics that are aligned with individual teams' goals.
Establish communication channels
: Use email groups, chat platforms, or dedicated collaboration tools as communication channels. Encourage team members to share their ideas and insights about cost optimization. Promote diverse perspectives. Make sure everyone is aware of the channels and how to access them.
Extend communication channels
: Make the communication channels available to the broader organization or department to encourage cross-functional collaboration and knowledge sharing. Identify power users or people in the organization who can act as champions for cost optimization. These individuals can help drive the adoption of cost-saving practices and help others understand the importance of cost optimization.
Use internal knowledge-sharing sessions, conferences, or industry forums. Employees can learn from others and contribute to the collective knowledge in the organization.
Azure facilitation
Making budgets and costs transparent
: For your Azure related budgets and costs, you can
create and management budgets
and provide read access to make these details available to the broader team. You can also create daily reports and
export cost data
to make cost data accessible to stakeholders.
Encouraging continuous improvement
: Azure regularly updates its services and introduces new features to improve efficiency and cost optimization. You can benefit from the latest advancements in cloud technology and take advantage of automation, advanced deployment strategies, and infrastructure as code (IaaS) practices.
Azure offers
Visual Studio subscriptions
with credits to try new features and learn new skills. Azure also provides role-based access control (RBAC), which allows read access to billing data through Microsoft Entra Privileged Identity Management.
Azure has a partner ecosystem that includes
training partners
who can provide expertise and guidance. Organizational leaders can talk to Microsoft and engage Cloud Solution Architects to get help and guidance in creating a culture of financial responsibility.
Developing skills in-house
: Azure provides a wide range of learning resources. These resources include documentation, video series, training modules, tutorials, and learning paths. These resources help personnel enhance their skills and knowledge. Azure also offers certifications that validate expertise in Azure services and technologies.
Microsoft offers the
Cloud Skills Challenge
, which allows individuals to test and improve their Azure skills. It's a fun, free, and interactive skilling program that gives you access to Microsoft skilling resources for your specific solution area. Gain access to Microsoft learning paths, virtual training days, and a virtual leaderboard to compete with peers in the industry.
Azure publishes
blogs
,
announcements
, and marketing materials that provide information on cost optimization and cost-optimized resources. They often contain information about upcoming or preview technology that you can experiment with.
Related links
Find an Azure partner
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Cloud design patterns that support cost optimization - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Cloud design patterns that support cost optimization
Article
2024-10-10
2 contributors
Feedback
In this article
When you design workload architectures, you should use industry patterns that address common challenges. Patterns can help you make intentional tradeoffs within workloads and optimize for your desired outcome. They can also help mitigate risks that originate from specific problems, which can affect reliability, security, performance, and operations. If not mitigated, risks will eventually increase costs. These patterns are backed by real-world experience, are designed for cloud scale and operating models, and are inherently vendor agnostic. Using well-known patterns as a way to standardize your workload design is a component of operational excellence.
Many design patterns directly support one or more architecture pillars. Design patterns that support the Cost Optimization pillar align with implementing favorable billing models, reducing overprovisioning, changing scaling dimensions, and maximizing value during migrations.
Design patterns for cost optimization
The following table summarizes cloud design patterns that support the goals of cost optimization.
Pattern
Summary
Claim Check
Separates data from the messaging flow, providing a way to separately retrieve the data related to a message. Messaging systems often impose limits on message size, and increased size limits is often a premium feature. Reducing the size of message bodies might enable you to use a cheaper messaging solution.
Competing Consumers
Applies distributed and concurrent processing to efficiently handle items in a queue. This pattern can help you optimize costs by enabling scaling that's based on queue depth, down to zero when the queue is empty. It can also optimize costs by enabling you to limit the maximum number of concurrent consumer instances.
Compute Resource Consolidation
Optimizes and consolidates compute resources by increasing density. This pattern combines multiple applications or components of a workload on a shared infrastructure. Doing so maximizes the utilization of computing resources by avoiding unused provisioned capacity via aggregation of components or even whole workloads on a pooled infrastructure. Container orchestrators are a common example.
Gateway Offloading
Offloads request processing to a gateway device before and after forwarding the request to a backend node. Adding an offloading gateway into the request process enables you to redirect costs from resources that would be spent per-node into the gateway implementation. Costs in the centralized processing model are frequently lower than those of the distributed model.
Messaging Bridge
Provides an intermediary to enable communication between messaging systems that are otherwise incompatible because of protocol or format. This intermediary can increase the longevity of your existing system while still allowing interoperability with systems that use a different messaging or eventing technology.
Publisher/Subscriber
Decouples components of an architecture by replacing direct client-to-service or client-to-services communication with communication by using an intermediate message broker or event bus. This design can enable an event-driven approach in your architecture, which couples well with consumption-based billing to avoid overprovisioning.
Queue-Based Load Leveling
Controls the level of incoming requests or tasks by buffering them in a queue and letting the queue processor handle them at a controlled pace. Because load processing is decoupled from the request or task intake, you can use this approach to reduce the need to overprovision resources to handle peak load.
Sharding
Directs load to a specific logical destination to handle the specific request, enabling colocation for optimization. A system that implements shards often benefits from using multiple instances of less expensive compute or storage resources rather than a single more expensive resource. In many cases, this configuration can save you money.
Static Content Hosting
Optimizes the delivery of static content to workload clients by using a hosting platform that's designed for that purpose. Dynamic application hosts are usually more expensive than static hosts because dynamic hosts can run your coded business logic. Using an application platform to deliver static content isn't cost-effective.
Strangler Fig
Provides an approach for systematically replacing the components of a running system with new components, often during a migration or modernization of the system. The goal of this approach is to maximize the use of existing investments in the currently running system while modernizing incrementally. It enables you to perform high-ROI replacements before low-ROI replacements.
Throttling
Imposes limits on the rate or throughput of incoming requests to a resource or component. The limits can inform cost modeling and can even be directly tied to the business model of your application. They also put clear upper bounds on utilization, which can be factored into resource sizing.
Valet Key
Grants security-restricted access to a resource without using an intermediary resource to proxy the access. This design offloads processing as an exclusive relationship between the client and the resource without adding a component to directly handle all client requests. The benefit is most dramatic when client requests are frequent or large enough to require significant proxy resources or the proxy does not add value as being part of the request.
Next steps
Review the cloud design patterns that support the other Azure Well-Architected Framework pillars:
Cloud design patterns that support reliability
Cloud design patterns that support security
Cloud design patterns that support operational excellence
Cloud design patterns that support performance efficiency
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for getting the best rates from providers - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for getting the best rates from providers
Article
2023-11-15
9 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:05
Get the best rates from providers. You should find and use the best rates for cloud resources and licenses. Regularly review cost savings. Cost reviews should include regional pricing, pricing tiers, pricing models (consumption or commitment-based), license portability, corporate purchasing plans, and price sheets.
This guide describes the recommendations for getting the best rates from providers for your workload. Getting the best rates is the practice of finding and securing the most cost-efficient pricing options for cloud and software resources without modifying architecture, resources, or functionality. By optimizing rates, you can reduce cloud costs without changing the workload. A small rate reduction on services you use a lot provides significant cost savings. Without rate optimization, you end up paying more for your resources, services, and licenses than necessary.
Definitions
Term
Definition
Consumption-based billing model
A pricing model where you're charged based on the actual usage of the service. Examples include the number of virtual machines deployed, the amount of storage used, and the amount of data transferred.
Commitment-based billing model
A pricing model where you reserve and pay for a specific amount of usage in advance and can often get a discounted rate compared to consumption pricing.
Rate
The unit price for using a service or license.
Key design strategies
Getting the best rates requires actively searching for the most cost-effective pricing models for all workload components. It weighs the benefits of different billing models, such as consumption (pay-as-you-go) versus commitment-based billing, software licenses and corporate discount plans, and the  price differences between regions.
To get the best rates on the resources and licenses in your workload, you should start with identifying and reducing costs in the most expensive areas. Evaluate the discounts available from providers, and choose the right discounts based on workload needs. Regularly check for discounts and reduce licensing fees where possible. Determine if it's more cost effective to build or buy new workload solutions.
Uncover workload spending patterns
Understanding the workload is the first step to finding and using the best rates on infrastructure, resources, licenses, and third-party services. It prepares you to make informed decisions and implement cost optimization strategies that are specific to the needs of the workload.
Here are actions that you can take to understand the workload rates:
Take inventory.
List all the components of your workload, including infrastructure, cloud resources, licenses, third-party services, and any other expenses related to the workload.
Understand spending.
Gain a clear understanding of the current spending for each item in the inventory list. Identify what you're paying for and where most of your expenses lie.
Create an ordered list of workload expenses.
List the most expensive components and work your way down to the least expensive. This exercise helps you prioritize your optimization efforts and focus on the areas that have the highest effects on cost.
Determine the right billing model
For your billing model, you choose between consumption (pay-as-you-go) and commitment-based billing models. You base the selection of consumption versus commitment-based pricing on the predictability, duration, and usage consistency of workload components. When you make this decision, you must collaborate with development and purchasing teams to evaluate resource needs, usage patterns, and potential cost optimization ideas.
Selecting the right billing model is crucial for cost-effectiveness. It helps align the workload with business objectives and get the best rates for the specific requirements of a workload. To determine the right billing model, consider the following strategies:
Understand the consumption-based billing model
Consumption-based billing model (pay-as-you-go) is a flexible pricing model that allows you to pay for services as you use them. Cost variables for consumption pricing include how long a resource is running. Service meters have various billing increments, such as per hour or per second. This model provides flexibility and cost control, because you pay for only what you consume.
The consumption-based billing model is best suited for the following scenarios:
Variable workload
: A variable workload has unpredictable spikes or seasonal variations in usage. Consumption-based billing allows you to scale resources up or down to meet the fluctuations in demand. It helps you to provide the required performance and not overpay during times of low usage.
Preproduction environments
: Consumption-based billing is preferred for development and test environments that are ephemeral. It offers the advantage of paying only during the project. Ensure that you provide resources aligned with the development effort. Resources cost less when development is scaled down.
Short-term projects
: Short-term projects often have specific resource requirements. Consumption-based billing allows you to pay for the resources only during the project.
Tradeoff
: Many on-premises environments are always on and always available. Being intentional about services might lower rates, but you must account for some creation time and operational overhead.
Understand the commitment-based billing model
Commitment-based pricing allows you to reserve a specific amount for a specific duration and pay for it in advance. By reserving the usage up front, you can get a discounted rate compared to consumption-based billing.
The amount you save with commitment-based pricing depends on factors such as the duration of the reservation, the reserved capacity, and the service. Commitment-based pricing is best suited for the following scenarios:
Predictable workloads
: If your workload has a consistent usage pattern, you can commit to a certain capacity over time and get a significant discount over consumption-based billing. Those instances incur charges whether you use them or not.
Production environments
: Commitment-based billing is suitable for production environments where you have a good understanding of the workload's resource needs.
Long-term projects
: Commitment-based billing can be cost-effective for projects that have long-term resource requirements, even if they aren't highly predictable.
Discuss options with the workload team
To ensure effective optimization of workload costs, the development team (or architect) and the purchasing team must work together. Combining their expertise enables you to identify opportunities to optimize costs and make informed decisions.
Here's a suggested process for collaborating on rate reduction efforts:
Identify opportunities for cost optimization
: Together, the teams should identify potential areas for cost optimization, such as infrastructure, cloud resources, licenses, and third-party services. Consider factors like usage patterns, scalability, workload, and regional requirements per environment.
Assess resource requirements
: Determine the resources needed to support the component or workload. Consider factors such as infrastructure, maintenance, and ongoing support. Understanding these requirements can help you gauge the long-term commitment involved.
Evaluate options
: Assess your options for cost optimization, such as pay-as-you-go versus commitment-based plans. Evaluate the pros and cons of each option in terms of cost savings and effect on performance. Evaluate the performance tiers in each service and the pricing differences between them.
Determine component permanence
It's important to assess how long you need a particular component to determine if committing to a commitment-based plan makes sense. If the expected usage duration is less than a year, don't commit to a commitment-based plan. Consider the flexibility of pay-as-you-go options for shorter-term requirements.
To determine the duration of component usage, you can follow this process:
Gather usage data
: Collect data on the historical usage of the component or workload. This data can include how long the component has been in operation and the frequency of usage.
Analyze usage patterns
: Analyze the collected usage data to identify patterns and trends. Look for consistent usage over a specific period of time or recurring usage patterns. This analysis helps you understand the typical duration of component usage.
Consider future requirements
: Consider any future requirements or changes in your component or workload. Evaluate whether any upcoming changes might affect its usage duration.
Assess business needs
: Evaluate the business needs and objectives associated with the component or workload. Consider factors such as project timelines, budget constraints, and the overall strategy of your organization.
Anticipating future developments can help you assess the long-term commitment required and whether it aligns with your objectives. This assessment helps you determine the appropriate duration for component usage.
Determine usage consistency
When you're considering a commitment-based plan, commit to the maximum consistent usage of a component. By committing to the maximum consistent usage, you can maximize the potential savings and cost optimization. However, there are a few factors to consider:
Usage patterns
: Analyze the historical usage patterns of the component. If the usage is consistently high and stable, committing to the maximum consistent usage makes sense. But if the usage is highly variable or unpredictable, committing to the maximum consistent usage might not be feasible or cost-effective.
Flexibility and scalability
: Consider the flexibility and scalability of the component. If the component can easily scale up or down based on demand, it might be more suitable to opt for flexible pricing models that allow you to adjust resources dynamically. This way, you can align your costs with the actual usage of the component.
Engagement with the provider
: Communicate with the provider to gather information about its plans, roadmap, and commitment to the component or workload. This dialog provides valuable insights into the provider's long-term vision and commitment level.
Cost analysis
: Perform a cost analysis to assess whether the potential savings of committing to a higher usage level outweighs the risks of not fully utilizing the commitment.
Select the right commitment-based plan
Strategic usage of commitment-based plan can significantly minimize costs for applicable resources. It allows you to effectively plan and allocate resources. To select the right commitment-based plan, consider the following strategies:
Choose an appropriate commitment-based plan
: Select a commitment-based plan that covers the minimum capacity that the workload requires. Starting with the minimum commitment gives you flexibility while you still benefit from cost savings.
Having a clear understanding of the workload's minimum capacity requirements before you commit to a commitment-based plan minimizes risk and ensures that you optimize your savings. However, there are exceptions. A commitment that requires minimal upfront costs has a lower risk. The lower the commitment risk, the quicker you can commit to a commitment-based plan. As the cost and risk of a commitment grow, you need to understand your minimum consistent usage for each component you're committing to.
Increment commitments
: As the capacity of your workload grows, gradually increase your commitments. Start small and scale up. Increment scaling up based on the workload's actual usage.
Renegotiate and consolidate
: Regularly renegotiate and normalize commitment-based plans to align their ending time. This alignment allows you to consolidate them into a single line item on your bill, so it's easier to manage and optimize costs.
Eliminate underutilization
: You need to evaluate and optimize commitment-based contracts to ensure they deliver their full potential value. Regularly review and analyze your charges and usage data. Understand the breakdown between actual cost and amortized costs and reconcile the data to ensure accurate billing.
Monitor utilization. Keep an eye on how much you're using your commitment-based plans. Set up alerts to tell you if you're not using all of your reserved resources. Check how you're using them over time and get rid of any you're not using. Make sure you're using the right size of virtual machines to get the most out of your plan. You can also adjust the sizes to fit what you already paid for.
Modify the commitment-based plan. Consider changing the scope of the reservation to share, allowing it to apply more broadly across your resources. It can help increase utilization and maximize savings. If you find underused commitment-based plans, try exchanging unused quantity or canceling and refunding plans.
Evaluate and commit to available discounts
Assess and analyze the potential discounts that can be applied to a specific workload. This process helps you identify opportunities for cost reduction and optimize the expenditure associated with the workload. It also helps you allocate resources more efficiently.
Try these tasks:
Ask about trial offers
: Use a provider's trial periods or negotiate free or reduced rates to execute proofs of concept. This approach allows you to try out the services or products with limited financial risk, so you can assess their suitability for your workload before you commit to a purchase. Remember to review the terms and conditions of any trial periods or negotiated agreements.
Review provider offerings
: Understand the discounts and pricing models that providers offer. Explore volume-based discounts, promotional offers, or discounts for long-term commitments. Discuss the available options that can meet the variability and flexibility requirements of your workload. Include information about different pricing models, scaling options, or commitment-based agreements.
Analyze usage and consumption
: Assess the workload's usage and consumption patterns to determine if the workload meets the eligibility criteria for specific discount programs. This analysis helps you identify the most suitable discounts for your workload.
Evaluate contract terms
: Review the terms and conditions of existing contracts or agreements to identify any potential discount options. Consider the duration of the commitment, renewal terms, and the possibility of negotiating better rates.
Communicate with providers
: Know the actual and anticipated usage of a workload when you discuss discounts. Let the providers know what environment the discussion is about. For example, you can often get discounts on preproduction environments. Ask providers to discuss available discount options, such as product bundling. Ask specific questions about discount programs, eligibility criteria, and any negotiation possibilities.
Understand reseller options
: Consider engaging with resellers who can provide extra insights into available discounts or offer alternative pricing models. Resellers might have access to specialized programs or discounts that can benefit your workload.
Committing to the right discount options is where you act on your evaluation. You're equipped with the available options. You communicated your needs and workload data to the various providers. Now you need to lock in the discounted rates for a defined period, which can result in significant cost savings compared to pay-as-you-go pricing.
Decide whether to build or buy a solution
Building a solution in-house allows for granular control over the features and configuration. This control can help you eliminate unnecessary functionality and optimize rates. However, building a solution in-house requires significant upfront investment in development time and maintenance.
When you buy a solution, such as from a marketplace, it offers quicker deployment with potentially lower upfront costs. But buying a solution might involve ongoing subscription or licensing fees.
Here are key considerations when you're deciding whether to build or buy a solution:
Control and customization
: Assess the specific functionality that you need for your product or solution. Determine whether buying a solution meets your requirements or whether building allows for the customization and flexibility that provide better rates.
Building a solution offers greater control over component selection and configuration. You can add customization to fit business needs and minimize unneeded features that might incur charges. Buying solutions provides preconfigured options with limited customization capabilities.
Time to market
: Assess the urgency and time constraints for deploying the workload component or solution. Building a solution in-house might take longer because of development and testing, whereas buying a solution allows for quicker deployment.
Technical expertise
: Building might require greater technical expertise to ensure proper configuration and maintenance over time. A custom solution requires effort up front and over time. Buying a solution is often more user-friendly and requires less technical knowledge.
Cost
: Evaluate the total cost of building a solution, including development resources, infrastructure, ongoing maintenance, and support. Compare the cost of building a solution with the cost of buying a solution. Include any support plans, licensing, or subscription fees. Buying a solution might provide more predictable pricing and potential discounts due to economies of scale.
Support and updates
: Consider the availability of support and updates for both building and buying. Assess the level of technical expertise required for each option and the ease of accessing support resources.
Updates for custom solutions add costs by requiring separate environments, testing, and backups. For purchased solutions, research the reputation and track record of the marketplace providers. Consider factors such as provider reliability, customer reviews, and the provided level of support.
Also consider the billing cycles. For example, subscription billing cycles are incentivized to maintain the quality of the solution over time. One-time purchases don't have the same cost incentive to maintain the solution.
Optimize licensing costs
Optimizing licensing costs means using various licensing programs and options to minimize expenses while maximizing value. This approach helps ensure you get the best rates from providers, preventing overpayment for software and services. It's important to review the license associated with its design, build, and deployment phases. This review should encompass tools used in its software development, security, monitoring, and design components. These licensing programs might include options for:
Hybrid use and bundling
: In addition to exploring licensing programs, consider using hybrid use and bundling options. These programs can provide extra cost savings by optimizing licensing for both on-premises and cloud environments.
Negotiations
: Don't hesitate to negotiate with your provider to secure better licensing terms. Negotiations can often lead to more favorable pricing and discounts.
Dev/test pricing
: Take advantage of dev/test pricing options that your provider offers. These programs typically provide discounted rates for nonproduction environments, so you can save costs during development and testing phases.
Volume discounts
: As your usage increases, you might become eligible for volume discounts. Cloud service providers often offer discounted rates based on the scale of usage, so it's important to monitor your usage and explore opportunities for cost optimization.
Existing enterprise agreements
: Check your existing enterprise agreements to see if any licensing benefits or cost-saving opportunities are available. Your procurement department or license reseller can provide valuable insights in this area.
Azure facilitation
Microsoft Cost Management
: Azure provides tools and features for managing and optimizing costs, such as Microsoft Cost Management. These tools allow you to track and analyze your cloud spending, set budgets, get cost alerts, and access detailed cost reports.
Azure reservations and Azure savings plans
: Reservations and savings plans allow you to commit to using specific resources for a term and get significant discounts on Azure services. Here are the details:
Azure reservations
help you save money by committing to one-year or three-year plans for multiple products. Committing allows you to get a discount on the resources that you use.
Reservations can significantly reduce your resource costs from pay-as-you-go prices. Reservations provide a billing discount and don't affect the runtime state of your resources. After you purchase a reservation, the discount automatically applies to matching resources.
You should use reserved instances when you don't expect certain services, products, and locations to change over time. We highly recommend that you begin with a reservation for optimal cost savings.
An
Azure savings plan
for compute is a flexible pricing model. It provides savings off pay-as-you-go pricing when you commit to spending a fixed hourly amount on compute services for one or three years.
Committing to a savings plan allows you to get discounts, up to the hourly commitment amount, on the resources that you use. Savings plan commitments are priced in US dollars for Microsoft Customer Agreement and Cloud Solution Provider customers, and in local currency for Enterprise Agreement customers. Savings plan discounts vary by meter and by commitment term (one year or three years), not commitment amount.
Savings plans provide a billing discount and don't affect the runtime state of your resources. You should use Azure savings plans for more flexibility in covering diverse compute expenses by committing to specific hourly spending.
Eliminating unused reservations and savings plans
: To eliminate unused reservations and savings plans, you can use the Microsoft Cost Management and Billing tools. They provide insights into your reservation and savings plan usage, allowing you to identify any unused or underutilized commitments and make adjustments accordingly. Utilization can be viewed in the Azure portal under the Reservations section.
Azure dev/test
:
Azure dev/test
is an offer that comes with Visual Studio subscription benefits. With this offer, you get some Azure monthly credits to try various Azure services at no cost. Credit amounts vary by subscription level. You can also benefit from discounted Azure dev/test rates for various Azure services, which enable cost-efficient development and testing.
Azure services
: Many Azure services offer both consumption and commitment-based billing models. You can switch to better align to your usage, potentially without sacrificing functionality.
Azure Hybrid Benefit
: With
Azure Hybrid Benefit
, you can reduce the overall cost of ownership by using your existing on-premises licenses to cover the cost of running resources in Azure. This benefit applies to both Windows and Linux virtual machines, along with SQL Server workloads. To take advantage of Azure Hybrid Benefit, you need to ensure that your licenses are eligible and meet the requirements.
License Mobility
: Azure supports
License Mobility
. You can bring your own licenses for certain software products and apply them to Azure resources. This ability can help reduce licensing costs and simplify license management.
Licensing agreements
: Microsoft offers commitment-based and transactional licensing options for organizations that want to purchase Microsoft cloud services subscriptions, on-premises software licenses, or
Software Assurance
. Use these offers for your workload as applicable. Microsoft offers various volume licensing programs and agreements based on your workload's needs, including:
Microsoft Enterprise Agreement
Microsoft Customer Agreement
Microsoft Open Value program
Microsoft Products and Services Agreement
For more information, see the
Microsoft licensing resources
.
Azure spot instances
: Azure spot instances provide access to unused Azure compute capacity at discounted prices. By using spot instances, you can save money on workloads that are flexible and can handle interruptions.
Related links
Azure reservations
Azure savings plan
Azure dev/test
Azure Hybrid Benefit
License Mobility
Software Assurance
Microsoft Enterprise Agreement
Microsoft Customer Agreement
Microsoft Open Value program
Microsoft Products and Services Agreement
Microsoft licensing resources
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Cost optimization quick links - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Read in English
Table of contents
Read in English
Edit
Share via
Facebook
x.com
LinkedIn
Email
Table of contents
Cost optimization quick links
Apply cost optimization guidance in your architecture to sustain and improve your return on investment (ROI).
Learn key points
Quickstart
Design principles
Checklist
Tradeoffs
Cost optimization patterns
Azure Well-Architected Review assessment
Training
Cost optimization
video
What tradeoffs have you made to optimize for cost?
Review design principles
Concept
Develop cost-management discipline
Design with a cost-efficiency mindset
Design for usage optimization
Design for rate optimization
Monitor and optimize over time
Set, measure, and protect financial targets
How-To Guide
Create a culture of financial responsibility
Create a cost model
Collect and review cost data
Set spending guardrails
Take cost optimization actions
How-To Guide
Get the best rates
Align usage to billing increments
Optimize component costs
Consolidate
Optimize
How-To Guide
Environments
Flows
Data
Application code
Scaling
Personnel time
Explore related resources
Reference
Azure Advisor: Cost recommendations
Azure Pricing Calculator
Microsoft Azure Total Cost of Ownership (TCO) Calculator
Microsoft Cost Management
Visualize cost reports
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for optimizing code costs - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for optimizing code costs
Article
2023-11-15
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:11
Optimize code costs. Evaluate and modify code to meet functional and nonfunctional requirements with fewer or cheaper resources.
This guide describes the recommendations for optimizing code costs. Code optimization is the process of improving the efficiency, performance, and cost-effectiveness of application code. Effective code optimization involves making changes to the code to reduce resource consumption, minimize execution time, and improve overall performance.
By optimizing code, you can identify and eliminate inefficiencies that might lead to increased resource consumption and higher costs. You can reduce processing time, memory usage, and network overhead, which can lead to applications that are faster and more responsive. Improved performance enhances the user experience and enables your system to handle larger workloads efficiently.
Definitions
Term
Definition
Code instrumentation
The practice of adding code snippets or libraries to code that collect data and monitor code performance during runtime.
Concurrency
The execution of multiple processes at the same time.
Data serialization
The process of converting data objects into a format that can be stored or transmitted and then reconstructing them back to their original form when needed.
Hot paths
Critical or frequently run sections of a program that require high performance and low latency.
Key design strategies
Cost optimizing code means improving code to achieve the same functionality with fewer per-instance resources, such as CPU cycles, memory, and storage. By reducing resource consumption, you can save money when applications handle large volumes of data or experience high traffic loads.
Code improvements are most effective when you're following other cost optimization efforts around scaling, rightsizing, redundancy, and throttling. After you take care of these foundational elements, you can consider code optimization.
You might not know if you have inefficient code. Serverless, autoscale, and reliability features can mask code inefficiencies. The following strategies can help you identify and fix application code that costs more than it should.
Instrument your code
Instrumenting code is the practice of adding code snippets or libraries that collect data and monitor code performance during runtime. It allows developers to gather information about key metrics, such as resource consumption (CPU or memory usage) and execution time. By instrumenting code, developers can gain insights into code hot paths, identify performance bottlenecks, and optimize the code for better efficiency and cost-effectiveness.
In an ideal environment, you should do code analysis early in the software development lifecycle. The earlier you catch a code problem, the cheaper it's to fix.
Automate as much of this code analysis as possible. Use dynamic and static tools for code analysis to reduce the manual effort. However, keep in mind that this testing is still a simulation of production. Production provides the clearest understanding of code optimization.
Tradeoff
: Code monitoring tools are likely to increase costs.
Optimize hot paths
By instrumenting your code, you can measure the resource consumption of code paths. These measurements help you identify hot paths. Hot paths have a significant effect on performance and resource usage. They're critical or frequently run sections of a program that require high performance and low latency.
To identify hot paths, consider these tasks:
Analyze runtime data
: Collect and analyze runtime data to identify areas of the code that consume significant resources, such as CPU, memory, or I/O operations. Look for patterns or sections of code that are frequently run or take a long time to complete.
Measure performance
: Use profiling tools or performance testing frameworks to measure the execution time and resource consumption of code paths. This measurement helps identify bottlenecks and areas for improvement.
Consider business logic and user effect
: Evaluate the importance of code paths based on their relevance to the application's functionality or critical business operations. Determine which code paths are crucial for delivering value to users or meeting performance requirements.
Review performance recommendations that are specific to the programming language you're working with. Evaluate your code against these recommendations to identify areas for improvement. Remove any unnecessary operations within the code path that might affect performance.
Remove unnecessary function calls
: Review your code. Identify any functions that aren't essential for the desired functionality and might negatively affect performance. For example, if a function call performs a validation that happened earlier in the code, you can remove that unnecessary function call.
Minimize logging operations
: Logging can be helpful for debugging and analysis, but excessive logging can affect performance. Evaluate the necessity of each logging operation and remove any unnecessary logging calls that aren't critical for performance analysis.
Optimize loops and conditionals
: Analyze loops and conditionals in your code. Identify any unnecessary iterations or conditions that you can eliminate. Simplifying and optimizing these structures can improve the performance of your code.
Reduce unnecessary data processing
: Review your code for any unnecessary data-processing operations, such as redundant calculations or transformations. Eliminate these unnecessary operations to improve the efficiency of your code.
Minimize network requests
: If your code makes network requests, minimize the number of requests and optimize their usage. Batch requests when possible and avoid unnecessary round trips to improve performance.
Minimize allocations
: Identify areas where excessive memory allocation occurs. Optimize the code by reducing unnecessary allocations and reusing existing resources when possible.
By minimizing allocations, you can improve memory efficiency and overall performance. Use the appropriate memory management and garbage collection strategies for your programming language.
Reduce data structure size
: Assess the size of your data structures, such as classes, and identify areas where reduction is possible. Review the data requirements and eliminate any unnecessary fields or properties. Optimize memory usage by selecting appropriate data types and packing data efficiently.
Assess cross-cutting implementations
: Consider the effects of cross-cutting implementations, such as middleware or token checks. Assess whether they're negatively affecting performance.
Tradeoff
: Optimizing code and hot paths requires developer expertise in identifying code inefficiencies. These highly skilled individuals might need to spend time on other tasks.
Evaluate the use of concurrency
Evaluating the use of concurrency involves assessing whether asynchronous processing, multithreading, or multiprocessing can maximize resource utilization and reduce expenses. By using asynchronous processing, multithreading, or multiprocessing, you can handle more tasks with the same resources. However, it's crucial to ensure proper implementation to avoid more overhead and to maintain cost-effectiveness.
To evaluate whether using concurrency is a good fit, you can follow these guidelines:
Asynchronous processing
: Asynchronous processing allows nonblocking execution. For example, you can start a process and then pause it to allow a second process to finish.
Determine the code components or operations that you can run asynchronously. Identify the programming language or framework that you're using and understand the asynchronous programming model that it supports, such as
async
/
await
in .NET or promises in JavaScript.
Restructure your code to use asynchronous programming constructs by enabling nonblocking execution of tasks. Decouple long-running or I/O-intensive operations from the main execution thread by using asynchronous methods or callbacks. Use asynchronous APIs or libraries that your programming language or framework provides to handle asynchronous workflows.
Multithreading
: In multithreading, you run multiple threads of a single process concurrently.
Identify sections of your code that you can run concurrently and independently. Read documentation or guidelines that are specific to the programming language or framework you're using for multithreading best practices. Create multiple threads or thread pools to handle parallel execution of tasks.
Implement synchronization mechanisms, such as locks, mutexes, or semaphores, to ensure thread safety and prevent race conditions when code accesses shared resources. Consider using higher-level abstractions, like thread pools or task-based parallelism libraries, to streamline the management of multiple threads and simplify concurrency control.
Multiprocessing
: Multiprocessing can have processes run in parallel. It can provide better utilization of multiple CPU cores than multithreading.
Determine whether the workload or operations in your code lend themselves to parallel processing. Identify the programming language or framework that you're using and explore its multiprocessing capabilities. For example, consider the multiprocessing module in Python or parallel streams in Java. Design your code to split the workload into multiple independent tasks that can be processed concurrently.
Use multiprocessing APIs or libraries to create and manage parallel processes. Distribute the workload among these APIs or libraries. To enable coordination and data sharing among multiple processes, implement communication mechanisms like interprocess communication (IPC), shared memory, or message passing, depending on your programming language or framework.
Use the right SDKs
For cost optimization, select SDKs that are designed to optimize resource usage and improve performance. It's important to evaluate the features and capabilities of each SDK. Consider its compatibility with your programming language and development environment.
Here's guidance to help choose the best SDKs for your workload:
Conduct performance testing
: Compare the resource usage and performance of SDKs through performance testing. Choose the SDK that best meets your needs in terms of resource optimization and performance improvement. Integrate the chosen SDK into your codebase by following the provided documentation and guidelines.
Monitor resource usage and optimize code
: Monitor resource usage with the implemented SDK. Gather insights from monitoring and analysis to optimize your code.
Choose the right operating system
Most coding languages can run on various operating systems, so it's important to evaluate your operating system against cheaper alternatives. If an alternative operating system supports the same or similar functionality at less cost, it's worth considering. By choosing a cheaper operating system, you can potentially reduce the cost of licensing fees and infrastructure costs.
The right operating system can contribute to overall cost optimization for your workload. To choose the right operating system for your workload, try these activities:
Evaluate your requirements
: Understand the specific needs of your workload, including the coding languages and frameworks that you're using. Consider any dependencies or integrations with other systems.
Consider compatibility
: Ensure the operating system you choose is compatible with your coding languages, frameworks, and any third-party libraries or tools you use. Check the documentation and community support for the operating system to ensure that it has good compatibility with your technology stack.
Assess functionality
: Determine if the alternative operating system supports the same or similar functionality as your current operating system. Evaluate whether it provides the necessary features and capabilities that your workload requires.
Compare costs
: Compare the costs associated with operating systems. Consider factors such as licensing fees, support costs, and infrastructure requirements. Look for cheaper alternatives that can meet your workload's requirements without compromising functionality.
Consider performance and optimization
: Evaluate the performance and optimization capabilities of the alternative operating system. Look for benchmarks, case studies, or performance comparisons to understand how it performs in real-world scenarios.
Review security and stability
: Assess the security and stability of the alternative operating system. Look for security updates, patches, and community support to ensure that the operating system is actively maintained and is secure and stable overall.
Consider vendor support
: Evaluate the level of vendor support that's available for the alternative operating system. Check if there are official support channels, documentation, and a community of users who can provide assistance if you need it.
Optimize network traffic
Optimizing network traversal is about minimizing network traffic between workload components. Data transfer often has an associated cost. By minimizing network traffic, you can reduce the amount of data that needs to be transferred while lowering costs.
Analyze your workload and identify any unnecessary data transfers between components. Avoid transferring redundant or duplicate data, and transmit only essential information. For example, if a component repeatedly requests the same data from another component, it's a candidate for optimization. You can refactor your code to reduce unnecessary calls or to batch requests, minimizing the data transferred. Applications might send entire objects or data structures when only a few fields are needed. By optimizing the code to send only the required data, you minimize the size of each data transfer.
Optimize network protocols
Network protocols play a crucial role in the efficiency of network communication. By optimizing network protocols, you can improve the overall efficiency of data transfer and reduce resource consumption.
Consider these suggestions:
Choose efficient protocols
: Select protocols that are known for their efficiency in terms of data transfer speed and minimizing overhead. For example, consider using protocols like HTTP/2 over HTTP/1.1. These protocols are designed to improve performance by reducing latency and optimizing data transfer. Use libraries and frameworks in your application to use these protocols.
Support compression
: Implement compression mechanisms in your network protocols to reduce the size of data being transferred. Compression can significantly reduce the amount of data transmitted over the network, leading to improved performance and reduced bandwidth usage. Server-side compression is typically enabled in the application code or server configuration.
Utilize connection pooling
: Connection pooling allows for the reuse of established network connections to reduce the overhead of establishing new connections for each request. Connection pooling can improve the efficiency of network communication by avoiding the overhead of connection setup and teardown. Choose a connection pooling library or framework and configure to meet workload needs.
Implement other optimizations
: Explore other optimizations that are specific to your workload and network environment. For example, you can use content caching, load balancing, and traffic shaping to further optimize network traversal.
Minimize network overhead
Minimize the amount of network traffic and data transfer between components of your workload. By reducing network overhead, you can lower costs associated with data egress and ingress and improve overall network performance.
Consider these techniques:
Reduce redundant requests
: Analyze the code to identify any duplicate or unnecessary requests. Instead of making multiple requests for the same data, you can modify the code to retrieve the data once and reuse it as needed.
Optimize data size
: Review the data being transmitted between components or systems, and look for opportunities to minimize its size. Consider techniques such as compressing the data before transmission or using more efficient data formats. By reducing the data size, you can decrease network bandwidth usage and improve overall efficiency.
Batch requests
: If applicable, consider batching multiple smaller requests into a single larger request. Batching reduces the overhead of establishing multiple connections and decreases the overall data transmission.
Use data serialization
: Data serialization is the process of converting complex data structures or objects into a format that can be easily transmitted over a network or stored in a persistent storage system. This strategy involves representing the data in a standardized format, so the data can be efficiently transmitted, processed, and reconstructed at the receiving end.
Select a serialization format that's compact, fast, and suitable for your workload's requirements.
Serialization format
Description
Protocol Buffers (protobuf)
A binary serialization format that offers efficient encoding and decoding of structured data. It uses typed definition files to define message structures.
MessagePack
A binary serialization format for compact transmission over the wire. It supports various data types and provides fast serialization and deserialization performance.
JavaScript Object Notation (JSON)
A widely used data serialization format that's human-readable and easy to work with. JSON is text based and has broad cross-platform support.
Binary JSON (BSON)
A binary serialization format that's similar to JSON but designed for efficient serialization and deserialization. BSON includes extra data types that aren't available in JSON.
Depending on the serialization format, you need to implement logic to serialize objects or data structures into the chosen format and deserialize them back into their original form. You can implement this logic by using libraries or frameworks that provide serialization capabilities for the format.
Optimize data access
Optimizing data access refers to streamlining the patterns and techniques for retrieving and storing data, to minimize unnecessary operations. When you optimize data access, you can save costs by reducing resource usage, reducing data retrieval, and improving the efficiency of data processing. Consider techniques such as data caching, efficient data querying, and data compression.
Use caching mechanisms
Caching involves storing frequently accessed data closer to the components that require it. This technique reduces the need for network traversal by serving the data from the cache instead of fetching it over the network.
Consider these caching mechanisms:
Use an external cache
: One popular caching solution is a content delivery network. It helps minimize latency and reduce network traversal by caching static content closer to consumers.
Tune caching parameters
: Configure caching parameters, such as time to live (TTL), to optimize the benefit of caching while minimizing potential drawbacks. Setting an appropriate TTL ensures that cached data remains fresh and relevant.
Use in-memory caching
: In addition to external caching solutions, consider implementing in-memory caching in your application. In-memory caching can help utilize idle compute resources and increase the compute density of allocated resources.
Optimize database traffic
You can enhance the efficiency of application communication to the database. Here are some key considerations and techniques for optimizing database traffic:
Create indexes
: Indexing is the process of creating data structures that improve the speed of data retrieval. By creating indexes on frequently queried columns, you can significantly reduce the time it takes to run queries. For example, if you have a table of users with a column for usernames, you can create an index on the username column to speed up queries that search for specific usernames.
Identify the most frequently accessed columns and create indexes on those columns to speed up data retrieval. Regularly analyze and optimize the existing indexes to ensure that they're still effective. Avoid over-indexing because it can negatively affect insert and update operations.
Optimize queries
: Design efficient queries by considering the specific data requirements and minimizing unnecessary data retrieval. Start by using appropriate join types (for example, inner join and left join), based on the relationship between tables. Use query optimization techniques such as query hints, query plan analysis, and query rewriting to improve performance.
Cache query results
: You can store the results of frequently run queries in memory or a cache. Subsequent executions of the same query can then be served from the cache, which eliminates the need for expensive database operations.
Use an object-relational mapping (ORM) framework:
Use ORM features such as lazy loading, caching, and batch processing to optimize data retrieval and minimize database round trips. Use ORM frameworks such as Entity Framework for C# or Hibernate for Java.
Optimize stored procedures
: Analyze and optimize the logic and performance of stored procedures. The goal is to avoid unnecessary computations or redundant queries in stored procedures. Optimize the use of temporary tables, variables, and cursors to minimize resource consumption.
Organize data
Organizing data for efficient access and retrieval involves structuring and storing data in a way that maximizes performance and minimizes resource consumption. It can improve query response times, reduce data transfer costs, and optimize storage utilization.
Here are some techniques for organizing data efficiently:
Partition
: Partitioning involves dividing a large dataset into smaller, more manageable subsets called partitions. You can store each partition separately to allow for parallel processing and improved query performance. For example, you can partition data based on a specific range of values or by distributing data across servers. This technique can enhance scalability, reduce contention, and optimize resource utilization.
Shard
: Sharding is a technique of horizontally dividing data across multiple database instances or servers. Each shard contains a subset of the data, and queries can be processed in parallel across these shards. Sharding can improve query performance by distributing the workload and reducing the amount of data that each query accesses.
Compress
: Data compression involves reducing the size of data to minimize storage requirements and improve the efficiency of data transfer. Because compressed data takes up less disk space, it allows for savings in storage costs. Compressed data can also be transferred more quickly over networks and reduce data transfer costs.
For example, consider a scenario where you have a large dataset of customer information. By partitioning the data based on customer regions or demographics, you can distribute the workload across multiple servers and improve query performance. You can also compress the data to reduce storage costs and improve the efficiency of data transfer.
Optimize solution design
Evaluate your workload architecture to identify opportunities for resource optimization. The goal is to use the right services for the right job.
To reach this goal, you might need to redesign parts of the architecture to use fewer resources. Consider serverless or managed services, and optimize resource allocation. By optimizing your architecture, you can meet the functional and nonfunctional requirements while consuming fewer per-instance resources.
Use design patterns
Design patterns are reusable solutions that help developers solve recurring design problems. They provide a structured approach to designing code that's efficient, maintainable, and scalable.
Design patterns help optimize the use of system resources by providing guidelines for efficient resource allocation and management. For example, the Circuit Breaker pattern helps prevent unnecessary resource consumption by providing a mechanism to handle and recover from failures in a controlled manner.
Design patterns can help cost optimize code in the following ways:
Reduced development time
: Design patterns provide proven solutions to common design problems, which can save development time. By following established patterns, developers can avoid repetitive work and focus on implementing the specific requirements of their applications.
Improved maintainability
: Design patterns promote modular and structured code that's easier to understand, modify, and maintain. They can lead to cost savings in terms of reduced debugging and maintenance efforts.
Scalability and performance
: Design patterns help in designing scalable and performant systems. Patterns like the Cache-Aside pattern can improve performance by caching frequently accessed data to reduce the need for expensive computations or external calls.
To implement design patterns, developers need to understand the principles and guidelines of each pattern and apply them in the code. Consider identifying the appropriate pattern for a problem, understanding its structure and components, and integrating the pattern into the overall design.
Various resources are available, such as documentation, tutorials, and sample code. These resources can help developers learn and implement design patterns effectively.
Change configurations
Regularly review and update your workload configuration to ensure that it aligns with your current requirements. Consider adjusting resource sizing and configuration settings based on workload demands. By optimizing configurations, you can effectively allocate resources and avoid overprovisioning to save costs.
Refactor architecture
Evaluate your workload architecture and identify opportunities for refactoring or redesigning components to optimize resource consumption. Consider techniques such as adopting a microservices architecture, implementing the Circuit Breaker pattern, and using serverless computing. By optimizing your architecture, you can achieve better resource utilization and cost efficiency.
Modify resource sizes
Continuously monitor and analyze the resource utilization of your workload. Based on the observed patterns and trends, adjust resource sizing and configuration settings to optimize resource consumption.
Consider rightsizing virtual machines, adjusting memory allocation, and optimizing storage capacity. By rightsizing resources, you can avoid unnecessary costs associated with underutilization or overprovisioning.
Tradeoff
: Reworking code and architecture might not fit with current project schedules and could lead to schedule and cost slippage.
Azure facilitation
Instrumenting code
: Azure provides monitoring and logging tools like
Azure Monitor
,
Application Insights
, and
Log Analytics
. You can use these tools to track and analyze the performance and behavior of your code in real time.
Identifying hot and optimize paths
: Application Insights and
Application Insights Profiler
help identify and optimize the hot paths in your code by analyzing execution times and resource usage. You can minimize unnecessary memory allocations and optimize memory usage with Profiler.
Using the right SDKs
: Azure offers
SDKs
in multiple programming languages, optimized for performance and ease of use. These SDKs provide prebuilt functions and libraries that interact with Azure services to reduce the need for custom implementation.
Optimizing network traversal
: Various Azure services support high-speed network protocols like
HTTP/2
and
QUIC
for efficient communication between services and applications.
Azure services, such as
Azure Database for PostgreSQL - Flexible Server
, support
connection pooling
.
Azure supports batch processing in various services, so you can group multiple operations together and run them in a single request. Batch processing can significantly improve efficiency and reduce network overhead.
Regarding data serialization, Azure supports various serialization formats, including JSON and XML. Choose the appropriate serialization format based on data size, performance requirements, and interoperability needs.
Optimizing data access
: Azure provides caching services like Azure Cache for Redis. You can use caching to store frequently accessed data closer to the application, which results in faster retrieval and reduced back-end load.
Indexing and query optimization:
Azure services like
Azure SQL Database
and
Azure Cosmos DB
provide indexing capabilities to optimize query performance. By choosing the right indexing strategy and optimizing queries, you can improve the overall efficiency of data retrieval.
Object-relational mapping (ORM):
Azure supports ORM frameworks like Entity Framework. These frameworks simplify data access and mapping between object-oriented code and relational or NoSQL databases.
Optimizing stored procedures:
You can use Azure services like
Azure SQL Database
to create and optimize stored procedures. Stored procedures can enhance performance by reducing network round trips and precompiling SQL statements.
Partitioning and sharding:
Azure offers partitioning and sharding capabilities in services like
Azure Cosmos DB
and
Azure SQL Database
. You can use partitioning to distribute data across multiple nodes for scalability and performance optimization.
Compressing data:
Azure services support data compression techniques like GZIP and DEFLATE.
Optimizing architecture
: Azure provides architectural guidance and design patterns for designing scalable, resilient, and performant applications. For more information, see
Design patterns
.
Related links
Azure Monitor
Application Insights
Log Analytics
Application Insights Profiler
Connection pooling
Azure Database for PostgreSQL - Flexible Server connection pooling
Azure SQL Database index tuning
Azure Cosmos DB indexing policies
Azure Cosmos DB partitioning
Azure SQL Database partitioning
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for optimizing component costs. - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for optimizing component costs
Article
2023-11-15
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:07
Optimize component costs. Regularly remove or optimize legacy, unneeded, and underutilized workload components, including application features, platform features, and resources.
This guide describes the recommendations for optimizing workload component costs. Optimizing component costs refers to the process of evaluating and improving the cost-efficiency of individual elements within a workload. It emphasizes the continuous review and potential removal or improvement of outdated, unnecessary, or rarely used components, such as application features, platform features, and resources. It also covers cost optimization of disaster recovery environments and how to avoid introducing unoptimized components. The guidance in this article applies to existing workloads that aren't in the design phase. Neglecting regular component optimization can lead to inflated costs, resource waste, and inefficient workloads that drain both time and money.
Definitions
Term
Definition
Application feature
A distinct capability within the application software that enables users to perform specific tasks or access specific information.
Platform feature
A specific functionality or capability provided by a platform. It can vary depending on the platform, but generally, platform features are designed to enhance the user experience, improve productivity, or enable specific tasks or actions.
Resource
A single entity or component that you can create, configure, and utilize within a cloud service provider.
Key design strategies
Optimizing workload components is about refining the various elements of a workload, including application features, platform capabilities, and resource. The goal is to ensure the workload uses all components efficiently and cost-effectively. Strategies include removing, modifying, and avoiding components that cause you to spend more than you need. The component cost optimization process ensures you allocate resources to features and components that deliver the most value, avoiding unnecessary expenses.
Optimize application features
Optimizing application features is the process of either removing, reinvesting, or monetizing application features based on value. It ensures you allocate resources to application features that provide the most value to customers. Optimizing application features helps avoid investing in features that contribute to technical debt or don't yield enough return on investment.
Evaluate application feature value
To determine the value of a feature, consider its effects on the overall application and the value it provides to the customers. Some factors to consider include:
Customer needs
: Assess how well the feature meets the needs and expectations of customers. Customer feedback, surveys, and usage data can be valuable in understanding the perceived value.
Business goals
: Evaluate how the feature aligns with the strategic objectives of the business. Consider how features support revenue generation, customer satisfaction, or competitive advantage.
Effect on user experience
: Determine the effect the feature has on enhancing the user experience and improving usability or productivity.
Differentiation
: Assess whether the feature provides a unique selling point or competitive advantage compared to other applications in the market.
Evaluate application feature cost
It's essential that you understand the cost associated with each feature for effective resource allocation and optimization. Consider various aspects when evaluating costs, such as:
Development effort
: Assess the time, resources, and expertise required to develop and maintain the feature or surrounding features. Underutilized features often become a key source of technical debt.
Maintenance and support
: Consider the ongoing costs associated with maintaining and supporting the feature, including bug fixes, security updates, and troubleshooting.
Infrastructure and resource utilization
: Evaluate the effect of the feature on infrastructure requirements, including server resources, storage, and bandwidth.
Integration complexity
: Assess the complexity and cost of integrating the feature with other systems or third-party services.
Performance considerations
: Evaluate the effect of the feature on the application's performance, including scalability, response time, and resource usage.
Review application feature value with stakeholders
Review the value of application features with stakeholders by engaging key personnel, such as product managers, software developers, and business analysts, to assess the value of specific features on business objectives. This collaboration is essential for cost optimization as it provides insights into maintenance efforts and identifies features that might hinder productivity or detract from developing new, valuable features. Your development team can give you important information about how much work it takes to maintain certain features. Encourage them to speak up about features that might be more trouble than they're worth, especially if these features distract the team from creating new ones.
Determine the future of the feature
Based on your analysis and evaluation, determine the future of the application features. Remove, reinvest, or monetize any application feature that doesn't provide a return on investment:
Removal
: Consider the planned end of life of an application feature based on data. Reasons for feature removal might include low customer demand, high maintenance costs, complexity, or redundancy that’s not worth the effort to fix. Create a plan for the removal, which might involve refactoring the code, updating dependencies, or reorganizing the UI.
Risk
: You can inadvertently remove features that are critical for certain users or scenarios and might negatively affect performance, operations, and security in your application.
Reinvest
: Some application features might not add enough value in their current state but could add value if you reinvest in them. Reinvestment means reworking or promoting the application feature. Prioritize the identified improvements based on their value and feasibility. Determine the roadmap and timeline for implementing the changes. Consider factors such as development resources, dependencies, and the potential effect on the application.
Monetize
: Turn application features into a revenue-generating opportunity via monetization. Sometimes features provide value to users but aren’t worth the current investment. Explore opportunities to monetize these features, such as offering them as separate paid add-ons or licensing them to other companies.
Optimize workload resources
Optimizing workload resources involves removing any resources that unused and optimizing any underutilized resources that the workload needs. This effort can save money, avoid waste, and ensure that the workload only uses the resources that add value.
Remove unused workload resources.
Unused resources are deployed services your workload or operations processes don't use. These resources might be long-term idled, orphaned, or forgotten. They provide no return on investment, and you should remove them. Common causes of unused resources include:
Alerts.
Demo builds.
Environment decommissioning.
Feature decommissioning.
IP addresses.
Network firewalls.
Proof of concept.
Snapshots.
Storage accounts.
Temporary testing environments.
Temporary triage environments.
To remove unused resources in a workload, consider these steps:
Take an inventory
: Conduct a thorough inventory of all resources within the workload across environments.
Find orphaned resources
: Resources can become orphaned when they're no longer needed or when their parent resources are removed. For example, you might remove a virtual machine, but its associated storage account isn't removed. Review your workload to identify unneeded or orphaned resources.
Remove idle components
: There’s typically a cost associated with a deployed resource. Even if the resource allows you to stop or reallocate, you might continue to pay for the resource. Consider removing idle resources. If you need the data, back it up first and then remove the resource. You’re better off redeploying the resource and restoring the data than allowing the resource to remain idle.
Optimize underutilized resources.
Underutilized resources represent wasted expenditure as you pay for resource capacity that isn't fully utilized. Identify and optimize these resources to reduce costs and allocate resources more effectively. To evaluate and optimize the cost of underutilized resources, follow these steps:
Monitor resources
: Use tools to monitor how much CPU, memory, and storage you actually use. Choose the best plan that matches your needs based on this information.
Analyze utilization
: Look at the data to find out which resources you don't use. Pay attention to the resources that have low usage over time or large differences in usage between busy and slow times.
Right-sizing
: Check if there are too many resources allocated to features that aren't in use. If so, adjust their size to better match what you actually need.
Automatic scaling
: Use automatic scaling to adjust the resources you use based on how busy you are. Make sure that you set a maximum scaling limit to avoid sudden spikes that can be costly and unnecessary.
After you make these adjustments, test to make sure everything still works as it should. Continuously monitor resource utilization and adjust resource allocation as workload demands change over time. Regularly review and optimize resource utilization to maintain cost efficiency and performance optimization.
Optimize disaster recovery resources.
Optimizing disaster recovery environments is about ensuring the resources allocated for disaster recovery are used efficiently. A warm (active-passive) disaster recovery strategy is a common source of underutilization. In a warm disaster recovery strategy, one environment receives all the load while the other environment is idle until there's a disaster scenario. To optimize a disaster recovery environment, consider how a hot (active-active), cold (active-off), or active-redeploy approach can help avoid underutilized resources. Here's an overview of these three disaster recovery approaches:
Hot plans
: Both the primary and secondary environments serve traffic concurrently. Your workload can balance loads between these environments and respond to demands in real-time. Distributing the load between two active environments, allows you to use cheaper resources, reduce single-point bottlenecks, and utilize capacities to the fullest. It can lead to reduced costs in terms of resource wastage or idling. A hot approach might demand more investment in synchronization and maintaining parity between the two environments.
Cold plans
: A cold disaster recovery model involves a standby environment that remains dormant until a disaster triggers the need for failover. Since the standby environment isn't actively running, costs related to compute, storage, and network operations are minimized. Your expenses revolve around storing backups, virtual machine (VM) images, or templates. Failover in the cold model can take longer because resources need to be booted up and data might need to be restored. Ensure that the recovery time aligns with your business's recovery time objectives (RTO) before committing to this approach.
Active-redeploy
: This strategy uses infrastructure as code. When a failover event occurs, you deploy the secondary environment, using predefined templates and scripts. With no predeployed compute resources in the disaster recovery environment, you save on the costs associated with maintaining idle resources. You only incur costs during the actual deployment in a failover scenario. Like the cold approach, this model might introduce longer recovery times, especially if the infrastructure's complexity is high. You should test and measure the recovery time to ensure it meets your recovery time objective.
Optimize platform features
Optimizing platform features involves eliminating or updating platform features, such as performance tiers and configuration settings, to optimize costs. It helps align spending with the requirements of the workload and avoids unnecessary expenses on unneeded features. Here are some tips to optimize the cost of platform features:
Know the capabilities of the things you purchase
: Before you can optimize, you need a clear inventory of the services and their features across your cloud platforms. Understand the features and functionalities of the platforms or services in your workload. Be aware of the specific tier you chose and the features each tier offers. For example, if you don't require autoscaling or advanced networking, a lower-tier plan might suffice.
Disable unused features
: Identify and disable platform features that cost money. You might have unneeded storage snapshots, unused disks, redundant security features, or underutilized networking capabilities.
Use the right versions
: Newer versions of a service can provide similar performance for the same price. For example, a virtual machine with newer hardware can often provide the same performance for less money.
Use the right configurations
: You might be paying for more availability or performance than you need. Eliminate availability or performance guarantees that the workload doesn’t need.
Eliminate unneeded automation
: Evaluate your automation processes and eliminate any unused automation that might incur extra costs.
Eliminate tool redundancy
: Get rid of tools that you don't need or tools that provide the same function. Evaluate potential redundancy in the tools you use for building software, writing code, security, and monitoring. For example, if you use GitHub Actions to build your software, you don't need to buy another tool that builds software. Before you buy features or tools, check if there's already a tool in your workload that can do the job. Eliminate tool redundancy to avoid wasted money and make the most of what you already have.
Be methodical in optimization efforts
Preventing unoptimized components is about proactively ensuring components are essential and optimized before adding or modifying. The best way to get rid of waste is to avoid it in the first place. Use strategies that prevent unnecessary expenses by addressing inefficiencies at the root, ensuring a workload runs cost-effectively from the outset. To help prevent waste, consider these strategies:
Find the root cause before changing solutions
: Before you fix a problem, make sure you know what's actually causing it. For example, if your website is slow, don't immediately switch to a new system. First, figure out why it's slow. You might find out that the real issue is something else, like bad database queries. Fix the real problem to save time and money.
Apply metadata
: Apply metadata to organize and track resources. You can use metadata to categorize and group resources, making it easier to track, delete, and avoid orphaned resources. Create a consistent metadata strategy across resources. Consider adding owners, the anticipated resource duration (for example,
sunset-30d
), or other tags.
Document nonstandard changes
: Document any changes made to your infrastructure or configurations performed outside the normal control process of your workload to cut unexpected costs. For example, you might increase a resource’s scaling (up or out) capacities to meet a short-term demand or triage an issue but forget to scale it back down. Make a list of nonstandard changes and use it as a reminder to revert the changes when they're no longer necessary.
Keep things simple
: Simplify your infrastructure and minimize complexity to help reduce costs. Use only the necessary resources and services that meet your requirements.
Azure facilitation
Optimizing application features
: You can use
Azure Monitor
and
Application Insights
to monitor the usage of your application and identify areas that are or aren't used. Based on the insights gathered, you can make informed decisions to remove or optimize unused or underutilized features.
Optimizing workload resources and platform features
: Azure Advisor provides
cost recommendations
provides recommendations to identify and eliminate unused resources. You can use Advisor to analyze your resource usage and receive suggestions about resources to remove or scale down. The
Cost Optimization workbook
in Azure Advisor serves as a centralized hub for some of the most commonly used tools that can help you drive utilization and efficiency goals. It offers a range of recommendations, including Azure Advisor cost recommendations. It also helps identify idle resources and manage of improperly deallocated virtual machines.
Azure Monitor supports
workbooks
. With Azure Monitor workbooks, you can find or create a workbook that finds and reports orphaned resources across a defined scope. You can use
Azure Automation
to shut down virtual machines during periods of inactivity. Resource shutdowns help reduce costs by minimizing the use of idle resources.
You can use the
autoscale feature
in Azure to automatically scale your application based on predefined conditions, so you don’t have to overprovision capacity. Automatic scaling can help you allocate resources efficiently and cost-effectively.
From a design perspective,
Azure load balancers
can distribute loads across availability zones and regions. These load balancers can help eliminate idle resources, for example, in disaster recovery approaches.
Related links
Recommendations for continuous performance optimization
Recommendations for defining reliability targets
Recommendations for highly available multi-region design
Recommendations for optimizing scaling and partitioning
Recommendations for setting spending guardrails
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for optimizing data costs - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for optimizing data costs
Article
2023-11-15
6 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:10
Optimize data costs. Data spending with data priority. Data optimization should include improvements to data management (tiering and retention), volume, replication, backups, file formats, and storage solutions.
This guide describes the recommendations for optimizing data costs for a workload. Optimizing data costs involves minimizing the expenses related to the storage and management of data according to its significance and access frequency. Appropriate data management can significantly reduce overhead costs and align spending with data utility. Neglecting to optimize data costs can lead to inflated expenses, inefficient resource allocation, and financial waste due to misaligned storage solutions and unnecessary data retention.
Definitions
Term
Definition
Data lifecycle management
The process of managing data throughout its entire lifecycle, from creation to deletion. This process involves organizing, storing, protecting, and archiving data based on its value and usage patterns.
Data redundancy
The practice of storing duplicate copies of data across multiple storage systems or locations. The purpose of data redundancy is to improve data availability and fault tolerance.
Data tiering
A storage strategy that involves categorizing data based on its access frequency and storing it on storage tiers accordingly.
Retention policy
The duration for which data should be retained before it can be deleted. It specifies the time period during which data must be preserved to meet legal, regulatory, or business requirements.
Key design strategies
Within a specific workload, you optimize data costs by reducing the expenses associated with storing and managing data. There are various strategies and best practices to minimize data storage and processing costs. The goal is to align data costs with data priority. You need to assign cost tiers to types of data based on their importance or frequency of access.
The primary drivers for the cost of workload data are access frequency, access latency, and storage amount. The following guidance contains strategies for optimizing costs across these cost drivers.
Take an inventory of data
Before you can optimize the cost of your data, you need to generate an inventory of data. Examine data access and determine its importance within your workload and its operations. Identify which data is accessed frequently and which data is accessed less frequently. The following inventory actions can help you allocate storage resources effectively:
Collect data access information:
Conduct a data audit to identify and catalog all data stores. Determine the value of data sets based on their importance to business operations, return on investment, and frequency of use. Gather access logs, usage metrics, or analytics from your data storage solutions.
Identify data types:
Categorize data based on its type, such as personal data, financial data, intellectual property, or operational data. Understand the sensitivity and criticality of each data type.
Identify access patterns:
Identify the patterns in data access, such as daily, weekly, or monthly usage patterns. You should understand latency, file sizes, and data freshness requirements for that data.
Prioritize data
Data prioritization is the process of categorizing and assigning importance levels to types of data based on sensitivity and criticality. Data priority should align with the importance of the environment. For example, production data is more important than preproduction data.
Assess the importance of various types of data to your workload by using these steps:
Define priority levels:
Establish priority levels for data (such as high, medium, and low) based on its value to the organization, regulatory requirements, and potential effect of data loss. The goal is to align data priority to the appropriate data solution.
Assign labels:
Label each data set with its sensitivity and criticality. You can apply labels at the row, column, or file level, depending on the data structure and usage. For databases, you can use a special tool to label and relate the sensitivity and criticality of data to specific rows and columns. This approach provides granular control over the management and access of data.
Optimize data management
Data management is the process of storing, moving, and securing workload data. By optimizing data management, you can align spending to data priority and derive more value from your data. Consider the following strategies for data management.
Optimize data lifecycle management
It's important to manage data throughout its lifecycle. Stages of the lifecycle include data creation (or acquisition), storage, usage, sharing, retention, and disposal (deletion or archiving). The goal of data lifecycle management is to optimize data storage solutions while complying with relevant regulations and policies.
Data storage has three critical cost components:
Storage cost
: The expense associated with storing data, such as per gigabyte.
Transaction cost
: Costs linked to data operations, such as write operations, read operations, and data retrieval (per gigabyte). Reading and writing data might have different costs.
Latency cost
: The expense associated with the speed or delay in accessing the data.
The following considerations are foundational to data lifecycle management:
Use data tiering:
The goal of data tiering is to align access and retention with the most cost-effective storage tier. Storage tiers range from frequent/immediate access (hot) to infrequent/delayed access (cold).
It costs more to use a tier that doesn't align with data access and retention needs. For example, data that your application accesses frequently should be in hot storage. Data that your application accesses infrequently should be in cold storage. Effectively managing these aspects helps ensure efficient data storage.
Consider compliance requirements:
Implementing data tiering requires careful consideration of compliance requirements and data governance policies. Compliance and legal requirements often drive data access and retention. Establish data retention policies to ensure compliance with legal, regulatory, and business requirements.
Define data lifecycle policies
. Data lifecycle policies specify when and how data should be moved between storage tiers based on predefined criteria. These policies ensure that you keep data in the appropriate tier for the required duration. For example, a policy can state that data must be retained in the hot tier for 30 days, in the cool tier for 90 days, and in the archive tier for one year. Set the retention period based on factors such as legal requirements, industry regulations, or internal policies.
Use automation
: Retention policies can trigger the movement of data between tiers. You should automate policies by using platform features before you build any custom solution.
When the retention period for a particular tier expires, the policy can automatically move the data to the next lower-cost tier. For example, when the retention period for the hot tier ends, the policy can move the data to the cool tier. The policy ensures that data is continuously optimized based on its access patterns and cost requirements.
Tradeoff
: Managing data retention policies requires ongoing monitoring and maintenance. It can introduce more overhead for data management processes. It might also affect storage costs. Longer retention periods or the use of higher-cost storage tiers can increase storage expenses.
Risk
: A poor implementation of data lifecycle management could lead to data loss or limited access to critical data. You should have proper backup and recovery mechanisms in place to mitigate the risk of data loss.
Optimize data segmentation
Optimizing data segmentation involves strategically organizing data into distinct segments and consolidate similar data types to efficiently allocate storage resources. It allows you to tailor allocation of storage resources to data priority.
To effectively optimize data segmentation, you categorize data by type and usage pattern. Then you place the data segments on the most-effective solution depending on their operational similarities and requirements. For example, you place data that requires high-performance storage on resources with faster retrieval time. Archival data uses a lower-cost resource with slower retrieval time.
This approach ensures that high-demand data uses faster storage for optimal performance and less accessed data uses cheaper storage. Similarly, when data types share usage patterns, you should group them together on a single resource to reduce overhead, simplify management, and improve data handling.
Minimize data transfer
Minimizing data transfer refers to the reduction of data movement across networks to decrease data transfer costs. It reduces the volume of data that the workload moves and lowers network usage fees. To minimize data transfer, consider the following recommendations:
Use the right location.
place data geographically closer to its users. Data proximity reduces network travel, which speeds up access and optimizes costs.
Use caching.
Consider the benefits of caching to minimize data transfer.
Use a content delivery network.
A content delivery network can store frequently read static data closer to users. It reduces data movement across the network and helps offload bandwidth usage.
Optimize security and compliance
Certain production data demands higher security and compliance requirements. These measures might impose extra costs related to data protection, encryption, backup, retention, and auditing.
You must ensure that changes in data storage solutions adhere to these requirements. Data that has lower security and compliance requirements often presents an opportunity to optimize cost.
Optimize data volume
Finding strategies to decrease the amount of data that you store can help reduce costs. By changing the accessibility of the data and implementing the following techniques, you can effectively optimize the volume of your stored data:
Capture less data
: Take a closer look at the data you're capturing. Determine if any of it's unnecessary for your purposes. Modify your process, settings, or configurations to capture only the essential data.
Compress data
: Compression saves money by reducing the size of data. It's most effective in write-once, read-never or read-rarely scenarios. It's more suitable for colder storage.
Tradeoff
: Both compression and decompression of data increase CPU time.
Delete unneeded data
: Implement policies to streamline the process of storing relevant information. Evaluate the retention period for backups and snapshots, and delete data that you no longer need. You might want to have a process that leads up to eventual data deletion, such as first archiving data and enabling a soft-delete period. Always consider recoverability before deleting data.
Deduplicate data
: Implement data deduplication techniques to eliminate redundant data. Deduplication reduces storage requirements by ensuring that you store only unique data blocks, so you save costs. Use hashing algorithms and comparison of data chunks. Regularly run deduplication processes to identify and eliminate duplicate data.
Optimize user behavior
: In workloads that collect user-generated data, educate users on the importance of efficient data storage. Encourage them to regularly review and delete unnecessary files and data. Implement storage quotas or pricing models that discourage excessive data storage.
Optimize data replication
Data replication involves creating multiple copies of data and storing them in other geographic locations or zones for reliability. Replication ensures that if one location or zone experiences a failure or outage, you can still access the data from the replicated copies in other locations.
This redundancy helps improve the availability and resilience of data. It minimizes the risk of data loss and downtime.
To optimize data replication for cost optimization, consider the following guidelines:
Evaluate data replication requirements
: Assess the specific needs of your workload and determine the level of data replication that it requires. Consider factors such as data criticality, recovery time objectives (RTOs), and recovery point objectives (RPOs).
Choose the right replication strategy
: Select a replication technology that aligns with your goals for cost optimization. Consider the service-level agreement (SLA) requirements for your workload.
Evaluate options such as synchronous replication, asynchronous replication, or a combination of both. Base the decision on factors like data consistency requirements and network bandwidth considerations. Assess the level of availability that you need for your workload, and evaluate the need for zonal versus regional redundancy.
Optimize network bandwidth
: Minimize the usage of network bandwidth by implementing compression and data deduplication techniques. These techniques can reduce the amount of data transferred during replication, which can save costs.
Monitor and optimize replication frequency
: Regularly review and adjust the replication frequency based on the changing needs of your workload. Fine-tuning the replication frequency can help optimize costs by reducing unnecessary replication overhead.
Optimize backups
A backup is a periodic snapshot or copy of data that you can create and store separately from the primary storage. If there's data corruption, accidental deletion, or system failure, you can use backups to restore the data to its previous state.
Here are some techniques for optimizing backups:
Data classification
: Classify your data based on its importance and prioritization for backup. Classification helps you to focus resources on backing up critical data while minimizing backup costs for data that's less important.
Incremental backups
: Instead of performing full backups every time, consider implementing incremental backups. Incremental backups capture only changes made since the last backup, which can reduce storage and network bandwidth requirements.
Tradeoff
: Incremental backups require more steps and time to restore data. You need to restore the full backup first and then apply each incremental backup in sequence until you reach the desired restore point.
Backup compression
: Enable compression during the backup process to reduce the size of backup files. Compressed backups require less storage space, so you can save costs.
Backup storage tiers
: Evaluate your backup retention policies and consider moving older backups to lower-cost storage tiers, such as cold storage or archive storage. Storing less frequently accessed backups in cost-effective storage options helps optimize costs.
Backup retention period
: Review and adjust the retention periods for your backups based on business requirements and compliance regulations. Maintaining backups for longer durations might lead to extra storage costs.
Backup frequency
: Analyze the backup frequency for various types of data. Adjust the backup schedule based on the frequency of data changes and the importance of the data. These practices help eliminate unnecessary backups and reduce storage costs.
Optimize file formats
File formats influence cost optimization by optimizing input/output (I/O) patterns and query patterns of your data. Some file formats cater to particular scenarios. Aligning the file format with your workload requirements can improve the workload's performance.
Here are considerations for common formats:
Avro
: The Avro file format is a good choice when you're dealing with write-heavy I/O patterns or when query patterns necessitate fetching multiple rows of records in their entirety. Avro's serialization and deserialization processes are efficient, so it's compatible with message buses like Kafka that produce a series of events and messages in quick succession.
Parquet and Optimized Row Columnar (ORC)
: The Parquet and ORC file formats excel in scenarios of read-heavy I/O patterns or when the query patterns focus on specific columns of the records.
Both formats are columnar storage, which means that data is stored column by column rather than row by row. Columnar storage allows for improved compression and efficient read operations. Only the required columns need to be fetched, so you avoid unnecessary I/O for irrelevant data.
Optimize storage solutions
Evaluate and select the most appropriate storage methods and systems for your data. This effort might include switching databases, using different storage types, or adding caching mechanisms. Ease of management is another factor to consider when you're choosing a storage solution.
By tailoring storage solutions to the specific needs and characteristics of the data, you can achieve better cost-effectiveness while meeting performance and scalability demands. There are costs associated with switching databases or swapping services, but storing data in the wrong storage solution can cost you extra money.
Here are a few use cases:
Switching databases
: You could consider switching to a database system that better suits your needs. For instance, if you're using a relational database, you might explore the option of moving to a NoSQL database if your data is more document oriented or requires flexible schemas.
Moving from a relational database to a flat file store
: In some cases, storing data in flat files instead of a traditional relational database can provide advantages such as simplicity and cost-effectiveness. Flat files are well suited for certain types of data, such as log files or data that doesn't require complex querying. For example, you can store binary images in a SQL database, but it's more cost-effective to store them in a storage service that's specifically for handling binary data.
Moving from infrastructure as a service (IaaS) to platform as a service (PaaS)
: IaaS database solutions can be time-consuming and resource-intensive properties that divert a technical team's attention from core tasks. The growth in data volume and the challenges of manual scaling, backups, and infrastructure maintenance can make a PaaS solution more cost-effective and efficient.
Adding a cache
: To reduce resource usage on the main database server, consider using a cache solution for caching complex query results. Rightsizing the database server might help in optimizing the cost. With applicable use cases, consider using time to live (TTL) with the cached data to reduce the storage needs and reduce the cost.
Query-optimized versus data storage stores
: Query-optimized stores are designed for fast data retrieval and analysis. They focus on quick data ingestion and reads but not frequent updates. They're great for time-series data and rapid access to recent data, but not for heavy transactional tasks.
Data storage stores handle large volumes of flexible data, especially unstructured or semistructured data. Although data storage stores can support analytics, complex tasks might need specialized databases. They're best for storing lots of variable data like logs or user-generated content in scenarios like NoSQL use cases.
Azure facilitation
Taking an inventory of data
:
Microsoft Purview
is a family of data governance, risk, and compliance solutions that can help your organization govern, protect, and manage your entire data estate. Microsoft Purview solutions provide integrated coverage and help address the recent increases in remote user connectivity, the fragmentation of data across organizations, and the blurring of traditional IT management roles.
Optimizing data management
: Azure Storage and Azure Data Lake Storage have different
data access tiers
. They also offer
data lifecycle management policies
that automate data tiering and retention.
You can use a rule-based policy to transition blob data to the appropriate access tiers or to expire data at the end of its lifecycle. This policy allows you to transition blobs from cool (or cold) to hot immediately when they're accessed, to optimize for performance.
Optimizing backups
: The
Azure Backup
service provides multiple capabilities to streamline your backups. It offers features such as native database backup and storage backup through disk snapshots. It supports virtual machine backup, long-term retention, and backup management.
Here are some of the service's features:
Monitoring
: You can use Backup center as a single pane of glass to monitor your jobs and backup inventory on a day-to-day basis. Backup center provides an interface to Backup reports, which use Azure Monitor Logs and Azure workbooks.
Reports
: Backup reports offer the following capabilities:
Allocate and forecast consumed cloud storage.
Audit backups and restores.
Identify key trends at various levels of granularity.
Gain visibility and insights into cost optimization opportunities for your backups.
Reserved capacity
:
Azure Backup Storage
reserved capacity offers you a discount on capacity for backup data stored for the vault-standard tier when you commit to a reservation for either one year or three years. A reservation provides a fixed amount of backup storage capacity for the term of the reservation.
Archive tier
: You can use Azure Backup to store backup data, including long-term retention (LTR) backup data, according to the retention needs that your organization's compliance rules define. In most cases, the older backup data is rarely accessed and is stored only for compliance needs. Azure Backup supports the backup of LTR points in the
archive tier
, in addition to snapshots and the standard tier.
Optimizing storage solutions
: Azure has many storage solutions. They offer various features and capabilities to help optimize costs based on your specific requirements. Azure has guidance to help you
choose the right data store
.
To choose the most suitable storage solution and configuration, it's important to assess your data access patterns, retention needs, and performance requirements. Regularly monitoring and optimizing your storage usage by using tools like Azure Advisor can help you further optimize costs.
Related links
Recommendations for consolidation
Microsoft Purview
Data access tiers
Data lifecycle management policies
Azure Backup Storage
Archive tier
Choose the right data store
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for optimizing environment costs - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for optimizing environment costs
Article
2023-11-15
6 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:08
Optimize environment costs. Align spending to prioritize preproduction, production, operations, and disaster recovery environments. For each environment, consider the required availability, licensing, operating hours and conditions, and security. Nonproduction environments should emulate the production environment. Implement strategic tradeoffs into nonproduction environments.
This guide describes the recommendations for cost optimizing workload environments. Each environment should be tailored for its specific purpose and optimized for cost effectiveness. It's important to make strategic tradeoffs and allocate resources where they matter the most, without compromising on critical components. By treating environments differently and optimizing them accordingly, you can achieve a balance between cost optimization and meeting the required objectives.
Definitions
Term
Definition
Recovery point objective (RPO)
The maximum acceptable duration of data loss during an incident.
Recovery time objective (RTO)
The maximum acceptable time that an application can be unavailable after an incident.
Service-level agreement (SLA)
A contractual agreement between the service provider and the service customer. The agreement defines the service-level objectives (SLOs). Failure to meet the agreement might have financial consequences for the service provider.
Key design strategies
The goal of optimizing environment costs is to find the right balance of value, cost, and risk for each environment, including production, preproduction, and disaster recovery (DR) environments. Customize each environment for its particular use to save money and efficiently use resources. Determine the benefits of each environment, like efficiency or customer satisfaction. You want to evaluate the return on investment (ROI) for the environment, even if it doesn't make a direct profit. Spend more money on high-risk environments to reduce issues and save money on low-risk environments. Aim to balance value, cost, and risk in each environment.
Assess environment value
Assessing the value of each environment means understanding its broader effect on business, gauging user satisfaction, and determining how it aligns with overarching organizational goals. This assessment helps you make informed decisions about resource allocation and align cost with environmental priorities. The essence of value extends beyond how much revenue an environment generates. When evaluating an environment's value, you need to prioritize spending in a manner that resonates with the goals of the workload. To assess the value of each environment, consider the following factors:
Consider the user
: Consider who uses each environment and what they need from it. For example, customers use the production environment, which must be reliable and meet specific SLAs for performance and uptime.
On the other hand, the development environment is mainly for the workload team, such as developers and testers. This environment doesn't have to meet customer-facing SLAs, but it should have the necessary tools and resources for the team to work effectively.
When you understand the unique needs of users in each environment, you can better allocate resources and avoid extra costs. This avoidance helps ensure each environment is functional and cost effective.
Align with organizational measures of value
: Align your cost-cutting efforts with your organization's priorities, like profit or employee satisfaction. For each environment, understand how success is defined, so you can keep your actions on target. For example, if your organization focuses on profit maximization or employee satisfaction, align your spending decisions with those metrics.
Determine environment costs
Determining environment costs is about knowing the costs of infrastructure, services, licenses, and operational expenses in each workload environment. Cost management tools are key to gaining insights into spending patterns and trends across environments. To determine environment costs, consider these strategies:
Identify cost drivers
: Identify the key factors that drive costs in each environment. These factors can include resource utilization, storage usage, data retention, data transfer, and specific services.
Evaluate risks
: Assess the risks that are associated with spending decisions and their potential effect on the environment and business operations. Consider factors such as data security, compliance, performance, audits, and SLA requirements.
Monitor and adjust your spending
: Continuously monitor and analyze spending patterns, value delivery, and risk factors. Regularly review and adjust your spending optimization strategies as the needs of the environment and business evolve.
Optimize the production environment
Optimizing costs in the production environment involves implementing strategies to reduce unnecessary expenses and improve operational efficiencies. Focus on differentiating production deployments and meeting the needs of users. Here are recommendations for optimizing the production environment:
Differentiate regions
: Spend less on regions that serve fewer customers. For example, you should invest more in a region that serves 90 percent of your users than in a region that serves 10 percent of your users. Adjust your deployment strategy to meet the requirements of each region and user segment.
Differentiate scaling
: Implement horizontal and vertical scaling strategies. Scale resources efficiently to meet demand without over-provisioning.
Differentiate infrastructure
: Choose cost-effective hardware and infrastructure solutions that meet the required performance and scalability. Consider factors such as performance, cost, reliability, and scalability.
Tune tenant models
: Customize the environment based on the tenant model. For example, spend more on services and features for paid tenants and spend less for nonpaying tenants.
Optimize disaster recovery environments
A DR environment refers to infrastructure and processes that a workload uses to recover after a disruptive event. Disruptive events include natural disasters, cyber attacks, and hardware failures. Balance the cost of maintaining a DR environment and the potential affects of a disruptive event. Consider the following strategies:
Evaluate the criticality of systems and data
: Assess the importance of systems and data to determine the required level of protection and resources for each component.
Determine RTOs and RPOs
: To help determine the design of the DR environment, define the acceptable downtime and data loss limits for each system or application.
Optimize a cold DR environment
: A cold DR environment has little or no infrastructure or running services. You can use infrastructure as code (IaC) to quickly deploy infrastructure during a disruptive event. Your backup and storage policies need to meet the RPOs and RTOs of the environment. Ensure that the amount and frequency of data backups isn't more robust than needed.
Tradeoff
: A cold DR environment is a cost-effective option, but you might have long recovery times.
Optimize a hot DR environment
: All infrastructure and services run in a hot DR environment. The data mirrors the primary site in real time. It provides near-instantaneous failover and minimal data loss if there's a disaster. Consider an active-active deployment to optimize costs.
Optimize a warm DR environment
: A warm DR approach is a middle ground between a cold DR environment and a hot DR environment. A warm environment is partially active and periodically syncs with the primary site. It offers a balance between cost and recovery time. However, it’s the least cost-optimized approach. Consider a cold or hot approach to optimize costs.
Optimize preproduction environments
Optimizing preproduction environments involves strategically managing resources within development, testing, and staging areas to closely simulate production while reducing unnecessary costs. Preproduction environments don't require the full scale and availability of production environments. The most opportunities lie in tailoring these environments to specific testing and development needs without duplicating production exactly. Areas of cost reduction include using lower-cost resources, turning off unneeded services, and applying discounts offered for preproduction usage. Consider the following strategies to optimize preproduction environments:
Evaluate preproduction environments
Insufficient or improper allocation of preproduction environments might lead to over-provisioning or under-provisioning of resources. To evaluate your preproduction environments for your workload, consider the following guidance:
Understand the environment types
: Identify the types of preproduction environments, such as development, testing, and staging, that you need for your workload. Each environment should have a defined role and specific function to ensure efficient resource allocation.
Align with users' requirements
: Before you set up preproduction environments, understand the requirements and expectations of your users. Tailor the features and specifications based on their needs to avoid unnecessary expenses of features or resources.
Consolidate the environment
: Determine if you can combine environments without compromising their functionality. Combine environments that have functions that don’t overlap. For instance, you can merge a user acceptance environment with a quality assurance environment. The functions are distinct, and one environment is usually idle when the other is in use.
Risk
: Be cautious when you combine environments to ensure that you don't introduce conflicts or compromise the testing or development processes.
The following table provides examples of common preproduction environments.
Preproduction environment example
Description
Development environment
Developers use this environment to write and test code. It provides a sandbox space, so developers can experiment, build, and integrate code changes.
Quality assurance environment
This environment is dedicated to quality assurance activities. It for testing to identify and fix bugs or issues before deploying to the production environment.
Security environment
This environment is for security testing. It's for ensuring an application is secure against threats and vulnerabilities.
User acceptance testing environment
In this environment, end users and stakeholders test an application to validate its functionality and ensure that it meets requirements and expectations.
Staging environment
This environment closely resembles the production environment. It's for final testing and validation before deploying to production.
Apply governance
Applying governance is about limiting deployment options in preproduction environments to control expenses and mitigate risks. In preproduction, you have flexibility to tailor configurations and deploy resources. The more the preproduction environment deviates from the production environment, the greater the potential risk. Use governance to constrain preproduction environments. Consider the following guidelines:
Limit performance tiers
: Evaluate the performance requirements of your preproduction environments. Choose performance tiers that balance cost and performance. A service often has different performance tiers, and some of these tiers are more suitable for testing. Some services have tiers that offer production-like features but don't come with an SLA. These services reduce costs but still provide the necessary functionality for testing and development.
Understand preproduction SKUs
: Some SKUs are designed for development environments. To optimize costs, evaluate services and tiers. Opt for low-performance tiers if the workload doesn't require high performance.
Control the number of instances and CPUs
: Determine the optimal number of instances and CPU resources that your preproduction environment needs based on workload demands. Avoid over-provisioning resources to minimize costs.
Limit retention and logging
: Define retention policies for logs and data in preproduction environments. Consider the necessary duration for retaining logs and data based on compliance requirements and cost considerations. Avoid excessive logging and retention to reduce storage costs.
Use a consistent CPU architecture
: Use the same CPU architecture in preproduction and production. For example, x86 applications don't run natively on Azure Resource Manager, and vice versa. Use the same CPU architecture as your production environment to ensure compatibility and minimize potential issues.
Use the same operating system
: Avoid changing the operating system (for example from Windows to Linux) or kernel in preproduction environments. Software built for Windows often doesn't run natively on Linux without a compatibility layer, and vice versa. The file systems and directory structures are different, which can cause application patching issues. Consistent environments help reduce the risk of compatibility issues and ensure smooth deployments.
Constrain scaling
: To optimize cost, you can constrain automation to mitigate runaway automation. For example, set a maximum scaling limit at three in the development environment, and set it at 10 in the production environment. Constrain scaling to help control the resource usage and automation cost.
Turn off unneeded resources
: Turn off resources when they aren't actively used, such as during off hours and weekends. You can use automation tools or scripts to schedule the shutdown and startup of resources. Some vendors provide APIs that you can use to programmatically stop and start the resources. Consider using IaC to create ephemeral environments that you can remove when you no longer need them.
Restrict available regions
: Consider the potential benefit of running preproduction environments in different regions where Azure resources might be cheaper. Restrict preproduction deployments to these regions to optimize the cost of these environments.
Balance similarity with production
It's often unnecessary and expensive for preproduction environments to mirror the production environment exactly. The goal is to ensure each preproduction environment is appropriately different from production to avoid unnecessary costs. However, when preproduction and production are different, there's a risk of deploying a bug into production. The more different these environments are, the more risk there is. Tailoring the preproduction environment to meet your needs can help you manage risks while optimizing cost. To balance the similarity with production, consider the following recommendations:
Avoid exact replicas
: Avoid making the preproduction environment an exact copy of production. It can unnecessarily increase costs. Create a preproduction environment that's cost-effective but enable you to uncover and address potential risks before deployment.
Avoid extreme deviations
: Avoid excessive deviation from production, like the use of different services. Different services might not accurately simulate real-world risks. Determine a risk threshold, and don't cross the threshold solely to save money.
Shorten runtimes
: Consider shortening the runtimes of processes in the preproduction stage to save money. Be cautious of new vulnerabilities that might arise, such as undetected memory leaks.
Review licenses
: Review the licensing plans for your security tools. If the number of nodes vary significantly between your production and preproduction setups, reassess your needs to fine-tune costs without compromising security.
Optimize development environments
Development environments are designed for development, testing, and debugging purposes. They have shorter lifecycles and are often created as needed and exist for a short time. Development environments typically have lower requirements for reliability, capacity, and security compared to other preproduction and production environments. They might have fewer capabilities and can accept lower resource utilization. To optimize your development environment:
Evaluate tooling
: Regularly assess the cost-effectiveness of your current tooling setup, including integrated development environments (IDEs), licenses, and related tools. Consider free or open-source alternatives that offer similar functionality without compromising quality. Continuously reevaluate the necessity and efficiency of these tools as the development landscape evolves.
Consider hardware
: Evaluate the cost and performance of your current hardware setups. Investing in better and more efficient hardware can enhance productivity and reduce long-term costs. Instead of frequent hardware replacements, consider upgrading existing systems to prolong their lifespan and improve performance.
Optimize the number of environments
: Analyze the advantages and disadvantages of individualized development environments versus a shared environment. Individual environments can mimic production setups, prevent interference among developers, and offer customized setups. However, scaling becomes more costly as the number of developers increases. Shared environments can save costs, but reliability concerns might arise if issues affect the entire development team simultaneously. Find the right balance based on cost, risk mitigation, efficiency, and developer satisfaction.
Regularly clean up
: Routinely clean up and optimize your development environment to avoid the accumulation of orphaned resources, unused data, and proof-of-concept experiments. Implement clean-up processes or automated tools to identify and remove unused resources. Keep only essential and active components. Regular clean-up helps reduce storage costs and ensures efficient resource utilization.
Implement sampled scaling
: Instead of scaling all components to their maximum capacity, consider a sampled approach in which you selectively scale vital components. This approach can be cost-effective while minimizing risks. Evaluate the risk-to-benefit ratio of not scaling certain elements and consider the potential effect on the environment.
Optimize data management
: Development environments might have low needs for data retention and backup frequency.
Consider endpoint emulation
You can optimize costs in a preproduction environment by using endpoint emulation or mock endpoints, particularly for expensive resources like GPUs. Identify components or services in your preproduction environment that are the most expensive or resource-intensive. Use mock endpoints to simulate the responses of these costly components without invoking them. To simulate API responses, you can use commercial or open source API mocking servers, or custom implementations.
Emulation and mock endpoints help save costs, but you must ensure that they represent the production environment to a sufficient degree for testing. Strike a balance between accuracy and cost to help avoid future issues in production. For example, if GPUs are a major cost factor, consider GPU emulation for tasks that don't require real GPU processing power in preproduction stages. Emulation might not fully represent the performance or quirks of real GPUs, so use it when exact GPU behavior isn't critical for preproduction testing.
Azure facilitation
Determining and optimizing environment costs:
Microsoft Cost Management
is a suite of tools that help organizations monitor, allocate, and optimize the cost of their Microsoft Cloud workloads. Cost Management is available to anyone with access to a billing or resource management scope.
Azure Advisor
is a tool that provides cost optimization recommendations, including identifying areas of virtual machine usage that need optimization. Use Advisor to help you make informed decisions and optimize costs in your Azure environment. Azure provides cost management tools and features that help prioritize spending. You can use these tools to track and analyze costs across environments, set budgets, and receive cost optimization recommendations.
Applying governance
: With Azure Policy, you can limit resource types, SKUs, and instances by defining policy rules that enforce restrictions on the types of resources that you can deploy in your Azure environment. You can maintain control over the provisioned resources and ensure compliance with your organization's policies and best practices.
To limit resource types by using Azure Policy, you can define policy rules that specify the allowed resource types. Apply those rules to the relevant Azure subscriptions or resource groups. Azure Policy prevents users from deploying resources that aren't allowed.
Use Azure Resource Manager to define and manage resources in a declarative manner. You can tune resources that are allocated to each environment based on their specific requirements. Use templates and parameterize resource configurations to optimize costs.
Optimizing preproduction environments:
Azure offers dev/test pricing options that provide discounted rates for nonproduction environments. You can allocate more resources and budget to critical production environments, which optimizes costs in nonproduction environments. You can also use the Azure licensing offer, Azure Hybrid Benefit.
You can use
Azure API Management
for API mocking. API Management acts as a facade to back-end services, which allows API providers to abstract API implementations and evolve back-end architecture without affecting API consumers.
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for optimizing flow costs - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for optimizing flow costs
Article
2023-12-20
6 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:09
Optimize flow costs. Align the cost of each flow with flow priority. When you prioritize flows, consider the features, functionality, and nonfunctional requirements of each flow. Optimizing flow spend often requires strategic compromises.
This guide describes the recommendations for optimizing the cost of each of the flows in your workload. Cost-optimizing the flows in a workload involves strategically allocating and managing resources to minimize expenses while maintaining performance. This optimization is crucial because it ensures efficient utilization of invested resources, reduces unnecessary expenditures, and improves the overall return on investment for the infrastructure. If you don't cost-optimize the flows in a workload, you risk overspending on resources, which results in inflated operational costs and diminished profitability.
Definitions
Term
Definition
Decouple
The strategy of removing a flow from a resource that contains multiple flows and placing it into a separate resource.
Flow
In a workload, the sequence of actions that performs a specific function. A flow involves the movement of data and the running of processes between components of the workload.
System flow
The flow of information and processes within a system. The system automatically follows this flow to enable user flows or workload functionality.
User flow
The paths or sequences of actions that users take within an application or system.
Key design strategies
Invest more in high-priority flows than in lower-priority flows. Aligning flow priority and spending can involve decoupling flows that currently share the same resource. It can also involve combining flows that have similar requirements but are run on separate resources. For example, suppose you have a web application that includes multiple flows, like user registration, sign-in, and data processing. These flows run on a single server, even though they have different resource needs. To optimize both costs and performance, you might separate flows or combine flows:
Separate flows
. For example, you might decouple the user registration flow from the others and move it to a dedicated, lower-cost server. This flow is important but not resource-intensive, so it's a good candidate for a less expensive server.
Combine flows
. For example, you might combine the sign-in and data processing flows, which both have higher resource requirements, and run them together on a high-performance server. Combining these flows enables the server to efficiently handle the resource-intensive needs of both flows. It optimizes performance and costs.
In a workload, there can be different types of flows or paths that you need to consider. This guide focuses on the following flow types:
System flows
. Optimizing system flows involves streamlining the communication and interaction between system components, minimizing bottlenecks, and ensuring efficient resource utilization.
User flows
. Optimizing user flows involves improving the user experience, reducing friction points, and ensuring smooth navigation and interaction within the application or system.
Create an inventory of flows
A flow inventory is a comprehensive list and description of all the sequences of actions, data transitions, and system interactions within a workload. A flow inventory is the first step to ensuring investments align with the priority of flows. You should only optimize flows when you fully understand their purpose and dependencies. Here are steps for creating an inventory of workload flows:
Document flows
. Start by documenting and listing all existing flows in your workload to get an understanding of the comprehensive state of the system. Include every sequence of actions, data transitions, and system interactions. Familiarize yourself with every component, like external services, databases, middleware, and third-party integrations. Additionally, track or estimate the volume of requests over time.
Visualize flows
. To get a clearer perspective, represent your findings visually, possibly in flowcharts or diagrams. Visualizations help you see the interdependencies between components. Consider using a tool like Visio to help you with the visualizations.
Categorize flows
. Bundle similar flows, taking into account attributes like their functionality (for example, authentication, data retrieval, and transaction processing), criticality to business, or the resources they use (CPU, memory, or bandwidth).
Prioritize flows
Flow prioritization is the process of classifying flows based on their influence on business outcomes, implications on user experience, and the resources they consume. Critical flows often require higher levels of availability, faster recovery times, and better performance to meet workload objectives. By prioritizing flows, you can better align spending to flow priority. To prioritize flows, consider the following steps:
Identify flow value
. When you optimize workload flow costs, you need to identify the flow that provides the most value. You don't want to spend more than a flow is worth. Instead of simply cutting costs, consider shifting costs to prioritize the more valuable flows. For example, your checkout flow is critical for business, but the purchase history isn't. You should allocate more resources and budget to the checkout flow.
Low-priority flows have lower expectations for availability, recovery, and performance. You can reduce costs by using cheaper configurations to reduce performance, availability, or business continuity spending.
Consider flow metrics
. If you're struggling to prioritize your flows, consider the availability and recovery goals that you assigned to them. Critical flows often have high availability requirements and service-level agreements (SLAs). Flows associated with a lower RPO and RTO are more important than flows that have a higher RPO and RTO.
Optimize independent flows
Sometimes your flows are already running on different resources. In these cases, you can more easily evaluate and optimize spending. Evaluate the components and processes involved in each independent flow to determine whether there are ways to optimize or simplify them. To optimize independent flows, you can follow these steps:
Eliminate unnecessary components
. Remove any extraneous elements that don't contribute to the flow's core functionality, thereby reducing complexity and cost.
Redesign the flow
. Consider redesigning the flow's architecture to enhance its efficiency. You might change the sequence of operations, reduce latency, or improve data transfer speeds, for example.
Choose an appropriate performance tier
. Different flows might have varying demands in terms of processing speed, memory, or other resource metrics. Make sure to choose a resource tier that aligns well with each flow's specific requirements.
Adjust scaling settings
. If a flow experiences variable demand, consider implementing autoscaling to dynamically adjust resources according to real-time needs, thus optimizing costs.
Fine-tune configurations
. Fine-tune other settings, like networking or data storage options, to better align with the flow's performance and budget requirements.
Separate dissimilar flows
Separating dissimilar flows onto different resources is a process of allocating distinct tasks with varying computational needs to dedicated resources. Dissimilar flows are flows that have different attributes. These attributes can include computational requirements, data dependencies, I/O operations, latency sensitivity, security needs, and compliance requirements. It's often more cost efficient to run different types of flows on separate resources. Doing so enables precise resource allocation to each flow, which reduces unnecessary expenditures and ensures maximum efficiency.
Consider separating dissimilar flows that are currently combined. This separation boosts scalability, fault tolerance, and adaptability and also streamlines costs. By ensuring that each flow operates independently, you reduce interference risks and can allocate resources more cost-effectively based on each flow's priority. For example, assume that you colocate CRM (user flow) with a data engine (data flow). User traffic to the CRM system during office hours might slow down the data engine. When you decouple flows, the data engine can scale each component or service independently based on workload demand. This decoupling optimizes resource allocation and reduces costs.
Combine similar flows
Combining similar flows onto a single resource is a process of consolidating tasks or processes with comparable attributes and using shared resources for them. This strategy eliminates redundancies and ensures more efficient use of resources, leading to significant cost savings. Similar types of flows share similar attributes. You might consider the same attributes that you look at when you separate dissimilar flows: computational requirements, data dependencies, I/O operations, latency sensitivity, security needs, and compliance requirements. Here are some examples where combining similar workload flows to use the same resource can lead to substantial savings:
Web servers
. Instead of dedicating separate web servers for each application, consider consolidating them, especially if their traffic isn't consistently high. A shared web server, paired with a reverse proxy, can effectively manage and route traffic to multiple applications.
API gateways
. Rather than maintaining individual API gateways for separate microservices or applications, you can use a centralized API gateway to streamline requests and direct them to the relevant service. Doing so makes management easier and also reduces costs.
Log processing
. Instead of having multiple applications or services that each operate their own log processing instances, consider directing them all to a shared log processing tool. This approach minimizes the number of active instances, which translates to direct cost savings.
Authentication services
. If multiple applications deploy their own distinct authentication mechanisms, redundancy is introduced. Integrating a single sign-on (SSO) solution or a communal authentication service reduces this duplication and optimizes resource usage, which reduces costs.
Risk
: Don't mistake coincidence with design. Two flows that look similar don't necessarily serve the same purpose. You need to understand the function and design of each flow before merging or changing them. Misinterpreting a flow by focusing solely on its appearance can lead to unintended consequences and disrupt the service or process that it supports. If multiple flows serve the same function and there are no discernible differences in their design or intent, consider consolidating them.
Monitor flows continuously
The nature of flows and workloads can change over time, so you need to review flow spending to ensure that costs align with priorities. Evaluate the resource utilization of each flow by analyzing the compute, storage, and network usage associated with each flow. Identify any inefficiencies or areas where resources are underutilized. This analysis helps you pinpoint opportunities for cost optimization. Here are some considerations to take into account when you review flow utilization:
Analyze usage patterns
. Analyze the usage patterns of the flows. Some flows might be more active during certain times of the day or month, while others might have a consistent load. By understanding these patterns, you can predict resource needs and adjust allocation to avoid bottlenecks and overprovisioning.
Monitor relevant metrics
. Determine the metrics that can help you assess the efficiency and cost-effectiveness of each flow. Consider CPU utilization, data transfer costs, transaction costs, and storage footprint. Use monitoring tools to gather detailed metrics about resource usage and performance.
Consider ongoing maintenance
. Consider the cost of maintenance, especially when you use infrastructure-as-a-service solutions like virtual machines. You need to account for activities like patching, upgrades, backups, monitoring, and security.
During your analysis, identify any inefficiencies or areas where resources aren't utilized effectively. Consider idle compute instances, unused data, and low network bandwidth. These inefficiencies can indicate opportunities for cost optimization.
Azure facilitation
Prioritizing, optimizing, and monitoring flows:
The
User Flow tool
in Application Insights provides a visual representation of user navigation across your site’s pages and features. This tool aids in identifying areas where users frequently leave, repeat actions, or follow specific paths. By comparing actual user behavior with your anticipated outcomes and objectives, you can identify critical flows. It also allows you to optimize potential issues such as high churn rates, repetitive actions, or design flaws. The tool also allows for custom property filtering through dimensions, offering a more tailored analysis.
Azure Monitor
helps you gain insights into the performance and health of your applications. It provides monitoring and diagnostics capabilities. These capabilities enable you to identify performance bottlenecks, optimize resource utilization, and detect and troubleshoot issues that might affect costs.
Log Analytics
is a tool that enables you to collect, analyze, and visualize log data from various sources. By using Log Analytics, you can gain insights into your application and infrastructure logs, identify trends, and optimize costs by managing usage and data retention. Consider colocating logs and using dedicated solutions instead of shared ones to better manage costs.
Related links
User Flow tool
Azure Monitor
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for optimizing personnel time - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for optimizing personnel time
Article
2023-11-15
6 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:13
Optimize personnel time. Align the time personnel spends on tasks with the priority of the task. The goal is to reduce the time spent on tasks without degrading the outcome. Optimization efforts should include minimizing noise, reducing build times, high fidelity debugging, and production mocking.
This guide describes the recommendations for optimizing personnel time. This optimization is a strategic process of maximizing the productivity and efficiency of employees that design, implement, and operate the workload during their working hours. It involves aligning their skills, strengths, and tasks in a manner that ensures that every hour they spend at work is used most effectively. The goal is to eliminate wasted personnel potential and capabilities. Failure to optimize personnel time can lead to employee burnout, reduced competitive edge, and reduced productivity.
Definitions
Term
Definition
Noise
Irrelevant or misleading information that can distract from actual issues or trends.
Signal
Meaningful and relevant information that provides insights into the behavior and performance of a system or application.
Technical debt
The accumulated inefficiencies, suboptimal design choices, or shortcuts intentionally taken during the development process to deliver code faster.
Key design strategies
Personnel typically create the most significant expense in a workload. Personnel cost and value underscore the importance of efficient time management. This guide is about maximizing the potential of every hour worked. Given that employees can't work all day and night, the emphasis is on ensuring that each person is more effective within their designated hours or equally effective in a reduced timeframe. The goal is to achieve better utilization of their time for the benefit of the individual and the workload.
Set optimization targets
Setting personnel time optimization targets is a process of establishing clear, measurable goals. These targets serve as guidelines for desired improvements in tasks and functions. You can use these benchmarks to evaluate outcomes against the targets. First, define the metrics for measuring the success of personnel time optimization efforts. Determine the specific objectives that you want to achieve through optimization. Example objectives might be to reduce time spent on administrative tasks or to reduce the time it takes to respond to customer inquiries. To set targets for personnel time optimization, consider the following strategies:
Select quantitative metrics
: Choose metrics that align with your objectives and can be measured accurately. Consider metrics like time saved, productivity increases, efficiency improvements, and task completion time.
Gather qualitative metrics
: In addition to quantitative metrics, gather feedback from personnel to measure their satisfaction with their roles. This feedback can provide valuable insights into the effects of personnel time optimization efforts on employee morale and engagement.
Set targets
: Set realistic and achievable targets for each selected metric. These targets should be based on the current performance levels and the desired level of improvement.
Optimize development time
Optimizing development involves refining the software development processes to achieve greater efficiency. As a result, developers can invest more time in refining features, innovating within the constraints of a particular workload, and addressing any unique challenges that the workload presents.
Keep features lean
When you design and customize features, keep them lean and simple. Avoid unnecessary complexity and configuration options that can increase the time required to develop, test, and maintain the workload. Keeping the workload simple and focused leads to easier adaptability and optimization over time.
Reduce build times
Reducing build times is the process of minimizing the time it takes to compile and generate a deployment. Shorter build times enable developers to spend less time waiting for builds to finish and allows them to focus on writing code and delivering features. Reducing build times also helps ensure that developers receive feedback on their code changes more quickly. Quicker feedback allows them to iterate and fix issues faster, which supports the Agile development model. Faster build times facilitate more frequent builds, enabling teams to adopt Agile development practices like continuous integration and continuous delivery (CI/CD). Here are some strategies for reducing build times:
Optimize build configurations
: Review the build configuration settings and eliminate unnecessary steps or processes that add overhead to the build process. Checkpointing builds and combining partial builds with prebuilt builds can help reduce build times and improve efficiency. This approach enables you to reuse previously built components and build only the necessary parts, which leads to faster build times and reduced time investment.
Parallelize build tasks
: Identify tasks that can be run simultaneously and configure the build system to run them in parallel. Take advantage of available computing resources.
Use caching
: Cache dependencies, intermediate build artifacts, and other reusable components to avoid redundant work during subsequent builds.
Use incremental builds
: To avoid unnecessary recompilation, implement techniques that allow the build system to rebuild only the parts of the deployment that changed since the previous build.
Distribute the build process
: If applicable, distribute the build process across multiple machines or build agents to use parallelism and reduce overall build time.
Optimize infrastructure
: Ensure that the build environment has sufficient resources, like CPU, memory, and disk I/O, to handle the build.
Use production mocking
By mocking components or services, developers can isolate their code for focused testing by simulating dependencies. Mocking enables developers to create specific scenarios and edge cases that are difficult or impractical to reproduce in a real production environment. It can speed up testing cycles, facilitate parallel work, and eliminate troubleshooting dependencies. Here are some approaches to implementing production mocking:
Mocking frameworks
: Use specialized mocking frameworks or libraries that enable you to create mock objects, stubs, or fakes to replace dependencies.
Dependency injection
: Design your application to use dependency injection, which enables easy substitution of real dependencies with mock objects during testing or debugging.
Service virtualization
: Use service virtualization tools or techniques to simulate the behavior of external services or APIs. Doing so enables developers to test integrations without accessing the real services.
Configuration-driven mocking
: Implement a configuration-driven approach in which the application's behavior can be modified via configuration settings or flags to enable mocking as needed.
Dynamic and conditional mocking
: Design the application to support dynamic and conditional mocking, which enable developers to switch between real and mock components depending on specific conditions or scenarios.
Optimize the development environment
The goal is for developers to get fast feedback on changes. Make necessary technology changes to improve the development experience.
Containerization
: Consider containerizing the workload to run locally. Containers help developers replicate the production environment locally and test their changes quickly. They enable faster iteration and debugging, which leads to a more efficient development process. Containers also provide a consistent and isolated environment for running the application. Finally, they enable easy scaling and deployment of the application.
Developer workstations
: An optimal developer workstation should have a suitable integrated development environment (IDE). A good developer workstation boosts developer efficiency, reducing the time and resources needed for various tasks. A good IDE provides code completion and syntax highlighting tailored to the programming language. It should also support version control like Git. A well-equipped IDE enables developers to pinpoint and fix issues quickly during development, which reduces debugging time.
Developer environments
: Developers' environments shouldn't be too constrained. Developers should have the permissions necessary to complete tasks without undue restrictions so they can work efficiently and effectively.
Optimize preproduction environments
In general, the closer preproduction environments are to production environments, the more time you save. This increased consistency also helps to minimize risk. The closer the two environments are, the better you can test and validate the functionality and performance of your releases before deploying them to the production environment. This similarity in environments helps you identify and address any issues or bottlenecks early on, which reduces the risk of problems occurring in the production environment.
Tradeoff
: You need to balance personnel time against resource costs. The closer an environment is to the production environment, the more it costs.
Reuse components and libraries
Reusable components and libraries can save developers substantial amounts of time. Instead of writing, testing, and debugging code, developers can reuse validated components and libraries and develop or fix application features faster. Be sure to provide documentation for each component or library. Store the code and documentation in a central repository that has version control like GitHub.
Additionally, use open-source software or libraries from trusted publishers that are available in package managers, like NuGet or Maven. These package managers provide a centralized and reliable source for accessing and managing libraries. Using trusted libraries from package managers can further enhance productivity and reduce the time spent on developing and maintaining code.
Remove technical debt
Removing technical debt is essential for maintaining a healthy and efficient codebase. By following specific standards and implementing mechanisms like quality gates, you can effectively address technical debt and improve the overall quality of your code. Here's how you can incorporate this guidance into your approach:
Allocate time to resolve technical debt
: Dedicate a portion of your development team's time to resolving technical debt. A good starting point is to allocate about 20% of the team's time specifically to addressing technical debt. The dedicated time enables developers to focus on refactoring, code cleanup, and improving the overall quality of the codebase.
Empower the development team
: Allow the development team to own the prioritization of technical debt resolution. The development team is in the best position to identify areas of the codebase that require attention and understand the effects of technical debt on workload functionality. Encourage open communication and collaboration within the team to ensure that technical debt is addressed effectively.
Prioritize
: Prioritize technical debt items based on their effects on workload functionality. Focus on addressing the issues that have the most significant effect on the performance, maintainability, and scalability of the workload. By prioritizing effectively, you can maximize the effects of your efforts to remove technical debt.
Removing technical debt is an ongoing process. It requires a proactive approach and continuous effort from the development team. By setting and adhering to specific standards in the codebase and implementing mechanisms like quality gates, you can effectively address technical debt and create a cleaner, more maintainable codebase:
Set coding standards
: Establish clear and specific coding standards that define the desired structure, style, and best practices for your codebase. These standards should cover areas like naming conventions, code formatting, documentation, and error handling. By adhering to these standards, you ensure consistency and readability throughout the codebase.
Implement quality gates
: Quality gates are mechanisms that enforce the defined coding standards and catch potential issues early in the development process. They can include automated code reviews, static code analysis tools, and continuous integration pipelines. By integrating quality gates into your development workflow, you can identify and address code quality issues before they become technical debt.
Optimize personnel collaboration
Optimizing personnel collaboration is a process of enhancing team dynamics, communication, and knowledge-sharing. The goal is to prevent misunderstandings, duplicated efforts, and wasted time. It involves breaking down silos, revising unnecessary standards, creating shared knowledge repositories, and investing in relevant training. Effective collaboration reduces repeated errors and maximizes the collective expertise of a team. To optimize personnel collaboration, consider the following strategies:
Eliminate silos
: Silos can lead to a lack of shared knowledge and unnecessary replication of tasks. Cross-functional collaboration can save time and improve results. Break down barriers between departments or teams to promote inter-departmental cooperation. Foster cross-departmental meetings, workshops, and joint projects. Encourage open communication channels across teams.
Optimize standards
: Unnecessary standards can lead to wasted time and resources without contributing to better outcomes. Assess, improve, or eliminate standards or protocols that don't add value but increase the workload. Periodically review standards and protocols. Get feedback from ground-level employees. If a standard doesn't add value, consider eliminating or revising it.
Create a shared knowledge repository
: A shared knowledge base prevents repeated mistakes, aids training, and reduces the time spent searching for information. Develop a centralized place where all members can access and contribute to collective knowledge. Employ knowledge management tools, regularly update the repository, and incentivize contributions from team members.
Invest in training
: Make a substantial investment in training for the processes, tools, and project. Doing so ensures that a baseline requirement is met before people start contributing to the project. Ensure that teams are trained on the established standards and processes to enable them to work efficiently and effectively within the defined guidelines. Team members should be trained on those standards and processes so that they don't waste effort identifying them on their own.
Optimize processes
Optimizing processes involves refining workflows to eliminate unnecessary steps, reduce manual effort, and streamline roles and change management. This enhancement ensures that tasks are more efficient. Streamlined processes reduce the time and resources needed for tasks. The time reduction leads to improved productivity and saves money. To optimize processes, consider these recommendations:
Refine the software development lifecycle (SDLC) approach
: Adopting an optimal SDLC can help you achieve high quality with less overhead. Assess your current SDLC method and consider more efficient alternatives. Explore and adopt methodologies like Scrum, Kanban, or Waterfall. Periodically reassess chosen frameworks for better efficiency, recognizing that SDLC is inherently collaborative.
Optimize per role
: Defined roles ensure clear responsibilities and expectations and increased efficiency. Understand and define the requirements of each role, including, for example, developers and solution architects. When you want to expand the team, you should know what each role needs in terms of hardware, licenses, and access.
Streamline change management
: Positive receptiveness to change ensures smoother transitions and better outcomes. Make the process of implementing change smooth and accepted. Cultivate a culture of active participation rather than resistance. Promote change adoption via coaching and continuous learning. Adapt to change constructively.
Optimize operational tasks
Optimizing workload operational tasks is a process of making job tasks faster and more straightforward. The goal is to streamline activities to enhance efficiency and ensure the most effective use of resources. This streamlining ensures that tasks are completed with fewer errors, distractions, and delays. It conserves personnel time, which leads to faster decision-making, reduced troubleshooting durations, and overall improved efficiency and cost savings. To optimize operational tasks, consider the following strategies.
Reduce the noise-to-signal ratio
Distinguishing signal from noise is crucial to observability because it enables teams to focus on the most critical aspects of their systems and applications. Filtering out noise can help teams make informed decisions, troubleshoot problems, and optimize the workload faster. Identifying and addressing issues more efficiently and quickly leads to a reduction in personnel costs.
To differentiate signal from noise, you need to define clear objectives and metrics. Identify the key performance indicators (KPIs) and metrics that are relevant to your workload. Establish thresholds or ranges for each metric to specify normal behavior and what should be flagged as an anomaly. Use monitoring tools to collect data and track the defined metrics in real time and identify patterns that indicate potential issues or areas of improvement.
Prioritize actionable insights. Focus on insights that point to degradations in the workload and prioritize them for further investigation or action. Regularly review and update your monitoring strategy based on feedback.
Use high fidelity debugging
High fidelity debugging
refers to the ability to accurately diagnose and fix issues in software applications. You gain detailed insights into the application's behavior and state during runtime. High fidelity debugging is crucial for effective software development and troubleshooting. With high fidelity debugging, developers can reproduce and analyze issues with greater precision, which reduces the time and effort required to fix bugs. An understanding of the application's behavior enables developers to make informed decisions faster to improve code quality.
Use a debugging tool
: Use a feature-rich debugger that provides comprehensive insights into the application's execution flow, variables, and memory state.
Enable detailed logging and tracing
: Instrument code with logging and tracing statements to capture relevant information during runtime. Doing so helps you diagnose issues.
Analyze error messages and stack traces
: Carefully examine error messages and stack traces to understand the context and sequence of events leading to an issue.
Enhance technical support
Improve the efficiency and efficacy of technical support operations. Reducing recurring issues saves time and improves user satisfaction. Identify recurring support issues, integrate engineering and support teams via support shadowing, and adopt IT classic deployment model processes to reduce overall support load.
Learn from incidents
Analyzing incidents can prevent recurrence and improve reaction times. Use past incidents as learning opportunities for future improvement. Conduct retrospectives to analyze incidents, identify improved actions and contact protocols, and enhance system observability through comprehensive logs and metrics.
Implement robust governance
Standardization reduces errors and rework to ensure consistent quality and cost optimization. Strengthen compliance and standardization within your organization. Automate compliance checks, and advocate for standardized solutions, architectures, and blueprints. To streamline decision-making, minimize choices that don't align with organizational constraints or SLAs.
Optimize personnel skills
Better skills lead to increased efficiency and fewer mistakes. Invest in the development and improvement of your team's skills. To optimize personnel skills, here are some recommendations to consider:
Upskilling
: Ensure that team members have essential cost optimization and monitoring skills. Provide sandbox environments for hands-on learning and skill development. Encourage team members to obtain certifications, and promote shadowing with experienced colleagues.
Tools
: Proficiency with tools is a key skill for optimizing tasks and gaining valuable insights for cost management. Ensure that personnel are proficient with essential tools and can adapt to new ones. Prioritize familiarity with key tools, especially tools that are related to monitoring. Train personnel to extract meaningful insights from data across various layers of the system, emphasizing the link between effective monitoring and cost management.
Aligned expertise
: Match employees to tasks based on their skills and expertise. Utilize their strengths and allocate tasks accordingly to maximize efficiency.
Azure facilitation
Setting optimization targets
:
Azure DevOps
provides a suite of tools for defining objectives, selecting metrics, and setting targets. It offers features like work item tracking, dashboards and reporting capabilities. It also provides source code management, continuous integration, continuous delivery, and project management features. By using Azure DevOps, teams can automate processes, collaborate effectively, and reduce manual effort.
Optimizing development time
: Azure provides various tools and features to optimize developer time, including:
Development environments
: Azure offers development environments in multiple forms, like Microsoft Dev Box, which provides Windows and Linux VMs on which developer tools are installed. Microsoft also provides Docker VMs for containerized development and Azure Container Registry, which enables Docker builds.
Integration with Azure DevOps
: Azure integrates with Azure DevOps to enhance productivity and streamline development processes.
IDE integration
: Azure provides IDE integration with popular development tools like Visual Studio and Visual Studio Code. This integration enables developers to seamlessly work with Azure services.
Standard SDKs and libraries
: Azure provides standard SDKs and libraries for all Azure services. These SDKs and libraries enable developers to reuse code and reduce the time it takes to integrate and implement Azure services.
Quickstart templates and samples
: Azure provides quickstart templates and samples that can accelerate the development process.
Package managers and standard libraries
: Azure supports package managers and provides standard libraries, like the NuGet package manager. They can simplify development and help developers reduce the time they spend on implementing common functionalities.
Open-source support
: Azure has a strong ecosystem that supports open-source technologies, so developers can use existing open-source tools and frameworks to optimize their time.
These features and tools provided by Azure help developers save time and increase productivity in their development workflows.
Optimizing operational tasks
: Azure supports infrastructure as code (IaC) capabilities, which enable you to define and manage your infrastructure by using code. Doing so helps reduce complexity and improves the adaptability of your systems.
Azure Monitor is a comprehensive monitoring service that provides visibility into the performance and health of applications and infrastructure on Azure. You can use it to collect telemetry, set up alerts, and gain real-time insights. By using Azure Monitor, you can proactively identify and resolve issues. It enables you to reduce the time you spend on troubleshooting.
Azure Automation
provides a way to automate manual, repetitive tasks on Azure. You can use it to create and manage runbooks, which are sets of instructions for performing specific tasks. By automating routine tasks, you can save time and free up personnel to focus on more critical activities.
Optimizing personnel skills
: Microsoft provides a comprehensive suite of
training
materials and activities. Training is available for developers, architects, and business stakeholders.
Related links
Azure DevOps
Azure Automation
Microsoft training
Community link
McKinsey & Company: Measure software developer productivity
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for optimizing scaling costs - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for optimizing scaling costs
Article
2023-11-15
4 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:12
Optimize scaling costs. Evaluate alternative scaling within your scale units. Consider alternative scaling configurations, and align with the cost model. Considerations should include utilization against the inherit limits of every instance, resource, and scale unit boundary. Use strategies for controlling demand and supply.
This guide provides recommendations for optimizing scaling costs. Cost optimizing scaling is the process of removing inefficiencies in workload scaling. The goal is to reduce scaling costs while still meeting all nonfunctional requirements. Spending less to get the same result. Optimizing scaling allows you to avoid unnecessary expenses, overprovisioning, and waste. It also helps prevent unexpected spikes in costs by controlling demand and capping supply. Inefficient scaling practices can lead to increased workload and operational costs and negatively affect the overall financial health of the workload.
Definitions
Term
Definition
Autoscaling
A scaling approach that automatically adds or removes resources when a set of conditions is met.
Cost metrics
Numeric data related to workload cost.
Scale down
A vertical scaling strategy that shifts to a lower SKU to provide less resources to the workload.
Scale in
A horizontal scaling strategy that removes instances to provide less resources to the workload.
Scale out
A horizontal scaling strategy that adds instances to provide more resources to the workload.
Scale unit
A group of resources that scale proportionately together.
Scale up
A vertical scaling strategy that shifts to a higher SKU to provide more resources to the workload.
Stock keeping unit (SKU)
A service tier for an Azure service.
Usage data
Usage data is either direct information (real) or indirect/representative information (proxy) about how much a task, service, or application is being used.
Key design strategies
The goal of cost optimizing scaling is to scale up and out at the last responsible moment and to scale down and in as soon as it’s practical. To optimize scaling for your workload, you can evaluate alternative scaling options within the scale units and align them with the cost model. A scale unit represents a specific grouping of resources that can be scaled independently or together. You should design scale units to handle a specific amount of load, and they can comprise multiple instances, servers, or other resources. You need to evaluate the cost effectiveness of your workload scale units and model alternates.
If you don't use scaling, see guidance on
scaling the workload
. You need to figure out if your application can scale. Stateless applications are easier to scale because they can handle multiple requests at the same time. Also, evaluate if the application is built using distributed systems principles. Distributed systems can handle increased load by distributing the workload across multiple nodes. However, a singleton application is designed to have only one instance running at any given time. So scaling might not be appropriate for all workloads.
Evaluate scale out versus scale up
Evaluating scale out versus scale up involves determining the most cost-effective approach between increasing resources in an existing system (scale up) or adding more instances of that system (scale out) based on various factors like pricing, workload requirements, and acceptable downtime. Choosing the right scaling approach can lead to significant savings, ensuring you pay for only what you need while still meeting performance and reliability standards.
The goal is to determine the most cost-efficient choice based on service-tier pricing, workload traits, acceptable downtime, and the cost model. For some, it might be more economical to opt for more expensive instances in fewer numbers. Conversely, for others, a cheaper tier with more instances might be better. To make an informed decision, you need to analyze real or representative data from your setup and evaluate the relative cost merits of each strategy. To evaluate the most cost efficient approach, consider these recommendations:
Gather usage data
: Collect actual production data or proxy data that represents the workload usage patterns and resource utilization. This data should include metrics such as CPU usage, memory usage, network traffic, and any other relevant metrics that affect the cost of scaling.
Define cost metrics
: Identify the cost metrics that are relevant to your workload, such as the cost per hour, cost per transaction, or cost per unit of resource usage. These metrics help you compare the cost effectiveness of different scaling options.
Gather usage data
: Collect actual production data or proxy data that represents the workload usage patterns and resource utilization. This data should include metrics such as CPU usage, memory usage, network traffic, and any other relevant metrics that affect the cost of scaling
Define cost metrics
: Identify the cost metrics that are relevant to your workload, such as the cost per hour, cost per transaction, or cost per unit of resource usage. These metrics help you compare the cost-effectiveness of different scaling options.
Refer to requirements
: When deciding between scale-out and scale-up strategies, consider the reliability, performance, and scaling requirements of your workload. Scaling out can improve reliability through redundancy. Scaling up increases the capacity of a resource, but there might be limits to how much you can scale up.
Consider resource limits
: When evaluating scaling options, it's important to consider the inherent limits of every instance, resource, and scale unit boundary. Be aware of the upper scaling limits for each resource and plan accordingly. Additionally, keep in mind the limits of your subscription and other resources.
Test scaling
: Create tests for different scaling scenarios, including scale out and scale up options. Applying the usage data, simulate the workload behavior under different scaling configurations. Conduct real-world testing using the modeled scaling scenarios.
Calculate costs
: Use the gathered data and cost metrics to calculate the costs associated with each scaling configuration. Consider factors such as instance pricing, resource utilization, and any extra costs related to scaling.
Optimize autoscaling
Optimizing the autoscaling policy involves refining autoscaling to react to load changes based on the workload’s nonfunctional requirements. You can limit excessive scaling activities by adjusting thresholds and using the right cooldown period. To optimize autoscaling, consider the following recommendations:
Analyze the current autoscaling policy
: Understand the existing policy and its behavior in response to varying load levels.
Refer to nonfunctional requirements
: Identify the specific nonfunctional requirements that you need to consider, such as response time, resource utilization, or cost.
Adjust scaling thresholds
: Adjust the scaling thresholds based on the workload characteristics and nonfunctional requirements. Set thresholds for scaling up or down based on factors like CPU utilization over time, network traffic, or queue length.
Adjust a cooldown period
: Adjust the cooldown period to prevent excessive scaling activities triggered by temporary load spikes. A cooldown period introduces a delay between scaling events, allowing the system to stabilize before further scaling actions.
Monitor and fine-tune
: Continuously monitor the system's behavior and performance. Analyze the scaling activities and adjust the policy as needed to optimize cost and meet the desired nonfunctional requirements.
Tradeoff
: Reducing the number of scaling events raises the chances of encountering issues related to scaling. It means you're eliminating the extra cushion or buffer that could help manage potential problems or delays from scaling.
Use event-based scaling
Event-driven autoscaling allows the application to dynamically adjust resources based on specific events or triggers rather than traditional metrics like CPU or memory utilization. For example, Kubernetes event-driven autoscaling (KEDA) can scale applications based on scalers such as the length of a Kafka topic. Precision helps prevent unnecessary scaling fluctuations and resource waste. A high level of precision ultimately optimizes costs. To use event-based scaling, follow these steps:
Choose an event source
: Determine the event source that triggers the scaling of your scale unit. A source can be a message queue, a streaming platform, or any other event-driven system.
Set up event ingestion
: Configure your application to consume events from the chosen event source. It typically involves establishing a connection, subscribing to the relevant topics or queues, and processing the incoming events.
Implement scaling logic
: Write the logic that determines when and how your scale unit should scale based on the incoming events. This logic should consider factors such as the number of events, the rate of incoming events, or any other relevant metrics.
Integrate with scaling mechanisms
: Depending on your application's runtime environment, you can use different scaling mechanisms to adjust the resources allocated to the application.
Configure scaling rules
: Define the scaling rules that specify how your scale unit should scale in response to events. These rules can be based on thresholds, patterns, or any other criteria that align with your application's requirements. Scaling thresholds should relate to business metrics. For example, if you add two more instances, you can support 50 more users in shopping cart processing.
Test and monitor
: Validate the behavior of your event-based scaling implementation by testing it with different event scenarios. Monitor the scaling actions and ensure that the actions align with your expectations.
Tradeoff
Configuring and fine-tuning event-based autoscaling can be complex, and improper configuration might lead to over-provisioning or under-provisioning of resources.
Optimize demand and supply
Control demand against your supply. On workloads where usage determines scaling, cost correlates with the scaling. To optimize the costs of scaling, you can minimize scaling spend. You can offload demand by distributing demand to other resources, or you can reduce demand by implementing priority queues, gateway offloading, buffering, and rate limiting. Both strategies can prevent undesired costs due to scaling and resource consumption. You can also control supply by capping the scaling limits. To optimize workload demand and supply, consider the following recommendations.
Offload demand
Offloading demand refers to the practice of distributing or transferring resource demand to other resources or services. You can use various technologies or strategies:
Caching
: Use caching to store frequently accessed data or content, reducing the load on your backend infrastructure. For example, use content delivery networks (CDNs) to cache and serve static content, reducing the need for scaling the backend. However, not every workload can cache data. Workloads that require up-to-date and real-time data, like trading or gaming workloads, shouldn’t use a cache. The cached data would be old and irrelevant to the user.
Tradeoff
. Caching might introduce challenges in terms of cache invalidation, consistency, and managing cache expiration. It's important to carefully design and implement caching strategies to avoid potential tradeoffs.
Content offloading
: Offload content to external services or platforms to reduce the workload on your infrastructure. For example, rather than store video files on your primary server, you can host these files in a separate storage service that's independent from your primary server. You can load these large files directly from the storage service. This approach frees up resources on your servers, allowing you to use a smaller server. It can be cheaper to store large files in a separate data store. You can use a CDN to improve performance.
Load balancing
: Distribute incoming requests across multiple servers using load balancing. Load balancing evenly distributes the workload and prevents any single server from becoming overwhelmed. Load balancers optimize resource utilization and improve the efficiency of your infrastructure.
Database offloading
: Reduce the load on your main application server by offloading database operations to a separate database server or a specialized service. For example, use a CDN for static content caching and a Redis cache for dynamic content (data from database) caching. Techniques like database sharding, read replicas, or using managed database services can also reduce the load.
Tradeoff:
Offloading specific tasks to alternate resources helps reduce or avoid extra scaling and costs associated with scaling. However, it's important to consider the operational and maintenance challenges that might arise from offloading. Conducting a comprehensive cost-benefit analysis is crucial when selecting the most appropriate offloading techniques for your workload. This analysis ensures that the chosen method is both efficient and feasible in relation to the anticipated savings and operational complexities.
Reduce demand
Reducing resource demand means implementing strategies that help minimize resource utilization in a workload. Offloading demand shifts demand to other resources. Reducing demand decreases demand on the workload. Reducing demand allows you to avoid overprovisioning resources and paying for unused or underutilized capacity. You should use code-level design patterns to reduce the demand on workload resources. To reduce demand through design patterns, follow these steps:
Understand design patterns
: Familiarize yourself with various design patterns that promote resource optimization.
Analyze workload requirements
: Assess the specific requirements of your workload, including its expected demand patterns, peak loads, and resource needs.
Select appropriate design patterns
: Choose the design patterns that align with your workload's requirements and objectives. For example, if your workload experiences fluctuating demand, event-driven scaling and throttling patterns can help manage the workload by dynamically allocating resources. Apply the selected design patterns to your workload architecture. You might need to separate workload components, containerize applications, optimize storage utilization, and more.
Continuously monitor and optimize
: Regularly evaluate the effectiveness of the implemented design patterns and adjust as needed. Monitor resource usage, performance metrics, and cost optimization opportunities.
By following these steps and using appropriate design patterns, you can reduce resource demand, optimize costs, and ensure the efficient operation of their workloads.
Use these design patterns to reduce demand:
Cache aside
: The pattern checks the cache to see if the data is already stored in memory. If the data is found in the cache, the application can quickly retrieve and return the data, reducing the need to query the persistent data store.
Claim check
: By separating data from the messaging flow, this pattern reduces the size of messages and supports a more cost-effective messaging solution.
Competing consumers
: This pattern efficiently handles items in a queue by applying distributed and concurrent processing. This design pattern optimizes costs by scaling that is based on queue depth and setting limits on maximum concurrent consumer instances.
Compute resource consolidation
: This pattern increases density and consolidates compute resources by combining multiple applications or components on shared infrastructure. It maximizes resource utilization, avoiding unused provisioned capacity and reducing costs.
Deployment stamps
: The use of deployment stamps provides several advantages, such as geo-distributing groups of devices, deploying new features to specific stamps, and observing cost per device. Deployment stamps allow for better scalability, fault tolerance, and efficient resource utilization.
Gateway offloading
: This pattern offloads request processing in a gateway device, redirecting costs from per-node resources to the gateway implementation. Using this design pattern can result in a lower cost of ownership in a centralized processing model.
Publisher/subscriber
: This pattern decouples components in an architecture, replacing direct communication with an intermediate message broker or event bus. It enables an event-driven approach and consumption-based billing, avoiding overprovisioning.
Queue-based load leveling
: The pattern buffers incoming requests or tasks in a queue. The buffering smooths out the workload and reduces the need for overprovisioning of resources to handle peak load. Incoming requests are processed asynchronously to reduce costs.
Sharding
: This pattern directs specific requests to a logical destination, allowing optimizations with data colocation. Sharding can lead to cost savings by using multiple instances of lower-spec compute or storage resources.
Static content hosting
: This pattern delivers static content efficiently by using a hosting platform designed for this purpose. It avoids the use of more expensive dynamic application hosts, optimizing resource utilization.
Throttling
: This pattern puts limits on the rate (rate limiting) or throughput of incoming requests to a resource or component. It helps inform cost modeling and can be tied directly to the business model of the application.
Valet key
: This pattern grants secure and exclusive access to a resource without involving more components, reducing the need for intermediary resources and improving efficiency.
Control supply
Defining an upper limit on the amount that you're willing to spend on a particular resource or service is one way to control supply. It's an important strategy for controlling costs and ensuring that expenses don't exceed a certain level. Establish a budget and monitor the spending to ensure it stays within the defined amount. You can use cost management platforms, budget alerts, or tracking usage and spending patterns. Some services allow you to throttle supply and limit rates, and you should use those features where helpful.
Controlling supply refers to defining an upper limit on the amount that you're willing to spend on a particular resource or service. It's an important strategy because it helps control costs and ensures that expenses don't exceed a certain level. Establish a budget and monitor the spending to ensure it stays within the defined threshold. You can use cost management platforms, budget alerts, or tracking usage and spending patterns. Some services allow you to throttle supply and limit rates, and you should use those features where helpful.
Tradeoff
: Stricter limits might result in missed opportunities to scale when demand increases, potentially impacting user experience. It could cause shutdowns or unable to respond to load. It's important to strike a balance between cost optimization and ensuring that you have sufficient resources to meet your business needs.
Azure facilitation
Evaluating scale-out versus scale-up
: Azure provides a test environment where you can deploy and test different scaling configurations. By using the actual workload data or proxy data, you can simulate real-world scenarios and measure the effects on costs. Azure offers tools and services for performance testing, load testing, and monitoring, which can help you evaluate the cost effectiveness of scale out versus scale up options.
Azure provides cost management recommendations through various tools and services, such as the
Azure Advisor
. These recommendations analyze your usage patterns, resource utilization, and scaling configurations to provide insights and suggestions for optimizing costs.
Azure Load Testing
is a fully managed load-testing service that generates high-scale load. The service simulates traffic for your applications, regardless of where they're hosted. Developers, testers, and quality assurance (QA) engineers can use load testing to optimize application performance, scalability, or capacity.
Optimizing autoscaling
: Many Azure compute services support deploying multiple identical instances, and rapidly tuning the scaling thresholds and policies. Azure provides autoscaling capabilities that allow you to automatically adjust the number of instances or resources based on workload demand. You can define scaling rules and thresholds to trigger scale-out or scale-in actions. By using autoscaling, you can optimize resource allocation and cost efficiency by dynamically scaling resources based on actual demand.
Azure maintains a list of
subscription and service limits.
There’s a general limit to the number of instances of a resource you can deploy in each resource group with some exceptions. For more information, see
Resource instance limits per resource group.
Optimizing demand and supply
: Azure Monitor provides insights into the performance and health of your applications and infrastructure. You can use Azure Monitor to monitor the load on your resources and analyze trends over time. By using metrics and logs collected by Azure Monitor, you can identify areas where scaling adjustments might be needed. This information can guide the refinement of your autoscaling policy to ensure it aligns with the nonfunctional requirements and cost optimization goals.
Offloading supply
: Azure has a modern cloud Content Delivery Network (CDN) called
Azure Front Door
and caching services (
Azure Cache for Redis
and
Azure HPC Cache
). The CDN caches content closer to the end-users, reducing network latency and improving response times. Caching stores a copy of the data in front of the main data store, reducing the need for repeated requests to the backend. By using CDN and caching services, you can optimize performance and reduce the load on servers for potential cost savings.
Controlling supply
: Azure also allows you to set resource limits for your cloud workload. By defining resource limits, you can ensure that your workload stays within the allocated resources and avoid unnecessary costs. Azure provides various mechanisms for setting resource limits such as quotas, policies, and budget alerts. These mechanisms help you monitor and control resource usage.
API Management
can rate limit and throttle requests. Being able to throttle incoming requests is a key role of Azure API Management. Either by controlling the rate of requests or the total requests/data transferred, API Management allows API providers to protect their APIs from abuse and create value for different API product tiers.
Related links
Scale the workload
Azure Advisor Cost recommendations
What is Azure Load Testing?
Azure subscription and service limits, quotas, and constraints
Resources not limited to 800 instances per resource group
What is Azure Front Door?
What is Azure Cache for Redis?
What is Azure HPC Cache?
Advanced request throttling with Azure API Management
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Cost Optimization design principles - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Cost Optimization design principles
Article
2023-11-15
4 contributors
Feedback
In this article
Architecture design is always driven by business goals and must
factor in return on investment (ROI) and financial constraints
. Typical questions to consider include:
Do the allocated budgets enable you to meet your goals?
What's the spending pattern for the application and its operations? What are priority areas?
How will you maximize the investment in resources, by better utilization or by reduction?
A cost-optimized workload isn't necessarily a low-cost workload. There are significant tradeoffs. Tactical approaches are reactive and can reduce costs only in the short term. To achieve long-term financial responsibility, you need to
create a strategy with prioritization, continuous monitoring, and repeatable processes
that focuses on optimization.
The design principles are intended to provide optimization strategies that you need to consider when you design and implement your workload architecture. Start with the recommended approaches and
justify the benefits for a set of business requirements
. After you set your strategy, drive actions by using the
Cost Optimization checklist
as your next step.
As you prioritize business requirements to align with technology needs, you can adjust costs. However, you should expect a series of
tradeoffs in areas in which you want to optimize cost, such as security, scalability, resilience, and operability
. If the cost of addressing the challenges in those areas is high and these principles aren't applied properly, you might make risky choices in favor of a cheaper solution, ultimately affecting your organization's business goals and reputation.
Develop cost-management discipline
Build a team culture that has awareness of budget, expenses, reporting, and cost tracking.
Cost optimization is conducted at various levels of the organization. It's important to understand how your workload is aligned with organizational goals and FinOps practices. A view into the business units, resource organization, and centralized audit policies allows you to adopt a standardized financial system.
Approach
Benefit
Develop a
cost model
. This fundamental exercise is a prerequisite to setting up a financial tracking system.
A cost model helps segment expenses and estimate and
forecast the total cost of ownership
, including infrastructure, support, and implementation. It enables you to identify cost drivers early and predict how any change, growth, or shrinkage will affect overall spending in your projected business model.
Have an
effective but flexible accountability model
that's implemented with properly assigned roles and responsibilities.
As the architecture evolves, various roles participate in decision making. Clear accountability helps
enforce the functional expectations
of each role (given a scope), drive clarity, and generate reports with transparency at desired levels.
Estimate
realistic budgets
that cover all non-negotiable functional and nonfunctional requirements, personnel and training costs, and processes that provide for anticipated growth.
You'll be able to
set financial boundaries
and establish ways to check your spending against the allocated budget. You'll also get notifications when certain thresholds are exceeded, which prevents overspending at the tenant scope, resource scope, and other scopes that are applied to the budget.
Use
governance
and processes to implement the accountability model and budgets.
It's not enough to get notifications, because that's reactionary.
Proactive governance
can help you avoid actions that might lead to unnecessary expenditure that's beyond the budget.
Certain actions can improve the current state. Are retention policies too relaxed? Do you need scalability limits to ensure responsible engineering?
Build capabilities in the system that
capture and classify expense
.
You'll be able to calculate the costs that
reveal technical and business perspectives
at different billing boundaries.
You'll also be able to conduct regular reviews and drive showback and chargeback processes.
Plan on
training costs, hiring expenses, and the cost of infrastructure needed
to augment skills as the workload matures.
Investing in staffing
complements existing skills
through full-time or vendor support.
Encourage
upstream communication
from architects and application owners.
Research costs are reduced when you act on feedback, which should be considered as meaningful as numeric data. You'll empower employees by using their input to
drive realistic design changes
and business strategies.
Design with a cost-efficiency mindset
Spend only on what you need to achieve the highest return on your investments.
Every architectural decision has direct and indirect financial implications.
Understand the costs associated with build versus buy options
, technology choices, the billing model and licensing, training, operations, and so on.
Given a set of requirements, optimize and make tradeoff decisions, in relation to costs, that still effectively address the cross-cutting concerns of the workload.
Approach
Benefit
Measure the total cost
incurred by technology and automation choices, taking into account the impact on ROI. The design must work within the acceptable boundaries for all functional and nonfunctional requirements. The design must also be flexible to accommodate predicted evolution.
Factor in the cost of acquisition, training, and change management.
Implementing a balanced approach that takes ROI into account
prevents overengineering
, which might increase costs.
Discarding alternatives that are expensive and lack business justification provides buffer in your budget that you can spend in other areas.
We don't recommend that you design beyond planned growth because doing so might divert investments that are allocated for near-term design choices and tradeoff compensation.
Establish the initial cost
, using the billing models that are best suited to fulfill your requirements.
Refining cost estimates will help you forecast how costs compare to the budget and identify the main cost drivers. Do the cost drivers help meet the business requirements?
You need to know the initial cost before you can readjust your choices and evaluate other cost-effective options. You'll uncover hidden costs that might go undetected if the design was in a purely hypothetical state.
Fine-tune the design by prioritizing services
that can reduce the overall cost, don't need additional investment, or don't have a significant impact on functionality. Prioritization should account for the business model and technology choices that bring high ROI.
You'll be able to explore cheaper options that might enable resource flexibility or dynamic scaling, or you might justify the use of existing investments. The prioritization parameters might factor in costs that are required for critical workloads, runtime, and operations, and other costs that might help the team work more efficiently.
Design your architecture to support cost guardrails
.
Enforcement via governance policies or built-in application design patterns can prevent incidental or unapproved charges.
For workloads that are backed by service-level agreements (SLAs),
weigh the pros and cons of reserving budget for penalties versus using it for implementation
. You can avoid penalties if your implementation is sound.
Ensuring that your design fulfills its intended function and meets commitments is a proactive approach that reduces eventual risks of liability.
Negotiating realistic cost commitments or working with your product owner to create a dedicated violation budget makes these goals more achievable.
Design for usage optimization
Maximize the use of resources and operations. Apply them to the negotiated functional and nonfunctional requirements of the solution.
Services and offerings provide various capabilities and pricing tiers.
After you purchase a set of features, avoid underutilizing them
. Find ways to maximize your investment in the tier. Likewise, continuously evaluate billing models to find those that better align to your usage, based on current production workloads.
Approach
Benefit
Evaluate whether your chosen
resource SKUs provide
additional features that can help you meet performance, security, reliability, or operational targets.
By taking advantage of features offered by the SKU that you selected for your design, you can maximize the use of what you paid for and
avoid paying for unused features
.
Use consumption-based pricing
when it's practical.
You'll pay for exactly what you use. This option might be more expensive than a fully utilized prepaid option. However,
if you don't expect to fully utilize pre-purchased compute
, consumption billing might be a better choice.
Apply policies
to comply with the design and the design's upper and lower limits.
Governance ensures that only allowed regions and services and their budgeted quantity are provisioned. This governance
reduces waste and the over-provisioning of resources
.
Prioritize deployment of active-active models
or active-only over active-passive models, as part of your recovery plan, if you already paid for the resources.
If your design defaults to using active-passive models, you might have
idle resources
that could otherwise be used. Converting to active-active might enable you to meet your load leveling and scale bursting requirements without overspending. If you can meet your recovery targets with an active-only model, the costs of those resources can be removed completely.
Regularly and rigorously
review deployments for unused resources
and data and decommission them.
Shutting down unused resources and deleting data when you no longer need it reduces waste and
frees up funds so you can invest them elsewhere
.
Find additional
uses for resources that you committed to
in discounted longer-term plans.
Consider
pre-purchased resources, existing licenses, and other commitment-based discounted resources that are unused
. You can save money by using these resources. You can use these resources for tests, additional environments, or even addressing functional and nonfunctional requirements.
Likewise, finding opportunities to utilize committed plans for resources that your workload is using will enable your workload to optimize those resource costs via the precommitment.
Take advantage of your
investment in your support plan
.
Using your support plan to
handle production problems or for proactive reviews
will help you get your money's worth. Fully engage with your Microsoft support model.
Design for rate optimization
Increase efficiency without redesigning, renegotiating, or sacrificing functional or nonfunctional requirements.
Take advantage of opportunities to optimize the utility and costs of your existing resources and operations. If you don't, you unnecessarily spend money without any added ROI.
Approach
Benefit
Optimize by committing and pre-purchasing to
take advantage of discounts
offered on resource types that aren't expected to change over time and for which costs and utilization are predictable.
Also, work with your licensing team to influence future purchase agreement programs and renewals.
Microsoft offers reduced rates for predictable and long-term commitment to specific resources and resource categories. Resources
cost less during the usage period
and can be amortized over the period.
By keeping your licensing team aware of the current and predicted investment by resource, you can help them
right-size commitments
when your organization signs the agreement. In some cases, these projections and commitments could influence your organization's price sheet, which benefits your workload's cost and also other teams that use the same technology.
Find ways to reduce licensing costs by evaluating
alternatives that don't require additional licensing
. Consider options like hybrid use and pre-production subscription pricing.
You'll be able to
reduce licensing costs
for services, operating systems, and tools by taking advantage of options that give you usage rights to the same or comparable technologies at a lower cost.
Switch to
fixed-price billing
instead of consumption-based billing for a resource when its utilization is high and predictable and a comparable
SKU
or
billing option is available
.
When
utilization is high and predictable
, the fixed-price model usually costs less and often supports more features. Using it could increase your ROI.
Use centralized resources
that are provided by your organization, and share the cost with other teams.
Shared resources often have higher capacity to support multiple workloads, and
costs are distributed across teams
. Taking a dependency on shared resources can save money, as long as the functionality of your workload isn't compromised.
Showback and chargeback are other potential benefits.
Deploy to regions
that cost less.
Some regions offer services at a cheaper price. If you can still meet functional and nonfunctional requirements, you should consider using those regions. You can further benefit by evaluating the regional choice per environment, potentially using favorable pricing for preproduction environments even if the production environment cannot.
Co-locate usage
with other resources, workloads, and even teams.
Prefer services that make it easier to achieve higher density.
Consider the potential tradeoffs, especially on security boundaries.
You'll be able to save costs by optimizing hardware utilization.
As density increases, the amount of resources that you need to run a workload decreases
. This decrease reduces cost per unit and the cost of management.
Monitor and optimize over time
Continuously right-size investment as your workload evolves with the ecosystem.
What was important yesterday might not be important today. As you learn through evaluation of production workloads,
expect changes in architecture, business requirements, processes, and even team structure
. Your software development lifecycle (SDLC) practices might need to evolve. External factors might also change, like the cloud platform, its resources, and your agreements.
You should carefully assess the impact of all changes on cost. Monitor changes and the ROI trend on a regular cadence, and evaluate whether you need to adjust functional and nonfunctional requirements.
Approach
Benefit
By using your cost tracking system, continuously evaluate and optimize the costs of resources, data, and paid support. Are there
underutilized resources that can be retired, replaced, rebuilt, or refactored
?
You'll reduce costs by
avoiding paying for resources that aren't fully utilized
. Understanding pricing metrics can help you make decisions that are more aligned with your cost model. It can also prevent unwarranted billing. By resizing or removing underutilized resources, or even changing SKUs, you can reduce costs.
You might also be able to save some costs by evaluating the use of your support contract and right-sizing it.
Continuously adjust architecture
design decisions, resources, code, and workflows based on ROI data.
Regular reviews of metrics, performance data, billing reports, and feature usage might lead to
fine-tuning that can reduce costs
.
Treat different SDLC environments differently
, and deploy the right number of environments.
Production environments should be your main cost driver.
You can save money by understanding that
not all environments need to simulate production
. Nonproduction environments can have different features, SKUs, instance counts, and even logging.
You also can save costs by creating pre-production environments on-demand and removing them when you no longer need them.
Next steps
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Recommendations for setting spending guardrails - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Recommendations for setting spending guardrails
Article
2023-11-15
7 contributors
Feedback
In this article
Applies to this Azure Well-Architected Framework Cost Optimization checklist recommendation:
CO:04
Set spending guardrails. Guardrails should include release gates, governance policies, resource limits, and access controls. Prioritize platform automation over manual processes.
This guide describes the recommendations for setting spending guardrails. Spending guardrails are measures to control and manage costs within a specified budget. They help prevent unexpected or excessive spending and promote cost-effective utilization of resources. Without spending guardrails, your workload costs might exceed your budget, leading to unplanned expenses that can strain your financial resources.
Definitions
Term
Definition
Governance policies
A set of rules that enforce compliance and enable auditing of workload resources.
Governance
A set of policies, processes, and controls that help ensure that the workload is managed effectively, securely, and in compliance with organizational and regulatory requirements.
Infrastructure as code (IaC)
A descriptive model for defining and deploying infrastructure, including networks, virtual machines, load balancers, and connection topologies.
Release gate
A condition or checkpoint in a release pipeline that must be satisfied before the deployment can proceed. A release gate helps to ensure that specific criteria are met before software is released.
Key design strategies
Set spending guardrails by implementing measures to control and manage your costs within a specified budget. These measures include governance policies, access controls, release gates, budget thresholds, and alerts. Automation reduces the risk of human error, improves efficiency, and assists the consistent application of spending guardrails. Prioritize platform automation over manual processes. Automation tools and services the platform provides can streamline resource provisioning, configuration, and management.
Use governance policies
Governance policies can act as spending guardrails on various aspects of resources such as resource types, configurations, tags, location, and data management. Many cloud platforms have a service that automates the enforcement of governance policies. Use automated policies to control resource usage, enforce accountability, and eliminate spending on restricted resource types. Here are some of the policies you should consider enforcing:
Restricted resource types
: Policies can specify which types of resources are allowed or disallowed within an organization. For example, an organization might have a policy that restricts the use of certain expensive resource types to control costs.
Resource limits
: Set resource limits to controls costs and prevent overprovisioning. Include limits on the number of resources that can be provisioned, the size of resources, and the duration of resource usage in your policy. These limits can help you to prevent excessive spending and optimize resource utilization. For example, resource limits can minimize the effects of an unauthorized account breach related to crypto mining.
Defined resource configurations
: Policies can define specific configurations for resources. You can enforce settings on resources that promote cost optimization such as automatic scaling and data archiving
Restricted locations
: You can use policies to restrict the deployment of resources to specific regions or locations. Consider restricting locations to avoid costly data transfer fees and to maintain compliance with data sovereignty regulations.
Managed data
: Use policies to enforce data management practices that help optimize costs. For example, you can implement policies that require the use of lower-cost storage tiers for less frequently accessed data or policies that define expiration rules for data retention.
Enforced metadata
: Establish policies that mandate the use of specific metadata for better tracking and cost allocation. You can also use metadata in your automation or manual review. For example, use metadata to automate resources backups by using a backup tag. A consistent metadata policy helps to align costs with spending guardrails.
Limited idle resources
: Use policies to identify idle resources so you can delete or repurpose them. Consider setting policies that automatically shut down instances during the hours they’re not in use.
Risk
: If you implement automatic scaling, set a maximum scaling threshold based on testing. Maximum thresholds can help you avoid massive scaling spikes that cause cost overruns, but a threshold that’s set too low might negatively affect performance. For more information, see
Recommendations for optimizing scaling costs
.
Configure access controls
Configure access controls to set restrictions that prevent overspending and to help ensure that only authorized individuals can consume resources. Access controls can help reduce the risk of accidental or unnecessary changes that negatively affect cost optimization. To implement access controls for cost optimization, follow these steps:
Identify necessary control.
Identify the resources and services that need access controls.
Define access policies.
Define access policies based on the principle of least-privilege access, granting users only the necessary permissions to perform their tasks. For example, some users might need only read access, while others might also require write or delete permissions.
Implement authentication.
Implement authentication methods, like username/password, multifactor authentication, or integration with identity providers, to help ensure that only authorized users can access resources.
Use role-based access control (RBAC).
Set up RBAC to assign roles and permissions to users based on their job responsibilities. Using RBAC can help you manage resource access effectively.
Review and update controls.
Regularly review and update access controls to ensure that they align with the changing needs of the organization. Remove unnecessary access permissions and adjust access levels as needed.
Use release gates
Release gates are checkpoints or conditions that must be met before a release or deployment can proceed. Use release gates to help ensure that the release is cost-effective and aligns with optimization goals. Release gates offer a structured approach to the identification and implementation of cost-saving measures. To implement release gates for workload cost optimization, consider the following steps:
Establish release gate criteria.
Establish the conditions or criteria that must be met before resources are released or deployed. Include factors such as spending limits, resource utilization thresholds, or project milestones.
Incorporate release gates.
Incorporate the release gates into the deployment pipeline. You can use automation tools or custom scripts to ensure that resource deployments are subject to the defined criteria.
Monitor spending.
Continuously monitor spending and resource usage against the defined criteria. If the organization exceeds spending thresholds, the release gates should prevent further deployments until the issue is addressed.
Configure cost alerts
It's important to set alerts for budgets, cost anomalies, and commitment-based plan utilization to optimize costs. These alerts provide visibility into your cloud spending and enable proactive cost management. Be careful to manage notification recipients for alerts and keep the recipient list up to date with current responsibilities and access. Some alerts that you might create to optimize costs include:
Budget alerts
: Set alerts on budgets to track your spending against predefined thresholds. You can monitor your costs and receive notifications when you approach or exceed the budgeted amount by creating a monthly budget, billing account, or resource group. Budget alerts help you to stay informed on your spending and take preventative actions to control costs.
Cost anomaly alerts
: Anomaly alerts notify you about unexpected cost variations that might indicate inefficiencies or abnormal spending patterns. You can configure these alerts to identify anomalies in the actual or forecasted costs. Use cost anomaly alerts to investigate the underlying cause of a cost variation and take corrective actions when necessary.
Commitment-based plan utilization alerts
: Implement commitment-based plan utilization alerts to monitor your plan usage. If you have commitment-based plans, setting alerts on plan utilization can help you effectively manage and maximize the value of these commitments. You can configure these alerts to notify stakeholders if the utilization of commitment-based resources drops below a desired threshold. Optimize your commitment-based resources and ensure that you use the benefits of your commitments.
Use IaC
Infrastructure as code is the practice of managing and provisioning infrastructure resources by using code, typically in the form of configuration files. Implement this strategy to define and automate the deployment and configuration of infrastructure resources, such as virtual machines, networks, and storage, by using code-based templates.
IaC strategies provide a structured and repeatable approach to managing and controlling infrastructure resources. IaC can help you to deploy resources as-needed, delete resources without running them continuously, and optimize costs by ensuring you deploy and configure resources according to predefined rules. Follow these steps to use IaC for cost optimization:
Create IaC templates.
Create a code-based template language to define your infrastructure resources and their configurations. These templates let you specify the desired state of your infrastructure resources in a declarative manner. Implement best practices for cost optimization in your infrastructure code. Consider right-sizing your resources by using reserved instances or savings plans. Use cost-effective storage options and apply resource metadata for cost allocation and tracking.
Store templates.
Store IaC templates in a version control system to track changes and manage different versions. You can use version control to maintain a history of your infrastructure configurations and foster collaboration among team members.
Use parameters.
Use parameters in your templates to make them reusable and configurable. By using parameters, you can easily customize your infrastructure deployments for different environments or scenarios.
Use ephemeral environments.
Use ephemeral environments for development, testing, and staging purposes to optimize costs. Ephemeral environments should only be run when necessary. Create these environments by using IaC tools and delete the environment when you're finished.
Use IaC tools.
Use IaC tools and frameworks to automate the deployment and configuration of your infrastructure resources. Use automation to consistently and reliably deploy resources according to your defined policies.
Monitor deployed resources.
Regularly monitor your resources and their costs to ensure compliance with your spending policies. Use monitoring and alerting tools to identify any deviations from the defined guardrails and take corrective actions as needed. Check for unused resources and delete them, preferably with automation.
Azure facilitation
Using governance policies
: Use
Azure Policy
to define and enforce governance policies that align with your cost optimization goals. You can use Azure Policy to set rules on management groups, subscriptions, and resource groups. These policies can regulate resource provisioning, usage limits, and cost allocation. Use policies to promote rightsizing of resources, identify and eliminate idle or underutilized resources, and encourage the use of cost-effective services and architectures.
Azure provides built-in policies for common use cases that provide a standardized and efficient way to enforce rules and guidelines across your Azure resources. We recommend that you define your own custom policies to meet your unique business requirements or specific industry regulations that Azure built-in policies don't cover. For more information, see
Azure Policy built-in policy definitions
.
Azure allows you to set limits or quotas to prevent unexpected costs. You can define limits on the number of resources that can be provisioned, in addition to the size and duration of resource usage. Set these limits to help prevent overprovisioning and to control costs.
Identify underused or idle resources.
Use
Azure Advisor
to optimize and reduce your overall Azure costs by identifying idle and under-utilized resources. Receive cost recommendations from the
cost
section in the
advisor
dashboard.
Add resource metadata.
Use Azure governance to implement resource tagging and categorization. Tag resources using relevant metadata to track and allocate costs to different departments, projects, or cost centers. Visibility into cost attribution can help you identify areas of high spending, optimize resource allocation, and facilitate better cost management.
Configuring access controls
: Use Azure RBAC to manage access to resources. You can use RBAC to grant permissions to users, groups, or applications based on their roles. Implement RBAC to help ensure that only authorized users have access to resources, reducing the risk of unauthorized resource usage and potential cost implications.
Using release gates
: Use
Azure Pipelines
release management to define and enforce your release gates. You can set up manual or automated checkpoints to help ensure that you meet specific criteria, such as security checks, compliance requirements, and cost thresholds.
Using infrastructure as code.
You can use Azure tools and services to deploy and manage infrastructure resources by using code. By using tools like Azure Resource Manager (ARM) templates, Azure Bicep, and Azure DevOps, you can define and deploy your infrastructure resources in a declarative manner. Azure has
Bicep, Azure Resource Manager, and Terraform templates
for every Azure resource.
Use
Azure Pipelines
or other continuous integration and continuous delivery (CI/CD) tools to  automate the build, test, and deployment processes. Teams can use pipelines to define a series of steps and actions that run automatically whenever changes are made to the codebase. Automate these processes to reduce manual effort, ensure consistency, and accelerate the delivery of software.
Consider using lower-cost resources for your ephemeral or nonproduction environments to optimize costs. Azure provides various pricing tiers for resources. Azure DevTest Labs pricing and Azure Reservations are cost-saving methods that you can explore for ephemeral environments.
Git repositories, such as
Azure Repos
and
GitHub
, provide version control capabilities for managing code and infrastructure configurations. Teams and developers can use automated repositories to collaborate, track changes, and maintain a history of their codebase.
Azure Deployment Environments
empowers development teams to quickly and easily create app infrastructure by using project-based templates that establish consistency and best practices while maximizing security. On-demand access to secure environments accelerates the stages of the software development lifecycle in a compliant and cost-efficient way.
The
Azure Developer CLI
is an open-source tool that accelerates the time it takes for you to get your application from a local development environment to Azure. The Azure Developer CLI offers developer-friendly commands that map to key stages in your workflow, whether you're working in the terminal, an integrated development environment (IDE), or CI/CD.
Configuring cost alerts
: Use
Microsoft Cost Management
to optimize costs and enforce spending guardrails. You can use cost management features to set budgets and alerts, visualize cost information by using tools like Power BI, and analyze cost patterns and performance bottlenecks.
Organizational alignment
Central teams should use the Cloud Adoption Framework guidance to set up spending guardrails across the organization so workload teams understand what the central team can offer.
We encourage the organization to adopt policy-driven guardrails. For an example implementation, see
Adopt policy-driven guardrails
.
Related links
Assign access to Cost Management data
Cost Management tools in Azure
Create and manage budgets
Identify anomalies and unexpected changes in cost
Monitor usage and spending with cost alerts
Cost Optimization checklist
Refer to the complete set of recommendations.
Cost Optimization checklist
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025
Cost Optimization tradeoffs - Microsoft Azure Well-Architected Framework | Microsoft Learn
Skip to main content
Skip to Ask Learn chat experience
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.
Download Microsoft Edge
More info about Internet Explorer and Microsoft Edge
Table of contents
Exit focus mode
Ask Learn
Ask Learn
Read in English
Save
Table of contents
Read in English
Add
Add to plan
Edit
Share via
Facebook
x.com
LinkedIn
Email
Print
Note
Access to this page requires authorization. You can try
signing in
or
changing directories
.
Access to this page requires authorization. You can try
changing directories
.
Cost Optimization tradeoffs
Article
2024-10-10
6 contributors
Feedback
In this article
When you design a workload to maximize return on investment (ROI) under financial constraints, you first need clearly defined functional and nonfunctional requirements. A work and effort prioritization strategy is essential. The foundation is a team that has a strong sense of financial responsibility. The team should have a strong understanding of available technologies and their billing models.
After you understand the ROI of a workload, you can start improving it. To improve the ROI, consider how decisions based on the
Cost Optimization design principles
and the recommendations in the
design review checklist for Cost Optimization
might influence the goals and optimizations of other Azure Well-Architected Framework pillars. For cost optimization, it's important to avoid focusing on a cheaper solution. Choices that focus only on minimizing spending can increase the risk of undermining your workload's business goals and reputation. This article describes example tradeoffs that a workload team might encounter when considering the target setting, design, and operations for cost optimization.
Cost Optimization tradeoffs with Reliability
The cost of a service disruption must be measured against the cost of preventing or recovering from one. If the cost of disruptions exceeds the cost of reliability design, you should invest more to prevent or mitigate disruptions. Conversely, the cost of the reliability efforts might be more than the cost of a disruption, including factors like compliance requirements and reputation. You should consider strategic divestment in reliability design only in this scenario.
Tradeoff: Reduced resiliency.
A workload incorporates resiliency measures to attempt to avoid and withstand specific types and quantities of malfunction.
To save money, the workload team might underprovision a component or overconstrain its scaling, making the component more likely to fail during sudden spikes in demand.
Consolidating workload resources (
increasing density
) for cost optimization makes individual components more likely to fail during spikes in demand and during maintenance operations like updates.
Removing components that support resiliency design patterns, like a message bus, and creating a direct dependency reduces self-preservation capabilities.
Saving money by reducing redundancy can limit a workload's ability to handle concurrent malfunctions.
Using budget SKUs might limit the maximum service-level objective (SLO) that the workload can reach.
Setting hard spending limits can prevent a workload from scaling to meet legitimate demand.
Without reliability testing tools or tests, the reliability of a workload is unknown, and it's less likely to meet reliability targets.
Tradeoff: Limited recovery strategy.
A workload that's reliable has a tested incident response and recovery plan for disaster scenarios.
Reduced testing or drilling of a workload's disaster recovery plan might affect the speed and effectiveness of recovery operations.
Creating or retaining fewer backups decreases possible recovery points and increases the chance of losing data.
Choosing a less expensive support contract with technology partners might increase workload recovery time due to potential delays in technical assistance.
Tradeoff: Increased complexity.
A workload that uses straightforward approaches and avoids unnecessary or overengineered complexity is generally easier to manage in terms of reliability.
Using cost-optimization cloud patterns can add new components, like a content delivery network (CDN), or shift duties to edge and client devices that a workload must provide reliability targets for.
Event-based scaling can be more complicated to tune and validate than resource-based scaling.
Reducing data volume and tiering data through data lifecycle actions, possibly in conjunction with implementing aggregated data points before a lifecycle event, introduces reliability factors to consider in the workload.
Using different regions to optimize cost can make management, networking, and monitoring more difficult.
Cost Optimization tradeoffs with Security
The cost of a compromise to confidentiality, integrity, and availability in a workload must always be balanced against the cost of the effort to prevent that compromise. A security incident can have a wide range of financial and legal impacts and harm a company's reputation. Investing in security is a risk mitigation activity. The cost of experiencing the risks must be balanced against the investment. As a rule, don't compromise on security to gain cost optimizations that are below the point of responsible and agreed upon risk mitigation. Optimizing security costs by rightsizing solutions is an important optimization practice, but be aware of tradeoffs like the following when doing so.
Tradeoff: Reduced security controls.
Security controls are established across multiple layers, sometimes redundantly, to provide defense in depth.
One cost optimization tactic is to look for ways to remove components or processes that accrue unit or operational costs. Removing security components like the following examples for the sake of saving money impacts security. You need to carefully perform a risk analysis on this impact.
Reducing or simplifying authentication and authorization techniques compromises the
verify explicitly
principle of zero-trust architecture. Examples of these simplifications include using a basic authentication scheme like preshared keys rather than investing time to learn industry OAuth approaches, or using simplified role-based access control assignments to reduce management overhead.
Removing encryption in transit or at rest to reduce costs on certificates and their operational processes exposes data to potential integrity or confidentiality breaches.
Removing or reducing security scanning or inspection tooling or security testing because of the associated cost and time investment can directly impact the confidentiality, integrity, or availability that the tooling and testing is intended to protect.
Reducing the frequency of security patching because of the operational time invested in cataloging and performing the patching affects a workload's ability to address evolving threats.
Removing network controls like firewalls might lead to a failure to block malicious inbound and outbound traffic.
Tradeoff: Increased workload surface area.
The Security pillar prioritizes a reduced and contained surface area to minimize attack vectors and the management of security controls.
Cloud design patterns that optimize costs sometimes necessitate the introduction of additional components. These additional components increase the surface area of the workload. The components and the data within them must be secured, possibly in ways that aren't already used in the system. These components and data are often subject to compliance. Examples of patterns that can introduce components include:
Using the Static Content Hosting pattern to offload data to a new CDN component.
Using the Valet Key pattern to offload processing and secure resource access to client compute.
Using the Queue-Based Load Leveling pattern to smooth costs by introducing a message bus.
Tradeoff: Removed segmentation.
The Security pillar prioritizes strong segmentation to support the application of targeted security controls and to control the blast radius.
Sharing resources, for example in multitenancy situations or co-locating multiple applications on a shared application platform, is an approach for reducing costs by increasing density and reducing the management surface. This increased density can lead to security concerns like these:
Lateral movement between components that share resources is easier. A security event that compromises the availability of the application platform host or an individual application also has a larger blast radius.
Co-located resources might share a workload identity and have less meaningful audit trails in access logs.
Network security controls must be broad enough to cover all co-located resources. This configuration potentially violates the principle of least privilege for some resources.
Co-locating disparate applications or data on a shared host can lead to extending compliance requirements and security controls to applications or data that would otherwise be out of scope. This broadening of scope necessitates additional security scrutiny and auditing effort on the co-located components.
Cost Optimization tradeoffs with Operational Excellence
Tradeoff: Compromised software development lifecycle (SDLC) capacities.
A workload's SDLC process provides rigor, consistency, specificity, and prioritization to change management in a workload.
Reducing testing efforts to save time and the cost associated with test personnel, resources, and tooling can result in more bugs in production.
Delaying paying back technical debt to focus personnel efforts on new features can lead to slower development cycles and overall reduced agility.
Deprioritizing documentation to focus personnel efforts on product development can lead to longer onboarding time for new employees, impact the effectiveness of incident response, and compromise compliance requirements.
A lack of investment in training leads to stagnated skills, reducing the team's ability to adopt newer technologies and practices.
Removing automation tooling to save money can result in personnel spending more time on the tasks that are no longer automated. It also increases the risk of errors and inconsistencies.
Reducing planning efforts, like scoping and activity prioritization, to cut expenses can increase the likelihood of rework due to vague specifications and poor implementation.
Avoiding or reducing continuous improvement activities, like retrospectives and after-incident reports, to keep the workload team focused on delivery can create missed opportunities to optimize routine, unplanned, and emergency processes.
Tradeoff: Reduced observability.
Observability is necessary to help ensure that a workload has meaningful alerting and successful incident response.
Decreasing log and metric volume to save on storage and transfer costs reduces system observability and can lead to:
Fewer data points for creating alerts related to reliability, security, and performance.
Coverage gaps in incident response activities.
Limited observability into interactions or boundaries related to security or compliance.
Cost optimization design patterns can add components to a workload, increasing its complexity. The workload monitoring strategy must include those new components. For example, some patterns might introduce flows that span multiple components or shift processes from the server to the client. These changes can increase the complexity of correlating and tracking information.
Reduced investment in observability tooling and the maintenance of effective dashboards can decrease the ability to learn from production, validate design choices, and inform product design. This reduction can also hamper incident response activities and make it harder to meet the recovery time objective and SLO.
Tradeoff: Deferred maintenance.
Workload teams are expected to keep code, tooling, software packages, and operating systems patched and up to date in a timely and orderly way.
Letting maintenance contracts with tooling vendors expire can result in missed optimization features, bug resolutions, and security updates.
Increasing the time between system patches to save time can lead to missed bug fixes or a lack of protection against evolving security threats.
Cost Optimization tradeoffs with Performance Efficiency
The Cost Optimization and Performance Efficiency pillars both prioritize maximizing a workload's value. Performance Efficiency emphasizes meeting performance targets without spending more than necessary. Cost Optimization emphasizes maximizing the value produced by a workload's resources without exceeding performance targets. As a result, Cost Optimization often improves Performance Efficiency. However, there are Performance Efficiency tradeoffs associated with Cost Optimization. These tradeoffs can make it harder to reach performance targets and hinder ongoing performance optimization.
Tradeoff: Underprovisioned or underscaled resources.
A performance-efficient workload has enough resources to serve demand but doesn't have excessive unused overhead, even when usage patterns fluctuate.
Reducing costs by downsizing resources can deprive applications of resources. The application might not be able to handle significant usage pattern fluctuations.
Limiting or delaying scaling to cap or reduce costs might result in insufficient supply to meet demand.
Autoscale settings that scale down aggressively to reduce costs might leave a service unprepared for sudden spikes in demand or cause frequent scaling fluctuations (flapping).
Tradeoff: Lack of optimization over time.
Evaluating the effects of changes in functionality, changes in usage patterns, new technologies, and different approaches on the workload is one way to try to increase efficiency.
Limiting the focus on developing expertise in performance optimization in order to prioritize delivery can cause missed opportunities for improving resource usage efficiency.
Removing access performance testing or monitoring tools increases the risk of undetected performance issues. It also limits the ability for a workload team to execute on measure/improve cycles.
Neglecting areas prone to performance degradation, like data stores, can gradually deteriorate query performance and elevate overall system usage.
Related links
Explore the tradeoffs for the other pillars:
Reliability tradeoffs
Security tradeoffs
Operational Excellence tradeoffs
Performance Efficiency tradeoffs
Feedback
Was this page helpful?
Yes
No
Additional resources
Additional resources
In this article
en-us
Your Privacy Choices
Theme
Light
Dark
High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2025