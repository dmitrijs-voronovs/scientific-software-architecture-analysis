quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Testability,"es_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; GTEx_sQTL_Testis_all_snp_gene_associations. View page source. GTEx_sQTL_Testis_all_snp_gene_associations. Versions: v8; Reference genome builds: GRCh38; Type: hail.Table. Schema (v8, GRCh38); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; version: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'phenotype_id': struct {; intron: interval<locus<GRCh38>>,; cluster: str,; gene_id: str; }; 'tss_distance': int32; 'ma_samples': int32; 'ma_count': int32; 'maf': float64; 'pval_nominal': float64; 'slope': float64; 'slope_se': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Testis_all_snp_gene_associations.html:8808,Log,Log,8808,docs/0.2/datasets/schemas/GTEx_sQTL_Testis_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Testis_all_snp_gene_associations.html,1,['Log'],['Log']
Testability,"es_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; GTEx_sQTL_Uterus_all_snp_gene_associations. View page source. GTEx_sQTL_Uterus_all_snp_gene_associations. Versions: v8; Reference genome builds: GRCh38; Type: hail.Table. Schema (v8, GRCh38); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; version: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'phenotype_id': struct {; intron: interval<locus<GRCh38>>,; cluster: str,; gene_id: str; }; 'tss_distance': int32; 'ma_samples': int32; 'ma_count': int32; 'maf': float64; 'pval_nominal': float64; 'slope': float64; 'slope_se': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Uterus_all_snp_gene_associations.html:8808,Log,Log,8808,docs/0.2/datasets/schemas/GTEx_sQTL_Uterus_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Uterus_all_snp_gene_associations.html,1,['Log'],['Log']
Testability,"es_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; GTEx_sQTL_Vagina_all_snp_gene_associations. View page source. GTEx_sQTL_Vagina_all_snp_gene_associations. Versions: v8; Reference genome builds: GRCh38; Type: hail.Table. Schema (v8, GRCh38); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; version: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'phenotype_id': struct {; intron: interval<locus<GRCh38>>,; cluster: str,; gene_id: str; }; 'tss_distance': int32; 'ma_samples': int32; 'ma_count': int32; 'maf': float64; 'pval_nominal': float64; 'slope': float64; 'slope_se': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Vagina_all_snp_gene_associations.html:8808,Log,Log,8808,docs/0.2/datasets/schemas/GTEx_sQTL_Vagina_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Vagina_all_snp_gene_associations.html,1,['Log'],['Log']
Testability,"esent values 0 or 1) or Boolean, in which case; true and false are coded as 1 and 0, respectively.; Hail supports the Wald test (‘wald’), likelihood ratio test (‘lrt’),; Rao score test (‘score’), and Firth test (‘firth’). Hail only includes; columns for which the response variable and all covariates are defined.; For each row, Hail imputes missing input values as the mean of the; non-missing values.; The example above considers a model of the form. \[\mathrm{Prob}(\mathrm{is\_case}) =; \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt}; + \beta_2 \, \mathrm{age}; + \beta_3 \, \mathrm{is\_female} + \varepsilon),; \quad; \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid function, the genotype; \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for Het, and 2 for; HomVar, and the Boolean covariate \(\mathrm{is\_female}\) is coded as; for True (female) and 0 for False (male). The null model sets; \(\beta_1 = 0\).; The structure of the emitted row field depends on the test statistic as; shown in the tables below. Test; Field; Type; Value. Wald; beta; float64; fit effect coefficient,; \(\hat\beta_1\). Wald; standard_error; float64; estimated standard error,; \(\widehat{\mathrm{se}}\). Wald; z_stat; float64; Wald \(z\)-statistic, equal to; \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; p_value; float64; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; beta; float64; fit effect coefficient,; \(\hat\beta_1\). LRT, Firth; chi_sq_stat; float64; deviance statistic. LRT, Firth; p_value; float64; LRT / Firth p-value testing; \(\beta_1 = 0\). Score; chi_sq_stat; float64; score statistic. Score; p_value; float64; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for; each row using Newton iteration and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:9150,test,test,9150,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['test']
Testability,"ession of type tint64 or) – :obj: tuple of Expression of type tint64. Examples; >>> v = hl.nd.array([1, 2, 3, 4]) ; >>> m = v.reshape((2, 2)) . Returns:; NDArrayExpression. property shape; The shape of this ndarray.; Examples; >>> hl.eval(nd.shape); (2, 2). Returns:; TupleExpression. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. sum(axis=None)[source]; Sum out one or more axes of an ndarray. Parameters:; axis (int tuple) – The axis or axes to sum out. Returns:; NDArrayNumericExpression or NumericExpression. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. transpose",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.NDArrayNumericExpression.html:9846,log,logging,9846,docs/0.2/hail.expr.NDArrayNumericExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.NDArrayNumericExpression.html,1,['log'],['logging']
Testability,"ession of type tint64 or) – :obj: tuple of Expression of type tint64. Examples; >>> v = hl.nd.array([1, 2, 3, 4]) ; >>> m = v.reshape((2, 2)) . Returns:; NDArrayExpression. property shape; The shape of this ndarray.; Examples; >>> hl.eval(nd.shape); (2, 2). Returns:; TupleExpression. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. transpose(axes=None)[source]; Permute the dimensions of this ndarray according to the ordering of axes. Axis j in the ith index of; axes maps the jth dimension of the ndarray to the ith dimen",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.NDArrayExpression.html:7154,log,logging,7154,docs/0.2/hail.expr.NDArrayExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.NDArrayExpression.html,1,['log'],['logging']
Testability,"ession or Int64Expression. hail.expr.functions.bit_not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representation of 7 is 111, so:; >>> hl.eval(hl.bit_count(7)); 3. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression. hail.expr.functions.exp(x)[source]. hail.expr.functions.expit(x)[source]. hail.expr.functions.is_nan(x)[source]. hail.expr.functions.is_finite(x)[source]. hail.expr.functions.is_infinite(x)[source]. hail.expr.functions.log(x, base=None)[source]; Take the logarithm of the x with base base.; Examples; >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; If the base argument is not supplied, then the natural logarithm is used. Parameters:. x (float or Expression of type tfloat64); base (float or Expression of type tfloat64). Returns:; Expression of type tfloat64. hail.expr.functions.log10(x)[source]. hail.expr.functions.logit(x)[source]. hail.expr.functions.floor(x)[source]. hail.expr.functions.ceil(x)[source]. hail.expr.functions.sqrt(x)[source]. hail.expr.functions.sign(x)[source]; Returns the sign of a numeric value, array or ndarray.; Examples; >>> hl.eval(hl.sign(-1.23)); -1.0. >>> hl.eval(hl.sign([-4, 0, 5])); [-1, 0, 1]. >>> hl.eval(hl.sign([0.0, 3.14])); [0.0, 1.0]. >>> hl.eval(hl.sign(float('nan'))); nan. Notes; The sign function preserves type and maps nan to nan. Parameters:; x (NumericExpression, ArrayNumericExpression or NDArrayNumericExpression). Returns:; NumericExpression, ArrayNumericExpression or NDArrayNumericExpression. hail.expr.functions.min(*exprs, filter_missing=True)[source]; Returns t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:7500,log,log,7500,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['log']
Testability,"ession refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. size()[source]; Returns the size of a collection.; Examples; >>> hl.eval(a.size()); 5. >>> hl.eval(s3.size()); 3. Returns:; Expression of type tint32 – The number of elements in the collection. starmap(f)[source]; Transform each element of a collection of tuples.; Examples; >>> hl.eval(hl.array([(1, 2), (2, 3)]).starmap(lambda x, y: x+y)); [3, 5]. Parameters:; f (function ( (*args) -> Expression)) – Function to transform each element of the collection. Returns:; CollectionExpression. – Collection where each element has been transformed according to f. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.CollectionExpression.html:11244,test,tested,11244,docs/0.2/hail.expr.CollectionExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.CollectionExpression.html,1,['test'],['tested']
Testability,"ession) – Expression for x-axis (from a Hail table).; y (NumericExpression) – Expression for y-axis (from the same Hail table as x).; bins (int or [int, int]) – The bin specification:; - If int, the number of bins for the two dimensions (nx = ny = bins).; - If [int, int], the number of bins in each dimension (nx, ny = bins).; The default value is 40.; range (None or ((float, float), (float, float))) – The leftmost and rightmost edges of the bins along each dimension:; ((xmin, xmax), (ymin, ymax)). All values outside of this range will be considered outliers; and not tallied in the histogram. If this value is None, or either of the inner lists is None,; the range will be computed from the data.; width (int) – Plot width (default 600px).; height (int) – Plot height (default 600px).; title (str) – Title of the plot.; colors (Sequence[str]) – List of colors (hex codes, or strings as described; here). Compatible with one of the many; built-in palettes available here.; log (bool) – Plot the log10 of the bin counts. Returns:; bokeh.plotting.figure. hail.plot.scatter(x, y, label=None, title=None, xlabel=None, ylabel=None, size=4, legend=True, hover_fields=None, colors=None, width=800, height=800, collect_all=None, n_divisions=500, missing_label='NA')[source]; Create an interactive scatter plot.; x and y must both be either:; - a NumericExpression from the same Table.; - a tuple (str, NumericExpression) from the same Table. If passed as a tuple the first element is used as the hover label.; If no label or a single label is provided, then returns bokeh.plotting.figure; Otherwise returns a bokeh.models.layouts.Column containing:; - a bokeh.models.widgets.inputs.Select dropdown selection widget for labels; - a bokeh.plotting.figure containing the interactive scatter plot; Points will be colored by one of the labels defined in the label using the color scheme defined in; the corresponding entry of colors if provided (otherwise a default scheme is used). To specify your color; m",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/plot.html:5916,log,log,5916,docs/0.2/plot.html,https://hail.is,https://hail.is/docs/0.2/plot.html,1,['log'],['log']
Testability,"esting :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. ================ =========================== ======= =====; Test Annotation Type Value; ================ =========================== ======= =====; Wald, LRT, Firth ``va.logreg.fit.nIter`` Int number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth); Wald, LRT, Firth ``va.logreg.fit.converged`` Boolean true if iteration converged; Wald, LRT, Firth ``va.logreg.fit.exploded`` Boolean true if iteration exploded; ================ =========================== ======= =====. We consider iteration to have converged when every coordinate of :math:`\\beta` changes by less than :math:`10^{-6}`. For Wald and LRT, up to 25 iterations are attempted; in testing we find 4 or 5 iterations nearly always suffice. Convergence may also fail due to explosion, which refers to low-level numerical linear algebra exceptions caused by manipulating ill-conditioned matrices. Explosion may result from (nearly) linearly dependent covariates or complete `separation <https://en.wikipedia.org/wiki/Separation_(statistics)>`__. A more common situation in genetics is quasi-complete seperation, e.g. variants that are observed only in cases (or co",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:142930,log,logreg,142930,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"ests. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; test : {'wald', 'lrt', 'score', 'firth'}; Statistical test.; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table. Returns; -------; :class:`.Table`; """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""). y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). # _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_names = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field_names, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows').",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:57161,test,test,57161,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"eta=hl.missing(hl.tfloat64),; chi_sq_stat=hl.missing(hl.tfloat64),; p_value=hl.missing(hl.tfloat64),; firth_null_fit=hl.missing(firth_improved_null_fit.dtype),; fit=hl.missing(firth_fit.dtype),; ); return (; hl.case(); .when(; firth_improved_null_fit.converged,; hl.case(); .when(; firth_fit.converged,; hl.struct(; beta=firth_fit.b[firth_fit.b.shape[0] - 1],; chi_sq_stat=firth_chi_sq,; p_value=firth_p,; firth_null_fit=firth_improved_null_fit,; fit=firth_fit,; ),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit, fit=firth_fit)),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit)); ). return hl.bind(cont2, firth_fit). return hl.bind(cont, firth_improved_null_fit). @typecheck(; test=enumeration('wald', 'lrt', 'score', 'firth'),; y=oneof(expr_float64, sequenceof(expr_float64)),; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=nullable(int),; tolerance=nullable(float),; ); def _logistic_regression_rows_nd(; test, y, x, covariates, pass_through=(), *, max_iterations: Optional[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covar",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:46744,test,test,46744,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,8,"['log', 'test']","['logistic', 'test']"
Testability,"etattribute__(self, item):; if item in super().__getattribute__('_warn_on_shadowed_name'):; warning(; f'Field {item} is shadowed by another method or attribute. '; f'Use [""{item}""] syntax to access the field.'; ); self._warn_on_shadowed_name.remove(item); return super().__getattribute__(item). def __getattr__(self, item):; raise AttributeError(get_nice_attr_error(self, item)). def __len__(self):; return len(self._fields). def __bool__(self):; return bool(len(self)). [docs] @typecheck_method(item=oneof(str, int, slice)); def __getitem__(self, item):; """"""Access a field of the struct by name or index. Examples; --------. >>> hl.eval(struct['a']); 5. >>> hl.eval(struct[1]); 'Foo'. Parameters; ----------; item : :class:`str`; Field name. Returns; -------; :class:`.Expression`; Struct field.; """"""; if isinstance(item, str):; return self._get_field(item); if isinstance(item, int):; return self._get_field(self.dtype.fields[item]); else:; assert item.start is None or isinstance(item.start, int); assert item.stop is None or isinstance(item.stop, int); assert item.step is None or isinstance(item.step, int); return self.select(*self.dtype.fields[item.start : item.stop : item.step]). def __iter__(self):; return iter(self._fields). def __contains__(self, item):; return item in self._fields. def __hash__(self):; return object.__hash__(self). [docs] def __eq__(self, other):; """"""Check each field for equality. Parameters; ----------; other : :class:`.Expression`; An expression of the same type.; """"""; return Expression.__eq__(self, other). [docs] def __ne__(self, other):; return Expression.__ne__(self, other). def __nonzero__(self):; return Expression.__nonzero__(self). def _annotate_ordered(self, insertions_dict, field_order):; def get_type(field):; e = insertions_dict.get(field); if e is None:; e = self._fields[field]; return e.dtype. new_type = hl.tstruct(**{f: get_type(f) for f in field_order}); indices, aggregations = unify_all(self, *insertions_dict.values()); return construct_exp",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:45867,assert,assert,45867,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['assert'],['assert']
Testability,"eters:. c1 (int or Expression of type tint32) – Value for cell 1.; c2 (int or Expression of type tint32) – Value for cell 2.; c3 (int or Expression of type tint32) – Value for cell 3.; c4 (int or Expression of type tint32) – Value for cell 4. Returns:; StructExpression – A tstruct expression with four fields, p_value; (tfloat64), odds_ratio (tfloat64),; ci_95_lower (:py:data:.tfloat64`), and ci_95_upper; (tfloat64). hail.expr.functions.contingency_table_test(c1, c2, c3, c4, min_cell_count)[source]; Performs chi-squared or Fisher’s exact test of independence on a 2x2; contingency table.; Examples; >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=22)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=23)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967). Notes; If all cell counts are at least min_cell_count, the chi-squared test is; used. Otherwise, Fisher’s exact test is used.; Returned fields may be nan or inf. Parameters:. c1 (int or Expression of type tint32) – Value for cell 1.; c2 (int or Expression of type tint32) – Value for cell 2.; c3 (int or Expression of type tint32) – Value for cell 3.; c4 (int or Expression of type tint32) – Value for cell 4.; min_cell_count (int or Expression of type tint32) – Minimum count in every cell to use the chi-squared test. Returns:; StructExpression – A tstruct expression with two fields, p_value; (tfloat64) and odds_ratio (tfloat64). hail.expr.functions.cochran_mantel_haenszel_test(a, b, c, d)[source]; Perform the Cochran-Mantel-Haenszel test for association.; Examples; >>> a = [56, 61, 73, 71]; >>> b = [69, 257, 65, 48]; >>> c = [40, 57, 71, 55]; >>> d = [77, 301, 79, 48]; >>> hl.eval(hl.cochran_mantel_haenszel_test(a, b, c, d)); Struct(test_statistic=5.0496881823306765, p_value=0.024630370456863417). >>> mt = ds.filter_rows(mt.locus == hl.Locus(20, 10633237)); >>> mt.count_rows(); 1; >>> a, b,",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:5641,test,test,5641,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['test'],['test']
Testability,"etics; plot; ggplot; vds; experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; Functions; Numeric functions. View page source. Numeric functions; Numeric functions. abs(x); Take the absolute value of a numeric value, array or ndarray. approx_equal(x, y[, tolerance, absolute, ...]); Tests whether two numbers are approximately equal. bit_and(x, y); Bitwise and x and y. bit_or(x, y); Bitwise or x and y. bit_xor(x, y); Bitwise exclusive-or x and y. bit_lshift(x, y); Bitwise left-shift x by y. bit_rshift(x, y[, logical]); Bitwise right-shift x by y. bit_not(x); Bitwise invert x. bit_count(x); Count the number of 1s in the in the two's complement binary representation of x. exp(x). expit(x). is_nan(x). is_finite(x). is_infinite(x). log(x[, base]); Take the logarithm of the x with base base. log10(x). logit(x). sign(x); Returns the sign of a numeric value, array or ndarray. sqrt(x). int(x); Convert to a 32-bit integer expression. int32(x); Convert to a 32-bit integer expression. int64(x); Convert to a 64-bit integer expression. float(x); Convert to a 64-bit floating point expression. float32(x); Convert to a 32-bit floating point expression. float64(x); Convert to a 64-bit floating point expression. floor(x). ceil(x). uniroot(f, min, max, *[, max_iter, epsilon, ...]); Finds a root of the function f within the interval [min, max]. Numeric collection functions. min(*exprs[, filter_missing]); Returns the minimum element of a collection or of given numeric expressions. nanmin(*exprs[, filter_missing]); Returns the minimum value of a collection or of given arguments, excluding NaN. max(*exprs[, filter_missing]); Returns the maximum element of a collection or of given numeric expressions. nanmax(*exprs[, filter_missing]); Returns the maximum value ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:1307,log,log,1307,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,2,['log'],"['log', 'logarithm']"
Testability,"etric matrix, we can eigendecompose it into an; orthogonal matrix and a diagonal matrix of eigenvalues:. .. math::. \begin{align*}; U \Lambda U^T &= B \quad\quad \Lambda \textrm{ diagonal } U \textrm{ orthogonal} \\; Q &= h^T U \Lambda U^T h; \end{align*}. An orthogonal matrix transforms a vector of i.i.d. standard normal variables into a new vector; of different i.i.d standard normal variables, so we can interpret :math:`Q` as a weighted sum of; i.i.d. standard normal variables:. .. math::. \begin{align*}; \tilde{h} &= U^T h \\; Q &= \sum_s \Lambda_{ss} \tilde{h}_s^2; \end{align*}. The distribution of such sums (indeed, any quadratic form of i.i.d. standard normal variables); is governed by the generalized chi-squared distribution (the CDF is available in Hail as; :func:`.pgenchisq`):. .. math::. \begin{align*}; \lambda_i &= \Lambda_{ii} \\; Q &\sim \mathrm{GeneralizedChiSquared}(\lambda, \vec{1}, \vec{0}, 0, 0); \end{align*}. Therefore, we can test the null hypothesis by calculating the probability of receiving values; larger than :math:`Q`. If that probability is very small, then the residual phenotypes are; likely not i.i.d. normal variables with variance :math:`\widehat{\sigma}^2`. The SKAT method was originally described in:. Wu MC, Lee S, Cai T, Li Y, Boehnke M, Lin X. *Rare-variant association testing for; sequencing data with the sequence kernel association test.* Am J Hum Genet. 2011 Jul; 15;89(1):82-93. doi: 10.1016/j.ajhg.2011.05.029. Epub 2011 Jul 7. PMID: 21737059; PMCID:; PMC3135811. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3135811/. Examples; --------. Generate a dataset with a phenotype noisily computed from the genotypes:. >>> hl.reset_global_randomness(); >>> mt = hl.balding_nichols_model(1, n_samples=100, n_variants=20); >>> mt = mt.annotate_rows(gene = mt.locus.position // 12); >>> mt = mt.annotate_rows(weight = 1); >>> mt = mt.annotate_cols(phenotype = hl.agg.sum(mt.GT.n_alt_alleles()) - 20 + hl.rand_norm(0, 1)). Test if the phenotype is si",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:74976,test,test,74976,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"ets; \(\beta_1 = 0\).; The structure of the emitted row field depends on the test statistic as; shown in the tables below. Test; Field; Type; Value. Wald; beta; float64; fit effect coefficient,; \(\hat\beta_1\). Wald; standard_error; float64; estimated standard error,; \(\widehat{\mathrm{se}}\). Wald; z_stat; float64; Wald \(z\)-statistic, equal to; \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; p_value; float64; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; beta; float64; fit effect coefficient,; \(\hat\beta_1\). LRT, Firth; chi_sq_stat; float64; deviance statistic. LRT, Firth; p_value; float64; LRT / Firth p-value testing; \(\beta_1 = 0\). Score; chi_sq_stat; float64; score statistic. Score; p_value; float64; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for; each row using Newton iteration and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. Test; Field; Type; Value. Wald, LRT, Firth; fit.n_iterations; int32; number of iterations until; convergence, explosion, or; reaching the max (by default,; 25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; fit.converged; bool; True if iteration converged. Wald, LRT, Firth; fit.exploded; bool; True if iteration exploded. We consider iteration to have converged when every coordinate of; \(\beta\) changes by less than \(10^{-6}\) by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation.; A more common situation in genetics",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:10056,test,test,10056,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['test']
Testability,"eturn construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`, :func:`.if_else`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `condition`.; """"""; return if_else(condition, consequent, alternate, missing_false). [docs]@typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def if_else(condition, consequent, alternate, missing_false: bool = False):; """"""Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.if_else(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.if_else(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:13229,test,test,13229,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"eturn the result of aggregating by group. Examples; --------; Aggregate to a matrix with genes as row keys, collecting the functional; consequences per gene as a row field and computing the number of; non-reference calls as an entry field:. >>> dataset_result = (dataset.group_rows_by(dataset.gene); ... .aggregate_rows(consequences = hl.agg.collect_as_set(dataset.consequence)); ... .aggregate_entries(n_non_ref = hl.agg.count_where(dataset.GT.is_non_ref())); ... .result()). Aggregate to a matrix with cohort as column keys, computing the mean height; per cohort as a column field and computing the number of non-reference calls; as an entry field:. >>> dataset_result = (dataset.group_cols_by(dataset.cohort); ... .aggregate_cols(mean_height = hl.agg.stats(dataset.pheno.height).mean); ... .aggregate_entries(n_non_ref = hl.agg.count_where(dataset.GT.is_non_ref())); ... .result()). See Also; --------; :meth:`.aggregate`. Returns; -------; :class:`.MatrixTable`; Aggregated matrix table.; """"""; assert self._row_keys is not None or self._col_keys is not None. defined_exprs = []; for e in [self._row_fields, self._col_fields, self._entry_fields]:; if e is not None:; defined_exprs.append(e); for e in [self._computed_row_key, self._computed_col_key]:; if e is not None:; defined_exprs.extend(e.values()). def promote_none(e):; return hl.struct() if e is None else e. entry_exprs = promote_none(self._entry_fields); if len(entry_exprs) == 0:; warning(""'GroupedMatrixTable.result': No entry fields were defined.""). base, cleanup = self._parent._process_joins(*defined_exprs). if self._col_keys is not None:; cck = self._computed_col_key or {}; computed_key_uids = {k: Env.get_uid() for k in cck}; modified_keys = [computed_key_uids.get(k, k) for k in self._col_keys]; mt = MatrixTable(; ir.MatrixAggregateColsByKey(; ir.MatrixMapCols(; base._mir,; self._parent.col.annotate(**{computed_key_uids[k]: v for k, v in cck.items()})._ir,; modified_keys,; ),; entry_exprs._ir,; promote_none(self._col_fields",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:13350,assert,assert,13350,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,['assert'],['assert']
Testability,"eturn: Annotated dataset.; :rtype: :py:class:`.VariantDataset`; """""". jvds = self._jvdf.imputeSex(maf_threshold, include_par, female_threshold, male_threshold, joption(pop_freq)); return VariantDataset(self.hc, jvds). [docs] @handle_py4j; @typecheck_method(right=vds_type); def join(self, right):; """"""Join two variant datasets. **Notes**. This method performs an inner join on variants,; concatenates samples, and takes variant and; global annotations from the left dataset (self). The datasets must have distinct samples, the same sample schema, and the same split status (both split or both multi-allelic). :param right: right-hand variant dataset; :type right: :py:class:`.VariantDataset`. :return: Joined variant dataset; :rtype: :py:class:`.VariantDataset`; """""". return VariantDataset(self.hc, self._jvds.join(right._jvds)). [docs] @handle_py4j; @typecheck(datasets=tupleof(vds_type)); def union(*datasets):; """"""Take the union of datasets vertically (include all variants). **Examples**. .. testsetup::. vds_autosomal = vds; vds_chromX = vds; vds_chromY = vds. Union two datasets:. >>> vds_union = vds_autosomal.union(vds_chromX). Given a list of datasets, union them all:. >>> all_vds = [vds_autosomal, vds_chromX, vds_chromY]. The following three syntaxes are equivalent:. >>> vds_union1 = vds_autosomal.union(vds_chromX, vds_chromY); >>> vds_union2 = all_vds[0].union(*all_vds[1:]); >>> vds_union3 = VariantDataset.union(*all_vds). **Notes**. In order to combine two datasets, these requirements must be met:; - the samples must match; - the variant annotation schemas must match (field order within structs matters).; - the cell (genotype) schemas must match (field order within structs matters). The column annotations in the resulting dataset are simply the column annotations; from the first dataset; the column annotation schemas do not need to match. This method can trigger a shuffle, if partitions from two datasets overlap. :param vds_type: Datasets to combine.; :type vds_type: tuple ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:91219,test,testsetup,91219,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['testsetup']
Testability,"eturns h, tau with dimensions (N, M), (K,). Notes; -----. The reduced QR, the default output of this function, has the following properties:. .. math::. m \ge n \\; nd : \mathbb{R}^{m \times n} \\; Q : \mathbb{R}^{m \times n} \\; R : \mathbb{R}^{n \times n} \\; \\; Q^T Q = \mathbb{1}. The complete QR, has the following properties:. .. math::. m \ge n \\; nd : \mathbb{R}^{m \times n} \\; Q : \mathbb{R}^{m \times m} \\; R : \mathbb{R}^{m \times n} \\; \\; Q^T Q = \mathbb{1}; Q Q^T = \mathbb{1}. Parameters; ----------; nd : :class:`.NDArrayExpression`; A 2 dimensional ndarray, shape(M, N); mode : :class:`.str`; One of ""reduced"", ""complete"", ""r"", or ""raw"". Defaults to ""reduced"". Returns; -------; - q: ndarray of float64; A matrix with orthonormal columns.; - r: ndarray of float64; The upper-triangular matrix R.; - (h, tau): ndarrays of float64; The array h contains the Householder reflectors that generate q along with r.; The tau array contains scaling factors for the reflectors; """""". assert nd.ndim == 2, f""QR decomposition requires 2 dimensional ndarray, found: {nd.ndim}"". if mode not in [""reduced"", ""r"", ""raw"", ""complete""]:; raise ValueError(f""Unrecognized mode '{mode}' for QR decomposition""). float_nd = nd.map(lambda x: hl.float64(x)); ir = NDArrayQR(float_nd._ir, mode); indices = nd._indices; aggs = nd._aggregations; if mode == ""raw"":; return construct_expr(ir, ttuple(tndarray(tfloat64, 2), tndarray(tfloat64, 1)), indices, aggs); elif mode == ""r"":; return construct_expr(ir, tndarray(tfloat64, 2), indices, aggs); elif mode in [""complete"", ""reduced""]:; return construct_expr(ir, ttuple(tndarray(tfloat64, 2), tndarray(tfloat64, 2)), indices, aggs). [docs]@typecheck(nd=expr_ndarray(), full_matrices=bool, compute_uv=bool); def svd(nd, full_matrices=True, compute_uv=True):; """"""Performs a singular value decomposition. Parameters; ----------; nd : :class:`.NDArrayNumericExpression`; A 2 dimensional ndarray, shape(M, N).; full_matrices: :class:`.bool`; If True (default), u and ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/nd/nd.html:10516,assert,assert,10516,docs/0.2/_modules/hail/nd/nd.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/nd/nd.html,2,['assert'],['assert']
Testability,"evel Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; Functions; Numeric functions. View page source. Numeric functions; Numeric functions. abs(x); Take the absolute value of a numeric value, array or ndarray. approx_equal(x, y[, tolerance, absolute, ...]); Tests whether two numbers are approximately equal. bit_and(x, y); Bitwise and x and y. bit_or(x, y); Bitwise or x and y. bit_xor(x, y); Bitwise exclusive-or x and y. bit_lshift(x, y); Bitwise left-shift x by y. bit_rshift(x, y[, logical]); Bitwise right-shift x by y. bit_not(x); Bitwise invert x. bit_count(x); Count the number of 1s in the in the two's complement binary representation of x. exp(x). expit(x). is_nan(x). is_finite(x). is_infinite(x). log(x[, base]); Take the logarithm of the x with base base. log10(x). logit(x). sign(x); Returns the sign of a numeric value, array or ndarray. sqrt(x). int(x); Convert to a 32-bit integer expression. int32(x); Convert to a 32-bit integer expression. int64(x); Convert to a 64-bit integer expression. float(x); Convert to a 64-bit floating point expression. float32(x); Convert to a 32-bit floating point expression. float64(x); Convert to a 64-bit floating point expression. floor(x). ceil(x). uniroot(f, min, max, *[, max_iter, epsilon, ...]); Finds a root of the function f within the interval [min, max]. Numeric collection functions. min(*exprs[, filter_missing]); Returns the minimum element of a collection or of given numeric expressions. nanmin(*exprs[, filter_missing]); Returns the minimum value of a collection or of given arguments, excluding NaN. max(*exprs[, filter_missing]); Returns the maximum element of a collection or of given numeric expressions. nanmax(*exprs[, filter_missing]); Returns the maximum value of a collection or of given arguments, exclud",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:1377,log,logit,1377,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['logit']
Testability,"evels.find(lambda w: y >= w)); ).aggregate(c=hail.agg.count()); data = grouped_ht.filter(; hail.is_defined(grouped_ht.x); & (grouped_ht.x != str(x_range[1])); & hail.is_defined(grouped_ht.y); & (grouped_ht.y != str(y_range[1])); ); return data. def _collect_scatter_plot_data(; x: Tuple[str, NumericExpression],; y: Tuple[str, NumericExpression],; fields: Optional[Dict[str, Expression]] = None,; n_divisions: Optional[int] = None,; missing_label: str = 'NA',; ) -> pd.DataFrame:; expressions = dict(); if fields is not None:; expressions.update({; k: hail.or_else(v, missing_label) if isinstance(v, StringExpression) else v for k, v in fields.items(); }). if n_divisions is None:; collect_expr = hail.struct(**dict((k, v) for k, v in (x, y)), **expressions); plot_data = [point for point in collect_expr.collect() if point[x[0]] is not None and point[y[0]] is not None]; source_pd = pd.DataFrame(plot_data); else:; # FIXME: remove the type conversion logic if/when downsample supports continuous values for labels; # Save all numeric types to cast in DataFrame; numeric_expr = {k: 'int32' for k, v in expressions.items() if isinstance(v, Int32Expression)}; numeric_expr.update({k: 'int64' for k, v in expressions.items() if isinstance(v, Int64Expression)}); numeric_expr.update({k: 'float32' for k, v in expressions.items() if isinstance(v, Float32Expression)}); numeric_expr.update({k: 'float64' for k, v in expressions.items() if isinstance(v, Float64Expression)}). # Cast non-string types to string; expressions = {k: hail.str(v) if not isinstance(v, StringExpression) else v for k, v in expressions.items()}. agg_f = x[1]._aggregation_method(); res = agg_f(; hail.agg.downsample(; x[1], y[1], label=list(expressions.values()) if expressions else None, n_divisions=n_divisions; ); ); source_pd = pd.DataFrame([; dict(; **{x[0]: point[0], y[0]: point[1]},; **(dict(zip(expressions, point[2])) if point[2] is not None else {}),; ); for point in res; ]); source_pd = source_pd.astype(numeric_expr, co",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:23253,log,logic,23253,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['log'],['logic']
Testability,"eviation `sigma`. Returns density of standard normal; distribution by default. Examples; --------. >>> hl.eval(hl.dnorm(1)); 0.24197072451914337. >>> hl.eval(hl.dnorm(1, mu=1, sigma=2)); 0.19947114020071635. >>> hl.eval(hl.dnorm(1, log_p=True)); -1.4189385332046727. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Real number at which to compute the probability density.; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The probability density.; """"""; return _func(""dnorm"", tfloat64, x, mu, sigma, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, log_p=expr_bool); def dpois(x, lamb, log_p=False) -> Float64Expression:; """"""Compute the (log) probability density at x of a Poisson distribution with rate parameter `lamb`. Examples; --------. >>> hl.eval(hl.dpois(5, 3)); 0.10081881344492458. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Non-negative number at which to compute the probability density.; lamb : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Poisson rate parameter. Must be non-negative.; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The (log) probability density.; """"""; return _func(""dpois"", tfloat64, x, lamb, log_p). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def exp(x) -> Float64Expression:; """"""Computes `e` raised to the power `x`. Examples; --------. >>> hl.eval(hl.exp(2)); 7.38905609893065. Parameters; ----------; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:29670,log,log,29670,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['log']
Testability,"ew rows of the matrix table to the console. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. Notes; The output can be passed piped to another output source using the handler argument:; >>> mt.show(handler=lambda x: logging.info(x)) . Parameters:. n_rows (int) – Maximum number of rows to show.; n_cols (int) – Maximum number of columns to show.; width (int) – Horizontal width at which to break fields.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field.; handler (Callable[[str], Any]) – Handler function for data string. summarize(*, rows=True, cols=True, entries=True, handler=None)[source]; Compute and print summary information about the fields in the matrix table. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. Parameters:. rows (bool) – Compute summary for the row fields.; cols (bool) – Compute summary for the column fields.; entries (bool) – Compute summary for the entry fields. tail(n_rows, n_cols=None, *, n=None)[source]; Subset matrix to last n rows.; Examples; >>> mt_range = hl.utils.range_matrix_table(100, 100). Passing only one argument will take the last n rows:; >>> mt_range.tail(10).count(); (10, 100). Passing two arguments refers to rows and columns, respectively:; >>> mt_range.tail(10, 20).count(); (10, 20). Either argument may be None to indicate no filter.; Last 10 rows, all columns:; >>> mt_range.tail(10, None).count(); (10, 100). All rows, last 10 columns:; >>> mt_range.tail(None, 10).count(); (100, 10). Notes; For backwards compatibility, the n parameter is not named n_rows,; but the parameter refers to the number of rows to keep.; The number of partitions in the new matrix is equal to the number of; partitions containing the ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.MatrixTable.html:61039,test,tested,61039,docs/0.2/hail.MatrixTable.html,https://hail.is,https://hail.is/docs/0.2/hail.MatrixTable.html,1,['test'],['tested']
Testability,"expr(x, dtype, indices, aggregations); elif isinstance(dtype, ttuple):; elements = []; found_expr = False; assert len(e) == len(dtype.types); for i in range(len(e)):; value = _to_expr(e[i], dtype.types[i]); found_expr = found_expr or isinstance(value, Expression); elements.append(value); if not found_expr:; return e; else:; exprs = [; elements[i] if isinstance(elements[i], Expression) else hl.literal(elements[i], dtype.types[i]); for i in range(len(elements)); ]; indices, aggregations = unify_all(*exprs); x = ir.MakeTuple([expr._ir for expr in exprs]); return expressions.construct_expr(x, dtype, indices, aggregations); elif isinstance(dtype, tdict):; keys = []; values = []; found_expr = False; for k, v in e.items():; k_ = _to_expr(k, dtype.key_type); v_ = _to_expr(v, dtype.value_type); found_expr = found_expr or isinstance(k_, Expression); found_expr = found_expr or isinstance(v_, Expression); keys.append(k_); values.append(v_); if not found_expr:; return e; else:; assert len(keys) > 0; # Here I use `to_expr` to call `lit` the keys and values separately.; # I anticipate a common mode is statically-known keys and Expression; # values.; key_array = to_expr(keys, tarray(dtype.key_type)); value_array = to_expr(values, tarray(dtype.value_type)); return hl.dict(hl.zip(key_array, value_array)); elif isinstance(dtype, hl.tndarray):; return hl.nd.array(e); else:; raise NotImplementedError(dtype). def unify_all(*exprs) -> Tuple[Indices, LinkedList]:; if len(exprs) == 0:; return Indices(), LinkedList(Aggregation); try:; new_indices = Indices.unify(*[e._indices for e in exprs]); except ExpressionException:; # source mismatch; from collections import defaultdict. sources = defaultdict(lambda: []); for e in exprs:; from .expression_utils import get_refs. for name, inds in get_refs(e, *[e for a in e._aggregations for e in a.exprs]).items():; sources[inds.source].append(str(name)); raise ExpressionException(; ""Cannot combine expressions from different source objects.""; ""\n Found fie",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html:12337,assert,assert,12337,docs/0.2/_modules/hail/expr/expressions/base_expression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html,2,['assert'],['assert']
Testability,expr.StringExpression method). lengths (hail.genetics.ReferenceGenome property). lgt_to_gt() (in module hail.vds). liftover() (in module hail.expr.functions). linear_mixed_model() (in module hail.methods). linear_mixed_regression_rows() (in module hail.methods). linear_regression_rows() (in module hail.methods). LinearMixedModel (class in hail.stats). linreg() (in module hail.expr.aggregators). literal() (in module hail.expr.functions). load() (hail.vds.combiner.VariantDatasetCombiner static method). load_combiner() (in module hail.vds.combiner). load_dataset() (in module hail.experimental). local_to_global() (in module hail.vds). localize_entries() (hail.MatrixTable method). Locus (class in hail.genetics). locus() (in module hail.expr.functions). locus_from_global_position() (hail.genetics.ReferenceGenome method). (in module hail.expr.functions). locus_interval() (in module hail.expr.functions). locus_windows() (in module hail.linalg.utils). LocusExpression (class in hail.expr). log() (hail.linalg.BlockMatrix method). (in module hail.expr.functions). log10() (in module hail.expr.functions). logistic_regression_rows() (in module hail.methods). logit() (in module hail.expr.functions). loop() (in module hail.experimental). lower() (hail.expr.StringExpression method). ls() (in module hailtop.fs). M. make_betas() (in module hail.experimental.ldscsim). make_table() (hail.MatrixTable method). manhattan() (in module hail.plot). map() (hail.expr.ArrayExpression method). (hail.expr.ArrayNumericExpression method). (hail.expr.CollectionExpression method). (hail.expr.NDArrayExpression method). (hail.expr.NDArrayNumericExpression method). (hail.expr.SetExpression method). (in module hail.expr.functions). map2() (hail.expr.NDArrayExpression method). (hail.expr.NDArrayNumericExpression method). map_values() (hail.expr.DictExpression method). mat_id (hail.genetics.Trio property). matches() (hail.expr.StringExpression method). MatrixTable (class in hail). max() (in module hail.expr.a,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/genindex.html:33426,log,log,33426,docs/0.2/genindex.html,https://hail.is,https://hail.is/docs/0.2/genindex.html,1,['log'],['log']
Testability,"exprs) == 1; and isinstance(col_exprs[0], StructExpression); and types_match(self.col_key.values(), col_exprs[0].values()); ):; return self.index_entries(row_exprs, tuple(col_exprs[0].values())); elif len(col_exprs) != len(self.col_key):; raise ExpressionException(; f'Key mismatch: matrix table has {len(self.col_key)} col key fields, '; f'found {len(col_exprs)} index expressions.'; ); else:; raise ExpressionException(; f""Key type mismatch: cannot index matrix table with given expressions:\n""; f"" MatrixTable col key: {', '.join(str(t) for t in self.col_key.dtype.values())}\n""; f"" Col index expressions: {', '.join(str(e.dtype) for e in col_exprs)}""; ). indices, aggregations = unify_all(*(row_exprs + col_exprs)); src = indices.source; if aggregations:; raise ExpressionException('Cannot join using an aggregated field'). uid = Env.get_uid(); uids = [uid]. if isinstance(src, Table):; # join table with matrix.entries_table(); return self.entries().index(*(row_exprs + col_exprs)); else:; assert isinstance(src, MatrixTable); row_uid = Env.get_uid(); uids.append(row_uid); col_uid = Env.get_uid(); uids.append(col_uid). def joiner(left: MatrixTable):; localized = self._localize_entries(row_uid, col_uid); src_cols_indexed = self.add_col_index(col_uid).cols(); src_cols_indexed = src_cols_indexed.annotate(**{col_uid: hl.int32(src_cols_indexed[col_uid])}); left = left._annotate_all(; row_exprs={row_uid: localized.index(*row_exprs)[row_uid]},; col_exprs={col_uid: src_cols_indexed.index(*col_exprs)[col_uid]},; ); return left.annotate_entries(**{uid: left[row_uid][left[col_uid]]}). join_ir = ir.Join(; ir.ProjectedTopLevelReference('g', uid, self.entry.dtype), uids, [*row_exprs, *col_exprs], joiner; ); return construct_expr(join_ir, self.entry.dtype, indices, aggregations). @typecheck_method(entries_field_name=str, cols_field_name=str); def _localize_entries(self, entries_field_name, cols_field_name) -> 'Table':; assert entries_field_name not in self.row; assert cols_field_name not in s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:96923,assert,assert,96923,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,['assert'],['assert']
Testability,"extreme""); #; # Ergo, we want to check the right-tail of the distribution.; p_value=1.0 - genchisq_data.value,; fault=genchisq_data.fault,; ); return ht.select_globals('y_residual', 's2', 'n_complete_samples'). [docs]@typecheck(; group=expr_any,; weight=expr_float64,; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; max_size=int,; null_max_iterations=int,; null_tolerance=float,; accuracy=numeric,; iterations=int,; ); def _logistic_skat(; group,; weight,; y,; x,; covariates,; max_size: int = 46340,; null_max_iterations: int = 25,; null_tolerance: float = 1e-6,; accuracy: float = 1e-6,; iterations: int = 10000,; ):; r""""""The logistic sequence kernel association test (SKAT). Logistic SKAT tests if the phenotype, `y`, is significantly associated with the genotype,; `x`. For :math:`N` samples, in a group of :math:`M` variants, with :math:`K` covariates, the; model is given by:. .. math::. \begin{align*}; X &: R^{N \times K} \\; G &: \{0, 1, 2\}^{N \times M} \\; \\; Y &\sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_0 X + \beta_1 G)); \end{align*}. The usual null hypothesis is :math:`\beta_1 = 0`. SKAT tests for an association, but does not; provide an effect size or other information about the association. Wu et al. argue that, under the null hypothesis, a particular value, :math:`Q`, is distributed; according to a generalized chi-squared distribution with parameters determined by the genotypes,; weights, and residual phenotypes. The SKAT p-value is the probability of drawing even larger; values of :math:`Q`. If :math:`\widehat{\beta_\textrm{null}}` is the best-fit beta under the; null model:. .. math::. Y \sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_\textrm{null} X)). Then :math:`Q` is defined by Wu et al. as:. .. math::. \begin{align*}; p_i &= \textrm{logit}^{-1}(\widehat{\beta_\textrm{null}} X) \\; r_i &= y_i - p_i \\; W_{ii} &= w_i \\; \\; Q &= r^T G W G^T r; \end{align*}. Therefore :math:`r_i`, the residual phenotype, is the portion of t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:87465,log,logit,87465,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logit']
Testability,"f all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no compactions ergo no error; return 0; elif all_quantiles:; p = compute_grid_size(s); return 1 / p + compute_single_error(s, failure_prob / p); else:; return compute_single_error(s, failure_prob). [docs]@typecheck(t=hail_type); def missing(t: Union[HailType, str]):; """"""Creates an expression representing a missing value of a specified type. Examples; --------. >>> hl.eval(hl.missing(hl.tarray(hl.tstr))); None. >>> hl.eval(hl.missing('array<str>')); None. Notes; -----; This method is useful for constructing an expression that includes missing; values, since :obj:`None` cannot be interpreted as an expression. Parameters; ----------; t : :class:`str` or :class:`.HailType`; Type of the missing expression. Returns; -------; :class:`.Expre",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:7276,log,log,7276,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['log']
Testability,"f partitions; should be substantially faster. Bug Fixes. (#12783) Fixed bug; where logs were not properly transmitted to Python.; (#12812) Fixed bug; where Table/MT._calculate_new_partitions returned unbalanced; intervals with whole-stage code generation runtime.; (#12839) Fixed; hailctl dataproc jupyter notebooks to be compatible with Spark; 3.3, which have been broken since 0.2.110.; (#12855) In; Query-on-Batch, allow writing to requester pays buckets, which was; broken before this release. Version 0.2.112; Released 2023-03-15. Bug Fixes. (#12784) Removed an; internal caching mechanism in Query on Batch that caused stalls in; pipelines with large intermediates. Version 0.2.111; Released 2023-03-13. New Features. (#12581) In Query on; Batch, users can specify which regions to have jobs run in. Bug Fixes. (#12772) Fix; hailctl hdinsight submit to pass args to the files. Version 0.2.110; Released 2023-03-08. New Features. (#12643) In Query on; Batch, hl.skat(..., logistic=True) is now supported.; (#12643) In Query on; Batch, hl.liftover is now supported.; (#12629) In Query on; Batch, hl.ibd is now supported.; (#12722) Add; hl.simulate_random_mating to generate a population from founders; under the assumption of random mating.; (#12701) Query on; Spark now officially supports Spark 3.3.0 and Dataproc 2.1.x. Performance Improvements. (#12679) In Query on; Batch, hl.balding_nichols_model is slightly faster. Also added; hl.utils.genomic_range_table to quickly create a table keyed by; locus. Bug Fixes. (#12711) In Query on; Batch, fix null pointer exception (manifesting as; scala.MatchError: null) when reading data from requester pays; buckets.; (#12739) Fix; hl.plot.cdf, hl.plot.pdf, and hl.plot.joint_plot which; were broken by changes in Hail and changes in bokeh.; (#12735) Fix; (#11738) by allowing; user to override default types in to_pandas.; (#12760) Mitigate; some JVM bytecode generation errors, particularly those related to; too many method parameters.; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:37658,log,logistic,37658,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['log'],['logistic']
Testability,"f quasi-complete seperation in R. Suppose we have 2010 samples distributed as follows for a particular variant:. Status; HomRef; Het; HomVar. Case; 1000; 10; 0. Control; 1000; 0; 0. The following R code fits the (standard) logistic, Firth logistic, and linear regression models to this data, where x is genotype, y is phenotype, and logistf is from the logistf package:; x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085, and 0.0016, respectively. The erroneous value 0.991 is due to quasi-complete separation. Moving one of the 10 hets from case to control eliminates this quasi-complete separation; the p-values from R are then 0.0373, 0.0111, and 0.0116, respectively, as expected for a less significant association.; The Firth test reduces bias from small counts and resolves the issue of separation by penalizing maximum likelihood estimation by the Jeffrey’s invariant prior. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton method is linear rather than quadratic. For Firth, 100 iterations are attempted for the null model and, if that is successful, for the full model as well. In testing we find 20 iterations nearly always suffices. If the null model fails to converge, then the sa.lmmreg.fit annotations reflect the null model; otherwise, they reflect the full model.; See Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants for an empirical comparison of the logistic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert’s notes Statistical Theory. Firth introduced his approach in Bias reduction of maximum likelihood estimates, 1993. Heinze and Schemper fu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:114635,test,test,114635,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"f the collection. Must return a; BooleanExpression. Returns:; BooleanExpression. – True if f returns True for any element, False otherwise. append(item); Append an element to the array and return the result.; Examples; >>> hl.eval(names.append('Dan')); ['Alice', 'Bob', 'Charlie', 'Dan']. Note; This method does not mutate the caller, but instead returns a new; array by copying the caller and adding item. Parameters:; item (Expression) – Element to append, same type as the array element type. Returns:; ArrayExpression. collect(_localize=True); Collect all records of an expression into a local list.; Examples; Collect all the values from C1:; >>> table1.C1.collect(); [2, 2, 10, 11]. Warning; Extremely experimental. Warning; The list of records may be very large. Returns:; list. contains(item); Returns a boolean indicating whether item is found in the array.; Examples; >>> hl.eval(names.contains('Charlie')); True. >>> hl.eval(names.contains('Helen')); False. Parameters:; item (Expression) – Item for inclusion test. Warning; This method takes time proportional to the length of the array. If a; pipeline uses this method on the same array several times, it may be; more efficient to convert the array to a set first early in the script; (set()). Returns:; BooleanExpression – True if the element is found in the array, False otherwise. describe(handler=<built-in function print>); Print information about type, index, and dependencies. property dtype; The data type of the expression. Returns:; HailType. export(path, delimiter='\t', missing='NA', header=True); Export a field to a text file.; Examples; >>> small_mt.GT.export('output/gt.tsv'); >>> with open('output/gt.tsv', 'r') as f:; ... for line in f:; ... print(line, end=''); locus alleles 0 1 2 3; 1:1 [""A"",""C""] 0/1 0/0 0/1 0/0; 1:2 [""A"",""C""] 1/1 0/1 0/1 0/1; 1:3 [""A"",""C""] 0/0 0/1 0/0 0/0; 1:4 [""A"",""C""] 0/1 1/1 0/1 0/1. >>> small_mt.GT.export('output/gt-no-header.tsv', header=False); >>> with open('output/gt-no-header.tsv",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.ArrayNumericExpression.html:7159,test,test,7159,docs/0.2/hail.expr.ArrayNumericExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.ArrayNumericExpression.html,1,['test'],['test']
Testability,"f variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association. The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the `Jeffrey's; invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:32918,log,logistic,32918,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,8,['log'],"['logistf', 'logistic']"
Testability,"f variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association. The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the `Jeffrey's; invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This; test is slower, as both the null and full model must be fit per variant,; and convergence of the modified",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:53374,log,logistic,53374,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,8,['log'],"['logistf', 'logistic']"
Testability,"f you’re not using one of these OSes, set; the environment (or Make) variable HAIL_COMPILE_NATIVES to any value. This; variable tells GNU Make to build the native libraries from source.; Build and install a wheel file from source with local-mode pyspark:; make install HAIL_COMPILE_NATIVES=1. As above, but explicitly specifying the Scala and Spark versions:; make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5. Building the Docs and Website; Install build dependencies listed in the docs style guide.; Build without rendering the notebooks (which is slow):; make hail-docs-do-not-render-notebooks. Build while rendering the notebooks:; make hail-docs. Serve the built website on http://localhost:8000/; (cd build/www && python3 -m http.server). Running the tests; Install development dependencies:; make -C .. install-dev-requirements. A couple Hail tests compare to PLINK 1.9 (not PLINK 2.0 [ignore the confusing; URL]):. PLINK 1.9. Execute every Hail test using at most 8 parallel threads:; make -j8 test. Contributing; Chat with the dev team on our Zulip chatroom or; development forum if you have an idea for a contribution.; We can help you determine if your project is a good candidate for merging.; Keep in mind the following principles when submitting a pull request:. A PR should focus on a single feature. Multiple features should be split into multiple PRs.; Before submitting your PR, you should rebase onto the latest main.; PRs must pass all tests before being merged. See the section above on Running the tests locally.; PRs require a review before being merged. We will assign someone from our dev team to review your PR.; When you make a PR, include a short message that describes the purpose of the; PR and any necessary context for the changes you are making.; For user facing changes (new functions, etc), include “CHANGELOG” in the commit message or PR title.; This helps identify what should be included in the change log when a new version is rel",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/getting_started_developing.html:2355,test,test,2355,docs/0.2/getting_started_developing.html,https://hail.is,https://hail.is/docs/0.2/getting_started_developing.html,2,['test'],['test']
Testability,"f""Method '{method}' requires a field 'alleles' (type 'array<str>')\n""); if dataset.alleles.dtype != tarray(tstr):; raise ValueError(; f""Method '{method}' requires a field 'alleles' (type 'array<str>')\n""; f"" Found:\n""; f"" 'alleles': {dataset.alleles.dtype}""; ). def require_row_key_variant_w_struct_locus(dataset, method):; if (; list(dataset.row_key) != ['locus', 'alleles']; or not dataset['alleles'].dtype == tarray(tstr); or (; not isinstance(dataset['locus'].dtype, tlocus); and dataset['locus'].dtype != hl.dtype('struct{contig: str, position: int32}'); ); ):; raise ValueError(; ""Method '{}' requires row key to be two fields 'locus'""; "" (type 'locus<any>' or 'struct{{contig: str, position: int32}}') and ""; ""'alleles' (type 'array<str>')\n""; "" Found:{}"".format(; method, ''.join(""\n '{}': {}"".format(k, str(dataset[k].dtype)) for k in dataset.row_key); ); ). def require_first_key_field_locus(dataset, method):; if isinstance(dataset, Table):; key = dataset.key; else:; assert isinstance(dataset, MatrixTable); key = dataset.row_key; if len(key) == 0 or not isinstance(key[0].dtype, tlocus):; raise ValueError(; ""Method '{}' requires first key field of type 'locus<any>'.\n"" "" Found:{}"".format(; method, ''.join(""\n '{}': {}"".format(k, str(dataset[k].dtype)) for k in key); ); ). @typecheck(table=Table, method=str); def require_key(table, method):; if len(table.key) == 0:; raise ValueError(""Method '{}' requires a non-empty key"".format(method)). @typecheck(dataset=MatrixTable, method=str, tolerate_generic_locus=bool); def require_biallelic(dataset, method, tolerate_generic_locus: bool = False) -> MatrixTable:; if tolerate_generic_locus:; require_row_key_variant_w_struct_locus(dataset, method); else:; require_row_key_variant(dataset, method); return dataset._select_rows(; method,; hl.case(); .when(dataset.alleles.length() == 2, dataset._rvrow); .or_error(; f""'{method}' expects biallelic variants ('alleles' field of length 2), found ""; + hl.str(dataset.locus); + "", ""; + hl.str(data",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/misc.html:9275,assert,assert,9275,docs/0.2/_modules/hail/methods/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html,2,['assert'],['assert']
Testability,"f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; rais",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11832,assert,assert,11832,docs/0.2/_modules/hail/experimental/db.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html,2,['assert'],['assert']
Testability,"f._when_missing_case is not None:; expr = hl.if_else(hl.is_missing(base), self._when_missing_case, expr); return expr. return hl.bind(f, self._base). [docs] @typecheck_method(value=expr_any, then=expr_any); def when(self, value, then) -> 'SwitchBuilder':; """"""Add a value test. If the `base` expression is equal to `value`, then; returns `then`. Warning; -------; Missingness always compares to missing. Both ``NA == NA`` and; ``NA != NA`` return ``NA``. Use :meth:`~SwitchBuilder.when_missing`; to test missingness. Parameters; ----------; value : :class:`.Expression`; then : :class:`.Expression`. Returns; -------; :class:`.SwitchBuilder`; Mutates and returns `self`.; """"""; can_compare = unify_types(self._base.dtype, value.dtype); if not can_compare:; raise TypeError(""cannot compare expressions of type '{}' and '{}'"".format(self._base.dtype, value.dtype)). self._unify_type(then.dtype); self._cases.append((value, then)); return self. [docs] @typecheck_method(then=expr_any); def when_missing(self, then) -> 'SwitchBuilder':; """"""Add a test for missingness. If the `base` expression is missing,; returns `then`. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.SwitchBuilder`; Mutates and returns `self`.; """"""; if self._when_missing_case is not None:; raise ExpressionException(""'when_missing' can only be called once""); self._unify_type(then.dtype). self._when_missing_case = then; return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the switch statement by adding a default case. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0 and self._when_missing_case is None:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the switch statement by returning missing. Notes; -----; If no value ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/builders.html:3382,test,test,3382,docs/0.2/_modules/hail/expr/builders.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html,2,['test'],['test']
Testability,"f; that the filtered alleles are not real so we should discard any; probability mass associated with them. The subset algorithm would produce the following:. .. code-block:: text. GT: 1/1; GQ: 980; AD: 0,50. 0 | 980; 1 | 980 0; +-----------; 0 1. In summary:. - GT: Set to most likely genotype based on the PLs ignoring the filtered allele(s).; - AD: The filtered alleles' columns are eliminated, e.g., filtering alleles 1 and 2 transforms ``25,5,10,20`` to ``25,20``.; - DP: No change.; - PL: The filtered alleles' columns are eliminated and the remaining columns shifted so the minimum value is 0.; - GQ: The second-lowest PL (after shifting). **Downcode algorithm**. The downcode algorithm (``subset=False``) recodes occurances of filtered alleles; to occurances of the reference allele (e.g. 1 -> 0 in our example). So the depths of filtered alleles in the AD field; are added to the depth of the reference allele. Where downcodeing filtered alleles merges distinct genotypes, the minimum PL is used (since PL is on a log scale, this roughly corresponds to adding probabilities). The PLs; are then re-normalized (shifted) so that the most likely genotype has a PL of 0, and GT is set to this genotype.; If an allele is filtered, this algorithm acts similarly to :py:meth:`~hail.VariantDataset.split_multi`. The downcoding algorithm would produce the following:. .. code-block:: text. GT: 0/1; GQ: 10; AD: 35,50. 0 | 20; 1 | 0 10; +-----------; 0 1. In summary:. - GT: Downcode filtered alleles to reference.; - AD: The filtered alleles' columns are eliminated and their value is added to the reference, e.g., filtering alleles 1 and 2 transforms ``25,5,10,20`` to ``40,20``.; - DP: No change.; - PL: Downcode filtered alleles to reference, combine PLs using minimum for each overloaded genotype, and shift so the overall minimum PL is 0.; - GQ: The second-lowest PL (after shifting). **Expression Variables**. The following symbols are in scope for ``expr``:. - ``v`` (*Variant*): :ref:`variant`; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:63508,log,log,63508,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['log']
Testability,"fault; from hail.utils.java import BackendType, Env, choose_backend, warning; from hailtop.aiocloud.aiogoogle import GCSRequesterPaysConfiguration, get_gcs_requester_pays_configuration; from hailtop.fs.fs import FS; from hailtop.hail_event_loop import hail_event_loop; from hailtop.utils import secret_alnum_string. from . import __resource_str; from .backend.backend import local_jar_information; from .builtin_references import BUILTIN_REFERENCES. def _get_tmpdir(tmpdir):; if tmpdir is None:; tmpdir = '/tmp'; return tmpdir. def _get_local_tmpdir(local_tmpdir):; local_tmpdir = get_env_or_default(local_tmpdir, 'TMPDIR', 'file:///tmp'); r = urlparse(local_tmpdir); if not r.scheme:; r = r._replace(scheme='file'); elif r.scheme != 'file':; raise ValueError('invalid local_tmpfile: must use scheme file, got scheme {r.scheme}'); return urlunparse(r). def _get_log(log):; if log is None:; py_version = version(); log_dir = os.environ.get('HAIL_LOG_DIR'); if log_dir is None:; log_dir = os.getcwd(); log = hail.utils.timestamp_path(os.path.join(log_dir, 'hail'), suffix=f'-{py_version}.log'); return log. def convert_gcs_requester_pays_configuration_to_hadoop_conf_style(; x: Optional[Union[str, Tuple[str, List[str]]]],; ) -> Tuple[Optional[str], Optional[str]]:; if isinstance(x, str):; return x, None; if isinstance(x, tuple):; return x[0], "","".join(x[1]); return None, None. class HailContext(object):; @staticmethod; def create(; log: str,; quiet: bool,; append: bool,; tmpdir: str,; local_tmpdir: str,; default_reference: str,; global_seed: Optional[int],; backend: Backend,; ):; hc = HailContext(; log=log,; quiet=quiet,; append=append,; tmpdir=tmpdir,; local_tmpdir=local_tmpdir,; global_seed=global_seed,; backend=backend,; ); hc.initialize_references(default_reference); return hc. @typecheck_method(; log=str, quiet=bool, append=bool, tmpdir=str, local_tmpdir=str, global_seed=nullable(int), backend=Backend; ); def __init__(self, log, quiet, append, tmpdir, local_tmpdir, global_seed, back",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:2033,log,log,2033,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['log'],['log']
Testability,"field and will include the following row fields:; 'source': str; 'feature': str; 'score': float64; 'strand': str; 'frame': int32; 'interval': interval<>. There will also be corresponding fields for every tag found in the; attribute field of the GTF file. Note; This function will return an interval field of type tinterval; constructed from the seqname, start, and end fields in the; GTF file. This interval is inclusive of both the start and end positions; in the GTF file.; If the reference_genome parameter is specified, the start and end; points of the interval field will be of type tlocus.; Otherwise, the start and end points of the interval field will be of; type tstruct with fields seqname (type str) and; position (type tint32).; Furthermore, if the reference_genome parameter is specified and; skip_invalid_contigs is True, this import function will skip; lines in the GTF where seqname is not consistent with the reference; genome specified. Example; >>> ht = hl.experimental.import_gtf('data/test.gtf',; ... reference_genome='GRCh37',; ... skip_invalid_contigs=True). >>> ht.describe() ; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'source': str; 'feature': str; 'score': float64; 'strand': str; 'frame': int32; 'gene_type': str; 'exon_id': str; 'havana_transcript': str; 'level': str; 'transcript_name': str; 'gene_status': str; 'gene_id': str; 'transcript_type': str; 'tag': str; 'transcript_status': str; 'gene_name': str; 'transcript_id': str; 'exon_number': str; 'havana_gene': str; 'interval': interval<locus<GRCh37>>; ----------------------------------------; Key: ['interval']; ----------------------------------------. Parameters:. path (str) – File to import.; reference_genome (str or ReferenceGenome, optional) – Reference genome to use.; skip_invalid_contigs (bool) – If True and reference_genome is not None, skip lines where; seqname is not consistent with the reference genome.; min_partitions (",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/experimental/index.html:25762,test,test,25762,docs/0.2/experimental/index.html,https://hail.is,https://hail.is/docs/0.2/experimental/index.html,1,['test'],['test']
Testability,"final}; bokeh.io.push_notebook(handle=handle). from ipywidgets import interact. interact(update, smoothing=(0.02, 0.8, 0.005)). return p, mk_interact; else:; return p. [docs]@typecheck(; data=oneof(Struct, expr_float64),; range=nullable(sized_tupleof(numeric, numeric)),; bins=int,; legend=nullable(str),; title=nullable(str),; log=bool,; interactive=bool,; ); def histogram(; data, range=None, bins=50, legend=None, title=None, log=False, interactive=False; ) -> Union[figure, Tuple[figure, Callable]]:; """"""Create a histogram. Notes; -----; `data` can be a :class:`.Float64Expression`, or the result of the :func:`~.aggregators.hist`; or :func:`~.aggregators.approx_cdf` aggregators. Parameters; ----------; data : :class:`.Struct` or :class:`.Float64Expression`; Sequence of data to plot.; range : Tuple[float]; Range of x values in the histogram.; bins : int; Number of bins in the histogram.; legend : str; Label of data on the x-axis.; title : str; Title of the histogram.; log : bool; Plot the log10 of the bin counts. Returns; -------; :class:`bokeh.plotting.figure`; """"""; if isinstance(data, Expression):; if data._indices.source is not None:; if interactive:; raise ValueError(""'interactive' flag can only be used on data from 'approx_cdf'.""); agg_f = data._aggregation_method(); if range is not None:; start = range[0]; end = range[1]; else:; finite_data = hail.bind(lambda x: hail.case().when(hail.is_finite(x), x).or_missing(), data); start, end = agg_f((aggregators.min(finite_data), aggregators.max(finite_data))); if start is None and end is None:; raise ValueError(""'data' contains no values that are defined and finite""); data = agg_f(aggregators.hist(data, start, end, bins)); else:; raise ValueError('Invalid input'); elif 'values' in data:; cdf = data; hist, edges = np.histogram(cdf['values'], bins=bins, weights=np.diff(cdf.ranks), density=True); data = Struct(bin_freq=hist, bin_edges=edges, n_larger=0, n_smaller=0). if legend is None:; legend = """". if log:; bin_freq = []; cou",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:10551,log,log,10551,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['log'],['log']
Testability,"fit = ht.null_fit; # FIXME: we should test a whole block of variants at a time not one-by-one; xvec = ht.xvec; yvec = ht.yvec. if test == 'score':; chi_sq, p = _poisson_score_test(null_fit, covmat, yvec, xvec); return ht.select(chi_sq_stat=chi_sq, p_value=p, **ht.pass_through).select_globals('null_fit'). X = hl.nd.hstack([covmat, xvec.T.reshape(-1, 1)]); b = hl.nd.hstack([null_fit.b, hl.nd.array([0.0])]); mu = sigmoid(X @ b); residual = yvec - mu; score = hl.nd.hstack([null_fit.score, hl.nd.array([xvec @ residual])]). fisher00 = null_fit.fisher; fisher01 = ((covmat.T * mu) @ xvec).reshape((-1, 1)); fisher10 = fisher01.T; fisher11 = hl.nd.array([[(mu * xvec.T) @ xvec]]); fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). test_fit = _poisson_fit(X, yvec, b, mu, score, fisher, max_iterations, tolerance); if test == 'lrt':; return ht.select(test_fit=test_fit, **lrt_test(X, null_fit, test_fit), **ht.pass_through).select_globals(; 'null_fit'; ); assert test == 'wald'; return ht.select(test_fit=test_fit, **wald_test(X, test_fit), **ht.pass_through).select_globals('null_fit'). def _poisson_fit(; X: NDArrayNumericExpression, # (N, K); y: NDArrayNumericExpression, # (N,); b: NDArrayNumericExpression, # (K,); mu: NDArrayNumericExpression, # (N,); score: NDArrayNumericExpression, # (K,); fisher: NDArrayNumericExpression, # (K, K); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Poisson(exp(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1; assert mu.ndim == 1; assert score.ndim == 1; assert fisher.ndim == 2. dtype = numerical_regression_fit_dtype; blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}). def fit(recur, iteration, b, mu, score, fisher):; def cont(exploded, delta_b, max_delta_b):; log_lkhd = y @ hl.log(m",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:67466,assert,assert,67466,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,"['assert', 'test']","['assert', 'test']"
Testability,"fit ratio of variance component coefficients, \(\hat{\delta}\). global.lmmreg.h2; Double; fit narrow-sense heritability, \(\hat{h}^2\). global.lmmreg.nEigs; Int; number of eigenvectors of kinship matrix used to fit model. global.lmmreg.dropped_variance_fraction; Double; specified value of dropped_variance_fraction. global.lmmreg.evals; Array[Double]; all eigenvalues of the kinship matrix in descending order. global.lmmreg.fit.seH2; Double; standard error of \(\hat{h}^2\) under asymptotic normal approximation. global.lmmreg.fit.normLkhdH2; Array[Double]; likelihood function of \(h^2\) normalized on the discrete grid 0.01, 0.02, ..., 0.99. Index i is the likelihood for percentage i. global.lmmreg.fit.maxLogLkhd; Double; (restricted) maximum log likelihood corresponding to \(\hat{\delta}\). global.lmmreg.fit.logDeltaGrid; Array[Double]; values of \(\mathrm{ln}(\delta)\) used in the grid search. global.lmmreg.fit.logLkhdVals; Array[Double]; (restricted) log likelihood of \(y\) given \(X\) and \(\mathrm{ln}(\delta)\) at the (RE)ML fit of \(\beta\) and \(\sigma_g^2\). These global annotations are also added to hail.log, with the ranked evals and \(\delta\) grid with values in .tsv tabular form. Use grep 'lmmreg:' hail.log to find the lines just above each table.; If Step 5 is performed, lmmreg() also adds four linear regression variant annotations. Annotation; Type; Value. va.lmmreg.beta; Double; fit genotype coefficient, \(\hat\beta_0\). va.lmmreg.sigmaG2; Double; fit coefficient of genetic variance component, \(\hat{\sigma}_g^2\). va.lmmreg.chi2; Double; \(\chi^2\) statistic of the likelihood ratio test. va.lmmreg.pval; Double; \(p\)-value. Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; The simplest way to export all resulting annotations is:; >>> lmm_vds.export_variants('output/lmmreg.tsv.bgz', 'variant = v, va.lmmreg.*'); >>> lmmreg_results = lmm_vds.globals['lmmreg']. By default, genotypes v",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:94729,log,logLkhdVals,94729,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,2,['log'],"['log', 'logLkhdVals']"
Testability,"fo.FS < 200.0 || va.info.ReadPosRankSum < 20.0)) va.filters.add(""HardFilter"") else va.filters']). If we now export this VDS as VCF, it would produce the following header (for these new fields):; ##INFO=<ID=AC_HC,Number=.,Type=String,Description="""". This header doesn’t contain all information that should be present in an optimal VCF header:; 1) There is no FILTER entry for HardFilter; 2) Since AC_HC has one entry per non-reference allele, its Number should be A; 3) AC_HC should have a Description; We can fix this by setting the attributes of these fields:; >>> annotated_vds = (annotated_vds; ... .set_va_attributes(; ... 'va.info.AC_HC',; ... {'Description': 'Allele count for high quality genotypes (DP >= 10, GQ >= 20)',; ... 'Number': 'A'}); ... .set_va_attributes(; ... 'va.filters',; ... {'HardFilter': 'This site fails GATK suggested hard filters.'})). Exporting the VDS with the attributes now prints the following header lines:; ##INFO=<ID=test,Number=A,Type=String,Description=""Allele count for high quality genotypes (DP >= 10, GQ >= 20)""; ##FILTER=<ID=HardFilter,Description=""This site fails GATK suggested hard filters."">. Parameters:; ann_path (str) – Path to variant annotation beginning with va.; attributes (dict) – A str-str dict containing the attributes to set. Returns:Annotated dataset with the attribute added to the variant annotation. Return type:VariantDataset. split_multi(propagate_gq=False, keep_star_alleles=False, max_shift=100)[source]¶; Split multiallelic variants. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; >>> vds.split_multi().write('output/split.vds'). Notes; We will explain by example. Consider a hypothetical 3-allelic; variant:; A C,T 0/2:7,2,6:15:45:99,50,99,0,45,99. split_multi will create two biallelic variants (one for each; alternate allele) at the same position; A C 0/0:13,2:15:45:0,45,99; A T 0/1:9,6:15:50:50,0,99. Each multiallelic GT field is downcoded once for each; alternate allele. ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:161655,test,test,161655,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"for Wald, LRT; 100 for Firth); Wald, LRT, Firth `fit.converged` bool ``True`` if iteration converged; Wald, LRT, Firth `fit.exploded` bool ``True`` if iteration exploded; ================ =================== ======= ===============================. We consider iteration to have converged when every coordinate of; :math:`\beta` changes by less than :math:`10^{-6}` by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression model",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:31959,test,testing,31959,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['testing']
Testability,"for a column; even when it has only one value in it.; (#13075); (#13074) Add a new; transient error plaguing pipelines in Query-on-Batch in Google:; java.net.SocketTimeoutException: connect timed out.; (#12569) The; documentation for hail.ggplot.facets is now correctly included in; the API reference. Version 0.2.117; Released 2023-05-22. New Features. (#12875) Parallel; export modes now write a manifest file. These manifest files are text; files with one filename per line, containing name of each shard; written successfully to the directory. These filenames are relative; to the export directory.; (#13007) In; Query-on-Batch and hailtop.batch, memory and storage request; strings may now be optionally terminated with a B for bytes. Bug Fixes. (#13065) In Azure; Query-on-Batch, fix a resource leak that prevented running pipelines; with >500 partitions and created flakiness with >250 partitions.; (#13067) In; Query-on-Batch, driver and worker logs no longer buffer so messages; should arrive in the UI after a fixed delay rather than proportional; to the frequency of log messages.; (#13028) Fix crash; in hl.vds.filter_intervals when using a table to filter a VDS; that stores the max ref block length.; (#13060) Prevent 500; Internal Server Error in Jupyter Notebooks of Dataproc clusters; started by hailctl dataproc.; (#13051) In; Query-on-Batch and hailtop.batch, Azure Blob Storage https; URLs are now supported.; (#13042) In; Query-on-Batch, naive_coalesce no longer performs a full; write/read of the dataset. It now operates identically to the; Query-on-Spark implementation.; (#13031) In; hl.ld_prune, an informative error message is raised when a; dataset does not contain diploid calls instead of an assertion error.; (#13032) In; Query-on-Batch, in Azure, Hail now users a newer version of the Azure; blob storage libraries to reduce the frequency of “Stream is already; closed” errors.; (#13011) In; Query-on-Batch, the driver will use ~1/2 as much memory to read; results a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:32703,log,logs,32703,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,2,['log'],"['log', 'logs']"
Testability,"for the latter model can be solved exactly in time complexity that is linear rather than cubic in \(n\). In particular, having rotated, we can run a very efficient 1-dimensional optimization procedure over \(\delta\) to find the REML estimate \((\hat{\delta}, \hat{\beta}, \hat{\sigma}_g^2)\) of the triple \((\delta, \beta, \sigma_g^2)\), which in turn determines \(\hat{\sigma}_e^2\) and \(\hat{h}^2\).; We first compute the maximum log likelihood on a \(\delta\)-grid that is uniform on the log scale, with \(\mathrm{ln}(\delta)\) running from -8 to 8 by 0.01, corresponding to \(h^2\) decreasing from 0.9995 to 0.0005. If \(h^2\) is maximized at the lower boundary then standard linear regression would be more appropriate and Hail will exit; more generally, consider using standard linear regression when \(\hat{h}^2\) is very small. A maximum at the upper boundary is highly suspicious and will also cause Hail to exit. In any case, the log file records the table of grid values for further inspection, beginning under the info line containing “lmmreg: table of delta”.; If the optimal grid point falls in the interior of the grid as expected, we then use Brent’s method to find the precise location of the maximum over the same range, with initial guess given by the optimal grid point and a tolerance on \(\mathrm{ln}(\delta)\) of 1e-6. If this location differs from the optimal grid point by more than 0.01, a warning will be displayed and logged, and one would be wise to investigate by plotting the values over the grid.; Note that \(h^2\) is related to \(\mathrm{ln}(\delta)\) through the sigmoid function. More precisely,. \[h^2 = 1 - \mathrm{sigmoid}(\mathrm{ln}(\delta)) = \mathrm{sigmoid}(-\mathrm{ln}(\delta))\]; Hence one can change variables to extract a high-resolution discretization of the likelihood function of \(h^2\) over \([0,1]\) at the corresponding REML estimators for \(\beta\) and \(\sigma_g^2\), as well as integrate over the normalized likelihood function using chan",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:102045,log,log,102045,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['log']
Testability,"from -8 to 8 by 0.01, corresponding to :math:`h^2` decreasing from 0.9995 to 0.0005. If :math:`h^2` is maximized at the lower boundary then standard linear regression would be more appropriate and Hail will exit; more generally, consider using standard linear regression when :math:`\\hat{h}^2` is very small. A maximum at the upper boundary is highly suspicious and will also cause Hail to exit. In any case, the log file records the table of grid values for further inspection, beginning under the info line containing ""lmmreg: table of delta"". If the optimal grid point falls in the interior of the grid as expected, we then use `Brent's method <https://en.wikipedia.org/wiki/Brent%27s_method>`__ to find the precise location of the maximum over the same range, with initial guess given by the optimal grid point and a tolerance on :math:`\\mathrm{ln}(\delta)` of 1e-6. If this location differs from the optimal grid point by more than 0.01, a warning will be displayed and logged, and one would be wise to investigate by plotting the values over the grid. Note that :math:`h^2` is related to :math:`\\mathrm{ln}(\delta)` through the `sigmoid function <https://en.wikipedia.org/wiki/Sigmoid_function>`_. More precisely,. .. math::. h^2 = 1 - \mathrm{sigmoid}(\\mathrm{ln}(\delta)) = \mathrm{sigmoid}(-\\mathrm{ln}(\delta)). Hence one can change variables to extract a high-resolution discretization of the likelihood function of :math:`h^2` over :math:`[0,1]` at the corresponding REML estimators for :math:`\\beta` and :math:`\sigma_g^2`, as well as integrate over the normalized likelihood function using `change of variables <https://en.wikipedia.org/wiki/Integration_by_substitution>`_ and the `sigmoid differential equation <https://en.wikipedia.org/wiki/Sigmoid_function#Properties>`_. For convenience, ``global.lmmreg.fit.normLkhdH2`` records the the likelihood function of :math:`h^2` normalized over the discrete grid ``0.01, 0.02, ..., 0.98, 0.99``. The length of the array is 101 so tha",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:131657,log,logged,131657,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logged']
Testability,"from_numpy did not work correctly. Version 1.0 of; org.scalanlp.breeze, a dependency of Apache Spark that hail also; depends on, has a correctness bug that results in BlockMatrices that; repeat the top left block of the block matrix for every block. This; affected anyone running Spark 3.0.x or 3.1.x. Bug fixes. (#11556) Fixed; assertion error ocassionally being thrown by valid joins where the; join key was a prefix of the left key. Versioning. (#11551) Support; Python 3.10. Version 0.2.89; Release 2022-03-04. (#11452) Fix; impute_sex_chromosome_ploidy docs. Version 0.2.88; Release 2022-03-01; This release addresses the deploy issues in the 0.2.87 release of Hail. Version 0.2.87; Release 2022-02-28; An error in the deploy process required us to yank this release from; PyPI. Please do not use this release. Bug fixes. (#11401) Fixed bug; where from_pandas didn’t support missing strings. Version 0.2.86; Release 2022-02-25. Bug fixes. (#11374) Fixed bug; where certain pipelines that read in PLINK files would give assertion; error.; (#11401) Fixed bug; where from_pandas didn’t support missing ints. Performance improvements. (#11306) Newly; written tables that have no duplicate keys will be faster to join; against. Version 0.2.85; Release 2022-02-14. Bug fixes. (#11355) Fixed; assertion errors being hit relating to RVDPartitioner.; (#11344) Fix error; where hail ggplot would mislabel points after more than 10 distinct; colors were used. New features. (#11332) Added; geom_ribbon and geom_area to hail ggplot. Version 0.2.84; Release 2022-02-10. Bug fixes. (#11328) Fix bug; where occasionally files written to disk would be unreadable.; (#11331) Fix bug; that potentially caused files written to disk to be unreadable.; (#11312) Fix; aggregator memory leak.; (#11340) Fix bug; where repeatedly annotating same field name could cause failure to; compile.; (#11342) Fix to; possible issues about having too many open file handles. New features. (#11300); geom_histogram ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:52922,assert,assertion,52922,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['assert'],['assertion']
Testability,"ft-shift x by y.; Examples; >>> hl.eval(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:; >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_rshift(x, y, logical=False)[source]; Bitwise right-shift x by y.; Examples; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With logical=False (default), the sign is preserved:; >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With logical=True, the sign bit is treated as any other:; >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; If logical is False, then the shift is a sign-preserving right shift.; If logical is True, then the shift is logical, with the sign bit; treated as any other bit.; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression); logical (bool). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representation of 7 is 111, so:; >>> hl.eval(hl.bit_count(7)); 3. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression. hail.expr.functions.exp(x)[source]. hail.expr.functions.expit(x)[source]. hail.expr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:6157,log,logical,6157,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['logical']
Testability,"g And Version Policy. menu; Hail. Python API; Hail Query Python API; Functions; Core language functions; SwitchBuilder. View page source. SwitchBuilder. class hail.expr.builders.SwitchBuilder[source]; Class for generating conditional trees based on value of an expression.; Examples; >>> csq = hl.literal('loss of function'); >>> expr = (hl.switch(csq); ... .when('synonymous', 1); ... .when('SYN', 1); ... .when('missense', 2); ... .when('MIS', 2); ... .when('loss of function', 3); ... .when('LOF', 3); ... .or_missing()); >>> hl.eval(expr); 3. Notes; All expressions appearing as the then parameters to; when() or; default() method calls must be the; same type. See also; case(), cond(), switch(). Parameters:; expr (Expression) – Value to match against. Attributes. Methods. default; Finish the switch statement by adding a default case. or_error; Finish the switch statement by throwing an error with the given message. or_missing; Finish the switch statement by returning missing. when; Add a value test. when_missing; Add a test for missingness. default(then)[source]; Finish the switch statement by adding a default case.; Notes; If no value from a when() call is matched, then; then is returned. Parameters:; then (Expression). Returns:; Expression. or_error(message)[source]; Finish the switch statement by throwing an error with the given message.; Notes; If no value from a SwitchBuilder.when() call is matched, then an; error is thrown. Parameters:; message (Expression of type tstr). Returns:; Expression. or_missing()[source]; Finish the switch statement by returning missing.; Notes; If no value from a when() call is matched, then; the result is missing. Parameters:; then (Expression). Returns:; Expression. when(value, then)[source]; Add a value test. If the base expression is equal to value, then; returns then. Warning; Missingness always compares to missing. Both NA == NA and; NA != NA return NA. Use when_missing(); to test missingness. Parameters:. value (Expression);",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/hail.expr.builders.SwitchBuilder.html:1583,test,test,1583,docs/0.2/functions/hail.expr.builders.SwitchBuilder.html,https://hail.is,https://hail.is/docs/0.2/functions/hail.expr.builders.SwitchBuilder.html,1,['test'],['test']
Testability,"g Hail:; curl https://broad.io/install-gcs-connector | python3. Do not try; to update before installing Hail 0.2.131. Version 0.2.130; Released 2024-10-02; 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with hailctl. Please upgrade to 0.2.130; if you use dataproc. New Features. (hail##14447) Added copy_spark_log_on_error initialization flag; that when set, copies the hail driver log to the remote tmpdir if; query execution raises an exception. Bug Fixes. (#14452) Fixes a bug; that prevents users from starting dataproc clusters with hailctl. Version 0.2.129; Released 2024-04-02. Documentation. (#14321) Removed; GOOGLE_APPLICATION_CREDENTIALS from batch docs. Metadata server; introduction means users no longer need to explicitly activate; service accounts with the gcloud command line tool.; (#14339) Added; citations since 2021. New Features. (#14406) Performance; improvements for reading structured data from (Matrix)Tables; (#14255) Added; Cochran-Hantel-Haenszel test for association; (cochran_mantel_haenszel_test). Our thanks to @Will-Tyler for; generously contributing this feature.; (#14393) hail; depends on protobuf no longer; users may choose their own version; of protobuf.; (#14360) Exposed; previously internal _num_allele_type as numeric_allele_type; and deprecated it. Add new AlleleType enumeration for users to be; able to easily use the values returned by numeric_allele_type.; (#14297); vds.sample_gc now uses independent aggregators. Users may now; import these functions and use them directly.; (#14405); VariantDataset.validate now checks that all ref blocks are no; longer than the ref_block_max_length field, if it exists. Bug Fixes. (#14420) Fixes a; serious, but likely rare, bug in the Table/MatrixTable reader, which; has been present since Sep 2020. It manifests as many (around half or; more) of the rows being dropped. This could only happen when 1); reading a (matrix)table whose partitioning meta",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:13217,test,test,13217,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['test'],['test']
Testability,"g can only be used on data from 'approx_cdf'.""); agg_f = data._aggregation_method(); if range is not None:; start = range[0]; end = range[1]; else:; finite_data = hail.bind(lambda x: hail.case().when(hail.is_finite(x), x).or_missing(), data); start, end = agg_f((aggregators.min(finite_data), aggregators.max(finite_data))); if start is None and end is None:; raise ValueError(""'data' contains no values that are defined and finite""); data = agg_f(aggregators.hist(data, start, end, bins)); else:; raise ValueError('Invalid input'); elif 'values' in data:; cdf = data; hist, edges = np.histogram(cdf['values'], bins=bins, weights=np.diff(cdf.ranks), density=True); data = Struct(bin_freq=hist, bin_edges=edges, n_larger=0, n_smaller=0). if legend is None:; legend = """". if log:; bin_freq = []; count_problems = 0; for x in data.bin_freq:; if x == 0.0:; count_problems += 1; bin_freq.append(x); else:; bin_freq.append(math.log10(x)). if count_problems > 0:; warning(; f""There were {count_problems} bins with height 0, those cannot be log transformed and were left as 0s.""; ). changes = {; ""bin_freq"": bin_freq,; ""n_larger"": math.log10(data.n_larger) if data.n_larger > 0.0 else data.n_larger,; ""n_smaller"": math.log10(data.n_smaller) if data.n_smaller > 0.0 else data.n_smaller,; }; data = data.annotate(**changes); y_axis_label = 'log10 Frequency'; else:; y_axis_label = 'Frequency'. x_span = data.bin_edges[-1] - data.bin_edges[0]; x_start = data.bin_edges[0] - 0.05 * x_span; x_end = data.bin_edges[-1] + 0.05 * x_span; p = figure(; title=title,; x_axis_label=legend,; y_axis_label=y_axis_label,; background_fill_color='#EEEEEE',; x_range=(x_start, x_end),; ); q = p.quad(; bottom=0,; top=data.bin_freq,; left=data.bin_edges[:-1],; right=data.bin_edges[1:],; legend_label=legend,; line_color='black',; ); if data.n_larger > 0:; p.quad(; bottom=0,; top=data.n_larger,; left=data.bin_edges[-1],; right=(data.bin_edges[-1] + (data.bin_edges[1] - data.bin_edges[0])),; line_color='black',; fill_color='g",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:11809,log,log,11809,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['log'],['log']
Testability,"g filtered alleles merges distinct genotypes, the minimum PL is used (since PL is on a log scale, this roughly corresponds to adding probabilities). The PLs; are then re-normalized (shifted) so that the most likely genotype has a PL of 0, and GT is set to this genotype.; If an allele is filtered, this algorithm acts similarly to split_multi().; The downcoding algorithm would produce the following:; GT: 0/1; GQ: 10; AD: 35,50. 0 | 20; 1 | 0 10; +-----------; 0 1. In summary:. GT: Downcode filtered alleles to reference.; AD: The filtered alleles’ columns are eliminated and their value is added to the reference, e.g., filtering alleles 1 and 2 transforms 25,5,10,20 to 40,20.; DP: No change.; PL: Downcode filtered alleles to reference, combine PLs using minimum for each overloaded genotype, and shift so the overall minimum PL is 0.; GQ: The second-lowest PL (after shifting). Expression Variables; The following symbols are in scope for expr:. v (Variant): Variant; va: variant annotations; aIndex (Int): the index of the allele being tested. The following symbols are in scope for annotation:. v (Variant): Variant; va: variant annotations; aIndices (Array[Int]): the array of old indices (such that aIndices[newIndex] = oldIndex and aIndices[0] = 0). Parameters:; expr (str) – Boolean filter expression involving v (variant), va (variant annotations), ; and aIndex (allele index); annotation (str) – Annotation modifying expression involving v (new variant), va (old variant annotations),; and aIndices (maps from new to old indices); subset (bool) – If true, subsets PL and AD, otherwise downcodes the PL and AD.; Genotype and GQ are set based on the resulting PLs.; keep (bool) – If true, keep variants matching expr; filter_altered_genotypes (bool) – If true, genotypes that contain filtered-out alleles are set to missing.; max_shift (int) – maximum number of base pairs by which; a split variant can move. Affects memory usage, and will; cause Hail to throw an error if a variant that m",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:51041,test,tested,51041,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['tested']
Testability,"g variant; Incomplete terminal codon variant; Stop retained variant; Synonymous variant; Splice region variant; Coding sequence variant; Mature miRNA variant; 5’ UTR variant; 3’ UTR variant; Non-coding transcript exon variant; Intron variant; NMD transcript variant; Non-coding transcript variant; Upstream gene variant; Downstream gene variant; TFBS ablation; TFBS amplification; TF binding site variant; Regulatory region ablation; Regulatory region amplification; Feature elongation; Regulatory region variant; Feature truncation; Intergenic variant. If a canonical transcript with the most severe consequence exists, take that gene and transcript. Otherwise, take a non-canonical; transcript with the most severe consequence. Though this is the default logic, you may wish to define gene symbols differently. One way to do so while still using the VEP output; would be to add VEP annotations to your VDS, create a gene symbol variant annotation by parsing through the VEP output however you; wish, and then pass that annotation to annotate_variants_db() using the gene_key parameter.; Here’s an example that uses the gene symbol from the first VEP transcript:; import hail; from pprint import pprint. hc = hail.HailContext(). vds = (; hc; .import_vcf('gs://annotationdb/test/sample.vcf'); .split_multi(); .annotate_variants_db('va.vep'); .annotate_variants_expr('va.my_gene = va.vep.transcript_consequences[0].gene_symbol'); .annotate_variants_db('va.gene.constraint.pli', gene_key='va.my_gene'); ). pprint(vds.variant_schema). This code would return:; Struct{; rsid: String,; qual: Double,; filters: Set[String],; info: Struct{; ...; },; vep: Struct{; ...; },; my_gene: String,; gene: Struct{; constraint: Struct{; pli: Double; }; }; }. Suggest additions or edits¶; Please contact Andrea Ganna (aganna@broadinstitute.org) or Liam Abbott (labbott@broadinstitute.org) with any questions. Next ; Previous. © Copyright 2016, Hail Team. . Built with Sphinx using a theme provided by Read the Docs. . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/annotationdb.html:5445,test,test,5445,docs/0.1/annotationdb.html,https://hail.is,https://hail.is/docs/0.1/annotationdb.html,1,['test'],['test']
Testability,"g10 of the bin counts. Returns; -------; :class:`bokeh.plotting.figure`; """"""; if isinstance(data, Expression):; if data._indices.source is not None:; if interactive:; raise ValueError(""'interactive' flag can only be used on data from 'approx_cdf'.""); agg_f = data._aggregation_method(); if range is not None:; start = range[0]; end = range[1]; else:; finite_data = hail.bind(lambda x: hail.case().when(hail.is_finite(x), x).or_missing(), data); start, end = agg_f((aggregators.min(finite_data), aggregators.max(finite_data))); if start is None and end is None:; raise ValueError(""'data' contains no values that are defined and finite""); data = agg_f(aggregators.hist(data, start, end, bins)); else:; raise ValueError('Invalid input'); elif 'values' in data:; cdf = data; hist, edges = np.histogram(cdf['values'], bins=bins, weights=np.diff(cdf.ranks), density=True); data = Struct(bin_freq=hist, bin_edges=edges, n_larger=0, n_smaller=0). if legend is None:; legend = """". if log:; bin_freq = []; count_problems = 0; for x in data.bin_freq:; if x == 0.0:; count_problems += 1; bin_freq.append(x); else:; bin_freq.append(math.log10(x)). if count_problems > 0:; warning(; f""There were {count_problems} bins with height 0, those cannot be log transformed and were left as 0s.""; ). changes = {; ""bin_freq"": bin_freq,; ""n_larger"": math.log10(data.n_larger) if data.n_larger > 0.0 else data.n_larger,; ""n_smaller"": math.log10(data.n_smaller) if data.n_smaller > 0.0 else data.n_smaller,; }; data = data.annotate(**changes); y_axis_label = 'log10 Frequency'; else:; y_axis_label = 'Frequency'. x_span = data.bin_edges[-1] - data.bin_edges[0]; x_start = data.bin_edges[0] - 0.05 * x_span; x_end = data.bin_edges[-1] + 0.05 * x_span; p = figure(; title=title,; x_axis_label=legend,; y_axis_label=y_axis_label,; background_fill_color='#EEEEEE',; x_range=(x_start, x_end),; ); q = p.quad(; bottom=0,; top=data.bin_freq,; left=data.bin_edges[:-1],; right=data.bin_edges[1:],; legend_label=legend,; line_color='blac",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:11549,log,log,11549,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['log'],['log']
Testability,"g^2\), as well as integrate over the normalized likelihood function using change of variables and the sigmoid differential equation.; For convenience, global.lmmreg.fit.normLkhdH2 records the the likelihood function of \(h^2\) normalized over the discrete grid 0.01, 0.02, ..., 0.98, 0.99. The length of the array is 101 so that index i contains the likelihood at percentage i. The values at indices 0 and 100 are left undefined.; By the theory of maximum likelihood estimation, this normalized likelihood function is approximately normally distributed near the maximum likelihood estimate. So we estimate the standard error of the estimator of \(h^2\) as follows. Let \(x_2\) be the maximum likelihood estimate of \(h^2\) and let \(x_ 1\) and \(x_3\) be just to the left and right of \(x_2\). Let \(y_1\), \(y_2\), and \(y_3\) be the corresponding values of the (unnormalized) log likelihood function. Setting equal the leading coefficient of the unique parabola through these points (as given by Lagrange interpolation) and the leading coefficient of the log of the normal distribution, we have:. \[\frac{x_3 (y_2 - y_1) + x_2 (y_1 - y_3) + x_1 (y_3 - y_2))}{(x_2 - x_1)(x_1 - x_3)(x_3 - x_2)} = -\frac{1}{2 \sigma^2}\]; The standard error \(\hat{\sigma}\) is then estimated by solving for \(\sigma\).; Note that the mean and standard deviation of the (discretized or continuous) distribution held in global.lmmreg.fit.normLkhdH2 will not coincide with \(\hat{h}^2\) and \(\hat{\sigma}\), since this distribution only becomes normal in the infinite sample limit. One can visually assess normality by plotting this distribution against a normal distribution with the same mean and standard deviation, or use this distribution to approximate credible intervals under a flat prior on \(h^2\).; Testing each variant for association; Fixing a single variant, we define:. \(v = n \times 1\) vector of genotypes, with missing genotypes imputed as the mean of called genotypes; \(X_v = \left[v | X \right] ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:104081,log,log,104081,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['log']
Testability,"ge Log And Version Policy. menu; Hail. Hail Tutorials; Table Joins Tutorial. View page source. Table Joins Tutorial; This tutorial walks through some ways to join Hail tables. We’ll use a simple movie dataset to illustrate. The movie dataset comes in multiple parts. Here are a few questions we might naturally ask about the dataset:. What is the mean rating per genre?; What is the favorite movie for each occupation?; What genres are most preferred by women vs men?. We’ll use joins to combine datasets in order to answer these questions.; Let’s initialize Hail, fetch the tutorial data, and load three tables: users, movies, and ratings. [1]:. import hail as hl. hl.utils.get_movie_lens('data/'). users = hl.read_table('data/users.ht'); movies = hl.read_table('data/movies.ht'); ratings = hl.read_table('data/ratings.ht'). Loading BokehJS ... Initializing Hail with default parameters...; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2010-0.2.133-4c60fddb171a.log; 2024-10-04 20:10:22.038 Hail: INFO: Movie Lens files found!. The Key to Understanding Joins; To understand joins in Hail, we need to revisit one of the crucial properties of tables: the key.; A table has an ordered list of fields known as the key. Our users table has one key, the id field. We can see all the fields, as well as the keys, of a table by calling describe(). [2]:. users.describe(). ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'id': int32; 'age': int32; 'sex': str; 'occupation': str; 'zipcode': str; -----",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/06-joins.html:1635,log,logger,1635,docs/0.2/tutorials/06-joins.html,https://hail.is,https://hail.is/docs/0.2/tutorials/06-joins.html,1,['log'],['logger']
Testability,"ge else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation sa.fam.isCase added by importing a FAM file with case-control phenotype, case is 1 and control is 0.; Hail’s logistic regression tests correspond to the b.wald, b.lrt, and b.score tests in EPACTS. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes. Parameters:; test (str) – Statistical test, one of: ‘wald’, ‘lrt’, ‘score’, or ‘firth’.; y (str) – Response expression. Must evaluate to Boolean or; numeric with all values 0 or 1.; covariates (list of str) – list of covariate expressions; root (str) – Variant annotation path to store result of logistic regression.; use_dosages (bool) – If true, use genotype dosage rather than hard call. Returns:Variant dataset with logistic regression variant annotations. Return type:VariantDataset. logreg_burden(key_name, variant_keys, single_key, agg_expr, test, y, covariates=[])[source]¶; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Run a gene burden test using the logistic Wald test on the maximum genotype per gene. Here va.genes is; a variant annotation of type Set[String] giving the set of genes containing the variant; (see Extended example in linreg_burden() for a deeper dive in the context of linear regression):; >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.genes',; ... single_key=False,; ... agg_expr='gs.map(g => g.gt).max()',; ... test='wald',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). Run a gene burden test usi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:117081,log,logistic,117081,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logistic']
Testability,"gebra on the multivariate normal density shows that the linear mixed model above is mathematically equivalent to the model. \[U^Ty \sim \mathrm{N}\left(U^TX\beta, \sigma_g^2 (S + \delta I)\right)\]; for which the covariance is diagonal (e.g., unmixed). That is, rotating the phenotype vector (\(y\)) and covariate vectors (columns of \(X\)) in \(\mathbb{R}^n\) by \(U^T\) transforms the model to one with independent residuals. For any particular value of \(\delta\), the restricted maximum likelihood (REML) solution for the latter model can be solved exactly in time complexity that is linear rather than cubic in \(n\). In particular, having rotated, we can run a very efficient 1-dimensional optimization procedure over \(\delta\) to find the REML estimate \((\hat{\delta}, \hat{\beta}, \hat{\sigma}_g^2)\) of the triple \((\delta, \beta, \sigma_g^2)\), which in turn determines \(\hat{\sigma}_e^2\) and \(\hat{h}^2\).; We first compute the maximum log likelihood on a \(\delta\)-grid that is uniform on the log scale, with \(\mathrm{ln}(\delta)\) running from -8 to 8 by 0.01, corresponding to \(h^2\) decreasing from 0.9995 to 0.0005. If \(h^2\) is maximized at the lower boundary then standard linear regression would be more appropriate and Hail will exit; more generally, consider using standard linear regression when \(\hat{h}^2\) is very small. A maximum at the upper boundary is highly suspicious and will also cause Hail to exit. In any case, the log file records the table of grid values for further inspection, beginning under the info line containing “lmmreg: table of delta”.; If the optimal grid point falls in the interior of the grid as expected, we then use Brent’s method to find the precise location of the maximum over the same range, with initial guess given by the optimal grid point and a tolerance on \(\mathrm{ln}(\delta)\) of 1e-6. If this location differs from the optimal grid point by more than 0.01, a warning will be displayed and logged, and one would be wise to ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:101537,log,log,101537,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,2,['log'],['log']
Testability,"generate output in notebook; cells when :func:`bokeh.io.show` is called. Calls; :func:`bokeh.io.output_notebook`. """"""; bokeh.io.output_notebook(). def show(obj, interact=None):; """"""Immediately display a Bokeh object or application. Calls; :func:`bokeh.io.show`. Parameters; ----------; obj; A Bokeh object to display.; interact; A handle returned by a plotting method with `interactive=True`.; """"""; if interact is None:; bokeh.io.show(obj); else:; handle = bokeh.io.show(obj, notebook_handle=True); interact(handle). [docs]def cdf(data, k=350, legend=None, title=None, normalize=True, log=False) -> figure:; """"""Create a cumulative density plot. Parameters; ----------; data : :class:`.Struct` or :class:`.Float64Expression`; Sequence of data to plot.; k : int; Accuracy parameter (passed to :func:`~.approx_cdf`).; legend : str; Label of data on the x-axis.; title : str; Title of the histogram.; normalize: bool; Whether or not the cumulative data should be normalized.; log: bool; Whether or not the y-axis should be of type log. Returns; -------; :class:`bokeh.plotting.figure`; """"""; if isinstance(data, Expression):; if data._indices is None:; raise ValueError('Invalid input'); agg_f = data._aggregation_method(); data = agg_f(aggregators.approx_cdf(data, k)). if legend is None:; legend = """". if normalize:; y_axis_label = 'Quantile'; else:; y_axis_label = 'Rank'; if log:; y_axis_type = 'log'; else:; y_axis_type = 'linear'; p = figure(; title=title,; x_axis_label=legend,; y_axis_label=y_axis_label,; y_axis_type=y_axis_type,; width=600,; height=400,; background_fill_color='#EEEEEE',; tools='xpan,xwheel_zoom,reset,save',; active_scroll='xwheel_zoom',; ); p.add_tools(HoverTool(tooltips=[(""value"", ""$x""), (""rank"", ""@top"")], mode='vline')). ranks = np.array(data.ranks); values = np.array(data['values']); if normalize:; ranks = ranks / ranks[-1]. # invisible, there to support tooltips; p.quad(top=ranks[1:-1], bottom=ranks[1:-1], left=values[:-1], right=values[1:], fill_alpha=0, line_alpha=",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:2986,log,log,2986,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,4,['log'],['log']
Testability,"ges[0],; line_color='black',; fill_color='red',; legend_label='Outliers Below',; ); if interactive:. def mk_interact(handle):; def update(bins=bins, phase=0):; if phase > 0 and phase < 1:; bins = bins + 1; delta = (cdf['values'][-1] - cdf['values'][0]) / bins; edges = np.linspace(cdf['values'][0] - (1 - phase) * delta, cdf['values'][-1] + phase * delta, bins); else:; edges = np.linspace(cdf['values'][0], cdf['values'][-1], bins); hist, edges = np.histogram(cdf['values'], bins=edges, weights=np.diff(cdf.ranks), density=True); new_data = {'top': hist, 'left': edges[:-1], 'right': edges[1:], 'bottom': np.full(len(hist), 0)}; q.data_source.data = new_data; bokeh.io.push_notebook(handle=handle). from ipywidgets import interact. interact(update, bins=(0, 5 * bins), phase=(0, 1, 0.01)). return p, mk_interact; else:; return p. [docs]@typecheck(; data=oneof(Struct, expr_float64),; range=nullable(sized_tupleof(numeric, numeric)),; bins=int,; legend=nullable(str),; title=nullable(str),; normalize=bool,; log=bool,; ); def cumulative_histogram(data, range=None, bins=50, legend=None, title=None, normalize=True, log=False) -> figure:; """"""Create a cumulative histogram. Parameters; ----------; data : :class:`.Struct` or :class:`.Float64Expression`; Sequence of data to plot.; range : Tuple[float]; Range of x values in the histogram.; bins : int; Number of bins in the histogram.; legend : str; Label of data on the x-axis.; title : str; Title of the histogram.; normalize: bool; Whether or not the cumulative data should be normalized.; log: bool; Whether or not the y-axis should be of type log. Returns; -------; :class:`bokeh.plotting.figure`; """"""; if isinstance(data, Expression):; if data._indices.source is not None:; agg_f = data._aggregation_method(); if range is not None:; start = range[0]; end = range[1]; else:; start, end = agg_f((aggregators.min(data), aggregators.max(data))); data = agg_f(aggregators.hist(data, start, end, bins)); else:; raise ValueError('Invalid input'). if lege",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:13977,log,log,13977,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,4,['log'],['log']
Testability,"ght * g.gt).sum()',; ... test='score',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). To use a weighted sum of genotypes with missing genotypes mean-imputed rather than ignored, set; agg_expr='gs.map(g => va.weight * orElse(g.gt.toDouble, 2 * va.qc.AF)).sum()' where va.qc.AF; is the allele frequency over those samples that have no missing phenotype or covariates. Caution; With single_key=False, variant_keys expects a variant annotation of Set or Array type, in order to; allow each variant to have zero, one, or more keys (for example, the same variant may appear in multiple; genes). Unlike with type Set, if the same key appears twice in a variant annotation of type Array, then that; variant will be counted twice in that key’s group. With single_key=True, variant_keys expects a; variant annotation whose value is itself the key of interest. In bose cases, variants with missing keys are; ignored. Notes; This method modifies logreg() by replacing the genotype covariate per variant and sample with; an aggregated (i.e., collapsed) score per key and sample. This numeric score is computed from the sample’s; genotypes and annotations over all variants with that key. The phenotype type must either be numeric; (with all present values 0 or 1) or Boolean, in which case true and false are coded as 1 and 0, respectively.; Hail supports the Wald test (‘wald’), likelihood ratio test (‘lrt’), Rao score test (‘score’),; and Firth test (‘firth’) as the test parameter. Conceptually, the method proceeds as follows:. Filter to the set of samples for which all phenotype and covariates are defined. For each key and sample, aggregate genotypes across variants with that key to produce a numeric score.; agg_expr must be of numeric type and has the following symbols are in scope:. s (Sample): sample; sa: sample annotations; global: global annotations; gs (Aggregable[Genotype]): aggregable of Genotype for sample s. Note that v, va, and g are accessible through;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:119469,log,logreg,119469,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logreg']
Testability,"gion from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: List[DatasetVersion]):; assert set(key_properties).issubset(DB._valid_key_properties); self.name = name; self.description = description; self.url = url; self.key_properties = key_properties; self.versions = versions. @property; def is_gene_keyed(self) -> bool:; """"""If a :class:`Dataset` is gene keyed. Returns; -------; :obj:`bool`; Whether or not dataset is gene keyed.; """"""; return 'gene' in self.key_properties. def index_compatible_version(self, key_expr: StructExpression) -> StructExpression:; """"""Get index from compatible version of annotation dataset. Checks for compatible indexed values from each :class:`.DatasetVersion`; in :attr:`.Dataset.versions`, where `key_expr` is the row key struct; from the dataset to be annotated. Parameters; ----------; key_expr : :class:`.StructExpression`; Row key struct from relational object to be annotated. Returns; -------; :class:`.StructExpression`; Struct of compatible indexed values.; """"""; all_matches = 'unique' not in self",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/db.html:7275,assert,assert,7275,docs/0.2/_modules/hail/experimental/db.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html,2,['assert'],['assert']
Testability,"gma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid function, the genotype; \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for Het, and 2 for; HomVar, and the Boolean covariate \(\mathrm{is\_female}\) is coded as; for True (female) and 0 for False (male). The null model sets; \(\beta_1 = 0\).; The structure of the emitted row field depends on the test statistic as; shown in the tables below. Test; Field; Type; Value. Wald; beta; float64; fit effect coefficient,; \(\hat\beta_1\). Wald; standard_error; float64; estimated standard error,; \(\widehat{\mathrm{se}}\). Wald; z_stat; float64; Wald \(z\)-statistic, equal to; \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; p_value; float64; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; beta; float64; fit effect coefficient,; \(\hat\beta_1\). LRT, Firth; chi_sq_stat; float64; deviance statistic. LRT, Firth; p_value; float64; LRT / Firth p-value testing; \(\beta_1 = 0\). Score; chi_sq_stat; float64; score statistic. Score; p_value; float64; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for; each row using Newton iteration and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. Test; Field; Type; Value. Wald, LRT, Firth; fit.n_iterations; int32; number of iterations until; convergence, explosion, or; reaching the max (by default,; 25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; fit.converged; bool; True if iteration converged. Wald, LRT, Firth; fit.exploded; bool; True if iteration exploded. We consider iteration to have converged when every coordinate of; \(\beta\) changes by less than \(10^{-6}\) by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence ma",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:9812,test,testing,9812,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['testing']
Testability,"gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; Schema (2.2, GRCh37). ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; ldsc_baselineLD_annotations. View page source. ldsc_baselineLD_annotations. Versions: 2.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (2.2, GRCh37); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'SNP': str; 'baseL2': float64; 'Coding_UCSCL2': float64; 'Coding_UCSC.flanking.500L2': float64; 'Conserved_LindbladTohL2': float64; 'Conserved_LindbladToh.flanking.500L2': float64; 'CTCF_HoffmanL2': float64; 'CTCF_Hoffman.flanking.500L2': float64; 'DGF_ENCODEL2': float64; 'DGF_ENCODE.flanking.500L2': float64; 'DHS_peaks_TrynkaL2': float64; 'DHS_TrynkaL2': float64; 'DHS_Trynka.flanking.500L2': float64; 'Enhancer_AnderssonL2': float64; 'Enhancer_Andersson.flanking.500L2': float64; 'Enhancer_HoffmanL2': float64; 'Enhancer_Hoffman.flanki",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_annotations.html:8794,Log,Log,8794,docs/0.2/datasets/schemas/ldsc_baselineLD_annotations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_annotations.html,1,['Log'],['Log']
Testability,"gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; Schema (0.3, GRCh37). panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_meta_analysis_all_ancestries. View page source. panukb_meta_analysis_all_ancestries. Versions: 0.3; Reference genome builds: GRCh37; Type: hail.MatrixTable. Schema (0.3, GRCh37); ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 'trait_type': str; 'phenocode': str; 'pheno_sex': str; 'coding': str; 'modifier': str; 'pheno_data': array<struct {; n_cases: int32,; n_controls: int32,; heritability: struct {; estimates: struct {; ldsc: struct {; h2_liability: float64,; h2_liability_se: float64,; h2_z: float64,; h2_observed: float64,; h2_observed_se: float64,; intercept: float64,; intercept_se: float64,; ratio: float64,; ratio_se: float64; },; sldsc_25bin: struct {; h2_liability: float64,; h2_liability_se: float64,; h2_z: float64,; h2_observed: float64,; h2_observed_se: float64,; intercept: float64,; intercept_se: float64,; ratio:",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_all_ancestries.html:8802,Log,Log,8802,docs/0.2/datasets/schemas/panukb_meta_analysis_all_ancestries.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_all_ancestries.html,1,['Log'],['Log']
Testability,"gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; Schema (0.3, GRCh37). panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_meta_analysis_high_quality. View page source. panukb_meta_analysis_high_quality. Versions: 0.3; Reference genome builds: GRCh37; Type: hail.MatrixTable. Schema (0.3, GRCh37); ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 'trait_type': str; 'phenocode': str; 'pheno_sex': str; 'coding': str; 'modifier': str; 'pheno_data': array<struct {; n_cases: int32,; n_controls: int32,; heritability: struct {; estimates: struct {; ldsc: struct {; h2_liability: float64,; h2_liability_se: float64,; h2_z: float64,; h2_observed: float64,; h2_observed_se: float64,; intercept: float64,; intercept_se: float64,; ratio: float64,; ratio_se: float64; },; sldsc_25bin: struct {; h2_liability: float64,; h2_liability_se: float64,; h2_z: float64,; h2_observed: float64,; h2_observed_se: float64,; intercept: float64,; intercept_se: float64,; ratio: flo",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_high_quality.html:8800,Log,Log,8800,docs/0.2/datasets/schemas/panukb_meta_analysis_high_quality.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_high_quality.html,1,['Log'],['Log']
Testability,"gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats; Schema (0.3, GRCh37). Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_summary_stats. View page source. panukb_summary_stats. Versions: 0.3; Reference genome builds: GRCh37; Type: hail.MatrixTable. Schema (0.3, GRCh37); ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 'trait_type': str; 'phenocode': str; 'pheno_sex': str; 'coding': str; 'modifier': str; 'pheno_data': array<struct {; n_cases: int32,; n_controls: int32,; heritability: float64,; saige_version: str,; inv_normalized: bool,; pop: str; }>; 'description': str; 'description_more': str; 'coding_description': str; 'category': str; 'n_cases_full_cohort_both_sexes': int64; 'n_cases_full_cohort_females': int64; 'n_cases_full_cohort_males': int64; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'gene': str; 'annotation': str; ----------------------------------------; Entry fields:; 'summ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_summary_stats.html:8787,Log,Log,8787,docs/0.2/datasets/schemas/panukb_summary_stats.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_summary_stats.html,1,['Log'],['Log']
Testability,"gq_from_pl(pl)).drop('old_locus', 'old_alleles'). See also; split_multi_hts(). Parameters:. ds (MatrixTable or Table) – An unsplit dataset.; keep_star (bool) – Do not filter out * alleles.; left_aligned (bool) – If True, variants are assumed to be left aligned and have unique; loci. This avoids a shuffle. If the assumption is violated, an error; is generated.; permit_shuffle (bool) – If True, permit a data shuffle to sort out-of-order split results.; This will only be required if input data has duplicate loci, one of; which contains more than one alternate allele. Returns:; MatrixTable or Table. hail.methods.split_multi_hts(ds, keep_star=False, left_aligned=False, vep_root='vep', *, permit_shuffle=False)[source]; Split multiallelic variants for datasets that contain one or more fields; from a standard high-throughput sequencing entry schema.; struct {; GT: call,; AD: array<int32>,; DP: int32,; GQ: int32,; PL: array<int32>,; PGT: call,; PID: str; }. For other entry fields, write your own splitting logic using; MatrixTable.annotate_entries().; Examples; >>> hl.split_multi_hts(dataset).write('output/split.mt'). Warning; This method assumes ds contains at most one non-split variant per locus. This assumption permits the; most efficient implementation of the splitting algorithm. If your queries involving split_multi_hts; crash with errors about out-of-order keys, this assumption may be violated. Otherwise, this; warning likely does not apply to your dataset.; If each locus in ds contains one multiallelic variant and one or more biallelic variants, you; can filter to the multiallelic variants, split those, and then combine the split variants with; the original biallelic variants.; For example, the following code splits a dataset mt which contains a mixture of split and; non-split variants.; >>> bi = mt.filter_rows(hl.len(mt.alleles) == 2); >>> bi = bi.annotate_rows(a_index=1, was_split=False); >>> multi = mt.filter_rows(hl.len(mt.alleles) > 2); >>> split = hl.split_multi_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:86994,log,logic,86994,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['log'],['logic']
Testability,"h test ('firth') as the ``test`` parameter. Conceptually, the method proceeds as follows:. 1) Filter to the set of samples for which all phenotype and covariates are defined. 2) For each key and sample, aggregate genotypes across variants with that key to produce a numeric score.; ``agg_expr`` must be of numeric type and has the following symbols are in scope:. - ``s`` (*Sample*): sample; - ``sa``: sample annotations; - ``global``: global annotations; - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``. Note that ``v``, ``va``, and ``g`` are accessible through; `Aggregable methods <https://hail.is/hail/types.html#aggregable>`_ on ``gs``. The resulting **sample key table** has key column ``key_name`` and a numeric column of scores for each sample; named by the sample ID. 3) For each key, fit the logistic regression model using the supplied phenotype, covariates, and test.; The model and tests are those of :py:meth:`.logreg` with sample genotype ``gt`` replaced by the; score in the sample key table. For each key, missing scores are mean-imputed across all samples. The resulting **logistic regression key table** has key column of type String given by the ``key_name``; parameter and additional columns corresponding to the fields of the ``va.logreg`` schema given for ``test``; in :py:meth:`.logreg`. :py:meth:`.logreg_burden` returns both the logistic regression key table and the sample key table. :param str key_name: Name to assign to key column of returned key tables. :param str variant_keys: Variant annotation path for the TArray or TSet of keys associated to each variant. :param bool single_key: if true, ``variant_keys`` is interpreted as a single (or missing) key per variant,; rather than as a collection of keys. :param str agg_expr: Sample aggregation expression (per key). :param str test: Statistical test, one of: 'wald', 'lrt', 'score', or 'firth'. :param str y: Response expression. :param covariates: list of covariate expressions.; :t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:152864,log,logreg,152864,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"h variant for association. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Suppose the variant dataset saved at data/example_lmmreg.vds has a Boolean variant annotation va.useInKinship and numeric or Boolean sample annotations sa.pheno, sa.cov1, sa.cov2. Then the lmmreg() function in; >>> assoc_vds = hc.read(""data/example_lmmreg.vds""); >>> kinship_matrix = assoc_vds.filter_variants_expr('va.useInKinship').rrm(); >>> lmm_vds = assoc_vds.lmmreg(kinship_matrix, 'sa.pheno', ['sa.cov1', 'sa.cov2']). will execute the following four steps in order:. filter to samples in given kinship matrix to those for which sa.pheno, sa.cov, and sa.cov2 are all defined; compute the eigendecomposition \(K = USU^T\) of the kinship matrix; fit covariate coefficients and variance parameters in the sample-covariates-only (global) model using restricted maximum likelihood (REML), storing results in global annotations under global.lmmreg; test each variant for association, storing results under va.lmmreg in variant annotations. This plan can be modified as follows:. Set run_assoc=False to not test any variants for association, i.e. skip Step 5.; Set use_ml=True to use maximum likelihood instead of REML in Steps 4 and 5.; Set the delta argument to manually set the value of \(\delta\) rather that fitting \(\delta\) in Step 4.; Set the global_root argument to change the global annotation root in Step 4.; Set the va_root argument to change the variant annotation root in Step 5. lmmreg() adds 9 or 13 global annotations in Step 4, depending on whether \(\delta\) is set or fit. Annotation; Type; Value. global.lmmreg.useML; Boolean; true if fit by ML, false if fit by REML. global.lmmreg.beta; Dict[String, Double]; map from intercept and the given covariates expressions to the corresponding fit \(\beta\) coefficients. global.lmmreg.sigmaG2; Double; fit coefficient of genetic variance, \(\hat{\sigma}_g^2\). global.lmmreg.sigmaE2; Double; fit coefficient o",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:92704,test,test,92704,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"h(csq); ... .when('synonymous', 1); ... .when('SYN', 1); ... .when('missense', 2); ... .when('MIS', 2); ... .when('loss of function', 3); ... .when('LOF', 3); ... .or_missing()); >>> hl.eval(expr); 3. Notes; All expressions appearing as the then parameters to; when() or; default() method calls must be the; same type. See also; case(), cond(), switch(). Parameters:; expr (Expression) – Value to match against. Attributes. Methods. default; Finish the switch statement by adding a default case. or_error; Finish the switch statement by throwing an error with the given message. or_missing; Finish the switch statement by returning missing. when; Add a value test. when_missing; Add a test for missingness. default(then)[source]; Finish the switch statement by adding a default case.; Notes; If no value from a when() call is matched, then; then is returned. Parameters:; then (Expression). Returns:; Expression. or_error(message)[source]; Finish the switch statement by throwing an error with the given message.; Notes; If no value from a SwitchBuilder.when() call is matched, then an; error is thrown. Parameters:; message (Expression of type tstr). Returns:; Expression. or_missing()[source]; Finish the switch statement by returning missing.; Notes; If no value from a when() call is matched, then; the result is missing. Parameters:; then (Expression). Returns:; Expression. when(value, then)[source]; Add a value test. If the base expression is equal to value, then; returns then. Warning; Missingness always compares to missing. Both NA == NA and; NA != NA return NA. Use when_missing(); to test missingness. Parameters:. value (Expression); then (Expression). Returns:; SwitchBuilder – Mutates and returns self. when_missing(then)[source]; Add a test for missingness. If the base expression is missing,; returns then. Parameters:; then (Expression). Returns:; SwitchBuilder – Mutates and returns self. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/hail.expr.builders.SwitchBuilder.html:2347,test,test,2347,docs/0.2/functions/hail.expr.builders.SwitchBuilder.html,https://hail.is,https://hail.is/docs/0.2/functions/hail.expr.builders.SwitchBuilder.html,3,['test'],['test']
Testability,"h(name='rf-loo', default_python_image=python_image). with hfs.open(df_y_path) as f:; local_df_y = pd.read_table(f, header=0, index_col=0). df_x_input = b.read_input(df_x_path); df_y_input = b.read_input(df_y_path). results = []. for window in local_df_y.index.to_list():; j = b.new_python_job(); result = j.call(random_forest, df_x_input, df_y_input, window); tsv_result = j.call(as_tsv, result); results.append(tsv_result.as_str()). output = hb.concatenate(b, results); b.write_output(output, output_path). b.run(wait=False); backend.close(). run_rf_checkpoint.py; from typing import Tuple. import pandas as pd; from sklearn.ensemble import RandomForestRegressor. import hailtop.batch as hb; import hailtop.fs as hfs. def random_forest(df_x_path: str, df_y_path: str, window_name: str, cores: int = 1) -> Tuple[str, float, float]:; # read in data; df_x = pd.read_table(df_x_path, header=0, index_col=0); df_y = pd.read_table(df_y_path, header=0, index_col=0). # split training and testing data for the current window; x_train = df_x[df_x.index != window_name]; x_test = df_x[df_x.index == window_name]. y_train = df_y[df_y.index != window_name]; y_test = df_y[df_y.index == window_name]. # run random forest; max_features = 3 / 4; rf = RandomForestRegressor(n_estimators=100, n_jobs=cores, max_features=max_features, oob_score=True, verbose=False). rf.fit(x_train, y_train). # apply the trained random forest on testing data; y_pred = rf.predict(x_test). # store obs and pred values for this window; obs = y_test[""oe""].to_list()[0]; pred = y_pred[0]. return (window_name, obs, pred). def as_tsv(input: Tuple[str, float, float]) -> str:; return '\t'.join(str(i) for i in input). def checkpoint_path(window):; return f'gs://my_bucket/checkpoints/random-forest/{window}'. def main(df_x_path, df_y_path, output_path, python_image):; backend = hb.ServiceBackend(); b = hb.Batch(name='rf-loo', default_python_image=python_image). with hfs.open(df_y_path) as f:; local_df_y = pd.read_table(f, header=0, ind",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/cookbook/random_forest.html:13804,test,testing,13804,docs/batch/cookbook/random_forest.html,https://hail.is,https://hail.is/docs/batch/cookbook/random_forest.html,2,['test'],['testing']
Testability,"h.join(log_dir, 'hail'), suffix=f'-{py_version}.log'); return log. def convert_gcs_requester_pays_configuration_to_hadoop_conf_style(; x: Optional[Union[str, Tuple[str, List[str]]]],; ) -> Tuple[Optional[str], Optional[str]]:; if isinstance(x, str):; return x, None; if isinstance(x, tuple):; return x[0], "","".join(x[1]); return None, None. class HailContext(object):; @staticmethod; def create(; log: str,; quiet: bool,; append: bool,; tmpdir: str,; local_tmpdir: str,; default_reference: str,; global_seed: Optional[int],; backend: Backend,; ):; hc = HailContext(; log=log,; quiet=quiet,; append=append,; tmpdir=tmpdir,; local_tmpdir=local_tmpdir,; global_seed=global_seed,; backend=backend,; ); hc.initialize_references(default_reference); return hc. @typecheck_method(; log=str, quiet=bool, append=bool, tmpdir=str, local_tmpdir=str, global_seed=nullable(int), backend=Backend; ); def __init__(self, log, quiet, append, tmpdir, local_tmpdir, global_seed, backend):; assert not Env._hc. self._log = log. self._tmpdir = tmpdir; self._local_tmpdir = local_tmpdir. self._backend = backend. self._warn_cols_order = True; self._warn_entries_order = True. self._default_ref: Optional[ReferenceGenome] = None. if not quiet:; py_version = version(); sys.stderr.write(; 'Welcome to\n'; ' __ __ <>__\n'; ' / /_/ /__ __/ /\n'; ' / __ / _ `/ / /\n'; ' /_/ /_/\\_,_/_/_/ version {}\n'.format(py_version); ). if py_version.startswith('devel'):; sys.stderr.write(; 'NOTE: This is a beta version. Interfaces may change\n'; ' during the beta period. We recommend pulling\n'; ' the latest changes weekly.\n'; ); sys.stderr.write(f'LOGGING: writing to {log}\n'). self._user_specified_rng_nonce = True; if global_seed is None:; if 'rng_nonce' not in backend.get_flags('rng_nonce'):; backend.set_flags(rng_nonce=hex(Random().randrange(-(2**63), 2**63 - 1))); self._user_specified_rng_nonce = False; else:; backend.set_flags(rng_nonce=hex(global_seed)); Env._hc = self. def initialize_references(self, default_reference)",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:3073,log,log,3073,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['log'],['log']
Testability,"h`, :func:`.if_else`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `condition`.; """"""; return if_else(condition, consequent, alternate, missing_false). [docs]@typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def if_else(condition, consequent, alternate, missing_false: bool = False):; """"""Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.if_else(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.if_else(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `condition`.; """"""; if missing_false:; condition = hl.bind(lambda x: hl.is_defined(x) & x, condition); indices, aggregations = unify_all(condition, consequent, alternate). consequent, alternate, success = unify_exprs(consequent, alternate); if not success:; raise TypeError(; f""'if_else' and 'cond' require the 'consequent' and 'alternate' arguments to have the same type\n""; f"" consequent: type '{consequent.dtype}'\n""; f"" alternate: type '{alternate.dtype}'""; ); assert consequent.dtype == alternate.dtype. return construct_expr(ir.If(condition._ir, consequent._ir, alternate._ir), ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:14547,test,test,14547,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"hat is uniform on the log scale, with \(\mathrm{ln}(\delta)\) running from -8 to 8 by 0.01, corresponding to \(h^2\) decreasing from 0.9995 to 0.0005. If \(h^2\) is maximized at the lower boundary then standard linear regression would be more appropriate and Hail will exit; more generally, consider using standard linear regression when \(\hat{h}^2\) is very small. A maximum at the upper boundary is highly suspicious and will also cause Hail to exit. In any case, the log file records the table of grid values for further inspection, beginning under the info line containing “lmmreg: table of delta”.; If the optimal grid point falls in the interior of the grid as expected, we then use Brent’s method to find the precise location of the maximum over the same range, with initial guess given by the optimal grid point and a tolerance on \(\mathrm{ln}(\delta)\) of 1e-6. If this location differs from the optimal grid point by more than 0.01, a warning will be displayed and logged, and one would be wise to investigate by plotting the values over the grid.; Note that \(h^2\) is related to \(\mathrm{ln}(\delta)\) through the sigmoid function. More precisely,. \[h^2 = 1 - \mathrm{sigmoid}(\mathrm{ln}(\delta)) = \mathrm{sigmoid}(-\mathrm{ln}(\delta))\]; Hence one can change variables to extract a high-resolution discretization of the likelihood function of \(h^2\) over \([0,1]\) at the corresponding REML estimators for \(\beta\) and \(\sigma_g^2\), as well as integrate over the normalized likelihood function using change of variables and the sigmoid differential equation.; For convenience, global.lmmreg.fit.normLkhdH2 records the the likelihood function of \(h^2\) normalized over the discrete grid 0.01, 0.02, ..., 0.98, 0.99. The length of the array is 101 so that index i contains the likelihood at percentage i. The values at indices 0 and 100 are left undefined.; By the theory of maximum likelihood estimation, this normalized likelihood function is approximately normally distribut",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:102551,log,logged,102551,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logged']
Testability,"he complement of the CDF value is:; #; # 1. Q is a measure of variance and thus positive.; #; # 2. We want to know the probability of obtaining a variance even larger (""more extreme""); #; # Ergo, we want to check the right-tail of the distribution.; p_value=1.0 - genchisq_data.value,; fault=genchisq_data.fault,; ); return ht.select_globals('y_residual', 's2', 'n_complete_samples', 'null_fit'). [docs]@typecheck(; key_expr=expr_any,; weight_expr=expr_float64,; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; logistic=oneof(bool, sized_tupleof(nullable(int), nullable(float))),; max_size=int,; accuracy=numeric,; iterations=int,; ); def skat(; key_expr,; weight_expr,; y,; x,; covariates,; logistic: Union[bool, Tuple[int, float]] = False,; max_size: int = 46340,; accuracy: float = 1e-6,; iterations: int = 10000,; ) -> Table:; r""""""Test each keyed group of rows for association by linear or logistic; SKAT test. Examples; --------. Test each gene for association using the linear sequence kernel association; test:. >>> skat_table = hl.skat(key_expr=burden_ds.gene,; ... weight_expr=burden_ds.weight,; ... y=burden_ds.burden.pheno,; ... x=burden_ds.GT.n_alt_alleles(),; ... covariates=[1, burden_ds.burden.cov1, burden_ds.burden.cov2]). .. caution::. By default, the Davies algorithm iterates up to 10k times until an; accuracy of 1e-6 is achieved. Hence a reported p-value of zero with no; issues may truly be as large as 1e-6. The accuracy and maximum number of; iterations may be controlled by the corresponding function parameters.; In general, higher accuracy requires more iterations. .. caution::. To process a group with :math:`m` rows, several copies of an; :math:`m \times m` matrix of doubles must fit in worker memory. Groups; with tens of thousands of rows may exhaust worker memory causing the; entire job to fail. In this case, use the `max_size` parameter to skip; groups larger than `max_size`. Warning; -------; :func:`.skat` considers the same set of col",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:101896,test,test,101896,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,3,"['Test', 'test']","['Test', 'test']"
Testability,"he get item syntax of; job[‘identifier’]. If an object for that identifier doesn’t exist,; then one will be created automatically (only allowed in the; command() method). The identifier name can be any valid Python; identifier such as ofile5000.; All JobResourceFile are temporary files and must be written to; a permanent location using Batch.write_output() if the output; needs to be saved.; Only resources can be referred to in commands. Referencing a; batch.Batch or Job will result in an error. Parameters:; command (str) – A bash command. Return type:; BashJob. Returns:; Same job object with command appended. declare_resource_group(**mappings); Declare a resource group for a job.; Examples; Declare a resource group:; >>> b = Batch(); >>> input = b.read_input_group(bed='data/example.bed',; ... bim='data/example.bim',; ... fam='data/example.fam'); >>> j = b.new_job(); >>> j.declare_resource_group(tmp1={'bed': '{root}.bed',; ... 'bim': '{root}.bim',; ... 'fam': '{root}.fam',; ... 'log': '{root}.log'}); >>> j.command(f'plink --bfile {input} --make-bed --out {j.tmp1}'); >>> b.run() . Warning; Be careful when specifying the expressions for each file as this is Python; code that is executed with eval!. Parameters:; mappings (Dict[str, Any]) – Keywords (in the above example tmp1) are the name(s) of the; resource group(s). File names may contain arbitrary Python; expressions, which will be evaluated by Python eval. To use the; keyword as the file name, use {root} (in the above example {root}; will be replaced with tmp1). Return type:; BashJob. Returns:; Same job object with resource groups set. image(image); Set the job’s docker image.; Examples; Set the job’s docker image to ubuntu:22.04:; >>> b = Batch(); >>> j = b.new_job(); >>> (j.image('ubuntu:22.04'); ... .command(f'echo ""hello""')); >>> b.run() . Parameters:; image (str) – Docker image to use. Return type:; BashJob. Returns:; Same job object with docker image set. Previous; Next . © Copyright 2024, Hail Team. Built w",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.BashJob.html:3442,log,log,3442,docs/batch/api/batch/hailtop.batch.job.BashJob.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.BashJob.html,2,['log'],['log']
Testability,"he p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association. The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the `Jeffrey's; invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This; test is slower, as both the null and full model must be fit per variant,; and convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted for the null model; and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the `logreg.fit` fields reflect the null model;; otherwise, they reflect the full model. See; `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert's notes; `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__.; Firth introduced his approach in; `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/GibbsFieldEst/BiasReductionMLE.pdf>`__.; Heinze and Schemper further analyze Firth's approach in; `A solution to the problem of separation in logistic regression, 2002 <https://cemsiis.meduniwien.ac.at/fileadmin/msi_akim/CeMSIIS/KB/volltexte/Heinze_Schemper_2002_Statistics_in_Medicine.pdf>`__. Hail's logistic regression tests correspond to the ``b.wald``,; ``b.lrt``, and ``b.score`` tests in `EPACTS`_. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:55002,log,logistic,55002,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,"['log', 'test']","['logistic', 'tests']"
Testability,"he result can be stored in memory on a single machine. Warning; Using counter() with a large number of unique items can cause; out-of-memory exceptions. Parameters:. expr (Expression) – Expression to count by key.; weight (NumericExpression, optional) – Expression by which to weight each occurence (when unspecified,; it is effectively 1). Returns:; DictExpression – Dictionary with the number of occurrences of each unique record. hail.expr.aggregators.any(condition)[source]; Returns True if condition is True for any record.; Examples; >>> (table1.group_by(table1.SEX); ... .aggregate(any_over_70 = hl.agg.any(table1.HT > 70)); ... .show()); +-----+-------------+; | SEX | any_over_70 |; +-----+-------------+; | str | bool |; +-----+-------------+; | ""F"" | False |; | ""M"" | True |; +-----+-------------+. Notes; If there are no records to aggregate, the result is False.; Missing records are not considered. If every record is missing,; the result is also False. Parameters:; condition (BooleanExpression) – Condition to test. Returns:; BooleanExpression. hail.expr.aggregators.all(condition)[source]; Returns True if condition is True for every record.; Examples; >>> (table1.group_by(table1.SEX); ... .aggregate(all_under_70 = hl.agg.all(table1.HT < 70)); ... .show()); +-----+--------------+; | SEX | all_under_70 |; +-----+--------------+; | str | bool |; +-----+--------------+; | ""F"" | False |; | ""M"" | False |; +-----+--------------+. Notes; If there are no records to aggregate, the result is True.; Missing records are not considered. If every record is missing,; the result is also True. Parameters:; condition (BooleanExpression) – Condition to test. Returns:; BooleanExpression. hail.expr.aggregators.take(expr, n, ordering=None)[source]; Take n records of expr, optionally ordered by ordering.; Examples; Take 3 elements of field X:; >>> table1.aggregate(hl.agg.take(table1.X, 3)); [5, 6, 7]. Take the ID and HT fields, ordered by HT (descending):; >>> table1.aggregate(hl.agg.ta",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/aggregators.html:7105,test,test,7105,docs/0.2/aggregators.html,https://hail.is,https://hail.is/docs/0.2/aggregators.html,1,['test'],['test']
Testability,"heno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). To use a weighted sum of genotypes with missing genotypes mean-imputed rather than ignored, set; ``agg_expr='gs.map(g => va.weight * orElse(g.gt.toDouble, 2 * va.qc.AF)).sum()'`` where ``va.qc.AF``; is the allele frequency over those samples that have no missing phenotype or covariates. .. caution::. With ``single_key=False``, ``variant_keys`` expects a variant annotation of Set or Array type, in order to; allow each variant to have zero, one, or more keys (for example, the same variant may appear in multiple; genes). Unlike with type Set, if the same key appears twice in a variant annotation of type Array, then that; variant will be counted twice in that key's group. With ``single_key=True``, ``variant_keys`` expects a; variant annotation whose value is itself the key of interest. In bose cases, variants with missing keys are; ignored. **Notes**. This method modifies :py:meth:`.logreg` by replacing the genotype covariate per variant and sample with; an aggregated (i.e., collapsed) score per key and sample. This numeric score is computed from the sample's; genotypes and annotations over all variants with that key. The phenotype type must either be numeric; (with all present values 0 or 1) or Boolean, in which case true and false are coded as 1 and 0, respectively. Hail supports the Wald test ('wald'), likelihood ratio test ('lrt'), Rao score test ('score'),; and Firth test ('firth') as the ``test`` parameter. Conceptually, the method proceeds as follows:. 1) Filter to the set of samples for which all phenotype and covariates are defined. 2) For each key and sample, aggregate genotypes across variants with that key to produce a numeric score.; ``agg_expr`` must be of numeric type and has the following symbols are in scope:. - ``s`` (*Sample*): sample; - ``sa``: sample annotations; - ``global``: global annotations; - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``. Note that",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:151408,log,logreg,151408,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"her (Table) – Table with compatible key field(s). Returns:; MatrixTable. Notes; The row key type of the matrix table must match the key type of other.; This method does not change the schema of the matrix table; it is; filtering the matrix table to row keys present in another table.; To discard rows whose key is present in other, use; anti_join_rows().; Examples; >>> ds_result = ds.semi_join_rows(rows_to_keep). It may be expensive to key the matrix table by the right-side key.; In this case, it is possible to implement a semi-join using a non-key; field as follows:; >>> ds_result = ds.filter_rows(hl.is_defined(rows_to_keep.index(ds['locus'], ds['alleles']))). See also; anti_join_rows(), filter_rows(), semi_join_cols(). show(n_rows=None, n_cols=None, include_row_fields=False, width=None, truncate=None, types=True, handler=None)[source]; Print the first few rows of the matrix table to the console. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. Notes; The output can be passed piped to another output source using the handler argument:; >>> mt.show(handler=lambda x: logging.info(x)) . Parameters:. n_rows (int) – Maximum number of rows to show.; n_cols (int) – Maximum number of columns to show.; width (int) – Horizontal width at which to break fields.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field.; handler (Callable[[str], Any]) – Handler function for data string. summarize(*, rows=True, cols=True, entries=True, handler=None)[source]; Compute and print summary information about the fields in the matrix table. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. Parameters:. rows (bool) – Compute summary for the row fields.; cols (bool) – Compute ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.MatrixTable.html:60173,test,tested,60173,docs/0.2/hail.MatrixTable.html,https://hail.is,https://hail.is/docs/0.2/hail.MatrixTable.html,1,['test'],['tested']
Testability,"her11 = hl.nd.array([[(mu * xvec.T) @ xvec]]); fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). test_fit = _poisson_fit(X, yvec, b, mu, score, fisher, max_iterations, tolerance); if test == 'lrt':; return ht.select(test_fit=test_fit, **lrt_test(X, null_fit, test_fit), **ht.pass_through).select_globals(; 'null_fit'; ); assert test == 'wald'; return ht.select(test_fit=test_fit, **wald_test(X, test_fit), **ht.pass_through).select_globals('null_fit'). def _poisson_fit(; X: NDArrayNumericExpression, # (N, K); y: NDArrayNumericExpression, # (N,); b: NDArrayNumericExpression, # (K,); mu: NDArrayNumericExpression, # (N,); score: NDArrayNumericExpression, # (K,); fisher: NDArrayNumericExpression, # (K, K); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Poisson(exp(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1; assert mu.ndim == 1; assert score.ndim == 1; assert fisher.ndim == 2. dtype = numerical_regression_fit_dtype; blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}). def fit(recur, iteration, b, mu, score, fisher):; def cont(exploded, delta_b, max_delta_b):; log_lkhd = y @ hl.log(mu) - mu.sum(). next_b = b + delta_b; next_mu = hl.exp(X @ next_b); next_score = X.T @ (y - next_mu); next_fisher = (next_mu * X.T) @ X. return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(; b=b,; score=score,; fisher=fisher,; mu=mu,; n_iterations=iteration,; log_lkhd=log_lkhd,; converged=True,; exploded=False,; ),; ); .when(; iteration == max_iterations,; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=False),; ); .default(rec",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:68083,assert,assert,68083,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,['assert'],['assert']
Testability,"here is an entry for each (row, column) pair. Importing and Reading; Like tables, matrix tables can be imported from a variety of formats: VCF, (B)GEN, PLINK, TSV, etc. Matrix tables can also be read from a “native” matrix table format. Let’s read a sample of prepared 1KG data. [1]:. import hail as hl; from bokeh.io import output_notebook, show; output_notebook(). hl.utils.get_1kg('data/'). Loading BokehJS ... Loading BokehJS ... Initializing Hail with default parameters...; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2011-0.2.133-4c60fddb171a.log; 2024-10-04 20:11:52.232 Hail: INFO: 1KG files found. [2]:. mt = hl.read_matrix_table('data/1kg.mt'); mt.describe(). ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 's': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'qual': float64; 'filters': set<str>; 'info': struct {; AC: array<int32>,; AF: array<float64>,; AN: int32,; BaseQRankSum: float64,; ClippingRankSum: float64,; DP: int32,; DS: bool,; FS: float64,; HaplotypeScore: float64,; InbreedingCoeff: float64,; MLEAC: array<int32>,; MLEAF: array<float64>,; MQ: float64,; MQ0: int32,; MQRankSum: float64,; QD: float64,; ReadPosRankSum: float64,; set: str; }; ----------------------------------------; Entry fields:; 'GT': call; 'AD': array<int32>; 'DP': int32; 'GQ': int32; 'PL': array<int32>; ----------------------------------------; Column key: ['s']; Row key: ['locus', 'alleles']; ----------------------",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/07-matrixtable.html:3266,log,log,3266,docs/0.2/tutorials/07-matrixtable.html,https://hail.is,https://hail.is/docs/0.2/tutorials/07-matrixtable.html,1,['log'],['log']
Testability,"hl.is_defined)). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**y_dict, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). ht = mt._localize_entries('entries', 'samples'). # covmat rows are samples, columns are the different covariates; ht = ht.annotate_globals(; covmat=hl.nd.array(ht.samples.map(lambda s: [s[cov_name] for cov_name in cov_field_names])); ). # yvecs is a list of sample-length vectors, one for each dependent variable.; ht = ht.annotate_globals(yvecs=[hl.nd.array(ht.samples[y_name]) for y_name in y_field_names]). # Fit null models, which means doing a logreg fit with just the covariates for each phenotype.; def fit_null(yvec):; def error_if_not_converged(null_fit):; return (; hl.case(); .when(; ~null_fit.exploded,; (; hl.case(); .when(null_fit.converged, null_fit); .or_error(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:59194,log,logistic,59194,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logistic']
Testability,"hl.range(0, len(header_dict['column_ids'])).map(lambda col_idx: hl.struct(col_id=hl_columns[col_idx])); ). if not add_row_id:; ht = ht.drop('row_id'). mt = ht._unlocalize_entries('entries', 'cols', ['col_id']); mt = mt.key_rows_by(*row_key); return mt. [docs]@typecheck(; bed=str,; bim=str,; fam=str,; min_partitions=nullable(int),; delimiter=str,; missing=str,; quant_pheno=bool,; a2_reference=bool,; reference_genome=nullable(reference_genome_type),; contig_recoding=nullable(dictof(str, str)),; skip_invalid_loci=bool,; n_partitions=nullable(int),; block_size=nullable(int),; ); def import_plink(; bed,; bim,; fam,; min_partitions=None,; delimiter='\\\\s+',; missing='NA',; quant_pheno=False,; a2_reference=True,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; n_partitions=None,; block_size=None,; ) -> MatrixTable:; """"""Import a PLINK dataset (BED, BIM, FAM) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_plink(bed='data/test.bed',; ... bim='data/test.bim',; ... fam='data/test.fam',; ... reference_genome='GRCh37'). Notes; -----. Only binary SNP-major mode files can be read into Hail. To convert your; file from individual-major mode to SNP-major mode, use PLINK to read in; your fileset and use the ``--make-bed`` option. Hail uses the individual ID (column 2 in FAM file) as the sample id (`s`).; The individual IDs must be unique. The resulting :class:`.MatrixTable` has the following fields:. * Row fields:. * `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The; chromosome and position. If `reference_genome` is defined, the type; will be :class:`.tlocus` parameterized by `reference_genome`.; Otherwise, the type will be a :class:`.tstruct` with two fields:; `contig` with type :py:data:`.tstr` and `position` with type; :py:data:`.tint32`.; * `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference allele (A2; if `a2_reference` is ``True``) is the first ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/impex.html:85969,test,test,85969,docs/0.2/_modules/hail/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html,2,['test'],['test']
Testability,"hmem’ are also valid arguments. ‘lowmem’ corresponds to; approximately 1 Gi/core, ‘standard’ corresponds to approximately; 4 Gi/core, and ‘highmem’ corresponds to approximately 7 Gi/core.; The default value is ‘standard’. Parameters:; memory (Union[str, int, None]) – Units are in bytes if memory is an int. If None,; use the default value for the ServiceBackend (‘standard’). Return type:; Self. Returns:; Same job object with memory requirements set. regions(regions); Set the cloud regions a job can run in.; Notes; Can only be used with the backend.ServiceBackend.; This method may be used to ensure code executes in the same region as the data it reads.; This can avoid egress charges as well as improve latency.; Examples; Require the job to run in ‘us-central1’:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.regions(['us-central1']); ... .command(f'echo ""hello""')). Specify the job can run in any region:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.regions(None); ... .command(f'echo ""hello""')). Parameters:; regions (Optional[List[str]]) – The cloud region(s) to run this job in. Use None to signify; the job can run in any available region. Use py:staticmethod:.ServiceBackend.supported_regions; to list the available regions to choose from. The default is the job can run in; any region. Return type:; Self. Returns:; Same job object with the cloud regions the job can run in set. spot(is_spot); Set whether a job is run on spot instances. By default, all jobs run on spot instances.; Examples; Ensure a job only runs on non-spot instances:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> j = j.spot(False); >>> j = j.command(f'echo ""hello""'). Parameters:; is_spot (bool) – If False, this job will be run on non-spot instances. Return type:; Self. Returns:; Same job object. storage(storage); Set the job’s storage size.; Examples; Set the job’s disk requirements to 10 Gi:; >",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html:7133,test,test,7133,docs/batch/api/batch/hailtop.batch.job.Job.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html,2,['test'],['test']
Testability,hondrial() (hail.representation.Variant method). is_MNP() (hail.representation.AltAllele method). is_not_called() (hail.representation.Call method). (hail.representation.Genotype method). is_SNP() (hail.representation.AltAllele method). is_transition() (hail.representation.AltAllele method). is_transversion() (hail.representation.AltAllele method). J. join() (hail.KeyTable method). (hail.VariantDataset method). K. key (hail.KeyTable attribute). key_by() (hail.KeyTable method). key_schema (hail.KinshipMatrix attribute). KeyTable (class in hail). KinshipMatrix (class in hail). L. ld_matrix() (hail.VariantDataset method). ld_prune() (hail.VariantDataset method). LDMatrix (class in hail). linreg() (hail.VariantDataset method). linreg3() (hail.VariantDataset method). linreg_burden() (hail.VariantDataset method). linreg_multi_pheno() (hail.VariantDataset method). lmmreg() (hail.VariantDataset method). Locus (class in hail.representation). locus() (hail.representation.Variant method). logreg() (hail.VariantDataset method). logreg_burden() (hail.VariantDataset method). M. make_table() (hail.VariantDataset method). matrix() (hail.KinshipMatrix method). (hail.LDMatrix method). maximal_independent_set() (hail.KeyTable method). mendel_errors() (hail.VariantDataset method). min_rep() (hail.VariantDataset method). mother (hail.representation.Trio attribute). N. naive_coalesce() (hail.VariantDataset method). num_alleles() (hail.representation.Variant method). num_alt_alleles() (hail.representation.Call method). (hail.representation.Genotype method). (hail.representation.Variant method). num_columns (hail.KeyTable attribute). num_genotypes() (hail.representation.Variant method). num_mismatch() (hail.representation.AltAllele method). num_partitions() (hail.KeyTable method). (hail.VariantDataset method). num_samples (hail.VariantDataset attribute). O. od() (hail.representation.Genotype method). one_hot_alleles() (hail.representation.Call method). (hail.representation.Genotype method),MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/genindex.html:8062,log,logreg,8062,docs/0.1/genindex.html,https://hail.is,https://hail.is/docs/0.1/genindex.html,1,['log'],['logreg']
Testability,"hrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})\). For Phred-scaled values,; \(\mathrm{P}(\mathrm{Het})\) and \(\mathrm{P}(\mathrm{HomVar})\) are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1.; The example above considers a model of the form. \[\mathrm{Prob}(\mathrm{isCase}) = \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt} + \beta_2 \, \mathrm{age} + \beta_3 \, \mathrm{isFemale} + \varepsilon), \quad \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid; function, the; genotype \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; \(\mathrm{isFemale}\) is coded as 1 for true (female) and; 0 for false (male). The null model sets \(\beta_1 = 0\).; The resulting variant annotations depend on the test statistic; as shown in the tables below. Test; Annotation; Type; Value. Wald; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). Wald; va.logreg.se; Double; estimated standard error, \(\widehat{\mathrm{se}}\). Wald; va.logreg.zstat; Double; Wald \(z\)-statistic, equal to \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Valu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:111106,log,logreg,111106,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logreg']
Testability,"ht = ht.annotate_globals(; cols=hl.range(0, len(header_dict['column_ids'])).map(lambda col_idx: hl.struct(col_id=hl_columns[col_idx])); ). if not add_row_id:; ht = ht.drop('row_id'). mt = ht._unlocalize_entries('entries', 'cols', ['col_id']); mt = mt.key_rows_by(*row_key); return mt. [docs]@typecheck(; bed=str,; bim=str,; fam=str,; min_partitions=nullable(int),; delimiter=str,; missing=str,; quant_pheno=bool,; a2_reference=bool,; reference_genome=nullable(reference_genome_type),; contig_recoding=nullable(dictof(str, str)),; skip_invalid_loci=bool,; n_partitions=nullable(int),; block_size=nullable(int),; ); def import_plink(; bed,; bim,; fam,; min_partitions=None,; delimiter='\\\\s+',; missing='NA',; quant_pheno=False,; a2_reference=True,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; n_partitions=None,; block_size=None,; ) -> MatrixTable:; """"""Import a PLINK dataset (BED, BIM, FAM) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_plink(bed='data/test.bed',; ... bim='data/test.bim',; ... fam='data/test.fam',; ... reference_genome='GRCh37'). Notes; -----. Only binary SNP-major mode files can be read into Hail. To convert your; file from individual-major mode to SNP-major mode, use PLINK to read in; your fileset and use the ``--make-bed`` option. Hail uses the individual ID (column 2 in FAM file) as the sample id (`s`).; The individual IDs must be unique. The resulting :class:`.MatrixTable` has the following fields:. * Row fields:. * `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The; chromosome and position. If `reference_genome` is defined, the type; will be :class:`.tlocus` parameterized by `reference_genome`.; Otherwise, the type will be a :class:`.tstruct` with two fields:; `contig` with type :py:data:`.tstr` and `position` with type; :py:data:`.tint32`.; * `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference allele (A2; if `a2_refer",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/impex.html:85943,test,test,85943,docs/0.2/_modules/hail/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html,2,['test'],['test']
Testability,"ht exclusive. This means that [chr1:1, chr1:3) contains chr1:1 and chr1:2.; Arguments. startLocus (Locus) – Start position of interval; endLocus (Locus) – End position of interval. isDefined(a: T): Boolean – Returns true if item is non-missing. Otherwise, false. isMissing(a: T): Boolean – Returns true if item is missing. Otherwise, false. isnan(a: Double): Boolean – Returns true if the argument is NaN (not a number), false if the argument is defined but not NaN. Returns missing if the argument is missing. json(x: T): String – Returns the JSON representation of a data type. Locus(contig: String, pos: Int): Locus. Construct a Locus object.; let l = Locus(""1"", 10040532) in l.position; result: 10040532. Arguments. contig (String) – String representation of contig.; pos (Int) – SNP position or start of an indel. Locus(s: String): Locus. Construct a Locus object.; let l = Locus(""1:10040532"") in l.position; result: 10040532. Arguments. s (String) – String of the form CHR:POS. log(x: Double, b: Double): Double. Returns the base b logarithm of the given value x.; Arguments. x (Double) – the number to take the base b logarithm of.; b (Double) – the base. log(x: Double): Double. Returns the natural logarithm of the given value x.; Arguments. x (Double) – the number to take the natural logarithm of. log10(x: Double): Double. Returns the base 10 logarithm of the given value x.; Arguments. x (Double) – the number to take the base 10 logarithm of. merge(s1: Struct, s2: Struct): Struct. Create a new Struct with all fields in s1 and s2.; let s1 = {gene: ""ACBD"", function: ""LOF""} and s2 = {a: 20, b: ""hello""} in merge(s1, s2); result: {gene: ""ACBD"", function: ""LOF"", a: 20, b: ""hello""}. orElse(a: T, b: T): T. If a is not missing, returns a. Otherwise, returns b.; Examples; Replace missing phenotype values with the mean value:; >>> [mean_height] = vds.query_samples(['samples.map(s => sa.pheno.height).stats()'])['mean']; >>> vds.annotate_samples_expr('sa.pheno.heightImputed = orElse(sa.phe",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:11901,log,log,11901,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,1,['log'],['log']
Testability,"ht:; >>> ht1 = ht.annotate(B = ht2[ht.ID].B); >>> ht1.show(width=120); +-------+-------+-----+-------+-------+-------+-------+-------+----------+; | ID | HT | SEX | X | Z | C1 | C2 | C3 | B |; +-------+-------+-----+-------+-------+-------+-------+-------+----------+; | int32 | int32 | str | int32 | int32 | int32 | int32 | int32 | str |; +-------+-------+-----+-------+-------+-------+-------+-------+----------+; | 1 | 65 | ""M"" | 5 | 4 | 2 | 50 | 5 | ""cat"" |; | 2 | 72 | ""M"" | 6 | 3 | 2 | 61 | 1 | ""dog"" |; | 3 | 70 | ""F"" | 7 | 3 | 10 | 81 | -5 | ""mouse"" |; | 4 | 60 | ""F"" | 8 | 2 | 11 | 90 | -10 | ""rabbit"" |; +-------+-------+-----+-------+-------+-------+-------+-------+----------+. Interacting with Tables Locally; Hail has many useful methods for interacting with tables locally such as in an; Jupyter notebook. Use the Table.show() method to see the first few rows; of a table.; Table.take() will collect the first n rows of a table into a local; Python list:; >>> first3 = ht.take(3); >>> first3; [Struct(ID=1, HT=65, SEX='M', X=5, Z=4, C1=2, C2=50, C3=5),; Struct(ID=2, HT=72, SEX='M', X=6, Z=3, C1=2, C2=61, C3=1),; Struct(ID=3, HT=70, SEX='F', X=7, Z=3, C1=10, C2=81, C3=-5)]. Note that each element of the list is a Struct whose elements can be; accessed using Python’s get attribute or get item notation:; >>> first3[0].ID; 1. >>> first3[0]['ID']; 1. The Table.head() method is helpful for testing pipelines. It subsets a; table to the first n rows, causing downstream operations to run much more; quickly.; Table.describe() is a useful method for showing all of the fields of the; table and their types. The types themselves can be accessed using the fields; (e.g. ht.ID.dtype), and the full row and global types can be accessed with; ht.row.dtype and ht.globals.dtype. The row fields that are part of the; key can be accessed with Table.key. The Table.count() method; returns the number of rows. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/overview/table.html:8835,test,testing,8835,docs/0.2/overview/table.html,https://hail.is,https://hail.is/docs/0.2/overview/table.html,1,['test'],['testing']
Testability,"i_sq_stat=firth_chi_sq,; p_value=firth_p,; firth_null_fit=firth_improved_null_fit,; fit=firth_fit,; ),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit, fit=firth_fit)),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit)); ). return hl.bind(cont2, firth_fit). return hl.bind(cont, firth_improved_null_fit). @typecheck(; test=enumeration('wald', 'lrt', 'score', 'firth'),; y=oneof(expr_float64, sequenceof(expr_float64)),; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=nullable(int),; tolerance=nullable(float),; ); def _logistic_regression_rows_nd(; test, y, x, covariates, pass_through=(), *, max_iterations: Optional[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Warning; -------; :func:`.logistic_regression_rows` considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which **all** response variables and covariates are defined. For each row, missing values of; `x` are mean-imputed over these columns. As in the example, t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:47323,log,logistic,47323,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,"['log', 'test']","['logistic', 'test']"
Testability,"ia.org/wiki/F-distribution>`__ with parameters; `df1` and `df2`. Examples; --------. >>> hl.eval(hl.pF(0, 3, 10)); 0.0. >>> hl.eval(hl.pF(1, 3, 10)); 0.5676627969783028. >>> hl.eval(hl.pF(1, 3, 10, lower_tail=False)); 0.4323372030216972. >>> hl.eval(hl.pF(1, 3, 10, log_p=True)); -0.566227703842908. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is; a random variable with distribution :math:`F`(df1, df2). If `lower_tail`; is false, returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; df1 : float or :class:`.Expression` of type :py:data:`.tfloat64`; Parameter of the F-distribution; df2 : float or :class:`.Expression` of type :py:data:`.tfloat64`; Parameter of the F-distribution; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""pF"", tfloat64, x, df1, df2, lower_tail, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def ppois(x, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a Poisson distribution. Examples; --------. >>> hl.eval(hl.ppois(2, 1)); 0.9196986029286058. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is a; Poisson random variable with rate parameter `lamb`. If `lower_tail` is false,; returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; lamb : float or :class:`.Expression` of type :py:data:`.tfloat64`; Rate parameter of Poisson distribution.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:75790,log,logarithm,75790,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['logarithm']
Testability,"ial for a simple; example of conducting a genome-wide association study, and the installation page to get started; using Hail. Contents. Installation; Mac OS X; Linux; Google Dataproc; Azure HDInsight; Other Spark Clusters; After installation, try your first Hail query. Hail on the Cloud; General Advice; Query-on-Batch; Google Cloud; Microsoft Azure; Amazon Web Services; Databricks. Tutorials; Genome-Wide Association Study (GWAS) Tutorial; Table Tutorial; Aggregation Tutorial; Filtering and Annotation Tutorial; Table Joins Tutorial; MatrixTable Tutorial; Plotting Tutorial; GGPlot Tutorial. Reference (Python API); hail; hailtop.fs; hailtop.batch. Configuration Reference; Supported Configuration Variables. Overview; Expressions; Tables; MatrixTables. How-To Guides; Aggregation; Annotation (Adding Fields); Genetics. Cheatsheets; Datasets; Schemas. Annotation Database; Database Query. Libraries; gnomad (Hail Utilities for gnomAD). For Software Developers; Requirements; Building Hail; Building the Docs and Website; Running the tests; Contributing. Other Resources; Hadoop Glob Patterns. Change Log And Version Policy; Python Version Compatibility Policy; Frequently Asked Questions; Version 0.2.133; Version 0.2.132; Version 0.2.131; Version 0.2.130; Version 0.2.129; Version 0.2.128; Version 0.2.127; Version 0.2.126; Version 0.2.125; Version 0.2.124; Version 0.2.123; Version 0.2.122; Version 0.2.121; Version 0.2.120; Version 0.2.119; Version 0.2.118; Version 0.2.117; Version 0.2.116; Version 0.2.115; Version 0.2.114; Version 0.2.113; Version 0.2.112; Version 0.2.111; Version 0.2.110; Version 0.2.109; Version 0.2.108; Version 0.2.107; Version 0.2.106; Version 0.2.105; Version 0.2.104; Version 0.2.103; Version 0.2.102; Version 0.2.101; Version 0.2.100; Version 0.2.99; Version 0.2.98; Version 0.2.97; Version 0.2.96; Version 0.2.95; Version 0.2.94; Version 0.2.93; Version 0.2.92; Version 0.2.91; Version 0.2.90; Version 0.2.89; Version 0.2.88; Version 0.2.87; Version 0.2.86; Ver",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/index.html:1675,test,tests,1675,docs/0.2/index.html,https://hail.is,https://hail.is/docs/0.2/index.html,1,['test'],['tests']
Testability,"iants = hl.struct(locus=variants). if len(variants.dtype) == 0 or not variants.dtype._is_prefix_of(expected_vtype):; raise TypeError(; ""'import_bgen' requires the expression type for 'variants' is a non-empty prefix of the BGEN key type: \n""; + f""\tFound: {variants.dtype!r}\n""; + f""\tExpected: {expected_vtype!r}\n""; ). uid = Env.get_uid(); fnames = list(variants.dtype); name, variants = variants._to_table(; uid; ) # This will add back the other key fields of the source, which we don't want; variants = variants.key_by(**{fname: variants[name][fname] for fname in fnames}); variants = variants.select(); elif isinstance(variants, Table):; if len(variants.key) == 0 or not variants.key.dtype._is_prefix_of(expected_vtype):; raise TypeError(; ""'import_bgen' requires the row key type for 'variants' is a non-empty prefix of the BGEN key type: \n""; + f""\tFound: {variants.key.dtype!r}\n""; + f""\tExpected: {expected_vtype!r}\n""; ); variants = variants.select(); else:; assert isinstance(variants, list); try:; if len(variants) == 0:; variants = hl.Table.parallelize(variants, schema=expected_vtype, key=['locus', 'alleles']); else:; first_v = variants[0]; if isinstance(first_v, hl.Locus):; variants = hl.Table.parallelize(; [hl.Struct(locus=v) for v in variants], schema=hl.tstruct(locus=lt), key='locus'; ); else:; assert isinstance(first_v, hl.utils.Struct); if len(first_v) == 1:; variants = hl.Table.parallelize(variants, schema=hl.tstruct(locus=lt), key='locus'); else:; variants = hl.Table.parallelize(variants, schema=expected_vtype, key=['locus', 'alleles']); except Exception:; raise TypeError(; f""'import_bgen' requires all elements in 'variants' are a non-empty prefix of the BGEN key type: {expected_vtype!r}""; ). vir = variants._tir; if (; isinstance(vir, ir.TableRead); and isinstance(vir.reader, ir.TableNativeReader); and vir.reader.intervals is None; and variants.count() == variants.distinct().count(); ):; variants_path = vir.reader.path; else:; variants_path = new_temp_file(pref",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/impex.html:45543,assert,assert,45543,docs/0.2/_modules/hail/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html,2,['assert'],['assert']
Testability,"iants with that key to produce a numeric score.; agg_expr must be of numeric type and has the following symbols are in scope:. s (Sample): sample; sa: sample annotations; global: global annotations; gs (Aggregable[Genotype]): aggregable of Genotype for sample s. Note that v, va, and g are accessible through; Aggregable methods on gs.; The resulting sample key table has key column key_name and a numeric column of scores for each sample; named by the sample ID. For each key, fit the logistic regression model using the supplied phenotype, covariates, and test.; The model and tests are those of logreg() with sample genotype gt replaced by the; score in the sample key table. For each key, missing scores are mean-imputed across all samples.; The resulting logistic regression key table has key column of type String given by the key_name; parameter and additional columns corresponding to the fields of the va.logreg schema given for test; in logreg(). logreg_burden() returns both the logistic regression key table and the sample key table. Parameters:; key_name (str) – Name to assign to key column of returned key tables.; variant_keys (str) – Variant annotation path for the TArray or TSet of keys associated to each variant.; single_key (bool) – if true, variant_keys is interpreted as a single (or missing) key per variant,; rather than as a collection of keys.; agg_expr (str) – Sample aggregation expression (per key).; test (str) – Statistical test, one of: ‘wald’, ‘lrt’, ‘score’, or ‘firth’.; y (str) – Response expression.; covariates (list of str) – list of covariate expressions. Returns:Tuple of logistic regression key table and sample aggregation key table. Return type:(KeyTable, KeyTable). make_table(variant_expr, genotype_expr, key=[], separator='.')[source]¶; Produce a key with one row per variant and one or more columns per sample.; Examples; Consider a VariantDataset vds with 2 variants and 3 samples:; Variant FORMAT A B C; 1:1:A:T GT:GQ 0/1:99 ./. 0/0:99; 1:2:G:C GT:G",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:121181,log,logistic,121181,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logistic']
Testability,"ibrium). Both of these are easy in Hail. In [43]:. common_vds = (vds; .filter_variants_expr('va.qc.AF > 0.01'); .ld_prune(memory_per_core=256, num_cores=4)). 2018-10-18 01:26:50 Hail: INFO: Running LD prune with nSamples=843, nVariants=9085, nPartitions=4, and maxQueueSize=257123.; 2018-10-18 01:26:50 Hail: INFO: LD prune step 1 of 3: nVariantsKept=8478, nPartitions=4, time=351.375ms; 2018-10-18 01:26:51 Hail: INFO: LD prune step 2 of 3: nVariantsKept=8478, nPartitions=12, time=1.184s; 2018-10-18 01:26:52 Hail: INFO: Coerced sorted dataset; 2018-10-18 01:26:52 Hail: INFO: LD prune step 3 of 3: nVariantsKept=8478, time=481.478ms. In [44]:. common_vds.count(). Out[44]:. (843L, 8555L). These filters removed about 15% of sites (we started with a bit over; 10,000). This is NOT representative of most sequencing datasets! We; have already downsampled the full thousand genomes dataset to include; more common variants than we’d expect by chance.; In Hail, the association tests accept sample annotations for the sample; phenotype and covariates. Since we’ve already got our phenotype of; interest (caffeine consumption) in the dataset, we are good to go:. In [45]:. gwas = common_vds.linreg('sa.CaffeineConsumption'); pprint(gwas.variant_schema). 2018-10-18 01:26:52 Hail: INFO: Running linear regression on 843 samples with 1 covariate including intercept... Struct{; rsid: String,; qual: Double,; filters: Set[String],; pass: Boolean,; info: Struct{; AC: Array[Int],; AF: Array[Double],; AN: Int,; BaseQRankSum: Double,; ClippingRankSum: Double,; DP: Int,; DS: Boolean,; FS: Double,; HaplotypeScore: Double,; InbreedingCoeff: Double,; MLEAC: Array[Int],; MLEAF: Array[Double],; MQ: Double,; MQ0: Int,; MQRankSum: Double,; QD: Double,; ReadPosRankSum: Double,; set: String; },; qc: Struct{; callRate: Double,; AC: Int,; AF: Double,; nCalled: Int,; nNotCalled: Int,; nHomRef: Int,; nHet: Int,; nHomVar: Int,; dpMean: Double,; dpStDev: Double,; gqMean: Double,; gqStDev: Double,; nNonRef: Int,; r",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/hail-overview.html:21599,test,tests,21599,docs/0.1/tutorials/hail-overview.html,https://hail.is,https://hail.is/docs/0.1/tutorials/hail-overview.html,1,['test'],['tests']
Testability,"ic variants.; snps (int) - Number of SNP alternate alleles.; mnps (int) - Number of MNP alternate alleles.; insertions (int) - Number of insertion alternate alleles.; deletions (int) - Number of deletions alternate alleles.; complex (int) - Number of complex alternate alleles.; star (int) - Number of star (upstream deletion) alternate alleles.; max_alleles (int) - The highest number of alleles at any variant. Returns:Object containing summary information. Return type:Summary. tdt(pedigree, root='va.tdt')[source]¶; Find transmitted and untransmitted variants; count per variant and; nuclear family. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Compute TDT association results:; >>> pedigree = Pedigree.read('data/trios.fam'); >>> (vds.tdt(pedigree); ... .export_variants(""output/tdt_results.tsv"", ""Variant = v, va.tdt.*"")). Notes; The transmission disequilibrium test tracks the number of times the alternate allele is transmitted (t) or not transmitted (u) from a heterozgyous parent to an affected child under the null that the rate of such transmissions is 0.5. For variants where transmission is guaranteed (i.e., the Y chromosome, mitochondria, and paternal chromosome X variants outside of the PAR), the test cannot be used.; The TDT statistic is given by. \[(t-u)^2 \over (t+u)\]; and follows a 1 degree of freedom chi-squared distribution under the null hypothesis.; The number of transmissions and untransmissions for each possible set of genotypes is determined from the table below. The copy state of a locus with respect to a trio is defined as follows, where PAR is the pseudoautosomal region (PAR). HemiX – in non-PAR of X and child is male; Auto – otherwise (in autosome or PAR, or child is female). Kid; Dad; Mom; Copy State; T; U. HomRef; Het; Het; Auto; 0; 2. HomRef; HomRef; Het; Auto; 0; 1. HomRef; Het; HomRef; Auto; 0; 1. Het; Het; Het; Auto; 1; 1. Het; HomRef; Het; Auto; 1; 0. Het; Het; HomRef; Auto; 1; 0. Het; HomVar;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:167975,test,test,167975,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"icate keys will be faster to join; against. Version 0.2.85; Release 2022-02-14. Bug fixes. (#11355) Fixed; assertion errors being hit relating to RVDPartitioner.; (#11344) Fix error; where hail ggplot would mislabel points after more than 10 distinct; colors were used. New features. (#11332) Added; geom_ribbon and geom_area to hail ggplot. Version 0.2.84; Release 2022-02-10. Bug fixes. (#11328) Fix bug; where occasionally files written to disk would be unreadable.; (#11331) Fix bug; that potentially caused files written to disk to be unreadable.; (#11312) Fix; aggregator memory leak.; (#11340) Fix bug; where repeatedly annotating same field name could cause failure to; compile.; (#11342) Fix to; possible issues about having too many open file handles. New features. (#11300); geom_histogram infers min and max values automatically.; (#11317) Add support; for alpha aesthetic and identity position to; geom_histogram. Version 0.2.83; Release 2022-02-01. Bug fixes. (#11268) Fixed; log argument in hail.plot.histogram.; (#11276) Fixed; log argument in hail.plot.pdf.; (#11256) Fixed; memory leak in LD Prune. New features. (#11274) Added; geom_col to hail.ggplot. hailctl dataproc. (#11280) Updated; dataproc image version to one not affected by log4j vulnerabilities. Version 0.2.82; Release 2022-01-24. Bug fixes. (#11209); Significantly improved usefulness and speed of Table.to_pandas,; resolved several bugs with output. New features. (#11247) Introduces; a new experimental plotting interface hail.ggplot, based on R’s; ggplot library.; (#11173) Many math; functions like hail.sqrt now automatically broadcast over; ndarrays. Performance Improvements. (#11216); Significantly improve performance of parse_locus_interval. Python and Java Support. (#11219) We no; longer officially support Python 3.6, though it may continue to work; in the short term.; (#11220) We support; building hail with Java 11. File Format. The native file format version is now 1.6.0. Older versi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:54081,log,log,54081,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['log'],['log']
Testability,"icate(right_fields, max_attempts=100, already_used=left_fields). if renames:; renames = dict(renames); right = right.rename(renames); info(; 'Table.join: renamed the following fields on the right to avoid name conflicts:'; + ''.join(f'\n {k!r} -> {v!r}' for k, v in renames.items()); ). return Table(ir.TableJoin(self._tir, right._tir, how, _join_key)). [docs] @typecheck_method(expr=BooleanExpression); def all(self, expr):; """"""Evaluate whether a boolean expression is true for all rows. Examples; --------; Test whether `C1` is greater than 5 in all rows of the table:. >>> if table1.all(table1.C1 == 5):; ... print(""All rows have C1 equal 5.""). Parameters; ----------; expr : :class:`.BooleanExpression`; Expression to test. Returns; -------; :obj:`bool`; """"""; return self.aggregate(hl.agg.all(expr)). [docs] @typecheck_method(expr=BooleanExpression); def any(self, expr):; """"""Evaluate whether a Boolean expression is true for at least one row. Examples; --------. Test whether `C1` is equal to 5 any row in any row of the table:. >>> if table1.any(table1.C1 == 5):; ... print(""At least one row has C1 equal 5.""). Parameters; ----------; expr : :class:`.BooleanExpression`; Boolean expression. Returns; -------; :obj:`bool`; ``True`` if the predicate evaluated for ``True`` for any row, otherwise ``False``.; """"""; return self.aggregate(hl.agg.any(expr)). [docs] @typecheck_method(mapping=dictof(str, str)); def rename(self, mapping) -> 'Table':; """"""Rename fields of the table. Examples; --------; Rename `C1` to `col1` and `C2` to `col2`:. >>> table_result = table1.rename({'C1' : 'col1', 'C2' : 'col2'}). Parameters; ----------; mapping : :obj:`dict` of :class:`str`, :obj:`str`; Mapping from old field names to new field names. Notes; -----; Any field that does not appear as a key in `mapping` will not be; renamed. Returns; -------; :class:`.Table`; Table with renamed fields.; """"""; seen = {}. row_map = {}; global_map = {}. for k, v in mapping.items():; if v in seen:; raise ValueError(; ""Can",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:103850,Test,Test,103850,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,1,['Test'],['Test']
Testability,"icate, value, hl.missing(value.dtype)). [docs]@typecheck(; x=expr_int32, n=expr_int32, p=expr_float64, alternative=enumeration(""two.sided"", ""two-sided"", ""greater"", ""less""); ); def binom_test(x, n, p, alternative: str) -> Float64Expression:; """"""Performs a binomial test on `p` given `x` successes in `n` trials. Returns the p-value from the `exact binomial test; <https://en.wikipedia.org/wiki/Binomial_test>`__ of the null hypothesis that; success has probability `p`, given `x` successes in `n` trials. The alternatives are interpreted as follows:; - ``'less'``: a one-tailed test of the significance of `x` or fewer successes,; - ``'greater'``: a one-tailed test of the significance of `x` or more successes, and; - ``'two-sided'``: a two-tailed test of the significance of `x` or any equivalent or more unlikely outcome. Examples; --------. All the examples below use a fair coin as the null hypothesis. Zero is; interpreted as tail and one as heads. Test if a coin is biased towards heads or tails after observing two heads; out of ten flips:. >>> hl.eval(hl.binom_test(2, 10, 0.5, 'two-sided')); 0.10937499999999994. Test if a coin is biased towards tails after observing four heads out of ten; flips:. >>> hl.eval(hl.binom_test(4, 10, 0.5, 'less')); 0.3769531250000001. Test if a coin is biased towards heads after observing thirty-two heads out; of fifty flips:. >>> hl.eval(hl.binom_test(32, 50, 0.5, 'greater')); 0.03245432353613613. Parameters; ----------; x : int or :class:`.Expression` of type :py:data:`.tint32`; Number of successes.; n : int or :class:`.Expression` of type :py:data:`.tint32`; Number of trials.; p : float or :class:`.Expression` of type :py:data:`.tfloat64`; Probability of success, between 0 and 1.; alternative; : One of, ""two-sided"", ""greater"", ""less"", (deprecated: ""two.sided""). Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; p-value.; """""". if alternative == 'two.sided':; warning(; '""two.sided"" is a deprecated and will be removed in a futu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:61437,Test,Test,61437,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,1,['Test'],['Test']
Testability,"ices, aggregations=LinkedList); def construct_expr(; x: ir.IR, type: HailType, indices: Indices = Indices(), aggregations: LinkedList = LinkedList(Aggregation); ):; if type is None:; return Expression(x, None, indices, aggregations); x.assign_type(type); if isinstance(type, tarray) and is_numeric(type.element_type):; return ArrayNumericExpression(x, type, indices, aggregations); elif isinstance(type, tarray):; etype = type.element_type; if isinstance(etype, (hl.tarray, hl.tset)):; while isinstance(etype, (hl.tarray, hl.tset)):; etype = etype.element_type; if isinstance(etype, hl.tstruct):; return ArrayStructExpression(x, type, indices, aggregations); else:; return typ_to_expr[type.__class__](x, type, indices, aggregations); elif isinstance(type, tset):; etype = type.element_type; if isinstance(etype, (hl.tarray, hl.tset)):; while isinstance(etype, (hl.tarray, hl.tset)):; etype = etype.element_type; if isinstance(etype, hl.tstruct):; return SetStructExpression(x, type, indices, aggregations); else:; return typ_to_expr[type.__class__](x, type, indices, aggregations); elif isinstance(type, tndarray) and is_numeric(type.element_type):; return NDArrayNumericExpression(x, type, indices, aggregations); elif type in scalars:; return scalars[type](x, type, indices, aggregations); elif type.__class__ in typ_to_expr:; return typ_to_expr[type.__class__](x, type, indices, aggregations); else:; raise NotImplementedError(type). @typecheck(name=str, type=HailType, indices=Indices); def construct_reference(name, type, indices):; assert isinstance(type, hl.tstruct); x = ir.SelectedTopLevelReference(name, type); return construct_expr(x, type, indices). @typecheck(name=str, type=HailType, indices=Indices, aggregations=LinkedList); def construct_variable(name, type, indices: Indices = Indices(), aggregations: LinkedList = LinkedList(Aggregation)):; return construct_expr(ir.Ref(name, type), type, indices, aggregations). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:118241,assert,assert,118241,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['assert'],['assert']
Testability,"ices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; GTEx_sQTL_Liver_all_snp_gene_associations. View page source. GTEx_sQTL_Liver_all_snp_gene_associations. Versions: v8; Reference genome builds: GRCh38; Type: hail.Table. Schema (v8, GRCh38); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; version: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'phenotype_id': struct {; intron: interval<locus<GRCh38>>,; cluster: str,; gene_id: str; }; 'tss_distance': int32; 'ma_samples': int32; 'ma_count': int32; 'maf': float64; 'pval_nominal': float64; 'slope': float64; 'slope_se': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Liver_all_snp_gene_associations.html:8807,Log,Log,8807,docs/0.2/datasets/schemas/GTEx_sQTL_Liver_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Liver_all_snp_gene_associations.html,1,['Log'],['Log']
Testability,"ices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; GTEx_sQTL_Ovary_all_snp_gene_associations. View page source. GTEx_sQTL_Ovary_all_snp_gene_associations. Versions: v8; Reference genome builds: GRCh38; Type: hail.Table. Schema (v8, GRCh38); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; version: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'phenotype_id': struct {; intron: interval<locus<GRCh38>>,; cluster: str,; gene_id: str; }; 'tss_distance': int32; 'ma_samples': int32; 'ma_count': int32; 'maf': float64; 'pval_nominal': float64; 'slope': float64; 'slope_se': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Ovary_all_snp_gene_associations.html:8807,Log,Log,8807,docs/0.2/datasets/schemas/GTEx_sQTL_Ovary_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Ovary_all_snp_gene_associations.html,1,['Log'],['Log']
Testability,"ict = dict(zip(y_field_names, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # Handle filtering columns with missing values:; mt = mt.filter_cols(hl.array(y + covariates).all(hl.is_defined)). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**y_dict, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). ht = mt._localize_entries('entries', 'samples'). # covmat rows are samples, columns are the different covariates; ht = ht.annotate_globals(; covmat=hl.nd.array(ht.samples.map(lambda s: [s[cov_name] for cov_name in cov_field_names])); ). # yvecs is a list of sample-length vectors, one for each dependent variable.; ht = ht.annotate_globals(yvecs=[hl.nd.array(ht.samples[y_name]) for y_name in y_field_names]). # Fit null models, which means doing a logreg fit with just the covariates for each phenotype.; def fit_null(yvec):; def error_if_not_converged(null_fit):; return (; hl.case(); .when(; ~null_fit.exploded,; (; hl.case(); .when(null_fit.converged, null_fit); .or_error(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:58949,log,logreg,58949,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logreg']
Testability,"iders the same set of columns (i.e., samples, points) for; every group, namely those columns for which all covariates are defined.; For each row, missing values of x are mean-imputed over these columns.; As in the example, the intercept covariate 1 must be included; explicitly if desired. Notes; This method provides a scalable implementation of the score-based; variance-component test originally described in; Rare-Variant Association Testing for Sequencing Data with the Sequence Kernel Association Test.; Row weights must be non-negative. Rows with missing weights are ignored. In; the R package skat—which assumes rows are variants—default weights; are given by evaluating the Beta(1, 25) density at the minor allele; frequency. To replicate these weights in Hail using alternate allele; frequencies stored in a row-indexed field AF, one can use the expression:; >>> hl.dbeta(hl.min(ds2.AF), 1.0, 25.0) ** 2. In the logistic case, the response y must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded; as 1 and 0, respectively.; The resulting Table provides the group’s key (id), thenumber of; rows in the group (size), the variance component score q_stat, the SKAT; p-value, and a fault flag. For the toy example above, the table has the; form:. id; size; q_stat; p_value; fault. geneA; 2; 4.136; 0.205; 0. geneB; 1; 5.659; 0.195; 0. geneC; 3; 4.122; 0.192; 0. Groups larger than max_size appear with missing q_stat, p_value, and; fault. The hard limit on the number of rows in a group is 46340.; Note that the variance component score q_stat agrees with Q in the R; package skat, but both differ from \(Q\) in the paper by the factor; \(\frac{1}{2\sigma^2}\) in the linear case and \(\frac{1}{2}\) in; the logistic case, where \(\sigma^2\) is the unbiased estimator of; residual variance for the linear null model. The R package also applies a; “small-sample adjustment” to the null distribution in the logistic case; when the sample size ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:79991,log,logistic,79991,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['log'],['logistic']
Testability,"ields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. ================ =================== ======= ===============================; Test Field Type Value; ================ =================== ======= ===============================; Wald, LRT, Firth `fit.n_iterations` int32 number of iterations until; convergence, explosion, or; reaching the max (by default,; 25 for Wald, LRT; 100 for Firth); Wald, LRT, Firth `fit.converged` bool ``True`` if iteration converged; Wald, LRT, Firth `fit.exploded` bool ``True`` if iteration exploded; ================ =================== ======= ===============================. We consider iteration to have converged when every coordinate of; :math:`\beta` changes by less than :math:`10^{-6}` by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence p",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:31417,test,testing,31417,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['testing']
Testability,"if the argument is defined but not NaN. Returns missing if the argument is missing. json(x: T): String – Returns the JSON representation of a data type. Locus(contig: String, pos: Int): Locus. Construct a Locus object.; let l = Locus(""1"", 10040532) in l.position; result: 10040532. Arguments. contig (String) – String representation of contig.; pos (Int) – SNP position or start of an indel. Locus(s: String): Locus. Construct a Locus object.; let l = Locus(""1:10040532"") in l.position; result: 10040532. Arguments. s (String) – String of the form CHR:POS. log(x: Double, b: Double): Double. Returns the base b logarithm of the given value x.; Arguments. x (Double) – the number to take the base b logarithm of.; b (Double) – the base. log(x: Double): Double. Returns the natural logarithm of the given value x.; Arguments. x (Double) – the number to take the natural logarithm of. log10(x: Double): Double. Returns the base 10 logarithm of the given value x.; Arguments. x (Double) – the number to take the base 10 logarithm of. merge(s1: Struct, s2: Struct): Struct. Create a new Struct with all fields in s1 and s2.; let s1 = {gene: ""ACBD"", function: ""LOF""} and s2 = {a: 20, b: ""hello""} in merge(s1, s2); result: {gene: ""ACBD"", function: ""LOF"", a: 20, b: ""hello""}. orElse(a: T, b: T): T. If a is not missing, returns a. Otherwise, returns b.; Examples; Replace missing phenotype values with the mean value:; >>> [mean_height] = vds.query_samples(['samples.map(s => sa.pheno.height).stats()'])['mean']; >>> vds.annotate_samples_expr('sa.pheno.heightImputed = orElse(sa.pheno.height, %d)' % mean_height). orMissing(a: Boolean, b: T): T – If predicate evaluates to true, returns value. Otherwise, returns NA. pchisqtail(x: Double, df: Double): Double. Returns right-tail probability p for which p = Prob(\(Z^2\) > x) with \(Z^2\) a chi-squared random variable with degrees of freedom specified by df. x must be positive.; Arguments. x (Double) – Number at which to compute the probability.; df (Doubl",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:12360,log,logarithm,12360,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,1,['log'],['logarithm']
Testability,"if the call is phased.; Examples; >>> hl.eval(call.phased); False. Returns:; BooleanExpression. property ploidy; Return the number of alleles of this call.; Examples; >>> hl.eval(call.ploidy); 2. Notes; Currently only ploidy 1 and 2 are supported. Returns:; Expression of type tint32. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. unphase()[source]; Returns an unphased version of this call. Returns:; CallExpression. unphased_diploid_gt_index()[source]; Return the genotype index for unphased, diploid calls.; Examples; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.CallExpression.html:10641,log,logging,10641,docs/0.2/hail.expr.CallExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.CallExpression.html,1,['log'],['logging']
Testability,"ight_expr=expr_float64,; ld_score_expr=expr_numeric,; chi_sq_exprs=oneof(expr_float64, sequenceof(expr_float64)),; n_samples_exprs=oneof(expr_numeric, sequenceof(expr_numeric)),; n_blocks=int,; two_step_threshold=int,; n_reference_panel_variants=nullable(int),; ); def ld_score_regression(; weight_expr,; ld_score_expr,; chi_sq_exprs,; n_samples_exprs,; n_blocks=200,; two_step_threshold=30,; n_reference_panel_variants=None,; ) -> Table:; r""""""Estimate SNP-heritability and level of confounding biases from genome-wide association study; (GWAS) summary statistics. Given a set or multiple sets of GWAS summary statistics, :func:`.ld_score_regression` estimates the heritability; of a trait or set of traits and the level of confounding biases present in; the underlying studies by regressing chi-squared statistics on LD scores,; leveraging the model:. .. math::. \mathrm{E}[\chi_j^2] = 1 + Na + \frac{Nh_g^2}{M}l_j. * :math:`\mathrm{E}[\chi_j^2]` is the expected chi-squared statistic; for variant :math:`j` resulting from a test of association between; variant :math:`j` and a trait.; * :math:`l_j = \sum_{k} r_{jk}^2` is the LD score of variant; :math:`j`, calculated as the sum of squared correlation coefficients; between variant :math:`j` and nearby variants. See :func:`ld_score`; for further details.; * :math:`a` captures the contribution of confounding biases, such as; cryptic relatedness and uncontrolled population structure, to the; association test statistic.; * :math:`h_g^2` is the SNP-heritability, or the proportion of variation; in the trait explained by the effects of variants included in the; regression model above.; * :math:`M` is the number of variants used to estimate :math:`h_g^2`.; * :math:`N` is the number of samples in the underlying association study. For more details on the method implemented in this function, see:. * `LD Score regression distinguishes confounding from polygenicity in genome-wide association studies (Bulik-Sullivan et al, 2015) <https://www.ncbi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:1826,test,test,1826,docs/0.2/_modules/hail/experimental/ld_score_regression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html,2,['test'],['test']
Testability,"il.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representation of 7 is 111, so:; >>> hl.eval(hl.bit_count(7)); 3. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression. hail.expr.functions.exp(x)[source]. hail.expr.functions.expit(x)[source]. hail.expr.functions.is_nan(x)[source]. hail.expr.functions.is_finite(x)[source]. hail.expr.functions.is_infinite(x)[source]. hail.expr.functions.log(x, base=None)[source]; Take the logarithm of the x with base base.; Examples; >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; If the base argument is not supplied, then the natural logarithm is used. Parameters:. x (float or Expression of type tfloat64); base (float or Expression of type tfloat64). Returns:; Expression of type tfloat64. hail.expr.functions.log10(x)[source]. hail.expr.functions.logit(x)[source]. hail.expr.functions.floor(x)[source]. hail.expr.functions.ceil(x)[source]. hail.expr.functions.sqrt(x)[source]. hail.expr.functions.sign(x)[source]; Returns the sign of a numeric value, array or ndarray.; Examples; >>> hl.eval(hl.sign(-1.23)); -1.0. >>> hl.eval(hl.sign([-4, 0, 5])); [-1, 0, 1]. >>> hl.eval(hl.sign([0.0, 3.14])); [0.0, 1.0]. >>> hl.eval(hl.sign(float('nan'))); nan. Notes; The sign function preserves type and maps nan to nan. Parameters:; x (NumericExpression, ArrayNumericExpression or NDArrayNumericExpression). Returns:; NumericExpression, ArrayNumericExpression or NDArrayNumericExpression. hail.expr.functions.min(*exprs, filter_missing=True)[source]; Returns the minimum element of a collection or of given numeric expressions.; Examples; Take the minimum value of an array:; >>> hl.eval(hl.min([1, 3, 5, 6, 7, 9])); 1. Take the minimum value of arguments:; >>> hl.eval(hl.min(1, 50, 2)); 1. Notes; Like the Python builtin min function, this function can eithe",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:7800,log,logit,7800,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['logit']
Testability,"ile with case-control phenotype, case is 1 and control is 0.; Hail’s logistic regression tests correspond to the b.wald, b.lrt, and b.score tests in EPACTS. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes. Parameters:; test (str) – Statistical test, one of: ‘wald’, ‘lrt’, ‘score’, or ‘firth’.; y (str) – Response expression. Must evaluate to Boolean or; numeric with all values 0 or 1.; covariates (list of str) – list of covariate expressions; root (str) – Variant annotation path to store result of logistic regression.; use_dosages (bool) – If true, use genotype dosage rather than hard call. Returns:Variant dataset with logistic regression variant annotations. Return type:VariantDataset. logreg_burden(key_name, variant_keys, single_key, agg_expr, test, y, covariates=[])[source]¶; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Run a gene burden test using the logistic Wald test on the maximum genotype per gene. Here va.genes is; a variant annotation of type Set[String] giving the set of genes containing the variant; (see Extended example in linreg_burden() for a deeper dive in the context of linear regression):; >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.genes',; ... single_key=False,; ... agg_expr='gs.map(g => g.gt).max()',; ... test='wald',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). Run a gene burden test using the logistic score test on the weighted sum of genotypes per gene.; Here va.gene is a variant annotation of type String giving a single gene per variant (or no gene if; missi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:117210,test,test,117210,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"ilure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no compactions ergo no error; return 0; elif all_quantiles:; p = compute_grid_size(s); return 1 / p + compute_single_error(s, failure_prob / p); else:; return compute_single_error(s, failure_prob). [docs]@typecheck(t=hail_type); def missing(t: Union[HailType, str]):; """"""Creates an expression representing a missing value of a specified type. Examples; --------. >>> hl.eval(hl.missing(hl.tarray(hl.tstr))); None. >>> hl.eval(hl.missing('array<str>')); None. Notes; -----; This method is useful for constructing an expression that includes missing; values, since :obj:`None` cannot be interpreted as an expression. Parameters; ----------; t : :class:`str` or :class:`.HailType`; Type of the missing expression. Returns; -------; :class:`.Expression`; A missing expression of type `t`.; """"""; return construct_expr(ir.NA(t), t). [docs]@deprecated(version=""0.2.62"", reason=""Replaced by hl.missing""); @typecheck(t=hail_type); def null(t: Union[HailType, str]):; """"""Deprecate",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:7506,log,log,7506,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['log']
Testability,"imate (tfloat64) – A point estimate of the; SNP-heritability \(h_g^2\).; standard_error (tfloat64) – An estimate of; the standard error of this point estimate. Warning; ld_score_regression() considers only the rows for which both row; fields weight_expr and ld_score_expr are defined. Rows with missing; values in either field are removed prior to fitting the LD score; regression model. Parameters:. weight_expr (Float64Expression) – Row-indexed expression for the LD scores used to derive; variant weights in the model.; ld_score_expr (Float64Expression) – Row-indexed expression for the LD scores used as covariates; in the model.; chi_sq_exprs (Float64Expression or list of) – Float64Expression; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions for chi-squared; statistics resulting from genome-wide association; studies (GWAS).; n_samples_exprs (NumericExpression or list of) – NumericExpression; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions indicating the number of; samples used in the studies that generated the test; statistics supplied to chi_sq_exprs.; n_blocks (int) – The number of blocks used in the jackknife approach to; estimating standard errors.; two_step_threshold (int) – Variants with chi-squared statistics greater than this; value are excluded in the first step of the two-step; procedure used to fit the model.; n_reference_panel_variants (int, optional) – Number of variants used to estimate the; SNP-heritability \(h_g^2\). Returns:; Table – Table keyed by phenotype with intercept and heritability estimates; for each phenotype passed to the function. hail.experimental.write_expression(expr, path, overwrite=False)[source]; Write an Expression.; In the same vein as Python’s pickle, write out an expression; that does not have a source (such as one that comes from; Table.aggregate with _localize=False).; Example; >>> ht = hl.utils.range_table(100).annotate(x=hl.rand_norm()); >>> mean_norm = ht.a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/experimental/index.html:14452,test,test,14452,docs/0.2/experimental/index.html,https://hail.is,https://hail.is/docs/0.2/experimental/index.html,1,['test'],['test']
Testability,"imation by the Jeffrey’s invariant prior. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton method is linear rather than quadratic. For Firth, 100 iterations are attempted for the null model and, if that is successful, for the full model as well. In testing we find 20 iterations nearly always suffices. If the null model fails to converge, then the sa.lmmreg.fit annotations reflect the null model; otherwise, they reflect the full model.; See Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants for an empirical comparison of the logistic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert’s notes Statistical Theory. Firth introduced his approach in Bias reduction of maximum likelihood estimates, 1993. Heinze and Schemper further analyze Firth’s approach in A solution to the problem of separation in logistic regression, 2002.; Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; Phenotype and covariate sample annotations may also be specified using programmatic expressions without identifiers, such as:; if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation sa.fam.isCase added by importing a FAM file with case-control phenotype, case is 1 and control is 0.; Hail’s logistic regression tests correspond to the b.wald, b.lrt, and b.score tests in EPACTS. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes. Parameters:; test (str) – Statistical test, one of: ‘wald’, ‘lrt’, ‘score’, or ‘fir",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:115781,log,logistic,115781,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logistic']
Testability,"imer’s disease. Transl; 	 Psychiatry 12, 523; 	 (2022). https://doi.org/10.1038/s41398-022-02281-6 https://www.nature.com/articles/s41398-022-02281-6. Wadon, M.E., Fenner, E., Kendall, K.M. et al. Clinical and genotypic analysis in; 	 determining dystonia non-motor phenotypic heterogeneity: a UK Biobank study. J Neurol; 	 269, 6436–6451 (2022). https://doi.org/10.1007/s00415-022-11307-4 https://link.springer.com/article/10.1007/s00415-022-11307-4. 	 Andi Madihah Manggabarani, Takuyu Hashiguchi, Masatsugu Hashiguchi, Atsushi Hayashi,; 	 Masataka Kikuchi, Yusdar Mustamin, Masaru Bamba, Kunihiro Kodama, Takanari Tanabata,; 	 Sachiko Isobe, Hidenori Tanaka, Ryo Akashi, Akihiro Nakaya, Shusei Sato, Construction of; 	 prediction models for growth traits of soybean cultivars based on phenotyping in diverse; 	 genotype and environment combinations, DNA Research, Volume 29, Issue 4, August 2022,; 	 dsac024, https://doi.org/10.1093/dnares/dsac024 https://academic.oup.com/dnaresearch/article/29/4/dsac024/6653298?login=false. 	 Chaffin, M., Papangeli, I., Simonson, B. et al. Single-nucleus profiling of human; 	 dilated and hypertrophic cardiomyopathy. Nature 608, 174–180; 	 (2022). https://doi.org/10.1038/s41586-022-04817-8 https://www.nature.com/articles/s41586-022-04817-8. 	 Lee, J., Lee, J., Jeon, S. et al. A database of 5305 healthy Korean individuals reveals; 	 genetic and clinical implications for an East Asian population. Exp Mol Med 54,; 	 1862–1871; 	 (2022). https://doi.org/10.1038/s12276-022-00871-4 https://www.nature.com/articles/s12276-022-00871-4. 	 Akingbuwa, W.A., Hammerschlag, A.R., Bartels, M. et al. Ultra-rare and common genetic; 	 variant analysis converge to implicate negative selection and neuronal processes in the; 	 aetiology of schizophrenia. Mol Psychiatry 27, 3699–3707; 	 (2022). https://doi.org/10.1038/s41380-022-01621-8 https://www.nature.com/articles/s41380-022-01621-8. 	 Mitja, K.I., et al. FinnGen: Unique genetic insights from combining isolated p",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/references.html:7820,log,login,7820,references.html,https://hail.is,https://hail.is/references.html,1,['log'],['login']
Testability,"import *; from pyspark import SparkContext; from pyspark.sql import SQLContext. from hail.dataset import VariantDataset; from hail.expr import Type; from hail.java import *; from hail.keytable import KeyTable; from hail.stats import UniformDist, TruncatedBetaDist, BetaDist; from hail.utils import wrap_to_list. [docs]class HailContext(object):; """"""The main entry point for Hail functionality. .. warning::; Only one Hail context may be running in a Python session at any time. If you; need to reconfigure settings, restart the Python session or use the :py:meth:`.HailContext.stop` method.; ; If passing in a Spark context, ensure that the configuration parameters ``spark.sql.files.openCostInBytes``; and ``spark.sql.files.maxPartitionBytes`` are set to as least 50GB. :param sc: Spark context, one will be created if None.; :type sc: :class:`.pyspark.SparkContext`. :param appName: Spark application identifier. :param master: Spark cluster master. :param local: Local resources to use. :param log: Log path. :param bool quiet: Don't write logging information to standard error. :param append: Write to end of log file instead of overwriting. :param parquet_compression: Level of on-disk annotation compression. :param min_block_size: Minimum file split size in MB. :param branching_factor: Branching factor for tree aggregation. :param tmp_dir: Temporary directory for file merging. :ivar sc: Spark context; :vartype sc: :class:`.pyspark.SparkContext`; """""". @typecheck_method(sc=nullable(SparkContext),; app_name=strlike,; master=nullable(strlike),; local=strlike,; log=strlike,; quiet=bool,; append=bool,; parquet_compression=strlike,; min_block_size=integral,; branching_factor=integral,; tmp_dir=strlike); def __init__(self, sc=None, app_name=""Hail"", master=None, local='local[*]',; log='hail.log', quiet=False, append=False, parquet_compression='snappy',; min_block_size=1, branching_factor=50, tmp_dir='/tmp'):. if Env._hc:; raise FatalError('Hail Context has already been created, restart s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/context.html:1408,log,log,1408,docs/0.1/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/context.html,1,['log'],['log']
Testability,"in their corresponding arrays. Note; The order of the columns is not guaranteed. Returns:; MatrixTable. cols()[source]; Returns a table with all column fields in the matrix.; Examples; Extract the column table:; >>> cols_table = dataset.cols(). Warning; Matrix table columns are typically sorted by the order at import, and; not necessarily by column key. Since tables are always sorted by key,; the table which results from this command will have its rows sorted by; the column key (which becomes the table key). To preserve the original; column order as the table row order, first unkey the columns using; key_cols_by() with no arguments. Returns:; Table – Table with all column fields from the matrix, with one row per column of the matrix. compute_entry_filter_stats(row_field='entry_stats_row', col_field='entry_stats_col')[source]; Compute statistics about the number and fraction of filtered entries. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. Parameters:. row_field (str) – Name for computed row field (default: entry_stats_row.; col_field (str) – Name for computed column field (default: entry_stats_col. Returns:; MatrixTable. Notes; Adds a new row field, row_field, and a new column field, col_field,; each of which are structs with the following fields:. n_filtered (tint64) - Number of filtered entries per row; or column.; n_remaining (tint64) - Number of entries not filtered per; row or column.; fraction_filtered (tfloat32) - Number of filtered entries; divided by the total number of filtered and remaining entries. See also; filter_entries(), unfilter_entries(). count()[source]; Count the number of rows and columns in the matrix.; Examples; >>> dataset.count(). Returns:; int, int – Number of rows, number of cols. count_cols(_localize=True)[source]; Count the number of columns in the matrix.; Examples; Count the number of columns:; >>> n_cols = dataset.count_cols(). Returns:; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.MatrixTable.html:23600,test,tested,23600,docs/0.2/hail.MatrixTable.html,https://hail.is,https://hail.is/docs/0.2/hail.MatrixTable.html,1,['test'],['tested']
Testability,"indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a BooleanExpression will be implicitly converted to; a Float64Expression with this property.; x (Float64Expression) – Entry-indexed expression for input variable.; covariates (list of Float64Expression) – Non-empty list of column-indexed covariate expressions.; pass_through (list of str or Expression) – Additional row fields to include in the resulting table.; max_iterations (int) – The maximum number of iterations.; tolerance (float, optional) – The iterative fit of this model is considered “converged” if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns:; Table. hail.methods.poisson_regression_rows(test, y, x, covariates, pass_through=(), *, max_iterations=25, tolerance=None)[source]; For each row, test an input variable for association with a; count response variable using Poisson regression.; Notes; See logistic_regression_rows() for more info on statistical tests; of general linear models. Note; Use the pass_through parameter to include additional row fields from; matrix table underlying x. For example, to include an “rsid” field, set; pass_through=['rsid'] or pass_through=[mt.rsid]. Parameters:. y (Float64Expression) – Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x (Float64Expression) – Entry-indexed expression for input variable.; covariates (list of Float64Expression) – Non-empty list of column-indexed covariate expressions.; pass_through (list of str or Expression) – Additional row fields to include in the resulting table.; tolerance (float, optional) – The iterative fit of this model is considered “converged” if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns:; Table. hail.methods.pca(entry_expr, k=10, compute_loadings=False)[source]; Run principal component analysis (PCA) on numeric columns derived from ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:15714,test,tests,15714,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['tests']
Testability,"ined in path (does not; search recursively).; Each dict element of the result list contains the following data:. is_dir (bool) – Path is a directory.; size_bytes (int) – Size in bytes.; size (str) – Size as a readable string.; modification_time (str) – Time of last file modification.; owner (str) – Owner.; path (str) – Path. Parameters:; path (str). Returns:; list [dict]. hail.utils.hadoop_scheme_supported(scheme)[source]; Returns True if the Hadoop filesystem supports URLs with the given; scheme.; Examples; >>> hadoop_scheme_supported('gs') . Notes; URLs with the https scheme are only supported if they are specifically; Azure Blob Storage URLs of the form https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>. Parameters:; scheme (str). Returns:; bool. hail.utils.copy_log(path)[source]; Attempt to copy the session log to a hadoop-API-compatible location.; Examples; Specify a manual path:; >>> hl.copy_log('gs://my-bucket/analysis-10-jan19.log') ; INFO: copying log to 'gs://my-bucket/analysis-10-jan19.log'... Copy to a directory:; >>> hl.copy_log('gs://my-bucket/') ; INFO: copying log to 'gs://my-bucket/hail-20180924-2018-devel-46e5fad57524.log'... Notes; Since Hail cannot currently log directly to distributed file systems, this; function is provided as a utility for offloading logs from ephemeral nodes.; If path is a directory, then the log file will be copied using its; base name to the directory (e.g. /home/hail.log would be copied as; gs://my-bucket/hail.log if path is gs://my-bucket. Parameters:; path (str). hail.utils.range_table(n, n_partitions=None)[source]; Construct a table with the row index and no other fields.; Examples; >>> df = hl.utils.range_table(100). >>> df.count(); 100. Notes; The resulting table contains one field:. idx (tint32) - Row index (key). This method is meant for testing and learning, and is not optimized for; production performance. Parameters:. n (int) – Number of rows.; n_partitions (int, optional) – Number of partitio",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/utils/index.html:9129,log,log,9129,docs/0.2/utils/index.html,https://hail.is,https://hail.is/docs/0.2/utils/index.html,2,['log'],['log']
Testability,"ing a specified format string and arguments. json(x); Convert an expression to a JSON string expression. parse_json(x, dtype); Convert a JSON string to a structured expression. hamming(s1, s2); Returns the Hamming distance between the two strings. delimit(collection[, delimiter]); Joins elements of collection into single string delimited by delimiter. entropy(s); Returns the Shannon entropy of the character distribution defined by the string. parse_int(x); Parse a string as a 32-bit integer. parse_int32(x); Parse a string as a 32-bit integer. parse_int64(x); Parse a string as a 64-bit integer. parse_float(x); Parse a string as a 64-bit floating point number. parse_float32(x); Parse a string as a 32-bit floating point number. parse_float64(x); Parse a string as a 64-bit floating point number. Statistical functions. chi_squared_test(c1, c2, c3, c4); Performs chi-squared test of independence on a 2x2 contingency table. fisher_exact_test(c1, c2, c3, c4); Calculates the p-value, odds ratio, and 95% confidence interval using Fisher's exact test for a 2x2 table. contingency_table_test(c1, c2, c3, c4, ...); Performs chi-squared or Fisher's exact test of independence on a 2x2 contingency table. cochran_mantel_haenszel_test(a, b, c, d); Perform the Cochran-Mantel-Haenszel test for association. dbeta(x, a, b); Returns the probability density at x of a beta distribution with parameters a (alpha) and b (beta). dpois(x, lamb[, log_p]); Compute the (log) probability density at x of a Poisson distribution with rate parameter lamb. hardy_weinberg_test(n_hom_ref, n_het, n_hom_var); Performs test of Hardy-Weinberg equilibrium. pchisqtail(x, df[, ncp, lower_tail, log_p]); Returns the probability under the right-tail starting at x for a chi-squared distribution with df degrees of freedom. pnorm(x[, mu, sigma, lower_tail, log_p]); The cumulative probability function of a normal distribution with mean mu and standard deviation sigma. ppois(x, lamb[, lower_tail, log_p]); The cumulative pro",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/index.html:10094,test,test,10094,docs/0.2/functions/index.html,https://hail.is,https://hail.is/docs/0.2/functions/index.html,1,['test'],['test']
Testability,"ing eigenvectors with small eigenvalues. Returns:Variant dataset with linear mixed regression annotations. Return type:VariantDataset. logreg(test, y, covariates=[], root='va.logreg', use_dosages=False)[source]¶; Test each variant for association using logistic regression. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Run the logistic regression Wald test per variant using a Boolean phenotype and two covariates stored; in sample annotations:; >>> vds_result = vds.logreg('wald', 'sa.pheno.isCase', covariates=['sa.pheno.age', 'sa.pheno.isFemale']). Notes; The logreg() method performs,; for each variant, a significance test of the genotype in; predicting a binary (case-control) phenotype based on the; logistic regression model. The phenotype type must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded as 1 and 0, respectively.; Hail supports the Wald test (‘wald’), likelihood ratio test (‘lrt’), Rao score test (‘score’),; and Firth test (‘firth’). Hail only includes samples for which the phenotype and all covariates are; defined. For each variant, Hail imputes missing genotypes as the mean of called genotypes.; By default, genotypes values are given by hard call genotypes (g.gt).; If use_dosages=True, then genotype values are defined by the dosage; \(\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})\). For Phred-scaled values,; \(\mathrm{P}(\mathrm{Het})\) and \(\mathrm{P}(\mathrm{HomVar})\) are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1.; The example above considers a model of the form. \[\mathrm{Prob}(\mathrm{isCase}) = \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt} + \beta_2 \, \mathrm{age} + \beta_3 \, \mathrm{isFemale} + \varepsilon), \quad \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid; function, the; genotype \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for; He",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:109697,test,test,109697,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,4,['test'],['test']
Testability,"ing sure that ref and alt alleles are represented uniformely.; In addition to the resulting variant containing all alleles, this function also returns the mapping from the old to the new allele indices.; Note that this mapping counts the reference allele always contains the reference allele mapping 0 -> 0. let left = Variant(""1:1000:AT:A,CT"") and right = Variant(""1:1000:A:C,AGG"") in combineVariants(left,right); result: Struct{'variant': Variant(contig=1, start=1000, ref=AT, alts=[AltAllele(ref=AT, alt=A), AltAllele(ref=AT, alt=CT), AltAllele(ref=AT, alt=AGGT)]), 'laIndices': {0: 0, 1: 1, 2: 2}, 'raIndices': {0:0, 2: 1, 3: 2}}. Arguments. left (Variant) – Left variant to combine.; right (Variant) – Right variant to combine. ctt(c1: Int, c2: Int, c3: Int, c4: Int, minCellCount: Int): Struct{pValue:Double,oddsRatio:Double}. pValue (Double) – p-value; oddsRatio (Double) – odds ratio. Calculates p-value and odds ratio for 2x2 table. If any cell is lower than minCellCount Fishers exact test is used, otherwise faster chi-squared approximation is used.; Arguments. c1 (Int) – value for cell 1; c2 (Int) – value for cell 2; c3 (Int) – value for cell 3; c4 (Int) – value for cell 4; minCellCount (Int) – Minimum cell count for using chi-squared approximation. Dict(keys: Array[T], values: Array[U]): Dict[T, U]. Construct a Dict from an array of keys and an array of values.; Arguments. keys (Array[T]) – Keys of Dict.; values (Array[U]) – Values of Dict. dpois(x: Double, lambda: Double, logP: Boolean): Double. Returns Prob(\(X\) = x) from a Poisson distribution with rate parameter lambda.; Arguments. x (Double) – Non-negative number at which to compute the probability density.; lambda (Double) – Poisson rate parameter. Must be non-negative.; logP (Boolean) – If true, probabilities are returned as log(p). dpois(x: Double, lambda: Double): Double. Returns Prob(\(X\) = x) from a Poisson distribution with rate parameter lambda.; Arguments. x (Double) – Non-negative number at which to com",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:2934,test,test,2934,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,1,['test'],['test']
Testability,"ings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: List[DatasetVersion]):; assert set(key_properties).issubset(DB._valid_key_properties); self.name = name; self.description = description; self.url = url; self.key_properties = key_properties; self.versions = versions. @property; def is_gene_keyed(self) -> bool:; """"""If a :class:`Dataset` is gene keyed. Returns; -------; :obj:`bool`; Whether or not dataset is gene keyed.; """"""; return 'gene' in self.key_properties. def index_compatible_version(self, key_exp",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/db.html:6553,assert,assert,6553,docs/0.2/_modules/hail/experimental/db.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html,10,['assert'],['assert']
Testability,"initializing Hail Query with; backend='batch'.; (#14571) Fixed a; deficiency that caused certain pipelines that construct Hail; NDArrays from streams to run out of memory.; (#14579) Fix; serialization bug that broke some Query-on-Batch pipelines with many; complex expressions.; (#14567) Fix Jackson; configuration that broke some Query-on-Batch pipelines with many; complex expressions. Version 0.2.131; Released 2024-05-30. New Features. (#14560) The gvcf; import stage of the VDS combiner now preserves the GT of reference; blocks. Some datasets have haploid calls on sex chromosomes, and the; fact that the reference was haploid should be preserved. Bug Fixes. (#14563) The version; of notebook installed in Hail Dataproc clusters has been upgraded; from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter Notebooks; wouldn’t start on clusters. The workaround involving creating a; cluster with --packages='ipython<8.22' is no longer necessary. Deprecations. (#14158) Hail now; supports and primarily tests against Dataproc 2.2.5, Spark 3.5.0, and; Java 11. We strongly recommend updating to Spark 3.5.0 and Java 11.; You should also update your GCS connector after installing Hail:; curl https://broad.io/install-gcs-connector | python3. Do not try; to update before installing Hail 0.2.131. Version 0.2.130; Released 2024-10-02; 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with hailctl. Please upgrade to 0.2.130; if you use dataproc. New Features. (hail##14447) Added copy_spark_log_on_error initialization flag; that when set, copies the hail driver log to the remote tmpdir if; query execution raises an exception. Bug Fixes. (#14452) Fixes a bug; that prevents users from starting dataproc clusters with hailctl. Version 0.2.129; Released 2024-04-02. Documentation. (#14321) Removed; GOOGLE_APPLICATION_CREDENTIALS from batch docs. Metadata server; introduction means users no longer need to explicitly activate; service acc",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:12007,test,tests,12007,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['test'],['tests']
Testability,"int32)); return _func('approxCDFCombine', t, k, left, right). @typecheck(cdf=expr_struct(), failure_prob=expr_oneof(expr_float32, expr_float64), all_quantiles=bool); def _error_from_cdf(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :class:`.StructExpression`; Result of :func:`.approx_cdf` aggregator; failure_prob: :class:`.NumericExpression`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :class:`.NumericExpression`; Upper bound on error of quantile estimates.; """""". def compute_sum(cdf):; s = hl.sum(; hl.range(0, hl.len(cdf._compaction_counts)).map(lambda i: cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_pr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:5904,log,log,5904,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['log']
Testability,"ion field?; counter is modeled on the Python Counter object: it counts the number of times each distinct value occurs in the collection of values being aggregated. [6]:. users.aggregate(hl.agg.counter(users.occupation)). [6]:. {'administrator': 79,; 'artist': 28,; 'doctor': 7,; 'educator': 95,; 'engineer': 67,; 'entertainment': 18,; 'executive': 32,; 'healthcare': 16,; 'homemaker': 7,; 'lawyer': 12,; 'librarian': 51,; 'marketing': 26,; 'none': 9,; 'other': 105,; 'programmer': 66,; 'retired': 14,; 'salesman': 12,; 'scientist': 31,; 'student': 196,; 'technician': 27,; 'writer': 45}. filter; You can filter elements of a collection before aggregation by using filter. [7]:. users.aggregate(hl.agg.filter(users.sex == 'M', hl.agg.count())). [7]:. 670. The argument to filter should be a Boolean expression. [8]:. users.aggregate(hl.agg.count_where(users.sex == 'M')). [8]:. 670. Boolean expressions can be compound, but be sure to use parentheses appropriately. A single ‘&’ denotes logical AND and a single ‘|’ denotes logical OR. [9]:. users.aggregate(hl.agg.filter((users.occupation == 'writer') | (users.occupation == 'executive'), hl.agg.count())). [9]:. 77. [10]:. users.aggregate(hl.agg.filter((users.sex == 'F') | (users.occupation == 'executive'), hl.agg.count())). [10]:. 302. hist; As we saw in the first tutorial, hist can be used to build a histogram over numeric data. [11]:. hist = users.aggregate(hl.agg.hist(users.age, 10, 70, 60)); hist. [11]:. Struct(bin_edges=[10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0], bin_freq=[1, 1, 0, 5, 3, 6, 5, 14, 18, 23, 32, 27, 37, 28, 33, 38, 34, 35, 36, 32, 39, 25, 28, 26, 17, 27, 21, 19, 17, 22, 21, 10, 21, 13, 23, 15, ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/04-aggregation.html:4607,log,logical,4607,docs/0.2/tutorials/04-aggregation.html,https://hail.is,https://hail.is/docs/0.2/tutorials/04-aggregation.html,2,['log'],['logical']
Testability,"ion(); log_dir = os.environ.get('HAIL_LOG_DIR'); if log_dir is None:; log_dir = os.getcwd(); log = hail.utils.timestamp_path(os.path.join(log_dir, 'hail'), suffix=f'-{py_version}.log'); return log. def convert_gcs_requester_pays_configuration_to_hadoop_conf_style(; x: Optional[Union[str, Tuple[str, List[str]]]],; ) -> Tuple[Optional[str], Optional[str]]:; if isinstance(x, str):; return x, None; if isinstance(x, tuple):; return x[0], "","".join(x[1]); return None, None. class HailContext(object):; @staticmethod; def create(; log: str,; quiet: bool,; append: bool,; tmpdir: str,; local_tmpdir: str,; default_reference: str,; global_seed: Optional[int],; backend: Backend,; ):; hc = HailContext(; log=log,; quiet=quiet,; append=append,; tmpdir=tmpdir,; local_tmpdir=local_tmpdir,; global_seed=global_seed,; backend=backend,; ); hc.initialize_references(default_reference); return hc. @typecheck_method(; log=str, quiet=bool, append=bool, tmpdir=str, local_tmpdir=str, global_seed=nullable(int), backend=Backend; ); def __init__(self, log, quiet, append, tmpdir, local_tmpdir, global_seed, backend):; assert not Env._hc. self._log = log. self._tmpdir = tmpdir; self._local_tmpdir = local_tmpdir. self._backend = backend. self._warn_cols_order = True; self._warn_entries_order = True. self._default_ref: Optional[ReferenceGenome] = None. if not quiet:; py_version = version(); sys.stderr.write(; 'Welcome to\n'; ' __ __ <>__\n'; ' / /_/ /__ __/ /\n'; ' / __ / _ `/ / /\n'; ' /_/ /_/\\_,_/_/_/ version {}\n'.format(py_version); ). if py_version.startswith('devel'):; sys.stderr.write(; 'NOTE: This is a beta version. Interfaces may change\n'; ' during the beta period. We recommend pulling\n'; ' the latest changes weekly.\n'; ); sys.stderr.write(f'LOGGING: writing to {log}\n'). self._user_specified_rng_nonce = True; if global_seed is None:; if 'rng_nonce' not in backend.get_flags('rng_nonce'):; backend.set_flags(rng_nonce=hex(Random().randrange(-(2**63), 2**63 - 1))); self._user_specified_rng_non",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:2845,log,log,2845,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,6,"['assert', 'log']","['assert', 'log']"
Testability,"ion); y (Int32Expression or Int64Expression); logical (bool). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representation of 7 is 111, so:; >>> hl.eval(hl.bit_count(7)); 3. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression. hail.expr.functions.exp(x)[source]. hail.expr.functions.expit(x)[source]. hail.expr.functions.is_nan(x)[source]. hail.expr.functions.is_finite(x)[source]. hail.expr.functions.is_infinite(x)[source]. hail.expr.functions.log(x, base=None)[source]; Take the logarithm of the x with base base.; Examples; >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; If the base argument is not supplied, then the natural logarithm is used. Parameters:. x (float or Expression of type tfloat64); base (float or Expression of type tfloat64). Returns:; Expression of type tfloat64. hail.expr.functions.log10(x)[source]. hail.expr.functions.logit(x)[source]. hail.expr.functions.floor(x)[source]. hail.expr.functions.ceil(x)[source]. hail.expr.functions.sqrt(x)[source]. hail.expr.functions.sign(x)[source]; Returns the sign of a numeric value, array or ndarray.; Examples; >>> hl.eval(hl.sign(-1.23)); -1.0. >>> hl.eval(hl.sign([-4, 0, 5])); [-1, 0, 1]. >>> hl.eval(hl.sign([0.0, 3.14])); [0.0, 1.0]. >>> hl.eval(hl.sign(float('nan'))); nan. Notes; The sign function preserves type and maps nan to nan. Parameters:; x (NumericExpression, ArrayNumericExpression or NDArrayNumericExpression). Returns:; NumericExpression, ArrayNumericExpression or NDArrayNumericExp",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:7422,log,log,7422,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['log']
Testability,"ion; Hail on the Cloud; Tutorials; Reference (Python API); hail; Classes; Modules; expressions; types; functions; aggregators; scans; methods; nd; utils; linalg; stats; genetics; plot; ggplot; vds; experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; Methods; Statistics. View page source. Statistics. linear_mixed_model(y, x[, z_t, k, p_path, ...]); Initialize a linear mixed model from a matrix table. linear_mixed_regression_rows(entry_expr, model); For each row, test an input variable for association using a linear mixed model. linear_regression_rows(y, x, covariates[, ...]); For each row, test an input variable for association with response variables using linear regression. logistic_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a binary response variable using logistic regression. poisson_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a count response variable using Poisson regression. pca(entry_expr[, k, compute_loadings]); Run principal component analysis (PCA) on numeric columns derived from a matrix table. row_correlation(entry_expr[, block_size]); Computes the correlation matrix between row vectors. hail.methods.linear_mixed_model(y, x, z_t=None, k=None, p_path=None, overwrite=False, standardize=True, mean_impute=True)[source]; Initialize a linear mixed model from a matrix table. Warning; This functionality is no longer implemented/supported as of Hail 0.2.94. hail.methods.linear_mixed_regression_rows(entry_expr, model, pa_t_path=None, a_t_path=None, mean_impute=True, partition_size=None, pass_through=())[source]; For each row, test an input variable for association using a linear; mixed model. Warning; This functionality i",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:1102,test,test,1102,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,3,"['log', 'test']","['logistic', 'test']"
Testability,"ionExpression. – Collection where each element has been transformed according to f. remove(item)[source]; Returns a new set excluding item.; Examples; >>> hl.eval(s1.remove(1)); {2, 3}. Parameters:; item (Expression) – Value to remove. Returns:; SetExpression – Set with item removed. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. size(); Returns the size of a collection.; Examples; >>> hl.eval(a.size()); 5. >>> hl.eval(s3.size()); 3. Returns:; Expression of type tint32 – The number of elements in the collection. starmap(f); Transform each element of a collection of tuples.; Examples; >>> hl.eval(hl.array([(1, 2), (2, 3)]).starmap(lambda x, y: x+y)); [3, 5]. Parameters:; f (function ( (*args) -> Expression)) – Function to transform each element of the collection. Returns:; CollectionExpression. – Collection where each element has been transformed according to f. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.SetExpression.html:13267,log,logging,13267,docs/0.2/hail.expr.SetExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.SetExpression.html,1,['log'],['logging']
Testability,"ion_method(); data = agg_f(aggregators.approx_cdf(data, k)). if legend is None:; legend = """". if normalize:; y_axis_label = 'Quantile'; else:; y_axis_label = 'Rank'; if log:; y_axis_type = 'log'; else:; y_axis_type = 'linear'; p = figure(; title=title,; x_axis_label=legend,; y_axis_label=y_axis_label,; y_axis_type=y_axis_type,; width=600,; height=400,; background_fill_color='#EEEEEE',; tools='xpan,xwheel_zoom,reset,save',; active_scroll='xwheel_zoom',; ); p.add_tools(HoverTool(tooltips=[(""value"", ""$x""), (""rank"", ""@top"")], mode='vline')). ranks = np.array(data.ranks); values = np.array(data['values']); if normalize:; ranks = ranks / ranks[-1]. # invisible, there to support tooltips; p.quad(top=ranks[1:-1], bottom=ranks[1:-1], left=values[:-1], right=values[1:], fill_alpha=0, line_alpha=0); p.step(x=[*values, values[-1]], y=ranks, line_width=2, line_color='black', legend_label=legend); return p. [docs]def pdf(; data, k=1000, confidence=5, legend=None, title=None, log=False, interactive=False; ) -> Union[figure, Tuple[figure, Callable]]:; if isinstance(data, Expression):; if data._indices is None:; raise ValueError('Invalid input'); agg_f = data._aggregation_method(); data = agg_f(aggregators.approx_cdf(data, k)). if legend is None:; legend = """". y_axis_label = 'Frequency'; if log:; y_axis_type = 'log'; else:; y_axis_type = 'linear'; fig = figure(; title=title,; x_axis_label=legend,; y_axis_label=y_axis_label,; y_axis_type=y_axis_type,; width=600,; height=400,; tools='xpan,xwheel_zoom,reset,save',; active_scroll='xwheel_zoom',; background_fill_color='#EEEEEE',; ). y = np.array(data['ranks'][1:-1]) / data['ranks'][-1]; x = np.array(data['values'][1:-1]); min_x = data['values'][0]; max_x = data['values'][-1]; err = _error_from_cdf_python(data, 10 ** (-confidence), all_quantiles=True). new_y, keep = _max_entropy_cdf(min_x, max_x, x, y, err); slopes = np.diff([0, *new_y[keep], 1]) / np.diff([min_x, *x[keep], max_x]); if log:; plot = fig.step(x=[min_x, *x[keep], max_x], y=[",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:4195,log,log,4195,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['log'],['log']
Testability,"ion_rows and; poisson_regression_rows if NaNs appear. Version 0.2.6; Released 2018-12-17. New features. (#4962) Expanded; comparison operators (==, !=, <, <=, >, >=); to support expressions of every type.; (#4927) Expanded; functionality of Table.order_by to support ordering by arbitrary; expressions, instead of just top-level fields.; (#4926) Expanded; default GRCh38 contig recoding behavior in import_plink. Performance improvements. (#4952) Resolved; lingering issues related to; (#4909). Bug fixes. (#4941) Fixed; variable scoping error in regression methods.; (#4857) Fixed bug in; maximal_independent_set appearing when nodes were named something; other than i and j.; (#4932) Fixed; possible error in export_plink related to tolerance of writer; process failure.; (#4920) Fixed bad; error message in Table.order_by. Version 0.2.5; Released 2018-12-07. New features. (#4845) The; or_error; method in hl.case and hl.switch statements now takes a string; expression rather than a string literal, allowing more informative; messages for errors and assertions.; (#4865) We use this; new or_error functionality in methods that require biallelic; variants to include an offending variant in the error message.; (#4820) Added; hl.reversed; for reversing arrays and strings.; (#4895) Added; include_strand option to the; hl.liftover; function. Performance improvements. (#4907)(#4911); Addressed one aspect of bad scaling in enormous literal values; (triggered by a list of 300,000 sample IDs) related to logging.; (#4909)(#4914); Fixed a check in Table/MatrixTable initialization that scaled O(n^2); with the total number of fields. Bug fixes. (#4754)(#4799); Fixed optimizer assertion errors related to certain types of; pipelines using group_rows_by.; (#4888) Fixed; assertion error in BlockMatrix.sum.; (#4871) Fixed; possible error in locally sorting nested collections.; (#4889) Fixed break; in compatibility with extremely old MatrixTable/Table files.; (#4527)(#4761); Fixed optimizer ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:103425,assert,assertions,103425,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['assert'],['assertions']
Testability,"ionality is no longer implemented/supported as of Hail 0.2.94.; """"""; raise NotImplementedError(""linear_mixed_model is no longer implemented/supported as of Hail 0.2.94""). [docs]@typecheck(; entry_expr=expr_float64,; model=LinearMixedModel,; pa_t_path=nullable(str),; a_t_path=nullable(str),; mean_impute=bool,; partition_size=nullable(int),; pass_through=sequenceof(oneof(str, Expression)),; ); def linear_mixed_regression_rows(; entry_expr, model, pa_t_path=None, a_t_path=None, mean_impute=True, partition_size=None, pass_through=(); ):; """"""For each row, test an input variable for association using a linear; mixed model. .. warning::. This functionality is no longer implemented/supported as of Hail 0.2.94.; """"""; raise NotImplementedError(""linear_mixed_model is no longer implemented/supported as of Hail 0.2.94""). @typecheck(; group=expr_any,; weight=expr_float64,; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; max_size=int,; accuracy=numeric,; iterations=int,; ); def _linear_skat(; group, weight, y, x, covariates, max_size: int = 46340, accuracy: float = 1e-6, iterations: int = 10000; ):; r""""""The linear sequence kernel association test (SKAT). Linear SKAT tests if the phenotype, `y`, is significantly associated with the genotype, `x`. For; :math:`N` samples, in a group of :math:`M` variants, with :math:`K` covariates, the model is; given by:. .. math::. \begin{align*}; X &: R^{N \times K} \quad\quad \textrm{covariates} \\; G &: \{0, 1, 2\}^{N \times M} \textrm{genotypes} \\; \\; \varepsilon &\sim N(0, \sigma^2) \\; y &= \beta_0 X + \beta_1 G + \varepsilon; \end{align*}. The usual null hypothesis is :math:`\beta_1 = 0`. SKAT tests for an association, but does not; provide an effect size or other information about the association. Wu et al. argue that, under the null hypothesis, a particular value, :math:`Q`, is distributed; according to a generalized chi-squared distribution with parameters determined by the genotypes,; weights, and residual pheno",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:71659,test,test,71659,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"irth_null_fit=firth_improved_null_fit, fit=firth_fit)),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit)); ). return hl.bind(cont2, firth_fit). return hl.bind(cont, firth_improved_null_fit). @typecheck(; test=enumeration('wald', 'lrt', 'score', 'firth'),; y=oneof(expr_float64, sequenceof(expr_float64)),; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=nullable(int),; tolerance=nullable(float),; ); def _logistic_regression_rows_nd(; test, y, x, covariates, pass_through=(), *, max_iterations: Optional[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Warning; -------; :func:`.logistic_regression_rows` considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which **all** response variables and covariates are defined. For each row, missing values of; `x` are mean-imputed over these columns. As in the example, the; intercept covariate ``1`` must be included **explicitly** if desired. Notes; -----; This method performs, for each row, a significance ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:47507,test,test,47507,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the logreg.fit fields reflect the null model; otherwise,; they reflect the full model.; See; Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert’s notes; Statistical Theory.; Firth introduced his approach in; Bias reduction of maximum likelihood estimates, 1993.; Heinze and Schemper further analyze Firth’s approach in; A solution to the problem of separation in logistic regression, 2002.; Hail’s logistic regression tests correspond to the b.wald,; b.lrt, and b.score tests in EPACTS. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EPACTS results will currently only agree for variants with no; missing genotypes. Note; Use the pass_through parameter to include additional row fields from; matrix table underlying x. For example, to include an “rsid” field, set; pass_through=['rsid'] or pass_through=[mt.rsid]. Parameters:. test ({‘wald’, ‘lrt’, ‘score’, ‘firth’}) – Statistical test.; y (Float64Expression or list of Float64Expression) – One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a BooleanExpression will be implicitly converted to; a Float64Expression with this property.; x (Float64Expression) – Entry-indexed expression for input variable.; covariates (list of Float64Expression) – Non-empty list of column-indexed covariate expressions.; pass_through (list of str or Expre",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:14076,test,tests,14076,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['tests']
Testability,"is not None. base = self._row_fields if self._row_fields is not None else hl.struct(); for k, e in named_exprs.items():; analyze('GroupedMatrixTable.aggregate_rows', e, self._parent._global_indices, {self._parent._row_axis}). self._check_bindings('aggregate_rows', named_exprs, self._parent._row_indices); return self._copy(row_fields=base.annotate(**named_exprs)). [docs] @typecheck_method(named_exprs=expr_any); def aggregate_entries(self, **named_exprs) -> 'GroupedMatrixTable':; """"""Aggregate entries by group. Examples; --------; Aggregate to a matrix with genes as row keys, computing the number of; non-reference calls as an entry field:. >>> dataset_result = (dataset.group_rows_by(dataset.gene); ... .aggregate_entries(n_non_ref = hl.agg.count_where(dataset.GT.is_non_ref())); ... .result()). See Also; --------; :meth:`.aggregate`, :meth:`.result`. Parameters; ----------; named_exprs : varargs of :class:`.Expression`; Aggregation expressions. Returns; -------; :class:`.GroupedMatrixTable`; """"""; assert self._row_keys is not None or self._col_keys is not None. base = self._entry_fields if self._entry_fields is not None else hl.struct(); for k, e in named_exprs.items():; analyze(; 'GroupedMatrixTable.aggregate_entries',; e,; self._fixed_indices(),; {self._parent._row_axis, self._parent._col_axis},; ). self._check_bindings(; 'aggregate_entries',; named_exprs,; self._parent._col_indices if self._col_keys is not None else self._parent._row_indices,; ); return self._copy(entry_fields=base.annotate(**named_exprs)). [docs] def result(self) -> 'MatrixTable':; """"""Return the result of aggregating by group. Examples; --------; Aggregate to a matrix with genes as row keys, collecting the functional; consequences per gene as a row field and computing the number of; non-reference calls as an entry field:. >>> dataset_result = (dataset.group_rows_by(dataset.gene); ... .aggregate_rows(consequences = hl.agg.collect_as_set(dataset.consequence)); ... .aggregate_entries(n_non_ref = hl.agg.c",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:11782,assert,assert,11782,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,['assert'],['assert']
Testability,"is property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**y_dict, **dict(zip(cov_field_names, covariates))),; row_ex",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:37283,log,logistic,37283,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logistic']
Testability,"ise ExpressionException(; f""'literal' can only accept scalar or global expression arguments,""; f"" found indices {x._indices.axes}""; ); return False; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11595,assert,assert,11595,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,4,['assert'],['assert']
Testability,"isher01]), hl.nd.hstack([fisher10, fisher11])]). test_fit = _poisson_fit(X, yvec, b, mu, score, fisher, max_iterations, tolerance); if test == 'lrt':; return ht.select(test_fit=test_fit, **lrt_test(X, null_fit, test_fit), **ht.pass_through).select_globals(; 'null_fit'; ); assert test == 'wald'; return ht.select(test_fit=test_fit, **wald_test(X, test_fit), **ht.pass_through).select_globals('null_fit'). def _poisson_fit(; X: NDArrayNumericExpression, # (N, K); y: NDArrayNumericExpression, # (N,); b: NDArrayNumericExpression, # (K,); mu: NDArrayNumericExpression, # (N,); score: NDArrayNumericExpression, # (K,); fisher: NDArrayNumericExpression, # (K, K); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Poisson(exp(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1; assert mu.ndim == 1; assert score.ndim == 1; assert fisher.ndim == 2. dtype = numerical_regression_fit_dtype; blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}). def fit(recur, iteration, b, mu, score, fisher):; def cont(exploded, delta_b, max_delta_b):; log_lkhd = y @ hl.log(mu) - mu.sum(). next_b = b + delta_b; next_mu = hl.exp(X @ next_b); next_score = X.T @ (y - next_mu); next_fisher = (next_mu * X.T) @ X. return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(; b=b,; score=score,; fisher=fisher,; mu=mu,; n_iterations=iteration,; log_lkhd=log_lkhd,; converged=True,; exploded=False,; ),; ); .when(; iteration == max_iterations,; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b, next_mu, next_score, next_fisher)); ). delta_b_struct = hl.nd.solve(f",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:68192,assert,assert,68192,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['assert'],['assert']
Testability,"isplayed_n_cols != self.actual_n_cols:; s += f""showing the first { self.displayed_n_cols } of { self.actual_n_cols } columns""; return s. def __repr__(self):; return self.__str__(). def _repr_html_(self):; s = self.table_show._repr_html_(); if self.displayed_n_cols != self.actual_n_cols:; s += '<p style=""background: #fdd; padding: 0.4em;"">'; s += f""showing the first { self.displayed_n_cols } of { self.actual_n_cols } columns""; s += '</p>\n'; return s. [docs] @typecheck_method(; n_rows=nullable(int),; n_cols=nullable(int),; include_row_fields=bool,; width=nullable(int),; truncate=nullable(int),; types=bool,; handler=nullable(anyfunc),; ); def show(; self, n_rows=None, n_cols=None, include_row_fields=False, width=None, truncate=None, types=True, handler=None; ):; """"""Print the first few rows of the matrix table to the console. .. include:: _templates/experimental.rst. Notes; -----; The output can be passed piped to another output source using the `handler` argument:. >>> mt.show(handler=lambda x: logging.info(x)) # doctest: +SKIP. Parameters; ----------; n_rows : :obj:`int`; Maximum number of rows to show.; n_cols : :obj:`int`; Maximum number of columns to show.; width : :obj:`int`; Horizontal width at which to break fields.; truncate : :obj:`int`, optional; Truncate each field to the given number of characters. If; ``None``, truncate fields to the given `width`.; types : :obj:`bool`; Print an extra header line with the type of each field.; handler : Callable[[str], Any]; Handler function for data string.; """""". def estimate_size(struct_expression):; return sum(max(len(f), len(str(x.dtype))) + 3 for f, x in struct_expression.flatten().items()). if n_cols is None:; import shutil. (characters, _) = shutil.get_terminal_size((80, 10)); characters -= 6 # borders; key_characters = estimate_size(self.row_key); characters -= key_characters; if include_row_fields:; characters -= estimate_size(self.row_value); characters = max(characters, 0); n_cols = characters // (estimate_size(s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:84196,log,logging,84196,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,['log'],['logging']
Testability,"isq(-20, w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.5950150356303258; >>> hl.eval(hl.pgenchisq(10 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.923219534175858; >>> hl.eval(hl.pgenchisq(40 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.9971746768781656. Notes; -----. We follow Wikipedia's notational conventions. Some texts refer to the weight vector (our `w`) as; :math:`\lambda` or `lb` and the non-centrality vector (our `lam`) as `nc`. We use the Davies' algorithm which was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expressi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:68660,test,test,68660,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"ist(expected_axes),; axes=list(indices.axes),; stray=list(unexpected_axes),; fields=''.join(; ""\n '{}' (indices {})"".format(name, list(inds.axes)) for name, inds in bad_refs; ),; agg=''; if (unexpected_axes - aggregation_axes); else ""\n '{}' supports aggregation over axes {}, ""; ""so these fields may appear inside an aggregator function."".format(caller, list(aggregation_axes)),; ); ); ). if aggregations:; if aggregation_axes:; # the expected axes of aggregated expressions are the expected axes + axes aggregated over; expected_agg_axes = expected_axes.union(aggregation_axes). for agg in aggregations:; assert isinstance(agg, Aggregation); refs = get_refs(*agg.exprs); agg_axes = agg.agg_axes(). # check for stray indices; unexpected_agg_axes = agg_axes - expected_agg_axes; if unexpected_agg_axes:; # one or more out-of-scope fields; bad_refs = []; for name, inds in refs.items():; bad_axes = inds.axes.intersection(unexpected_agg_axes); if bad_axes:; bad_refs.append((name, inds)). assert len(bad_refs) > 0. errors.append(; ExpressionException(; ""scope violation: '{caller}' supports aggregation over indices {expected}""; ""\n Found indices {axes}, with unexpected indices {stray}. Invalid fields:{fields}"".format(; caller=caller,; expected=list(aggregation_axes),; axes=list(agg_axes),; stray=list(unexpected_agg_axes),; fields=''.join(; ""\n '{}' (indices {})"".format(name, list(inds.axes)); for name, inds in bad_refs; ),; ); ); ); else:; errors.append(ExpressionException(""'{}' does not support aggregation"".format(caller))). for w in warnings:; warning('{}'.format(w.msg)); if errors:; for e in errors:; error('{}'.format(e.msg)); raise errors[0]. @typecheck(expression=expr_any); def eval_timed(expression):; """"""Evaluate a Hail expression, returning the result and the times taken for; each stage in the evaluation process. Parameters; ----------; expression : :class:`.Expression`; Any expression, or a Python value that can be implicitly interpreted as an expression. Returns; -------; (A",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html:3748,assert,assert,3748,docs/0.2/_modules/hail/expr/expressions/expression_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html,2,['assert'],['assert']
Testability,"istic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert’s notes Statistical Theory. Firth introduced his approach in Bias reduction of maximum likelihood estimates, 1993. Heinze and Schemper further analyze Firth’s approach in A solution to the problem of separation in logistic regression, 2002.; Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; Phenotype and covariate sample annotations may also be specified using programmatic expressions without identifiers, such as:; if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation sa.fam.isCase added by importing a FAM file with case-control phenotype, case is 1 and control is 0.; Hail’s logistic regression tests correspond to the b.wald, b.lrt, and b.score tests in EPACTS. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes. Parameters:; test (str) – Statistical test, one of: ‘wald’, ‘lrt’, ‘score’, or ‘firth’.; y (str) – Response expression. Must evaluate to Boolean or; numeric with all values 0 or 1.; covariates (list of str) – list of covariate expressions; root (str) – Variant annotation path to store result of logistic regression.; use_dosages (bool) – If true, use genotype dosage rather than hard call. Returns:Variant dataset with logistic regression variant annotations. Return type:VariantDataset. logreg_burden(key_name, variant_keys, single_key, agg_expr, test, y, covariates=[])[source]¶; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. Important; The genotype_schema",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:116402,test,tests,116402,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['tests']
Testability,"istogram; Create a histogram. cumulative_histogram; Create a cumulative histogram. histogram2d; Plot a two-dimensional histogram. scatter; Create an interactive scatter plot. qq; Create a Quantile-Quantile plot. manhattan; Create a Manhattan plot. output_notebook; Configure the Bokeh output state to generate output in notebook cells when bokeh.io.show() is called. visualize_missingness; Visualize missingness in a MatrixTable. hail.plot.cdf(data, k=350, legend=None, title=None, normalize=True, log=False)[source]; Create a cumulative density plot. Parameters:. data (Struct or Float64Expression) – Sequence of data to plot.; k (int) – Accuracy parameter (passed to approx_cdf()).; legend (str) – Label of data on the x-axis.; title (str) – Title of the histogram.; normalize (bool) – Whether or not the cumulative data should be normalized.; log (bool) – Whether or not the y-axis should be of type log. Returns:; bokeh.plotting.figure. hail.plot.pdf(data, k=1000, confidence=5, legend=None, title=None, log=False, interactive=False)[source]. hail.plot.smoothed_pdf(data, k=350, smoothing=0.5, legend=None, title=None, log=False, interactive=False, figure=None)[source]; Create a density plot. Parameters:. data (Struct or Float64Expression) – Sequence of data to plot.; k (int) – Accuracy parameter.; smoothing (float) – Degree of smoothing.; legend (str) – Label of data on the x-axis.; title (str) – Title of the histogram.; log (bool) – Plot the log10 of the bin counts.; interactive (bool) – If True, return a handle to pass to bokeh.io.show().; figure (bokeh.plotting.figure) – If not None, add density plot to figure. Otherwise, create a new figure. Returns:; bokeh.plotting.figure. hail.plot.histogram(data, range=None, bins=50, legend=None, title=None, log=False, interactive=False)[source]; Create a histogram.; Notes; data can be a Float64Expression, or the result of the hist(); or approx_cdf() aggregators. Parameters:. data (Struct or Float64Expression) – Sequence of data to pl",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/plot.html:2321,log,log,2321,docs/0.2/plot.html,https://hail.is,https://hail.is/docs/0.2/plot.html,1,['log'],['log']
Testability,"istory and mathematics of linear mixed models in genetics, including `FastLMM <https://www.microsoft.com/en-us/research/project/fastlmm/>`__, see `Christoph Lippert's PhD thesis <https://publikationen.uni-tuebingen.de/xmlui/bitstream/handle/10900/50003/pdf/thesis_komplett.pdf>`__. For an investigation of various approaches to defining kinship, see `Comparison of Methods to Account for Relatedness in Genome-Wide Association Studies with Family-Based Data <http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1004445>`__. :param kinshipMatrix: Kinship matrix to be used.; :type kinshipMatrix: :class:`KinshipMatrix`. :param str y: Response sample annotation. :param covariates: List of covariate sample annotations.; :type covariates: list of str. :param str global_root: Global annotation root, a period-delimited path starting with `global`. :param str va_root: Variant annotation root, a period-delimited path starting with `va`. :param bool run_assoc: If true, run association testing in addition to fitting the global model. :param bool use_ml: Use ML instead of REML throughout. :param delta: Fixed delta value to use in the global model, overrides fitting delta.; :type delta: float or None. :param float sparsity_threshold: Genotype vector sparsity at or below which to use sparse genotype vector in rotation (advanced). :param bool use_dosages: If true, use dosages rather than hard call genotypes. :param int n_eigs: Number of eigenvectors of the kinship matrix used to fit the model. :param float dropped_variance_fraction: Upper bound on fraction of sample variance lost by dropping eigenvectors with small eigenvalues. :return: Variant dataset with linear mixed regression annotations.; :rtype: :py:class:`.VariantDataset`; """""". jvds = self._jvdf.lmmreg(kinshipMatrix._jkm, y, jarray(Env.jvm().java.lang.String, covariates),; use_ml, global_root, va_root, run_assoc, joption(delta), sparsity_threshold,; use_dosages, joption(n_eigs), joption(dropped_variance_fraction)",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:138089,test,testing,138089,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['testing']
Testability,"it.select('n_iterations', 'converged', 'exploded'),; ). def logistic_score_test(X, y, null_fit):; m = X.shape[1]; m0 = null_fit.b.shape[0]; b = hl.nd.hstack([null_fit.b, hl.nd.zeros((hl.int32(m - m0)))]). X0 = X[:, 0:m0]; X1 = X[:, m0:]. mu = hl.expit(X @ b). score_0 = null_fit.score; score_1 = X1.T @ (y - mu); score = hl.nd.hstack([score_0, score_1]). fisher00 = null_fit.fisher; fisher01 = X0.T @ (X1 * (mu * (1 - mu)).reshape(-1, 1)); fisher10 = fisher01.T; fisher11 = X1.T @ (X1 * (mu * (1 - mu)).reshape(-1, 1)). fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). solve_attempt = hl.nd.solve(fisher, score, no_crash=True). chi_sq = hl.or_missing(~solve_attempt.failed, (score * solve_attempt.solution).sum()). p = hl.pchisqtail(chi_sq, m - m0). return hl.struct(chi_sq_stat=chi_sq, p_value=p). def _firth_fit(; b: NDArrayNumericExpression, # (K,); X: NDArrayNumericExpression, # (N, K); y: NDArrayNumericExpression, # (N,); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares using Firth's regression to fit the model y ~ Bernoulli(logit(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1. dtype = numerical_regression_fit_dtype._drop_fields(['score', 'fisher']); blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}); X_bslice = X[:, : b.shape[0]]. def fit(recur, iteration, b):; def cont(exploded, delta_b, max_delta_b):; log_lkhd_left = hl.log(y * mu + (hl.literal(1.0) - y) * (1 - mu)).sum(); log_lkhd_right = hl.log(hl.abs(hl.nd.diagonal(r))).sum(); log_lkhd = log_lkhd_left + log_lkhd_right. next_b = b + delta_b. return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(b=b, mu=mu, n_iterati",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:43552,log,logit,43552,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logit']
Testability,"itting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; va.logreg.fit.converged; Boolean; true if iteration converged. Wald, LRT, Firth; va.logreg.fit.exploded; Boolean; true if iteration exploded. We consider iteration to have converged when every coordinate of \(\beta\) changes by less than \(10^{-6}\). For Wald and LRT, up to 25 iterations are attempted; in testing we find 4 or 5 iterations nearly always suffice. Convergence may also fail due to explosion, which refers to low-level numerical linear algebra exceptions caused by manipulating ill-conditioned matrices. Explosion may result from (nearly) linearly dependent covariates or complete separation.; A more common situation in genetics is quasi-complete seperation, e.g. variants that are observed only in cases (or controls). Such variants inevitably arise when testing millions of variants with very low minor allele count. The maximum likelihood estimate of \(\beta\) under logistic regression is then undefined but convergence may still occur after a large number of iterations due to a very flat likelihood surface. In testing, we find that such variants produce a secondary bump from 10 to 15 iterations in the histogram of number of iterations per variant. We also find that this faux convergence produces large standard errors and large (insignificant) p-values. To not miss such variants, consider using Firth logistic regression, linear regression, or group-based tests.; Here’s a concrete illustration of quasi-complete seperation in R. Suppose we have 2010 samples distributed as follows for a particular variant:. Status; HomRef; Het; HomVar. Case; 1000; 10; 0. Control; 1000; 0; 0. The following R code fits the (standard) logistic, Firth logistic, and linear regression models to this data, where x is genotype, y is phenotype, and logistf is from the logistf p",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:113053,test,testing,113053,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['testing']
Testability,"ive customization. Let’s start with an example. We are going to plot y = x^2 for x from 0 to 10. First we make a hail table representing that data:. [2]:. ht = hl.utils.range_table(10); ht = ht.annotate(squared = ht.idx**2). Every plot starts with a call to ggplot, and then requires adding a geom to specify what kind of plot you’d like to create. [3]:. fig = ggplot(ht, aes(x=ht.idx, y=ht.squared)) + geom_line(); fig.show(). Initializing Hail with default parameters...; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2013-0.2.133-4c60fddb171a.log; SLF4J: Failed to load class ""org.slf4j.impl.StaticMDCBinder"".; SLF4J: Defaulting to no-operation MDCAdapter implementation.; SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details. aes creates an “aesthetic mapping”, which maps hail expressions to aspects of the plot. There is a predefined list of aesthetics supported by every geom. Most take an x and y at least.; With this interface, it’s easy to change out our plotting representation separate from our data. We can plot bars:. [4]:. fig = ggplot(ht, aes(x=ht.idx, y=ht.squared)) + geom_col(); fig.show(). Or points:. [5]:. fig = ggplot(ht, aes(x=ht.idx, y=ht.squared)) + geom_point(); fig.show(). There are optional aesthetics too. If we want, we could color the points based on whether they’re even or odd:. [6]:. fig = ggplot(ht, aes(x=ht.idx, y=ht.squared, color=hl.if_else(ht.idx % 2 == 0, ""even"", ""odd""))) + geom_point(); fig.show(). Note that the color aesthetic by default just takes in an expression that evaluates to str",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/09-ggplot.html:2272,log,log,2272,docs/0.2/tutorials/09-ggplot.html,https://hail.is,https://hail.is/docs/0.2/tutorials/09-ggplot.html,1,['log'],['log']
Testability,"ix. impute_sex(call[, aaf_threshold, ...]); Impute sex of samples by calculating inbreeding coefficient on the X chromosome. ld_matrix(entry_expr, locus_expr, radius[, ...]); Computes the windowed correlation (linkage disequilibrium) matrix between variants. ld_prune(call_expr[, r2, bp_window_size, ...]); Returns a maximal subset of variants that are nearly uncorrelated within each window. compute_charr(ds[, min_af, max_af, min_dp, ...]); Compute CHARR, the DNA sample contamination estimator. mendel_errors(call, pedigree); Find Mendel errors; count per variant, individual and nuclear family. de_novo(mt, pedigree, pop_frequency_prior, *); Call putative de novo events from trio data. nirvana(dataset, config[, block_size, name]); Annotate variants using Nirvana. realized_relationship_matrix(call_expr); Computes the realized relationship matrix (RRM). sample_qc(mt[, name]); Compute per-sample metrics useful for quality control. skat(key_expr, weight_expr, y, x, covariates); Test each keyed group of rows for association by linear or logistic SKAT test. lambda_gc(p_value[, approximate]); Compute genomic inflation factor (lambda GC) from an Expression of p-values. split_multi(ds[, keep_star, left_aligned, ...]); Split multiallelic variants. split_multi_hts(ds[, keep_star, ...]); Split multiallelic variants for datasets that contain one or more fields from a standard high-throughput sequencing entry schema. transmission_disequilibrium_test(dataset, ...); Performs the transmission disequilibrium test on trios. trio_matrix(dataset, pedigree[, complete_trios]); Builds and returns a matrix where columns correspond to trios and entries contain genotypes for the trio. variant_qc(mt[, name]); Compute common variant statistics (quality control metrics). vep(dataset[, config, block_size, name, ...]); Annotate variants with VEP. Relatedness; Hail provides three methods for the inference of relatedness: PLINK-style; identity by descent [1], KING [2], and PC-Relate [3]. identity_by_des",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/index.html:5946,log,logistic,5946,docs/0.2/methods/index.html,https://hail.is,https://hail.is/docs/0.2/methods/index.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"j in range(0, p):; info(f""krylov_factorization: Beginning iteration {j+1}/{p}""); G_i = t.aggregate(hl.agg.ndarray_sum(A_expr.T @ (A_expr @ G_i)), _localize=False); G_i = hl.nd.qr(G_i)[0]._persist(); g_list.append(G_i). info(""krylov_factorization: Iterations complete. Computing local QR""); V0 = hl.nd.hstack(g_list). if compute_V:; V = hl.nd.qr(V0)[0]._persist(); t = t.annotate(AV=A_expr @ V); else:; V = hl.nd.qr(V0)[0]; t = t.annotate(AV=A_expr @ V); V = None. if compute_U:; temp_file_name = hl.utils.new_temp_file(""_krylov_factorization_intermediate"", ""ht""); t = t.checkpoint(temp_file_name); AV_local = t.aggregate(hl.nd.vstack(hl.agg.collect(t.AV)), _localize=False); U, R = hl.nd.qr(AV_local)._persist(); else:; Rs = t.aggregate(hl.nd.vstack(hl.agg.collect(hl.nd.qr(t.AV)[1])), _localize=False); R = hl.nd.qr(Rs)[1]._persist(); U = None. return KrylovFactorization(U, R, V, k). def _reduced_svd(A: TallSkinnyMatrix, k=10, compute_U=False, iterations=2, iteration_size=None):; # Set Parameters; q = iterations; if iteration_size is None:; L = k + 2; else:; L = iteration_size; assert (q + 1) * L >= k; n = A.ncols. # Generate random matrix G; G = hl.rand_norm(0, 1, size=(n, L)); G = hl.nd.qr(G)[0]._persist(). fact = _krylov_factorization(A, G, q, compute_U); info(""_reduced_svd: Computing local SVD""); return fact.reduced_svd(k). @typecheck(; A=oneof(expr_float64, TallSkinnyMatrix), num_moments=int, p=nullable(int), moment_samples=int, block_size=int; ); def _spectral_moments(A, num_moments, p=None, moment_samples=500, block_size=128):; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_spectral_moments/entry_expr', A); A = _make_tsm(A, block_size). n = A.ncols. if p is None:; p = min(num_moments // 2, 10). # TODO: When moment_samples > n, we should just do a TSQR on A, and compute; # the spectrum of R.; assert moment_samples < n, '_spectral_moments: moment_samples must be smaller than num cols of A'; G = hl.rand_unif(-1, 1, size=(n, moment_samples)).map(lambd",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/pca.html:14395,assert,assert,14395,docs/0.2/_modules/hail/methods/pca.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html,2,['assert'],['assert']
Testability,"k: f._all_summary_aggs() for k, f in self.items()}). [docs] def get(self, k, default=None):; """"""See :meth:`StructExpression.__getitem__`""""""; return super().get(k, default). [docs] def items(self):; """"""A list of pairs of field name and expression for said field.""""""; return super().items(). [docs] def keys(self):; """"""The list of field names.""""""; return super().keys(). [docs] def values(self):; """"""A list of expressions for each field.""""""; return super().values(). [docs]class TupleExpression(Expression, Sequence):; """"""Expression of type :class:`.ttuple`. >>> tup = hl.literal((""a"", 1, [1, 2, 3])); """""". [docs] @typecheck_method(item=oneof(int, slice)); def __getitem__(self, item):; """"""Index into the tuple. Examples; --------. >>> hl.eval(tup[1]); 1. Parameters; ----------; item : :obj:`int`; Element index. Returns; -------; :class:`.Expression`; """"""; if isinstance(item, slice):; assert item.start is None or isinstance(item.start, int); assert item.stop is None or isinstance(item.stop, int); assert item.step is None or isinstance(item.step, int); return hl.or_missing(; hl.is_defined(self), hl.tuple([self[i] for i in range(len(self))[item.start : item.stop : item.step]]); ); if not 0 <= item < len(self):; raise IndexError(""Out of bounds index, {}. Tuple length is {}."".format(item, len(self))); return construct_expr(ir.GetTupleElement(self._ir, item), self.dtype.types[item], self._indices). [docs] def __len__(self):; """"""Returns the length of the tuple. Examples; --------. >>> len(tup); 3. Returns; -------; :obj:`int`; """"""; return len(self.dtype.types). def __bool__(self):; return bool(len(self)). def __iter__(self):; for i in range(len(self)):; yield self[i]. def _nested_summary(self, agg_result, top):; return {f'[{i}]': self[i]._summarize(agg_result[i]) for i in range(len(self))}. def _summary_aggs(self):; return hl.tuple([self[i]._all_summary_aggs() for i in range(len(self))]). [docs] def count(self, value):; """"""Do not use this method. This only exists for compatibility wi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:53286,assert,assert,53286,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['assert'],['assert']
Testability,"ke,; master=nullable(strlike),; local=strlike,; log=strlike,; quiet=bool,; append=bool,; parquet_compression=strlike,; min_block_size=integral,; branching_factor=integral,; tmp_dir=strlike); def __init__(self, sc=None, app_name=""Hail"", master=None, local='local[*]',; log='hail.log', quiet=False, append=False, parquet_compression='snappy',; min_block_size=1, branching_factor=50, tmp_dir='/tmp'):. if Env._hc:; raise FatalError('Hail Context has already been created, restart session '; 'or stop Hail context to change configuration.'). SparkContext._ensure_initialized(). self._gateway = SparkContext._gateway; self._jvm = SparkContext._jvm. # hail package; self._hail = getattr(self._jvm, 'is').hail. Env._jvm = self._jvm; Env._gateway = self._gateway. jsc = sc._jsc.sc() if sc else None. # we always pass 'quiet' to the JVM because stderr output needs; # to be routed through Python separately.; self._jhc = self._hail.HailContext.apply(; jsc, app_name, joption(master), local, log, True, append,; parquet_compression, min_block_size, branching_factor, tmp_dir). self._jsc = self._jhc.sc(); self.sc = sc if sc else SparkContext(gateway=self._gateway, jsc=self._jvm.JavaSparkContext(self._jsc)); self._jsql_context = self._jhc.sqlContext(); self._sql_context = SQLContext(self.sc, self._jsql_context). # do this at the end in case something errors, so we don't raise the above error without a real HC; Env._hc = self. sys.stderr.write('Running on Apache Spark version {}\n'.format(self.sc.version)); if self._jsc.uiWebUrl().isDefined():; sys.stderr.write('SparkUI available at {}\n'.format(self._jsc.uiWebUrl().get())). if not quiet:; connect_logger('localhost', 12888). sys.stderr.write(; 'Welcome to\n'; ' __ __ <>__\n'; ' / /_/ /__ __/ /\n'; ' / __ / _ `/ / /\n'; ' /_/ /_/\_,_/_/_/ version {}\n'.format(self.version)). [docs] @staticmethod; def get_running():; """"""Return the running Hail context in this Python session. **Example**. .. doctest::; :options: +SKIP. >>> HailContext() # oops! Forg",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/context.html:2915,log,log,2915,docs/0.1/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/context.html,1,['log'],['log']
Testability,"kelihood ratio test ('lrt'), Rao score test ('score'),; and Firth test ('firth') as the ``test`` parameter. Conceptually, the method proceeds as follows:. 1) Filter to the set of samples for which all phenotype and covariates are defined. 2) For each key and sample, aggregate genotypes across variants with that key to produce a numeric score.; ``agg_expr`` must be of numeric type and has the following symbols are in scope:. - ``s`` (*Sample*): sample; - ``sa``: sample annotations; - ``global``: global annotations; - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``. Note that ``v``, ``va``, and ``g`` are accessible through; `Aggregable methods <https://hail.is/hail/types.html#aggregable>`_ on ``gs``. The resulting **sample key table** has key column ``key_name`` and a numeric column of scores for each sample; named by the sample ID. 3) For each key, fit the logistic regression model using the supplied phenotype, covariates, and test.; The model and tests are those of :py:meth:`.logreg` with sample genotype ``gt`` replaced by the; score in the sample key table. For each key, missing scores are mean-imputed across all samples. The resulting **logistic regression key table** has key column of type String given by the ``key_name``; parameter and additional columns corresponding to the fields of the ``va.logreg`` schema given for ``test``; in :py:meth:`.logreg`. :py:meth:`.logreg_burden` returns both the logistic regression key table and the sample key table. :param str key_name: Name to assign to key column of returned key tables. :param str variant_keys: Variant annotation path for the TArray or TSet of keys associated to each variant. :param bool single_key: if true, ``variant_keys`` is interpreted as a single (or missing) key per variant,; rather than as a collection of keys. :param str agg_expr: Sample aggregation expression (per key). :param str test: Statistical test, one of: 'wald', 'lrt', 'score', or 'firth'. :param str y: Response ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:152834,test,tests,152834,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['tests']
Testability,"l an; accuracy of 1e-6 is achieved. Hence a reported p-value of zero with no; issues may truly be as large as 1e-6. The accuracy and maximum number of; iterations may be controlled by the corresponding function parameters.; In general, higher accuracy requires more iterations. Caution; To process a group with \(m\) rows, several copies of an; \(m \times m\) matrix of doubles must fit in worker memory. Groups; with tens of thousands of rows may exhaust worker memory causing the; entire job to fail. In this case, use the max_size parameter to skip; groups larger than max_size. Warning; skat() considers the same set of columns (i.e., samples, points) for; every group, namely those columns for which all covariates are defined.; For each row, missing values of x are mean-imputed over these columns.; As in the example, the intercept covariate 1 must be included; explicitly if desired. Notes; This method provides a scalable implementation of the score-based; variance-component test originally described in; Rare-Variant Association Testing for Sequencing Data with the Sequence Kernel Association Test.; Row weights must be non-negative. Rows with missing weights are ignored. In; the R package skat—which assumes rows are variants—default weights; are given by evaluating the Beta(1, 25) density at the minor allele; frequency. To replicate these weights in Hail using alternate allele; frequencies stored in a row-indexed field AF, one can use the expression:; >>> hl.dbeta(hl.min(ds2.AF), 1.0, 25.0) ** 2. In the logistic case, the response y must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded; as 1 and 0, respectively.; The resulting Table provides the group’s key (id), thenumber of; rows in the group (size), the variance component score q_stat, the SKAT; p-value, and a fault flag. For the toy example above, the table has the; form:. id; size; q_stat; p_value; fault. geneA; 2; 4.136; 0.205; 0. geneB; 1; 5.659; 0.195; 0. geneC",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:79452,test,test,79452,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['test'],['test']
Testability,"l genotypes; are HomRef) will have missing annotations.; The simplest way to export all resulting annotations is:; >>> lmm_vds.export_variants('output/lmmreg.tsv.bgz', 'variant = v, va.lmmreg.*'); >>> lmmreg_results = lmm_vds.globals['lmmreg']. By default, genotypes values are given by hard call genotypes (g.gt).; If use_dosages=True, then genotype values for per-variant association are defined by the dosage; \(\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})\). For Phred-scaled values,; \(\mathrm{P}(\mathrm{Het})\) and \(\mathrm{P}(\mathrm{HomVar})\) are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1.; Performance; Hail’s initial version of lmmreg() scales beyond 15k samples and to an essentially unbounded number of variants, making it particularly well-suited to modern sequencing studies and complementary to tools designed for SNP arrays. Analysts have used lmmreg() in research to compute kinship from 100k common variants and test 32 million non-rare variants on 8k whole genomes in about 10 minutes on Google cloud.; While lmmreg() computes the kinship matrix \(K\) using distributed matrix multiplication (Step 2), the full eigendecomposition (Step 3) is currently run on a single core of master using the LAPACK routine DSYEVD, which we empirically find to be the most performant of the four available routines; laptop performance plots showing cubic complexity in \(n\) are available here. On Google cloud, eigendecomposition takes about 2 seconds for 2535 sampes and 1 minute for 8185 samples. If you see worse performance, check that LAPACK natives are being properly loaded (see “BLAS and LAPACK” in Getting Started).; Given the eigendecomposition, fitting the global model (Step 4) takes on the order of a few seconds on master. Association testing (Step 5) is fully distributed by variant with per-variant time complexity that is completely independent of the number of sample covariates and dominated by multiplicati",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:96539,test,test,96539,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"l supports the Wald test ('wald'), likelihood ratio test ('lrt'),; Rao score test ('score'), and Firth test ('firth'). Hail only includes; columns for which the response variable and all covariates are defined.; For each row, Hail imputes missing input values as the mean of the; non-missing values. The example above considers a model of the form. .. math::. \mathrm{Prob}(\mathrm{is\_case}) =; \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt}; + \beta_2 \, \mathrm{age}; + \beta_3 \, \mathrm{is\_female} + \varepsilon),; \quad; \varepsilon \sim \mathrm{N}(0, \sigma^2). where :math:`\mathrm{sigmoid}` is the `sigmoid function`_, the genotype; :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for Het, and 2 for; HomVar, and the Boolean covariate :math:`\mathrm{is\_female}` is coded as; for ``True`` (female) and 0 for ``False`` (male). The null model sets; :math:`\beta_1 = 0`. .. _sigmoid function: https://en.wikipedia.org/wiki/Sigmoid_function. The structure of the emitted row field depends on the test statistic as; shown in the tables below. ========== ================== ======= ============================================; Test Field Type Value; ========== ================== ======= ============================================; Wald `beta` float64 fit effect coefficient,; :math:`\hat\beta_1`; Wald `standard_error` float64 estimated standard error,; :math:`\widehat{\mathrm{se}}`; Wald `z_stat` float64 Wald :math:`z`-statistic, equal to; :math:`\hat\beta_1 / \widehat{\mathrm{se}}`; Wald `p_value` float64 Wald p-value testing :math:`\beta_1 = 0`; LRT, Firth `beta` float64 fit effect coefficient,; :math:`\hat\beta_1`; LRT, Firth `chi_sq_stat` float64 deviance statistic; LRT, Firth `p_value` float64 LRT / Firth p-value testing; :math:`\beta_1 = 0`; Score `chi_sq_stat` float64 score statistic; Score `p_value` float64 score p-value testing :math:`\beta_1 = 0`; ========== ================== ======= ============================================. For the Wald and likelihood ratio te",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:29319,test,test,29319,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,['test'],['test']
Testability,"l) – If True, load .gz files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec.; sep (str) – This parameter is a deprecated name for delimiter, please use that; instead.; delimiter (str) – A single character string which separates values in the file.; comment (str or list of str) – Skip lines beginning with the given string if the string is a single; character. Otherwise, skip lines that match the regex specified. Multiple; comment characters or patterns should be passed as a list. Returns:; MatrixTable – MatrixTable constructed from imported data. hail.methods.import_plink(bed, bim, fam, min_partitions=None, delimiter='\\\\s+', missing='NA', quant_pheno=False, a2_reference=True, reference_genome='default', contig_recoding=None, skip_invalid_loci=False, n_partitions=None, block_size=None)[source]; Import a PLINK dataset (BED, BIM, FAM) as a MatrixTable.; Examples; >>> ds = hl.import_plink(bed='data/test.bed',; ... bim='data/test.bim',; ... fam='data/test.fam',; ... reference_genome='GRCh37'). Notes; Only binary SNP-major mode files can be read into Hail. To convert your; file from individual-major mode to SNP-major mode, use PLINK to read in; your fileset and use the --make-bed option.; Hail uses the individual ID (column 2 in FAM file) as the sample id (s).; The individual IDs must be unique.; The resulting MatrixTable has the following fields:. Row fields:. locus (tlocus or tstruct) – Row key. The; chromosome and position. If reference_genome is defined, the type; will be tlocus parameterized by reference_genome.; Otherwise, the type will be a tstruct with two fields:; contig with type tstr and position with type; tint32.; alleles (tarray of tstr) – Row key. An; array containing the alleles of the variant. The reference allele (A2; if a2_reference is True) is the first element in the array.; rsid (tstr) – Column 2 in the BIM file.; cm_position (tfloat64) – Column 3 in the BIM file,; the position in centimorgans. Column fields",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/impex.html:27208,test,test,27208,docs/0.2/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/methods/impex.html,1,['test'],['test']
Testability,"l, or label names not appearing in this dict will be colored using a default color scheme.; width: int; Plot width; height: int; Plot height; collect_all : bool; Deprecated. Use `n_divisions` instead.; n_divisions : int, optional; Factor by which to downsample (default value = 500).; A lower input results in fewer output datapoints.; Use `None` to collect all points.; missing_label: str; Label to use when a point is missing data for a categorical label. Returns; -------; :class:`bokeh.plotting.figure` if no label or a single label was given, otherwise :class:`bokeh.models.layouts.Column`; """"""; hover_fields = {} if hover_fields is None else hover_fields; label_by_col: Dict[str, Expression]; if label is None:; label_by_col = {}; elif isinstance(label, Expression):; label_by_col = {'label': label}; else:; assert isinstance(label, dict); label_by_col = label. source = pvals._indices.source; if isinstance(source, Table):; ht = source.select(p_value=pvals, **hover_fields, **label_by_col); else:; assert isinstance(source, MatrixTable); ht = source.select_rows(p_value=pvals, **hover_fields, **label_by_col).rows(); ht = ht.key_by().select('p_value', *hover_fields, *label_by_col).key_by('p_value'); n = ht.aggregate(aggregators.count(), _localize=False); ht = ht.annotate(observed_p=-hail.log10(ht['p_value']), expected_p=-hail.log10((hail.scan.count() + 1) / n)); if 'p' not in hover_fields:; hover_fields['p_value'] = ht['p_value']; p = scatter(; ht.expected_p,; ht.observed_p,; label={x: ht[x] for x in label_by_col},; title=title,; xlabel=xlabel,; ylabel=ylabel,; size=size,; legend=legend,; hover_fields={x: ht[x] for x in hover_fields},; colors=colors,; width=width,; height=height,; n_divisions=_downsampling_factor('qq', n_divisions, collect_all),; missing_label=missing_label,; ); from hail.methods.statgen import _lambda_gc_agg. lambda_gc, max_p = ht.aggregate((; _lambda_gc_agg(ht['p_value']),; hail.agg.max(hail.max(ht.observed_p, ht.expected_p)),; )); if isinstance(p, Column):;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:49832,assert,assert,49832,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['assert'],['assert']
Testability,"l.eval(call.ploidy); 2. Notes; Currently only ploidy 1 and 2 are supported. Returns:; Expression of type tint32. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. unphase()[source]; Returns an unphased version of this call. Returns:; CallExpression. unphased_diploid_gt_index()[source]; Return the genotype index for unphased, diploid calls.; Examples; >>> hl.eval(call.unphased_diploid_gt_index()); 1. Returns:; Expression of type tint32. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.CallExpression.html:11119,test,tested,11119,docs/0.2/hail.expr.CallExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.CallExpression.html,1,['test'],['tested']
Testability,"l_tmpdir=local_tmpdir,; global_seed=global_seed,; backend=backend,; ); hc.initialize_references(default_reference); return hc. @typecheck_method(; log=str, quiet=bool, append=bool, tmpdir=str, local_tmpdir=str, global_seed=nullable(int), backend=Backend; ); def __init__(self, log, quiet, append, tmpdir, local_tmpdir, global_seed, backend):; assert not Env._hc. self._log = log. self._tmpdir = tmpdir; self._local_tmpdir = local_tmpdir. self._backend = backend. self._warn_cols_order = True; self._warn_entries_order = True. self._default_ref: Optional[ReferenceGenome] = None. if not quiet:; py_version = version(); sys.stderr.write(; 'Welcome to\n'; ' __ __ <>__\n'; ' / /_/ /__ __/ /\n'; ' / __ / _ `/ / /\n'; ' /_/ /_/\\_,_/_/_/ version {}\n'.format(py_version); ). if py_version.startswith('devel'):; sys.stderr.write(; 'NOTE: This is a beta version. Interfaces may change\n'; ' during the beta period. We recommend pulling\n'; ' the latest changes weekly.\n'; ); sys.stderr.write(f'LOGGING: writing to {log}\n'). self._user_specified_rng_nonce = True; if global_seed is None:; if 'rng_nonce' not in backend.get_flags('rng_nonce'):; backend.set_flags(rng_nonce=hex(Random().randrange(-(2**63), 2**63 - 1))); self._user_specified_rng_nonce = False; else:; backend.set_flags(rng_nonce=hex(global_seed)); Env._hc = self. def initialize_references(self, default_reference):; assert self._backend; self._backend.initialize_references(); if default_reference in BUILTIN_REFERENCES:; self._default_ref = self._backend.get_reference(default_reference); else:; self._default_ref = ReferenceGenome.read(default_reference). @property; def default_reference(self) -> ReferenceGenome:; assert self._default_ref is not None, '_default_ref should have been initialized in HailContext.create'; return self._default_ref. @default_reference.setter; def default_reference(self, value):; if not isinstance(value, ReferenceGenome):; raise TypeError(f'{value} is {type(value)} not a ReferenceGenome'); self._default_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:3708,log,log,3708,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,3,"['LOG', 'log']","['LOGGING', 'log']"
Testability,"lar, for the sample annotation ``sa.fam.isCase`` added by importing a FAM file with case-control phenotype, case is 1 and control is 0. Hail's logistic regression tests correspond to the ``b.wald``, ``b.lrt``, and ``b.score`` tests in `EPACTS <http://genome.sph.umich.edu/wiki/EPACTS#Single_Variant_Tests>`__. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes. :param str test: Statistical test, one of: 'wald', 'lrt', 'score', or 'firth'. :param str y: Response expression. Must evaluate to Boolean or; numeric with all values 0 or 1. :param covariates: list of covariate expressions; :type covariates: list of str. :param str root: Variant annotation path to store result of logistic regression. :param bool use_dosages: If true, use genotype dosage rather than hard call. :return: Variant dataset with logistic regression variant annotations.; :rtype: :py:class:`.VariantDataset`; """""". jvds = self._jvdf.logreg(test, y, jarray(Env.jvm().java.lang.String, covariates), root, use_dosages); return VariantDataset(self.hc, jvds). [docs] @handle_py4j; @typecheck_method(key_name=strlike,; variant_keys=strlike,; single_key=bool,; agg_expr=strlike,; test=strlike,; y=strlike,; covariates=listof(strlike)); def logreg_burden(self, key_name, variant_keys, single_key, agg_expr, test, y, covariates=[]):; r""""""Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. .. include:: requireTGenotype.rst. **Examples**. Run a gene burden test using the logistic Wald test on the maximum genotype per gene. Here ``va.genes`` is; a variant annotation of type Set[String] giving the set of genes containing the variant; (see **Extended example** in :py:meth:`.linreg_burden` for a deeper dive in the context of linear regression):. >>> logreg_kt, s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:148664,log,logistic,148664,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logistic']
Testability,"ld containing unicode; characters.; (#5692) When; keyed is True, hl.maximal_independent_set now does not; produce duplicates.; (#5725) Docs now; consistently refer to hl.agg not agg.; (#5730)(#5782); Taught import_bgen to optimize its variants argument. Experimental. (#5732) The; hl.agg.approx_quantiles aggregate computes an approximation of; the quantiles of an expression.; (#5693)(#5396); Table._multi_way_zip_join now correctly handles keys that have; been truncated. Version 0.2.12; Released 2019-03-28. New features. (#5614) Add support; for multiple missing values in hl.import_table.; (#5666) Produce HTML; table output for Table.show() when running in Jupyter notebook. Bug fixes. (#5603)(#5697); Fixed issue where min_partitions on hl.import_table was; non-functional.; (#5611) Fix; hl.nirvana crash. Experimental. (#5524) Add; summarize functions to Table, MatrixTable, and Expression.; (#5570) Add; hl.agg.approx_cdf aggregator for approximate density calculation.; (#5571) Add log; parameter to hl.plot.histogram.; (#5601) Add; hl.plot.joint_plot, extend functionality of hl.plot.scatter.; (#5608) Add LD score; simulation framework.; (#5628) Add; hl.experimental.full_outer_join_mt for full outer joins on; MatrixTables. Version 0.2.11; Released 2019-03-06. New features. (#5374) Add default; arguments to hl.add_sequence for running on GCP.; (#5481) Added; sample_cols method to MatrixTable.; (#5501) Exposed; MatrixTable.unfilter_entries. See filter_entries; documentation for more information.; (#5480) Added; n_cols argument to MatrixTable.head.; (#5529) Added; Table.{semi_join, anti_join} and; MatrixTable.{semi_join_rows, semi_join_cols, anti_join_rows, anti_join_cols}.; (#5528) Added; {MatrixTable, Table}.checkpoint methods as wrappers around; write / read_{matrix_table, table}. Bug fixes. (#5416) Resolved; issue wherein VEP and certain regressions were recomputed on each; use, rather than once.; (#5419) Resolved; issue with import_vcf force_bgz and file size che",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:97875,log,log,97875,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['log'],['log']
Testability,"le annotations ``sa.pheno``, ``sa.cov1``, ``sa.cov2``. Then the :py:meth:`.lmmreg` function in. >>> assoc_vds = hc.read(""data/example_lmmreg.vds""); >>> kinship_matrix = assoc_vds.filter_variants_expr('va.useInKinship').rrm(); >>> lmm_vds = assoc_vds.lmmreg(kinship_matrix, 'sa.pheno', ['sa.cov1', 'sa.cov2']). will execute the following four steps in order:. 1) filter to samples in given kinship matrix to those for which ``sa.pheno``, ``sa.cov``, and ``sa.cov2`` are all defined; 2) compute the eigendecomposition :math:`K = USU^T` of the kinship matrix; 3) fit covariate coefficients and variance parameters in the sample-covariates-only (global) model using restricted maximum likelihood (`REML <https://en.wikipedia.org/wiki/Restricted_maximum_likelihood>`__), storing results in global annotations under ``global.lmmreg``; 4) test each variant for association, storing results under ``va.lmmreg`` in variant annotations. This plan can be modified as follows:. - Set ``run_assoc=False`` to not test any variants for association, i.e. skip Step 5.; - Set ``use_ml=True`` to use maximum likelihood instead of REML in Steps 4 and 5.; - Set the ``delta`` argument to manually set the value of :math:`\delta` rather that fitting :math:`\delta` in Step 4.; - Set the ``global_root`` argument to change the global annotation root in Step 4.; - Set the ``va_root`` argument to change the variant annotation root in Step 5. :py:meth:`.lmmreg` adds 9 or 13 global annotations in Step 4, depending on whether :math:`\delta` is set or fit. +----------------------------------------------+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+; | Annotation | Type | Value |; +==============================================+======================+==============================================================================================================================================",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:116322,test,test,116322,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['test']
Testability,"le for hail based on the very popular ggplot2 package from R’s tidyverse. That library is very fully featured and we will never be quite as flexible as it, but with just a subset of its functionality we can make highly customizable plots. The Grammar of Graphics; The key idea here is that there’s not one magic function to make the plot you want. Plots are built up from a set of core primitives that allow for extensive customization. Let’s start with an example. We are going to plot y = x^2 for x from 0 to 10. First we make a hail table representing that data:. [2]:. ht = hl.utils.range_table(10); ht = ht.annotate(squared = ht.idx**2). Every plot starts with a call to ggplot, and then requires adding a geom to specify what kind of plot you’d like to create. [3]:. fig = ggplot(ht, aes(x=ht.idx, y=ht.squared)) + geom_line(); fig.show(). Initializing Hail with default parameters...; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2013-0.2.133-4c60fddb171a.log; SLF4J: Failed to load class ""org.slf4j.impl.StaticMDCBinder"".; SLF4J: Defaulting to no-operation MDCAdapter implementation.; SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details. aes creates an “aesthetic mapping”, which maps hail expressions to aspects of the plot. There is a predefined list of aesthetics supported by every geom. Most take an x and y at least.; With this interface, it’s easy to change out our plotting representation separate from our data. We can plot bars:. [4]:. fig = ggplot(ht, aes(x=ht.idx, y=ht.squared)) + geom_col(); fig.show(). Or poi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/09-ggplot.html:1871,log,logger,1871,docs/0.2/tutorials/09-ggplot.html,https://hail.is,https://hail.is/docs/0.2/tutorials/09-ggplot.html,1,['log'],['logger']
Testability,"le into a Table. import_gen(path[, sample_file, tolerance, ...]); Import GEN file(s) as a MatrixTable. import_locus_intervals(path[, ...]); Import a locus interval list as a Table. import_matrix_table(paths[, row_fields, ...]); Import tab-delimited file(s) as a MatrixTable. import_plink(bed, bim, fam[, ...]); Import a PLINK dataset (BED, BIM, FAM) as a MatrixTable. import_table(paths[, key, min_partitions, ...]); Import delimited text file (text table) as Table. import_vcf(path[, force, force_bgz, ...]); Import VCF file(s) as a MatrixTable. index_bgen(path[, index_file_map, ...]); Index BGEN files as required by import_bgen(). read_matrix_table(path, *[, _intervals, ...]); Read in a MatrixTable written with MatrixTable.write(). read_table(path, *[, _intervals, ...]); Read in a Table written with Table.write(). Statistics. linear_mixed_model(y, x[, z_t, k, p_path, ...]); Initialize a linear mixed model from a matrix table. linear_mixed_regression_rows(entry_expr, model); For each row, test an input variable for association using a linear mixed model. linear_regression_rows(y, x, covariates[, ...]); For each row, test an input variable for association with response variables using linear regression. logistic_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a binary response variable using logistic regression. poisson_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a count response variable using Poisson regression. pca(entry_expr[, k, compute_loadings]); Run principal component analysis (PCA) on numeric columns derived from a matrix table. row_correlation(entry_expr[, block_size]); Computes the correlation matrix between row vectors. Genetics. balding_nichols_model(n_populations, ...[, ...]); Generate a matrix table of variants, samples, and genotypes using the Balding-Nichols or Pritchard-Stephens-Donnelly model. concordance(left, right, *[, ...]); Calculate call conc",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/index.html:3426,test,test,3426,docs/0.2/methods/index.html,https://hail.is,https://hail.is/docs/0.2/methods/index.html,1,['test'],['test']
Testability,"le, use an expression that defines the columns of the output file. Multiple columns are separated by commas. Export the variant name v, the PASS annotation va.pass, and the mean GQ annotation va.gqStats.mean to a TSV file. There will be one line per variant and the output for the variant column v will be of the form contig:start:ref:alt. No header line will be present!!. v, va.pass, va.gqStats.mean. Same as above but include a header with the column names “Variant”, “PASS”, and “MeanGQ”. Variant = v, PASS = va.pass, MeanGQ = va.gqStats.mean. Export the sample name s, a sample annotation for the number of het calls sa.nHet, and a sample annotation for case status sa.pheno.isCase. There will be one line per sample. The header line will be “Sample”, “nHet”, and “Phenotype”. Sample = s, nHet = sa.nHet, Phenotype = sa.pheno.isCase. Export all annotations generated by variant_qc(). Variant = v, va.qc.*. Input Variables to Methods¶; The linear and logistic regression commands utilize expressions containing sample annotation variables to define the response variable and covariates. Linear regression command defining the response variable and covariates from sample annotations. >>> vds.linreg('sa.isCase', covariates='sa.PC1, sa.PC2, sa.PC3, sa.AGE'). Filtering¶; Filter commands take a boolean expression. Here are some examples of boolean expressions using VDS elements:. Variant chromosome name v.contig does not equal “X” or “Y”. v.contig != “X” && v.contig != “Y”. Sample id s does not match the substring “NA12”. !(""NA12"" ~ s). Sample annotation for whether a sample is female sa.isFemale, which is a boolean variable. sa.isFemale. Variant annotation for whether a variant has a pass flag va.pass, which is a boolean variable. va.pass. Variant annotation for the quality score va.qual (numeric variable) is greater than 20. va.qual > 20. Expression that combines attributes of both v and va. (va.qual > 20 && va.pass) || v.nAlleles == 2. Expression that combine attributes of both s a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/overview.html:4371,log,logistic,4371,docs/0.1/overview.html,https://hail.is,https://hail.is/docs/0.1/overview.html,1,['log'],['logistic']
Testability,"le.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. size(); Returns the size of a collection.; Examples; >>> hl.eval(a.size()); 5. >>> hl.eval(s3.size()); 3. Returns:; Expression of type tint32 – The number of elements in the collection. starmap(f); Transform each element of a collection of tuples.; Examples; >>> hl.eval(hl.array([(1, 2), (2, 3)]).starmap(lambda x, y: x+y)); [3, 5]. Parameters:; f (function ( (*args) -> Expression)) – Function to transform each element of the collection. Returns:; CollectionExpression. – Collection where each element has been transformed according to f. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.ArrayExpression.html:15028,test,tested,15028,docs/0.2/hail.expr.ArrayExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.ArrayExpression.html,2,['test'],['tested']
Testability,"lectFields; mt = mt._select_all(; col_exprs=dict(**y_dict, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'LogisticRegression',; 'test': test,; 'yFields': y_field,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. result = Table(ir.MatrixToTableApply(mt._mir, config)). if not y_is_list:; result = result.transmute(**result.logistic_regression[0]). return result.persist(). # Helpers for logreg:; def mean_impute(hl_array):; non_missing_mean = hl.mean(hl_array, filter_missing=True); return hl_array.map(lambda entry: hl.coalesce(entry, non_missing_mean)). sigmoid = expit. def nd_max(hl_nd):; return hl.max(hl.array(hl_nd.reshape(-1))). def logreg_fit(; X: NDArrayNumericExpression, # (K,); y: NDArrayNumericExpression, # (N, K); null_fit: Optional[StructExpression],; max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Bernoulli(logit(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; # X is samples by covs.; # y is length num samples, for one cov.; n = X.shape[0]; m = X.shape[1]. if null_fit is None:; avg = y.sum() / n; logit_avg = hl.log(avg / (1 - avg)); b = hl.nd.hstack([hl.nd.array([logit_avg]), hl.nd.zeros((hl.int32(m - 1)))]); mu = sigmoid(X @ b); score = X.T @ (y - mu); # Reshape so we do a rowwise multiply; fisher = X.T @ (X * (mu * (1 - mu)).reshape(-1, 1)); else:; # num covs used to fit null model.; m0 = null_fit.b.shape[0]; m_diff = m - m0. X0 = X[:, 0:m0]; X1 = X[:, m0:]. b = hl.nd.hstack([null_fit.b, hl.nd.zeros((m_diff,))]); mu = sigmoid(X @ b); score = hl.nd.hstack([null_fit.score, X1.T @ (y - mu)]). fisher00 = null_fit.fisher; fisher01 = X0.T @ (X1 * (mu * (1 - m",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:39311,log,logit,39311,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logit']
Testability,"legend=None, title=None, normalize=True, log=False)[source]; Create a cumulative density plot. Parameters:. data (Struct or Float64Expression) – Sequence of data to plot.; k (int) – Accuracy parameter (passed to approx_cdf()).; legend (str) – Label of data on the x-axis.; title (str) – Title of the histogram.; normalize (bool) – Whether or not the cumulative data should be normalized.; log (bool) – Whether or not the y-axis should be of type log. Returns:; bokeh.plotting.figure. hail.plot.pdf(data, k=1000, confidence=5, legend=None, title=None, log=False, interactive=False)[source]. hail.plot.smoothed_pdf(data, k=350, smoothing=0.5, legend=None, title=None, log=False, interactive=False, figure=None)[source]; Create a density plot. Parameters:. data (Struct or Float64Expression) – Sequence of data to plot.; k (int) – Accuracy parameter.; smoothing (float) – Degree of smoothing.; legend (str) – Label of data on the x-axis.; title (str) – Title of the histogram.; log (bool) – Plot the log10 of the bin counts.; interactive (bool) – If True, return a handle to pass to bokeh.io.show().; figure (bokeh.plotting.figure) – If not None, add density plot to figure. Otherwise, create a new figure. Returns:; bokeh.plotting.figure. hail.plot.histogram(data, range=None, bins=50, legend=None, title=None, log=False, interactive=False)[source]; Create a histogram.; Notes; data can be a Float64Expression, or the result of the hist(); or approx_cdf() aggregators. Parameters:. data (Struct or Float64Expression) – Sequence of data to plot.; range (Tuple[float]) – Range of x values in the histogram.; bins (int) – Number of bins in the histogram.; legend (str) – Label of data on the x-axis.; title (str) – Title of the histogram.; log (bool) – Plot the log10 of the bin counts. Returns:; bokeh.plotting.figure. hail.plot.cumulative_histogram(data, range=None, bins=50, legend=None, title=None, normalize=True, log=False)[source]; Create a cumulative histogram. Parameters:. data (Struct or F",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/plot.html:2747,log,log,2747,docs/0.2/plot.html,https://hail.is,https://hail.is/docs/0.2/plot.html,1,['log'],['log']
Testability,"lele count, one element per; allele, including the reference. Sums to AN.; AN (int32) – Total number of called alleles.; homozygote_count (array<int32>) – Number of homozygotes per; allele. One element per allele, including the reference.; call_rate (float64) – Fraction of calls neither missing nor filtered.; Equivalent to n_called / count_cols().; n_called (int64) – Number of samples with a defined GT.; n_not_called (int64) – Number of samples with a missing GT.; n_filtered (int64) – Number of filtered entries.; n_het (int64) – Number of heterozygous samples.; n_non_ref (int64) – Number of samples with at least one called; non-reference allele.; het_freq_hwe (float64) – Expected frequency of heterozygous; samples under Hardy-Weinberg equilibrium. See; functions.hardy_weinberg_test() for details.; p_value_hwe (float64) – p-value from two-sided test of Hardy-Weinberg; equilibrium. See functions.hardy_weinberg_test() for details.; p_value_excess_het (float64) – p-value from one-sided test of; Hardy-Weinberg equilibrium for excess heterozygosity.; See functions.hardy_weinberg_test() for details. Warning; het_freq_hwe and p_value_hwe are calculated as in; functions.hardy_weinberg_test(), with non-diploid calls; (ploidy != 2) ignored in the counts. As this test is only; statistically rigorous in the biallelic setting, variant_qc(); sets both fields to missing for multiallelic variants. Consider using; split_multi() to split multi-allelic variants beforehand. Parameters:. mt (MatrixTable) – Dataset.; name (str) – Name for resulting field. Returns:; MatrixTable. hail.methods.vep(dataset, config=None, block_size=1000, name='vep', csq=False, tolerate_parse_error=False)[source]; Annotate variants with VEP. Note; Requires the dataset to have a compound row key:. locus (type tlocus); alleles (type tarray of tstr). vep() runs Variant Effect Predictor on the; current dataset and adds the result as a row field.; Examples; Add VEP annotations to the dataset:; >>> result = hl.vep(d",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:100569,test,test,100569,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['test'],['test']
Testability,"leles,; a tarray of tstr elements.; The columns of the matrix table must be keyed by a field; of type tstr that uniquely identifies phenotypes; represented in the matrix table. The column key must be a single; expression; compound keys are not accepted.; weight_expr and ld_score_expr must be row-indexed; fields.; chi_sq_exprs must be a single entry-indexed field; (not a list of fields).; n_samples_exprs must be a single entry-indexed field; (not a list of fields).; The phenotype field that keys the table returned by; ld_score_regression() will have values corresponding to the; column keys of the input matrix table. This function returns a Table with one row per set of summary; statistics passed to the chi_sq_exprs argument. The following; row-indexed fields are included in the table:. phenotype (tstr) – The name of the phenotype. The; returned table is keyed by this field. See the notes below for; details on the possible values of this field.; mean_chi_sq (tfloat64) – The mean chi-squared; test statistic for the given phenotype.; intercept (Struct) – Contains fields:. estimate (tfloat64) – A point estimate of the; intercept \(1 + Na\).; standard_error (tfloat64) – An estimate of; the standard error of this point estimate. snp_heritability (Struct) – Contains fields:. estimate (tfloat64) – A point estimate of the; SNP-heritability \(h_g^2\).; standard_error (tfloat64) – An estimate of; the standard error of this point estimate. Warning; ld_score_regression() considers only the rows for which both row; fields weight_expr and ld_score_expr are defined. Rows with missing; values in either field are removed prior to fitting the LD score; regression model. Parameters:. weight_expr (Float64Expression) – Row-indexed expression for the LD scores used to derive; variant weights in the model.; ld_score_expr (Float64Expression) – Row-indexed expression for the LD scores used as covariates; in the model.; chi_sq_exprs (Float64Expression or list of) – Float64Expression; One or mo",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/experimental/index.html:13074,test,test,13074,docs/0.2/experimental/index.html,https://hail.is,https://hail.is/docs/0.2/experimental/index.html,1,['test'],['test']
Testability,"lelize(; ... [{'a': 5, 'b': 10}, {'a': 0, 'b': 200}],; ... schema=hl.tstruct(a=hl.tint, b=hl.tint),; ... key='a'; ... ); >>> t.show(); +-------+-------+; | a | b |; +-------+-------+; | int32 | int32 |; +-------+-------+; | 0 | 200 |; | 5 | 10 |; +-------+-------+. You may also elide schema entirely and let Hail guess the type. The list elements must; either be Hail Struct or dict s.; >>> t = hl.Table.parallelize(; ... [{'a': 5, 'b': 10}, {'a': 0, 'b': 200}],; ... key='a'; ... ); >>> t.show(); +-------+-------+; | a | b |; +-------+-------+; | int32 | int32 |; +-------+-------+; | 0 | 200 |; | 5 | 10 |; +-------+-------+. You may also specify only a handful of types in partial_type. Hail will automatically; deduce the types of the other fields. Hail _cannot_ deduce the type of a field which only; contains empty arrays (the element type is unspecified), so we specify the type of labels; explicitly.; >>> dictionaries = [; ... {""number"":10038,""state"":""open"",""user"":{""login"":""tpoterba"",""site_admin"":False,""id"":10562794}, ""milestone"":None,""labels"":[]},; ... {""number"":10037,""state"":""open"",""user"":{""login"":""daniel-goldstein"",""site_admin"":False,""id"":24440116},""milestone"":None,""labels"":[]},; ... {""number"":10036,""state"":""open"",""user"":{""login"":""jigold"",""site_admin"":False,""id"":1693348},""milestone"":None,""labels"":[]},; ... {""number"":10035,""state"":""open"",""user"":{""login"":""tpoterba"",""site_admin"":False,""id"":10562794},""milestone"":None,""labels"":[]},; ... {""number"":10033,""state"":""open"",""user"":{""login"":""tpoterba"",""site_admin"":False,""id"":10562794},""milestone"":None,""labels"":[]},; ... ]; >>> t = hl.Table.parallelize(; ... dictionaries,; ... partial_type={""milestone"": hl.tstr, ""labels"": hl.tarray(hl.tstr)}; ... ); >>> t.show(); +--------+--------+--------------------+-----------------+----------+; | number | state | user.login | user.site_admin | user.id |; +--------+--------+--------------------+-----------------+----------+; | int32 | str | str | bool | int32 |; +--------+--------+------------",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.Table.html:51146,log,login,51146,docs/0.2/hail.Table.html,https://hail.is,https://hail.is/docs/0.2/hail.Table.html,1,['log'],['login']
Testability,"lement in `array` not smaller; than `elem`. This is a value between 0 and the length of `array`, inclusive; (if all elements in `array` are smaller than `elem`, the returned value is; the length of `array` or the index of the first missing value, if one; exists). If either `elem` or `array` is missing, the result is missing. Examples; --------. >>> a = hl.array([0, 2, 4, 8]). >>> hl.eval(hl.binary_search(a, -1)); 0. >>> hl.eval(hl.binary_search(a, 1)); 1. >>> hl.eval(hl.binary_search(a, 10)); 4. """"""; c = coercer_from_dtype(array.dtype.element_type); if not c.can_coerce(elem.dtype):; raise TypeError(; f""'binary_search': cannot search an array of type {array.dtype} for a value of type {elem.dtype}""; ); elem = c.coerce(elem); return hl.switch(elem).when_missing(hl.missing(hl.tint32)).default(_lower_bound(array, elem)). @typecheck(s=expr_str); def _escape_string(s):; return _func(""escapeString"", hl.tstr, s). @typecheck(left=expr_any, right=expr_any, tolerance=expr_float64, absolute=expr_bool); def _values_similar(left, right, tolerance=1e-6, absolute=False):; assert left.dtype == right.dtype; return (is_missing(left) & is_missing(right)) | (; (is_defined(left) & is_defined(right)) & _func(""valuesSimilar"", hl.tbool, left, right, tolerance, absolute); ). @typecheck(coords=expr_array(expr_array(expr_float64)), radius=expr_float64); def _locus_windows_per_contig(coords, radius):; rt = hl.ttuple(hl.tarray(hl.tint32), hl.tarray(hl.tint32)); return _func(""locus_windows_per_contig"", rt, coords, radius). [docs]@typecheck(a=expr_array(), seed=nullable(builtins.int)); def shuffle(a, seed: Optional[builtins.int] = None) -> ArrayExpression:; """"""Randomly permute an array. Example; -------. >>> hl.reset_global_randomness(); >>> hl.eval(hl.shuffle(hl.range(5))); [4, 0, 2, 1, 3]. Parameters; ----------; a : :class:`.ArrayExpression`; Array to permute.; seed : :obj:`int`, optional; Random seed. Returns; -------; :class:`.ArrayExpression`; """"""; return sorted(a, key=lambda _: hl.rand_unif(0",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:184956,assert,assert,184956,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['assert'],['assert']
Testability,"len(self.key), len(right.key)). left_key_types = list(self.key.dtype.values())[:_join_key]; right_key_types = list(right.key.dtype.values())[:_join_key]; if not left_key_types == right_key_types:; raise ValueError(; f""'join': key mismatch:\n ""; f"" left: [{', '.join(str(t) for t in left_key_types)}]\n ""; f"" right: [{', '.join(str(t) for t in right_key_types)}]""; ); left_fields = set(self._fields); right_fields = set(right._fields) - set(right.key). renames, _ = deduplicate(right_fields, max_attempts=100, already_used=left_fields). if renames:; renames = dict(renames); right = right.rename(renames); info(; 'Table.join: renamed the following fields on the right to avoid name conflicts:'; + ''.join(f'\n {k!r} -> {v!r}' for k, v in renames.items()); ). return Table(ir.TableJoin(self._tir, right._tir, how, _join_key)). [docs] @typecheck_method(expr=BooleanExpression); def all(self, expr):; """"""Evaluate whether a boolean expression is true for all rows. Examples; --------; Test whether `C1` is greater than 5 in all rows of the table:. >>> if table1.all(table1.C1 == 5):; ... print(""All rows have C1 equal 5.""). Parameters; ----------; expr : :class:`.BooleanExpression`; Expression to test. Returns; -------; :obj:`bool`; """"""; return self.aggregate(hl.agg.all(expr)). [docs] @typecheck_method(expr=BooleanExpression); def any(self, expr):; """"""Evaluate whether a Boolean expression is true for at least one row. Examples; --------. Test whether `C1` is equal to 5 any row in any row of the table:. >>> if table1.any(table1.C1 == 5):; ... print(""At least one row has C1 equal 5.""). Parameters; ----------; expr : :class:`.BooleanExpression`; Boolean expression. Returns; -------; :obj:`bool`; ``True`` if the predicate evaluated for ``True`` for any row, otherwise ``False``.; """"""; return self.aggregate(hl.agg.any(expr)). [docs] @typecheck_method(mapping=dictof(str, str)); def rename(self, mapping) -> 'Table':; """"""Rename fields of the table. Examples; --------; Rename `C1` to `col1` and `C2`",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:103391,Test,Test,103391,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,1,['Test'],['Test']
Testability,"lerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; count response variable using `Poisson regression <https://en.wikipedia.org/wiki/Poisson_regression>`__. Notes; -----; See :func:`.logistic_regression_rows` for more info on statistical tests; of general linear models. Note; ----; Use the `pass_through` parameter to include additional row fields",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:60570,assert,assert,60570,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['assert'],['assert']
Testability,"lf), hl.agg.count()),; self._summary_aggs(),; )). def _summarize(self, agg_res=None, *, name=None, header=None, top=False):; src = self._indices.source; summary_header = None; if src is None or len(self._indices.axes) == 0:; raise ValueError(""Cannot summarize a scalar expression""); if agg_res is None:; count, agg_res = self._aggregation_method()(hl.tuple((hl.agg.count(), self._all_summary_aggs()))); summary_header = f'{count} records.'; sum_fields, nested = self._summary_fields(agg_res, top); summary = Summary(self._type, agg_res[0], sum_fields, nested, header=summary_header); if name is None and header is None:; return summary; else:; return NamedSummary(summary, name, header). [docs] def summarize(self, handler=None):; """"""Compute and print summary information about the expression. .. include:: _templates/experimental.rst; """""". src = self._indices.source; if self in src._fields:; field_name = src._fields_inverse[self]; prefix = field_name; elif self._ir.is_nested_field:; prefix = self._ir.name; else:; prefix = '<expr>'. if handler is None:; handler = hl.utils.default_handler(); handler(self._summarize(name=prefix)). def _selector_and_agg_method(self):; src = self._indices.source; assert src is not None; assert len(self._indices.axes) > 0; if isinstance(src, hl.MatrixTable):; if self._indices == src._row_indices:; return src.select_rows, lambda t: t.aggregate_rows; elif self._indices == src._col_indices:; return src.select_cols, lambda t: t.aggregate_cols; else:; return src.select_entries, lambda t: t.aggregate_entries; else:; return src.select, lambda t: t.aggregate. def _aggregation_method(self):; return self._selector_and_agg_method()[1](self._indices.source). def _persist(self):; src = self._indices.source; if src is not None:; raise ValueError(""Can only persist a scalar (no Table/MatrixTable source)""); expr = Env.backend().persist_expression(self); assert expr.dtype == self.dtype; return expr. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html:35171,assert,assert,35171,docs/0.2/_modules/hail/expr/expressions/base_expression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html,6,['assert'],['assert']
Testability,"lf):; pass. [docs]class tndarray(HailType):; """"""Hail type for n-dimensional arrays. .. include:: _templates/experimental.rst. In Python, these are represented as NumPy :obj:`numpy.ndarray`. Notes; -----. NDArrays contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of array.; ndim : int32; Number of dimensions. See Also; --------; :class:`.NDArrayExpression`, :obj:`.nd.array`; """""". @typecheck_method(element_type=hail_type, ndim=oneof(NatBase, int)); def __init__(self, element_type, ndim):; self._element_type = element_type; self._ndim = NatLiteral(ndim) if isinstance(ndim, int) else ndim; super(tndarray, self).__init__(). @property; def element_type(self):; """"""NDArray element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. @property; def ndim(self):; """"""NDArray number of dimensions. Returns; -------; :obj:`int`; Number of dimensions.; """"""; assert isinstance(self._ndim, NatLiteral), ""tndarray must be realized with a concrete number of dimensions""; return self._ndim.n. def _traverse(self, obj, f):; if f(self, obj):; for elt in np.nditer(obj, ['zerosize_ok']):; self.element_type._traverse(elt.item(), f). def _typecheck_one_level(self, annotation):; if annotation is not None and not isinstance(annotation, np.ndarray):; raise TypeError(""type 'ndarray' expected Python 'numpy.ndarray', but found type '%s'"" % type(annotation)). def __str__(self):; return ""ndarray<{}, {}>"".format(self.element_type, self.ndim). def _eq(self, other):; return isinstance(other, tndarray) and self.element_type == other.element_type and self.ndim == other.ndim. def _pretty(self, b, indent, increment):; b.append('ndarray<'); self._element_type._pretty(b, indent, increment); b.append(', '); b.append(str(self.ndim)); b.append('>'). def _parsable_string(self):; return f'NDArray[{self._element_type._parsable_string()},{self.ndim}]'. def _convert_from_json(self, x, ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:15147,assert,assert,15147,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['assert'],['assert']
Testability,"lid optional suffixes are K, Ki, M, Mi,; G, Gi, T, Ti, P, and Pi. Omitting a suffix means; the value is in bytes.; For the ServiceBackend, the values ‘lowmem’, ‘standard’,; and ‘highmem’ are also valid arguments. ‘lowmem’ corresponds to; approximately 1 Gi/core, ‘standard’ corresponds to approximately; 4 Gi/core, and ‘highmem’ corresponds to approximately 7 Gi/core.; The default value is ‘standard’. Parameters:; memory (Union[str, int, None]) – Units are in bytes if memory is an int. If None,; use the default value for the ServiceBackend (‘standard’). Return type:; Self. Returns:; Same job object with memory requirements set. regions(regions); Set the cloud regions a job can run in.; Notes; Can only be used with the backend.ServiceBackend.; This method may be used to ensure code executes in the same region as the data it reads.; This can avoid egress charges as well as improve latency.; Examples; Require the job to run in ‘us-central1’:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.regions(['us-central1']); ... .command(f'echo ""hello""')). Specify the job can run in any region:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.regions(None); ... .command(f'echo ""hello""')). Parameters:; regions (Optional[List[str]]) – The cloud region(s) to run this job in. Use None to signify; the job can run in any available region. Use py:staticmethod:.ServiceBackend.supported_regions; to list the available regions to choose from. The default is the job can run in; any region. Return type:; Self. Returns:; Same job object with the cloud regions the job can run in set. spot(is_spot); Set whether a job is run on spot instances. By default, all jobs run on spot instances.; Examples; Ensure a job only runs on non-spot instances:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> j = j.spot(False); >>> j = j.command(f'echo ""hello""'). Parameters:; is_spot (bool) – If False, this job wil",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html:6952,test,test,6952,docs/batch/api/batch/hailtop.batch.job.Job.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html,2,['test'],['test']
Testability,"lines may; see as much as a halving in latency.; (#13849) Fix; (#13788), improving; the error message when hl.logistic_regression_rows is provided; row or entry annotations for the dependent variable.; (#13888); hl.default_reference can now be passed an argument to change the; default reference genome. Bug Fixes. (#13702) Fix; (#13699) and; (#13693). Since; 0.2.96, pipelines that combined random functions; (e.g. hl.rand_unif) with index(..., all_matches=True) could; fail with a ClassCastException.; (#13707) Fix; (#13633).; hl.maximum_independent_set now accepts strings as the names of; individuals. It has always accepted structures containing a single; string field.; (#13713) Fix; (#13704), in which; Hail could encounter an IllegalArgumentException if there are too; many transient errors.; (#13730) Fix; (#13356) and; (#13409). In QoB; pipelines with 10K or more partitions, transient “Corrupted block; detected” errors were common. This was caused by incorrect retry; logic. That logic has been fixed.; (#13732) Fix; (#13721) which; manifested with the message “Missing Range header in response”. The; root cause was a bug in the Google Cloud Storage SDK on which we; rely. The fix is to update to a version without this bug. The buggy; version of GCS SDK was introduced in 0.2.123.; (#13759) Since Hail; 0.2.123, Hail would hang in Dataproc Notebooks due to; (#13690).; (#13755) Ndarray; concatenation now works with arrays with size zero dimensions.; (#13817) Mitigate; new transient error from Google Cloud Storage which manifests as; aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548).; (#13715) Fix; (#13697), a long; standing issue with QoB. When a QoB driver or worker fails, the; corresponding Batch Job will also appear as failed.; (#13829) Fix; (#13828). The Hail; combiner now properly imports PGT fields from GVCFs.; (#13805) Fix; (#13767).; hailctl dataproc submit now expands ~ in the --files and; -",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:22311,log,logic,22311,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['log'],['logic']
Testability,"ling BlockMatrix.transpose on; sparse, non-symmetric BlockMatrices.; (#8876) Fixed; “ChannelClosedException: null” in {Table, MatrixTable}.write. Version 0.2.42; Released 2020-05-27. New Features. (#8822) Add optional; non-centrality parameter to hl.pchisqtail.; (#8861) Add; contig_recoding option to hl.experimental.run_combiner. Bug fixes. (#8863) Fixes VCF; combiner to successfully import GVCFs with alleles called as .; (#8845) Fixed issue; where accessing an element of an ndarray in a call to Table.transmute; would fail.; (#8855) Fix crash in; filter_intervals. Version 0.2.41; Released 2020-05-15. Bug fixes. (#8799)(#8786); Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a; tuple value. hailctl dataproc. (#8790) Use; configured compute zone as default for hailctl dataproc connect; and hailctl dataproc modify. Version 0.2.40; Released 2020-05-12. VCF Combiner. (#8706) Add option to; key by both locus and alleles for final output. Bug fixes. (#8729) Fix assertion; error in Table.group_by(...).aggregate(...); (#8708) Fix assertion; error in reading tables and matrix tables with _intervals option.; (#8756) Fix return; type of LocusExpression.window to use locus’s reference genome; instead of default RG. Version 0.2.39; Released 2020-04-29. Bug fixes. (#8615) Fix contig; ordering in the CanFam3 (dog) reference genome.; (#8622) Fix bug that; causes inscrutable JVM Bytecode errors.; (#8645) Ease; unnecessarily strict assertion that caused errors when aggregating by; key (e.g. hl.experimental.spread).; (#8621); hl.nd.array now supports arrays with no elements; (e.g. hl.nd.array([]).reshape((0, 5))) and, consequently, matmul; with an inner dimension of zero. New features. (#8571); hl.init(skip_logging_configuration=True) will skip configuration; of Log4j. Users may use this to configure their own logging.; (#8588) Users who; manually build Python wheels will experience less unnecessary output; when doing so.; (#8572) Add; hl.parse_json which con",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:71149,assert,assertion,71149,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['assert'],['assertion']
Testability,"litatively, subsetting corresponds to the belief; that the filtered alleles are not real so we should discard any; probability mass associated with them.; The subset algorithm would produce the following:; GT: 1/1; GQ: 980; AD: 0,50. 0 | 980; 1 | 980 0; +-----------; 0 1. In summary:. GT: Set to most likely genotype based on the PLs ignoring the filtered allele(s).; AD: The filtered alleles’ columns are eliminated, e.g., filtering alleles 1 and 2 transforms 25,5,10,20 to 25,20.; DP: No change.; PL: The filtered alleles’ columns are eliminated and the remaining columns shifted so the minimum value is 0.; GQ: The second-lowest PL (after shifting). Downcode algorithm; The downcode algorithm (subset=False) recodes occurances of filtered alleles; to occurances of the reference allele (e.g. 1 -> 0 in our example). So the depths of filtered alleles in the AD field; are added to the depth of the reference allele. Where downcodeing filtered alleles merges distinct genotypes, the minimum PL is used (since PL is on a log scale, this roughly corresponds to adding probabilities). The PLs; are then re-normalized (shifted) so that the most likely genotype has a PL of 0, and GT is set to this genotype.; If an allele is filtered, this algorithm acts similarly to split_multi().; The downcoding algorithm would produce the following:; GT: 0/1; GQ: 10; AD: 35,50. 0 | 20; 1 | 0 10; +-----------; 0 1. In summary:. GT: Downcode filtered alleles to reference.; AD: The filtered alleles’ columns are eliminated and their value is added to the reference, e.g., filtering alleles 1 and 2 transforms 25,5,10,20 to 40,20.; DP: No change.; PL: Downcode filtered alleles to reference, combine PLs using minimum for each overloaded genotype, and shift so the overall minimum PL is 0.; GQ: The second-lowest PL (after shifting). Expression Variables; The following symbols are in scope for expr:. v (Variant): Variant; va: variant annotations; aIndex (Int): the index of the allele being tested. The following s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:50085,log,log,50085,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['log']
Testability,"lled packages, given the right; configuration options. Bug fixes. (#7070) Fix; unintentionally strict type error in MatrixTable.union_rows.; (#7170) Fix issues; created downstream of BlockMatrix.T.; (#7146) Fix bad; handling of edge cases in BlockMatrix.filter.; (#7182) Fix problem; parsing VCFs where lines end in an INFO field of type flag. Version 0.2.23; Released 2019-09-23. hailctl dataproc. (#7087) Added back; progress bar to notebooks, with links to the correct Spark UI url.; (#7104) Increased; disk requested when using --vep to address the “colony collapse”; cluster error mode. Bug fixes. (#7066) Fixed; generated code when methods from multiple reference genomes appear; together.; (#7077) Fixed crash; in hl.agg.group_by. New features. (#7009) Introduced; analysis pass in Python that mostly obviates the hl.bind and; hl.rbind operators; idiomatic Python that generates Hail; expressions will perform much better.; (#7076) Improved; memory management in generated code, add additional log statements; about allocated memory to improve debugging.; (#7085) Warn only; once about schema mismatches during JSON import (used in VEP,; Nirvana, and sometimes import_table.; (#7106); hl.agg.call_stats can now accept a number of alleles for its; alleles parameter, useful when dealing with biallelic calls; without the alleles array at hand. Performance. (#7086) Improved; performance of JSON import.; (#6981) Improved; performance of Hail min/max/mean operators. Improved performance of; split_multi_hts by an additional 33%.; (#7082)(#7096)(#7098); Improved performance of large pipelines involving many annotate; calls. Version 0.2.22; Released 2019-09-12. New features. (#7013) Added; contig_recoding to import_bed and import_locus_intervals. Performance. (#6969) Improved; performance of hl.agg.mean, hl.agg.stats, and; hl.agg.corr.; (#6987) Improved; performance of import_matrix_table.; (#7033)(#7049); Various improvements leading to overall 10-15% improvement. hailctl datap",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:85581,log,log,85581,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['log'],['log']
Testability,"llele(ref=AT, alt=A), AltAllele(ref=AT, alt=CT), AltAllele(ref=AT, alt=AGGT)]), 'laIndices': {0: 0, 1: 1, 2: 2}, 'raIndices': {0:0, 2: 1, 3: 2}}. Arguments. left (Variant) – Left variant to combine.; right (Variant) – Right variant to combine. ctt(c1: Int, c2: Int, c3: Int, c4: Int, minCellCount: Int): Struct{pValue:Double,oddsRatio:Double}. pValue (Double) – p-value; oddsRatio (Double) – odds ratio. Calculates p-value and odds ratio for 2x2 table. If any cell is lower than minCellCount Fishers exact test is used, otherwise faster chi-squared approximation is used.; Arguments. c1 (Int) – value for cell 1; c2 (Int) – value for cell 2; c3 (Int) – value for cell 3; c4 (Int) – value for cell 4; minCellCount (Int) – Minimum cell count for using chi-squared approximation. Dict(keys: Array[T], values: Array[U]): Dict[T, U]. Construct a Dict from an array of keys and an array of values.; Arguments. keys (Array[T]) – Keys of Dict.; values (Array[U]) – Values of Dict. dpois(x: Double, lambda: Double, logP: Boolean): Double. Returns Prob(\(X\) = x) from a Poisson distribution with rate parameter lambda.; Arguments. x (Double) – Non-negative number at which to compute the probability density.; lambda (Double) – Poisson rate parameter. Must be non-negative.; logP (Boolean) – If true, probabilities are returned as log(p). dpois(x: Double, lambda: Double): Double. Returns Prob(\(X\) = x) from a Poisson distribution with rate parameter lambda.; Arguments. x (Double) – Non-negative number at which to compute the probability density.; lambda (Double) – Poisson rate parameter. Must be non-negative. drop(s: Struct, identifiers: String*): Struct. Return a new Struct with the a subset of fields not matching identifiers.; let s = {gene: ""ACBD"", function: ""LOF"", nHet: 12} in drop(s, gene, function); result: {nHet: 12}. Arguments. s (Struct) – Struct to drop fields from.; identifiers (String*) – Field names to drop from s. Multiple arguments allowed. exp(x: Double): Double. Returns Euler’s n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:3434,log,logP,3434,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,1,['log'],['logP']
Testability,"lleles.; - `homozygote_count` (``array<int32>``) -- Number of homozygotes per; allele. One element per allele, including the reference.; - `call_rate` (``float64``) -- Fraction of calls neither missing nor filtered.; Equivalent to `n_called` / :meth:`.count_cols`.; - `n_called` (``int64``) -- Number of samples with a defined `GT`.; - `n_not_called` (``int64``) -- Number of samples with a missing `GT`.; - `n_filtered` (``int64``) -- Number of filtered entries.; - `n_het` (``int64``) -- Number of heterozygous samples.; - `n_non_ref` (``int64``) -- Number of samples with at least one called; non-reference allele.; - `het_freq_hwe` (``float64``) -- Expected frequency of heterozygous; samples under Hardy-Weinberg equilibrium. See; :func:`.functions.hardy_weinberg_test` for details.; - `p_value_hwe` (``float64``) -- p-value from two-sided test of Hardy-Weinberg; equilibrium. See :func:`.functions.hardy_weinberg_test` for details.; - `p_value_excess_het` (``float64``) -- p-value from one-sided test of; Hardy-Weinberg equilibrium for excess heterozygosity.; See :func:`.functions.hardy_weinberg_test` for details. Warning; -------; `het_freq_hwe` and `p_value_hwe` are calculated as in; :func:`.functions.hardy_weinberg_test`, with non-diploid calls; (``ploidy != 2``) ignored in the counts. As this test is only; statistically rigorous in the biallelic setting, :func:`.variant_qc`; sets both fields to missing for multiallelic variants. Consider using; :func:`~hail.methods.split_multi` to split multi-allelic variants beforehand. Parameters; ----------; mt : :class:`.MatrixTable`; Dataset.; name : :class:`str`; Name for resulting field. Returns; -------; :class:`.MatrixTable`; """"""; require_alleles_field(mt, 'variant_qc'). bound_exprs = {}; gq_dp_exprs = {}. def has_field_of_type(name, dtype):; return name in mt.entry and mt[name].dtype == dtype. if has_field_of_type('DP', hl.tint32):; gq_dp_exprs['dp_stats'] = hl.agg.stats(mt.DP).select('mean', 'stdev', 'min', 'max'). if has_field_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/qc.html:10487,test,test,10487,docs/0.2/_modules/hail/methods/qc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html,2,['test'],['test']
Testability,"loded. We consider iteration to have converged when every coordinate of; \(\beta\) changes by less than \(10^{-6}\) by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation.; A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of \(\beta\) under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests.; Here’s a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. Status; HomRef; Het; HomVar. Case; 1000; 10; 0. Control; 1000; 0; 0. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where x is genotype,; y is phenotype, and logistf is from the logistf package:; x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:11468,test,testing,11468,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['testing']
Testability,"logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association.; The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the Jeffrey’s; invariant prior. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the logreg.fit fields reflect the null model; otherwise,; they reflect the full model.; See; Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert’s notes; Statistical Theory.; Firth introduced his approach in; Bias reduction of maximum likelihood estimates, 1993.; Heinze and Schemper further analyze Firth’s approach in; A solution to the problem of separation in logistic regression, 2002.; Hail’s logistic regression tests correspond to the b.wald,; b.lrt, and b.score tests in EPACTS. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EPACTS results will currently only agree for variants with ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:13347,log,logreg,13347,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['log'],['logreg']
Testability,"logical (bool). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representation of 7 is 111, so:; >>> hl.eval(hl.bit_count(7)); 3. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression. hail.expr.functions.exp(x)[source]. hail.expr.functions.expit(x)[source]. hail.expr.functions.is_nan(x)[source]. hail.expr.functions.is_finite(x)[source]. hail.expr.functions.is_infinite(x)[source]. hail.expr.functions.log(x, base=None)[source]; Take the logarithm of the x with base base.; Examples; >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; If the base argument is not supplied, then the natural logarithm is used. Parameters:. x (float or Expression of type tfloat64); base (float or Expression of type tfloat64). Returns:; Expression of type tfloat64. hail.expr.functions.log10(x)[source]. hail.expr.functions.logit(x)[source]. hail.expr.functions.floor(x)[source]. hail.expr.functions.ceil(x)[source]. hail.expr.functions.sqrt(x)[source]. hail.expr.functions.sign(x)[source]; Returns the sign of a numeric value, array or ndarray.; Examples; >>> hl.eval(hl.sign(-1.23)); -1.0. >>> hl.eval(hl.sign([-4, 0, 5])); [-1, 0, 1]. >>> hl.eval(hl.sign([0.0, 3.14])); [0.0, 1.0]. >>> hl.eval(hl.sign(float('nan'))); nan. Notes; The sign function preserves type and maps nan to nan. Parameters:; x (NumericExpression, ArrayNumericExpression or NDArrayNumericExpression). Returns:; NumericExpression, ArrayNumericExpression or NDArrayNumericExpression. hail.expr.functions.min(*exprs, filte",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:7466,log,log,7466,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['log']
Testability,"logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**y_dict, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'LogisticRegression',; 'test': test,; 'yFields': y_field,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. result = Table(ir.MatrixToTableApply(mt._mir, config)). if not y_is_list:; result = result.transmute(**result.logistic_regression[0]). return result.persist(). # Helpers for logreg:; def mean_impute(hl_array):; non_missing_mean = hl.mean(hl_array, filter_missing=True); return hl_array.map(lambda entry: hl.coalesce(entry, non_missing_mean)). sigmoid = expit. def nd_max(hl_nd):; return hl.max(hl.array(hl_nd.reshape(-1))). def logreg_fit(; X: NDArrayNumericExpression, # (K,); y: NDArrayNumericExpression, # (N, K); null_fit: Optional[StructExpression],; max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Bernoulli(logit(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; # X is samples by covs.; # y is length num samples, for one cov.; n = X.shape[0]; m = X.shape[1]. if null_fit is None:; avg = y.sum() / n; logit_avg = hl.log(avg / (1 - avg)); b = hl.nd.hstack([hl.nd.array([logit_avg]), hl.nd.zeros((hl.int32(m - 1)))]); mu = sigmoid(X @ b); score = X.T @ (y - mu); # Reshape so we do a rowwise multiply; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:38793,log,logreg,38793,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logreg']
Testability,"loud.aiogoogle import GCSRequesterPaysConfiguration, get_gcs_requester_pays_configuration; from hailtop.fs.fs import FS; from hailtop.hail_event_loop import hail_event_loop; from hailtop.utils import secret_alnum_string. from . import __resource_str; from .backend.backend import local_jar_information; from .builtin_references import BUILTIN_REFERENCES. def _get_tmpdir(tmpdir):; if tmpdir is None:; tmpdir = '/tmp'; return tmpdir. def _get_local_tmpdir(local_tmpdir):; local_tmpdir = get_env_or_default(local_tmpdir, 'TMPDIR', 'file:///tmp'); r = urlparse(local_tmpdir); if not r.scheme:; r = r._replace(scheme='file'); elif r.scheme != 'file':; raise ValueError('invalid local_tmpfile: must use scheme file, got scheme {r.scheme}'); return urlunparse(r). def _get_log(log):; if log is None:; py_version = version(); log_dir = os.environ.get('HAIL_LOG_DIR'); if log_dir is None:; log_dir = os.getcwd(); log = hail.utils.timestamp_path(os.path.join(log_dir, 'hail'), suffix=f'-{py_version}.log'); return log. def convert_gcs_requester_pays_configuration_to_hadoop_conf_style(; x: Optional[Union[str, Tuple[str, List[str]]]],; ) -> Tuple[Optional[str], Optional[str]]:; if isinstance(x, str):; return x, None; if isinstance(x, tuple):; return x[0], "","".join(x[1]); return None, None. class HailContext(object):; @staticmethod; def create(; log: str,; quiet: bool,; append: bool,; tmpdir: str,; local_tmpdir: str,; default_reference: str,; global_seed: Optional[int],; backend: Backend,; ):; hc = HailContext(; log=log,; quiet=quiet,; append=append,; tmpdir=tmpdir,; local_tmpdir=local_tmpdir,; global_seed=global_seed,; backend=backend,; ); hc.initialize_references(default_reference); return hc. @typecheck_method(; log=str, quiet=bool, append=bool, tmpdir=str, local_tmpdir=str, global_seed=nullable(int), backend=Backend; ); def __init__(self, log, quiet, append, tmpdir, local_tmpdir, global_seed, backend):; assert not Env._hc. self._log = log. self._tmpdir = tmpdir; self._local_tmpdir = local_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:2119,log,log,2119,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,4,['log'],['log']
Testability,"lowed if; originating from a matrix table.""""""). col_key = list(ds.col_key); if len(col_key) != 1:; raise ValueError(""""""Matrix table must be keyed by a single; phenotype field.""""""). analyze('ld_score_regression/chi_squared_expr', chi_sq_exprs[0], ds._entry_indices); analyze('ld_score_regression/n_samples_expr', n_samples_exprs[0], ds._entry_indices). ds = ds._select_all(; row_exprs={; '__locus': ds.locus,; '__alleles': ds.alleles,; '__w_initial': weight_expr,; '__w_initial_floor': hl.max(weight_expr, 1.0),; '__x': ld_score_expr,; '__x_floor': hl.max(ld_score_expr, 1.0),; },; row_key=['__locus', '__alleles'],; col_exprs={'__y_name': ds[col_key[0]]},; col_key=['__y_name'],; entry_exprs={'__y': chi_sq_exprs[0], '__n': n_samples_exprs[0]},; ); ds = ds.annotate_entries(**{'__w': ds.__w_initial}). ds = ds.filter_rows(; hl.is_defined(ds.__locus); & hl.is_defined(ds.__alleles); & hl.is_defined(ds.__w_initial); & hl.is_defined(ds.__x); ). else:; assert isinstance(ds, Table); for y in chi_sq_exprs:; analyze('ld_score_regression/chi_squared_expr', y, ds._row_indices); for n in n_samples_exprs:; analyze('ld_score_regression/n_samples_expr', n, ds._row_indices). ys = ['__y{:}'.format(i) for i, _ in enumerate(chi_sq_exprs)]; ws = ['__w{:}'.format(i) for i, _ in enumerate(chi_sq_exprs)]; ns = ['__n{:}'.format(i) for i, _ in enumerate(n_samples_exprs)]. ds = ds.select(; **dict(; **{'__locus': ds.locus, '__alleles': ds.alleles, '__w_initial': weight_expr, '__x': ld_score_expr},; **{y: chi_sq_exprs[i] for i, y in enumerate(ys)},; **{w: weight_expr for w in ws},; **{n: n_samples_exprs[i] for i, n in enumerate(ns)},; ); ); ds = ds.key_by(ds.__locus, ds.__alleles). table_tmp_file = new_temp_file(); ds.write(table_tmp_file); ds = hl.read_table(table_tmp_file). hts = [; ds.select(**{; '__w_initial': ds.__w_initial,; '__w_initial_floor': hl.max(ds.__w_initial, 1.0),; '__x': ds.__x,; '__x_floor': hl.max(ds.__x, 1.0),; '__y_name': i,; '__y': ds[ys[i]],; '__w': ds[ws[i]],; '__n': hl.int(ds[ns[",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:10309,assert,assert,10309,docs/0.2/_modules/hail/experimental/ld_score_regression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html,2,['assert'],['assert']
Testability,"ls; Expression Language; Python API; Annotation Database; Other Resources; Hadoop Glob Patterns; SQL; Impala. Hail. Docs »; Other Resources »; Querying using SQL. View page source. Querying using SQL¶; Since Hail uses the Parquet file format for data storage, a Hail VDS can be queried using; Hadoop SQL tools, like Hive or Impala. This mode of access may be convenient for users; who have ad hoc queries that they are able to express in SQL.; Note that SQL access is read-only: it is not possible to write Hail datasets using; SQL at the current time. Impala¶; Each VDS should be registered in the Hive metastore to allow Impala to query it (Impala uses Hive’s metastore to store table metadata). This is done by creating an external table in Hive, the “external” part means that the data is managed by an entity outside Hive (and; Impala). The table schema is read from one of the Parquet files in the VDS file; hierarchy.; To generate a Hive file:. Copy a VCF file into HDFS. $ hadoop fs -put src/test/resources/sample.vcf.bgz sample.vcf.bgz. Convert the VCF file into a VDS using Hail:; >>> hc.import_vcf(""sample.vcf.bgz"").write(""sample.vds"", parquet_genotypes=True). Note the use of parquet_genotypes=True, which writes the genotype; information using Parquet structures, rather than an opaque binary; representation that cannot be queried using SQL. Register the VDS as a Hive table. $ PARQUET_DATA_FILE=$(hadoop fs -stat '%n' hdfs:///user/$USER/sample.vds/rdd.parquet/*.parquet | head -1); $ impala-shell -q ""CREATE EXTERNAL TABLE variants LIKE PARQUET 'hdfs:///user/$USER/sample.vds/rdd.parquet/$PARQUET_DATA_FILE' STORED AS PARQUET LOCATION 'hdfs:///user/$USER/sample.vds/rdd.parquet'"". It is good practice to run Impala’s COMPUTE STATS command on the newly-created table, so that subsequent queries run efficiently.; $ impala-shell -q ""COMPUTE STATS variants"". Before running any queries it’s worth understanding the table schema, which is easily; done by calling DESCRIBE on the table:; $ ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/sql.html:1173,test,test,1173,docs/0.1/sql.html,https://hail.is,https://hail.is/docs/0.1/sql.html,1,['test'],['test']
Testability,"lse(sa.pheno.height, %d)' % mean_height). orMissing(a: Boolean, b: T): T – If predicate evaluates to true, returns value. Otherwise, returns NA. pchisqtail(x: Double, df: Double): Double. Returns right-tail probability p for which p = Prob(\(Z^2\) > x) with \(Z^2\) a chi-squared random variable with degrees of freedom specified by df. x must be positive.; Arguments. x (Double) – Number at which to compute the probability.; df (Double) – Degrees of freedom. pcoin(p: Double): Boolean. Returns true with probability p. This function is non-deterministic.; Arguments. p (Double) – Probability. Should be between 0.0 and 1.0. pnorm(x: Double): Double. Returns left-tail probability p for which p = Prob(\(Z\) < x) with \(Z\) a standard normal random variable.; Arguments. x (Double) – Number at which to compute the probability. pow(b: Double, x: Double): Double. Returns b raised to the power of x.; Arguments. b (Double) – the base.; x (Double) – the exponent. ppois(x: Double, lambda: Double, lowerTail: Boolean, logP: Boolean): Double. If lowerTail equals true, returns Prob(\(X \leq\) x) where \(X\) is a Poisson random variable with rate parameter lambda. If lowerTail equals false, returns Prob(\(X\) > x).; Arguments. x (Double) – Non-negative number at which to compute the probability density.; lambda (Double) – Poisson rate parameter. Must be non-negative.; lowerTail (Boolean) – If false, returns the exclusive right-tail probability \(P(X > x)\).; logP (Boolean) – If true, probabilities are returned as log(p). ppois(x: Double, lambda: Double): Double. Returns the left-tail Prob(\(X \leq\) x) where \(X\) is a Poisson random variable with rate parameter lambda.; Arguments. x (Double) – Non-negative bound for the left-tail cumulative probability.; lambda (Double) – Poisson rate parameter. Must be non-negative. qchisqtail(p: Double, df: Double): Double. Returns right-quantile x for which p = Prob(\(Z^2\) > x) with \(Z^2\) a chi-squared random variable with degrees of freedom speci",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:13924,log,logP,13924,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,1,['log'],['logP']
Testability,"lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:; >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_rshift(x, y, logical=False)[source]; Bitwise right-shift x by y.; Examples; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With logical=False (default), the sign is preserved:; >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With logical=True, the sign bit is treated as any other:; >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; If logical is False, then the shift is a sign-preserving right shift.; If logical is True, then the shift is logical, with the sign bit; treated as any other bit.; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression); logical (bool). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representation of 7 is 111, so:; >>> hl.eval(hl.bit_count(7)); 3. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression. hail.expr.functions.exp(x)[source]. hail.expr.functions.expit(x)[source]. hail.expr.functions.is_nan(x)[source]. hail.expr.functions.is_finite(x)[source]. hail.expr.f",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:6228,log,logical,6228,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,2,['log'],['logical']
Testability,"lter(nodes.mis_nodes.contains(nodes.node), keep); nodes = nodes.select_globals(); if keyed:; return nodes.key_by('node').distinct(); return nodes. def require_col_key_str(dataset: MatrixTable, method: str):; if not len(dataset.col_key) == 1 or dataset[next(iter(dataset.col_key))].dtype != hl.tstr:; raise ValueError(; f""Method '{method}' requires column key to be one field of type 'str', found ""; f""{list(str(x.dtype) for x in dataset.col_key.values())}""; ). def require_table_key_variant(ht, method):; if (; list(ht.key) != ['locus', 'alleles']; or not isinstance(ht['locus'].dtype, tlocus); or not ht['alleles'].dtype == tarray(tstr); ):; raise ValueError(; ""Method '{}' requires key to be two fields 'locus' (type 'locus<any>') and ""; ""'alleles' (type 'array<str>')\n""; "" Found:{}"".format(method, ''.join(""\n '{}': {}"".format(k, str(ht[k].dtype)) for k in ht.key)); ). def require_row_key_variant(dataset, method):; if isinstance(dataset, Table):; key = dataset.key; else:; assert isinstance(dataset, MatrixTable); key = dataset.row_key; if (; list(key) != ['locus', 'alleles']; or not isinstance(dataset['locus'].dtype, tlocus); or not dataset['alleles'].dtype == tarray(tstr); ):; raise ValueError(; ""Method '{}' requires row key to be two fields 'locus' (type 'locus<any>') and ""; ""'alleles' (type 'array<str>')\n""; "" Found:{}"".format(method, ''.join(""\n '{}': {}"".format(k, str(dataset[k].dtype)) for k in key)); ). def require_alleles_field(dataset, method):; if 'alleles' not in dataset.row:; raise ValueError(f""Method '{method}' requires a field 'alleles' (type 'array<str>')\n""); if dataset.alleles.dtype != tarray(tstr):; raise ValueError(; f""Method '{method}' requires a field 'alleles' (type 'array<str>')\n""; f"" Found:\n""; f"" 'alleles': {dataset.alleles.dtype}""; ). def require_row_key_variant_w_struct_locus(dataset, method):; if (; list(dataset.row_key) != ['locus', 'alleles']; or not dataset['alleles'].dtype == tarray(tstr); or (; not isinstance(dataset['locus'].dtype, tlocus); ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/misc.html:7754,assert,assert,7754,docs/0.2/_modules/hail/methods/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html,2,['assert'],['assert']
Testability,"ltering variants and genotypes; Annotating with expressions; Aggregables; Count; Sum; Fraction; Stats; Counter; FlatMap; Take; Collect; takeBy; Aggregating by key. Expression Language; Python API; Annotation Database; Other Resources. Hail. Docs »; Tutorials. View page source. Tutorials¶; To take Hail for a test drive, go through our tutorials. These can be viewed here in the documentation,; but we recommend instead that you run them yourself with Jupyter.; Download the Hail distribution from our getting started page, and follow; the instructions there to set up the Hail. Inside the unzipped distribution folder, you’ll find; a tutorials/ directory. cd to this directory and run jhail to start the notebook; server, then click a notebook to begin!. Hail Overview¶; This notebook is designed to provide a broad overview of Hail’s functionality, with emphasis on the; functionality to manipulate and query a genetic dataset. We walk through a genome-wide SNP association; test, and demonstrate the need to control for confounding caused by population stratification. Overview; Check for tutorial data or download if necessary; Loading data from disk; Getting to know our data; Integrate sample annotations; Query functions and the Hail Expression Language; Quality Control; Let’s do a GWAS!; Confounded!; Rare variant analysis; Eplilogue. Introduction to the expression language¶; This notebook starts with the basics of the Hail expression language, and builds up practical experience; with the type system, syntax, and functionality. By the end of this notebook, we hope that you will be; comfortable enough to start using the expression language to slice, dice, filter, and query genetic data. Introduction to the Expression Language; Setup; Hail Expression Language; Hail Types; Primitive Types; Missingness; Let; Conditionals; Compound Types; Numeric Arrays; Exercise; Structs; Genetic Types; Demo variables; Wrangling complex nested types; Learn more!; Exercises. Expression language: quer",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials-landing.html:1966,test,test,1966,docs/0.1/tutorials-landing.html,https://hail.is,https://hail.is/docs/0.1/tutorials-landing.html,1,['test'],['test']
Testability,"lternate is None:; plural = orig + 's'; else:; plural = alternate; return hl.if_else(n == 1, orig, plural). def plural(orig, n, alternate=None):; if n == 1:; return orig; elif alternate:; return alternate; else:; return orig + 's'. def get_obj_metadata(obj):; from hail.expr.expressions import ArrayStructExpression, SetStructExpression, StructExpression; from hail.matrixtable import GroupedMatrixTable, MatrixTable; from hail.table import GroupedTable, Table; from hail.utils import Struct. def table_error(index_obj):; def fmt_field(field):; assert field in index_obj._fields; inds = index_obj[field]._indices; if inds == index_obj._global_indices:; return ""'{}' [globals]"".format(field); elif inds == index_obj._row_indices:; return ""'{}' [row]"".format(field); elif inds == index_obj._col_indices: # Table will never get here; return ""'{}' [col]"".format(field); else:; assert inds == index_obj._entry_indices; return ""'{}' [entry]"".format(field). return fmt_field. def struct_error(s):; def fmt_field(field):; assert field in s._fields; return ""'{}'"".format(field). return fmt_field. if isinstance(obj, MatrixTable):; return 'MatrixTable', MatrixTable, table_error(obj), True; elif isinstance(obj, GroupedMatrixTable):; return 'GroupedMatrixTable', GroupedMatrixTable, table_error(obj._parent), True; elif isinstance(obj, Table):; return 'Table', Table, table_error(obj), True; elif isinstance(obj, GroupedTable):; return 'GroupedTable', GroupedTable, table_error(obj), False; elif isinstance(obj, Struct):; return 'Struct', Struct, struct_error(obj), False; elif isinstance(obj, StructExpression):; return 'StructExpression', StructExpression, struct_error(obj), True; elif isinstance(obj, ArrayStructExpression):; return 'ArrayStructExpression', ArrayStructExpression, struct_error(obj), True; elif isinstance(obj, SetStructExpression):; return 'SetStructExpression', SetStructExpression, struct_error(obj), True; else:; raise NotImplementedError(obj). def get_nice_attr_error(obj, item):; clas",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/misc.html:6747,assert,assert,6747,docs/0.2/_modules/hail/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/misc.html,2,['assert'],['assert']
Testability,"lude before the locus. Truncates at 1.; after : :class:`.Expression` of type :py:data:`.tint32`; Number of bases to include after the locus. Truncates at; contig length. Returns; -------; :class:`.IntervalExpression`; """"""; start_pos = hl.max(1, self.position - before); rg = self.dtype.reference_genome; end_pos = hl.min(hl.contig_length(self.contig, rg), self.position + after); return hl.interval(; start=hl.locus(self.contig, start_pos, reference_genome=rg),; end=hl.locus(self.contig, end_pos, reference_genome=rg),; includes_start=True,; includes_end=True,; ). def _extra_summary_fields(self, agg_result):; return {'Contig Counts': agg_result}. def _summary_aggs(self):; return hl.agg.filter(hl.is_defined(self), hl.agg.counter(self.contig)). [docs]class IntervalExpression(Expression):; """"""Expression of type :class:`.tinterval`. >>> interval = hl.interval(3, 11); >>> locus_interval = hl.parse_locus_interval(""1:53242-90543""); """""". [docs] @typecheck_method(value=expr_any); def contains(self, value):; """"""Tests whether a value is contained in the interval. Examples; --------. >>> hl.eval(interval.contains(3)); True. >>> hl.eval(interval.contains(11)); False. Parameters; ----------; value :; Object with type matching the interval point type. Returns; -------; :class:`.BooleanExpression`; ``True`` if `value` is contained in the interval, ``False`` otherwise.; """"""; if self.dtype.point_type != value.dtype:; raise TypeError(""expected '{}', found: '{}'"".format(self.dtype.point_type, value.dtype)); return self._method(""contains"", tbool, value). [docs] @typecheck_method(interval=expr_interval(expr_any)); def overlaps(self, interval):; """"""True if the the supplied interval contains any value in common with this one. Examples; --------. >>> hl.eval(interval.overlaps(hl.interval(5, 9))); True. >>> hl.eval(interval.overlaps(hl.interval(11, 20))); False. Parameters; ----------; interval : :class:`.Expression` with type :class:`.tinterval`; Interval object with the same point type. Returns;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:91575,Test,Tests,91575,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,1,['Test'],['Tests']
Testability,"lue in common with this one.; Examples; >>> hl.eval(interval.overlaps(hl.interval(5, 9))); True. >>> hl.eval(interval.overlaps(hl.interval(11, 20))); False. Parameters:; interval (Expression with type tinterval) – Interval object with the same point type. Returns:; BooleanExpression. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. property start; Returns the start point.; Examples; >>> hl.eval(interval.start); 3. Returns:; Expression. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.IntervalExpression.html:7461,test,tested,7461,docs/0.2/hail.expr.IntervalExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.IntervalExpression.html,1,['test'],['tested']
Testability,"lues,; \(\mathrm{P}(\mathrm{Het})\) and \(\mathrm{P}(\mathrm{HomVar})\) are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1.; The example above considers a model of the form. \[\mathrm{Prob}(\mathrm{isCase}) = \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt} + \beta_2 \, \mathrm{age} + \beta_3 \, \mathrm{isFemale} + \varepsilon), \quad \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid; function, the; genotype \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; \(\mathrm{isFemale}\) is coded as 1 for true (female) and; 0 for false (male). The null model sets \(\beta_1 = 0\).; The resulting variant annotations depend on the test statistic; as shown in the tables below. Test; Annotation; Type; Value. Wald; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). Wald; va.logreg.se; Double; estimated standard error, \(\widehat{\mathrm{se}}\). Wald; va.logreg.zstat; Double; Wald \(z\)-statistic, equal to \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until converg",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:111187,log,logreg,111187,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logreg']
Testability,"lumn-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_r",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:37081,test,test,37081,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"ly. The erroneous value 0.991 is due to quasi-complete separation. Moving one of the 10 hets from case to control eliminates this quasi-complete separation; the p-values from R are then 0.0373, 0.0111, and 0.0116, respectively, as expected for a less significant association.; The Firth test reduces bias from small counts and resolves the issue of separation by penalizing maximum likelihood estimation by the Jeffrey’s invariant prior. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton method is linear rather than quadratic. For Firth, 100 iterations are attempted for the null model and, if that is successful, for the full model as well. In testing we find 20 iterations nearly always suffices. If the null model fails to converge, then the sa.lmmreg.fit annotations reflect the null model; otherwise, they reflect the full model.; See Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants for an empirical comparison of the logistic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert’s notes Statistical Theory. Firth introduced his approach in Bias reduction of maximum likelihood estimates, 1993. Heinze and Schemper further analyze Firth’s approach in A solution to the problem of separation in logistic regression, 2002.; Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; Phenotype and covariate sample annotations may also be specified using programmatic expressions without identifiers, such as:; if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation sa.fam.isCase added by importing a FAM file with case-control phenotype, case is 1 and control is 0.; Hail’s logistic regressio",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:115332,test,testing,115332,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,3,"['log', 'test']","['logistic', 'testing', 'tests']"
Testability,"malizing the PL likelihoods (converted from the Phred-scale) to sum to 1. The example above considers a model of the form. .. math::. \mathrm{Prob}(\mathrm{isCase}) = \mathrm{sigmoid}(\\beta_0 + \\beta_1 \, \mathrm{gt} + \\beta_2 \, \mathrm{age} + \\beta_3 \, \mathrm{isFemale} + \\varepsilon), \quad \\varepsilon \sim \mathrm{N}(0, \sigma^2). where :math:`\mathrm{sigmoid}` is the `sigmoid; function <https://en.wikipedia.org/wiki/Sigmoid_function>`__, the; genotype :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; :math:`\mathrm{isFemale}` is coded as 1 for true (female) and; 0 for false (male). The null model sets :math:`\\beta_1 = 0`. The resulting variant annotations depend on the test statistic; as shown in the tables below. ========== =================== ====== =====; Test Annotation Type Value; ========== =================== ====== =====; Wald ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; Wald ``va.logreg.se`` Double estimated standard error, :math:`\widehat{\mathrm{se}}`; Wald ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`; Wald ``va.logreg.pval`` Double Wald p-value testing :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant ann",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:141699,log,logreg,141699,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"mance, check that LAPACK natives are being properly loaded (see “BLAS and LAPACK” in Getting Started).; Given the eigendecomposition, fitting the global model (Step 4) takes on the order of a few seconds on master. Association testing (Step 5) is fully distributed by variant with per-variant time complexity that is completely independent of the number of sample covariates and dominated by multiplication of the genotype vector \(v\) by the matrix of eigenvectors \(U^T\) as described below, which we accelerate with a sparse representation of \(v\). The matrix \(U^T\) has size about \(8n^2\) bytes and is currently broadcast to each Spark executor. For example, with 15k samples, storing \(U^T\) consumes about 3.6GB of memory on a 16-core worker node with two 8-core executors. So for large \(n\), we recommend using a high-memory configuration such as highmem workers.; Linear mixed model; lmmreg() estimates the genetic proportion of residual phenotypic variance (narrow-sense heritability) under a kinship-based linear mixed model, and then optionally tests each variant for association using the likelihood ratio test. Inference is exact.; We first describe the sample-covariates-only model used to estimate heritability, which we simply refer to as the global model. With \(n\) samples and \(c\) sample covariates, we define:. \(y = n \times 1\) vector of phenotypes; \(X = n \times c\) matrix of sample covariates and intercept column of ones; \(K = n \times n\) kinship matrix; \(I = n \times n\) identity matrix; \(\beta = c \times 1\) vector of covariate coefficients; \(\sigma_g^2 =\) coefficient of genetic variance component \(K\); \(\sigma_e^2 =\) coefficient of environmental variance component \(I\); \(\delta = \frac{\sigma_e^2}{\sigma_g^2} =\) ratio of environmental and genetic variance component coefficients; \(h^2 = \frac{\sigma_g^2}{\sigma_g^2 + \sigma_e^2} = \frac{1}{1 + \delta} =\) genetic proportion of residual phenotypic variance. Under a linear mixed model, \(y\) is ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:98195,test,tests,98195,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,2,['test'],"['test', 'tests']"
Testability,"mat datasets from disk. Simple pipelines may; see as much as a halving in latency.; (#13849) Fix; (#13788), improving; the error message when hl.logistic_regression_rows is provided; row or entry annotations for the dependent variable.; (#13888); hl.default_reference can now be passed an argument to change the; default reference genome. Bug Fixes. (#13702) Fix; (#13699) and; (#13693). Since; 0.2.96, pipelines that combined random functions; (e.g. hl.rand_unif) with index(..., all_matches=True) could; fail with a ClassCastException.; (#13707) Fix; (#13633).; hl.maximum_independent_set now accepts strings as the names of; individuals. It has always accepted structures containing a single; string field.; (#13713) Fix; (#13704), in which; Hail could encounter an IllegalArgumentException if there are too; many transient errors.; (#13730) Fix; (#13356) and; (#13409). In QoB; pipelines with 10K or more partitions, transient “Corrupted block; detected” errors were common. This was caused by incorrect retry; logic. That logic has been fixed.; (#13732) Fix; (#13721) which; manifested with the message “Missing Range header in response”. The; root cause was a bug in the Google Cloud Storage SDK on which we; rely. The fix is to update to a version without this bug. The buggy; version of GCS SDK was introduced in 0.2.123.; (#13759) Since Hail; 0.2.123, Hail would hang in Dataproc Notebooks due to; (#13690).; (#13755) Ndarray; concatenation now works with arrays with size zero dimensions.; (#13817) Mitigate; new transient error from Google Cloud Storage which manifests as; aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548).; (#13715) Fix; (#13697), a long; standing issue with QoB. When a QoB driver or worker fails, the; corresponding Batch Job will also appear as failed.; (#13829) Fix; (#13828). The Hail; combiner now properly imports PGT fields from GVCFs.; (#13805) Fix; (#13767).; hailctl dataproc submit ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:22299,log,logic,22299,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['log'],['logic']
Testability,"math:`\delta` grid with values in .tsv tabular form. Use ``grep 'lmmreg:' hail.log`` to find the lines just above each table. If Step 5 is performed, :py:meth:`.lmmreg` also adds four linear regression variant annotations. +------------------------+--------+-------------------------------------------------------------------------+; | Annotation | Type | Value |; +========================+========+=========================================================================+; | ``va.lmmreg.beta`` | Double | fit genotype coefficient, :math:`\hat\\beta_0` |; +------------------------+--------+-------------------------------------------------------------------------+; | ``va.lmmreg.sigmaG2`` | Double | fit coefficient of genetic variance component, :math:`\hat{\sigma}_g^2` |; +------------------------+--------+-------------------------------------------------------------------------+; | ``va.lmmreg.chi2`` | Double | :math:`\chi^2` statistic of the likelihood ratio test |; +------------------------+--------+-------------------------------------------------------------------------+; | ``va.lmmreg.pval`` | Double | :math:`p`-value |; +------------------------+--------+-------------------------------------------------------------------------+. Those variants that don't vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations. The simplest way to export all resulting annotations is:. >>> lmm_vds.export_variants('output/lmmreg.tsv.bgz', 'variant = v, va.lmmreg.*'); >>> lmmreg_results = lmm_vds.globals['lmmreg']; ; By default, genotypes values are given by hard call genotypes (``g.gt``).; If ``use_dosages=True``, then genotype values for per-variant association are defined by the dosage; :math:`\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})`. For Phred-scaled values,; :math:`\mathrm{P}(\mathrm{Het})` and :math:`\mathrm{P}(\mathrm{HomVar})` are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to su",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:123266,test,test,123266,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['test']
Testability,"max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`, :func:`.if_else`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `cond",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:12639,test,tests,12639,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['tests']
Testability,"me_type); def remove_liftover(self, dest_reference_genome):; """"""Remove liftover to `dest_reference_genome`. Parameters; ----------; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; """"""; if dest_reference_genome.name in self._liftovers:; del self._liftovers[dest_reference_genome.name]; Env.backend().remove_liftover(self.name, dest_reference_genome.name). [docs] @typecheck_method(chain_file=str, dest_reference_genome=reference_genome_type); def add_liftover(self, chain_file, dest_reference_genome):; """"""Register a chain file for liftover. Examples; --------; Access GRCh37 and GRCh38 using :func:`~hail.get_reference`:. >>> rg37 = hl.get_reference('GRCh37') # doctest: +SKIP; >>> rg38 = hl.get_reference('GRCh38') # doctest: +SKIP. Add a chain file from 37 to 38:. >>> rg37.add_liftover('gs://hail-common/references/grch37_to_grch38.over.chain.gz', rg38) # doctest: +SKIP. Notes; -----; This method can only be run once per reference genome. Use; :meth:`~has_liftover` to test whether a chain file has been registered. The chain file format is described; `here <https://genome.ucsc.edu/goldenpath/help/chain.html>`__. Chain files are hosted on google cloud for some of Hail's built-in; references:. **GRCh37 to GRCh38**; gs://hail-common/references/grch37_to_grch38.over.chain.gz. **GRCh38 to GRCh37**; gs://hail-common/references/grch38_to_grch37.over.chain.gz. Public download links are available; `here <https://console.cloud.google.com/storage/browser/hail-common/references/>`__. Parameters; ----------; chain_file : :class:`str`; Path to chain file. Can be compressed (GZIP) or uncompressed.; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to convert to.; """""". Env.backend().add_liftover(self.name, chain_file, dest_reference_genome.name); if dest_reference_genome.name in self._liftovers:; raise KeyError(f""Liftover already exists from {self.name} to {dest_reference_genome.name}.""); if dest_reference_genome.name == self.name:; raise V",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:14061,test,test,14061,docs/0.2/_modules/hail/genetics/reference_genome.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html,2,['test'],['test']
Testability,"methods; nd; utils; linalg; stats; genetics; plot; ggplot; vds; experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; Experimental; ldscsim. View page source. ldscsim. Models for SNP effects:; Infinitesimal (can simulate n correlated traits); Spike & slab (can simulate 2 correlated traits); Annotation-informed. Features:; Field aggregation tools for annotation-informed model and; population stratification with many covariates.; Automatic adjustment of genetic correlation parameters; to allow for the joint simulation of up to 100 randomly; correlated phenotypes.; Methods for binarizing phenotypes to have a certain prevalence; and for adding ascertainment bias to binarized phenotypes. simulate_phenotypes(mt, genotype, h2[, pi, ...]); Simulate phenotypes for testing LD score regression. make_betas(mt, h2[, pi, annot, rg]); Generates betas under different models. multitrait_inf(mt[, h2, rg, cov_matrix, seed]); Generates correlated betas for multi-trait infinitesimal simulations for any number of phenotypes. multitrait_ss(mt, h2, pi[, rg, seed]); Generates spike & slab betas for simulation of two correlated phenotypes. get_cov_matrix(h2, rg[, psd_rg]); Creates covariance matrix for simulating correlated SNP effects. calculate_phenotypes(mt, genotype, beta, h2); Calculates phenotypes by multiplying genotypes and betas. normalize_genotypes(genotype); Normalizes genotypes to have mean 0 and variance 1 at each SNP. annotate_all(mt[, row_exprs, col_exprs, ...]); Equivalent of _annotate_all, but checks source MatrixTable of exprs. ascertainment_bias(mt, y, P); Adds ascertainment bias to a binary phenotype to give it a sample prevalence of P = cases/(cases+controls). binarize(mt, y, K[, exact]); Binarize phenotype y such that it has prevalence K = ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/experimental/ldscsim.html:1288,test,testing,1288,docs/0.2/experimental/ldscsim.html,https://hail.is,https://hail.is/docs/0.2/experimental/ldscsim.html,1,['test'],['testing']
Testability,"mic locus. Parameters; ----------; alleles : :obj:`list` of :obj:`int`; List of alleles that compose the call.; phased : :obj:`bool`; If ``True``, the alleles are phased and the order is specified by; `alleles`. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.GT.take(5`)``. This is rare; it is much; more common to manipulate the :class:`.CallExpression` object, which is; constructed using the following functions:. - :func:`.call`; - :func:`.unphased_diploid_gt_index_call`; - :func:`.parse_call`; """""". def __init__(self, alleles, phased=False):; # Intentionally not using the type check annotations which are too slow.; assert isinstance(alleles, Sequence); assert isinstance(phased, bool). if len(alleles) > 2:; raise NotImplementedError(""Calls with greater than 2 alleles are not supported.""); self._phased = phased; ploidy = len(alleles); if phased or ploidy < 2:; self._alleles = alleles; else:; assert ploidy == 2; a0 = alleles[0]; a1 = alleles[1]; if a1 < a0:; a0, a1 = a1, a0; self._alleles = [a0, a1]. def __str__(self):; n = self.ploidy; if n == 0:; if self._phased:; return '|-'; return '-'. if n == 1:; if self._phased:; return f'|{self._alleles[0]}'; return str(self._alleles[0]). assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; if self._phased:; return f'{a0}|{a1}'; return f'{a0}/{a1}'. def __repr__(self):; return 'Call(alleles=%s, phased=%s)' % (self._alleles, self._phased). def __eq__(self, other):; return (; (self._phased == other._phased and self._alleles == other._alleles); if isinstance(other, Call); else NotImplemented; ). def __hash__(self):; return hash(self._phased) ^ hash(tuple(self._alleles)). def __getitem__(self, item):; """"""Get the i*th* allele. Returns; -------; :obj:`int`; """"""; return self._alleles[item]. @property; def alleles(self) -> Sequence[int]:; """"""Get the alleles of this call. Returns; -------; :obj:`list` of :obj:`int`; """"""; return self._alleles. @property; def ploidy",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/call.html:1623,assert,assert,1623,docs/0.2/_modules/hail/genetics/call.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html,2,['assert'],['assert']
Testability,"millions of variants with very low minor allele count. The maximum likelihood estimate of :math:`\\beta` under logistic regression is then undefined but convergence may still occur after a large number of iterations due to a very flat likelihood surface. In testing, we find that such variants produce a secondary bump from 10 to 15 iterations in the histogram of number of iterations per variant. We also find that this faux convergence produces large standard errors and large (insignificant) p-values. To not miss such variants, consider using Firth logistic regression, linear regression, or group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic, and linear regression models to this data, where ``x`` is genotype, ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085, and 0.0016, respectively. The erroneous value 0.991 is due to quasi-complete separation. Moving one of the 10 hets from case to control eliminates this quasi-complete separation; the p-values from R are then 0.0373, 0.0111, and 0.0116, respectively, as expected for a less significant association. The Firth test reduces bias from small counts and resolves the issue of separation by penalizing maximum likelihood estimation by the `Jeffrey's invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton me",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:144929,log,logistic,144929,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,4,['log'],"['logistf', 'logistic']"
Testability,"mn header. Otherwise, each compound column key is converted to; JSON and used as a column header. For example:. >>> small_mt = small_mt.key_cols_by(s=small_mt.sample_idx, family='fam1'); >>> small_mt.GT.export('output/gt-no-header.tsv'); >>> with open('output/gt-no-header.tsv', 'r') as f:; ... for line in f:; ... print(line, end=''); locus	alleles	{""s"":0,""family"":""fam1""}	{""s"":1,""family"":""fam1""}	{""s"":2,""family"":""fam1""}	{""s"":3,""family"":""fam1""}; 1:1	[""A"",""C""]	0/1	0/0	0/1	0/0; 1:2	[""A"",""C""]	1/1	0/1	0/1	0/1; 1:3	[""A"",""C""]	0/0	0/1	0/0	0/0; 1:4	[""A"",""C""]	0/1	1/1	0/1	0/1. Parameters; ----------; path : :class:`str`; The path to which to export.; delimiter : :class:`str`; The string for delimiting columns.; missing : :class:`str`; The string to output for missing values.; header : :obj:`bool`; When ``True`` include a header line.; """"""; uid = Env.get_uid(); self_name, ds = self._to_relational_preserving_rows_and_cols(uid); if isinstance(ds, hl.Table):; ds.export(output=path, delimiter=delimiter, header=header); else:; assert len(self._indices.axes) == 2; entries, cols = Env.get_uid(), Env.get_uid(); t = ds.select_cols().localize_entries(entries, cols); t = t.order_by(*t.key); output_col_name = Env.get_uid(); entry_array = t[entries]; if self_name:; entry_array = hl.map(lambda x: x[self_name], entry_array); entry_array = hl.map(lambda x: hl.if_else(hl.is_missing(x), missing, hl.str(x)), entry_array); file_contents = t.select(; **{k: hl.str(t[k]) for k in ds.row_key}, **{output_col_name: hl.delimit(entry_array, delimiter)}; ); if header:; col_key = t[cols]; if len(ds.col_key) == 1:; col_key = hl.map(lambda x: x[0], col_key); column_names = hl.map(hl.str, col_key).collect(_localize=False)[0]; header_table = (; hl.utils.range_table(1); .key_by(); .select(**{k: k for k in ds.row_key}, **{output_col_name: hl.delimit(column_names, delimiter)}); ); file_contents = header_table.union(file_contents); file_contents.export(path, delimiter=delimiter, header=False). [docs] @typecheck_metho",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html:30910,assert,assert,30910,docs/0.2/_modules/hail/expr/expressions/base_expression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html,2,['assert'],['assert']
Testability,"mple, aggregate genotypes across variants with that key to produce a numeric score.; ``agg_expr`` must be of numeric type and has the following symbols are in scope:. - ``s`` (*Sample*): sample; - ``sa``: sample annotations; - ``global``: global annotations; - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``. Note that ``v``, ``va``, and ``g`` are accessible through; `Aggregable methods <https://hail.is/hail/types.html#aggregable>`_ on ``gs``. The resulting **sample key table** has key column ``key_name`` and a numeric column of scores for each sample; named by the sample ID. 3) For each key, fit the logistic regression model using the supplied phenotype, covariates, and test.; The model and tests are those of :py:meth:`.logreg` with sample genotype ``gt`` replaced by the; score in the sample key table. For each key, missing scores are mean-imputed across all samples. The resulting **logistic regression key table** has key column of type String given by the ``key_name``; parameter and additional columns corresponding to the fields of the ``va.logreg`` schema given for ``test``; in :py:meth:`.logreg`. :py:meth:`.logreg_burden` returns both the logistic regression key table and the sample key table. :param str key_name: Name to assign to key column of returned key tables. :param str variant_keys: Variant annotation path for the TArray or TSet of keys associated to each variant. :param bool single_key: if true, ``variant_keys`` is interpreted as a single (or missing) key per variant,; rather than as a collection of keys. :param str agg_expr: Sample aggregation expression (per key). :param str test: Statistical test, one of: 'wald', 'lrt', 'score', or 'firth'. :param str y: Response expression. :param covariates: list of covariate expressions.; :type covariates: list of str. :return: Tuple of logistic regression key table and sample aggregation key table.; :rtype: (:py:class:`.KeyTable`, :py:class:`.KeyTable`); """""". r = self._jvdf.logregBur",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:153030,log,logistic,153030,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logistic']
Testability,"mport SparkBackend. log = _get_log(log); tmpdir = _get_tmpdir(tmp_dir); local_tmpdir = _get_local_tmpdir(local_tmpdir); optimizer_iterations = get_env_or_default(_optimizer_iterations, 'HAIL_OPTIMIZER_ITERATIONS', 3). app_name = app_name or 'Hail'; (; gcs_requester_pays_project,; gcs_requester_pays_buckets,; ) = convert_gcs_requester_pays_configuration_to_hadoop_conf_style(; get_gcs_requester_pays_configuration(; gcs_requester_pays_configuration=gcs_requester_pays_configuration,; ); ); backend = SparkBackend(; idempotent,; sc,; spark_conf,; app_name,; master,; local,; log,; quiet,; append,; min_block_size,; branching_factor,; tmpdir,; local_tmpdir,; skip_logging_configuration,; optimizer_iterations,; gcs_requester_pays_project=gcs_requester_pays_project,; gcs_requester_pays_buckets=gcs_requester_pays_buckets,; copy_log_on_error=copy_log_on_error,; ); if not backend.fs.exists(tmpdir):; backend.fs.mkdir(tmpdir). HailContext.create(log, quiet, append, tmpdir, local_tmpdir, default_reference, global_seed, backend); if not quiet:; connect_logger(backend._utils_package_object, 'localhost', 12888). @typecheck(; billing_project=nullable(str),; remote_tmpdir=nullable(str),; log=nullable(str),; quiet=bool,; append=bool,; tmpdir=nullable(str),; local_tmpdir=nullable(str),; default_reference=enumeration(*BUILTIN_REFERENCES),; global_seed=nullable(int),; disable_progress_bar=nullable(bool),; driver_cores=nullable(oneof(str, int)),; driver_memory=nullable(str),; worker_cores=nullable(oneof(str, int)),; worker_memory=nullable(str),; name_prefix=nullable(str),; token=nullable(str),; gcs_requester_pays_configuration=nullable(oneof(str, sized_tupleof(str, sequenceof(str)))),; regions=nullable(sequenceof(str)),; gcs_bucket_allow_list=nullable(sequenceof(str)),; ); async def init_batch(; *,; billing_project: Optional[str] = None,; remote_tmpdir: Optional[str] = None,; log: Optional[str] = None,; quiet: bool = False,; append: bool = False,; tmpdir: Optional[str] = None,; local_tmpdir: Op",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:16327,log,log,16327,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['log'],['log']
Testability,"mpute sex of samples by calculating inbreeding coefficient on the X chromosome. join; Join two variant datasets. ld_matrix; Computes the linkage disequilibrium (correlation) matrix for the variants in this VDS. ld_prune; Prune variants in linkage disequilibrium (LD). linreg; Test each variant for association using linear regression. linreg3; Test each variant for association with multiple phenotypes using linear regression. linreg_burden; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the linear regression model. linreg_multi_pheno; Test each variant for association with multiple phenotypes using linear regression. lmmreg; Use a kinship-based linear mixed model to estimate the genetic component of phenotypic variance (narrow-sense heritability) and optionally test each variant for association. logreg; Test each variant for association using logistic regression. logreg_burden; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the logistic regression model. make_table; Produce a key with one row per variant and one or more columns per sample. mendel_errors; Find Mendel errors; count per variant, individual and nuclear family. min_rep; Gives minimal, left-aligned representation of alleles. naive_coalesce; Naively descrease the number of partitions. num_partitions; Number of partitions. pc_relate; Compute relatedness estimates between individuals using a variant of the PC-Relate method. pca; Run Principal Component Analysis (PCA) on the matrix of genotypes. persist; Persist this variant dataset to memory and/or disk. query_genotypes; Performs aggregation queries over genotypes, and returns Python object(s). query_genotypes_typed; Performs aggregation queries over genotypes, and returns Python object(s) and type(s). query_samples; Performs aggregation queries over samples and sample annotations, and returns Python object(s). query_samples_typed; Performs aggregation qu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:5516,log,logistic,5516,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logistic']
Testability,"mputing the minimal representation.; - `old_to_new` (``array<int32>``) -- An array that maps old allele index to; new allele index. Its length is the same as `old_alleles`. Alleles that; are filtered are missing.; - `new_to_old` (``array<int32>``) -- An array that maps new allele index to; the old allele index. Its length is the same as the modified `alleles`; field. **Downcode algorithm**. We will illustrate the behavior on the example genotype below; when filtering the first alternate allele (allele 1) at a site; with 1 reference allele and 2 alternate alleles. .. code-block:: text. GT: 1/2; GQ: 10; AD: 0,50,35. 0 | 1000; 1 | 1000 10; 2 | 1000 0 20; +-----------------; 0 1 2. The downcode algorithm recodes occurances of filtered alleles; to occurances of the reference allele (e.g. 1 -> 0 in our; example). So the depths of filtered alleles in the AD field; are added to the depth of the reference allele. Where; downcoding filtered alleles merges distinct genotypes, the; minimum PL is used (since PL is on a log scale, this roughly; corresponds to adding probabilities). The PLs are then; re-normalized (shifted) so that the most likely genotype has a; PL of 0, and GT is set to this genotype. If an allele is; filtered, this algorithm acts similarly to; :func:`.split_multi_hts`. The downcode algorithm would produce the following:. .. code-block:: text. GT: 0/1; GQ: 10; AD: 35,50. 0 | 20; 1 | 0 10; +-----------; 0 1. In summary:. - GT: Downcode filtered alleles to reference.; - AD: Columns of filtered alleles are eliminated and their; values are added to the reference column, e.g., filtering; alleles 1 and 2 transforms ``25,5,10,20`` to ``40,20``.; - DP: No change.; - PL: Downcode filtered alleles to reference, combine PLs; using minimum for each overloaded genotype, and shift so; the overall minimum PL is 0.; - GQ: The second-lowest PL (after shifting). **Subset algorithm**. We will illustrate the behavior on the example genotype below; when filtering the first alternate ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:159734,log,log,159734,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['log']
Testability,"mum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; null_max_iterations : :obj:`int`; The maximum number of iterations when fitting the logistic null model. Defaults to 25.; null_tolerance : :obj:`float`; The null model logisitic regression converges when the errors is less than this. Defaults to; 1e-6.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alone. - s2 : :obj:`.tfloat64`, the variance of the residuals, :math:`\sigma^2` in the paper. - null_fit:. - b : :obj:`.tndarray` vector of coefficients. - score : :obj:`.tndarray` vector of score statistics. - fisher : :obj:`.tndarray` matrix of fisher statistics. - mu : :obj:`.tndarray` the expected value under the null model. - n_iterations : :obj:`.tint32` the number of iterations before termination. - log_lkhd : :obj:`.tfloat64` the log-likelihood of the final iteration. - converged : :obj:`.tbool` True if the null model converged. - exploded : :obj:`.tbo",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:96271,test,test,96271,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"m{age} + \\beta_3 \, \mathrm{isFemale} + \\varepsilon), \quad \\varepsilon \sim \mathrm{N}(0, \sigma^2). where :math:`\mathrm{sigmoid}` is the `sigmoid; function <https://en.wikipedia.org/wiki/Sigmoid_function>`__, the; genotype :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; :math:`\mathrm{isFemale}` is coded as 1 for true (female) and; 0 for false (male). The null model sets :math:`\\beta_1 = 0`. The resulting variant annotations depend on the test statistic; as shown in the tables below. ========== =================== ====== =====; Test Annotation Type Value; ========== =================== ====== =====; Wald ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; Wald ``va.logreg.se`` Double estimated standard error, :math:`\widehat{\mathrm{se}}`; Wald ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`; Wald ``va.logreg.pval`` Double Wald p-value testing :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. ================ =========================== ======= =====; Test Annotation Type Value; ================ =========================== ======= =====; Wald, LRT, Firth ``va.logreg.fit.n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:141932,test,testing,141932,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['testing']
Testability,"n about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_lshift(x, y)[source]; Bitwise left-shift x by y.; Examples; >>> hl.eval(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:; >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_rshift(x, y, logical=False)[source]; Bitwise right-shift x by y.; Examples; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With logical=False (default), the sign is preserved:; >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With logical=True, the sign bit is treated as any other:; >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; If logical is False, then the shift is a sign-preserving right shift.; If logical is True, then the shift is logical, with the sign bit; treated as any other bit.; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression); logical (bool). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representat",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:5940,log,logical,5940,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['logical']
Testability,"n bytes.; size (str) – Size as a readable string.; modification_time (str) – Time of last file modification.; owner (str) – Owner.; path (str) – Path. Parameters:; path (str). Returns:; list [dict]. hail.utils.hadoop_scheme_supported(scheme)[source]; Returns True if the Hadoop filesystem supports URLs with the given; scheme.; Examples; >>> hadoop_scheme_supported('gs') . Notes; URLs with the https scheme are only supported if they are specifically; Azure Blob Storage URLs of the form https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>. Parameters:; scheme (str). Returns:; bool. hail.utils.copy_log(path)[source]; Attempt to copy the session log to a hadoop-API-compatible location.; Examples; Specify a manual path:; >>> hl.copy_log('gs://my-bucket/analysis-10-jan19.log') ; INFO: copying log to 'gs://my-bucket/analysis-10-jan19.log'... Copy to a directory:; >>> hl.copy_log('gs://my-bucket/') ; INFO: copying log to 'gs://my-bucket/hail-20180924-2018-devel-46e5fad57524.log'... Notes; Since Hail cannot currently log directly to distributed file systems, this; function is provided as a utility for offloading logs from ephemeral nodes.; If path is a directory, then the log file will be copied using its; base name to the directory (e.g. /home/hail.log would be copied as; gs://my-bucket/hail.log if path is gs://my-bucket. Parameters:; path (str). hail.utils.range_table(n, n_partitions=None)[source]; Construct a table with the row index and no other fields.; Examples; >>> df = hl.utils.range_table(100). >>> df.count(); 100. Notes; The resulting table contains one field:. idx (tint32) - Row index (key). This method is meant for testing and learning, and is not optimized for; production performance. Parameters:. n (int) – Number of rows.; n_partitions (int, optional) – Number of partitions (uses Spark default parallelism if None). Returns:; Table. hail.utils.range_matrix_table(n_rows, n_cols, n_partitions=None)[source]; Construct a matrix table with row and c",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/utils/index.html:9334,log,log,9334,docs/0.2/utils/index.html,https://hail.is,https://hail.is/docs/0.2/utils/index.html,1,['log'],['log']
Testability,"n coefficient reference dict. Parameters; ----------; tb : :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` containing row (or col) for `coef_dict`.; str_expr : :class:`str`, optional; String expression pattern to match against row (or col) fields. If left; unspecified, the intersection of field names is only between existing; row (or col) fields in `mt` and keys of `ref_coef_dict`.; ref_coef_dict : :obj:`dict`, optional; Reference coefficient dictionary with keys that are row (or col) field; names from which to subset. If not included, coefficients are assumed to be 1.; axis : :class:`str`; Field type in which to search for field names. Options: 'rows', 'cols'. Returns; -------; coef_dict : :obj:`dict`; Coefficients to multiply each field. The coefficients are specified by; `coef_dict` value, the row (or col) field name is specified by `coef_dict` key.; """"""; assert str_expr is not None or ref_coef_dict is not None, ""str_expr and ref_coef_dict cannot both be None""; assert axis in {'rows', 'cols'}, ""axis must be 'rows' or 'cols'""; fields_to_search = tb.row if axis == 'rows' or isinstance(tb, Table) else tb.col; # when axis='rows' we're searching for annotations, axis='cols' searching for covariates; axis_field = 'annotation' if axis == 'rows' else 'covariate'; if str_expr is None:; # take all row (or col) fields in mt matching keys in coef_dict; coef_dict = {k: ref_coef_dict[k] for k in ref_coef_dict.keys() if k in fields_to_search}; # if intersect is empty: return error; assert len(coef_dict) > 0, f'None of the keys in ref_coef_dict match any {axis[:-1]} fields'; return coef_dict # return subset of ref_coef_dict; else:; # str_expr search in list of row (or col) fields; fields = [rf for rf in list(fields_to_search) if str_expr in rf]; assert len(fields) > 0, f'No {axis[:-1]} fields matched str_expr search: {str_expr}'; if ref_coef_dict is None:; print(f'Assuming coef = 1 for all {axis_field}s'); return {k: 1 for k in fields}; in_ref_c",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:30290,assert,assert,30290,docs/0.2/_modules/hail/experimental/ldscsim.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html,4,['assert'],['assert']
Testability,"n expression. Parameters:; t (str or HailType) – Type of the missing expression. Returns:; Expression – A missing expression of type t. hail.expr.functions.str(x)[source]; Returns the string representation of x.; Examples; >>> hl.eval(hl.str(hl.struct(a=5, b=7))); '{""a"":5,""b"":7}'. Parameters:; x. Returns:; StringExpression. hail.expr.functions.is_missing(expression)[source]; Returns True if the argument is missing.; Examples; >>> hl.eval(hl.is_missing(5)); False. >>> hl.eval(hl.is_missing(hl.missing(hl.tstr))); True. >>> hl.eval(hl.is_missing(hl.missing(hl.tbool) & True)); True. Parameters:; expression – Expression to test. Returns:; BooleanExpression – True if expression is missing, False otherwise. hail.expr.functions.is_defined(expression)[source]; Returns True if the argument is not missing.; Examples; >>> hl.eval(hl.is_defined(5)); True. >>> hl.eval(hl.is_defined(hl.missing(hl.tstr))); False. >>> hl.eval(hl.is_defined(hl.missing(hl.tbool) & True)); False. Parameters:; expression – Expression to test. Returns:; BooleanExpression – True if expression is not missing, False otherwise. hail.expr.functions.coalesce(*args)[source]; Returns the first non-missing value of args.; Examples; >>> x1 = hl.missing('int'); >>> x2 = 2; >>> hl.eval(hl.coalesce(x1, x2)); 2. Notes; All arguments must have the same type, or must be convertible to a common; type (all numeric, for instance). See also; or_else(). Parameters:; args (variable-length args of Expression). Returns:; Expression. hail.expr.functions.or_else(a, b)[source]; If a is missing, return b.; Examples; >>> hl.eval(hl.or_else(5, 7)); 5. >>> hl.eval(hl.or_else(hl.missing(hl.tint32), 7)); 7. See also; coalesce(). Parameters:. a (Expression); b (Expression). Returns:; Expression. hail.expr.functions.or_missing(predicate, value)[source]; Returns value if predicate is True, otherwise returns missing.; Examples; >>> hl.eval(hl.or_missing(True, 5)); 5. >>> hl.eval(hl.or_missing(False, 5)); None. Parameters:. predicate (",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/core.html:8788,test,test,8788,docs/0.2/functions/core.html,https://hail.is,https://hail.is/docs/0.2/functions/core.html,1,['test'],['test']
Testability,"n for an if/else statement; tests a condition and returns one of two options based on the result.; Examples; >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; If condition evaluates to True, returns consequent. If condition; evaluates to False, returns alternate. If predicate is missing, returns; missing. Note; The type of consequent and alternate must be the same. Parameters:. condition (BooleanExpression) – Condition to test.; consequent (Expression) – Branch to return if the condition is True.; alternate (Expression) – Branch to return if the condition is False.; missing_false (bool) – If True, treat missing condition as False. See also; case(), switch(), if_else(). Returns:; Expression – One of consequent, alternate, or missing, based on condition. hail.expr.functions.if_else(condition, consequent, alternate, missing_false=False)[source]; Expression for an if/else statement; tests a condition and returns one of two options based on the result.; Examples; >>> x = 5; >>> hl.eval(hl.if_else(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.if_else(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; If condition evaluates to True, returns consequent. If condition; evaluates to False, returns alternate. If predicate is missing, returns; missing. Note; The type of consequent and alternate must be the same. Parameters:. condition (BooleanExpression) – Condition to test.; consequent (Expression) – Branch to return if the condition is True.; alternate (Expression) – Branch to return if the condition is False.; missing_false (bool) – If True, treat missing condition as False. See also; case(), switch(). Returns:; Expression – One of consequent, alternate, or missing, based on condition. hail.expr.functions.switch(expr)[source]; Build a conditional tree on the value of an expression.; Examples; >>> csq = hl",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/core.html:4119,test,tests,4119,docs/0.2/functions/core.html,https://hail.is,https://hail.is/docs/0.2/functions/core.html,1,['test'],['tests']
Testability,"n released 42 months prior to the project, and at minimum the two; latest minor versions.; All minor versions of numpy released in the 24 months prior to the project, and at minimum the; last three minor versions. Change Log; Version 0.2.132. (#14576) Fixed bug where; submitting many Python jobs would fail with RecursionError. Version 0.2.131. (#14544) batch.read_input; and batch.read_input_group now accept os.PathLike objects as well as strings.; (#14328) Job resource usage; data can now be retrieved from the Batch API. Version 0.2.130. (#14425) A job’s ‘always run’; state is rendered in the Job and Batch pages. This makes it easier to understand; why a job is queued to run when others have failed or been cancelled.; (#14437) The billing page now; reports users’ spend on the batch service. Version 0.2.128. (#14224) hb.Batch now accepts a; default_regions argument which is the default for all jobs in the Batch. Version 0.2.124. (#13681) Fix hailctl batch init and hailctl auth login for; new users who have never set up a configuration before. Version 0.2.123. (#13643) Python jobs in Hail Batch that use the default image now support; all supported python versions and include the hail python package.; (#13614) Fixed a bug that broke the LocalBackend when run inside a; Jupyter notebook.; (#13200) hailtop.batch will now raise an error by default if a pipeline; attempts to read or write files from or two cold storage buckets in GCP. Version 0.2.122. (#13565) Users can now use VEP images from the hailgenetics DockerHub; in Hail Batch. Version 0.2.121. (#13396) Non-spot instances can be requested via the Job.spot() method. Version 0.2.117. (#13007) Memory and storage request strings may now be optionally terminated with a B for bytes.; (#13051) Azure Blob Storage https URLs are now supported. Version 0.2.115. (#12731) Introduced hailtop.fs that makes public a filesystem module that works for local fs, gs, s3 and abs. This can be used by import hailtop.fs as hfs.; (#12918) ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/change_log.html:1494,log,login,1494,docs/batch/change_log.html,https://hail.is,https://hail.is/docs/batch/change_log.html,1,['log'],['login']
Testability,"n the resulting struct in the order they appear in; fields.; The named_exprs arguments are new field expressions. Parameters:. fields (varargs of str) – Field names to keep.; named_exprs (keyword args of Expression) – New field expressions. Returns:; StructExpression – Struct containing specified existing fields and computed fields. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. values()[source]; A list of expressions for each field. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.StructExpression.html:8285,log,logging,8285,docs/0.2/hail.expr.StructExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.StructExpression.html,2,"['log', 'test']","['logging', 'tested']"
Testability,"n to hl.summarize_variants.; (#7792) Add Python; stack trace to array index out of bounds errors in Hail pipelines.; (#7832) Add; spark_conf argument to hl.init, permitting configuration of; Spark runtime for a Hail session.; (#7823) Added; datetime functions hl.experimental.strptime and; hl.experimental.strftime.; (#7888) Added; hl.nd.array constructor from nested standard arrays. File size. (#7923) Fixed; compression problem since 0.2.23 resulting in larger-than-expected; matrix table files for datasets with few entry fields (e.g. GT-only; datasets). Performance. (#7867) Fix; performance regression leading to extra scans of data when; order_by and key_by appeared close together.; (#7901) Fix; performance regression leading to extra scans of data when; group_by/aggregate and key_by appeared close together.; (#7830) Improve; performance of array arithmetic. Bug fixes. (#7922) Fix; still-not-well-understood serialization error about; ApproxCDFCombiner.; (#7906) Fix optimizer; error by relaxing unnecessary assertion.; (#7788) Fix possible; memory leak in ht.tail and ht.head.; (#7796) Fix bug in; ingesting numpy arrays not in row-major orientation. Version 0.2.30; Released 2019-12-20. Performance. (#7771) Fixed extreme; performance regression in scans.; (#7764) Fixed; mt.entry_field.take performance regression. New features. (#7614) Added; experimental support for loops with hl.experimental.loop. Miscellaneous. (#7745) Changed; export_vcf to only use scientific notation when necessary. Version 0.2.29; Released 2019-12-17. Bug fixes. (#7229) Fixed; hl.maximal_independent_set tie breaker functionality.; (#7732) Fixed; incompatibility with old files leading to incorrect data read when; filtering intervals after read_matrix_table.; (#7642) Fixed crash; when constant-folding functions that throw errors.; (#7611) Fixed; hl.hadoop_ls to handle glob patterns correctly.; (#7653) Fixed crash; in ld_prune by unfiltering missing GTs. Performance improvements. (#7719) Gene",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:79392,assert,assertion,79392,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['assert'],['assertion']
Testability,"n(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). [docs]class CaseBuilder(ConditionalBuilder):; """"""Class for chaining multiple if-else statements. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(x.length() == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.CaseBuilder.when` or; :meth:`~hail.expr.builders.CaseBuilder.default` method calls must be the; same type. Parameters; ----------; missing_false: :obj:`.bool`; Treat missing predicates as ``False``. See Also; --------; :func:`.case`, :func:`.cond`, :func:`.switch`; """""". def __init__(self, missing_false=False):; super(CaseBuilder, self).__init__(); self._missing_false = missing_false. def _finish(self, default):; assert len(self._cases) > 0. from hail.expr.functions import if_else. expr = default; for conditional, then in self._cases[::-1]:; expr = if_else(conditional, then, expr, missing_false=self._missing_false); return expr. [docs] @typecheck_method(condition=expr_bool, then=expr_any); def when(self, condition, then) -> 'CaseBuilder':; """"""Add a branch. If `condition` is ``True``, then returns `then`. Warning; -------; Missingness is treated similarly to :func:`.cond`. Missingness is; **not** treated as ``False``. A `condition` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/builders.html:6163,assert,assert,6163,docs/0.2/_modules/hail/expr/builders.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html,2,['assert'],['assert']
Testability,"n, [n_rows, n_cols], block_size); return BlockMatrix(rand). [docs] @classmethod; @typecheck_method(n_rows=int, n_cols=int, value=numeric, block_size=nullable(int)); def fill(cls, n_rows, n_cols, value, block_size=None):; """"""Creates a block matrix with all elements the same value. Examples; --------; Create a block matrix with 10 rows, 20 columns, and all elements equal to ``1.0``:. >>> bm = BlockMatrix.fill(10, 20, 1.0). Parameters; ----------; n_rows: :obj:`int`; Number of rows.; n_cols: :obj:`int`; Number of columns.; value: :obj:`float`; Value of all elements.; block_size: :obj:`int`, optional; Block size. Default given by :meth:`default_block_size`. Returns; -------; :class:`.BlockMatrix`; """"""; if not block_size:; block_size = BlockMatrix.default_block_size(). bmir = BlockMatrixBroadcast(_to_bmir(value, block_size), [], [n_rows, n_cols], block_size); return BlockMatrix(bmir). @classmethod; @typecheck_method(n_rows=int, n_cols=int, data=sequenceof(float), block_size=nullable(int)); def _create(cls, n_rows, n_cols, data, block_size=None):; """"""Private method for creating small test matrices."""""". if block_size is None:; block_size = BlockMatrix.default_block_size(). return BlockMatrix(ValueToBlockMatrix(hl.literal(data)._ir, [n_rows, n_cols], block_size)). [docs] @classmethod; @typecheck_method(ndarray_expression=expr_ndarray(), block_size=int); def from_ndarray(cls, ndarray_expression, block_size=4096):; """"""Create a BlockMatrix from an ndarray""""""; if ndarray_expression.dtype.element_type != hl.tfloat64:; raise ValueError(""BlockMatrix.from_ndarray expects an ndarray of type float64""). shape = hl.eval(ndarray_expression.shape). if shape is None:; raise ValueError(""Cannot make a BlockMatrix from a missing NDArray""); return BlockMatrix(ValueToBlockMatrix(ndarray_expression._ir, shape, block_size)). [docs] @staticmethod; def default_block_size():; """"""Default block side length."""""". # This should match BlockMatrix.defaultBlockSize in the Scala backend.; return 4096 # 32 * ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:17878,test,test,17878,docs/0.2/_modules/hail/linalg/blockmatrix.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html,2,['test'],['test']
Testability,"n,; ); covmat = mt.covmat; yvec = mt.yvec; n = mt.n_complete_samples. logmean = hl.log(yvec.sum() / n); b = hl.nd.array([logmean, *[0 for _ in range(k - 1)]]); mu = hl.exp(covmat @ b); residual = yvec - mu; score = covmat.T @ residual; fisher = (mu * covmat.T) @ covmat; mt = mt.annotate_globals(null_fit=_poisson_fit(covmat, yvec, b, mu, score, fisher, max_iterations, tolerance)); mt = mt.annotate_globals(; null_fit=hl.case(); .when(mt.null_fit.converged, mt.null_fit); .or_error(; hl.format(; '_lowered_poisson_regression_rows: null model did not converge: %s',; mt.null_fit.select('n_iterations', 'log_lkhd', 'converged', 'exploded'),; ); ); ); mt = mt.annotate_rows(mean_x=hl.agg.mean(mt.x)); mt = mt.annotate_rows(xvec=hl.nd.array(hl.agg.collect(hl.coalesce(mt.x, mt.mean_x)))); ht = mt.rows(). covmat = ht.covmat; null_fit = ht.null_fit; # FIXME: we should test a whole block of variants at a time not one-by-one; xvec = ht.xvec; yvec = ht.yvec. if test == 'score':; chi_sq, p = _poisson_score_test(null_fit, covmat, yvec, xvec); return ht.select(chi_sq_stat=chi_sq, p_value=p, **ht.pass_through).select_globals('null_fit'). X = hl.nd.hstack([covmat, xvec.T.reshape(-1, 1)]); b = hl.nd.hstack([null_fit.b, hl.nd.array([0.0])]); mu = sigmoid(X @ b); residual = yvec - mu; score = hl.nd.hstack([null_fit.score, hl.nd.array([xvec @ residual])]). fisher00 = null_fit.fisher; fisher01 = ((covmat.T * mu) @ xvec).reshape((-1, 1)); fisher10 = fisher01.T; fisher11 = hl.nd.array([[(mu * xvec.T) @ xvec]]); fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). test_fit = _poisson_fit(X, yvec, b, mu, score, fisher, max_iterations, tolerance); if test == 'lrt':; return ht.select(test_fit=test_fit, **lrt_test(X, null_fit, test_fit), **ht.pass_through).select_globals(; 'null_fit'; ); assert test == 'wald'; return ht.select(test_fit=test_fit, **wald_test(X, test_fit), **ht.pass_through).select_globals('null_fit'). def _poisson_fit(; X: NDArrayNumericExpres",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:66596,test,test,66596,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"n,; gcs_requester_pays_configuration=gcs_requester_pays_configuration,; copy_log_on_error=copy_spark_log_on_error,; ); if backend == 'local':; return init_local(; log=log,; quiet=quiet,; append=append,; tmpdir=tmp_dir,; default_reference=default_reference,; global_seed=global_seed,; skip_logging_configuration=skip_logging_configuration,; gcs_requester_pays_configuration=gcs_requester_pays_configuration,; ); raise ValueError(f'unknown Hail Query backend: {backend}'). @typecheck(; sc=nullable(SparkContext),; app_name=nullable(str),; master=nullable(str),; local=str,; log=nullable(str),; quiet=bool,; append=bool,; min_block_size=int,; branching_factor=int,; tmp_dir=nullable(str),; default_reference=enumeration(*BUILTIN_REFERENCES),; idempotent=bool,; global_seed=nullable(int),; spark_conf=nullable(dictof(str, str)),; skip_logging_configuration=bool,; local_tmpdir=nullable(str),; _optimizer_iterations=nullable(int),; gcs_requester_pays_configuration=nullable(oneof(str, sized_tupleof(str, sequenceof(str)))),; copy_log_on_error=nullable(bool),; ); def init_spark(; sc=None,; app_name=None,; master=None,; local='local[*]',; log=None,; quiet=False,; append=False,; min_block_size=0,; branching_factor=50,; tmp_dir=None,; default_reference='GRCh37',; idempotent=False,; global_seed=None,; spark_conf=None,; skip_logging_configuration=False,; local_tmpdir=None,; _optimizer_iterations=None,; gcs_requester_pays_configuration: Optional[GCSRequesterPaysConfiguration] = None,; copy_log_on_error: bool = False,; ):; from hail.backend.py4j_backend import connect_logger; from hail.backend.spark_backend import SparkBackend. log = _get_log(log); tmpdir = _get_tmpdir(tmp_dir); local_tmpdir = _get_local_tmpdir(local_tmpdir); optimizer_iterations = get_env_or_default(_optimizer_iterations, 'HAIL_OPTIMIZER_ITERATIONS', 3). app_name = app_name or 'Hail'; (; gcs_requester_pays_project,; gcs_requester_pays_buckets,; ) = convert_gcs_requester_pays_configuration_to_hadoop_conf_style(; get_gcs_request",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:14349,log,log,14349,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,4,['log'],['log']
Testability,"n.; - owner (:class:`str`) -- Owner.; - path (:class:`str`) -- Path. Parameters; ----------; path : :class:`str`. Returns; -------; :obj:`list` [:obj:`dict`]; """"""; return [sr.to_legacy_dict() for sr in Env.fs().ls(path)]. [docs]def hadoop_scheme_supported(scheme: str) -> bool:; """"""Returns ``True`` if the Hadoop filesystem supports URLs with the given; scheme. Examples; --------. >>> hadoop_scheme_supported('gs') # doctest: +SKIP. Notes; -----; URLs with the `https` scheme are only supported if they are specifically; Azure Blob Storage URLs of the form `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>`. Parameters; ----------; scheme : :class:`str`. Returns; -------; :obj:`.bool`; """"""; return Env.fs().supports_scheme(scheme). [docs]def copy_log(path: str) -> None:; """"""Attempt to copy the session log to a hadoop-API-compatible location. Examples; --------; Specify a manual path:. >>> hl.copy_log('gs://my-bucket/analysis-10-jan19.log') # doctest: +SKIP; INFO: copying log to 'gs://my-bucket/analysis-10-jan19.log'... Copy to a directory:. >>> hl.copy_log('gs://my-bucket/') # doctest: +SKIP; INFO: copying log to 'gs://my-bucket/hail-20180924-2018-devel-46e5fad57524.log'... Notes; -----; Since Hail cannot currently log directly to distributed file systems, this; function is provided as a utility for offloading logs from ephemeral nodes. If `path` is a directory, then the log file will be copied using its; base name to the directory (e.g. ``/home/hail.log`` would be copied as; ``gs://my-bucket/hail.log`` if `path` is ``gs://my-bucket``. Parameters; ----------; path: :class:`str`; """"""; from hail.utils import local_path_uri. log = os.path.realpath(Env.hc()._log); try:; if hadoop_is_dir(path):; _, tail = os.path.split(log); path = os.path.join(path, tail); info(f""copying log to {path!r}...""); hadoop_copy(local_path_uri(log), path); except Exception as e:; sys.stderr.write(f'Could not copy log: encountered error:\n {e}'). © Copyright 2015-2024, Hail Team.; La",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html:7253,log,log,7253,docs/0.2/_modules/hail/utils/hadoop_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html,4,['log'],['log']
Testability,"n`; Entry field of genotypes.; beta : :class:`.Expression`; Row field of SNP effects.; h2 : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`; SNP-based heritability (:math:`h^2`) of simulated trait. Can only be; ``None`` if running annotation-informed model.; popstrat : :class:`.Expression`, optional; Column field containing population stratification term.; popstrat_var : :obj:`float` or :obj:`int`; Variance of population stratification term.; exact_h2: :obj:`bool`; Whether to exactly simulate ratio of variance of genetic component of; phenotype to variance of phenotype to be h2. If `False`, ratio will be; h2 in expectation. Observed h2 in the simulation will be close to; expected h2 for large-scale simulations. Returns; -------; :class:`.MatrixTable`; :class:`.MatrixTable` with simulated phenotype as column field.; """"""; print('calculating phenotype'); h2 = h2.tolist() if isinstance(h2, np.ndarray) else ([h2] if not isinstance(h2, list) else h2); assert popstrat_var is None or (popstrat_var >= 0), 'popstrat_var must be non-negative'; uid = Env.get_uid(base=100); mt = annotate_all(; mt=mt,; row_exprs={'beta_' + uid: beta},; col_exprs={} if popstrat is None else {'popstrat_' + uid: popstrat},; entry_exprs={'gt_' + uid: genotype.n_alt_alleles() if genotype.dtype is hl.dtype('call') else genotype},; ); mt = mt.filter_rows(hl.agg.stats(mt['gt_' + uid]).stdev > 0); mt = normalize_genotypes(mt['gt_' + uid]); if mt['beta_' + uid].dtype == hl.dtype('array<float64>'): # if >1 traits; if exact_h2:; raise ValueError('exact_h2=True not supported for multitrait simulations'); else:; mt = mt.annotate_cols(; y_no_noise=hl.agg.array_agg(lambda beta: hl.agg.sum(beta * mt['norm_gt']), mt['beta_' + uid]); ); mt = mt.annotate_cols(y=mt.y_no_noise + hl.literal(h2).map(lambda x: hl.rand_norm(0, hl.sqrt(1 - x)))); elif exact_h2 and min([h2[0], 1 - h2[0]]) != 0:; print('exact h2'); mt = mt.annotate_cols(**{'y_no_noise_' + uid: hl.agg.sum(mt['beta_' + uid] * mt['norm_gt'])}",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:23086,assert,assert,23086,docs/0.2/_modules/hail/experimental/ldscsim.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html,2,['assert'],['assert']
Testability,"na(type_and_data['data']), typ, key=['id']). [docs]@typecheck(regex=str, path=oneof(str, sequenceof(str)), max_count=int, show=bool, force=bool, force_bgz=bool); def grep(regex, path, max_count=100, *, show: bool = True, force: bool = False, force_bgz: bool = False):; r""""""Searches given paths for all lines containing regex matches. Examples; --------. Print all lines containing the string ``hello`` in *file.txt*:. >>> hl.grep('hello','data/file.txt'). Print all lines containing digits in *file1.txt* and *file2.txt*:. >>> hl.grep('\\d', ['data/file1.txt','data/file2.txt']). Notes; -----; :func:`.grep` mimics the basic functionality of Unix ``grep`` in; parallel, printing results to the screen. This command is provided as a; convenience to those in the statistical genetics community who often; search enormous text files like VCFs. Hail uses `Java regular expression; patterns; <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/regex/Pattern.html>`__.; The `RegExr sandbox <http://regexr.com/>`__ may be helpful. Parameters; ----------; regex : :class:`str`; The regular expression to match.; path : :class:`str` or :obj:`list` of :obj:`str`; The files to search.; max_count : :obj:`int`; The maximum number of matches to return; show : :obj:`bool`; When `True`, show the values on stdout. When `False`, return a; dictionary mapping file names to lines.; force_bgz : :obj:`bool`; If ``True``, read files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; force : :obj:`bool`; If ``True``, read gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism. Returns; ---; :obj:`dict` of :class:`str` to :obj:`list` of :obj:`str`; """"""; from hail.backend.spark_backend import S",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/impex.html:35608,sandbox,sandbox,35608,docs/0.2/_modules/hail/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html,2,['sandbox'],['sandbox']
Testability,"name, inds)); elif inds.axes != expected_axes:; bad_refs.append((name, inds)). assert len(bad_refs) > 0; errors.append(; ExpressionException(; ""scope violation: '{caller}' expects an expression {strictness}indexed by {expected}""; ""\n Found indices {axes}, with unexpected indices {stray}. Invalid fields:{fields}{agg}"".format(; caller=caller,; strictness=strictness,; expected=list(expected_axes),; axes=list(indices.axes),; stray=list(unexpected_axes),; fields=''.join(; ""\n '{}' (indices {})"".format(name, list(inds.axes)) for name, inds in bad_refs; ),; agg=''; if (unexpected_axes - aggregation_axes); else ""\n '{}' supports aggregation over axes {}, ""; ""so these fields may appear inside an aggregator function."".format(caller, list(aggregation_axes)),; ); ); ). if aggregations:; if aggregation_axes:; # the expected axes of aggregated expressions are the expected axes + axes aggregated over; expected_agg_axes = expected_axes.union(aggregation_axes). for agg in aggregations:; assert isinstance(agg, Aggregation); refs = get_refs(*agg.exprs); agg_axes = agg.agg_axes(). # check for stray indices; unexpected_agg_axes = agg_axes - expected_agg_axes; if unexpected_agg_axes:; # one or more out-of-scope fields; bad_refs = []; for name, inds in refs.items():; bad_axes = inds.axes.intersection(unexpected_agg_axes); if bad_axes:; bad_refs.append((name, inds)). assert len(bad_refs) > 0. errors.append(; ExpressionException(; ""scope violation: '{caller}' supports aggregation over indices {expected}""; ""\n Found indices {axes}, with unexpected indices {stray}. Invalid fields:{fields}"".format(; caller=caller,; expected=list(aggregation_axes),; axes=list(agg_axes),; stray=list(unexpected_agg_axes),; fields=''.join(; ""\n '{}' (indices {})"".format(name, list(inds.axes)); for name, inds in bad_refs; ),; ); ); ); else:; errors.append(ExpressionException(""'{}' does not support aggregation"".format(caller))). for w in warnings:; warning('{}'.format(w.msg)); if errors:; for e in errors:; error('{}'",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html:3367,assert,assert,3367,docs/0.2/_modules/hail/expr/expressions/expression_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html,2,['assert'],['assert']
Testability,"nd Version Policy. menu; Hail. Python API; Hail Query Python API; utils. View page source. utils. ANY_REGION; Built-in mutable sequence. Interval(start, end[, includes_start, ...]); An object representing a range of values between start and end. Struct(**kwargs); Nested annotation structure. frozendict(d); An object representing an immutable dictionary. hadoop_open(path[, mode, buffer_size]); Open a file through the Hadoop filesystem API. hadoop_copy(src, dest); Copy a file through the Hadoop filesystem API. hadoop_exists(path); Returns True if path exists. hadoop_is_file(path); Returns True if path both exists and is a file. hadoop_is_dir(path); Returns True if path both exists and is a directory. hadoop_stat(path); Returns information about the file or directory at a given path. hadoop_ls(path); Returns information about files at path. hadoop_scheme_supported(scheme); Returns True if the Hadoop filesystem supports URLs with the given scheme. copy_log(path); Attempt to copy the session log to a hadoop-API-compatible location. range_table(n[, n_partitions]); Construct a table with the row index and no other fields. range_matrix_table(n_rows, n_cols[, ...]); Construct a matrix table with row and column indices and no entry fields. get_1kg(output_dir[, overwrite]); Download subset of the 1000 Genomes dataset and sample annotations. get_hgdp(output_dir[, overwrite]); Download subset of the Human Genome Diversity Panel dataset and sample annotations. get_movie_lens(output_dir[, overwrite]); Download public Movie Lens dataset. class hail.utils.Interval(start, end, includes_start=True, includes_end=False, point_type=None)[source]; An object representing a range of values between start and end.; >>> interval2 = hl.Interval(3, 6). Parameters:. start (any type) – Object with type point_type.; end (any type) – Object with type point_type.; includes_start (bool) – Interval includes start.; includes_end (bool) – Interval includes end. Note; This object refers to the Python val",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/utils/index.html:1574,log,log,1574,docs/0.2/utils/index.html,https://hail.is,https://hail.is/docs/0.2/utils/index.html,1,['log'],['log']
Testability,"nd `hailctl config set; gcs_requester_pays/buckets` to achieve the same effect. See Also; --------; :func:`.stop`. Parameters; ----------; sc : pyspark.SparkContext, optional; Spark Backend only. Spark context. If not specified, the Spark backend will create a new; Spark context.; app_name : :class:`str`; A name for this pipeline. In the Spark backend, this becomes the Spark application name. In; the Batch backend, this is a prefix for the name of every Batch.; master : :class:`str`, optional; Spark Backend only. URL identifying the Spark leader (master) node or `local[N]` for local; clusters.; local : :class:`str`; Spark Backend only. Local-mode core limit indicator. Must either be `local[N]` where N is a; positive integer or `local[*]`. The latter indicates Spark should use all cores; available. `local[*]` does not respect most containerization CPU limits. This option is only; used if `master` is unset and `spark.master` is not set in the Spark configuration.; log : :class:`str`; Local path for Hail log file. Does not currently support distributed file systems like; Google Storage, S3, or HDFS.; quiet : :obj:`bool`; Print fewer log messages.; append : :obj:`bool`; Append to the end of the log file.; min_block_size : :obj:`int`; Minimum file block size in MB.; branching_factor : :obj:`int`; Branching factor for tree aggregation.; tmp_dir : :class:`str`, optional; Networked temporary directory. Must be a network-visible file; path. Defaults to /tmp in the default scheme.; default_reference : :class:`str`; *Deprecated*. Please use :func:`.default_reference` to set the default reference genome. Default reference genome. Either ``'GRCh37'``, ``'GRCh38'``,; ``'GRCm38'``, or ``'CanFam3'``.; idempotent : :obj:`bool`; If ``True``, calling this function is a no-op if Hail has already been initialized.; global_seed : :obj:`int`, optional; Global random seed.; spark_conf : :obj:`dict` of :class:`str` to :class`str`, optional; Spark backend only. Spark configuration parameters.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:9004,log,log,9004,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,4,['log'],['log']
Testability,"nd betas. normalize_genotypes(genotype); Normalizes genotypes to have mean 0 and variance 1 at each SNP. annotate_all(mt[, row_exprs, col_exprs, ...]); Equivalent of _annotate_all, but checks source MatrixTable of exprs. ascertainment_bias(mt, y, P); Adds ascertainment bias to a binary phenotype to give it a sample prevalence of P = cases/(cases+controls). binarize(mt, y, K[, exact]); Binarize phenotype y such that it has prevalence K = cases/(cases+controls) Uses inverse CDF of Gaussian to set binarization threshold when exact = False, otherwise uses ranking to determine threshold. agg_fields(tb[, coef_dict, str_expr, axis]); Aggregates by linear combination fields matching either keys in coef_dict or str_expr. get_coef_dict(tb[, str_expr, ref_coef_dict, ...]); Gets either col or row fields matching str_expr and take intersection with keys in coefficient reference dict. hail.experimental.ldscsim.simulate_phenotypes(mt, genotype, h2, pi=None, rg=None, annot=None, popstrat=None, popstrat_var=None, exact_h2=False)[source]; Simulate phenotypes for testing LD score regression.; Simulates betas (SNP effects) under the infinitesimal, spike & slab, or; annotation-informed models, depending on parameters passed. Optionally adds; population stratification. Parameters:. mt (MatrixTable) – MatrixTable containing genotypes to be used. Also should contain; variant annotations as row fields if running the annotation-informed; model or covariates as column fields if adding population stratification.; genotype (Expression or CallExpression) – Entry field containing genotypes of individuals to be used for the; simulation.; h2 (float or int or list or numpy.ndarray) – SNP-based heritability of simulated trait.; pi (float or int or list or numpy.ndarray, optional) – Probability of SNP being causal when simulating under the spike & slab; model.; rg (float or int or list or numpy.ndarray, optional) – Genetic correlation between traits.; annot (Expression, optional) – Row field to use a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/experimental/ldscsim.html:2909,test,testing,2909,docs/0.2/experimental/ldscsim.html,https://hail.is,https://hail.is/docs/0.2/experimental/ldscsim.html,1,['test'],['testing']
Testability,"nd linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association. The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the `Jeffrey's; invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the `logreg.fit` fields reflect the null model; otherwise,; they reflect the full model. See; `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert's notes; `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__.; Firth introduced his approach in; `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Cour",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:33872,test,test,33872,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"nd linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association. The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the `Jeffrey's; invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This; test is slower, as both the null and full model must be fit per variant,; and convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted for the null model; and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the `logreg.fit` fields reflect the null model;; otherwise, they reflect the full model. See; `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert's notes; `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__.; Firth introduced his approach in; `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Courses/Stat376",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:54329,test,test,54329,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"nd side is the result of evaluating an expression with VDS elements. Computed From Existing Annotations¶. Add a new variant annotation called passAll which is the result of a boolean expression evaluating other variant annotation variables. va.passAll = va.pass && va.meanGQ > 20 && va.meanDP > 20. Add a new sample annotation called batch1 which is the result of a boolean expression comparing an existing boolean sample annotation variable to the string “Batch1”. sa.batch1 = sa.cohort == ""Batch1"". Add a new boolean sample annotation based on the length of the sample ID. sa.idTooLong = s.length > 10. Add a new variant annotation that is a String representing the chromosome and start position. va.altName = v.contig + "":"" + v.start. Add a new variant annotation that splits a comma-separated string with gene names and keeps the first element of the resulting array. va.geneName = va.geneNames.split("","")[0]. Add a new variant annotation that is the log of an existing annotation. va.logIntensity = log(va.intensity). Add a new global annotation computed from existing global annotations. global.callRate = global.nCalled / global.nGenotypes. Variant Annotation Computed from a Genotype Aggregable (gs)¶; In the context of creating new variant annotations, a genotype aggregable (gs) represents a row of genotypes in the variant-sample matrix.; The result of evaluating the genotype aggregable expression per row is added to the corresponding variant annotation.; The map function takes a lambda expression as input (g => ...). The filter function takes a boolean lambda expression as input (g => Boolean Expression). Transform the genotype aggregable to an aggregable of GQ scores using the map function and then calculate summary statistics on the GQ scores with the stats function. va.gqStats = gs.map(g => g.gq).stats(). Filter the genotype aggregable based on case status (sa.pheno.isCase) and genotype call (g.isHet and g.isHomVar) and then count the number of elements remaining. va.caseM",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/overview.html:6601,log,logIntensity,6601,docs/0.1/overview.html,https://hail.is,https://hail.is/docs/0.1/overview.html,2,['log'],"['log', 'logIntensity']"
Testability,"ndependent variable).; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions. You must explicitly provide an intercept term; if desired. You must provide at least one covariate.; max_size : :obj:`int`; Maximum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alone. - s2 : :obj:`.tfloat64`, the variance of the residuals, :math:`\sigma^2` in the paper. """"""; mt = matrix_table_source('skat/x', x); k = len(covariates); if k == 0:; raise ValueError('_linear_skat: at least one covariate is required.'); _warn_if_no_intercept('_linear_skat', covariates); mt = mt._select_all(; row_exprs=dict(group=group, weight=weight), col_exprs=dict(y=y, covariates=covariates), entry_exprs=dict(x=x); ); mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])); yvec, covmat, n = mt.aggregate_co",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:80312,test,test,80312,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"ndices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; GTEx_sQTL_Lung_all_snp_gene_associations. View page source. GTEx_sQTL_Lung_all_snp_gene_associations. Versions: v8; Reference genome builds: GRCh38; Type: hail.Table. Schema (v8, GRCh38); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; version: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'phenotype_id': struct {; intron: interval<locus<GRCh38>>,; cluster: str,; gene_id: str; }; 'tss_distance': int32; 'ma_samples': int32; 'ma_count': int32; 'maf': float64; 'pval_nominal': float64; 'slope': float64; 'slope_se': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Lung_all_snp_gene_associations.html:8806,Log,Log,8806,docs/0.2/datasets/schemas/GTEx_sQTL_Lung_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Lung_all_snp_gene_associations.html,1,['Log'],['Log']
Testability,"ndle/b37/human_g1k_v37.dict>`__; and `Homo_sapiens_assembly38.dict; <ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg38/Homo_sapiens_assembly38.dict>`__. If ``name='default'``, the value of :func:`.default_reference` is returned. Parameters; ----------; name : :class:`str`; Name of a previously loaded reference genome or one of Hail's built-in; references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``, ``'CanFam3'``, and; ``'default'``. Returns; -------; :class:`.ReferenceGenome`; """"""; Env.hc(); if name == 'default':; return default_reference(); else:; return Env.backend().get_reference(name). [docs]@typecheck(seed=int); def set_global_seed(seed):; """"""Deprecated. Has no effect. To ensure reproducible randomness, use the `global_seed`; argument to :func:`.init` and :func:`.reset_global_randomness`. See the :ref:`random functions <sec-random-functions>` reference docs for more. Parameters; ----------; seed : :obj:`int`; Integer used to seed Hail's random number generator; """""". warning(; 'hl.set_global_seed has no effect. See '; 'https://hail.is/docs/0.2/functions/random.html for details on '; 'ensuring reproducibility of randomness.'; ); pass. [docs]@typecheck(); def reset_global_randomness():; """"""Restore global randomness to initial state for test reproducibility."""""". Env.reset_global_randomness(). def _set_flags(**flags):; Env.backend().set_flags(**flags). def _get_flags(*flags):; return Env.backend().get_flags(*flags). @contextmanager; def _with_flags(**flags):; before = _get_flags(*flags); try:; _set_flags(**flags); yield; finally:; _set_flags(**before). def debug_info():; from hail.backend.backend import local_jar_information; from hail.backend.spark_backend import SparkBackend. spark_conf = None; if isinstance(Env.backend(), SparkBackend):; spark_conf = spark_context()._conf.getAll(); return {'spark_conf': spark_conf, 'local_jar_information': local_jar_information(), 'version': version()}. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:27134,test,test,27134,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['test'],['test']
Testability,"nd{align*}. Substitute this simplified expression into :math:`Z`:. .. math::. \begin{align*}; Z^T Z &= W^{1/2} G^T V^{1/2} (I - Q Q^T) V^{1/2} G W^{1/2} \\; \end{align*}. Split this symmetric matrix by observing that :math:`I - Q Q^T` is idempotent:. .. math::. \begin{align*}; I - Q Q^T &= (I - Q Q^T)(I - Q Q^T)^T \\; \\; Z &= (I - Q Q^T) V^{1/2} G W^{1/2} \\; Z &= (G - Q Q^T G) V^{1/2} W^{1/2}; \end{align*}. Finally, the squared singular values of :math:`Z` are the eigenvalues of :math:`Z^T Z`, so; :math:`Q` should be distributed as follows:. .. math::. \begin{align*}; U S V^T &= Z \quad\quad \textrm{the singular value decomposition} \\; \lambda_s &= S_{ss}^2 \\; \\; Q &\sim \textrm{GeneralizedChiSquared}(\lambda, \vec{1}, \vec{0}, 0, 0); \end{align*}. The null hypothesis test tests for the probability of observing even larger values of :math:`Q`. The SKAT method was originally described in:. Wu MC, Lee S, Cai T, Li Y, Boehnke M, Lin X. *Rare-variant association testing for; sequencing data with the sequence kernel association test.* Am J Hum Genet. 2011 Jul; 15;89(1):82-93. doi: 10.1016/j.ajhg.2011.05.029. Epub 2011 Jul 7. PMID: 21737059; PMCID:; PMC3135811. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3135811/. Examples; --------. Generate a dataset with a phenotype noisily computed from the genotypes:. >>> hl.reset_global_randomness(); >>> mt = hl.balding_nichols_model(1, n_samples=100, n_variants=20); >>> mt = mt.annotate_rows(gene = mt.locus.position // 12); >>> mt = mt.annotate_rows(weight = 1); >>> mt = mt.annotate_cols(phenotype = (hl.agg.sum(mt.GT.n_alt_alleles()) - 20 + hl.rand_norm(0, 1)) > 0.5). Test if the phenotype is significantly associated with the genotype:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | i",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:91049,test,testing,91049,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,['test'],"['test', 'testing']"
Testability,"nearColorMapper(palette=colors, low=data.c.min(), high=data.c.max()). x_axis = sorted(set(data.x), key=lambda z: float(z)); y_axis = sorted(set(data.y), key=lambda z: float(z)); p = figure(; title=title,; x_range=x_axis,; y_range=y_axis,; x_axis_location=""above"",; width=width,; height=height,; tools=""hover,save,pan,box_zoom,reset,wheel_zoom"",; toolbar_location='below',; ). p.grid.grid_line_color = None; p.axis.axis_line_color = None; p.axis.major_tick_line_color = None; p.axis.major_label_standoff = 0; import math. p.xaxis.major_label_orientation = math.pi / 3. p.rect(; x='x', y='y', width=1, height=1, source=data, fill_color={'field': 'c', 'transform': mapper}, line_color=None; ). color_bar = ColorBar(; color_mapper=mapper,; ticker=LogTicker(desired_num_ticks=len(colors)) if log else BasicTicker(desired_num_ticks=len(colors)),; label_standoff=12 if log else 6,; border_line_color=None,; location=(0, 0),; ); p.add_layout(color_bar, 'right'). hovertool = p.select_one(HoverTool); assert hovertool is not None; hovertool.tooltips = [; ('x', '@x'),; (; 'y',; '@y',; ),; ('count', '@c'),; ]. return p. @typecheck(; x=expr_numeric,; y=expr_numeric,; bins=oneof(int, sequenceof(int)),; range=nullable(sized_tupleof(nullable(sized_tupleof(numeric, numeric)), nullable(sized_tupleof(numeric, numeric)))),; ); def _generate_hist2d_data(x, y, bins, range):; source = x._indices.source; y_source = y._indices.source; if source is None or y_source is None:; raise ValueError(""histogram_2d expects two expressions of 'Table', found scalar expression""); if isinstance(source, hail.MatrixTable):; raise ValueError(""histogram_2d requires source to be Table, not MatrixTable""); if source != y_source:; raise ValueError(f""histogram_2d expects two expressions from the same 'Table', found {source} and {y_source}""); raise_unless_row_indexed('histogram_2d', x); raise_unless_row_indexed('histogram_2d', y); if isinstance(bins, int):; x_bins = y_bins = bins; else:; x_bins, y_bins = bins; if range is None:; x",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:20168,assert,assert,20168,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['assert'],['assert']
Testability,"ner.; - path (:class:`str`) -- Path. Parameters; ----------; path : :class:`str`. Returns; -------; :obj:`list` [:obj:`dict`]; """"""; return [sr.to_legacy_dict() for sr in Env.fs().ls(path)]. [docs]def hadoop_scheme_supported(scheme: str) -> bool:; """"""Returns ``True`` if the Hadoop filesystem supports URLs with the given; scheme. Examples; --------. >>> hadoop_scheme_supported('gs') # doctest: +SKIP. Notes; -----; URLs with the `https` scheme are only supported if they are specifically; Azure Blob Storage URLs of the form `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>`. Parameters; ----------; scheme : :class:`str`. Returns; -------; :obj:`.bool`; """"""; return Env.fs().supports_scheme(scheme). [docs]def copy_log(path: str) -> None:; """"""Attempt to copy the session log to a hadoop-API-compatible location. Examples; --------; Specify a manual path:. >>> hl.copy_log('gs://my-bucket/analysis-10-jan19.log') # doctest: +SKIP; INFO: copying log to 'gs://my-bucket/analysis-10-jan19.log'... Copy to a directory:. >>> hl.copy_log('gs://my-bucket/') # doctest: +SKIP; INFO: copying log to 'gs://my-bucket/hail-20180924-2018-devel-46e5fad57524.log'... Notes; -----; Since Hail cannot currently log directly to distributed file systems, this; function is provided as a utility for offloading logs from ephemeral nodes. If `path` is a directory, then the log file will be copied using its; base name to the directory (e.g. ``/home/hail.log`` would be copied as; ``gs://my-bucket/hail.log`` if `path` is ``gs://my-bucket``. Parameters; ----------; path: :class:`str`; """"""; from hail.utils import local_path_uri. log = os.path.realpath(Env.hc()._log); try:; if hadoop_is_dir(path):; _, tail = os.path.split(log); path = os.path.join(path, tail); info(f""copying log to {path!r}...""); hadoop_copy(local_path_uri(log), path); except Exception as e:; sys.stderr.write(f'Could not copy log: encountered error:\n {e}'). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html:7332,log,log,7332,docs/0.2/_modules/hail/utils/hadoop_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html,26,['log'],"['log', 'logs']"
Testability,"nes the number of effects to fit in the; nested (null) model, with the effects on the remaining covariates fixed; to zero. The returned struct has ten fields:; - `beta` (:class:`.tarray` of :py:data:`.tfloat64`):; Estimated regression coefficient for each covariate.; - `standard_error` (:class:`.tarray` of :py:data:`.tfloat64`):; Estimated standard error for each covariate.; - `t_stat` (:class:`.tarray` of :py:data:`.tfloat64`):; t-statistic for each covariate.; - `p_value` (:class:`.tarray` of :py:data:`.tfloat64`):; p-value for each covariate.; - `multiple_standard_error` (:py:data:`.tfloat64`):; Estimated standard deviation of the random error.; - `multiple_r_squared` (:py:data:`.tfloat64`):; Coefficient of determination for nested models.; - `adjusted_r_squared` (:py:data:`.tfloat64`):; Adjusted `multiple_r_squared` taking into account degrees of; freedom.; - `f_stat` (:py:data:`.tfloat64`):; F-statistic for nested models.; - `multiple_p_value` (:py:data:`.tfloat64`):; p-value for the; `F-test <https://en.wikipedia.org/wiki/F-test#Regression_problems>`__ of; nested models.; - `n` (:py:data:`.tint64`):; Number of samples included in the regression. A sample is included if and; only if `y`, all elements of `x`, and `weight` (if set) are non-missing. All but the last field are missing if `n` is less than or equal to the; number of covariates or if the covariates are linearly dependent. If set, the `weight` parameter generalizes the model to `weighted least; squares <https://en.wikipedia.org/wiki/Weighted_least_squares>`__, useful; for heteroscedastic (diagonal but non-constant) variance. Warning; -------; If any weight is negative, the resulting statistics will be ``nan``. Parameters; ----------; y : :class:`.Float64Expression`; Response (dependent variable).; x : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; Covariates (independent variables).; nested_dim : :obj:`int`; The null model includes the first `nested_dim` covariates.; Must be",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html:52328,test,test,52328,docs/0.2/_modules/hail/expr/aggregators/aggregators.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html,2,['test'],['test']
Testability,"nfiguration (either str or tuple of str and list of str, optional) – If a string is provided, configure the Google Cloud Storage file system to bill usage to the; project identified by that string. If a tuple is provided, configure the Google Cloud; Storage file system to bill usage to the specified project for buckets specified in the; list. See examples above.; regions (list of str, optional) – List of regions to run jobs in when using the Batch backend. Use ANY_REGION to specify any region is allowed; or use None to use the underlying default regions from the hailctl environment configuration. For example, use; hailctl config set batch/regions region1,region2 to set the default regions to use.; gcs_bucket_allow_list – A list of buckets that Hail should be permitted to read from or write to, even if their default policy is to; use “cold” storage. Should look like [""bucket1"", ""bucket2""].; copy_spark_log_on_error (bool, optional) – Spark backend only. If True, copy the log from the spark driver node to tmp_dir on error. hail.asc(col)[source]; Sort by col ascending. hail.desc(col)[source]; Sort by col descending. hail.stop()[source]; Stop the currently running Hail session. hail.spark_context()[source]; Returns the active Spark context. Returns:; pyspark.SparkContext. hail.tmp_dir()[source]; Returns the Hail shared temporary directory. Returns:; str. hail.default_reference(new_default_reference=None)[source]; With no argument, returns the default reference genome ('GRCh37' by default).; With an argument, sets the default reference genome to the argument. Returns:; ReferenceGenome. hail.get_reference(name)[source]; Returns the reference genome corresponding to name.; Notes; Hail’s built-in references are 'GRCh37', GRCh38', 'GRCm38', and; 'CanFam3'.; The contig names and lengths come from the GATK resource bundle:; human_g1k_v37.dict; and Homo_sapiens_assembly38.dict.; If name='default', the value of default_reference() is returned. Parameters:; name (str) – Nam",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/api.html:7197,log,log,7197,docs/0.2/api.html,https://hail.is,https://hail.is/docs/0.2/api.html,1,['log'],['log']
Testability,"ng :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. ================ =========================== ======= =====; Test Annotation Type Value; ================ =========================== ======= =====; Wald, LRT, Firth ``va.logreg.fit.nIter`` Int number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth); Wald, LRT, Firth ``va.logreg.fit.converged`` Boolean true if iteration converged; Wald, LRT, Firth ``va.logreg.fit.exploded`` Boolean true if iteration exploded; ================ =========================== ======= =====. We consider iteration to have converged when every coordinate of :math:`\\beta` changes by less than :math:`10^{-6}`. For Wald and LRT, up to 25 iterations are attempted; in testing we find 4 or 5 iterations nearly always suffice. Convergence may also fail due to explosion, which refers to low-level numerical linear algebra exceptions caused by manipulating ill-conditioned matrices. Explosion may result from (nearly) linearly dependent covariates or complete `separation <https://en.wikipedia.org/wiki/Separation_(statistics)>`__. A more common situation in genetics is quasi-complete seperation, e.g. variants that are observed only in cases (or controls). Such variants inevitably arise when testing millions of variants with very low minor allele count. The maximum likelihood estimate of :math:`\\beta` under logistic regression is then undefined but convergence may still occur",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:143163,log,logreg,143163,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"ng an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowered_poisson_regression_rows/x', x). row_exprs = _get_regression_row_fields(mt, pass_through, '_lowered_poisson_regression_rows'); mt = mt._select_all(; row_exprs=dict(pass_through=hl.struct(**row_exprs)),; col_exprs=dict(y=y, covariates=covariates),; entry_exprs=dict(x=x),; ); # FIXME: the order of the columns is irrelevant to regression; mt = mt.key_cols_by(). mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])). mt = mt.annotate_globals(; **mt.aggregate_cols(; hl.struct(; yvec=hl.agg.collect(hl.float(mt.y)),; covmat=hl.agg.collect(mt.covariates.map(hl.float)),; n=hl.agg.count(),; ),; _localize=False,; ); ); mt =",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:64385,assert,assert,64385,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['assert'],['assert']
Testability,"ng_byte, which_missing_bit):; answer.append(None); else:; field_decoded = t._convert_from_encoding(byte_reader, _should_freeze); answer.append(field_decoded). return tuple(answer). def _convert_to_encoding(self, byte_writer, value):; length = len(self); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8; for i, t in enumerate(self.types):; if not HailType._missing(value[i]):; t._convert_to_encoding(byte_writer, value[i]). def unify(self, t):; if not (isinstance(t, ttuple) and len(self.types) == len(t.types)):; return False; for t1, t2 in zip(self.types, t.types):; if not t1.unify(t2):; return False; return True. def subst(self):; return ttuple(*[t.subst() for t in self.types]). def clear(self):; for t in self.types:; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.types). def allele_pair(j: int, k: int):; assert j >= 0 and j <= 0xFFFF; assert k >= 0 and k <= 0xFFFF; return j | (k << 16). def allele_pair_sqrt(i):; k = int(math.sqrt(8 * float(i) + 1) / 2 - 0.5); assert k * (k + 1) // 2 <= i; j = i - k * (k + 1) // 2; # TODO another assert; return allele_pair(j, k). small_allele_pair = [; allele_pair(0, 0),; allele_pair(0, 1),; allele_pair(1, 1),; allele_pair(0, 2),; allele_pair(1, 2),; allele_pair(2, 2),; allele_pair(0, 3),; allele_pair(1, 3),; allele_pair(2, 3),; allele_pair(3, 3),; allele_pair(0, 4),; allele_pair(1, 4),; allele_pair(2, 4),; allele_pair(3, 4),; allele_pair(4, 4),; allele_pair(0, 5),; allele_pair(1, 5),; allele_pair(2, 5),; allele_pair(3, 5),; allele_pair(4, 5),; allele_pair(5, 5),; allele_pair(0, 6),; allele_pair(1, 6),; allele_pair(2, 6),; allele_pair(3, 6),; allele_pair(4, 6),; allele_pair(5, 6),; allele_pair(6, 6),; allele_pair(0, 7),; allele_pair(1, 7),; allele_pair(2, 7),; allele_pair(3, 7),; allele_pair(4, 7),; allele_pair(5, 7),; allele_pair(6, 7),; allele_pair(7, 7),; ]. class _tcall(Ha",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:41865,assert,assert,41865,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,4,['assert'],['assert']
Testability,"ning the Davies algorithm to compute the p-value as the right tail of a; weighted sum of \(\chi^2(1)\) distributions. fault value; Description. 0; no issues. 1; accuracy NOT achieved. 2; round-off error possibly significant. 3; invalid parameters. 4; unable to locate integration parameters. 5; out of memory. Parameters:. key_expr (Expression) – Row-indexed expression for key associated to each row.; weight_expr (Float64Expression) – Row-indexed expression for row weights.; y (Float64Expression) – Column-indexed response expression.; If logistic is True, all non-missing values must evaluate to 0 or; 1. Note that a BooleanExpression will be implicitly converted; to a Float64Expression with this property.; x (Float64Expression) – Entry-indexed expression for input variable.; covariates (list of Float64Expression) – List of column-indexed covariate expressions.; logistic (bool or tuple of int and float) – If false, use the linear test. If true, use the logistic test with no; more than 25 logistic iterations and a convergence tolerance of 1e-6. If; a tuple is given, use the logistic test with the tuple elements as the; maximum nubmer of iterations and convergence tolerance, respectively.; max_size (int) – Maximum size of group on which to run the test.; accuracy (float) – Accuracy achieved by the Davies algorithm if fault value is zero.; iterations (int) – Maximum number of iterations attempted by the Davies algorithm. Returns:; Table – Table of SKAT results. hail.methods.lambda_gc(p_value, approximate=True)[source]; Compute genomic inflation factor (lambda GC) from an Expression of p-values. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. Parameters:. p_value (NumericExpression) – Row-indexed numeric expression of p-values.; approximate (bool) – If False, computes exact lambda GC (slower and uses more memory). Returns:; float – Genomic inflation factor (lambda genomic control). ha",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:82167,log,logistic,82167,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,3,"['log', 'test']","['logistic', 'test']"
Testability,"no standard representation; for this at current). A record from a component GVCF is included in the; reference_data if it defines the END INFO field (if the GT is not reference,; an error will be thrown by the Hail VDS combiner).; The variant_data matrix table is a sparse matrix of non-reference calls.; This table contains the complete schema from the component GVCFs, aside from; fields which are known to be defined only for reference blocks (e.g. END or; MIN_DP). A record from a component GVCF is included in the variant_data if; it does not define the END INFO field. This means that some records of the; variant_data can be no-call (./.) or reference, depending on the; semantics of the variant caller that produced the GVCFs. Building analyses on the VariantDataset; Analyses operating on sequencing data can be largely grouped into three categories; by functionality used. Analyses that use prebuilt methods. Some analyses can be supported by using; only the utility functions defined in the hl.vds module, like; vds.sample_qc().; Analyses that use variant data and/or reference data separately. Some; pipelines need to interrogate properties of the component tables; individually. Examples might include singleton analysis or burden tests; (which needs only to look at the variant data) or coverage analysis (which; looks only at reference data). These pipelines should explicitly extract and; manipulate the component tables with vds.variant_data and; vds.reference_data.; Analyses that use the full variant-by-sample matrix with variant and reference data.; Many pipelines require variant and reference data together. There are helper; functions provided for producing either the sparse (containing reference; blocks) or dense (reference information is filled in at each variant site); representations. For more information, see the documentation for; vds.to_dense_mt() and vds.to_merged_sparse_mt(). Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/vds/index.html:8071,test,tests,8071,docs/0.2/vds/index.html,https://hail.is,https://hail.is/docs/0.2/vds/index.html,1,['test'],['tests']
Testability,"no.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). As above but with at most 100 Newton iterations and a stricter-than-default tolerance of 1e-8:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female],; ... max_iterations=100,; ... tolerance=1e-8). Warning; logistic_regression_rows() considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which all response variables and covariates are defined. For each row, missing values of; x are mean-imputed over these columns. As in the example, the; intercept covariate 1 must be included explicitly if desired. Notes; This method performs, for each row, a significance test of the input; variable in predicting a binary (case-control) response variable based; on the logistic regression model. The response variable type must either; be numeric (with all present values 0 or 1) or Boolean, in which case; true and false are coded as 1 and 0, respectively.; Hail supports the Wald test (‘wald’), likelihood ratio test (‘lrt’),; Rao score test (‘score’), and Firth test (‘firth’). Hail only includes; columns for which the response variable and all covariates are defined.; For each row, Hail imputes missing input values as the mean of the; non-missing values.; The example above considers a model of the form. \[\mathrm{Prob}(\mathrm{is\_case}) =; \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt}; + \beta_2 \, \mathrm{age}; + \beta_3 \, \mathrm{is\_female} + \varepsilon),; \quad; \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid function, the genotype; \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for Het, and 2 for; HomVar, and the Boolean covariate \(\mathrm{i",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:7956,test,test,7956,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representation of 7 is 111, so:; >>> hl.eval(hl.bit_count(7)); 3. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression. hail.expr.functions.exp(x)[source]. hail.expr.functions.expit(x)[source]. hail.expr.functions.is_nan(x)[source]. hail.expr.functions.is_finite(x)[source]. hail.expr.functions.is_infinite(x)[source]. hail.expr.functions.log(x, base=None)[source]; Take the logarithm of the x with base base.; Examples; >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; If the base argument is not supplied, then the natural logarithm is used. Parameters:. x (float or Expression of type tfloat64); base (float or Expression of type tfloat64). Returns:; Expression of type tfloat64. hail.expr.functions.log10(x)[source]. hail.expr.functions.logit(x)[source]. hail.expr.functions.floor(x)[source]. hail.expr.functions.ceil(x)[source]. hail.expr.functions.sqrt(x)[source]. hail.expr.functions.sign(x)[source]; Returns the sign of a numeric value, array or ndarray.; Examples; >>> hl.eval(hl.sign(-1.23)); -1.0. >>> hl.eval(hl.sign([-4, 0, 5])); [-1, 0, 1]. >>> hl.eval(hl.sign([0.0, 3.14])); [0.0, 1.0]. >>> hl.eval(hl.sign(float('nan'))); nan. Notes; The sign function preserves type and maps nan to nan. Parameters:; x (NumericExpression, ArrayNumericExpression or NDArrayNumericExpression). Returns:; NumericExpression, ArrayNumericExpression or NDArrayNumericExpression. hail.expr.functions.min(*exprs, filter_missing=True)[source]; Returns the minimum element of a collection or of given numer",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:7583,log,logarithm,7583,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['logarithm']
Testability,"not_called` (``int64``) -- Number of samples with a missing `GT`.; - `n_filtered` (``int64``) -- Number of filtered entries.; - `n_het` (``int64``) -- Number of heterozygous samples.; - `n_non_ref` (``int64``) -- Number of samples with at least one called; non-reference allele.; - `het_freq_hwe` (``float64``) -- Expected frequency of heterozygous; samples under Hardy-Weinberg equilibrium. See; :func:`.functions.hardy_weinberg_test` for details.; - `p_value_hwe` (``float64``) -- p-value from two-sided test of Hardy-Weinberg; equilibrium. See :func:`.functions.hardy_weinberg_test` for details.; - `p_value_excess_het` (``float64``) -- p-value from one-sided test of; Hardy-Weinberg equilibrium for excess heterozygosity.; See :func:`.functions.hardy_weinberg_test` for details. Warning; -------; `het_freq_hwe` and `p_value_hwe` are calculated as in; :func:`.functions.hardy_weinberg_test`, with non-diploid calls; (``ploidy != 2``) ignored in the counts. As this test is only; statistically rigorous in the biallelic setting, :func:`.variant_qc`; sets both fields to missing for multiallelic variants. Consider using; :func:`~hail.methods.split_multi` to split multi-allelic variants beforehand. Parameters; ----------; mt : :class:`.MatrixTable`; Dataset.; name : :class:`str`; Name for resulting field. Returns; -------; :class:`.MatrixTable`; """"""; require_alleles_field(mt, 'variant_qc'). bound_exprs = {}; gq_dp_exprs = {}. def has_field_of_type(name, dtype):; return name in mt.entry and mt[name].dtype == dtype. if has_field_of_type('DP', hl.tint32):; gq_dp_exprs['dp_stats'] = hl.agg.stats(mt.DP).select('mean', 'stdev', 'min', 'max'). if has_field_of_type('GQ', hl.tint32):; gq_dp_exprs['gq_stats'] = hl.agg.stats(mt.GQ).select('mean', 'stdev', 'min', 'max'). if not has_field_of_type('GT', hl.tcall):; raise ValueError(""'variant_qc': expect an entry field 'GT' of type 'call'""). bound_exprs['n_called'] = hl.agg.count_where(hl.is_defined(mt['GT'])); bound_exprs['n_not_called'] = hl.ag",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/qc.html:10793,test,test,10793,docs/0.2/_modules/hail/methods/qc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html,2,['test'],['test']
Testability,"notation is better optimized; if x in mt._fields_inverse:; x_field_name = mt._fields_inverse[x]; entry_expr = {}; else:; x_field_name = Env.get_uid(); entry_expr = {x_field_name: x}. y_field_name = '__y'; weight_field_name = '__weight'; key_field_name = '__key'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))). mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs={weight_field_name: weight_expr, key_field_name: key_expr},; entry_exprs=entry_expr,; ). if logistic is True:; use_logistic = True; max_iterations = 25; tolerance = 1e-6; elif logistic is False:; use_logistic = False; max_iterations = 0; tolerance = 0.0; else:; assert isinstance(logistic, tuple) and len(logistic) == 2; use_logistic = True; max_iterations, tolerance = logistic. config = {; 'name': 'Skat',; 'keyField': key_field_name,; 'weightField': weight_field_name,; 'xField': x_field_name,; 'yField': y_field_name,; 'covFields': cov_field_names,; 'logistic': use_logistic,; 'maxSize': max_size,; 'accuracy': accuracy,; 'iterations': iterations,; 'logistic_max_iterations': max_iterations,; 'logistic_tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). [docs]@typecheck(p_value=expr_numeric, approximate=bool); def lambda_gc(p_value, approximate=True):; """"""; Compute genomic inflation factor (lambda GC) from an Expression of p-values. .. include:: ../_templates/experimental.rst. Parameters; ----------; p_value : :class:`.NumericExpression`; Row-indexed numeric expression of p-values.; approximate : :obj:`bool`; If False, computes exact lambda GC (slower and uses more memory). Returns; -------; :obj:`float`; Genomic inflation factor (lambda genomic control).; """"""; raise_unless_row_indexed('lambda_gc', p_value); t = table_source('lambda_gc', p_value); med_chisq = _lambda_gc_agg(p_value, approximate); return t.aggregate(med_chisq). @typecheck(p_value=expr_numeric, approximate=bool); def _lambda_gc_agg(",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:109466,log,logistic,109466,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logistic']
Testability,"note there are two Qs: the Q from the QR decomposition and the; # Q-statistic from the paper):; #; # Q = r.T G diag(w) G.T r; # Z = r.T G diag(sqrt(w)); # Q = Z Z.T; #; # Plugging in our expresion for r:; #; # Z = y.T (I - Q Q.T) G diag(sqrt(w)); #; # Notice that I - Q Q.T is symmetric (ergo X = X.T) because each summand is symmetric and sums; # of symmetric matrices are symmetric matrices.; #; # We have asserted that; #; # y ~ N(0, \sigma^2); #; # It will soon be apparent that the distribution of Q is easier to characterize if our random; # variables are standard normals:; #; # h ~ N(0, 1); # y = \sigma h; #; # We set \sigma^2 to the sample variance of the residual vectors.; #; # Returning to Z:; #; # Z = h.T \sigma (I - Q Q.T) G diag(sqrt(w)); # Q = Z Z.T; #; # Which we can factor into a symmetric matrix and a standard normal:; #; # A = \sigma (I - Q Q.T) G diag(sqrt(w)); # B = A A.T; # Q = h.T B h; #; # This is called a ""quadratic form"". It is a weighted sum of products of pairs of entries of h,; # which we have asserted are i.i.d. standard normal variables. The distribution of such sums is; # given by the generalized chi-squared distribution:; #; # U L U.T = B B is symmetric and thus has an eigendecomposition; # h.T B h = Q ~ GeneralizedChiSquare(L, 1, 0, 0, 0); #; # The orthogonal matrix U remixes the vector of i.i.d. normal variables into a new vector of; # different i.i.d. normal variables. The L matrix is diagonal and scales each squared normal; # variable.; #; # Since B = A A.T is symmetric, its eigenvalues are the square of the singular values of A or; # A.T:; #; # W S V = A; # U L U.T = B; # = A A.T; # = W S V V.T S W; # = W S S W V is orthogonal so V V.T = I; # = W S^2 W. weights_arr = hl.array(ht.weight); A = (; hl.case(); .when(; hl.all(weights_arr.map(lambda x: x >= 0)),; (ht.G - ht.covmat_Q @ (ht.covmat_Q.T @ ht.G)) * hl.sqrt(ht.weight),; ); .or_error(; hl.format(; 'hl._linear_skat: every weight must be positive, in group %s, the weights were: %s',; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:84310,assert,asserted,84310,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['assert'],['asserted']
Testability,"ns.; block_size (int) – Number of row regressions to perform simultaneously per core. Larger blocks; require more memory but may improve performance.; pass_through (list of str or Expression) – Additional row fields to include in the resulting table.; weights (Float64Expression or list of Float64Expression) – Optional column-indexed weighting for doing weighted least squares regression. Specify a single weight if a; single y or list of ys is specified. If a list of lists of ys is specified, specify one weight per inner list. Returns:; Table. hail.methods.logistic_regression_rows(test, y, x, covariates, pass_through=(), *, max_iterations=None, tolerance=None)[source]; For each row, test an input variable for association with a; binary response variable using logistic regression.; Examples; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). As above but with at most 100 Newton iterations and a stricter-than-default tolerance of 1e-8:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female],; ... max_iterations=100,; ... tolerance=1e-8). Warning; logistic_regression_rows() conside",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:6583,test,test,6583,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['test']
Testability,"ns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return construct_expr(ir.ApplyUnaryPrimOp('~', x._ir), x.dtype, x._indices, x._aggregations). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_count(x):; """"""Count the number of 1s in the in the `two's complement <https://en.wikipedia.org/wiki/Two%27s_complement>`__ binary representation of `x`. Examples; --------; The binary representation of `7` is `111`, so:. ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:182006,log,logical,182006,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['logical']
Testability,"nse y must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded; as 1 and 0, respectively.; The resulting Table provides the group’s key (id), thenumber of; rows in the group (size), the variance component score q_stat, the SKAT; p-value, and a fault flag. For the toy example above, the table has the; form:. id; size; q_stat; p_value; fault. geneA; 2; 4.136; 0.205; 0. geneB; 1; 5.659; 0.195; 0. geneC; 3; 4.122; 0.192; 0. Groups larger than max_size appear with missing q_stat, p_value, and; fault. The hard limit on the number of rows in a group is 46340.; Note that the variance component score q_stat agrees with Q in the R; package skat, but both differ from \(Q\) in the paper by the factor; \(\frac{1}{2\sigma^2}\) in the linear case and \(\frac{1}{2}\) in; the logistic case, where \(\sigma^2\) is the unbiased estimator of; residual variance for the linear null model. The R package also applies a; “small-sample adjustment” to the null distribution in the logistic case; when the sample size is less than 2000. Hail does not apply this; adjustment.; The fault flag is an integer indicating whether any issues occurred when; running the Davies algorithm to compute the p-value as the right tail of a; weighted sum of \(\chi^2(1)\) distributions. fault value; Description. 0; no issues. 1; accuracy NOT achieved. 2; round-off error possibly significant. 3; invalid parameters. 4; unable to locate integration parameters. 5; out of memory. Parameters:. key_expr (Expression) – Row-indexed expression for key associated to each row.; weight_expr (Float64Expression) – Row-indexed expression for row weights.; y (Float64Expression) – Column-indexed response expression.; If logistic is True, all non-missing values must evaluate to 0 or; 1. Note that a BooleanExpression will be implicitly converted; to a Float64Expression with this property.; x (Float64Expression) – Entry-indexed expression for input variable.; covariates (list of Float64Ex",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:81033,log,logistic,81033,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['log'],['logistic']
Testability,"nstance(t, (tlocus, tinterval)):; return; if isinstance(t, tstruct):; for k, vt in t.items():; try:; raise_for_holes(vt); except ExpressionException as exc:; raise ExpressionException(f'cannot impute field {k}') from exc; return; if isinstance(t, ttuple):; for k, vt in enumerate(t):; try:; raise_for_holes(vt); except ExpressionException as exc:; raise ExpressionException(f'cannot impute {k}th element') from exc; return; if isinstance(t, (tarray, tset)):; try:; raise_for_holes(t.element_type); except ExpressionException as exc:; raise ExpressionException('cannot impute array elements') from exc; return; if isinstance(t, tdict):; try:; raise_for_holes(t.key_type); except ExpressionException as exc:; raise ExpressionException('cannot impute dict keys') from exc; try:; raise_for_holes(t.value_type); except ExpressionException as exc:; raise ExpressionException('cannot impute dict values') from exc; return. def to_expr(e, dtype=None, partial_type=None) -> 'Expression':; assert dtype is None or partial_type is None; if isinstance(e, Expression):; if dtype and not dtype == e.dtype:; raise TypeError(""expected expression of type '{}', found expression of type '{}'"".format(dtype, e.dtype)); return e; return cast_expr(e, dtype, partial_type). def cast_expr(e, dtype=None, partial_type=None) -> 'Expression':; assert dtype is None or partial_type is None; if not dtype:; dtype = impute_type(e, partial_type); x = _to_expr(e, dtype); if isinstance(x, Expression):; return x; else:; return hl.literal(x, dtype). def _to_expr(e, dtype):; if e is None:; return None; elif isinstance(e, Expression):; if e.dtype != dtype:; assert is_numeric(dtype), 'expected {}, got {}'.format(dtype, e.dtype); if dtype == tfloat64:; return hl.float64(e); elif dtype == tfloat32:; return hl.float32(e); elif dtype == tint64:; return hl.int64(e); else:; assert dtype == tint32; return hl.int32(e); return e; elif not is_compound(dtype):; # these are not container types and cannot contain expressions if we got her",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html:8658,assert,assert,8658,docs/0.2/_modules/hail/expr/expressions/base_expression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html,2,['assert'],['assert']
Testability,"nsufficient degrees of freedom: n=%s, k=%s"", mt.n, k); ); ),; covmat=hl.nd.array(mt.covmat),; n_complete_samples=mt.n,; ); covmat = mt.covmat; yvec = mt.yvec; n = mt.n_complete_samples. logmean = hl.log(yvec.sum() / n); b = hl.nd.array([logmean, *[0 for _ in range(k - 1)]]); mu = hl.exp(covmat @ b); residual = yvec - mu; score = covmat.T @ residual; fisher = (mu * covmat.T) @ covmat; mt = mt.annotate_globals(null_fit=_poisson_fit(covmat, yvec, b, mu, score, fisher, max_iterations, tolerance)); mt = mt.annotate_globals(; null_fit=hl.case(); .when(mt.null_fit.converged, mt.null_fit); .or_error(; hl.format(; '_lowered_poisson_regression_rows: null model did not converge: %s',; mt.null_fit.select('n_iterations', 'log_lkhd', 'converged', 'exploded'),; ); ); ); mt = mt.annotate_rows(mean_x=hl.agg.mean(mt.x)); mt = mt.annotate_rows(xvec=hl.nd.array(hl.agg.collect(hl.coalesce(mt.x, mt.mean_x)))); ht = mt.rows(). covmat = ht.covmat; null_fit = ht.null_fit; # FIXME: we should test a whole block of variants at a time not one-by-one; xvec = ht.xvec; yvec = ht.yvec. if test == 'score':; chi_sq, p = _poisson_score_test(null_fit, covmat, yvec, xvec); return ht.select(chi_sq_stat=chi_sq, p_value=p, **ht.pass_through).select_globals('null_fit'). X = hl.nd.hstack([covmat, xvec.T.reshape(-1, 1)]); b = hl.nd.hstack([null_fit.b, hl.nd.array([0.0])]); mu = sigmoid(X @ b); residual = yvec - mu; score = hl.nd.hstack([null_fit.score, hl.nd.array([xvec @ residual])]). fisher00 = null_fit.fisher; fisher01 = ((covmat.T * mu) @ xvec).reshape((-1, 1)); fisher10 = fisher01.T; fisher11 = hl.nd.array([[(mu * xvec.T) @ xvec]]); fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). test_fit = _poisson_fit(X, yvec, b, mu, score, fisher, max_iterations, tolerance); if test == 'lrt':; return ht.select(test_fit=test_fit, **lrt_test(X, null_fit, test_fit), **ht.pass_through).select_globals(; 'null_fit'; ); assert test == 'wald'; return ht.select(test_fit=test_fit",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:66504,test,test,66504,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"nt of an ndarray in a call to Table.transmute; would fail.; (#8855) Fix crash in; filter_intervals. Version 0.2.41; Released 2020-05-15. Bug fixes. (#8799)(#8786); Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a; tuple value. hailctl dataproc. (#8790) Use; configured compute zone as default for hailctl dataproc connect; and hailctl dataproc modify. Version 0.2.40; Released 2020-05-12. VCF Combiner. (#8706) Add option to; key by both locus and alleles for final output. Bug fixes. (#8729) Fix assertion; error in Table.group_by(...).aggregate(...); (#8708) Fix assertion; error in reading tables and matrix tables with _intervals option.; (#8756) Fix return; type of LocusExpression.window to use locus’s reference genome; instead of default RG. Version 0.2.39; Released 2020-04-29. Bug fixes. (#8615) Fix contig; ordering in the CanFam3 (dog) reference genome.; (#8622) Fix bug that; causes inscrutable JVM Bytecode errors.; (#8645) Ease; unnecessarily strict assertion that caused errors when aggregating by; key (e.g. hl.experimental.spread).; (#8621); hl.nd.array now supports arrays with no elements; (e.g. hl.nd.array([]).reshape((0, 5))) and, consequently, matmul; with an inner dimension of zero. New features. (#8571); hl.init(skip_logging_configuration=True) will skip configuration; of Log4j. Users may use this to configure their own logging.; (#8588) Users who; manually build Python wheels will experience less unnecessary output; when doing so.; (#8572) Add; hl.parse_json which converts a string containing JSON into a Hail; object. Performance Improvements. (#8535) Increase; speed of import_vcf.; (#8618) Increase; speed of Jupyter Notebook file listing and Notebook creation when; buckets contain many objects.; (#8613); hl.experimental.export_entries_by_col stages files for improved; reliability and performance. Documentation. (#8619) Improve; installation documentation to suggest better performing LAPACK and; BLAS libraries.; (#8647) Clarify t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:71619,assert,assertion,71619,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['assert'],['assertion']
Testability,"nt; number of eigenvectors of kinship matrix used to fit model. global.lmmreg.dropped_variance_fraction; Double; specified value of dropped_variance_fraction. global.lmmreg.evals; Array[Double]; all eigenvalues of the kinship matrix in descending order. global.lmmreg.fit.seH2; Double; standard error of \(\hat{h}^2\) under asymptotic normal approximation. global.lmmreg.fit.normLkhdH2; Array[Double]; likelihood function of \(h^2\) normalized on the discrete grid 0.01, 0.02, ..., 0.99. Index i is the likelihood for percentage i. global.lmmreg.fit.maxLogLkhd; Double; (restricted) maximum log likelihood corresponding to \(\hat{\delta}\). global.lmmreg.fit.logDeltaGrid; Array[Double]; values of \(\mathrm{ln}(\delta)\) used in the grid search. global.lmmreg.fit.logLkhdVals; Array[Double]; (restricted) log likelihood of \(y\) given \(X\) and \(\mathrm{ln}(\delta)\) at the (RE)ML fit of \(\beta\) and \(\sigma_g^2\). These global annotations are also added to hail.log, with the ranked evals and \(\delta\) grid with values in .tsv tabular form. Use grep 'lmmreg:' hail.log to find the lines just above each table.; If Step 5 is performed, lmmreg() also adds four linear regression variant annotations. Annotation; Type; Value. va.lmmreg.beta; Double; fit genotype coefficient, \(\hat\beta_0\). va.lmmreg.sigmaG2; Double; fit coefficient of genetic variance component, \(\hat{\sigma}_g^2\). va.lmmreg.chi2; Double; \(\chi^2\) statistic of the likelihood ratio test. va.lmmreg.pval; Double; \(p\)-value. Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; The simplest way to export all resulting annotations is:; >>> lmm_vds.export_variants('output/lmmreg.tsv.bgz', 'variant = v, va.lmmreg.*'); >>> lmmreg_results = lmm_vds.globals['lmmreg']. By default, genotypes values are given by hard call genotypes (g.gt).; If use_dosages=True, then genotype values for per-variant association are defined by the dosage; \(\mathrm{P}(",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:94933,log,log,94933,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['log']
Testability,"ntry_indexed('skat/x', x). analyze('skat/key_expr', key_expr, mt._row_indices); analyze('skat/weight_expr', weight_expr, mt._row_indices); analyze('skat/y', y, mt._col_indices). all_exprs = [key_expr, weight_expr, y]; for e in covariates:; all_exprs.append(e); analyze('skat/covariates', e, mt._col_indices). _warn_if_no_intercept('skat', covariates). # FIXME: remove this logic when annotation is better optimized; if x in mt._fields_inverse:; x_field_name = mt._fields_inverse[x]; entry_expr = {}; else:; x_field_name = Env.get_uid(); entry_expr = {x_field_name: x}. y_field_name = '__y'; weight_field_name = '__weight'; key_field_name = '__key'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))). mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs={weight_field_name: weight_expr, key_field_name: key_expr},; entry_exprs=entry_expr,; ). if logistic is True:; use_logistic = True; max_iterations = 25; tolerance = 1e-6; elif logistic is False:; use_logistic = False; max_iterations = 0; tolerance = 0.0; else:; assert isinstance(logistic, tuple) and len(logistic) == 2; use_logistic = True; max_iterations, tolerance = logistic. config = {; 'name': 'Skat',; 'keyField': key_field_name,; 'weightField': weight_field_name,; 'xField': x_field_name,; 'yField': y_field_name,; 'covFields': cov_field_names,; 'logistic': use_logistic,; 'maxSize': max_size,; 'accuracy': accuracy,; 'iterations': iterations,; 'logistic_max_iterations': max_iterations,; 'logistic_tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). [docs]@typecheck(p_value=expr_numeric, approximate=bool); def lambda_gc(p_value, approximate=True):; """"""; Compute genomic inflation factor (lambda GC) from an Expression of p-values. .. include:: ../_templates/experimental.rst. Parameters; ----------; p_value : :class:`.NumericExpression`; Row-indexed numeric expression of p-values.; approximate : :obj:`bool`; If False,",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:109003,log,logistic,109003,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,['log'],['logistic']
Testability,"numeric); def __pow__(self, x):; """"""Element-wise exponentiation: a ** x. Parameters; ----------; x: :obj:`int` or :obj:`float`; Exponent. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda i: i**x, needs_dense=False). def _map_dense(self, func):; return self._apply_map(func, True). def _map_sparse(self, func):; return self._apply_map(func, False). [docs] def sqrt(self):; """"""Element-wise square root. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.sqrt, needs_dense=False). [docs] def ceil(self):; """"""Element-wise ceiling. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.ceil, needs_dense=False). [docs] def floor(self):; """"""Element-wise floor. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.floor, needs_dense=False). [docs] def abs(self):; """"""Element-wise absolute value. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.abs, needs_dense=False). [docs] def log(self):; """"""Element-wise natural logarithm. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda x: hl.log(x), needs_dense=True). [docs] def diagonal(self):; """"""Extracts diagonal elements as a row vector. Returns; -------; :class:`.BlockMatrix`; """"""; diag_bmir = BlockMatrixBroadcast(self._bmir, [0, 0], [1, min(self.n_rows, self.n_cols)], self.block_size); return BlockMatrix(diag_bmir). [docs] @typecheck_method(axis=nullable(int)); def sum(self, axis=None):; """"""Sums array elements over one or both axes. Examples; --------; >>> import numpy as np; >>> nd = np.array([[ 1.0, 2.0, 3.0],; ... [ 4.0, 5.0, 6.0]]); >>> bm = BlockMatrix.from_numpy(nd); >>> bm.sum(); 21.0. >>> bm.sum(axis=0).to_numpy(); array([[5., 7., 9.]]). >>> bm.sum(axis=1).to_numpy(); array([[ 6.],; [15.]]). Parameters; ----------; axis: :obj:`int`, optional; Axis over which to sum.; By default, sum all elements.; If ``0``, sum over rows.; If ``1``, sum over columns. Returns; -------; :obj:`float` or :class:`BlockMa",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:51683,log,log,51683,docs/0.2/_modules/hail/linalg/blockmatrix.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html,4,['log'],"['log', 'logarithm']"
Testability,"o_to_keep,; ),; ['locus'],; lambda k, v: k.annotate(data=v),; ),; globals=hl.struct(g=hl.literal(ids).map(lambda s: hl.struct(__cols=[hl.struct(s=s)]))),; ); variant_ht = combine(variant_ht); vds = VariantDataset(; reference_ht._unlocalize_entries('__entries', '__cols', ['s']),; variant_ht._unlocalize_entries('__entries', '__cols', ['s'])._key_rows_by_assert_sorted(; 'locus', 'alleles'; ),; ). merge_vds.append(vds); merge_n_samples.append(len(merging)); if self.finished and len(merge_vds) == 1:; self._write_final(merge_vds[0]); return. temp_path = self._temp_out_path(f'gvcf-combine_job{self._job_id}/dataset_'); pad = len(str(len(merge_vds) - 1)); merge_metadata = [; VDSMetadata(path=temp_path + str(count).rjust(pad, '0') + '.vds', n_samples=n_samples); for count, n_samples in enumerate(merge_n_samples); ]; paths = [md.path for md in merge_metadata]; hl.vds.write_variant_datasets(merge_vds, paths, overwrite=True, codec_spec=FAST_CODEC_SPEC); for md in merge_metadata:; self._vdses[max(1, floor(log(md.n_samples, self._branch_factor)))].append(md). def _temp_out_path(self, extra):; return os.path.join(self._temp_path, 'combiner-intermediates', f'{self._uuid}_{extra}'). def _read_variant_datasets(self, inputs: List[str], intervals: List[Interval]):; reference_type = self._dataset_type.reference_type; variant_type = self._dataset_type.variant_type; return [; hl.vds.read_vds(; path,; intervals=intervals,; _assert_reference_type=reference_type,; _assert_variant_type=variant_type,; _warn_no_ref_block_max_length=False,; ); for path in inputs; ]. [docs]def new_combiner(; *,; output_path: str,; temp_path: str,; save_path: Optional[str] = None,; gvcf_paths: Optional[List[str]] = None,; vds_paths: Optional[List[str]] = None,; vds_sample_counts: Optional[List[int]] = None,; intervals: Optional[List[Interval]] = None,; import_interval_size: Optional[int] = None,; use_genome_default_intervals: bool = False,; use_exome_default_intervals: bool = False,; gvcf_external_header: Optional[s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html:22015,log,log,22015,docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,2,['log'],['log']
Testability,"oadcasting; def ceil(x):; """"""The smallest integral value that is greater than or equal to `x`. Examples; --------. >>> hl.eval(hl.ceil(3.1)); 4.0. Parameters; ----------; x : :class:`.Float32Expression`,:class:`.Float64Expression` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`; """"""; return _func(""ceil"", x.dtype, x). [docs]@typecheck(n_hom_ref=expr_int32, n_het=expr_int32, n_hom_var=expr_int32, one_sided=expr_bool); def hardy_weinberg_test(n_hom_ref, n_het, n_hom_var, one_sided=False) -> StructExpression:; """"""Performs test of Hardy-Weinberg equilibrium. Examples; --------. >>> hl.eval(hl.hardy_weinberg_test(250, 500, 250)); Struct(het_freq_hwe=0.5002501250625313, p_value=0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; -----; By default, this method performs a two-sided exact test with mid-p-value correction of; `Hardy-Weinberg equilibrium <https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle>`__; via an efficient implementation of the; `Levene-Haldane distribution <../_static/LeveneHaldane.pdf>`__,; which models the number of heterozygous individuals under equilibrium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n_hom_var`` is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; `het_freq_hwe`, is this mean divided by ``n``. To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set `one_sided=True` and the p-value returned will be; from the one-sided exact test. Parameters; ----------; n_hom_ref : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous reference g",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:34182,test,test,34182,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"oat or Expression of type tfloat64) – Mean (default = 0).; sigma (float or Expression of type tfloat64) – Standard deviation (default = 1).; log_p (bool or BooleanExpression) – If True, the natural logarithm of the probability density is returned. Returns:; Expression of type tfloat64 – The probability density. hail.expr.functions.dpois(x, lamb, log_p=False)[source]; Compute the (log) probability density at x of a Poisson distribution with rate parameter lamb.; Examples; >>> hl.eval(hl.dpois(5, 3)); 0.10081881344492458. Parameters:. x (float or Expression of type tfloat64) – Non-negative number at which to compute the probability density.; lamb (float or Expression of type tfloat64) – Poisson rate parameter. Must be non-negative.; log_p (bool or BooleanExpression) – If True, the natural logarithm of the probability density is returned. Returns:; Expression of type tfloat64 – The (log) probability density. hail.expr.functions.hardy_weinberg_test(n_hom_ref, n_het, n_hom_var, one_sided=False)[source]; Performs test of Hardy-Weinberg equilibrium.; Examples; >>> hl.eval(hl.hardy_weinberg_test(250, 500, 250)); Struct(het_freq_hwe=0.5002501250625313, p_value=0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; By default, this method performs a two-sided exact test with mid-p-value correction of; Hardy-Weinberg equilibrium; via an efficient implementation of the; Levene-Haldane distribution,; which models the number of heterozygous individuals under equilibrium.; The mean of this distribution is (n_ref * n_var) / (2n - 1), where; n_ref = 2*n_hom_ref + n_het is the number of reference alleles,; n_var = 2*n_hom_var + n_het is the number of variant alleles,; and n = n_hom_ref + n_het + n_hom_var is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; het_freq_hwe, is this mean divided by n.; To perform one-sided exact test of excess hetero",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:11146,test,test,11146,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['test'],['test']
Testability,"ocal_df_y.index.to_list():; checkpoint = checkpoint_path(window); if hfs.exists(checkpoint):; result = b.read_input(checkpoint); results.append(result); continue. j = b.new_python_job(). result = j.call(random_forest, df_x_input, df_y_input, window); tsv_result = j.call(as_tsv, result); tsv_result = tsv_result.as_str(). b.write_output(tsv_result, checkpoint); results.append(tsv_result). output = hb.concatenate(b, results); b.write_output(output, output_path). b.run(wait=False); backend.close(). run_rf_checkpoint_batching.py; from typing import Tuple. import pandas as pd; from sklearn.ensemble import RandomForestRegressor. import hailtop.batch as hb; import hailtop.fs as hfs; from hailtop.utils import grouped. def random_forest(df_x_path: str, df_y_path: str, window_name: str, cores: int = 1) -> Tuple[str, float, float]:; # read in data; df_x = pd.read_table(df_x_path, header=0, index_col=0); df_y = pd.read_table(df_y_path, header=0, index_col=0). # split training and testing data for the current window; x_train = df_x[df_x.index != window_name]; x_test = df_x[df_x.index == window_name]. y_train = df_y[df_y.index != window_name]; y_test = df_y[df_y.index == window_name]. # run random forest; max_features = 3 / 4; rf = RandomForestRegressor(n_estimators=100, n_jobs=cores, max_features=max_features, oob_score=True, verbose=False). rf.fit(x_train, y_train). # apply the trained random forest on testing data; y_pred = rf.predict(x_test). # store obs and pred values for this window; obs = y_test[""oe""].to_list()[0]; pred = y_pred[0]. return (window_name, obs, pred). def as_tsv(input: Tuple[str, float, float]) -> str:; return '\t'.join(str(i) for i in input). def checkpoint_path(window):; return f'gs://my_bucket/checkpoints/random-forest/{window}'. def main(df_x_path, df_y_path, output_path, python_image):; backend = hb.ServiceBackend(); b = hb.Batch(name='rf-loo', default_python_image=python_image). with hfs.open(df_y_path) as f:; local_df_y = pd.read_table(f, header=0, ind",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/cookbook/random_forest.html:15921,test,testing,15921,docs/batch/cookbook/random_forest.html,https://hail.is,https://hail.is/docs/batch/cookbook/random_forest.html,2,['test'],['testing']
Testability,"ock size requires more memmory. Returns:Variant dataset with linear regression variant annotations. Return type:VariantDataset. linreg_burden(key_name, variant_keys, single_key, agg_expr, y, covariates=[])[source]¶; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; linear regression model. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Run a gene burden test using linear regression on the maximum genotype per gene. Here va.genes is a variant; annotation of type Set[String] giving the set of genes containing the variant (see Extended example below; for a deep dive):; >>> linreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .linreg_burden(key_name='gene',; ... variant_keys='va.genes',; ... single_key=False,; ... agg_expr='gs.map(g => g.gt).max()',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). Run a gene burden test using linear regression on the weighted sum of genotypes per gene. Here va.gene is; a variant annotation of type String giving a single gene per variant (or no gene if missing), and va.weight; is a numeric variant annotation:; >>> linreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .linreg_burden(key_name='gene',; ... variant_keys='va.gene',; ... single_key=True,; ... agg_expr='gs.map(g => va.weight * g.gt).sum()',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). To use a weighted sum of genotypes with missing genotypes mean-imputed rather than ignored, set; agg_expr='gs.map(g => va.weight * orElse(g.gt.toDouble, 2 * va.qc.AF)).sum()' where va.qc.AF; is the allele frequency over those samples that have no missing phenotype or covariates. Caution; With single_key=False, variant_keys expects a variant annotation of Set or Array type, in order to; allow each variant to have zero, one, or more keys (for example, the same variant may appear in multiple; genes). Unlik",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:84915,test,test,84915,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"octest: +SKIP_OUTPUT_CHECK; {'Bob'}. Notes; -----; Returns a same-type expression; evaluated on a :class:`.SetExpression`, returns a; :class:`.SetExpression`. Evaluated on an :class:`.ArrayExpression`,; returns an :class:`.ArrayExpression`. Parameters; ----------; f : function ( (arg) -> :class:`.BooleanExpression`); Function to evaluate for each element of the collection. Must return a; :class:`.BooleanExpression`. Returns; -------; :class:`.CollectionExpression`; Expression of the same type as the callee.; """"""; # FIXME: enable doctest. def unify_ret(t):; if t != tbool:; raise TypeError(""'filter' expects 'f' to return an expression of type 'bool', found '{}'"".format(t)); return hl.tarray(self._type.element_type). def transform_ir(array, name, body):; return ir.toArray(ir.StreamFilter(ir.toStream(array), name, body)). array_filter = hl.array(self)._ir_lambda_method(transform_ir, f, self.dtype.element_type, unify_ret). if isinstance(self.dtype, tset):; return hl.set(array_filter); else:; assert isinstance(self.dtype, tarray), self.dtype; return array_filter. [docs] @typecheck_method(f=func_spec(1, expr_bool)); def find(self, f):; """"""Returns the first element where `f` returns ``True``. Examples; --------. >>> hl.eval(a.find(lambda x: x ** 2 > 20)); 5. >>> hl.eval(s3.find(lambda x: x[0] == 'D')); None. Notes; -----; If `f` returns ``False`` for every element, then the result is missing. Parameters; ----------; f : function ( (arg) -> :class:`.BooleanExpression`); Function to evaluate for each element of the collection. Must return a; :class:`.BooleanExpression`. Returns; -------; :class:`.Expression`; Expression whose type is the element type of the collection.; """""". # FIXME this should short-circuit; return self.fold(; lambda accum, x: hl.if_else(hl.is_missing(accum) & f(x), x, accum), hl.missing(self._type.element_type); ). [docs] @typecheck_method(f=func_spec(1, expr_any)); def flatmap(self, f):; """"""Map each element of the collection to a new collection, and flatten",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:4009,assert,assert,4009,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['assert'],['assert']
Testability,"odds ratio equals 1).; Returned fields may be nan or inf. Parameters:. c1 (int or Expression of type tint32) – Value for cell 1.; c2 (int or Expression of type tint32) – Value for cell 2.; c3 (int or Expression of type tint32) – Value for cell 3.; c4 (int or Expression of type tint32) – Value for cell 4. Returns:; StructExpression – A tstruct expression with four fields, p_value; (tfloat64), odds_ratio (tfloat64),; ci_95_lower (:py:data:.tfloat64`), and ci_95_upper; (tfloat64). hail.expr.functions.contingency_table_test(c1, c2, c3, c4, min_cell_count)[source]; Performs chi-squared or Fisher’s exact test of independence on a 2x2; contingency table.; Examples; >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=22)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=23)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967). Notes; If all cell counts are at least min_cell_count, the chi-squared test is; used. Otherwise, Fisher’s exact test is used.; Returned fields may be nan or inf. Parameters:. c1 (int or Expression of type tint32) – Value for cell 1.; c2 (int or Expression of type tint32) – Value for cell 2.; c3 (int or Expression of type tint32) – Value for cell 3.; c4 (int or Expression of type tint32) – Value for cell 4.; min_cell_count (int or Expression of type tint32) – Minimum count in every cell to use the chi-squared test. Returns:; StructExpression – A tstruct expression with two fields, p_value; (tfloat64) and odds_ratio (tfloat64). hail.expr.functions.cochran_mantel_haenszel_test(a, b, c, d)[source]; Perform the Cochran-Mantel-Haenszel test for association.; Examples; >>> a = [56, 61, 73, 71]; >>> b = [69, 257, 65, 48]; >>> c = [40, 57, 71, 55]; >>> d = [77, 301, 79, 48]; >>> hl.eval(hl.cochran_mantel_haenszel_test(a, b, c, d)); Struct(test_statistic=5.0496881823306765, p_value=0.024630370456863417). >>> mt = ds.filter_rows(mt.locu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:5600,test,test,5600,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['test'],['test']
Testability,odel() (in module hail.methods). linear_mixed_regression_rows() (in module hail.methods). linear_regression_rows() (in module hail.methods). LinearMixedModel (class in hail.stats). linreg() (in module hail.expr.aggregators). literal() (in module hail.expr.functions). load() (hail.vds.combiner.VariantDatasetCombiner static method). load_combiner() (in module hail.vds.combiner). load_dataset() (in module hail.experimental). local_to_global() (in module hail.vds). localize_entries() (hail.MatrixTable method). Locus (class in hail.genetics). locus() (in module hail.expr.functions). locus_from_global_position() (hail.genetics.ReferenceGenome method). (in module hail.expr.functions). locus_interval() (in module hail.expr.functions). locus_windows() (in module hail.linalg.utils). LocusExpression (class in hail.expr). log() (hail.linalg.BlockMatrix method). (in module hail.expr.functions). log10() (in module hail.expr.functions). logistic_regression_rows() (in module hail.methods). logit() (in module hail.expr.functions). loop() (in module hail.experimental). lower() (hail.expr.StringExpression method). ls() (in module hailtop.fs). M. make_betas() (in module hail.experimental.ldscsim). make_table() (hail.MatrixTable method). manhattan() (in module hail.plot). map() (hail.expr.ArrayExpression method). (hail.expr.ArrayNumericExpression method). (hail.expr.CollectionExpression method). (hail.expr.NDArrayExpression method). (hail.expr.NDArrayNumericExpression method). (hail.expr.SetExpression method). (in module hail.expr.functions). map2() (hail.expr.NDArrayExpression method). (hail.expr.NDArrayNumericExpression method). map_values() (hail.expr.DictExpression method). mat_id (hail.genetics.Trio property). matches() (hail.expr.StringExpression method). MatrixTable (class in hail). max() (in module hail.expr.aggregators). (in module hail.expr.functions). maximal_independent_set() (in module hail.methods). maximum() (in module hail.nd). mean() (in module hail.expr.aggregators). (i,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/genindex.html:33593,log,logit,33593,docs/0.2/genindex.html,https://hail.is,https://hail.is/docs/0.2/genindex.html,1,['log'],['logit']
Testability,"of called genotypes; \(X_v = \left[v | X \right] = n \times (1 + c)\) matrix concatenating \(v\) and \(X\); \(\beta_v = (\beta^0_v, \beta^1_v, \ldots, \beta^c_v) = (1 + c) \times 1\) vector of covariate coefficients. Fixing \(\delta\) at the global REML estimate \(\hat{\delta}\), we find the REML estimate \((\hat{\beta}_v, \hat{\sigma}_{g,v}^2)\) via rotation of the model. \[y \sim \mathrm{N}\left(X_v\beta_v, \sigma_{g,v}^2 (K + \hat{\delta} I)\right)\]; Note that the only new rotation to compute here is \(U^T v\).; To test the null hypothesis that the genotype coefficient \(\beta^0_v\) is zero, we consider the restricted model with parameters \(((0, \beta^1_v, \ldots, \beta^c_v), \sigma_{g,v}^2)\) within the full model with parameters \((\beta^0_v, \beta^1_v, \ldots, \beta^c_v), \sigma_{g_v}^2)\), with \(\delta\) fixed at \(\hat\delta\) in both. The latter fit is simply that of the global model, \(((0, \hat{\beta}^1, \ldots, \hat{\beta}^c), \hat{\sigma}_g^2)\). The likelihood ratio test statistic is given by. \[\chi^2 = n \, \mathrm{ln}\left(\frac{\hat{\sigma}^2_g}{\hat{\sigma}_{g,v}^2}\right)\]; and follows a chi-squared distribution with one degree of freedom. Here the ratio \(\hat{\sigma}^2_g / \hat{\sigma}_{g,v}^2\) captures the degree to which adding the variant \(v\) to the global model reduces the residual phenotypic variance.; Kinship Matrix; FastLMM uses the Realized Relationship Matrix (RRM) for kinship. This can be computed with rrm(). However, any instance of KinshipMatrix may be used, so long as sample_list contains the complete samples of the caller variant dataset in the same order.; Low-rank approximation of kinship for improved performance; lmmreg() can implicitly use a low-rank approximation of the kinship matrix to more rapidly fit delta and the statistics for each variant. The computational complexity per variant is proportional to the number of eigenvectors used. This number can be specified in two ways. Specify the parameter n_eigs to use only ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:105973,test,test,105973,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"of(expr_int32, expr_int64), y=expr_int32); def bit_lshift(x, y):; """"""Bitwise left-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:. >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_in",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:181226,log,logical,181226,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['logical']
Testability,"og_p]); The quantile function of a Poisson distribution with rate parameter lamb, inverts ppois(). hail.expr.functions.chi_squared_test(c1, c2, c3, c4)[source]; Performs chi-squared test of independence on a 2x2 contingency table.; Examples; >>> hl.eval(hl.chi_squared_test(10, 10, 10, 10)); Struct(p_value=1.0, odds_ratio=1.0). >>> hl.eval(hl.chi_squared_test(51, 43, 22, 92)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). Notes; The odds ratio is given by (c1 / c2) / (c3 / c4).; Returned fields may be nan or inf. Parameters:. c1 (int or Expression of type tint32) – Value for cell 1.; c2 (int or Expression of type tint32) – Value for cell 2.; c3 (int or Expression of type tint32) – Value for cell 3.; c4 (int or Expression of type tint32) – Value for cell 4. Returns:; StructExpression – A tstruct expression with two fields, p_value; (tfloat64) and odds_ratio (tfloat64). hail.expr.functions.fisher_exact_test(c1, c2, c3, c4)[source]; Calculates the p-value, odds ratio, and 95% confidence interval using; Fisher’s exact test for a 2x2 table.; Examples; >>> hl.eval(hl.fisher_exact_test(10, 10, 10, 10)); Struct(p_value=1.0000000000000002, odds_ratio=1.0,; ci_95_lower=0.24385796914260355, ci_95_upper=4.100747675033819). >>> hl.eval(hl.fisher_exact_test(51, 43, 22, 92)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967,; ci_95_lower=2.5659373368248444, ci_95_upper=9.677929632035475). Notes; This method is identical to the version implemented in; R with default; parameters (two-sided, alpha = 0.05, null hypothesis that the odds ratio equals 1).; Returned fields may be nan or inf. Parameters:. c1 (int or Expression of type tint32) – Value for cell 1.; c2 (int or Expression of type tint32) – Value for cell 2.; c3 (int or Expression of type tint32) – Value for cell 3.; c4 (int or Expression of type tint32) – Value for cell 4. Returns:; StructExpression – A tstruct expression with four fields, p_value; (tfloat64), odds_ratio (tfloat64),; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:4044,test,test,4044,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['test'],['test']
Testability,"ogistic, and linear regression models to this data, where ``x`` is genotype, ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085, and 0.0016, respectively. The erroneous value 0.991 is due to quasi-complete separation. Moving one of the 10 hets from case to control eliminates this quasi-complete separation; the p-values from R are then 0.0373, 0.0111, and 0.0116, respectively, as expected for a less significant association. The Firth test reduces bias from small counts and resolves the issue of separation by penalizing maximum likelihood estimation by the `Jeffrey's invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton method is linear rather than quadratic. For Firth, 100 iterations are attempted for the null model and, if that is successful, for the full model as well. In testing we find 20 iterations nearly always suffices. If the null model fails to converge, then the ``sa.lmmreg.fit`` annotations reflect the null model; otherwise, they reflect the full model. See `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__ for an empirical comparison of the logistic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert's notes `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__. Firth introduced his approach in `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Courses/Stat376/Pa",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:145874,test,test,145874,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['test']
Testability,"ogle Storage, S3, or HDFS.; quiet : :obj:`bool`; Print fewer log messages.; append : :obj:`bool`; Append to the end of the log file.; min_block_size : :obj:`int`; Minimum file block size in MB.; branching_factor : :obj:`int`; Branching factor for tree aggregation.; tmp_dir : :class:`str`, optional; Networked temporary directory. Must be a network-visible file; path. Defaults to /tmp in the default scheme.; default_reference : :class:`str`; *Deprecated*. Please use :func:`.default_reference` to set the default reference genome. Default reference genome. Either ``'GRCh37'``, ``'GRCh38'``,; ``'GRCm38'``, or ``'CanFam3'``.; idempotent : :obj:`bool`; If ``True``, calling this function is a no-op if Hail has already been initialized.; global_seed : :obj:`int`, optional; Global random seed.; spark_conf : :obj:`dict` of :class:`str` to :class`str`, optional; Spark backend only. Spark configuration parameters.; skip_logging_configuration : :obj:`bool`; Spark Backend only. Skip logging configuration in java and python.; local_tmpdir : :class:`str`, optional; Local temporary directory. Used on driver and executor nodes.; Must use the file scheme. Defaults to TMPDIR, or /tmp.; driver_cores : :class:`str` or :class:`int`, optional; Batch backend only. Number of cores to use for the driver process. May be 1, 2, 4, or 8. Default is; 1.; driver_memory : :class:`str`, optional; Batch backend only. Memory tier to use for the driver process. May be standard or; highmem. Default is standard.; worker_cores : :class:`str` or :class:`int`, optional; Batch backend only. Number of cores to use for the worker processes. May be 1, 2, 4, or 8. Default is; 1.; worker_memory : :class:`str`, optional; Batch backend only. Memory tier to use for the worker processes. May be standard or; highmem. Default is standard.; gcs_requester_pays_configuration : either :class:`str` or :class:`tuple` of :class:`str` and :class:`list` of :class:`str`, optional; If a string is provided, configure the Google Cloud",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:10097,log,logging,10097,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['log'],['logging']
Testability,"oing weighted least squares regression. Specify a single weight if a; single y or list of ys is specified. If a list of lists of ys is specified, specify one weight per inner list. Returns:; Table. hail.methods.logistic_regression_rows(test, y, x, covariates, pass_through=(), *, max_iterations=None, tolerance=None)[source]; For each row, test an input variable for association with a; binary response variable using logistic regression.; Examples; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). As above but with at most 100 Newton iterations and a stricter-than-default tolerance of 1e-8:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female],; ... max_iterations=100,; ... tolerance=1e-8). Warning; logistic_regression_rows() considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which all response variables and covariates are defined. For each row, missing values of; x are mean-imputed over these columns. As in the example, the; intercept covariate 1 must be included explicitly if desired. Notes; This method performs, for each row,",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:6933,test,test,6933,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['test']
Testability,"oject,; remote_tmpdir=remote_tmpdir,; disable_progress_bar=disable_progress_bar,; driver_cores=driver_cores,; driver_memory=driver_memory,; worker_cores=worker_cores,; worker_memory=worker_memory,; name_prefix=name_prefix,; credentials_token=token,; regions=regions,; gcs_requester_pays_configuration=gcs_requester_pays_configuration,; gcs_bucket_allow_list=gcs_bucket_allow_list,; ). log = _get_log(log); if tmpdir is None:; tmpdir = backend.remote_tmpdir + 'tmp/hail/' + secret_alnum_string(); local_tmpdir = _get_local_tmpdir(local_tmpdir). HailContext.create(log, quiet, append, tmpdir, local_tmpdir, default_reference, global_seed, backend). @typecheck(; log=nullable(str),; quiet=bool,; append=bool,; branching_factor=int,; tmpdir=nullable(str),; default_reference=enumeration(*BUILTIN_REFERENCES),; global_seed=nullable(int),; skip_logging_configuration=bool,; jvm_heap_size=nullable(str),; _optimizer_iterations=nullable(int),; gcs_requester_pays_configuration=nullable(oneof(str, sized_tupleof(str, sequenceof(str)))),; ); def init_local(; log=None,; quiet=False,; append=False,; branching_factor=50,; tmpdir=None,; default_reference='GRCh37',; global_seed=None,; skip_logging_configuration=False,; jvm_heap_size=None,; _optimizer_iterations=None,; gcs_requester_pays_configuration: Optional[GCSRequesterPaysConfiguration] = None,; ):; from hail.backend.local_backend import LocalBackend; from hail.backend.py4j_backend import connect_logger. log = _get_log(log); tmpdir = _get_tmpdir(tmpdir); optimizer_iterations = get_env_or_default(_optimizer_iterations, 'HAIL_OPTIMIZER_ITERATIONS', 3). jvm_heap_size = get_env_or_default(jvm_heap_size, 'HAIL_LOCAL_BACKEND_HEAP_SIZE', None); backend = LocalBackend(; tmpdir,; log,; quiet,; append,; branching_factor,; skip_logging_configuration,; optimizer_iterations,; jvm_heap_size,; gcs_requester_pays_configuration,; ). if not backend.fs.exists(tmpdir):; backend.fs.mkdir(tmpdir). HailContext.create(log, quiet, append, tmpdir, tmpdir, default_refer",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:18781,log,log,18781,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,4,['log'],['log']
Testability,"ok_handle=True); interact(handle). [docs]def cdf(data, k=350, legend=None, title=None, normalize=True, log=False) -> figure:; """"""Create a cumulative density plot. Parameters; ----------; data : :class:`.Struct` or :class:`.Float64Expression`; Sequence of data to plot.; k : int; Accuracy parameter (passed to :func:`~.approx_cdf`).; legend : str; Label of data on the x-axis.; title : str; Title of the histogram.; normalize: bool; Whether or not the cumulative data should be normalized.; log: bool; Whether or not the y-axis should be of type log. Returns; -------; :class:`bokeh.plotting.figure`; """"""; if isinstance(data, Expression):; if data._indices is None:; raise ValueError('Invalid input'); agg_f = data._aggregation_method(); data = agg_f(aggregators.approx_cdf(data, k)). if legend is None:; legend = """". if normalize:; y_axis_label = 'Quantile'; else:; y_axis_label = 'Rank'; if log:; y_axis_type = 'log'; else:; y_axis_type = 'linear'; p = figure(; title=title,; x_axis_label=legend,; y_axis_label=y_axis_label,; y_axis_type=y_axis_type,; width=600,; height=400,; background_fill_color='#EEEEEE',; tools='xpan,xwheel_zoom,reset,save',; active_scroll='xwheel_zoom',; ); p.add_tools(HoverTool(tooltips=[(""value"", ""$x""), (""rank"", ""@top"")], mode='vline')). ranks = np.array(data.ranks); values = np.array(data['values']); if normalize:; ranks = ranks / ranks[-1]. # invisible, there to support tooltips; p.quad(top=ranks[1:-1], bottom=ranks[1:-1], left=values[:-1], right=values[1:], fill_alpha=0, line_alpha=0); p.step(x=[*values, values[-1]], y=ranks, line_width=2, line_color='black', legend_label=legend); return p. [docs]def pdf(; data, k=1000, confidence=5, legend=None, title=None, log=False, interactive=False; ) -> Union[figure, Tuple[figure, Callable]]:; if isinstance(data, Expression):; if data._indices is None:; raise ValueError('Invalid input'); agg_f = data._aggregation_method(); data = agg_f(aggregators.approx_cdf(data, k)). if legend is None:; legend = """". y_axis_label =",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:3388,log,log,3388,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,4,['log'],['log']
Testability,"ollowing commands are relative to the hail directory.; The single command. $ ./gradlew -Dspark.version=2.0.2 shadowJar. creates a Hail JAR file at build/libs/hail-all-spark.jar. The initial build takes time as Gradle installs all Hail dependencies.; Add the following environmental variables by filling in the paths to SPARK_HOME and HAIL_HOME below and exporting all four of them (consider adding them to your .bashrc):; $ export SPARK_HOME=/path/to/spark; $ export HAIL_HOME=/path/to/hail; $ export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; $ export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar. Running on a Spark cluster¶; Hail can run on any cluster that has Spark 2 installed. For instructions; specific to Google Cloud Dataproc clusters and Cloudera clusters, see below.; For all other Spark clusters, you will need to build Hail from the source code.; To build Hail, log onto the master node of the Spark cluster, and build a Hail JAR; and a zipfile of the Python code by running:. $ ./gradlew -Dspark.version=2.0.2 shadowJar archiveZip. You can then open an IPython shell which can run Hail backed by the cluster; with the ipython command. $ SPARK_HOME=/path/to/spark/ \; HAIL_HOME=/path/to/hail/ \; PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/build/distributions/hail-python.zip:$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-*-src.zip"" \; ipython. Within the interactive shell, check that you can create a; HailContext by running the following commands. Note that you have to pass in; the existing SparkContext instance sc to the HailContext; constructor. >>> from hail import *; >>> hc = HailContext(). Files can be accessed from both Hadoop and Google Storage. If you’re running on Google’s Dataproc, you’ll want to store your files in Google Storage. In most on premises clusters, you’ll want to store your files in Hadoop.; To convert sample.vcf stored in Google Storage into Hail’s .vds format, run:. >>> hc.import_vc",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/getting_started.html:3569,log,log,3569,docs/0.1/getting_started.html,https://hail.is,https://hail.is/docs/0.1/getting_started.html,1,['log'],['log']
Testability,"om Forest Function; The inputs to the random forest function are two data frame files. df_x; is the path to a file containing a Pandas data frame where the variables; in the data frame represent the number of genomic features measured on each; corresponding window. df_y is the path to a file containing a Pandas data; frame where the variables in the data frame are the observed and expected variant; count ratio.; We write a function that runs the random forest model and leaves the window; of interest out of the model window_name.; An important thing to note in the code below is the number of cores is a parameter; to the function and matches the number of cores we give the job in the Batch control; code below.; def random_forest(df_x_path: str, df_y_path: str, window_name: str, cores: int = 1) -> Tuple[str, float, float]:; # read in data; df_x = pd.read_table(df_x_path, header=0, index_col=0); df_y = pd.read_table(df_y_path, header=0, index_col=0). # split training and testing data for the current window; x_train = df_x[df_x.index != window_name]; x_test = df_x[df_x.index == window_name]. y_train = df_y[df_y.index != window_name]; y_test = df_y[df_y.index == window_name]. # run random forest; rf = RandomForestRegressor(n_estimators=100,; n_jobs=cores,; max_features=3/4,; oob_score=True,; verbose=False). rf.fit(x_train, y_train). # apply the trained random forest on testing data; y_pred = rf.predict(x_test). # store obs and pred values for this window; obs = y_test[""oe""].to_list()[0]; pred = y_pred[0]. return (window_name, obs, pred). Format Result Function; The function below takes the expected output of the function random_forest; and returns a tab-delimited string that will be used later on when concatenating results.; def as_tsv(input: Tuple[str, float, float]) -> str:; return '\t'.join(str(i) for i in input). Build Python Image; In order to run a PythonJob, Batch needs an image that has the; same version of Python as the version of Python running on your compute",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/cookbook/random_forest.html:2984,test,testing,2984,docs/batch/cookbook/random_forest.html,https://hail.is,https://hail.is/docs/batch/cookbook/random_forest.html,2,['test'],['testing']
Testability,"om R are then 0.0373, 0.0111, and 0.0116, respectively, as expected for a less significant association.; The Firth test reduces bias from small counts and resolves the issue of separation by penalizing maximum likelihood estimation by the Jeffrey’s invariant prior. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton method is linear rather than quadratic. For Firth, 100 iterations are attempted for the null model and, if that is successful, for the full model as well. In testing we find 20 iterations nearly always suffices. If the null model fails to converge, then the sa.lmmreg.fit annotations reflect the null model; otherwise, they reflect the full model.; See Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants for an empirical comparison of the logistic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert’s notes Statistical Theory. Firth introduced his approach in Bias reduction of maximum likelihood estimates, 1993. Heinze and Schemper further analyze Firth’s approach in A solution to the problem of separation in logistic regression, 2002.; Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; Phenotype and covariate sample annotations may also be specified using programmatic expressions without identifiers, such as:; if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation sa.fam.isCase added by importing a FAM file with case-control phenotype, case is 1 and control is 0.; Hail’s logistic regression tests correspond to the b.wald, b.lrt, and b.score tests in EPACTS. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subse",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:115517,test,tests,115517,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['tests']
Testability,"om pyspark.sql import SQLContext. from hail.dataset import VariantDataset; from hail.expr import Type; from hail.java import *; from hail.keytable import KeyTable; from hail.stats import UniformDist, TruncatedBetaDist, BetaDist; from hail.utils import wrap_to_list. [docs]class HailContext(object):; """"""The main entry point for Hail functionality. .. warning::; Only one Hail context may be running in a Python session at any time. If you; need to reconfigure settings, restart the Python session or use the :py:meth:`.HailContext.stop` method.; ; If passing in a Spark context, ensure that the configuration parameters ``spark.sql.files.openCostInBytes``; and ``spark.sql.files.maxPartitionBytes`` are set to as least 50GB. :param sc: Spark context, one will be created if None.; :type sc: :class:`.pyspark.SparkContext`. :param appName: Spark application identifier. :param master: Spark cluster master. :param local: Local resources to use. :param log: Log path. :param bool quiet: Don't write logging information to standard error. :param append: Write to end of log file instead of overwriting. :param parquet_compression: Level of on-disk annotation compression. :param min_block_size: Minimum file split size in MB. :param branching_factor: Branching factor for tree aggregation. :param tmp_dir: Temporary directory for file merging. :ivar sc: Spark context; :vartype sc: :class:`.pyspark.SparkContext`; """""". @typecheck_method(sc=nullable(SparkContext),; app_name=strlike,; master=nullable(strlike),; local=strlike,; log=strlike,; quiet=bool,; append=bool,; parquet_compression=strlike,; min_block_size=integral,; branching_factor=integral,; tmp_dir=strlike); def __init__(self, sc=None, app_name=""Hail"", master=None, local='local[*]',; log='hail.log', quiet=False, append=False, parquet_compression='snappy',; min_block_size=1, branching_factor=50, tmp_dir='/tmp'):. if Env._hc:; raise FatalError('Hail Context has already been created, restart session '; 'or stop Hail context to change conf",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/context.html:1454,log,logging,1454,docs/0.1/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/context.html,1,['log'],['logging']
Testability,"omad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; Schema (0.2, GRCh37). panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_scores_AFR. View page source. panukb_ld_scores_AFR. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'varid': str; 'AF': float64; 'ld_score': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AFR.html:8787,Log,Log,8787,docs/0.2/datasets/schemas/panukb_ld_scores_AFR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AFR.html,1,['Log'],['Log']
Testability,"omad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; Schema (0.2, GRCh37). panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_scores_AMR. View page source. panukb_ld_scores_AMR. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'varid': str; 'AF': float64; 'ld_score': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AMR.html:8787,Log,Log,8787,docs/0.2/datasets/schemas/panukb_ld_scores_AMR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AMR.html,1,['Log'],['Log']
Testability,"omad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; Schema (0.2, GRCh37). panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_scores_CSA. View page source. panukb_ld_scores_CSA. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'varid': str; 'AF': float64; 'ld_score': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_CSA.html:8787,Log,Log,8787,docs/0.2/datasets/schemas/panukb_ld_scores_CSA.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_CSA.html,1,['Log'],['Log']
Testability,"omad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; Schema (0.2, GRCh37). panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_scores_EAS. View page source. panukb_ld_scores_EAS. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'varid': str; 'AF': float64; 'ld_score': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_EAS.html:8787,Log,Log,8787,docs/0.2/datasets/schemas/panukb_ld_scores_EAS.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_EAS.html,1,['Log'],['Log']
Testability,"omad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; Schema (0.2, GRCh37). panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_scores_EUR. View page source. panukb_ld_scores_EUR. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'varid': str; 'AF': float64; 'ld_score': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_EUR.html:8787,Log,Log,8787,docs/0.2/datasets/schemas/panukb_ld_scores_EUR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_EUR.html,1,['Log'],['Log']
Testability,"omad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; Schema (0.2, GRCh37). panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_scores_MID. View page source. panukb_ld_scores_MID. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'varid': str; 'AF': float64; 'ld_score': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_MID.html:8787,Log,Log,8787,docs/0.2/datasets/schemas/panukb_ld_scores_MID.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_MID.html,1,['Log'],['Log']
Testability,"omad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; GTEx_sQTL_Whole_Blood_all_snp_gene_associations. View page source. GTEx_sQTL_Whole_Blood_all_snp_gene_associations. Versions: v8; Reference genome builds: GRCh38; Type: hail.Table. Schema (v8, GRCh38); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; version: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'phenotype_id': struct {; intron: interval<locus<GRCh38>>,; cluster: str,; gene_id: str; }; 'tss_distance': int32; 'ma_samples': int32; 'ma_count': int32; 'maf': float64; 'pval_nominal': float64; 'slope': float64; 'slope_se': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Whole_Blood_all_snp_gene_associations.html:8813,Log,Log,8813,docs/0.2/datasets/schemas/GTEx_sQTL_Whole_Blood_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Whole_Blood_all_snp_gene_associations.html,1,['Log'],['Log']
Testability,"omplete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. Status; HomRef; Het; HomVar. Case; 1000; 10; 0. Control; 1000; 0; 0. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where x is genotype,; y is phenotype, and logistf is from the logistf package:; x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association.; The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the Jeffrey’s; invariant prior. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the logreg.fit fields reflect the null model; otherwise,; they reflect the full model.; See; Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert’s notes; Statistical Theory.; Firth introduced his approach in; Bias reduction of maximum likelihood estimates, 1993.; Hei",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:12802,test,test,12802,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['test']
Testability,"on 0.2.20; Released 2019-08-19. Critical memory management fix. (#6824) Fixed memory; management inside annotate_cols with aggregations. This was; causing memory leaks and segfaults. Bug fixes. (#6769) Fixed; non-functional hl.lambda_gc method.; (#6847) Fixed bug in; handling of NaN in hl.agg.min and hl.agg.max. These will now; properly ignore NaN (the intended semantics). Note that hl.min; and hl.max propagate NaN; use hl.nanmin and hl.nanmax to; ignore NaN. New features. (#6847) Added; hl.nanmin and hl.nanmax functions. Version 0.2.19; Released 2019-08-01. Critical performance bug fix. (#6629) Fixed a; critical performance bug introduced in; (#6266). This bug led; to long hang times when reading in Hail tables and matrix tables; written in version 0.2.18. Bug fixes. (#6757) Fixed; correctness bug in optimizations applied to the combination of; Table.order_by with hl.desc arguments and show(), leading; to tables sorted in ascending, not descending order.; (#6770) Fixed; assertion error caused by Table.expand_types(), which was used by; Table.to_spark and Table.to_pandas. Performance Improvements. (#6666) Slightly; improve performance of hl.pca and hl.hwe_normalized_pca.; (#6669) Improve; performance of hl.split_multi and hl.split_multi_hts.; (#6644) Optimize core; code generation primitives, leading to across-the-board performance; improvements.; (#6775) Fixed a major; performance problem related to reading block matrices. hailctl dataproc. (#6760) Fixed the; address pointed at by ui in connect, after Google changed; proxy settings that rendered the UI URL incorrect. Also added new; address hist/spark-history. Version 0.2.18; Released 2019-07-12. Critical performance bug fix. (#6605) Resolved code; generation issue leading a performance regression of 1-3 orders of; magnitude in Hail pipelines using constant strings or literals. This; includes almost every pipeline! This issue has exists in versions; 0.2.15, 0.2.16, and 0.2.17, and any users on those versi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:88512,assert,assertion,88512,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['assert'],['assertion']
Testability,"on and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. ================ =================== ======= ===============================; Test Field Type Value; ================ =================== ======= ===============================; Wald, LRT, Firth `fit.n_iterations` int32 number of iterations until; convergence, explosion, or; reaching the max (25 for; Wald, LRT; 100 for Firth); Wald, LRT, Firth `fit.converged` bool ``True`` if iteration converged; Wald, LRT, Firth `fit.exploded` bool ``True`` if iteration exploded; ================ =================== ======= ===============================. We consider iteration to have converged when every coordinate of; :math:`\beta` changes by less than :math:`10^{-6}`. For Wald and LRT,; up to 25 iterations are attempted; in testing we find 4 or 5 iterations; nearly always suffice. Convergence may also fail due to explosion,; which refers to low-level numerical linear algebra exceptions caused by; manipulating ill-conditioned matrices. Explosion may result from (nearly); linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produce",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:51873,test,testing,51873,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['testing']
Testability,"on to fitting the global model.; use_ml (bool) – Use ML instead of REML throughout.; delta (float or None) – Fixed delta value to use in the global model, overrides fitting delta.; sparsity_threshold (float) – Genotype vector sparsity at or below which to use sparse genotype vector in rotation (advanced).; use_dosages (bool) – If true, use dosages rather than hard call genotypes.; n_eigs (int) – Number of eigenvectors of the kinship matrix used to fit the model.; dropped_variance_fraction (float) – Upper bound on fraction of sample variance lost by dropping eigenvectors with small eigenvalues. Returns:Variant dataset with linear mixed regression annotations. Return type:VariantDataset. logreg(test, y, covariates=[], root='va.logreg', use_dosages=False)[source]¶; Test each variant for association using logistic regression. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Run the logistic regression Wald test per variant using a Boolean phenotype and two covariates stored; in sample annotations:; >>> vds_result = vds.logreg('wald', 'sa.pheno.isCase', covariates=['sa.pheno.age', 'sa.pheno.isFemale']). Notes; The logreg() method performs,; for each variant, a significance test of the genotype in; predicting a binary (case-control) phenotype based on the; logistic regression model. The phenotype type must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded as 1 and 0, respectively.; Hail supports the Wald test (‘wald’), likelihood ratio test (‘lrt’), Rao score test (‘score’),; and Firth test (‘firth’). Hail only includes samples for which the phenotype and all covariates are; defined. For each variant, Hail imputes missing genotypes as the mean of called genotypes.; By default, genotypes values are given by hard call genotypes (g.gt).; If use_dosages=True, then genotype values are defined by the dosage; \(\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})\). For",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:109113,log,logistic,109113,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"on. hail.expr.functions.bit_lshift(x, y)[source]; Bitwise left-shift x by y.; Examples; >>> hl.eval(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:; >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_rshift(x, y, logical=False)[source]; Bitwise right-shift x by y.; Examples; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With logical=False (default), the sign is preserved:; >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With logical=True, the sign bit is treated as any other:; >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; If logical is False, then the shift is a sign-preserving right shift.; If logical is True, then the shift is logical, with the sign bit; treated as any other bit.; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression); logical (bool). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representation of 7 is 111, so:; >>> hl.eval(hl.bit_count(7)); 3. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression. hail.expr.functions.exp(",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:6119,log,logical,6119,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['logical']
Testability,"on_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**y_dict, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'LogisticRegression',; 'test': test,; 'yFields': y_field,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. result = Table(ir.MatrixToTableApply(mt._mir, config)). if not y_is_list:; result = result.transmute(**result.logistic_regression[0]). return result.persist(). # Helpers for logreg:; def mean_impute(hl_array):; non_missing_mean = hl.mean(hl_array, filter_missing=True); return hl_array.map(lambda entry: hl.coalesce(entry, non_missing_mean)). sigmoid = expit. def nd_max(hl_nd):; return hl.max(hl.array(hl_nd.reshape(-1))). def logreg_fit(; X: NDArrayNumericExpression, # (K,); y: NDArrayNumericExpression, # (N, K); null_fit: Optional[StructExpression],; max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Bernoulli(logit(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim =",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:38402,test,test,38402,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,5,"['Log', 'test']","['LogisticRegression', 'test']"
Testability,"one, lower_tail=False, log_p=False) -> Float64Expression:; """"""Returns the probability under the right-tail starting at x for a chi-squared; distribution with df degrees of freedom. Examples; --------. >>> hl.eval(hl.pchisqtail(5, 1)); 0.025347318677468304. >>> hl.eval(hl.pchisqtail(5, 1, ncp=2)); 0.20571085634347097. >>> hl.eval(hl.pchisqtail(5, 1, lower_tail=True)); 0.9746526813225317. >>> hl.eval(hl.pchisqtail(5, 1, log_p=True)); -3.6750823266311876. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the CDF.; df : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom.; ncp: float or :class:`.Expression` of type :py:data:`.tfloat64`; Noncentrality parameter, defaults to 0 if unspecified.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; if ncp is None:; return _func(""pchisqtail"", tfloat64, x, df, lower_tail, log_p); else:; return _func(""pnchisqtail"", tfloat64, x, df, ncp, lower_tail, log_p). PGENCHISQ_RETURN_TYPE = tstruct(value=tfloat64, n_iterations=tint32, converged=tbool, fault=tint32). [docs]@typecheck(; x=expr_float64,; w=expr_array(expr_float64),; k=expr_array(expr_int32),; lam=expr_array(expr_float64),; mu=expr_float64,; sigma=expr_float64,; max_iterations=nullable(expr_int32),; min_accuracy=nullable(expr_float64),; ); def pgenchisq(x, w, k, lam, mu, sigma, *, max_iterations=None, min_accuracy=None) -> Float64Expression:; r""""""The cumulative probability function of a `generalized chi-squared distribution; <https://en.wikipedia.org/wiki/Generalized_chi-squared_distribution>`__. The generalized chi-squared distribution has many interpretations. We share here four; interpretations of the values of this dist",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:63889,log,logarithm,63889,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['logarithm']
Testability,"oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return construct_expr(ir.ApplyUnaryPrimOp('~', x._ir), x.dtype, x._indices, x._aggregations). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_count(x):; """"""Count the number of 1s in the in the `two's complement <https://en.wikipedia.org/wiki/Two%27s_complement>`__ binary representation of `x`. Examples; --------; The binary representation of `7` is `111`, so:. >>> hl.eval(hl.bit_count(7)); 3. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; ---",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:182111,log,logical,182111,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['logical']
Testability,"onfidence=5, legend=None, title=None, log=False, interactive=False; ) -> Union[figure, Tuple[figure, Callable]]:; if isinstance(data, Expression):; if data._indices is None:; raise ValueError('Invalid input'); agg_f = data._aggregation_method(); data = agg_f(aggregators.approx_cdf(data, k)). if legend is None:; legend = """". y_axis_label = 'Frequency'; if log:; y_axis_type = 'log'; else:; y_axis_type = 'linear'; fig = figure(; title=title,; x_axis_label=legend,; y_axis_label=y_axis_label,; y_axis_type=y_axis_type,; width=600,; height=400,; tools='xpan,xwheel_zoom,reset,save',; active_scroll='xwheel_zoom',; background_fill_color='#EEEEEE',; ). y = np.array(data['ranks'][1:-1]) / data['ranks'][-1]; x = np.array(data['values'][1:-1]); min_x = data['values'][0]; max_x = data['values'][-1]; err = _error_from_cdf_python(data, 10 ** (-confidence), all_quantiles=True). new_y, keep = _max_entropy_cdf(min_x, max_x, x, y, err); slopes = np.diff([0, *new_y[keep], 1]) / np.diff([min_x, *x[keep], max_x]); if log:; plot = fig.step(x=[min_x, *x[keep], max_x], y=[*slopes, slopes[-1]], mode='after'); else:; plot = fig.quad(left=[min_x, *x[keep]], right=[*x[keep], max_x], bottom=0, top=slopes, legend_label=legend). if interactive:. def mk_interact(handle):; def update(confidence=confidence):; err = _error_from_cdf_python(data, 10 ** (-confidence), all_quantiles=True) / 1.8; new_y, keep = _max_entropy_cdf(min_x, max_x, x, y, err); slopes = np.diff([0, *new_y[keep], 1]) / np.diff([min_x, *x[keep], max_x]); if log:; new_data = {'x': [min_x, *x[keep], max_x], 'y': [*slopes, slopes[-1]]}; else:; new_data = {; 'left': [min_x, *x[keep]],; 'right': [*x[keep], max_x],; 'bottom': np.full(len(slopes), 0),; 'top': slopes,; }; plot.data_source.data = new_data; bokeh.io.push_notebook(handle=handle). from ipywidgets import interact. interact(update, confidence=(1, 10, 0.01)). return fig, mk_interact; else:; return fig. def _max_entropy_cdf(min_x, max_x, x, y, e):; def compare(x1, y1, x2, y2):; return",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:5166,log,log,5166,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['log'],['log']
Testability,"only. Spark context. If not specified, the Spark backend will create a new; Spark context.; app_name : :class:`str`; A name for this pipeline. In the Spark backend, this becomes the Spark application name. In; the Batch backend, this is a prefix for the name of every Batch.; master : :class:`str`, optional; Spark Backend only. URL identifying the Spark leader (master) node or `local[N]` for local; clusters.; local : :class:`str`; Spark Backend only. Local-mode core limit indicator. Must either be `local[N]` where N is a; positive integer or `local[*]`. The latter indicates Spark should use all cores; available. `local[*]` does not respect most containerization CPU limits. This option is only; used if `master` is unset and `spark.master` is not set in the Spark configuration.; log : :class:`str`; Local path for Hail log file. Does not currently support distributed file systems like; Google Storage, S3, or HDFS.; quiet : :obj:`bool`; Print fewer log messages.; append : :obj:`bool`; Append to the end of the log file.; min_block_size : :obj:`int`; Minimum file block size in MB.; branching_factor : :obj:`int`; Branching factor for tree aggregation.; tmp_dir : :class:`str`, optional; Networked temporary directory. Must be a network-visible file; path. Defaults to /tmp in the default scheme.; default_reference : :class:`str`; *Deprecated*. Please use :func:`.default_reference` to set the default reference genome. Default reference genome. Either ``'GRCh37'``, ``'GRCh38'``,; ``'GRCm38'``, or ``'CanFam3'``.; idempotent : :obj:`bool`; If ``True``, calling this function is a no-op if Hail has already been initialized.; global_seed : :obj:`int`, optional; Global random seed.; spark_conf : :obj:`dict` of :class:`str` to :class`str`, optional; Spark backend only. Spark configuration parameters.; skip_logging_configuration : :obj:`bool`; Spark Backend only. Skip logging configuration in java and python.; local_tmpdir : :class:`str`, optional; Local temporary directory. Used on dri",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:9237,log,log,9237,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['log'],['log']
Testability,"ons. Source code for hail.representation.annotations; from hail.typecheck import *. [docs]class Struct(object):; """"""; Nested annotation structure. >>> bar = Struct({'foo': 5, '1kg': 10}). Struct elements are treated as both 'items' and 'attributes', which; allows either syntax for accessing the element ""foo"" of struct ""bar"":. >>> bar.foo; >>> bar['foo']. Note that it is possible to use Hail to define struct fields inside; of a key table or variant dataset that do not match python syntax.; The name ""1kg"", for example, will not parse to python because it; begins with an integer, which is not an acceptable leading character; for an identifier. There are two ways to access this field:. >>> getattr(bar, '1kg'); >>> bar['1kg']. The ``pprint`` module can be used to print nested Structs in a more; human-readable fashion:. >>> from pprint import pprint; >>> pprint(bar). :param dict attributes: struct members.; """""". def __init__(self, attributes):. self._attrs = attributes. def __getattr__(self, item):; assert (self._attrs); if item not in self._attrs:; raise AttributeError(""Struct instance has no attribute '%s'"" % item); return self._attrs[item]. def __contains__(self, item):; return item in self._attrs. def __getitem__(self, item):; return self.__getattr__(item). def __len__(self):; return len(self._attrs). def __repr__(self):; return str(self). def __str__(self):; return 'Struct' + str(self._attrs). def __eq__(self, other):; if isinstance(other, Struct):; return self._attrs == other._attrs; else:; return False. def __hash__(self):; return 37 + hash(tuple(sorted(self._attrs.items()))). [docs] @typecheck_method(item=strlike,; default=anytype); def get(self, item, default=None):; """"""Get an item, or return a default value if the item is not found.; ; :param str item: Name of attribute.; ; :param default: Default value.; ; :returns: Value of item if found, or default value if not.; """"""; return self._attrs.get(item, default). @typecheck(struct=Struct); def to_dict(struct):; d = ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/representation/annotations.html:1327,assert,assert,1327,docs/0.1/_modules/hail/representation/annotations.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/representation/annotations.html,1,['assert'],['assert']
Testability,"ons.pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False)[source]; The cumulative probability function of a normal distribution with mean; mu and standard deviation sigma. Returns cumulative probability of; standard normal distribution by default.; Examples; >>> hl.eval(hl.pnorm(0)); 0.5. >>> hl.eval(hl.pnorm(1, mu=2, sigma=2)); 0.30853753872598694. >>> hl.eval(hl.pnorm(2, lower_tail=False)); 0.022750131948179212. >>> hl.eval(hl.pnorm(2, log_p=True)); -0.023012909328963493. Notes; Returns the left-tail probability p = Prob(\(Z < x\)) with \(Z\); a normal random variable. Defaults to a standard normal random variable. Parameters:. x (float or Expression of type tfloat64); mu (float or Expression of type tfloat64) – Mean (default = 0).; sigma (float or Expression of type tfloat64) – Standard deviation (default = 1).; lower_tail (bool or BooleanExpression) – If True, compute the probability of an outcome at or below x,; otherwise greater than x.; log_p (bool or BooleanExpression) – Return the natural logarithm of the probability. Returns:; Expression of type tfloat64. hail.expr.functions.pT(x, n, lower_tail=True, log_p=False)[source]; The cumulative probability function of a t-distribution with; n degrees of freedom.; Examples; >>> hl.eval(hl.pT(0, 10)); 0.5. >>> hl.eval(hl.pT(1, 10)); 0.82955343384897. >>> hl.eval(hl.pT(1, 10, lower_tail=False)); 0.17044656615103004. >>> hl.eval(hl.pT(1, 10, log_p=True)); -0.186867754489647. Notes; If lower_tail is true, returns Prob(\(X \leq\) x) where \(X\) is; a t-distributed random variable with n degrees of freedom. If lower_tail; is false, returns Prob(\(X\) > x). Parameters:. x (float or Expression of type tfloat64); n (float or Expression of type tfloat64) – Degrees of freedom of the t-distribution.; lower_tail (bool or BooleanExpression) – If True, compute the probability of an outcome at or below x,; otherwise greater than x.; log_p (bool or BooleanExpression) – Return the natural logarithm of the probability. Returns:; Ex",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:22129,log,logarithm,22129,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['log'],['logarithm']
Testability,"ontext`. :param appName: Spark application identifier. :param master: Spark cluster master. :param local: Local resources to use. :param log: Log path. :param bool quiet: Don't write logging information to standard error. :param append: Write to end of log file instead of overwriting. :param parquet_compression: Level of on-disk annotation compression. :param min_block_size: Minimum file split size in MB. :param branching_factor: Branching factor for tree aggregation. :param tmp_dir: Temporary directory for file merging. :ivar sc: Spark context; :vartype sc: :class:`.pyspark.SparkContext`; """""". @typecheck_method(sc=nullable(SparkContext),; app_name=strlike,; master=nullable(strlike),; local=strlike,; log=strlike,; quiet=bool,; append=bool,; parquet_compression=strlike,; min_block_size=integral,; branching_factor=integral,; tmp_dir=strlike); def __init__(self, sc=None, app_name=""Hail"", master=None, local='local[*]',; log='hail.log', quiet=False, append=False, parquet_compression='snappy',; min_block_size=1, branching_factor=50, tmp_dir='/tmp'):. if Env._hc:; raise FatalError('Hail Context has already been created, restart session '; 'or stop Hail context to change configuration.'). SparkContext._ensure_initialized(). self._gateway = SparkContext._gateway; self._jvm = SparkContext._jvm. # hail package; self._hail = getattr(self._jvm, 'is').hail. Env._jvm = self._jvm; Env._gateway = self._gateway. jsc = sc._jsc.sc() if sc else None. # we always pass 'quiet' to the JVM because stderr output needs; # to be routed through Python separately.; self._jhc = self._hail.HailContext.apply(; jsc, app_name, joption(master), local, log, True, append,; parquet_compression, min_block_size, branching_factor, tmp_dir). self._jsc = self._jhc.sc(); self.sc = sc if sc else SparkContext(gateway=self._gateway, jsc=self._jvm.JavaSparkContext(self._jsc)); self._jsql_context = self._jhc.sqlContext(); self._sql_context = SQLContext(self.sc, self._jsql_context). # do this at the end in case some",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/context.html:2211,log,log,2211,docs/0.1/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/context.html,1,['log'],['log']
Testability,"onverged when every coordinate of :math:`\\beta` changes by less than :math:`10^{-6}`. For Wald and LRT, up to 25 iterations are attempted; in testing we find 4 or 5 iterations nearly always suffice. Convergence may also fail due to explosion, which refers to low-level numerical linear algebra exceptions caused by manipulating ill-conditioned matrices. Explosion may result from (nearly) linearly dependent covariates or complete `separation <https://en.wikipedia.org/wiki/Separation_(statistics)>`__. A more common situation in genetics is quasi-complete seperation, e.g. variants that are observed only in cases (or controls). Such variants inevitably arise when testing millions of variants with very low minor allele count. The maximum likelihood estimate of :math:`\\beta` under logistic regression is then undefined but convergence may still occur after a large number of iterations due to a very flat likelihood surface. In testing, we find that such variants produce a secondary bump from 10 to 15 iterations in the histogram of number of iterations per variant. We also find that this faux convergence produces large standard errors and large (insignificant) p-values. To not miss such variants, consider using Firth logistic regression, linear regression, or group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic, and linear regression models to this data, where ``x`` is genotype, ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:144245,test,testing,144245,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['testing']
Testability,"oogle Container Repository (GCR).; It is not advisable to put credentials inside any Docker image, even if it is only pushed to a; private repository.; The following Docker command pushes the image to GCR:; docker tag 1kg-gwas us-docker.pkg.dev/<MY_PROJECT>/1kg-gwas; docker push us-docker.pkg.dev/<MY_PROJECT>/1kg-gwas. Replace <MY_PROJECT> with the name of your Google project. Ensure your Batch service account; can access images in GCR. Batch Script; The next thing we want to do is write a Hail Batch script to execute LD-based clumping of; association results for the 1000 genomes dataset. Functions. GWAS; To start, we will write a function that creates a new Job on an existing Batch that; takes as arguments the VCF file and the phenotypes file. The return value of this; function is the Job that is created in the function, which can be used later to; access the binary PLINK file output and association results in downstream jobs.; def gwas(batch, vcf, phenotypes):; """"""; QC data and get association test statistics; """"""; cores = 2; g = batch.new_job(name='run-gwas'); g.image('us-docker.pkg.dev/<MY_PROJECT>/1kg-gwas:latest'); g.cpu(cores); g.declare_resource_group(ofile={; 'bed': '{root}.bed',; 'bim': '{root}.bim',; 'fam': '{root}.fam',; 'assoc': '{root}.assoc'; }); g.command(f'''; python3 /run_gwas.py \; --vcf {vcf} \; --phenotypes {phenotypes} \; --output-file {g.ofile} \; --cores {cores}; '''); return g. A couple of things to note about this function:. The image is the image created in the previous step. We copied the run_gwas.py; script into the root directory /. Therefore, to execute the run_gwas.py script, we; call /run_gwas.py.; The run_gwas.py script takes an output-file parameter and then creates files ending with; the extensions .bed, .bim, .fam, and .assoc. In order for Batch to know the script is; creating files as a group with a common file root, we need to use the BashJob.declare_resource_group(); method. We then pass g.ofile as the output file root to ru",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/cookbook/clumping.html:6676,test,test,6676,docs/batch/cookbook/clumping.html,https://hail.is,https://hail.is/docs/batch/cookbook/clumping.html,2,['test'],['test']
Testability,"oolean – Returns true if the argument is NaN (not a number), false if the argument is defined but not NaN. Returns missing if the argument is missing. json(x: T): String – Returns the JSON representation of a data type. Locus(contig: String, pos: Int): Locus. Construct a Locus object.; let l = Locus(""1"", 10040532) in l.position; result: 10040532. Arguments. contig (String) – String representation of contig.; pos (Int) – SNP position or start of an indel. Locus(s: String): Locus. Construct a Locus object.; let l = Locus(""1:10040532"") in l.position; result: 10040532. Arguments. s (String) – String of the form CHR:POS. log(x: Double, b: Double): Double. Returns the base b logarithm of the given value x.; Arguments. x (Double) – the number to take the base b logarithm of.; b (Double) – the base. log(x: Double): Double. Returns the natural logarithm of the given value x.; Arguments. x (Double) – the number to take the natural logarithm of. log10(x: Double): Double. Returns the base 10 logarithm of the given value x.; Arguments. x (Double) – the number to take the base 10 logarithm of. merge(s1: Struct, s2: Struct): Struct. Create a new Struct with all fields in s1 and s2.; let s1 = {gene: ""ACBD"", function: ""LOF""} and s2 = {a: 20, b: ""hello""} in merge(s1, s2); result: {gene: ""ACBD"", function: ""LOF"", a: 20, b: ""hello""}. orElse(a: T, b: T): T. If a is not missing, returns a. Otherwise, returns b.; Examples; Replace missing phenotype values with the mean value:; >>> [mean_height] = vds.query_samples(['samples.map(s => sa.pheno.height).stats()'])['mean']; >>> vds.annotate_samples_expr('sa.pheno.heightImputed = orElse(sa.pheno.height, %d)' % mean_height). orMissing(a: Boolean, b: T): T – If predicate evaluates to true, returns value. Otherwise, returns NA. pchisqtail(x: Double, df: Double): Double. Returns right-tail probability p for which p = Prob(\(Z^2\) > x) with \(Z^2\) a chi-squared random variable with degrees of freedom specified by df. x must be positive.; Arguments. ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:12272,log,logarithm,12272,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,1,['log'],['logarithm']
Testability,"op_scheme_supported(scheme)[source]; Returns True if the Hadoop filesystem supports URLs with the given; scheme.; Examples; >>> hadoop_scheme_supported('gs') . Notes; URLs with the https scheme are only supported if they are specifically; Azure Blob Storage URLs of the form https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>. Parameters:; scheme (str). Returns:; bool. hail.utils.copy_log(path)[source]; Attempt to copy the session log to a hadoop-API-compatible location.; Examples; Specify a manual path:; >>> hl.copy_log('gs://my-bucket/analysis-10-jan19.log') ; INFO: copying log to 'gs://my-bucket/analysis-10-jan19.log'... Copy to a directory:; >>> hl.copy_log('gs://my-bucket/') ; INFO: copying log to 'gs://my-bucket/hail-20180924-2018-devel-46e5fad57524.log'... Notes; Since Hail cannot currently log directly to distributed file systems, this; function is provided as a utility for offloading logs from ephemeral nodes.; If path is a directory, then the log file will be copied using its; base name to the directory (e.g. /home/hail.log would be copied as; gs://my-bucket/hail.log if path is gs://my-bucket. Parameters:; path (str). hail.utils.range_table(n, n_partitions=None)[source]; Construct a table with the row index and no other fields.; Examples; >>> df = hl.utils.range_table(100). >>> df.count(); 100. Notes; The resulting table contains one field:. idx (tint32) - Row index (key). This method is meant for testing and learning, and is not optimized for; production performance. Parameters:. n (int) – Number of rows.; n_partitions (int, optional) – Number of partitions (uses Spark default parallelism if None). Returns:; Table. hail.utils.range_matrix_table(n_rows, n_cols, n_partitions=None)[source]; Construct a matrix table with row and column indices and no entry fields.; Examples; >>> range_ds = hl.utils.range_matrix_table(n_rows=100, n_cols=10). >>> range_ds.count_rows(); 100. >>> range_ds.count_cols(); 10. Notes; The resulting matrix table con",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/utils/index.html:9535,log,log,9535,docs/0.2/utils/index.html,https://hail.is,https://hail.is/docs/0.2/utils/index.html,1,['log'],['log']
Testability,"or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""exp"", tfloat64, x). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def fisher_exact_test(c1, c2, c3, c4) -> StructExpression:; """"""Calculates the p-value, odds ratio, and 95% confidence interval using; Fisher's exact test for a 2x2 table. Examples; --------. >>> hl.eval(hl.fisher_exact_test(10, 10, 10, 10)); Struct(p_value=1.0000000000000002, odds_ratio=1.0,; ci_95_lower=0.24385796914260355, ci_95_upper=4.100747675033819). >>> hl.eval(hl.fisher_exact_test(51, 43, 22, 92)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967,; ci_95_lower=2.5659373368248444, ci_95_upper=9.677929632035475). Notes; -----; This method is identical to the version implemented in; `R <https://stat.ethz.ch/R-manual/R-devel/library/stats/html/fisher.test.html>`_ with default; parameters (two-sided, alpha = 0.05, null hypothesis that the odds ratio equals 1). Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with four fields, `p_value`; (:py:data:`.tfloat64`), `odds_ratio` (:py:data:`.tfloat64`),; `ci_95_lower (:py:data:`.tfloat64`), and `ci_95_upper`; (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64, ci_95_lower=tfloat64, ci_95_upper=tfloat64); return _func(""fisher_exact_test"", ret_type, c1, c2, c3, c4). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:31649,test,test,31649,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"or HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; :math:`\mathrm{isFemale}` is coded as 1 for true (female) and; 0 for false (male). The null model sets :math:`\\beta_1 = 0`. The resulting variant annotations depend on the test statistic; as shown in the tables below. ========== =================== ====== =====; Test Annotation Type Value; ========== =================== ====== =====; Wald ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; Wald ``va.logreg.se`` Double estimated standard error, :math:`\widehat{\mathrm{se}}`; Wald ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`; Wald ``va.logreg.pval`` Double Wald p-value testing :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. ================ =========================== ======= =====; Test Annotation Type Value; ================ =========================== ======= =====; Wald, LRT, Firth ``va.logreg.fit.nIter`` Int number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth); Wald, LRT, Firth ``va.logreg.fit.converged`` Boolean true if iteration converged; Wald, LRT, Firth ``va.logreg.fit.exploded`` Boolean true if itera",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:142202,log,logreg,142202,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_lshift(x, y)[source]; Bitwise left-shift x by y.; Examples; >>> hl.eval(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:; >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_rshift(x, y, logical=False)[source]; Bitwise right-shift x by y.; Examples; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With logical=False (default), the sign is preserved:; >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With logical=True, the sign bit is treated as any other:; >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; If logical is False, then the shift is a sign-preserving right shift.; If logical is True, then the shift is logical, with the sign bit; treated as any other bit.; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression); logical (bool). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source]; Count the number of 1s in the in the two’s complement binary representation of x.; Examples; The binary representation of 7 is 111, so:; >>> hl.eval(hl.bit_count(7)); 3. Parameters:; x (Int32Expression or Int64",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:6033,log,logical,6033,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['logical']
Testability,"or non-positive b. Returns; -------; :class:`.Float64Expression`; """"""; return _func(""dbeta"", tfloat64, x, a, b). [docs]@typecheck(x=expr_float64, df=expr_float64, ncp=nullable(expr_float64), log_p=expr_bool); def dchisq(x, df, ncp=None, log_p=False) -> Float64Expression:; """"""Compute the probability density at `x` of a chi-squared distribution with `df`; degrees of freedom. Examples; --------. >>> hl.eval(hl.dchisq(1, 2)); 0.3032653298563167. >>> hl.eval(hl.dchisq(1, 2, ncp=2)); 0.17472016746112667. >>> hl.eval(hl.dchisq(1, 2, log_p=True)); -1.1931471805599454. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; Non-negative number at which to compute the probability density.; df : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom.; ncp: float or :class:`.Expression` of type :py:data:`.tfloat64`; Noncentrality parameter, defaults to 0 if unspecified.; log_p : bool or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The probability density.; """"""; if ncp is None:; return _func(""dchisq"", tfloat64, x, df, log_p); else:; return _func(""dnchisq"", tfloat64, x, df, ncp, log_p). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, log_p=expr_bool); def dnorm(x, mu=0, sigma=1, log_p=False) -> Float64Expression:; """"""Compute the probability density at `x` of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns density of standard normal; distribution by default. Examples; --------. >>> hl.eval(hl.dnorm(1)); 0.24197072451914337. >>> hl.eval(hl.dnorm(1, mu=1, sigma=2)); 0.19947114020071635. >>> hl.eval(hl.dnorm(1, log_p=True)); -1.4189385332046727. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Real number at which to compute the probability density.; mu : float or :class:`.Expression` of type :py:data:`.tfl",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:28115,log,logarithm,28115,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['logarithm']
Testability,"or; HomVar, and the Boolean covariate \(\mathrm{is\_female}\) is coded as; for True (female) and 0 for False (male). The null model sets; \(\beta_1 = 0\).; The structure of the emitted row field depends on the test statistic as; shown in the tables below. Test; Field; Type; Value. Wald; beta; float64; fit effect coefficient,; \(\hat\beta_1\). Wald; standard_error; float64; estimated standard error,; \(\widehat{\mathrm{se}}\). Wald; z_stat; float64; Wald \(z\)-statistic, equal to; \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; p_value; float64; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; beta; float64; fit effect coefficient,; \(\hat\beta_1\). LRT, Firth; chi_sq_stat; float64; deviance statistic. LRT, Firth; p_value; float64; LRT / Firth p-value testing; \(\beta_1 = 0\). Score; chi_sq_stat; float64; score statistic. Score; p_value; float64; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for; each row using Newton iteration and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. Test; Field; Type; Value. Wald, LRT, Firth; fit.n_iterations; int32; number of iterations until; convergence, explosion, or; reaching the max (by default,; 25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; fit.converged; bool; True if iteration converged. Wald, LRT, Firth; fit.exploded; bool; True if iteration exploded. We consider iteration to have converged when every coordinate of; \(\beta\) changes by less than \(10^{-6}\) by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned mat",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:9871,test,tests,9871,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,2,"['log', 'test']","['logistic', 'tests']"
Testability,"or=copy_log_on_error,; ); if not backend.fs.exists(tmpdir):; backend.fs.mkdir(tmpdir). HailContext.create(log, quiet, append, tmpdir, local_tmpdir, default_reference, global_seed, backend); if not quiet:; connect_logger(backend._utils_package_object, 'localhost', 12888). @typecheck(; billing_project=nullable(str),; remote_tmpdir=nullable(str),; log=nullable(str),; quiet=bool,; append=bool,; tmpdir=nullable(str),; local_tmpdir=nullable(str),; default_reference=enumeration(*BUILTIN_REFERENCES),; global_seed=nullable(int),; disable_progress_bar=nullable(bool),; driver_cores=nullable(oneof(str, int)),; driver_memory=nullable(str),; worker_cores=nullable(oneof(str, int)),; worker_memory=nullable(str),; name_prefix=nullable(str),; token=nullable(str),; gcs_requester_pays_configuration=nullable(oneof(str, sized_tupleof(str, sequenceof(str)))),; regions=nullable(sequenceof(str)),; gcs_bucket_allow_list=nullable(sequenceof(str)),; ); async def init_batch(; *,; billing_project: Optional[str] = None,; remote_tmpdir: Optional[str] = None,; log: Optional[str] = None,; quiet: bool = False,; append: bool = False,; tmpdir: Optional[str] = None,; local_tmpdir: Optional[str] = None,; default_reference: str = 'GRCh37',; global_seed: Optional[int] = None,; disable_progress_bar: Optional[bool] = None,; driver_cores: Optional[Union[str, int]] = None,; driver_memory: Optional[str] = None,; worker_cores: Optional[Union[str, int]] = None,; worker_memory: Optional[str] = None,; name_prefix: Optional[str] = None,; token: Optional[str] = None,; gcs_requester_pays_configuration: Optional[GCSRequesterPaysConfiguration] = None,; regions: Optional[List[str]] = None,; gcs_bucket_allow_list: Optional[List[str]] = None,; ):; from hail.backend.service_backend import ServiceBackend. # FIXME: pass local_tmpdir and use on worker and driver; backend = await ServiceBackend.create(; billing_project=billing_project,; remote_tmpdir=remote_tmpdir,; disable_progress_bar=disable_progress_bar,; driver_cores=driver",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:16568,log,log,16568,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,4,['log'],['log']
Testability,"orm(); pT(); pF(); ppois(); qchisqtail(); qnorm(); qpois(). Random functions; Setting a seed; Reproducibility across sessions. Genetics functions; locus(); locus_from_global_position(); locus_interval(); parse_locus(); parse_variant(); parse_locus_interval(); variant_str(); call(); unphased_diploid_gt_index_call(); parse_call(); downcode(); triangle(); is_snp(); is_mnp(); is_transition(); is_transversion(); is_insertion(); is_deletion(); is_indel(); is_star(); is_complex(); is_strand_ambiguous(); is_valid_contig(); is_valid_locus(); contig_length(); allele_type(); numeric_allele_type(); pl_dosage(); gp_dosage(); get_sequence(); mendel_error_code(); liftover(); min_rep(); reverse_complement(). Core language functions. literal(x[, dtype]); Captures and broadcasts a Python variable or object as an expression. cond(condition, consequent, alternate[, ...]); Deprecated in favor of if_else(). if_else(condition, consequent, alternate[, ...]); Expression for an if/else statement; tests a condition and returns one of two options based on the result. switch(expr); Build a conditional tree on the value of an expression. case([missing_false]); Chain multiple if-else statements with a CaseBuilder. bind(f, *exprs[, _ctx]); Bind a temporary variable and use it in a function. rbind(*exprs[, _ctx]); Bind a temporary variable and use it in a function. null(t); Deprecated in favor of missing(). is_missing(expression); Returns True if the argument is missing. is_defined(expression); Returns True if the argument is not missing. coalesce(*args); Returns the first non-missing value of args. or_else(a, b); If a is missing, return b. or_missing(predicate, value); Returns value if predicate is True, otherwise returns missing. range(start[, stop, step]); Returns an array of integers from start to stop by step. query_table(path, point_or_interval); Query records from a table corresponding to a given point or range of keys. Constructors. bool(x); Convert to a Boolean expression. float(x); Conver",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/index.html:3173,test,tests,3173,docs/0.2/functions/index.html,https://hail.is,https://hail.is/docs/0.2/functions/index.html,1,['test'],['tests']
Testability,"ormal distribution with the same mean and standard deviation, or use this distribution to approximate credible intervals under a flat prior on \(h^2\).; Testing each variant for association; Fixing a single variant, we define:. \(v = n \times 1\) vector of genotypes, with missing genotypes imputed as the mean of called genotypes; \(X_v = \left[v | X \right] = n \times (1 + c)\) matrix concatenating \(v\) and \(X\); \(\beta_v = (\beta^0_v, \beta^1_v, \ldots, \beta^c_v) = (1 + c) \times 1\) vector of covariate coefficients. Fixing \(\delta\) at the global REML estimate \(\hat{\delta}\), we find the REML estimate \((\hat{\beta}_v, \hat{\sigma}_{g,v}^2)\) via rotation of the model. \[y \sim \mathrm{N}\left(X_v\beta_v, \sigma_{g,v}^2 (K + \hat{\delta} I)\right)\]; Note that the only new rotation to compute here is \(U^T v\).; To test the null hypothesis that the genotype coefficient \(\beta^0_v\) is zero, we consider the restricted model with parameters \(((0, \beta^1_v, \ldots, \beta^c_v), \sigma_{g,v}^2)\) within the full model with parameters \((\beta^0_v, \beta^1_v, \ldots, \beta^c_v), \sigma_{g_v}^2)\), with \(\delta\) fixed at \(\hat\delta\) in both. The latter fit is simply that of the global model, \(((0, \hat{\beta}^1, \ldots, \hat{\beta}^c), \hat{\sigma}_g^2)\). The likelihood ratio test statistic is given by. \[\chi^2 = n \, \mathrm{ln}\left(\frac{\hat{\sigma}^2_g}{\hat{\sigma}_{g,v}^2}\right)\]; and follows a chi-squared distribution with one degree of freedom. Here the ratio \(\hat{\sigma}^2_g / \hat{\sigma}_{g,v}^2\) captures the degree to which adding the variant \(v\) to the global model reduces the residual phenotypic variance.; Kinship Matrix; FastLMM uses the Realized Relationship Matrix (RRM) for kinship. This can be computed with rrm(). However, any instance of KinshipMatrix may be used, so long as sample_list contains the complete samples of the caller variant dataset in the same order.; Low-rank approximation of kinship for improved performance; lm",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:105500,test,test,105500,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"ory |; +------+------+-----------------------------------------+. Parameters; ----------; key_expr : :class:`.Expression`; Row-indexed expression for key associated to each row.; weight_expr : :class:`.Float64Expression`; Row-indexed expression for row weights.; y : :class:`.Float64Expression`; Column-indexed response expression.; If `logistic` is ``True``, all non-missing values must evaluate to 0 or; 1. Note that a :class:`.BooleanExpression` will be implicitly converted; to a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions.; logistic : :obj:`bool` or :obj:`tuple` of :obj:`int` and :obj:`float`; If false, use the linear test. If true, use the logistic test with no; more than 25 logistic iterations and a convergence tolerance of 1e-6. If; a tuple is given, use the logistic test with the tuple elements as the; maximum nubmer of iterations and convergence tolerance, respectively.; max_size : :obj:`int`; Maximum size of group on which to run the test.; accuracy : :obj:`float`; Accuracy achieved by the Davies algorithm if fault value is zero.; iterations : :obj:`int`; Maximum number of iterations attempted by the Davies algorithm. Returns; -------; :class:`.Table`; Table of SKAT results. """"""; if hl.current_backend().requires_lowering:; if logistic:; kwargs = {'accuracy': accuracy, 'iterations': iterations}; if logistic is not True:; null_max_iterations, null_tolerance = logistic; kwargs['null_max_iterations'] = null_max_iterations; kwargs['null_tolerance'] = null_tolerance; ht = hl._logistic_skat(key_expr, weight_expr, y, x, covariates, max_size, **kwargs); else:; ht = hl._linear_skat(key_expr, weight_expr, y, x, covariates, max_size, accuracy, iterations); ht = ht.select_globals(); return ht; mt = matrix_table_source('skat/x', x); raise_unless_entry_indexed('skat/x', x). analyze('skat/key_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:107084,log,logistic,107084,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,"['log', 'test']","['logistic', 'test']"
Testability,"osted on GitHub:; git clone https://github.com/hail-is/hail.git; cd hail/hail. By default, Hail uses pre-compiled native libraries that are compatible with; recent Mac OS X and Debian releases. If you’re not using one of these OSes, set; the environment (or Make) variable HAIL_COMPILE_NATIVES to any value. This; variable tells GNU Make to build the native libraries from source.; Build and install a wheel file from source with local-mode pyspark:; make install HAIL_COMPILE_NATIVES=1. As above, but explicitly specifying the Scala and Spark versions:; make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5. Building the Docs and Website; Install build dependencies listed in the docs style guide.; Build without rendering the notebooks (which is slow):; make hail-docs-do-not-render-notebooks. Build while rendering the notebooks:; make hail-docs. Serve the built website on http://localhost:8000/; (cd build/www && python3 -m http.server). Running the tests; Install development dependencies:; make -C .. install-dev-requirements. A couple Hail tests compare to PLINK 1.9 (not PLINK 2.0 [ignore the confusing; URL]):. PLINK 1.9. Execute every Hail test using at most 8 parallel threads:; make -j8 test. Contributing; Chat with the dev team on our Zulip chatroom or; development forum if you have an idea for a contribution.; We can help you determine if your project is a good candidate for merging.; Keep in mind the following principles when submitting a pull request:. A PR should focus on a single feature. Multiple features should be split into multiple PRs.; Before submitting your PR, you should rebase onto the latest main.; PRs must pass all tests before being merged. See the section above on Running the tests locally.; PRs require a review before being merged. We will assign someone from our dev team to review your PR.; When you make a PR, include a short message that describes the purpose of the; PR and any necessary context for the changes you are maki",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/getting_started_developing.html:2158,test,tests,2158,docs/0.2/getting_started_developing.html,https://hail.is,https://hail.is/docs/0.2/getting_started_developing.html,1,['test'],['tests']
Testability,"ot functions utilize Bokeh plotting libraries to create attractive,; interactive figures. Plotting functions in this module return a Bokeh Figure, so you can call; a method to plot your data and then choose to extend the plot however you like by interacting; directly with Bokeh. See the GWAS tutorial for examples.; Plot functions in Hail accept data in the form of either Python objects or Table and MatrixTable fields. cdf; Create a cumulative density plot. pdf. smoothed_pdf; Create a density plot. histogram; Create a histogram. cumulative_histogram; Create a cumulative histogram. histogram2d; Plot a two-dimensional histogram. scatter; Create an interactive scatter plot. qq; Create a Quantile-Quantile plot. manhattan; Create a Manhattan plot. output_notebook; Configure the Bokeh output state to generate output in notebook cells when bokeh.io.show() is called. visualize_missingness; Visualize missingness in a MatrixTable. hail.plot.cdf(data, k=350, legend=None, title=None, normalize=True, log=False)[source]; Create a cumulative density plot. Parameters:. data (Struct or Float64Expression) – Sequence of data to plot.; k (int) – Accuracy parameter (passed to approx_cdf()).; legend (str) – Label of data on the x-axis.; title (str) – Title of the histogram.; normalize (bool) – Whether or not the cumulative data should be normalized.; log (bool) – Whether or not the y-axis should be of type log. Returns:; bokeh.plotting.figure. hail.plot.pdf(data, k=1000, confidence=5, legend=None, title=None, log=False, interactive=False)[source]. hail.plot.smoothed_pdf(data, k=350, smoothing=0.5, legend=None, title=None, log=False, interactive=False, figure=None)[source]; Create a density plot. Parameters:. data (Struct or Float64Expression) – Sequence of data to plot.; k (int) – Accuracy parameter.; smoothing (float) – Degree of smoothing.; legend (str) – Label of data on the x-axis.; title (str) – Title of the histogram.; log (bool) – Plot the log10 of the bin counts.; interactive (",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/plot.html:1810,log,log,1810,docs/0.2/plot.html,https://hail.is,https://hail.is/docs/0.2/plot.html,1,['log'],['log']
Testability,"otate_fields[coords] = coord_expr; else:; coords = src._fields_inverse[coord_expr]. if isinstance(src, hl.MatrixTable):; new_src = src.annotate_rows(**annotate_fields); else:; new_src = src.annotate(**annotate_fields). locus_expr = new_src[locus]; if coord_expr is not None:; coord_expr = new_src[coords]. if coord_expr is None:; coord_expr = locus_expr.position. rg = locus_expr.dtype.reference_genome; contig_group_expr = hl.agg.group_by(hl.locus(locus_expr.contig, 1, reference_genome=rg), hl.agg.collect(coord_expr)). # check loci are in sorted order; last_pos = hl.fold(; lambda a, elt: (; hl.case(); .when(a <= elt, elt); .or_error(; hl.str(""locus_windows: 'locus_expr' global position must be in ascending order. ""); + hl.str(a); + hl.str("" was not less then or equal to ""); + hl.str(elt); ); ),; -1,; hl.agg.collect(; hl.case(); .when(hl.is_defined(locus_expr), locus_expr.global_position()); .or_error(""locus_windows: missing value for 'locus_expr'.""); ),; ); checked_contig_groups = (; hl.case().when(last_pos >= 0, contig_group_expr).or_error(""locus_windows: 'locus_expr' has length 0""); ). contig_groups = locus_expr._aggregation_method()(checked_contig_groups, _localize=False). coords = hl.sorted(hl.array(contig_groups)).map(lambda t: t[1]); starts_and_stops = hl._locus_windows_per_contig(coords, radius). if not _localize:; return starts_and_stops. starts, stops = hl.eval(starts_and_stops); return np.array(starts), np.array(stops). def _check_dims(a, name, ndim, min_size=1):; if len(a.shape) != ndim:; raise ValueError(f'{name} must be {ndim}-dimensional, ' f'found {a.ndim}'); for i in range(ndim):; if a.shape[i] < min_size:; raise ValueError(f'{name}.shape[{i}] must be at least ' f'{min_size}, found {a.shape[i]}'). def _ndarray_matmul_ndim(left, right):; if left == 1 and right == 1:; return 0; elif left == 1:; return right - 1; elif right == 1:; return left - 1; else:; assert left == right; return left. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/utils/misc.html:8560,assert,assert,8560,docs/0.2/_modules/hail/linalg/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/utils/misc.html,2,['assert'],['assert']
Testability,"otes; Missing values for predicate are treated as False. Parameters:; predicate (BooleanExpression) – Boolean predicate. Returns:; Expression of type tfloat64 – Fraction of records where predicate is True. hail.expr.aggregators.hardy_weinberg_test(expr, one_sided=False)[source]; Performs test of Hardy-Weinberg equilibrium.; Examples; Test each row of a dataset:; >>> dataset_result = dataset.annotate_rows(hwe = hl.agg.hardy_weinberg_test(dataset.GT)). Test each row on a sub-population:; >>> dataset_result = dataset.annotate_rows(; ... hwe_eas = hl.agg.filter(dataset.pop == 'EAS',; ... hl.agg.hardy_weinberg_test(dataset.GT))). Notes; This method performs the test described in functions.hardy_weinberg_test() based solely on; the counts of homozygous reference, heterozygous, and homozygous variant calls.; The resulting struct expression has two fields:. het_freq_hwe (tfloat64) - Expected frequency; of heterozygous calls under Hardy-Weinberg equilibrium.; p_value (tfloat64) - p-value from test of Hardy-Weinberg; equilibrium. By default, Hail computes the exact p-value with mid-p-value correction, i.e. the; probability of a less-likely outcome plus one-half the probability of an; equally-likely outcome. See this document for; details on the Levene-Haldane distribution and references.; To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set one_sided=True and the p-value returned will be; from the one-sided exact test. Warning; Non-diploid calls (ploidy != 2) are ignored in the counts. While the; counts are defined for multiallelic variants, this test is only statistically; rigorous in the biallelic setting; use split_multi(); to split multiallelic variants beforehand. Parameters:. expr (CallExpression) – Call to test for Hardy-Weinberg equilibrium.; one_sided (bool) – False by default. When True, perform one-sided test for excess heterozygosity. Returns:; StructExpression – Struct expression with fields het_freq_hwe and p_value.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/aggregators.html:15837,test,test,15837,docs/0.2/aggregators.html,https://hail.is,https://hail.is/docs/0.2/aggregators.html,1,['test'],['test']
Testability,"otype :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; :math:`\mathrm{isFemale}` is coded as 1 for true (female) and; 0 for false (male). The null model sets :math:`\\beta_1 = 0`. The resulting variant annotations depend on the test statistic; as shown in the tables below. ========== =================== ====== =====; Test Annotation Type Value; ========== =================== ====== =====; Wald ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; Wald ``va.logreg.se`` Double estimated standard error, :math:`\widehat{\mathrm{se}}`; Wald ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`; Wald ``va.logreg.pval`` Double Wald p-value testing :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. ================ =========================== ======= =====; Test Annotation Type Value; ================ =========================== ======= =====; Wald, LRT, Firth ``va.logreg.fit.nIter`` Int number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth); Wald, LRT, Firth ``va.logreg.fit.converged`` Boolean true if iteration converged; Wald, LRT, Firth ``va.lo",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:142161,test,testing,142161,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['testing']
Testability,"otype(2). All the below statements are true:. .. testcode::. hom_ref.one_hot_alleles(num_alleles) == [2, 0]; het.one_hot_alleles(num_alleles) == [1, 1]; hom_var.one_hot_alleles(num_alleles) == [0, 2]. This function returns None if the genotype call is missing. :param int num_alleles: number of possible alternate alleles; :rtype: list of int or None; """"""; return jiterable_to_list(from_option(self._jrep.oneHotAlleles(num_alleles))). [docs] @handle_py4j; @typecheck_method(num_genotypes=integral); def one_hot_genotype(self, num_genotypes):; """"""Returns a list containing the one-hot encoded representation of the genotype call. A one-hot encoding is a vector with one '1' and many '0' values, like; [0, 0, 1, 0] or [1, 0, 0, 0]. This function is useful for transforming; the genotype call (gt) into a one-hot encoded array. With the following; variables:. .. testcode::. num_genotypes = 3; hom_ref = Genotype(0); het = Genotype(1); hom_var = Genotype(2). All the below statements are true:. .. testcode::. hom_ref.one_hot_genotype(num_genotypes) == [1, 0, 0]; het.one_hot_genotype(num_genotypes) == [0, 1, 0]; hom_var.one_hot_genotype(num_genotypes) == [0, 0, 1]. This function returns None if the genotype call is missing. :param int num_genotypes: number of possible genotypes; :rtype: list of int or None; """""". return jiterable_to_list(from_option(self._jrep.oneHotGenotype(num_genotypes))). [docs] @handle_py4j; @typecheck_method(theta=numeric); def p_ab(self, theta=0.5):; """"""Returns the p-value associated with finding the given allele depth ratio. This function uses a one-tailed binomial test. This function returns None if the allelic depth (ad) is missing. :param float theta: null reference probability for binomial model; :rtype: float; """""". return from_option(self._jrep.pAB(theta)). [docs] def fraction_reads_ref(self):; """"""Returns the fraction of reads that are reference reads. Equivalent to:. >>> g.ad[0] / sum(g.ad). :rtype: float or None; """""". return from_option(self._jrep.fracti",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html:6454,test,testcode,6454,docs/0.1/_modules/hail/representation/genotype.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html,1,['test'],['testcode']
Testability,"ough` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if hl.current_backend().requires_lowering:; return _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:62519,test,test,62519,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"output. always_run(always_run=True); Set the job to always run, even if dependencies fail. Warning; Jobs set to always run are not cancellable!. Examples; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.always_run(); ... .command(f'echo ""hello""')). Parameters:; always_run (bool) – If True, set job to always run. Return type:; Self. Returns:; Same job object set to always run. cloudfuse(bucket, mount_point, *, read_only=True); Add a bucket to mount with gcsfuse in GCP or a storage container with blobfuse in Azure.; Notes; Can only be used with the backend.ServiceBackend. This method can; be called more than once. Warning; There are performance and cost implications of using gcsfuse; or blobfuse. Examples; Google Cloud Platform:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.cloudfuse('my-bucket', '/my-bucket'); ... .command(f'cat /my-bucket/my-blob-object')). Azure:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.cloudfuse('my-account/my-container', '/dest'); ... .command(f'cat /dest/my-blob-object')). Parameters:. bucket (str) – Name of the google storage bucket to mount or the path to an Azure container in the; format of <account>/<container>.; mount_point (str) – The path at which the cloud blob storage should be mounted to in the Docker; container.; read_only (bool) – If True, mount the cloud blob storage in read-only mode. Return type:; Self. Returns:; Same job object set with a cloud storage path to mount with either gcsfuse or blobfuse. cpu(cores); Set the job’s CPU requirements.; Notes; The string expression must be of the form {number}{suffix}; where the optional suffix is m representing millicpu.; Omitting a suffix means the value is in cpu.; For the ServiceBackend, cores must be a power of; two between 0.25 and 16.; Examples; Set the job’s CPU requirement to 250 millicpu:; >>> b = Batch(); >>> j = b.new_job(); >>> (j.cpu('250m'); ... .command(f'ech",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html:2888,test,test,2888,docs/batch/api/batch/hailtop.batch.job.Job.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html,2,['test'],['test']
Testability,"ovariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=nullable(int),; tolerance=nullable(float),; ); def _logistic_regression_rows_nd(; test, y, x, covariates, pass_through=(), *, max_iterations: Optional[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Warning; -------; :func:`.logistic_regression_rows` considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which **all** response variables and covariates are defined. For each row, missing values of; `x` are mean-imputed over these columns. As in the example, the; intercept covariate ``1`` must be included **explicitly** if desired. Notes; -----; This method performs, for each row, a significance test of the input; variable in predicting a binary (case-control) response variable based; on the logistic regression model. The response variable type must either; be numeric (with all present values 0 or 1) or Boolean, in which case; true and false are coded as 1 and 0, respectively. Hail supports the Wald test ('wald'), likelihood ratio test ('l",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:47857,test,test,47857,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"ow throw an exception on hl.export_bgen when there is no GP; field, instead of exporting null records.; (#12635) Fix bug; where hl.skat did not work on Apple M1 machines.; (#12571) When using; Query-on-Batch, hl.hadoop* methods now properly support creation and; modification time.; (#12566) Improve; error message when combining incompatibly indexed fields in certain; operations including array indexing. Version 0.2.108; Released 2023-1-12. New Features. (#12576); hl.import_bgen and hl.export_bgen now support compression; with Zstd. Bug fixes. (#12585); hail.ggplots that have more than one legend group or facet are; now interactive. If such a plot has enough legend entries that the; legend would be taller than the plot, the legend will now be; scrollable. Legend entries for such plots can be clicked to show/hide; traces on the plot, but this does not work and is a known issue that; will only be addressed if hail.ggplot is migrated off of plotly.; (#12584) Fixed bug; which arose as an assertion error about type mismatches. This was; usually triggered when working with tuples.; (#12583) Fixed bug; which showed an empty table for ht.col_key.show().; (#12582) Fixed bug; where matrix tables with duplicate col keys do not show properly.; Also fixed bug where tables and matrix tables with HTML unsafe column; headers are rendered wrong in Jupyter.; (#12574) Fixed a; memory leak when processing tables. Could trigger unnecessarily high; memory use and out of memory errors when there are many rows per; partition or large key fields.; (#12565) Fixed a bug; that prevented exploding on a field of a Table whose value is a; random value. Version 0.2.107; Released 2022-12-14. Bug fixes. (#12543) Fixed; hl.vds.local_to_global error when LA array contains non-ascending; allele indices. Version 0.2.106; Released 2022-12-13. New Features. (#12522) Added; hailctl config setting 'batch/backend' to specify the default; backend to use in batch scripts when not specified in code.; (#12",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:40487,assert,assertion,40487,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['assert'],['assertion']
Testability,"ow which to use sparse genotype vector in rotation (advanced). :param bool use_dosages: If true, use dosages rather than hard call genotypes. :param int n_eigs: Number of eigenvectors of the kinship matrix used to fit the model. :param float dropped_variance_fraction: Upper bound on fraction of sample variance lost by dropping eigenvectors with small eigenvalues. :return: Variant dataset with linear mixed regression annotations.; :rtype: :py:class:`.VariantDataset`; """""". jvds = self._jvdf.lmmreg(kinshipMatrix._jkm, y, jarray(Env.jvm().java.lang.String, covariates),; use_ml, global_root, va_root, run_assoc, joption(delta), sparsity_threshold,; use_dosages, joption(n_eigs), joption(dropped_variance_fraction)); return VariantDataset(self.hc, jvds). [docs] @handle_py4j; @requireTGenotype; @typecheck_method(test=strlike,; y=strlike,; covariates=listof(strlike),; root=strlike,; use_dosages=bool); def logreg(self, test, y, covariates=[], root='va.logreg', use_dosages=False):; """"""Test each variant for association using logistic regression. .. include:: requireTGenotype.rst. **Examples**. Run the logistic regression Wald test per variant using a Boolean phenotype and two covariates stored; in sample annotations:. >>> vds_result = vds.logreg('wald', 'sa.pheno.isCase', covariates=['sa.pheno.age', 'sa.pheno.isFemale']). **Notes**. The :py:meth:`~hail.VariantDataset.logreg` method performs,; for each variant, a significance test of the genotype in; predicting a binary (case-control) phenotype based on the; logistic regression model. The phenotype type must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded as 1 and 0, respectively. Hail supports the Wald test ('wald'), likelihood ratio test ('lrt'), Rao score test ('score'),; and Firth test ('firth'). Hail only includes samples for which the phenotype and all covariates are; defined. For each variant, Hail imputes missing genotypes as the mean of called genotypes. By default, ge",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:139328,log,logreg,139328,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,2,['log'],"['logistic', 'logreg']"
Testability,"own in the tables below. ========== =================== ====== =====; Test Annotation Type Value; ========== =================== ====== =====; Wald ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; Wald ``va.logreg.se`` Double estimated standard error, :math:`\widehat{\mathrm{se}}`; Wald ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`; Wald ``va.logreg.pval`` Double Wald p-value testing :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. ================ =========================== ======= =====; Test Annotation Type Value; ================ =========================== ======= =====; Wald, LRT, Firth ``va.logreg.fit.nIter`` Int number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth); Wald, LRT, Firth ``va.logreg.fit.converged`` Boolean true if iteration converged; Wald, LRT, Firth ``va.logreg.fit.exploded`` Boolean true if iteration exploded; ================ =========================== ======= =====. We consider iteration to have converged when every coordinate of :math:`\\beta` changes by less than :math:`10^{-6}`. For Wald and LRT, up to 25 iterations are attempted; in testing we fi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:142395,test,tests,142395,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,2,"['log', 'test']","['logistic', 'tests']"
Testability,"p-level fields.; (#4926) Expanded; default GRCh38 contig recoding behavior in import_plink. Performance improvements. (#4952) Resolved; lingering issues related to; (#4909). Bug fixes. (#4941) Fixed; variable scoping error in regression methods.; (#4857) Fixed bug in; maximal_independent_set appearing when nodes were named something; other than i and j.; (#4932) Fixed; possible error in export_plink related to tolerance of writer; process failure.; (#4920) Fixed bad; error message in Table.order_by. Version 0.2.5; Released 2018-12-07. New features. (#4845) The; or_error; method in hl.case and hl.switch statements now takes a string; expression rather than a string literal, allowing more informative; messages for errors and assertions.; (#4865) We use this; new or_error functionality in methods that require biallelic; variants to include an offending variant in the error message.; (#4820) Added; hl.reversed; for reversing arrays and strings.; (#4895) Added; include_strand option to the; hl.liftover; function. Performance improvements. (#4907)(#4911); Addressed one aspect of bad scaling in enormous literal values; (triggered by a list of 300,000 sample IDs) related to logging.; (#4909)(#4914); Fixed a check in Table/MatrixTable initialization that scaled O(n^2); with the total number of fields. Bug fixes. (#4754)(#4799); Fixed optimizer assertion errors related to certain types of; pipelines using group_rows_by.; (#4888) Fixed; assertion error in BlockMatrix.sum.; (#4871) Fixed; possible error in locally sorting nested collections.; (#4889) Fixed break; in compatibility with extremely old MatrixTable/Table files.; (#4527)(#4761); Fixed optimizer assertion error sometimes encountered with; hl.split_multi[_hts]. Version 0.2.4: Beginning of history!; We didn’t start manually curating information about user-facing changes; until version 0.2.4.; The full commit history is available; here. Previous. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:103878,log,logging,103878,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,4,"['assert', 'log']","['assertion', 'logging']"
Testability,"p. Parameters:. mapping (Aesthetic) – Any aesthetics specific to this geom.; fill – Color of fill to draw, black by default. Overrides fill aesthetic.; color – Color of line to draw outlining non x-axis facing side, none by default. Overrides color aesthetic. Returns:; FigureAttribute – The geom to be applied. hail.ggplot.geom_ribbon(mapping={}, fill=None, color=None)[source]; Creates filled in area between two lines specified by x, ymin, and ymax; Supported aesthetics: x, ymin, ymax, color, fill, tooltip. Parameters:. mapping (Aesthetic) – Any aesthetics specific to this geom.; fill – Color of fill to draw, black by default. Overrides fill aesthetic.; color – Color of line to draw outlining both side, none by default. Overrides color aesthetic.; return:; :class:`FigureAttribute` – The geom to be applied. Scales. scale_x_continuous; The default continuous x scale. scale_x_discrete; The default discrete x scale. scale_x_genomic; The default genomic x scale. scale_x_log10; Transforms x axis to be log base 10 scaled. scale_x_reverse; Transforms x-axis to be vertically reversed. scale_y_continuous; The default continuous y scale. scale_y_discrete; The default discrete y scale. scale_y_log10; Transforms y-axis to be log base 10 scaled. scale_y_reverse; Transforms y-axis to be vertically reversed. scale_color_continuous; The default continuous color scale. scale_color_discrete; The default discrete color scale. scale_color_hue; Map discrete colors to evenly placed positions around the color wheel. scale_color_manual; A color scale that assigns strings to colors using the pool of colors specified as values. scale_color_identity; A color scale that assumes the expression specified in the color aesthetic can be used as a color. scale_fill_continuous; The default continuous fill scale. scale_fill_discrete; The default discrete fill scale. scale_fill_hue; Map discrete fill colors to evenly placed positions around the color wheel. scale_fill_manual; A color scale that assigns s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/ggplot/index.html:8644,log,log,8644,docs/0.2/ggplot/index.html,https://hail.is,https://hail.is/docs/0.2/ggplot/index.html,1,['log'],['log']
Testability,"parse_locus_interval(x_contig, rg), rg.x_contigs), keep=True; ); if not include_par:; interval_type = hl.tarray(hl.tinterval(hl.tlocus(rg))); mt = hl.filter_intervals(mt, hl.literal(rg.par, interval_type), keep=False). mt = mt.filter_rows((mt[aaf] > aaf_threshold) & (mt[aaf] < (1 - aaf_threshold))); mt = mt.annotate_cols(ib=agg.inbreeding(mt.call, mt[aaf])); kt = mt.select_cols(; is_female=hl.if_else(; mt.ib.f_stat < female_threshold, True, hl.if_else(mt.ib.f_stat > male_threshold, False, hl.missing(tbool)); ),; **mt.ib,; ).cols(). return kt. def _get_regression_row_fields(mt, pass_through, method) -> Dict[str, str]:; row_fields = dict(zip(mt.row_key.keys(), mt.row_key.keys())); for f in pass_through:; if isinstance(f, str):; if f not in mt.row:; raise ValueError(f""'{method}/pass_through': MatrixTable has no row field {f!r}""); if f in row_fields:; # allow silent pass through of key fields; if f in mt.row_key:; pass; else:; raise ValueError(f""'{method}/pass_through': found duplicated field {f!r}""); row_fields[f] = mt[f]; else:; assert isinstance(f, Expression); if not f._ir.is_nested_field:; raise ValueError(f""'{method}/pass_through': expect fields or nested fields, not complex expressions""); if not f._indices == mt._row_indices:; raise ExpressionException(; f""'{method}/pass_through': require row-indexed fields, found indices {f._indices.axes}""; ); name = f._ir.name; if name in row_fields:; # allow silent pass through of key fields; if not (name in mt.row_key and f._ir == mt[name]._ir):; raise ValueError(f""'{method}/pass_through': found duplicated field {name!r}""); row_fields[name] = f; for k in mt.row_key:; del row_fields[k]; return row_fields. [docs]@typecheck(; y=oneof(expr_float64, sequenceof(expr_float64), sequenceof(sequenceof(expr_float64))),; x=expr_float64,; covariates=sequenceof(expr_float64),; block_size=int,; pass_through=sequenceof(oneof(str, Expression)),; weights=nullable(oneof(expr_float64, sequenceof(expr_float64))),; ); def linear_regression_rows(y,",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:7271,assert,assert,7271,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['assert'],['assert']
Testability,"path) of the new sample annotation and the right-hand side is the result of evaluating an expression with VDS elements. Computed From Existing Annotations¶. Add a new variant annotation called passAll which is the result of a boolean expression evaluating other variant annotation variables. va.passAll = va.pass && va.meanGQ > 20 && va.meanDP > 20. Add a new sample annotation called batch1 which is the result of a boolean expression comparing an existing boolean sample annotation variable to the string “Batch1”. sa.batch1 = sa.cohort == ""Batch1"". Add a new boolean sample annotation based on the length of the sample ID. sa.idTooLong = s.length > 10. Add a new variant annotation that is a String representing the chromosome and start position. va.altName = v.contig + "":"" + v.start. Add a new variant annotation that splits a comma-separated string with gene names and keeps the first element of the resulting array. va.geneName = va.geneNames.split("","")[0]. Add a new variant annotation that is the log of an existing annotation. va.logIntensity = log(va.intensity). Add a new global annotation computed from existing global annotations. global.callRate = global.nCalled / global.nGenotypes. Variant Annotation Computed from a Genotype Aggregable (gs)¶; In the context of creating new variant annotations, a genotype aggregable (gs) represents a row of genotypes in the variant-sample matrix.; The result of evaluating the genotype aggregable expression per row is added to the corresponding variant annotation.; The map function takes a lambda expression as input (g => ...). The filter function takes a boolean lambda expression as input (g => Boolean Expression). Transform the genotype aggregable to an aggregable of GQ scores using the map function and then calculate summary statistics on the GQ scores with the stats function. va.gqStats = gs.map(g => g.gq).stats(). Filter the genotype aggregable based on case status (sa.pheno.isCase) and genotype call (g.isHet and g.isHomVar) and th",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/overview.html:6567,log,log,6567,docs/0.1/overview.html,https://hail.is,https://hail.is/docs/0.1/overview.html,1,['log'],['log']
Testability,"pation?; What genres are most preferred by women vs men?. We’ll use joins to combine datasets in order to answer these questions.; Let’s initialize Hail, fetch the tutorial data, and load three tables: users, movies, and ratings. [1]:. import hail as hl. hl.utils.get_movie_lens('data/'). users = hl.read_table('data/users.ht'); movies = hl.read_table('data/movies.ht'); ratings = hl.read_table('data/ratings.ht'). Loading BokehJS ... Initializing Hail with default parameters...; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2010-0.2.133-4c60fddb171a.log; 2024-10-04 20:10:22.038 Hail: INFO: Movie Lens files found!. The Key to Understanding Joins; To understand joins in Hail, we need to revisit one of the crucial properties of tables: the key.; A table has an ordered list of fields known as the key. Our users table has one key, the id field. We can see all the fields, as well as the keys, of a table by calling describe(). [2]:. users.describe(). ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'id': int32; 'age': int32; 'sex': str; 'occupation': str; 'zipcode': str; ----------------------------------------; Key: ['id']; ----------------------------------------. key is a struct expression of all of the key fields, so we can refer to the key of a table without explicitly specifying the names of the key fields. [3]:. users.key.describe(). --------------------------------------------------------; Type:; struct {; id: int32; }; -----------------------------------------------------",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/06-joins.html:2036,log,log,2036,docs/0.2/tutorials/06-joins.html,https://hail.is,https://hail.is/docs/0.2/tutorials/06-joins.html,1,['log'],['log']
Testability,"pdir):; local_tmpdir = get_env_or_default(local_tmpdir, 'TMPDIR', 'file:///tmp'); r = urlparse(local_tmpdir); if not r.scheme:; r = r._replace(scheme='file'); elif r.scheme != 'file':; raise ValueError('invalid local_tmpfile: must use scheme file, got scheme {r.scheme}'); return urlunparse(r). def _get_log(log):; if log is None:; py_version = version(); log_dir = os.environ.get('HAIL_LOG_DIR'); if log_dir is None:; log_dir = os.getcwd(); log = hail.utils.timestamp_path(os.path.join(log_dir, 'hail'), suffix=f'-{py_version}.log'); return log. def convert_gcs_requester_pays_configuration_to_hadoop_conf_style(; x: Optional[Union[str, Tuple[str, List[str]]]],; ) -> Tuple[Optional[str], Optional[str]]:; if isinstance(x, str):; return x, None; if isinstance(x, tuple):; return x[0], "","".join(x[1]); return None, None. class HailContext(object):; @staticmethod; def create(; log: str,; quiet: bool,; append: bool,; tmpdir: str,; local_tmpdir: str,; default_reference: str,; global_seed: Optional[int],; backend: Backend,; ):; hc = HailContext(; log=log,; quiet=quiet,; append=append,; tmpdir=tmpdir,; local_tmpdir=local_tmpdir,; global_seed=global_seed,; backend=backend,; ); hc.initialize_references(default_reference); return hc. @typecheck_method(; log=str, quiet=bool, append=bool, tmpdir=str, local_tmpdir=str, global_seed=nullable(int), backend=Backend; ); def __init__(self, log, quiet, append, tmpdir, local_tmpdir, global_seed, backend):; assert not Env._hc. self._log = log. self._tmpdir = tmpdir; self._local_tmpdir = local_tmpdir. self._backend = backend. self._warn_cols_order = True; self._warn_entries_order = True. self._default_ref: Optional[ReferenceGenome] = None. if not quiet:; py_version = version(); sys.stderr.write(; 'Welcome to\n'; ' __ __ <>__\n'; ' / /_/ /__ __/ /\n'; ' / __ / _ `/ / /\n'; ' /_/ /_/\\_,_/_/_/ version {}\n'.format(py_version); ). if py_version.startswith('devel'):; sys.stderr.write(; 'NOTE: This is a beta version. Interfaces may change\n'; ' during th",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:2468,log,log,2468,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,6,['log'],['log']
Testability,"pe not in [hl.tint32, hl.tint64]:; raise TypeError(f""Argument {i} of reshape needs to be an integer, got {tuple_field_type}.""); shape_ir = hl.or_missing(hl.is_defined(shape), hl.tuple([hl.int64(i) for i in shape]))._ir; ndim = len(shape); else:; wrapped_shape = wrap_to_list(shape); ndim = len(wrapped_shape); shape_ir = hl.tuple(wrapped_shape)._ir. return construct_expr(; ir.NDArrayReshape(self._ir, shape_ir), tndarray(self._type.element_type, ndim), indices, aggregations; ). [docs] @typecheck_method(f=func_spec(1, expr_any)); def map(self, f):; """"""Applies an element-wise operation on an NDArray. Parameters; ----------; f : function ( (arg) -> :class:`.Expression`); Function to transform each element of the NDArray. Returns; -------; :class:`.NDArrayExpression`.; NDArray where each element has been transformed according to `f`.; """""". element_type = self._type.element_type; ndarray_map = self._ir_lambda_method(ir.NDArrayMap, f, element_type, lambda t: tndarray(t, self.ndim)). assert isinstance(self._type, tndarray); return ndarray_map. [docs] @typecheck_method(other=oneof(expr_ndarray(), list), f=func_spec(2, expr_any)); def map2(self, other, f):; """"""Applies an element-wise binary operation on two NDArrays. Parameters; ----------; other : class:`.NDArrayExpression`, :class:`.ArrayExpression`, numpy NDarray,; or nested python list/tuples. Both NDArrays must be the same shape or; broadcastable into common shape.; f : function ((arg1, arg2)-> :class:`.Expression`); Function to be applied to each element of both NDArrays. Returns; -------; :class:`.NDArrayExpression`.; Element-wise result of applying `f` to each index in NDArrays.; """""". if isinstance(other, (list, np.ndarray)):; other = hl.nd.array(other). self_broadcast, other_broadcast = self._broadcast_to_same_ndim(other). element_type1 = self_broadcast._type.element_type; element_type2 = other_broadcast._type.element_type; ndarray_map2 = self_broadcast._ir_lambda_method2(; other_broadcast, ir.NDArrayMap2, f, element_t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:101669,assert,assert,101669,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['assert'],['assert']
Testability,"pe of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `condition`.; """"""; if missing_false:; condition = hl.bind(lambda x: hl.is_defined(x) & x, condition); indices, aggregations = unify_all(condition, consequent, alternate). consequent, alternate, success = unify_exprs(consequent, alternate); if not success:; raise TypeError(; f""'if_else' and 'cond' require the 'consequent' and 'alternate' arguments to have the same type\n""; f"" consequent: type '{consequent.dtype}'\n""; f"" alternate: type '{alternate.dtype}'""; ); assert consequent.dtype == alternate.dtype. return construct_expr(ir.If(condition._ir, consequent._ir, alternate._ir), consequent.dtype, indices, aggregations). [docs]def case(missing_false: bool = False) -> 'hail.expr.builders.CaseBuilder':; """"""Chain multiple if-else statements with a :class:`.CaseBuilder`. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(hl.len(x) == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Parameters; ----------; missing_false : :obj:`bool`; Treat missing predicates as ``False``. See Also; --------; :class:`.CaseBuilder`, :func:`.switch`, :func:`.cond`. Returns; -------; :class:`.CaseBuilder`.; """"""; from .builders import CaseBuilder. return CaseBuilder(missing_false=missing_false). [docs]@typecheck(expr=expr_any); def switch(expr) -> 'hail.expr.builders.SwitchBuilder':; """"""Build a conditional tree on the value of an expression. Examples; --------. >>> csq = h",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:15414,assert,assert,15414,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['assert'],['assert']
Testability,"pe: bool; """""". return self._jcall.isHetRef(self._jrep). [docs] def is_not_called(self):; """"""True if the call is missing. :rtype: bool; """""". return self._jcall.isNotCalled(self._jrep). [docs] def is_called(self):; """"""True if the call is non-missing. :rtype: bool; """""". return self._jcall.isCalled(self._jrep). [docs] def num_alt_alleles(self):; """"""Returns the count of non-reference alleles. This function returns None if the genotype call is missing. :rtype: int or None; """""". return self._jcall.nNonRefAlleles(self._jrep). [docs] @handle_py4j; @typecheck_method(num_alleles=integral); def one_hot_alleles(self, num_alleles):; """"""Returns a list containing the one-hot encoded representation of the called alleles. This one-hot representation is the positional sum of the one-hot; encoding for each called allele. For a biallelic variant, the; one-hot encoding for a reference allele is [1, 0] and the one-hot; encoding for an alternate allele is [0, 1]. Thus, with the; following variables:. .. testcode::. num_alleles = 2; hom_ref = Call(0); het = Call(1); hom_var = Call(2). All the below statements are true:. .. testcode::. hom_ref.one_hot_alleles(num_alleles) == [2, 0]; het.one_hot_alleles(num_alleles) == [1, 1]; hom_var.one_hot_alleles(num_alleles) == [0, 2]. This function returns None if the call is missing. :param int num_alleles: number of possible alternate alleles; :rtype: list of int or None; """"""; return jiterable_to_list(self._jcall.oneHotAlleles(self._jrep, num_alleles)). [docs] @handle_py4j; @typecheck_method(num_genotypes=integral); def one_hot_genotype(self, num_genotypes):; """"""Returns a list containing the one-hot encoded representation of the genotype call. A one-hot encoding is a vector with one '1' and many '0' values, like; [0, 0, 1, 0] or [1, 0, 0, 0]. This function is useful for transforming; the genotype call (gt) into a one-hot encoded array. With the following; variables:. .. testcode::. num_genotypes = 3; hom_ref = Call(0); het = Call(1); hom_var = Call(2)",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html:10217,test,testcode,10217,docs/0.1/_modules/hail/representation/genotype.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html,1,['test'],['testcode']
Testability,"pieces of information, but this same pattern can be used to detect; effects of rare variation:. Count the number of heterozygous genotypes per gene by functional; category (synonymous, missense, or loss-of-function) to estimate; per-gene functional constraint; Count the number of singleton loss-of-function mutations per gene in; cases and controls to detect genes involved in disease. Eplilogue¶; Congrats! If you’ve made it this far, you’re perfectly primed to read; the Overview, look through the; Hail objects representing many; core concepts in genetics, and check out the many Hail functions defined; in the Python API. If you use Hail; for your own science, we’d love to hear from you on Gitter; chat or the discussion; forum.; There’s also a lot of functionality inside Hail that we didn’t get to in; this broad overview. Things like:. Flexible import and export to a variety of data and annotation; formats (VCF, BGEN, PLINK, JSON, TSV, …); Simulation; Burden tests; Kinship and pruning (IBD, GRM, RRM); Family-based tests and utilities; Distributed file system utilities; Interoperability with Python and Spark machine learning libraries; More!. For reference, here’s the full workflow to all tutorial endpoints; combined into one cell. It may take a minute! It’s doing a lot of work. In [60]:. table = hc.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample'); common_vds = (hc.read('data/1kg.vds'); .annotate_samples_table(table, root='sa'); .sample_qc(); .filter_samples_expr('sa.qc.dpMean >= 4 && sa.qc.callRate >= 0.97'); .filter_genotypes('''let ab = g.ad[1] / g.ad.sum() in; ((g.isHomRef && ab <= 0.1) ||; (g.isHet && ab >= 0.25 && ab <= 0.75) ||; (g.isHomVar && ab >= 0.9))'''); .variant_qc(); .filter_variants_expr('va.qc.AF > 0.01'); .ld_prune(memory_per_core=512, num_cores=4)). pca = common_vds.pca('sa.pca', k=5, eigenvalues='global.eigen'); pvals = (common_vds; .annotate_samples_table(pca.samples_table(), expr='sa.pca = table.pca'); .linreg('sa.CaffeineCons",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/hail-overview.html:30341,test,tests,30341,docs/0.1/tutorials/hail-overview.html,https://hail.is,https://hail.is/docs/0.1/tutorials/hail-overview.html,2,['test'],['tests']
Testability,"ple above considers a model of the form. \[\mathrm{Prob}(\mathrm{isCase}) = \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt} + \beta_2 \, \mathrm{age} + \beta_3 \, \mathrm{isFemale} + \varepsilon), \quad \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid; function, the; genotype \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; \(\mathrm{isFemale}\) is coded as 1 for true (female) and; 0 for false (male). The null model sets \(\beta_1 = 0\).; The resulting variant annotations depend on the test statistic; as shown in the tables below. Test; Annotation; Type; Value. Wald; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). Wald; va.logreg.se; Double; estimated standard error, \(\widehat{\mathrm{se}}\). Wald; va.logreg.zstat; Double; Wald \(z\)-statistic, equal to \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; va.logreg.fit.converged; Boolean; true if iteration converged. Wald, LRT, Firth; va.log",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:111364,log,logreg,111364,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logreg']
Testability,"ple size correction.; The q_stat return value is not the \(Q\) statistic from the paper. We match the output; of the SKAT R package which returns \(\tilde{Q}\):. \[\tilde{Q} = \frac{Q}{2}\]. Parameters:. group (Expression) – Row-indexed expression indicating to which group a variant belongs. This is typically a gene; name or an interval.; weight (Float64Expression) – Row-indexed expression for weights. Must be non-negative.; y (Float64Expression) – Column-indexed response (dependent variable) expression.; x (Float64Expression) – Entry-indexed expression for input (independent variable).; covariates (list of Float64Expression) – List of column-indexed covariate expressions. You must explicitly provide an intercept term; if desired. You must provide at least one covariate.; max_size (int) – Maximum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; null_max_iterations (int) – The maximum number of iterations when fitting the logistic null model. Defaults to 25.; null_tolerance (float) – The null model logisitic regression converges when the errors is less than this. Defaults to; 1e-6.; accuracy (float) – The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations (int) – The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns:; Table – One row per-group. The key is group. The row fields are:. group : the group parameter.; size : tint64, the number of variants in this group.; q_stat : tfloat64, the \(Q\) statistic, see Notes for why this differs from the paper.; p_value : tfloat64, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes.; fault : tint32, the fault flag from pgenchisq(). The global fields are:. n_complete_samples : tint32, the number of samples with neither a missing; phenotype nor a missing covariate.; y_residual : tint32, the resid",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:76215,log,logistic,76215,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['log'],['logistic']
Testability,"plest way to export all resulting annotations is:. >>> lmm_vds.export_variants('output/lmmreg.tsv.bgz', 'variant = v, va.lmmreg.*'); >>> lmmreg_results = lmm_vds.globals['lmmreg']; ; By default, genotypes values are given by hard call genotypes (``g.gt``).; If ``use_dosages=True``, then genotype values for per-variant association are defined by the dosage; :math:`\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})`. For Phred-scaled values,; :math:`\mathrm{P}(\mathrm{Het})` and :math:`\mathrm{P}(\mathrm{HomVar})` are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1. **Performance**. Hail's initial version of :py:meth:`.lmmreg` scales beyond 15k samples and to an essentially unbounded number of variants, making it particularly well-suited to modern sequencing studies and complementary to tools designed for SNP arrays. Analysts have used :py:meth:`.lmmreg` in research to compute kinship from 100k common variants and test 32 million non-rare variants on 8k whole genomes in about 10 minutes on `Google cloud <http://discuss.hail.is/t/using-hail-on-the-google-cloud-platform/80>`__. While :py:meth:`.lmmreg` computes the kinship matrix :math:`K` using distributed matrix multiplication (Step 2), the full `eigendecomposition <https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix>`__ (Step 3) is currently run on a single core of master using the `LAPACK routine DSYEVD <http://www.netlib.org/lapack/explore-html/d2/d8a/group__double_s_yeigen_ga694ddc6e5527b6223748e3462013d867.html>`__, which we empirically find to be the most performant of the four available routines; laptop performance plots showing cubic complexity in :math:`n` are available `here <https://github.com/hail-is/hail/pull/906>`__. On Google cloud, eigendecomposition takes about 2 seconds for 2535 sampes and 1 minute for 8185 samples. If you see worse performance, check that LAPACK natives are being properly loaded (see ""BLAS and LAPACK"" in Getting Started",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:124659,test,test,124659,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['test']
Testability,"position of a symmetric matrix. Parameters; ----------; nd : :class:`.NDArrayNumericExpression`; A 2 dimensional ndarray, shape(N, N).; eigvals_only: :class:`.bool`; If False (default), compute the eigenvectors and eigenvalues. Otherwise, only compute eigenvalues. Returns; -------; - w: :class:`.NDArrayNumericExpression`; The eigenvalues, shape(N).; - v: :class:`.NDArrayNumericExpression`; The eigenvectors, shape(N, N). Only returned if eigvals_only is false.; """"""; float_nd = nd.map(lambda x: hl.float64(x)); ir = NDArrayEigh(float_nd._ir, eigvals_only). return_type = tndarray(tfloat64, 1) if eigvals_only else ttuple(tndarray(tfloat64, 1), tndarray(tfloat64, 2)); return construct_expr(ir, return_type, nd._indices, nd._aggregations). [docs]@typecheck(nd=expr_ndarray()); def inv(nd):; """"""Performs a matrix inversion. Parameters; ----------. nd : :class:`.NDArrayNumericExpression`; A 2 dimensional ndarray. Returns; -------; :class:`.NDArrayNumericExpression`; The inverted matrix.; """""". assert nd.ndim == 2, ""Matrix inversion requires 2 dimensional ndarray"". float_nd = nd.map(lambda x: hl.float64(x)); ir = NDArrayInv(float_nd._ir); return construct_expr(ir, tndarray(tfloat64, 2), nd._indices, nd._aggregations). [docs]@typecheck(nds=tsequenceof_nd, axis=int); def concatenate(nds, axis=0):; """"""Join a sequence of arrays along an existing axis. Examples; --------. >>> x = hl.nd.array([[1., 2.], [3., 4.]]); >>> y = hl.nd.array([[5.], [6.]]); >>> hl.eval(hl.nd.concatenate([x, y], axis=1)); array([[1., 2., 5.],; [3., 4., 6.]]); >>> x = hl.nd.array([1., 2.]); >>> y = hl.nd.array([3., 4.]); >>> hl.eval(hl.nd.concatenate((x, y), axis=0)); array([1., 2., 3., 4.]). Parameters; ----------; nds : a sequence of :class:`.NDArrayNumericExpression`; The arrays must have the same shape, except in the dimension corresponding to axis (the first, by default).; Note: unlike Numpy, the numerical element type of each array_like must match.; axis : int, optional; The axis along which the arrays will",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/nd/nd.html:13426,assert,assert,13426,docs/0.2/_modules/hail/nd/nd.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/nd/nd.html,2,['assert'],['assert']
Testability,"pot (bool) – If False, this job will be run on non-spot instances. Return type:; Self. Returns:; Same job object. storage(storage); Set the job’s storage size.; Examples; Set the job’s disk requirements to 10 Gi:; >>> b = Batch(); >>> j = b.new_job(); >>> (j.storage('10Gi'); ... .command(f'echo ""hello""')); >>> b.run(). Notes; The storage expression must be of the form {number}{suffix}; where valid optional suffixes are K, Ki, M, Mi,; G, Gi, T, Ti, P, and Pi. Omitting a suffix means; the value is in bytes.; For the ServiceBackend, jobs requesting one or more cores receive; 5 GiB of storage for the root file system /. Jobs requesting a fraction of a core; receive the same fraction of 5 GiB of storage. If you need additional storage, you; can explicitly request more storage using this method and the extra storage space; will be mounted at /io. Batch automatically writes all ResourceFile to; /io.; The default storage size is 0 Gi. The minimum storage size is 0 Gi and the; maximum storage size is 64 Ti. If storage is set to a value between 0 Gi; and 10 Gi, the storage request is rounded up to 10 Gi. All values are; rounded up to the nearest Gi. Parameters:; storage (Union[str, int, None]) – Units are in bytes if storage is an int. If None, use the; default storage size for the ServiceBackend (0 Gi). Return type:; Self. Returns:; Same job object with storage set. timeout(timeout); Set the maximum amount of time this job can run for in seconds.; Notes; Can only be used with the backend.ServiceBackend.; Examples; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.timeout(10); ... .command(f'echo ""hello""')). Parameters:; timeout (Union[int, float, None]) – Maximum amount of time in seconds for a job to run before being killed.; If None, there is no timeout. Return type:; Self. Returns:; Same job object set with a timeout in seconds. Previous; Next . © Copyright 2024, Hail Team. Built with Sphinx using a; theme; provided by Read the Docs.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html:9498,test,test,9498,docs/batch/api/batch/hailtop.batch.job.Job.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html,2,['test'],['test']
Testability,"pr_ndarray()), expr_array(expr_ndarray())); shape_type = oneof(expr_int64, tupleof(expr_int64), expr_tuple()). [docs]def array(input_array, dtype=None):; """"""Construct an :class:`.NDArrayExpression`. Examples; --------. >>> hl.eval(hl.nd.array([1, 2, 3, 4])); array([1, 2, 3, 4], dtype=int32). >>> hl.eval(hl.nd.array([[1, 2, 3], [4, 5, 6]])); array([[1, 2, 3],; [4, 5, 6]], dtype=int32). >>> hl.eval(hl.nd.array(np.identity(3))); array([[1., 0., 0.],; [0., 1., 0.],; [0., 0., 1.]]). >>> hl.eval(hl.nd.array(hl.range(10, 20))); array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype=int32). Parameters; ----------; input_array : :class:`.ArrayExpression`, numpy ndarray, or nested python lists/tuples; The array to convert to a Hail ndarray.; dtype : :class:`.HailType`; Desired hail type. Default: `float64`. Returns; -------; :class:`.NDArrayExpression`; An ndarray based on the input array.; """"""; return _ndarray(input_array, dtype=dtype). @typecheck(a=expr_array(), shape=shape_type); def from_column_major(a, shape):; assert len(shape) == 2; return array(a).reshape(tuple(reversed(shape))).T. [docs]@typecheck(start=expr_int32, stop=nullable(expr_int32), step=expr_int32); def arange(start, stop=None, step=1) -> NDArrayNumericExpression:; """"""Returns a 1-dimensions ndarray of integers from `start` to `stop` by `step`. Examples; --------. >>> hl.eval(hl.nd.arange(10)); array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32). >>> hl.eval(hl.nd.arange(3, 10)); array([3, 4, 5, 6, 7, 8, 9], dtype=int32). >>> hl.eval(hl.nd.arange(0, 10, step=3)); array([0, 3, 6, 9], dtype=int32). Notes; -----; The range includes `start`, but excludes `stop`. If provided exactly one argument, the argument is interpreted as `stop` and; `start` is set to zero. This matches the behavior of Python's ``range``. Parameters; ----------; start : int or :class:`.Expression` of type :py:data:`.tint32`; Start of range.; stop : int or :class:`.Expression` of type :py:data:`.tint32`; End of range.; step : int or :class:`.Exp",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/nd/nd.html:2180,assert,assert,2180,docs/0.2/_modules/hail/nd/nd.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/nd/nd.html,2,['assert'],['assert']
Testability,"pression:; r""""""The cumulative probability function of a `t-distribution; <https://en.wikipedia.org/wiki/Student%27s_t-distribution>`__ with; `n` degrees of freedom. Examples; --------. >>> hl.eval(hl.pT(0, 10)); 0.5. >>> hl.eval(hl.pT(1, 10)); 0.82955343384897. >>> hl.eval(hl.pT(1, 10, lower_tail=False)); 0.17044656615103004. >>> hl.eval(hl.pT(1, 10, log_p=True)); -0.186867754489647. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is; a t-distributed random variable with `n` degrees of freedom. If `lower_tail`; is false, returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; n : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom of the t-distribution.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`. """"""; return _func(""pT"", tfloat64, x, n, lower_tail, log_p). [docs]@typecheck(x=expr_float64, df1=expr_float64, df2=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pF(x, df1, df2, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a `F-distribution; <https://en.wikipedia.org/wiki/F-distribution>`__ with parameters; `df1` and `df2`. Examples; --------. >>> hl.eval(hl.pF(0, 3, 10)); 0.0. >>> hl.eval(hl.pF(1, 3, 10)); 0.5676627969783028. >>> hl.eval(hl.pF(1, 3, 10, lower_tail=False)); 0.4323372030216972. >>> hl.eval(hl.pF(1, 3, 10, log_p=True)); -0.566227703842908. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is; a random variable with distribution :math:`F`(df1, df2). If `lower_tail`; is false, returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:74363,log,logarithm,74363,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['logarithm']
Testability,"project,; and at minimum the two latest minor versions.; All minor versions of numpy released in the 24 months prior to the; project, and at minimum the last three minor versions. Frequently Asked Questions. With a version like 0.x, is Hail ready for use in publications?; Yes. The semantic versioning standard uses 0.x; (development) versions to refer to software that is either “buggy” or; “partial”. While we don’t view Hail as particularly buggy (especially; compared to one-off untested scripts pervasive in bioinformatics!), Hail; 0.2 is a partial realization of a larger vision. What is the difference between the Hail Python library version and the native file format version?; The Hail Python library version, the version you see on; PyPI, in pip, or in; hl.version() changes every time we release the Python library. The; Hail native file format version only changes when we change the format; of Hail Table and MatrixTable files. If a version of the Python library; introduces a new native file format version, we note that in the change; log. All subsequent versions of the Python library can read the new file; format version.; The native file format changes much slower than the Python library; version. It is not currently possible to view the file format version of; a Hail Table or MatrixTable. What stability is guaranteed?; The Hail file formats and Python API are backwards compatible. This; means that a script developed to run on Hail 0.2.5 should continue to; work in every subsequent release within the 0.2 major version. This also; means any file written by python library versions 0.2.1 through 0.2.5; can be read by 0.2.5.; Forward compatibility of file formats and the Python API is not; guaranteed. In particular, a new file format version is only readable by; library versions released after the file format. For example, Python; library version 0.2.119 introduces a new file format version: 1.7.0. All; library versions before 0.2.119, for example 0.2.118, cannot r",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:8727,log,log,8727,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['log'],['log']
Testability,"put values as the mean of the; non-missing values.; The example above considers a model of the form. \[\mathrm{Prob}(\mathrm{is\_case}) =; \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt}; + \beta_2 \, \mathrm{age}; + \beta_3 \, \mathrm{is\_female} + \varepsilon),; \quad; \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid function, the genotype; \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for Het, and 2 for; HomVar, and the Boolean covariate \(\mathrm{is\_female}\) is coded as; for True (female) and 0 for False (male). The null model sets; \(\beta_1 = 0\).; The structure of the emitted row field depends on the test statistic as; shown in the tables below. Test; Field; Type; Value. Wald; beta; float64; fit effect coefficient,; \(\hat\beta_1\). Wald; standard_error; float64; estimated standard error,; \(\widehat{\mathrm{se}}\). Wald; z_stat; float64; Wald \(z\)-statistic, equal to; \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; p_value; float64; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; beta; float64; fit effect coefficient,; \(\hat\beta_1\). LRT, Firth; chi_sq_stat; float64; deviance statistic. LRT, Firth; p_value; float64; LRT / Firth p-value testing; \(\beta_1 = 0\). Score; chi_sq_stat; float64; score statistic. Score; p_value; float64; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for; each row using Newton iteration and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. Test; Field; Type; Value. Wald, LRT, Firth; fit.n_iterations; int32; number of iterations until; convergence, explosion, or; reaching the max (by default,; 25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; fit.converged; bool; True if iteration converged. Wald, LRT, Firth; f",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:9503,test,testing,9503,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['testing']
Testability,"r = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). test_fit = _poisson_fit(X, yvec, b, mu, score, fisher, max_iterations, tolerance); if test == 'lrt':; return ht.select(test_fit=test_fit, **lrt_test(X, null_fit, test_fit), **ht.pass_through).select_globals(; 'null_fit'; ); assert test == 'wald'; return ht.select(test_fit=test_fit, **wald_test(X, test_fit), **ht.pass_through).select_globals('null_fit'). def _poisson_fit(; X: NDArrayNumericExpression, # (N, K); y: NDArrayNumericExpression, # (N,); b: NDArrayNumericExpression, # (K,); mu: NDArrayNumericExpression, # (N,); score: NDArrayNumericExpression, # (K,); fisher: NDArrayNumericExpression, # (K, K); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Poisson(exp(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1; assert mu.ndim == 1; assert score.ndim == 1; assert fisher.ndim == 2. dtype = numerical_regression_fit_dtype; blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}). def fit(recur, iteration, b, mu, score, fisher):; def cont(exploded, delta_b, max_delta_b):; log_lkhd = y @ hl.log(mu) - mu.sum(). next_b = b + delta_b; next_mu = hl.exp(X @ next_b); next_score = X.T @ (y - next_mu); next_fisher = (next_mu * X.T) @ X. return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(; b=b,; score=score,; fisher=fisher,; mu=mu,; n_iterations=iteration,; log_lkhd=log_lkhd,; converged=True,; exploded=False,; ),; ); .when(; iteration == max_iterations,; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b, next_mu, next_score, next_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:68151,assert,assert,68151,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['assert'],['assert']
Testability,"r association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). As above but with at most 100 Newton iterations and a stricter-than-default tolerance of 1e-8:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female],; ... max_iterations=100,; ... tolerance=1e-8). Warning; -------; :func:`.logistic_regression_rows` considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which **all** response variables and covariates are defined. For each row, missing values of; `x` are mean-imputed over these columns. As in the example, the; intercept covariate ``1`` must be included **explicitly** if desired. Notes; -----; This method performs, for each row, a significance test of the input; variable in predicting a binary (case-control) response variable based; on the logistic regression model. The response variable type must either; be numeric (with all present values 0 or 1) or Boolean, in which case; true and false are coded as 1 and 0, respectively. Hail supports the",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:27321,test,test,27321,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"r association with response variables using linear regression. logistic_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a binary response variable using logistic regression. poisson_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a count response variable using Poisson regression. pca(entry_expr[, k, compute_loadings]); Run principal component analysis (PCA) on numeric columns derived from a matrix table. row_correlation(entry_expr[, block_size]); Computes the correlation matrix between row vectors. hail.methods.linear_mixed_model(y, x, z_t=None, k=None, p_path=None, overwrite=False, standardize=True, mean_impute=True)[source]; Initialize a linear mixed model from a matrix table. Warning; This functionality is no longer implemented/supported as of Hail 0.2.94. hail.methods.linear_mixed_regression_rows(entry_expr, model, pa_t_path=None, a_t_path=None, mean_impute=True, partition_size=None, pass_through=())[source]; For each row, test an input variable for association using a linear; mixed model. Warning; This functionality is no longer implemented/supported as of Hail 0.2.94. hail.methods.linear_regression_rows(y, x, covariates, block_size=16, pass_through=(), *, weights=None)[source]; For each row, test an input variable for association with; response variables using linear regression.; Examples; >>> result_ht = hl.linear_regression_rows(; ... y=dataset.pheno.height,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Warning; As in the example, the intercept covariate 1 must be; included explicitly if desired. Warning; If y is a single value or a list, linear_regression_rows(); considers the same set of columns (i.e., samples, points) for every response; variable and row, namely those columns for which all response variables; and covariates are defined.; If y is a list of lists, then each inner list is treated as ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:2060,test,test,2060,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['test']
Testability,"r of SNP alternate alleles.; n_insertion (int64) – Number of insertion alternate alleles.; n_deletion (int64) – Number of deletion alternate alleles.; n_singleton (int64) – Number of private alleles. Reference alleles are never counted as singletons, even if; every other allele at a site is non-reference.; n_transition (int64) – Number of transition (A-G, C-T) alternate alleles.; n_transversion (int64) – Number of transversion alternate alleles.; n_star (int64) – Number of star (upstream deletion) alleles.; r_ti_tv (float64) – Transition/Transversion ratio.; r_het_hom_var (float64) – Het/HomVar call ratio.; r_insertion_deletion (float64) – Insertion/Deletion allele ratio. Missing values NA may result from division by zero. Parameters:. mt (MatrixTable) – Dataset.; name (str) – Name for resulting field. Returns:; MatrixTable – Dataset with a new column-indexed field name. hail.methods._logistic_skat(group, weight, y, x, covariates, max_size=46340, null_max_iterations=25, null_tolerance=1e-06, accuracy=1e-06, iterations=10000)[source]; The logistic sequence kernel association test (SKAT).; Logistic SKAT tests if the phenotype, y, is significantly associated with the genotype,; x. For \(N\) samples, in a group of \(M\) variants, with \(K\) covariates, the; model is given by:. \[\begin{align*}; X &: R^{N \times K} \\; G &: \{0, 1, 2\}^{N \times M} \\; \\; Y &\sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_0 X + \beta_1 G)); \end{align*}\]; The usual null hypothesis is \(\beta_1 = 0\). SKAT tests for an association, but does not; provide an effect size or other information about the association.; Wu et al. argue that, under the null hypothesis, a particular value, \(Q\), is distributed; according to a generalized chi-squared distribution with parameters determined by the genotypes,; weights, and residual phenotypes. The SKAT p-value is the probability of drawing even larger; values of \(Q\). If \(\widehat{\beta_\textrm{null}}\) is the best-fit beta under the; null mode",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:68036,log,logistic,68036,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"r some of Hail’s built-in; references:; GRCh37 to GRCh38; gs://hail-common/references/grch37_to_grch38.over.chain.gz; GRCh38 to GRCh37; gs://hail-common/references/grch38_to_grch37.over.chain.gz; Public download links are available; here. Parameters:. chain_file (str) – Path to chain file. Can be compressed (GZIP) or uncompressed.; dest_reference_genome (str or ReferenceGenome) – Reference genome to convert to. add_sequence(fasta_file, index_file=None)[source]; Load the reference sequence from a FASTA file.; Examples; Access the GRCh37 reference genome using get_reference():; >>> rg = hl.get_reference('GRCh37') . Add a sequence file:; >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz',; ... 'gs://hail-common/references/human_g1k_v37.fasta.fai') . Add a sequence file with the default index location:; >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz') . Notes; This method can only be run once per reference genome. Use; has_sequence() to test whether a sequence is loaded.; FASTA and index files are hosted on google cloud for some of Hail’s built-in; references:; GRCh37. FASTA file: gs://hail-common/references/human_g1k_v37.fasta.gz; Index file: gs://hail-common/references/human_g1k_v37.fasta.fai. GRCh38. FASTA file: gs://hail-common/references/Homo_sapiens_assembly38.fasta.gz; Index file: gs://hail-common/references/Homo_sapiens_assembly38.fasta.fai. Public download links are available; here. Parameters:. fasta_file (str) – Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file (None or str) – Path to FASTA index file. Must be uncompressed. If None, replace; the fasta_file’s extension with fai. contig_length(contig)[source]; Contig length. Parameters:; contig (str) – Contig name. Returns:; int – Length of contig. property contigs; Contig names. Returns:; list of str. classmethod from_fasta_file(name, fasta_file, index_file, x_contigs=[], y_contigs=[], mt_contigs=[], par=[])[source]; Create reference ge",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/genetics/hail.genetics.ReferenceGenome.html:5406,test,test,5406,docs/0.2/genetics/hail.genetics.ReferenceGenome.html,https://hail.is,https://hail.is/docs/0.2/genetics/hail.genetics.ReferenceGenome.html,1,['test'],['test']
Testability,"r why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alone. - s2 : :obj:`.tfloat64`, the variance of the residuals, :math:`\sigma^2` in the paper. - null_fit:. - b : :obj:`.tndarray` vector of coefficients. - score : :obj:`.tndarray` vector of score statistics. - fisher : :obj:`.tndarray` matrix of fisher statistics. - mu : :obj:`.tndarray` the expected value under the null model. - n_iterations : :obj:`.tint32` the number of iterations before termination. - log_lkhd : :obj:`.tfloat64` the log-likelihood of the final iteration. - converged : :obj:`.tbool` True if the null model converged. - exploded : :obj:`.tbool` True if the null model failed to converge due to numerical; explosion. """"""; mt = matrix_table_source('skat/x', x); k = len(covariates); if k == 0:; raise ValueError('_logistic_skat: at least one covariate is required.'); _warn_if_no_intercept('_logistic_skat', covariates); mt = mt._select_all(; row_exprs=dict(group=group, weight=weight), col_exprs=dict(y=y, covariates=covariates), entry_exprs=dict(x=x); ); mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])); if mt.y.dtype != hl.tbool:; mt = mt.annotate_cols(; y=(; hl.case(); .when(hl.any(mt.y == 0, mt.y == 1), hl.bool(mt.y)); .or_error(; hl.format(; f'hl._logistic_skat: phenotypes must either be True, False, 0, or 1, found: %s of type {mt.y.dtype}',; mt.y,; ); ); ); ); yvec, covmat, n = mt.aggregate_cols(; (hl.agg.collect(hl.float(mt.y)), hl.agg.collect(mt.covariates.map(",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:97190,log,log-likelihood,97190,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['log-likelihood']
Testability,"r(float(e))); data['y'] = data['y'].apply(lambda e: str(float(e))). mapper: ColorMapper; if log:; mapper = LogColorMapper(palette=colors, low=data.c.min(), high=data.c.max()); else:; mapper = LinearColorMapper(palette=colors, low=data.c.min(), high=data.c.max()). x_axis = sorted(set(data.x), key=lambda z: float(z)); y_axis = sorted(set(data.y), key=lambda z: float(z)); p = figure(; title=title,; x_range=x_axis,; y_range=y_axis,; x_axis_location=""above"",; width=width,; height=height,; tools=""hover,save,pan,box_zoom,reset,wheel_zoom"",; toolbar_location='below',; ). p.grid.grid_line_color = None; p.axis.axis_line_color = None; p.axis.major_tick_line_color = None; p.axis.major_label_standoff = 0; import math. p.xaxis.major_label_orientation = math.pi / 3. p.rect(; x='x', y='y', width=1, height=1, source=data, fill_color={'field': 'c', 'transform': mapper}, line_color=None; ). color_bar = ColorBar(; color_mapper=mapper,; ticker=LogTicker(desired_num_ticks=len(colors)) if log else BasicTicker(desired_num_ticks=len(colors)),; label_standoff=12 if log else 6,; border_line_color=None,; location=(0, 0),; ); p.add_layout(color_bar, 'right'). hovertool = p.select_one(HoverTool); assert hovertool is not None; hovertool.tooltips = [; ('x', '@x'),; (; 'y',; '@y',; ),; ('count', '@c'),; ]. return p. @typecheck(; x=expr_numeric,; y=expr_numeric,; bins=oneof(int, sequenceof(int)),; range=nullable(sized_tupleof(nullable(sized_tupleof(numeric, numeric)), nullable(sized_tupleof(numeric, numeric)))),; ); def _generate_hist2d_data(x, y, bins, range):; source = x._indices.source; y_source = y._indices.source; if source is None or y_source is None:; raise ValueError(""histogram_2d expects two expressions of 'Table', found scalar expression""); if isinstance(source, hail.MatrixTable):; raise ValueError(""histogram_2d requires source to be Table, not MatrixTable""); if source != y_source:; raise ValueError(f""histogram_2d expects two expressions from the same 'Table', found {source} and {y_source}""",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:19963,log,log,19963,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,5,"['Log', 'log']","['LogTicker', 'log']"
Testability,"r; Label of data on the x-axis.; title : str; Title of the histogram.; normalize: bool; Whether or not the cumulative data should be normalized.; log: bool; Whether or not the y-axis should be of type log. Returns; -------; :class:`bokeh.plotting.figure`; """"""; if isinstance(data, Expression):; if data._indices.source is not None:; agg_f = data._aggregation_method(); if range is not None:; start = range[0]; end = range[1]; else:; start, end = agg_f((aggregators.min(data), aggregators.max(data))); data = agg_f(aggregators.hist(data, start, end, bins)); else:; raise ValueError('Invalid input'). if legend is None:; legend = """". cumulative_data = np.cumsum(data.bin_freq) + data.n_smaller; np.append(cumulative_data, [cumulative_data[-1] + data.n_larger]); num_data_points = max(cumulative_data). if normalize:; cumulative_data = cumulative_data / num_data_points; if title is not None:; title = f'{title} ({num_data_points:,} data points)'; if log:; p = figure(; title=title,; x_axis_label=legend,; y_axis_label='Frequency',; background_fill_color='#EEEEEE',; y_axis_type='log',; ); else:; p = figure(title=title, x_axis_label=legend, y_axis_label='Frequency', background_fill_color='#EEEEEE'); p.line(data.bin_edges[:-1], cumulative_data, line_color='#036564', line_width=3); return p. @typecheck(p=figure, font_size=str); def set_font_size(p, font_size: str = '12pt'):; """"""Set most of the font sizes in a bokeh figure. Parameters; ----------; p : :class:`bokeh.plotting.figure`; Input figure.; font_size : str; String of font size in points (e.g. '12pt'). Returns; -------; :class:`bokeh.plotting.figure`; """"""; p.legend.label_text_font_size = font_size; p.xaxis.axis_label_text_font_size = font_size; p.yaxis.axis_label_text_font_size = font_size; p.xaxis.major_label_text_font_size = font_size; p.yaxis.major_label_text_font_size = font_size; if hasattr(p.title, 'text_font_size'):; p.title.text_font_size = font_size; if hasattr(p.xaxis, 'group_text_font_size'):; p.xaxis.group_text_font_size",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:15312,log,log,15312,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,4,['log'],['log']
Testability,"r; gnomad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; Schema (0.2, GRCh37). panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_variant_indices_AFR. View page source. panukb_ld_variant_indices_AFR. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; 'n_samples': int32; 'pop': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'idx': int64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AFR.html:8796,Log,Log,8796,docs/0.2/datasets/schemas/panukb_ld_variant_indices_AFR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AFR.html,1,['Log'],['Log']
Testability,"r; gnomad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; Schema (0.2, GRCh37). panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_variant_indices_AMR. View page source. panukb_ld_variant_indices_AMR. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; 'n_samples': int32; 'pop': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'idx': int64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AMR.html:8796,Log,Log,8796,docs/0.2/datasets/schemas/panukb_ld_variant_indices_AMR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AMR.html,1,['Log'],['Log']
Testability,"r; gnomad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; Schema (0.2, GRCh37). panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_variant_indices_CSA. View page source. panukb_ld_variant_indices_CSA. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; 'n_samples': int32; 'pop': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'idx': int64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_CSA.html:8796,Log,Log,8796,docs/0.2/datasets/schemas/panukb_ld_variant_indices_CSA.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_CSA.html,1,['Log'],['Log']
Testability,"r; gnomad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; Schema (0.2, GRCh37). panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_variant_indices_EAS. View page source. panukb_ld_variant_indices_EAS. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; 'n_samples': int32; 'pop': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'idx': int64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_EAS.html:8796,Log,Log,8796,docs/0.2/datasets/schemas/panukb_ld_variant_indices_EAS.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_EAS.html,1,['Log'],['Log']
Testability,"r; gnomad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; Schema (0.2, GRCh37). panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_variant_indices_EUR. View page source. panukb_ld_variant_indices_EUR. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; 'n_samples': int32; 'pop': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'idx': int64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_EUR.html:8796,Log,Log,8796,docs/0.2/datasets/schemas/panukb_ld_variant_indices_EUR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_EUR.html,1,['Log'],['Log']
Testability,"r; gnomad_ld_scores_asj; gnomad_ld_scores_eas; gnomad_ld_scores_est; gnomad_ld_scores_fin; gnomad_ld_scores_nfe; gnomad_ld_scores_nwe; gnomad_ld_scores_seu; gnomad_ld_variant_indices_afr; gnomad_ld_variant_indices_amr; gnomad_ld_variant_indices_asj; gnomad_ld_variant_indices_eas; gnomad_ld_variant_indices_est; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; Schema (0.2, GRCh37). panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; panukb_ld_variant_indices_MID. View page source. panukb_ld_variant_indices_MID. Versions: 0.2; Reference genome builds: GRCh37; Type: hail.Table. Schema (0.2, GRCh37); ----------------------------------------; Global fields:; 'n_samples': int32; 'pop': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'idx': int64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_MID.html:8796,Log,Log,8796,docs/0.2/datasets/schemas/panukb_ld_variant_indices_MID.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_MID.html,1,['Log'],['Log']
Testability,"r=nullable(str),; default_reference=enumeration(*BUILTIN_REFERENCES),; global_seed=nullable(int),; skip_logging_configuration=bool,; jvm_heap_size=nullable(str),; _optimizer_iterations=nullable(int),; gcs_requester_pays_configuration=nullable(oneof(str, sized_tupleof(str, sequenceof(str)))),; ); def init_local(; log=None,; quiet=False,; append=False,; branching_factor=50,; tmpdir=None,; default_reference='GRCh37',; global_seed=None,; skip_logging_configuration=False,; jvm_heap_size=None,; _optimizer_iterations=None,; gcs_requester_pays_configuration: Optional[GCSRequesterPaysConfiguration] = None,; ):; from hail.backend.local_backend import LocalBackend; from hail.backend.py4j_backend import connect_logger. log = _get_log(log); tmpdir = _get_tmpdir(tmpdir); optimizer_iterations = get_env_or_default(_optimizer_iterations, 'HAIL_OPTIMIZER_ITERATIONS', 3). jvm_heap_size = get_env_or_default(jvm_heap_size, 'HAIL_LOCAL_BACKEND_HEAP_SIZE', None); backend = LocalBackend(; tmpdir,; log,; quiet,; append,; branching_factor,; skip_logging_configuration,; optimizer_iterations,; jvm_heap_size,; gcs_requester_pays_configuration,; ). if not backend.fs.exists(tmpdir):; backend.fs.mkdir(tmpdir). HailContext.create(log, quiet, append, tmpdir, tmpdir, default_reference, global_seed, backend); if not quiet:; connect_logger(backend._utils_package_object, 'localhost', 12888). [docs]def version() -> str:; """"""Get the installed Hail version. Returns; -------; str; """"""; if hail.__version__ is None:; hail.__version__ = __resource_str('hail_version').strip(). return hail.__version__. def revision() -> str:; """"""Get the installed Hail git revision. Returns; -------; str; """"""; if hail.__revision__ is None:; hail.__revision__ = __resource_str('hail_revision').strip(). return hail.__revision__. def _hail_cite_url():; v = version(); [tag, sha_prefix] = v.split(""-""); if not local_jar_information().development_mode:; # pip installed; return f""https://github.com/hail-is/hail/releases/tag/{tag}""; return ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:19845,log,log,19845,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['log'],['log']
Testability,"r=oneof(expr_ndarray(), list), f=func_spec(2, expr_any)); def map2(self, other, f):; """"""Applies an element-wise binary operation on two NDArrays. Parameters; ----------; other : class:`.NDArrayExpression`, :class:`.ArrayExpression`, numpy NDarray,; or nested python list/tuples. Both NDArrays must be the same shape or; broadcastable into common shape.; f : function ((arg1, arg2)-> :class:`.Expression`); Function to be applied to each element of both NDArrays. Returns; -------; :class:`.NDArrayExpression`.; Element-wise result of applying `f` to each index in NDArrays.; """""". if isinstance(other, (list, np.ndarray)):; other = hl.nd.array(other). self_broadcast, other_broadcast = self._broadcast_to_same_ndim(other). element_type1 = self_broadcast._type.element_type; element_type2 = other_broadcast._type.element_type; ndarray_map2 = self_broadcast._ir_lambda_method2(; other_broadcast, ir.NDArrayMap2, f, element_type1, element_type2, lambda t: tndarray(t, self_broadcast.ndim); ). assert isinstance(self._type, tndarray); return ndarray_map2. def _broadcast_to_same_ndim(self, other):; if isinstance(other, NDArrayExpression):; if self.ndim < other.ndim:; return self._broadcast(other.ndim), other; elif self.ndim > other.ndim:; return self, other._broadcast(self.ndim). return self, other. def _broadcast(self, n_output_dims):; assert self.ndim < n_output_dims. # Right-align existing dimensions and start prepending new ones; # to the left: e.g. [0, 1] -> [3, 2, 0, 1]; # Based off numpy broadcasting with the assumption that everything; # can be thought to have an infinite number of 1-length dimensions; # prepended; old_dims = range(self.ndim); new_dims = range(self.ndim, n_output_dims); idx_mapping = list(reversed(new_dims)) + list(old_dims). return construct_expr(; ir.NDArrayReindex(self._ir, idx_mapping),; tndarray(self._type.element_type, n_output_dims),; self._indices,; self._aggregations,; ). [docs]class NDArrayNumericExpression(NDArrayExpression):; """"""Expression of type :cl",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:102748,assert,assert,102748,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['assert'],['assert']
Testability,"r=strlike,; test=strlike,; y=strlike,; covariates=listof(strlike)); def logreg_burden(self, key_name, variant_keys, single_key, agg_expr, test, y, covariates=[]):; r""""""Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. .. include:: requireTGenotype.rst. **Examples**. Run a gene burden test using the logistic Wald test on the maximum genotype per gene. Here ``va.genes`` is; a variant annotation of type Set[String] giving the set of genes containing the variant; (see **Extended example** in :py:meth:`.linreg_burden` for a deeper dive in the context of linear regression):. >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.genes',; ... single_key=False,; ... agg_expr='gs.map(g => g.gt).max()',; ... test='wald',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). Run a gene burden test using the logistic score test on the weighted sum of genotypes per gene.; Here ``va.gene`` is a variant annotation of type String giving a single gene per variant (or no gene if; missing), and ``va.weight`` is a numeric variant annotation:. >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.gene',; ... single_key=True,; ... agg_expr='gs.map(g => va.weight * g.gt).sum()',; ... test='score',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). To use a weighted sum of genotypes with missing genotypes mean-imputed rather than ignored, set; ``agg_expr='gs.map(g => va.weight * orElse(g.gt.toDouble, 2 * va.qc.AF)).sum()'`` where ``va.qc.AF``; is the allele frequency over those samples that have no missing phenotype or covariates. .. caution::. With ``single_key=False``, ``variant_keys`` expects a variant annotation of Set or Array type, in order to; allow each variant to have zero, one, or more keys (for example, the",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:149965,test,test,149965,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,3,"['log', 'test']","['logistic', 'test']"
Testability,"r>) – The old alleles, before filtering and; computing the minimal representation.; old_to_new (array<int32>) – An array that maps old allele index to; new allele index. Its length is the same as old_alleles. Alleles that; are filtered are missing.; new_to_old (array<int32>) – An array that maps new allele index to; the old allele index. Its length is the same as the modified alleles; field. Downcode algorithm; We will illustrate the behavior on the example genotype below; when filtering the first alternate allele (allele 1) at a site; with 1 reference allele and 2 alternate alleles.; GT: 1/2; GQ: 10; AD: 0,50,35. 0 | 1000; 1 | 1000 10; 2 | 1000 0 20; +-----------------; 0 1 2. The downcode algorithm recodes occurances of filtered alleles; to occurances of the reference allele (e.g. 1 -> 0 in our; example). So the depths of filtered alleles in the AD field; are added to the depth of the reference allele. Where; downcoding filtered alleles merges distinct genotypes, the; minimum PL is used (since PL is on a log scale, this roughly; corresponds to adding probabilities). The PLs are then; re-normalized (shifted) so that the most likely genotype has a; PL of 0, and GT is set to this genotype. If an allele is; filtered, this algorithm acts similarly to; split_multi_hts().; The downcode algorithm would produce the following:; GT: 0/1; GQ: 10; AD: 35,50. 0 | 20; 1 | 0 10; +-----------; 0 1. In summary:. GT: Downcode filtered alleles to reference.; AD: Columns of filtered alleles are eliminated and their; values are added to the reference column, e.g., filtering; alleles 1 and 2 transforms 25,5,10,20 to 40,20.; DP: No change.; PL: Downcode filtered alleles to reference, combine PLs; using minimum for each overloaded genotype, and shift so; the overall minimum PL is 0.; GQ: The second-lowest PL (after shifting). Subset algorithm; We will illustrate the behavior on the example genotype below; when filtering the first alternate allele (allele 1) at a site; with 1 reference alle",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:25877,log,log,25877,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['log'],['log']
Testability,"rMixedModel,; pa_t_path=nullable(str),; a_t_path=nullable(str),; mean_impute=bool,; partition_size=nullable(int),; pass_through=sequenceof(oneof(str, Expression)),; ); def linear_mixed_regression_rows(; entry_expr, model, pa_t_path=None, a_t_path=None, mean_impute=True, partition_size=None, pass_through=(); ):; """"""For each row, test an input variable for association using a linear; mixed model. .. warning::. This functionality is no longer implemented/supported as of Hail 0.2.94.; """"""; raise NotImplementedError(""linear_mixed_model is no longer implemented/supported as of Hail 0.2.94""). @typecheck(; group=expr_any,; weight=expr_float64,; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; max_size=int,; accuracy=numeric,; iterations=int,; ); def _linear_skat(; group, weight, y, x, covariates, max_size: int = 46340, accuracy: float = 1e-6, iterations: int = 10000; ):; r""""""The linear sequence kernel association test (SKAT). Linear SKAT tests if the phenotype, `y`, is significantly associated with the genotype, `x`. For; :math:`N` samples, in a group of :math:`M` variants, with :math:`K` covariates, the model is; given by:. .. math::. \begin{align*}; X &: R^{N \times K} \quad\quad \textrm{covariates} \\; G &: \{0, 1, 2\}^{N \times M} \textrm{genotypes} \\; \\; \varepsilon &\sim N(0, \sigma^2) \\; y &= \beta_0 X + \beta_1 G + \varepsilon; \end{align*}. The usual null hypothesis is :math:`\beta_1 = 0`. SKAT tests for an association, but does not; provide an effect size or other information about the association. Wu et al. argue that, under the null hypothesis, a particular value, :math:`Q`, is distributed; according to a generalized chi-squared distribution with parameters determined by the genotypes,; weights, and residual phenotypes. The SKAT p-value is the probability of drawing even larger; values of :math:`Q`. :math:`Q` is defined by Wu et al. as:. .. math::. \begin{align*}; r &= y - \widehat{\beta_\textrm{null}} X \\; W_{ii} &= w_i \\; \\; Q &= r^",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:71684,test,tests,71684,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['tests']
Testability,"r] = None,; token: Optional[str] = None,; gcs_requester_pays_configuration: Optional[GCSRequesterPaysConfiguration] = None,; regions: Optional[List[str]] = None,; gcs_bucket_allow_list: Optional[List[str]] = None,; ):; from hail.backend.service_backend import ServiceBackend. # FIXME: pass local_tmpdir and use on worker and driver; backend = await ServiceBackend.create(; billing_project=billing_project,; remote_tmpdir=remote_tmpdir,; disable_progress_bar=disable_progress_bar,; driver_cores=driver_cores,; driver_memory=driver_memory,; worker_cores=worker_cores,; worker_memory=worker_memory,; name_prefix=name_prefix,; credentials_token=token,; regions=regions,; gcs_requester_pays_configuration=gcs_requester_pays_configuration,; gcs_bucket_allow_list=gcs_bucket_allow_list,; ). log = _get_log(log); if tmpdir is None:; tmpdir = backend.remote_tmpdir + 'tmp/hail/' + secret_alnum_string(); local_tmpdir = _get_local_tmpdir(local_tmpdir). HailContext.create(log, quiet, append, tmpdir, local_tmpdir, default_reference, global_seed, backend). @typecheck(; log=nullable(str),; quiet=bool,; append=bool,; branching_factor=int,; tmpdir=nullable(str),; default_reference=enumeration(*BUILTIN_REFERENCES),; global_seed=nullable(int),; skip_logging_configuration=bool,; jvm_heap_size=nullable(str),; _optimizer_iterations=nullable(int),; gcs_requester_pays_configuration=nullable(oneof(str, sized_tupleof(str, sequenceof(str)))),; ); def init_local(; log=None,; quiet=False,; append=False,; branching_factor=50,; tmpdir=None,; default_reference='GRCh37',; global_seed=None,; skip_logging_configuration=False,; jvm_heap_size=None,; _optimizer_iterations=None,; gcs_requester_pays_configuration: Optional[GCSRequesterPaysConfiguration] = None,; ):; from hail.backend.local_backend import LocalBackend; from hail.backend.py4j_backend import connect_logger. log = _get_log(log); tmpdir = _get_tmpdir(tmpdir); optimizer_iterations = get_env_or_default(_optimizer_iterations, 'HAIL_OPTIMIZER_ITERATIONS', 3). ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:18684,log,log,18684,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['log'],['log']
Testability,"raction; Double; specified value of dropped_variance_fraction. global.lmmreg.evals; Array[Double]; all eigenvalues of the kinship matrix in descending order. global.lmmreg.fit.seH2; Double; standard error of \(\hat{h}^2\) under asymptotic normal approximation. global.lmmreg.fit.normLkhdH2; Array[Double]; likelihood function of \(h^2\) normalized on the discrete grid 0.01, 0.02, ..., 0.99. Index i is the likelihood for percentage i. global.lmmreg.fit.maxLogLkhd; Double; (restricted) maximum log likelihood corresponding to \(\hat{\delta}\). global.lmmreg.fit.logDeltaGrid; Array[Double]; values of \(\mathrm{ln}(\delta)\) used in the grid search. global.lmmreg.fit.logLkhdVals; Array[Double]; (restricted) log likelihood of \(y\) given \(X\) and \(\mathrm{ln}(\delta)\) at the (RE)ML fit of \(\beta\) and \(\sigma_g^2\). These global annotations are also added to hail.log, with the ranked evals and \(\delta\) grid with values in .tsv tabular form. Use grep 'lmmreg:' hail.log to find the lines just above each table.; If Step 5 is performed, lmmreg() also adds four linear regression variant annotations. Annotation; Type; Value. va.lmmreg.beta; Double; fit genotype coefficient, \(\hat\beta_0\). va.lmmreg.sigmaG2; Double; fit coefficient of genetic variance component, \(\hat{\sigma}_g^2\). va.lmmreg.chi2; Double; \(\chi^2\) statistic of the likelihood ratio test. va.lmmreg.pval; Double; \(p\)-value. Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; The simplest way to export all resulting annotations is:; >>> lmm_vds.export_variants('output/lmmreg.tsv.bgz', 'variant = v, va.lmmreg.*'); >>> lmmreg_results = lmm_vds.globals['lmmreg']. By default, genotypes values are given by hard call genotypes (g.gt).; If use_dosages=True, then genotype values for per-variant association are defined by the dosage; \(\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})\). For Phred-scaled values,; \(\mathrm{P}(\",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:95038,log,log,95038,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['log']
Testability,"random_forest, df_x_input, df_y_input, window); tsv_result = j.call(as_tsv, result); tsv_result = tsv_result.as_str(). b.write_output(tsv_result, checkpoint); results[i] = tsv_result. Now we’ve only run the jobs in groups of 10 for jobs that have no; existing checkpoint file. The results will be concatenated in the correct; order. Synopsis; We have presented three different ways with increasing complexity to write; a pipeline that runs a random forest for various windows in the genome. The; complete code is provided here for your reference. run_rf_simple.py; from typing import Tuple. import pandas as pd; from sklearn.ensemble import RandomForestRegressor. import hailtop.batch as hb; import hailtop.fs as hfs. def random_forest(df_x_path: str, df_y_path: str, window_name: str, cores: int = 1) -> Tuple[str, float, float]:; # read in data; df_x = pd.read_table(df_x_path, header=0, index_col=0); df_y = pd.read_table(df_y_path, header=0, index_col=0). # split training and testing data for the current window; x_train = df_x[df_x.index != window_name]; x_test = df_x[df_x.index == window_name]. y_train = df_y[df_y.index != window_name]; y_test = df_y[df_y.index == window_name]. # run random forest; max_features = 3 / 4; rf = RandomForestRegressor(n_estimators=100, n_jobs=cores, max_features=max_features, oob_score=True, verbose=False). rf.fit(x_train, y_train). # apply the trained random forest on testing data; y_pred = rf.predict(x_test). # store obs and pred values for this window; obs = y_test[""oe""].to_list()[0]; pred = y_pred[0]. return (window_name, obs, pred). def as_tsv(input: Tuple[str, float, float]) -> str:; return '\t'.join(str(i) for i in input). def main(df_x_path, df_y_path, output_path, python_image):; backend = hb.ServiceBackend(); b = hb.Batch(name='rf-loo', default_python_image=python_image). with hfs.open(df_y_path) as f:; local_df_y = pd.read_table(f, header=0, index_col=0). df_x_input = b.read_input(df_x_path); df_y_input = b.read_input(df_y_path). resu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/cookbook/random_forest.html:12022,test,testing,12022,docs/batch/cookbook/random_forest.html,https://hail.is,https://hail.is/docs/batch/cookbook/random_forest.html,2,['test'],['testing']
Testability,"rdinate of; :math:`\beta` changes by less than :math:`10^{-6}`. For Wald and LRT,; up to 25 iterations are attempted; in testing we find 4 or 5 iterations; nearly always suffice. Convergence may also fail due to explosion,; which refers to low-level numerical linear algebra exceptions caused by; manipulating ill-conditioned matrices. Explosion may result from (nearly); linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-val",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:52684,test,testing,52684,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['testing']
Testability,"re are no records to aggregate, the result is ``False``. Missing records are not considered. If every record is missing,; the result is also ``False``. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test. Returns; -------; :class:`.BooleanExpression`; """"""; return count_where(condition) > 0. [docs]@typecheck(condition=expr_bool); def all(condition) -> BooleanExpression:; """"""Returns ``True`` if `condition` is ``True`` for every record. Examples; --------. >>> (table1.group_by(table1.SEX); ... .aggregate(all_under_70 = hl.agg.all(table1.HT < 70)); ... .show()); +-----+--------------+; | SEX | all_under_70 |; +-----+--------------+; | str | bool |; +-----+--------------+; | ""F"" | False |; | ""M"" | False |; +-----+--------------+. Notes; -----; If there are no records to aggregate, the result is ``True``. Missing records are not considered. If every record is missing,; the result is also ``True``. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test. Returns; -------; :class:`.BooleanExpression`; """"""; return count_where(~condition) == 0. [docs]@typecheck(expr=expr_any, weight=nullable(expr_numeric)); def counter(expr, *, weight=None) -> DictExpression:; """"""Count the occurrences of each unique record and return a dictionary. Examples; --------; Count the number of individuals for each unique `SEX` value:. >>> table1.aggregate(hl.agg.counter(table1.SEX)); {'F': 2, 'M': 2}; <BLANKLINE>. Compute the total height for each unique `SEX` value:. >>> table1.aggregate(hl.agg.counter(table1.SEX, weight=table1.HT)); {'F': 130, 'M': 137}; <BLANKLINE>. Note that when counting a set-typed field, the values become :class:`.frozenset` s because; Python does not permit the keys of a dictionary to be mutable:. >>> table1.aggregate(hl.agg.counter(hl.set({table1.SEX}), weight=table1.HT)); {frozenset({'F'}): 130, frozenset({'M'}): 137}; <BLANKLINE>. Notes; -----; If you need a more complex grouped aggregation than :func:`counter`; su",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html:20156,test,test,20156,docs/0.2/_modules/hail/expr/aggregators/aggregators.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html,2,['test'],['test']
Testability,"re coded as 1 and 0, respectively. Hail supports the Wald test ('wald'), likelihood ratio test ('lrt'), Rao score test ('score'),; and Firth test ('firth') as the ``test`` parameter. Conceptually, the method proceeds as follows:. 1) Filter to the set of samples for which all phenotype and covariates are defined. 2) For each key and sample, aggregate genotypes across variants with that key to produce a numeric score.; ``agg_expr`` must be of numeric type and has the following symbols are in scope:. - ``s`` (*Sample*): sample; - ``sa``: sample annotations; - ``global``: global annotations; - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``. Note that ``v``, ``va``, and ``g`` are accessible through; `Aggregable methods <https://hail.is/hail/types.html#aggregable>`_ on ``gs``. The resulting **sample key table** has key column ``key_name`` and a numeric column of scores for each sample; named by the sample ID. 3) For each key, fit the logistic regression model using the supplied phenotype, covariates, and test.; The model and tests are those of :py:meth:`.logreg` with sample genotype ``gt`` replaced by the; score in the sample key table. For each key, missing scores are mean-imputed across all samples. The resulting **logistic regression key table** has key column of type String given by the ``key_name``; parameter and additional columns corresponding to the fields of the ``va.logreg`` schema given for ``test``; in :py:meth:`.logreg`. :py:meth:`.logreg_burden` returns both the logistic regression key table and the sample key table. :param str key_name: Name to assign to key column of returned key tables. :param str variant_keys: Variant annotation path for the TArray or TSet of keys associated to each variant. :param bool single_key: if true, ``variant_keys`` is interpreted as a single (or missing) key per variant,; rather than as a collection of keys. :param str agg_expr: Sample aggregation expression (per key). :param str test: Statistical",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:152741,log,logistic,152741,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"reaching the max (25 for; Wald, LRT; 100 for Firth); Wald, LRT, Firth `fit.converged` bool ``True`` if iteration converged; Wald, LRT, Firth `fit.exploded` bool ``True`` if iteration exploded; ================ =================== ======= ===============================. We consider iteration to have converged when every coordinate of; :math:`\beta` changes by less than :math:`10^{-6}`. For Wald and LRT,; up to 25 iterations are attempted; in testing we find 4 or 5 iterations; nearly always suffice. Convergence may also fail due to explosion,; which refers to low-level numerical linear algebra exceptions caused by; manipulating ill-conditioned matrices. Explosion may result from (nearly); linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression model",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:52415,test,testing,52415,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['testing']
Testability,"red or Fisher's exact test of independence on a 2x2; contingency table. Examples; --------. >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=22)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=23)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967). Notes; -----; If all cell counts are at least `min_cell_count`, the chi-squared test is; used. Otherwise, Fisher's exact test is used. Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4.; min_cell_count : int or :class:`.Expression` of type :py:data:`.tint32`; Minimum count in every cell to use the chi-squared test. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""contingency_table_test"", ret_type, c1, c2, c3, c4, min_cell_count). # We use 64-bit integers.; # It is relatively easy to encounter an integer overflow bug with 32-bit integers.; [docs]@typecheck(a=expr_array(expr_int64), b=expr_array(expr_int64), c=expr_array(expr_int64), d=expr_array(expr_int64)); def cochran_mantel_haenszel_test(; a: Union[tarray, list], b: Union[tarray, list], c: Union[tarray, list], d: Union[tarray, list]; ) -> StructExpression:; """"""Perform the Cochran-Mantel-Haenszel test for association. Examples; --------; >>> a = [56, 61, 73, 71]; >>> b = [69, 257, 65, 48]; >>> c = [40, 57, 71, 55]; >>> d = [77, 301, 79, 48]; >>> hl.eval(hl.cochran_mantel_haenszel_test(a, b, c, d)); Struct(test_statis",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:21461,test,test,21461,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"reduces bias from small counts and resolves the issue of separation by penalizing maximum likelihood estimation by the `Jeffrey's invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton method is linear rather than quadratic. For Firth, 100 iterations are attempted for the null model and, if that is successful, for the full model as well. In testing we find 20 iterations nearly always suffices. If the null model fails to converge, then the ``sa.lmmreg.fit`` annotations reflect the null model; otherwise, they reflect the full model. See `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__ for an empirical comparison of the logistic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert's notes `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__. Firth introduced his approach in `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/GibbsFieldEst/BiasReductionMLE.pdf>`__. Heinze and Schemper further analyze Firth's approach in `A solution to the problem of separation in logistic regression, 2002 <https://cemsiis.meduniwien.ac.at/fileadmin/msi_akim/CeMSIIS/KB/volltexte/Heinze_Schemper_2002_Statistics_in_Medicine.pdf>`__. Those variants that don't vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations. Phenotype and covariate sample annotations may also be specified using `programmatic expressions <exprlang.html>`__ without identifiers, such as:. .. code-block:: text. if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular,",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:146662,test,tests,146662,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['tests']
Testability,"reference_genome. if hover_fields is None:; hover_fields = {}. hover_fields['locus'] = hail.str(locus). pvals = -hail.log10(pvals). source_pd = _collect_scatter_plot_data(; ('_global_locus', locus.global_position()),; ('_pval', pvals),; fields=hover_fields,; n_divisions=_downsampling_factor('manhattan', n_divisions, collect_all),; ); source_pd['p_value'] = [10 ** (-p) for p in source_pd['_pval']]; source_pd['_contig'] = [locus.split("":"")[0] for locus in source_pd['locus']]. observed_contigs = [contig for contig in ref.contigs.copy() if contig in set(source_pd['_contig'])]. contig_ticks = [ref._contig_global_position(contig) + ref.contig_length(contig) // 2 for contig in observed_contigs]; color_mapper = CategoricalColorMapper(factors=ref.contigs, palette=palette[:2] * int((len(ref.contigs) + 1) / 2)). p = figure(title=title, x_axis_label='Chromosome', y_axis_label='P-value (-log10 scale)', width=1000); p, _, legend, _, _, _ = _get_scatter_plot_elements(; p,; source_pd,; x_col='_global_locus',; y_col='_pval',; label_cols=['_contig'],; colors={'_contig': color_mapper},; size=size,; hover_cols={'locus', 'p_value'} | set(hover_fields),; ); assert legend is not None; legend.visible = False; p.xaxis.ticker = contig_ticks; p.xaxis.major_label_overrides = dict(zip(contig_ticks, [contig.replace(""chr"", """") for contig in observed_contigs])). if significance_line is not None:; p.renderers.append(; Span(; location=-math.log10(significance_line),; dimension='width',; line_color='red',; line_dash='dashed',; line_width=1.5,; ); ). return p. [docs]@typecheck(; entry_field=expr_any,; row_field=nullable(oneof(expr_numeric, expr_locus())),; column_field=nullable(expr_str),; window=nullable(int),; plot_width=int,; plot_height=int,; ); def visualize_missingness(; entry_field, row_field=None, column_field=None, window=6000000, plot_width=1800, plot_height=900; ) -> figure:; """"""Visualize missingness in a MatrixTable. Inspired by `naniar <https://cran.r-project.org/web/packages/naniar/index",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:54042,assert,assert,54042,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['assert'],['assert']
Testability,"remove; them. Examples; Compute TDT association statistics and show the first two results:; >>> pedigree = hl.Pedigree.read('data/tdt_trios.fam'); >>> tdt_table = hl.transmission_disequilibrium_test(tdt_dataset, pedigree); >>> tdt_table.show(2) ; +---------------+------------+-------+-------+----------+----------+; | locus | alleles | t | u | chi_sq | p_value |; +---------------+------------+-------+-------+----------+----------+; | locus<GRCh37> | array<str> | int64 | int64 | float64 | float64 |; +---------------+------------+-------+-------+----------+----------+; | 1:246714629 | [""C"",""A""] | 0 | 4 | 4.00e+00 | 4.55e-02 |; | 2:167262169 | [""T"",""C""] | NA | NA | NA | NA |; +---------------+------------+-------+-------+----------+----------+. Export variants with p-values below 0.001:; >>> tdt_table = tdt_table.filter(tdt_table.p_value < 0.001); >>> tdt_table.export(f""output/tdt_results.tsv""). Notes; The; transmission disequilibrium test; compares the number of times the alternate allele is transmitted (t) versus; not transmitted (u) from a heterozgyous parent to an affected child. The null; hypothesis holds that each case is equally likely. The TDT statistic is given by. \[(t - u)^2 \over (t + u)\]; and asymptotically follows a chi-squared distribution with one degree of; freedom under the null hypothesis.; transmission_disequilibrium_test() only considers complete trios (two; parents and a proband with defined sex) and only returns results for the; autosome, as defined by in_autosome(), and; chromosome X. Transmissions and non-transmissions are counted only for the; configurations of genotypes and copy state in the table below, in order to; filter out Mendel errors and configurations where transmission is; guaranteed. The copy state of a locus with respect to a trio is defined as; follows:. Auto – in autosome or in PAR of X or female child; HemiX – in non-PAR of X and male child. Here PAR is the pseudoautosomal region; of X and Y defined by ReferenceGenome, which ma",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:94956,test,test,94956,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['test'],['test']
Testability,"rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association.; The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the Jeffrey’s; invariant prior. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the logreg.fit fields reflect the null model; otherwise,; they reflect the full model.; See; Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert’s notes; Statistical Theory.; Firth introduced his approach in; Bias reduction of maximum likelihood estimates, 1993.; Heinze and Schemper further analyze Firth’s approach in; A solution to the problem of separation in logistic regression, 2002.; Hail’s logistic regression tests correspond to the b.wald,; b.lrt, and b.score tests in EPACTS. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EP",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:13245,test,testing,13245,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['testing']
Testability,"ression. Returns; -------; :class:`.Expression` of type :py:data:`.tint64` or :py:data:`.tfloat64`; Product of records of `expr`.; """""". return _agg_func('Product', [expr], expr.dtype). [docs]@typecheck(predicate=expr_bool); def fraction(predicate) -> Float64Expression:; """"""Compute the fraction of records where `predicate` is ``True``. Examples; --------; Compute the fraction of rows where `SEX` is ""F"" and `HT` > 65:. >>> table1.aggregate(hl.agg.fraction((table1.SEX == 'F') & (table1.HT > 65))); 0.25. Notes; -----; Missing values for `predicate` are treated as ``False``. Parameters; ----------; predicate : :class:`.BooleanExpression`; Boolean predicate. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; Fraction of records where `predicate` is ``True``.; """"""; return hl.bind(; lambda n: hl.if_else(n == 0, hl.missing(hl.tfloat64), hl.float64(filter(predicate, count())) / n), count(); ). [docs]@typecheck(expr=expr_call, one_sided=expr_bool); def hardy_weinberg_test(expr, one_sided=False) -> StructExpression:; """"""Performs test of Hardy-Weinberg equilibrium. Examples; --------; Test each row of a dataset:. >>> dataset_result = dataset.annotate_rows(hwe = hl.agg.hardy_weinberg_test(dataset.GT)). Test each row on a sub-population:. >>> dataset_result = dataset.annotate_rows(; ... hwe_eas = hl.agg.filter(dataset.pop == 'EAS',; ... hl.agg.hardy_weinberg_test(dataset.GT))). Notes; -----; This method performs the test described in :func:`.functions.hardy_weinberg_test` based solely on; the counts of homozygous reference, heterozygous, and homozygous variant calls. The resulting struct expression has two fields:. - `het_freq_hwe` (:py:data:`.tfloat64`) - Expected frequency; of heterozygous calls under Hardy-Weinberg equilibrium. - `p_value` (:py:data:`.tfloat64`) - p-value from test of Hardy-Weinberg; equilibrium. By default, Hail computes the exact p-value with mid-p-value correction, i.e. the; probability of a less-likely outcome plus one-half the probability",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html:30899,test,test,30899,docs/0.2/_modules/hail/expr/aggregators/aggregators.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html,2,['test'],['test']
Testability,"rey’s; invariant prior. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the logreg.fit fields reflect the null model; otherwise,; they reflect the full model.; See; Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert’s notes; Statistical Theory.; Firth introduced his approach in; Bias reduction of maximum likelihood estimates, 1993.; Heinze and Schemper further analyze Firth’s approach in; A solution to the problem of separation in logistic regression, 2002.; Hail’s logistic regression tests correspond to the b.wald,; b.lrt, and b.score tests in EPACTS. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EPACTS results will currently only agree for variants with no; missing genotypes. Note; Use the pass_through parameter to include additional row fields from; matrix table underlying x. For example, to include an “rsid” field, set; pass_through=['rsid'] or pass_through=[mt.rsid]. Parameters:. test ({‘wald’, ‘lrt’, ‘score’, ‘firth’}) – Statistical test.; y (Float64Expression or list of Float64Expression) – One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a BooleanExpression will be implicitly converted to; a Float64Expression with this property.; x (Float64Expression) – Entry-indexed expression for",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:13969,log,logistic,13969,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['log'],['logistic']
Testability,"riable for association with a; binary response variable using logistic regression.; Examples; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). As above but with at most 100 Newton iterations and a stricter-than-default tolerance of 1e-8:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female],; ... max_iterations=100,; ... tolerance=1e-8). Warning; logistic_regression_rows() considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which all response variables and covariates are defined. For each row, missing values of; x are mean-imputed over these columns. As in the example, the; intercept covariate 1 must be included explicitly if desired. Notes; This method performs, for each row, a significance test of the input; variable in predicting a binary (case-control) response variable based; on the logistic regression model. The response variable type must either; be numeric (with all present values 0 or 1) or Boolean, in which case; true and false are coded as 1 and 0, respectively.; Hail supports the Wald test (‘wald’), likelihood rati",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:7290,test,test,7290,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['test']
Testability,"riables to Methods; Filtering; Add New Annotations; Computed From Existing Annotations; Variant Annotation Computed from a Genotype Aggregable (gs); Sample Annotation Computed from a Genotype Aggregable (gs); Global Annotation Computed from a Sample Aggregable (samples); Global Annotation Computed from a Variant Aggregable (variants). Tutorials; Expression Language; Python API; Annotation Database; Other Resources. Hail. Docs »; Overview. View page source. Overview¶; A typical workflow in Hail begins with importing genotype data from a standard file format such as VCF, PLINK Binary files, GEN, or BGEN files into Hail’s Variant Dataset format.; Next, samples and variants are annotated with additional meta-information such as phenotype for samples and functional consequence for variants.; Samples, variants, and genotypes are filtered from the dataset based on expressions constructed using Hail’s Domain-Specific Language.; Once the dataset has been cleaned, various analytic methods such as PCA and logistic regression are used to find genetic associations.; Lastly, data is exported to a variety of file formats. Variant Dataset (VDS)¶. Hail represents a genetic data set as a matrix where the rows are keyed by; Variant objects, the columns are keyed by samples, and each cell is a; Genotype object. Variant objects and Genotype objects each; have methods to access attributes such as chromosome name and genotype call.; Although this representation is similar to the VCF format, Hail uses a fast and; storage-efficient internal representation called a Variant Dataset (VDS).; In addition to information about Samples, Variants, and Genotypes, Hail stores meta-data as annotations that can be attached to each variant (variant annotations),; each sample (sample annotations), and global to the dataset (global annotations).; Annotations in Hail can be thought of as a hierarchical data structure with a specific schema that is typed (similar to the JSON format).; For example, given this",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/overview.html:1238,log,logistic,1238,docs/0.1/overview.html,https://hail.is,https://hail.is/docs/0.1/overview.html,1,['log'],['logistic']
Testability,"riant annotation of Set or Array type, in order to; allow each variant to have zero, one, or more keys (for example, the same variant may appear in multiple; genes). Unlike with type Set, if the same key appears twice in a variant annotation of type Array, then that; variant will be counted twice in that key's group. With ``single_key=True``, ``variant_keys`` expects a; variant annotation whose value is itself the key of interest. In bose cases, variants with missing keys are; ignored. **Notes**. This method modifies :py:meth:`.logreg` by replacing the genotype covariate per variant and sample with; an aggregated (i.e., collapsed) score per key and sample. This numeric score is computed from the sample's; genotypes and annotations over all variants with that key. The phenotype type must either be numeric; (with all present values 0 or 1) or Boolean, in which case true and false are coded as 1 and 0, respectively. Hail supports the Wald test ('wald'), likelihood ratio test ('lrt'), Rao score test ('score'),; and Firth test ('firth') as the ``test`` parameter. Conceptually, the method proceeds as follows:. 1) Filter to the set of samples for which all phenotype and covariates are defined. 2) For each key and sample, aggregate genotypes across variants with that key to produce a numeric score.; ``agg_expr`` must be of numeric type and has the following symbols are in scope:. - ``s`` (*Sample*): sample; - ``sa``: sample annotations; - ``global``: global annotations; - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``. Note that ``v``, ``va``, and ``g`` are accessible through; `Aggregable methods <https://hail.is/hail/types.html#aggregable>`_ on ``gs``. The resulting **sample key table** has key column ``key_name`` and a numeric column of scores for each sample; named by the sample ID. 3) For each key, fit the logistic regression model using the supplied phenotype, covariates, and test.; The model and tests are those of :py:meth:`.logreg` wi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:151824,test,test,151824,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,5,['test'],['test']
Testability,"riantDataset(self.hc, jvds). [docs] @handle_py4j; @typecheck_method(key_name=strlike,; variant_keys=strlike,; single_key=bool,; agg_expr=strlike,; test=strlike,; y=strlike,; covariates=listof(strlike)); def logreg_burden(self, key_name, variant_keys, single_key, agg_expr, test, y, covariates=[]):; r""""""Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. .. include:: requireTGenotype.rst. **Examples**. Run a gene burden test using the logistic Wald test on the maximum genotype per gene. Here ``va.genes`` is; a variant annotation of type Set[String] giving the set of genes containing the variant; (see **Extended example** in :py:meth:`.linreg_burden` for a deeper dive in the context of linear regression):. >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.genes',; ... single_key=False,; ... agg_expr='gs.map(g => g.gt).max()',; ... test='wald',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). Run a gene burden test using the logistic score test on the weighted sum of genotypes per gene.; Here ``va.gene`` is a variant annotation of type String giving a single gene per variant (or no gene if; missing), and ``va.weight`` is a numeric variant annotation:. >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.gene',; ... single_key=True,; ... agg_expr='gs.map(g => va.weight * g.gt).sum()',; ... test='score',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). To use a weighted sum of genotypes with missing genotypes mean-imputed rather than ignored, set; ``agg_expr='gs.map(g => va.weight * orElse(g.gt.toDouble, 2 * va.qc.AF)).sum()'`` where ``va.qc.AF``; is the allele frequency over those samples that have no missing phenotype or covariates. .. caution::. With ``single_key=False``, ``variant_keys",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:149852,test,test,149852,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['test']
Testability,"rio objects to include in pedigree. Attributes. trios; List of trio objects in this pedigree. Methods. __init__; x.__init__(…) initializes x; see help(type(x)) for signature. complete_trios; List of trio objects that have a defined father, mother, and sex. filter_to; Filter the pedigree to a given list of sample IDs. read; Read a .fam file and return a pedigree object. write; Write a .fam file to the given path. complete_trios()[source]¶; List of trio objects that have a defined father, mother, and sex. Return type:list of Trio. filter_to(samples)[source]¶; Filter the pedigree to a given list of sample IDs.; Notes; For any trio, the following steps will be applied:. If the proband is not in the list of samples provided, the trio is removed.; If the father is not in the list of samples provided, the father is set to None.; If the mother is not in the list of samples provided, the mother is set to None. Parameters:samples (list of str) – list of sample IDs to keep. Return type:Pedigree. static read(fam_path, delimiter='\\s+')[source]¶; Read a .fam file and return a pedigree object.; Examples; >>> ped = Pedigree.read('data/test.fam'). Notes; This method reads a PLINK .fam file.; Hail expects a file in the same spec as PLINK outlines. Parameters:; fam_path (str) – path to .fam file.; delimiter (str) – Field delimiter. Return type:Pedigree. trios¶; List of trio objects in this pedigree. Return type:list of Trio. write(path)[source]¶; Write a .fam file to the given path.; Examples; >>> ped = Pedigree.read('data/test.fam'); >>> ped.write('out.fam'). Notes; This method writes a PLINK .fam file. Caution; Phenotype information is not preserved in the Pedigree data structure in Hail.; Reading and writing a PLINK .fam file will result in loss of this information.; Use the key table method import_fam() to manipulate this; information. Parameters:path (str) – output path. Next ; Previous. © Copyright 2016, Hail Team. . Built with Sphinx using a theme provided by Read the Docs. . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/representation/hail.representation.Pedigree.html:1786,test,test,1786,docs/0.1/representation/hail.representation.Pedigree.html,https://hail.is,https://hail.is/docs/0.1/representation/hail.representation.Pedigree.html,2,['test'],['test']
Testability,"rix (GRM). hardcalls; Drop all genotype fields except the GT field. ibd; Compute matrix of identity-by-descent estimations. ibd_prune; Prune samples from the VariantDataset based on ibd() PI_HAT measures of relatedness. impute_sex; Impute sex of samples by calculating inbreeding coefficient on the X chromosome. join; Join two variant datasets. ld_matrix; Computes the linkage disequilibrium (correlation) matrix for the variants in this VDS. ld_prune; Prune variants in linkage disequilibrium (LD). linreg; Test each variant for association using linear regression. linreg3; Test each variant for association with multiple phenotypes using linear regression. linreg_burden; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the linear regression model. linreg_multi_pheno; Test each variant for association with multiple phenotypes using linear regression. lmmreg; Use a kinship-based linear mixed model to estimate the genetic component of phenotypic variance (narrow-sense heritability) and optionally test each variant for association. logreg; Test each variant for association using logistic regression. logreg_burden; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the logistic regression model. make_table; Produce a key with one row per variant and one or more columns per sample. mendel_errors; Find Mendel errors; count per variant, individual and nuclear family. min_rep; Gives minimal, left-aligned representation of alleles. naive_coalesce; Naively descrease the number of partitions. num_partitions; Number of partitions. pc_relate; Compute relatedness estimates between individuals using a variant of the PC-Relate method. pca; Run Principal Component Analysis (PCA) on the matrix of genotypes. persist; Persist this variant dataset to memory and/or disk. query_genotypes; Performs aggregation queries over genotypes, and returns Python object(s). query_genotypes_typed; Performs",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:5292,test,test,5292,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"rix is computed using distributed matrix multiplication if the number of genotypes exceeds :math:`5000^2` and locally otherwise. :return: Matrix of r values between pairs of variants.; :rtype: :py:class:`LDMatrix`; """""". jldm = self._jvdf.ldMatrix(force_local); return LDMatrix(jldm). [docs] @handle_py4j; @requireTGenotype; @typecheck_method(y=strlike,; covariates=listof(strlike),; root=strlike,; use_dosages=bool,; min_ac=integral,; min_af=numeric); def linreg(self, y, covariates=[], root='va.linreg', use_dosages=False, min_ac=1, min_af=0.0):; r""""""Test each variant for association using linear regression. .. include:: requireTGenotype.rst. **Examples**. Run linear regression per variant using a phenotype and two covariates stored in sample annotations:. >>> vds_result = vds.linreg('sa.pheno.height', covariates=['sa.pheno.age', 'sa.pheno.isFemale']). **Notes**. The :py:meth:`.linreg` method computes, for each variant, statistics of; the :math:`t`-test for the genotype coefficient of the linear function; of best fit from sample genotype and covariates to quantitative; phenotype or case-control status. Hail only includes samples for which; phenotype and all covariates are defined. For each variant, missing genotypes; as the mean of called genotypes. By default, genotypes values are given by hard call genotypes (``g.gt``).; If ``use_dosages=True``, then genotype values are defined by the dosage; :math:`\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})`. For Phred-scaled values,; :math:`\mathrm{P}(\mathrm{Het})` and :math:`\mathrm{P}(\mathrm{HomVar})` are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1. Assuming there are sample annotations ``sa.pheno.height``,; ``sa.pheno.age``, ``sa.pheno.isFemale``, and ``sa.cov.PC1``, the code:. >>> vds_result = vds.linreg('sa.pheno.height', covariates=['sa.pheno.age', 'sa.pheno.isFemale', 'sa.cov.PC1']). considers a model of the form. .. math::. \mathrm{height} = \beta_0 + \beta_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:98090,test,test,98090,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['test']
Testability,"rix.filter_rows` (or vice versa), but; filters the block matrix in a single pass which may be more efficient. Parameters; ----------; rows_to_keep: :obj:`list` of :obj:`int`; Indices of rows to keep. Must be non-empty and increasing.; cols_to_keep: :obj:`list` of :obj:`int`; Indices of columns to keep. Must be non-empty and increasing. Returns; -------; :class:`.BlockMatrix`; """"""; BlockMatrix._check_indices(rows_to_keep, self.n_rows); BlockMatrix._check_indices(cols_to_keep, self.n_cols); return BlockMatrix(BlockMatrixFilter(self._bmir, [rows_to_keep, cols_to_keep])). @staticmethod; def _pos_index(i, size, name, allow_size=False):; if 0 <= i < size or (i == size and allow_size):; return i; elif 0 <= i + size < size:; return i + size; else:; raise ValueError(f'invalid {name} {i} for axis of size {size}'). @staticmethod; def _range_to_keep(idx, size):; if isinstance(idx, int):; pos_idx = BlockMatrix._pos_index(idx, size, 'index'); return slice(pos_idx, pos_idx + 1, 1). assert isinstance(idx, slice); if idx.step and idx.step <= 0:; raise ValueError(f'slice step must be positive, found {idx.step}'). start = 0 if idx.start is None else BlockMatrix._pos_index(idx.start, size, 'start index'); stop = size if idx.stop is None else BlockMatrix._pos_index(idx.stop, size, 'stop index', allow_size=True); step = 1 if idx.step is None else idx.step. if start < stop:; return slice(start, stop, step); else:; raise ValueError(f'slice {start}:{stop}:{step} is empty'). @typecheck_method(indices=tupleof(oneof(int, sliceof(nullable(int), nullable(int), nullable(int))))); def __getitem__(self, indices):; if len(indices) != 2:; raise ValueError(f'tuple of indices or slices must have length two, found {len(indices)}'). row_idx, col_idx = indices. if isinstance(row_idx, int) and isinstance(col_idx, int):; i = BlockMatrix._pos_index(row_idx, self.n_rows, 'row index'); j = BlockMatrix._pos_index(col_idx, self.n_cols, 'col index'). return Env.backend().execute(BlockMatrixToValueApply(self._bmir,",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:28874,assert,assert,28874,docs/0.2/_modules/hail/linalg/blockmatrix.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html,2,['assert'],['assert']
Testability,"rix; representation; expr; utils. Annotation Database; Other Resources. Hail. Docs »; Python API »; HailContext. View page source. HailContext¶. class hail.HailContext(sc=None, app_name='Hail', master=None, local='local[*]', log='hail.log', quiet=False, append=False, parquet_compression='snappy', min_block_size=1, branching_factor=50, tmp_dir='/tmp')[source]¶; The main entry point for Hail functionality. Warning; Only one Hail context may be running in a Python session at any time. If you; need to reconfigure settings, restart the Python session or use the HailContext.stop() method.; If passing in a Spark context, ensure that the configuration parameters spark.sql.files.openCostInBytes; and spark.sql.files.maxPartitionBytes are set to as least 50GB. Parameters:; sc (pyspark.SparkContext) – Spark context, one will be created if None.; appName – Spark application identifier.; master – Spark cluster master.; local – Local resources to use.; log – Log path.; quiet (bool) – Don’t write logging information to standard error.; append – Write to end of log file instead of overwriting.; parquet_compression – Level of on-disk annotation compression.; min_block_size – Minimum file split size in MB.; branching_factor – Branching factor for tree aggregation.; tmp_dir – Temporary directory for file merging. Variables:sc (pyspark.SparkContext) – Spark context. Attributes. version; Return the version of Hail associated with this HailContext. Methods. __init__; x.__init__(…) initializes x; see help(type(x)) for signature. balding_nichols_model; Simulate a variant dataset using the Balding-Nichols model. eval_expr; Evaluate an expression. eval_expr_typed; Evaluate an expression and return the result as well as its type. get_running; Return the running Hail context in this Python session. grep; Grep big files, like, really fast. import_bgen; Import .bgen file(s) as variant dataset. import_gen; Import .gen file(s) as variant dataset. import_plink; Import PLINK binary file (BED, BIM, FAM",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.HailContext.html:1258,log,logging,1258,docs/0.1/hail.HailContext.html,https://hail.is,https://hail.is/docs/0.1/hail.HailContext.html,1,['log'],['logging']
Testability,"rm simultaneously. Larger block size requires more memmory. :return: Variant dataset with linear regression variant annotations.; :rtype: :py:class:`.VariantDataset`. """""". jvds = self._jvdf.linreg3(jarray(Env.jvm().java.lang.String, ys),; jarray(Env.jvm().java.lang.String, covariates), root, use_dosages, variant_block_size); return VariantDataset(self.hc, jvds). [docs] @handle_py4j; @requireTGenotype; @typecheck_method(kinshipMatrix=KinshipMatrix,; y=strlike,; covariates=listof(strlike),; global_root=strlike,; va_root=strlike,; run_assoc=bool,; use_ml=bool,; delta=nullable(numeric),; sparsity_threshold=numeric,; use_dosages=bool,; n_eigs=nullable(integral),; dropped_variance_fraction=(nullable(float))); def lmmreg(self, kinshipMatrix, y, covariates=[], global_root=""global.lmmreg"", va_root=""va.lmmreg"",; run_assoc=True, use_ml=False, delta=None, sparsity_threshold=1.0, use_dosages=False,; n_eigs=None, dropped_variance_fraction=None):; """"""Use a kinship-based linear mixed model to estimate the genetic component of phenotypic variance (narrow-sense heritability) and optionally test each variant for association. .. include:: requireTGenotype.rst. **Examples**. Suppose the variant dataset saved at *data/example_lmmreg.vds* has a Boolean variant annotation ``va.useInKinship`` and numeric or Boolean sample annotations ``sa.pheno``, ``sa.cov1``, ``sa.cov2``. Then the :py:meth:`.lmmreg` function in. >>> assoc_vds = hc.read(""data/example_lmmreg.vds""); >>> kinship_matrix = assoc_vds.filter_variants_expr('va.useInKinship').rrm(); >>> lmm_vds = assoc_vds.lmmreg(kinship_matrix, 'sa.pheno', ['sa.cov1', 'sa.cov2']). will execute the following four steps in order:. 1) filter to samples in given kinship matrix to those for which ``sa.pheno``, ``sa.cov``, and ``sa.cov2`` are all defined; 2) compute the eigendecomposition :math:`K = USU^T` of the kinship matrix; 3) fit covariate coefficients and variance parameters in the sample-covariates-only (global) model using restricted maximum lik",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:115096,test,test,115096,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['test']
Testability,"rm{isFemale}\) is coded as 1 for true (female) and; 0 for false (male). The null model sets \(\beta_1 = 0\).; The resulting variant annotations depend on the test statistic; as shown in the tables below. Test; Annotation; Type; Value. Wald; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). Wald; va.logreg.se; Double; estimated standard error, \(\widehat{\mathrm{se}}\). Wald; va.logreg.zstat; Double; Wald \(z\)-statistic, equal to \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; va.logreg.fit.converged; Boolean; true if iteration converged. Wald, LRT, Firth; va.logreg.fit.exploded; Boolean; true if iteration exploded. We consider iteration to have converged when every coordinate of \(\beta\) changes by less than \(10^{-6}\). For Wald and LRT, up to 25 iterations are attempted; in testing we find 4 or 5 iterations nearly always suffice. Convergence may also fail due to explosion, which refers to low-level numerical linear algebra exceptions caused by manipulating ill-conditioned ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:111717,test,tests,111717,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,2,"['log', 'test']","['logistic', 'tests']"
Testability,"rns true if item is non-missing. Otherwise, false. isMissing(a: T): Boolean – Returns true if item is missing. Otherwise, false. isnan(a: Double): Boolean – Returns true if the argument is NaN (not a number), false if the argument is defined but not NaN. Returns missing if the argument is missing. json(x: T): String – Returns the JSON representation of a data type. Locus(contig: String, pos: Int): Locus. Construct a Locus object.; let l = Locus(""1"", 10040532) in l.position; result: 10040532. Arguments. contig (String) – String representation of contig.; pos (Int) – SNP position or start of an indel. Locus(s: String): Locus. Construct a Locus object.; let l = Locus(""1:10040532"") in l.position; result: 10040532. Arguments. s (String) – String of the form CHR:POS. log(x: Double, b: Double): Double. Returns the base b logarithm of the given value x.; Arguments. x (Double) – the number to take the base b logarithm of.; b (Double) – the base. log(x: Double): Double. Returns the natural logarithm of the given value x.; Arguments. x (Double) – the number to take the natural logarithm of. log10(x: Double): Double. Returns the base 10 logarithm of the given value x.; Arguments. x (Double) – the number to take the base 10 logarithm of. merge(s1: Struct, s2: Struct): Struct. Create a new Struct with all fields in s1 and s2.; let s1 = {gene: ""ACBD"", function: ""LOF""} and s2 = {a: 20, b: ""hello""} in merge(s1, s2); result: {gene: ""ACBD"", function: ""LOF"", a: 20, b: ""hello""}. orElse(a: T, b: T): T. If a is not missing, returns a. Otherwise, returns b.; Examples; Replace missing phenotype values with the mean value:; >>> [mean_height] = vds.query_samples(['samples.map(s => sa.pheno.height).stats()'])['mean']; >>> vds.annotate_samples_expr('sa.pheno.heightImputed = orElse(sa.pheno.height, %d)' % mean_height). orMissing(a: Boolean, b: T): T – If predicate evaluates to true, returns value. Otherwise, returns NA. pchisqtail(x: Double, df: Double): Double. Returns right-tail probability p ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:12124,log,logarithm,12124,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,1,['log'],['logarithm']
Testability,"rns true with probability p. This function is non-deterministic.; Arguments. p (Double) – Probability. Should be between 0.0 and 1.0. pnorm(x: Double): Double. Returns left-tail probability p for which p = Prob(\(Z\) < x) with \(Z\) a standard normal random variable.; Arguments. x (Double) – Number at which to compute the probability. pow(b: Double, x: Double): Double. Returns b raised to the power of x.; Arguments. b (Double) – the base.; x (Double) – the exponent. ppois(x: Double, lambda: Double, lowerTail: Boolean, logP: Boolean): Double. If lowerTail equals true, returns Prob(\(X \leq\) x) where \(X\) is a Poisson random variable with rate parameter lambda. If lowerTail equals false, returns Prob(\(X\) > x).; Arguments. x (Double) – Non-negative number at which to compute the probability density.; lambda (Double) – Poisson rate parameter. Must be non-negative.; lowerTail (Boolean) – If false, returns the exclusive right-tail probability \(P(X > x)\).; logP (Boolean) – If true, probabilities are returned as log(p). ppois(x: Double, lambda: Double): Double. Returns the left-tail Prob(\(X \leq\) x) where \(X\) is a Poisson random variable with rate parameter lambda.; Arguments. x (Double) – Non-negative bound for the left-tail cumulative probability.; lambda (Double) – Poisson rate parameter. Must be non-negative. qchisqtail(p: Double, df: Double): Double. Returns right-quantile x for which p = Prob(\(Z^2\) > x) with \(Z^2\) a chi-squared random variable with degrees of freedom specified by df. p must satisfy 0 < p <= 1. Inverse of pchisq1tail.; Arguments. p (Double) – Probability; df (Double) – Degrees of freedom. qnorm(p: Double): Double. Returns left-quantile x for which p = Prob(\(Z\) < x) with \(Z\) a standard normal random variable. p must satisfy 0 < p < 1. Inverse of pnorm.; Arguments. p (Double) – Probability. qpois(p: Double, lambda: Double, lowerTail: Boolean, logP: Boolean): Int. If lowerTail equals true, returns the smallest integer \(x\) such that Prob",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:14370,log,logP,14370,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,2,['log'],"['log', 'logP']"
Testability,"rns; -------; :class:`.Expression`; """"""; a, b, success = unify_exprs(a, b); if not success:; raise TypeError(; f""'or_else' requires the 'a' and 'b' arguments to have the same type\n""; f"" a: type '{a.dtype}'\n""; f"" b: type '{b.dtype}'""; ); return coalesce(a, b). [docs]@typecheck(predicate=expr_bool, value=expr_any); def or_missing(predicate, value):; """"""Returns `value` if `predicate` is ``True``, otherwise returns missing. Examples; --------. >>> hl.eval(hl.or_missing(True, 5)); 5. >>> hl.eval(hl.or_missing(False, 5)); None. Parameters; ----------; predicate : :class:`.BooleanExpression`; value : :class:`.Expression`; Value to return if `predicate` is ``True``. Returns; -------; :class:`.Expression`; This expression has the same type as `b`.; """""". return hl.if_else(predicate, value, hl.missing(value.dtype)). [docs]@typecheck(; x=expr_int32, n=expr_int32, p=expr_float64, alternative=enumeration(""two.sided"", ""two-sided"", ""greater"", ""less""); ); def binom_test(x, n, p, alternative: str) -> Float64Expression:; """"""Performs a binomial test on `p` given `x` successes in `n` trials. Returns the p-value from the `exact binomial test; <https://en.wikipedia.org/wiki/Binomial_test>`__ of the null hypothesis that; success has probability `p`, given `x` successes in `n` trials. The alternatives are interpreted as follows:; - ``'less'``: a one-tailed test of the significance of `x` or fewer successes,; - ``'greater'``: a one-tailed test of the significance of `x` or more successes, and; - ``'two-sided'``: a two-tailed test of the significance of `x` or any equivalent or more unlikely outcome. Examples; --------. All the examples below use a fair coin as the null hypothesis. Zero is; interpreted as tail and one as heads. Test if a coin is biased towards heads or tails after observing two heads; out of ten flips:. >>> hl.eval(hl.binom_test(2, 10, 0.5, 'two-sided')); 0.10937499999999994. Test if a coin is biased towards tails after observing four heads out of ten; flips:. >>> hl.eval(h",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:60747,test,test,60747,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"robability. Returns:; Expression of type tfloat64. hail.expr.functions.pF(x, df1, df2, lower_tail=True, log_p=False)[source]; The cumulative probability function of a F-distribution with parameters; df1 and df2.; Examples; >>> hl.eval(hl.pF(0, 3, 10)); 0.0. >>> hl.eval(hl.pF(1, 3, 10)); 0.5676627969783028. >>> hl.eval(hl.pF(1, 3, 10, lower_tail=False)); 0.4323372030216972. >>> hl.eval(hl.pF(1, 3, 10, log_p=True)); -0.566227703842908. Notes; If lower_tail is true, returns Prob(\(X \leq\) x) where \(X\) is; a random variable with distribution \(F`(df1, df2). If `lower_tail\); is false, returns Prob(\(X\) > x). Parameters:. x (float or Expression of type tfloat64); df1 (float or Expression of type tfloat64) – Parameter of the F-distribution; df2 (float or Expression of type tfloat64) – Parameter of the F-distribution; lower_tail (bool or BooleanExpression) – If True, compute the probability of an outcome at or below x,; otherwise greater than x.; log_p (bool or BooleanExpression) – Return the natural logarithm of the probability. Returns:; Expression of type tfloat64. hail.expr.functions.ppois(x, lamb, lower_tail=True, log_p=False)[source]; The cumulative probability function of a Poisson distribution.; Examples; >>> hl.eval(hl.ppois(2, 1)); 0.9196986029286058. Notes; If lower_tail is true, returns Prob(\(X \leq\) x) where \(X\) is a; Poisson random variable with rate parameter lamb. If lower_tail is false,; returns Prob(\(X\) > x). Parameters:. x (float or Expression of type tfloat64); lamb (float or Expression of type tfloat64) – Rate parameter of Poisson distribution.; lower_tail (bool or BooleanExpression) – If True, compute the probability of an outcome at or below x,; otherwise greater than x.; log_p (bool or BooleanExpression) – Return the natural logarithm of the probability. Returns:; Expression of type tfloat64. hail.expr.functions.qchisqtail(p, df, ncp=None, lower_tail=False, log_p=False)[source]; The quantile function of a chi-squared distribution with d",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:24105,log,logarithm,24105,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['log'],['logarithm']
Testability,"rom small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the `Jeffrey's; invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the `logreg.fit` fields reflect the null model; otherwise,; they reflect the full model. See; `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert's notes; `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__.; Firth introduced his approach in; `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/GibbsFieldEst/BiasReductionMLE.pdf>`__.; Heinze and Schemper further analyze Firth's approach in; `A solution to the problem of separation in logistic regression, 2002 <https://cemsiis.meduniwien.ac.at/fileadmin/msi_akim/CeMSIIS/KB/volltexte/Heinze_Schemper_2002_Statistics_in_Medicine.pdf>`__. Hail's logistic regression tests correspond to the ``b.wald``,; ``b.lrt``, and ``b.score`` tests in `EPACTS`_. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EPACTS results will currently only agree for variants with no; missing genotypes. .. _EPACTS: http://genome.sph.umich.edu/wiki/EPACTS#Si",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:34672,test,tests,34672,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['tests']
Testability,"ror(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:60197,test,test,60197,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"roup, not the canonical \1. Parameters:. pattern1 (str or StringExpression); pattern2 (str or StringExpression). reverse()[source]; Returns the reversed value.; .. rubric:: Examples; >>> string = hl.literal('ATGCC'); >>> hl.eval(string.reverse()); 'CCGTA'. Returns:; StringExpression. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. split(delim, n=None)[source]; Returns an array of strings generated by splitting the string at delim.; Examples; >>> hl.eval(s.split('\s+')); ['The', 'quick', 'brown', 'fox']. >>> hl.eval(s.split('\s+', 2)); ['The', 'quick brown fox']. Notes; The delimiter is a regex using the; Java regex syntax; delimiter. To split on special characters, escape them with double; backslash (\\). Parameters:. delim (str or StringExpression) – Delimiter regex.; n (Expression of type tint32, optional) – Maximum number of splits. Returns:; ArrayExpression – Array of split strings. startswith(substr)[source]; Returns whether substr is a prefix of the string.; Examples; >",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.StringExpression.html:12204,log,logging,12204,docs/0.2/hail.expr.StringExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.StringExpression.html,1,['log'],['logging']
Testability,"rpreted as a lower triangular matrix; If false, A is interpreted as a upper triangular matrix. Returns; -------; :class:`.NDArrayNumericExpression`, (N,) or (N, K); Solution to the triangular system Ax = B. Shape is same as shape of B. """"""; nd_dep_ndim_orig = b.ndim; A, b = solve_helper(A, b, nd_dep_ndim_orig). indices, aggregations = unify_all(A, b). if no_crash:; return_type = hl.tstruct(solution=hl.tndarray(hl.tfloat64, 2), failed=hl.tbool); ir = Apply(""linear_triangular_solve_no_crash"", return_type, A._ir, b._ir, lower._ir); result = construct_expr(ir, return_type, indices, aggregations); if nd_dep_ndim_orig == 1:; result = result.annotate(solution=result.solution.reshape((-1))); return result. return_type = hl.tndarray(hl.tfloat64, 2); ir = Apply(""linear_triangular_solve"", return_type, A._ir, b._ir, lower._ir); result = construct_expr(ir, return_type, indices, aggregations); if nd_dep_ndim_orig == 1:; result = result.reshape((-1)); return result. def solve_helper(nd_coef, nd_dep, nd_dep_ndim_orig):; assert nd_coef.ndim == 2; assert nd_dep_ndim_orig in {1, 2}. if nd_dep_ndim_orig == 1:; nd_dep = nd_dep.reshape((-1, 1)). if nd_coef.dtype.element_type != hl.tfloat64:; nd_coef = nd_coef.map(lambda e: hl.float64(e)); if nd_dep.dtype.element_type != hl.tfloat64:; nd_dep = nd_dep.map(lambda e: hl.float64(e)); return nd_coef, nd_dep. [docs]@typecheck(nd=expr_ndarray(), mode=str); def qr(nd, mode=""reduced""):; r""""""Performs a QR decomposition. If K = min(M, N), then:. - `reduced`: returns q and r with dimensions (M, K), (K, N); - `complete`: returns q and r with dimensions (M, M), (M, N); - `r`: returns only r with dimensions (K, N); - `raw`: returns h, tau with dimensions (N, M), (K,). Notes; -----. The reduced QR, the default output of this function, has the following properties:. .. math::. m \ge n \\; nd : \mathbb{R}^{m \times n} \\; Q : \mathbb{R}^{m \times n} \\; R : \mathbb{R}^{n \times n} \\; \\; Q^T Q = \mathbb{1}. The complete QR, has the following properties:. ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/nd/nd.html:8874,assert,assert,8874,docs/0.2/_modules/hail/nd/nd.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/nd/nd.html,2,['assert'],['assert']
Testability,"rpreted as a upper triangular matrix. Returns; -------; :class:`.NDArrayNumericExpression`, (N,) or (N, K); Solution to the triangular system Ax = B. Shape is same as shape of B. """"""; nd_dep_ndim_orig = b.ndim; A, b = solve_helper(A, b, nd_dep_ndim_orig). indices, aggregations = unify_all(A, b). if no_crash:; return_type = hl.tstruct(solution=hl.tndarray(hl.tfloat64, 2), failed=hl.tbool); ir = Apply(""linear_triangular_solve_no_crash"", return_type, A._ir, b._ir, lower._ir); result = construct_expr(ir, return_type, indices, aggregations); if nd_dep_ndim_orig == 1:; result = result.annotate(solution=result.solution.reshape((-1))); return result. return_type = hl.tndarray(hl.tfloat64, 2); ir = Apply(""linear_triangular_solve"", return_type, A._ir, b._ir, lower._ir); result = construct_expr(ir, return_type, indices, aggregations); if nd_dep_ndim_orig == 1:; result = result.reshape((-1)); return result. def solve_helper(nd_coef, nd_dep, nd_dep_ndim_orig):; assert nd_coef.ndim == 2; assert nd_dep_ndim_orig in {1, 2}. if nd_dep_ndim_orig == 1:; nd_dep = nd_dep.reshape((-1, 1)). if nd_coef.dtype.element_type != hl.tfloat64:; nd_coef = nd_coef.map(lambda e: hl.float64(e)); if nd_dep.dtype.element_type != hl.tfloat64:; nd_dep = nd_dep.map(lambda e: hl.float64(e)); return nd_coef, nd_dep. [docs]@typecheck(nd=expr_ndarray(), mode=str); def qr(nd, mode=""reduced""):; r""""""Performs a QR decomposition. If K = min(M, N), then:. - `reduced`: returns q and r with dimensions (M, K), (K, N); - `complete`: returns q and r with dimensions (M, M), (M, N); - `r`: returns only r with dimensions (K, N); - `raw`: returns h, tau with dimensions (N, M), (K,). Notes; -----. The reduced QR, the default output of this function, has the following properties:. .. math::. m \ge n \\; nd : \mathbb{R}^{m \times n} \\; Q : \mathbb{R}^{m \times n} \\; R : \mathbb{R}^{n \times n} \\; \\; Q^T Q = \mathbb{1}. The complete QR, has the following properties:. .. math::. m \ge n \\; nd : \mathbb{R}^{m \times n} \\; Q ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/nd/nd.html:8900,assert,assert,8900,docs/0.2/_modules/hail/nd/nd.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/nd/nd.html,2,['assert'],['assert']
Testability,"rray_scan(f, zero, a); Map each element of a to cumulative value of function f, with initial value zero. reversed(x); Reverses the elements of a collection. keyed_intersection(*arrays, key); Compute the intersection of sorted arrays on a given key. keyed_union(*arrays, key); Compute the distinct union of sorted arrays on a given key. Numeric functions. abs(x); Take the absolute value of a numeric value, array or ndarray. approx_equal(x, y[, tolerance, absolute, ...]); Tests whether two numbers are approximately equal. bit_and(x, y); Bitwise and x and y. bit_or(x, y); Bitwise or x and y. bit_xor(x, y); Bitwise exclusive-or x and y. bit_lshift(x, y); Bitwise left-shift x by y. bit_rshift(x, y[, logical]); Bitwise right-shift x by y. bit_not(x); Bitwise invert x. bit_count(x); Count the number of 1s in the in the two's complement binary representation of x. exp(x). expit(x). is_nan(x). is_finite(x). is_infinite(x). log(x[, base]); Take the logarithm of the x with base base. log10(x). logit(x). sign(x); Returns the sign of a numeric value, array or ndarray. sqrt(x). int(x); Convert to a 32-bit integer expression. int32(x); Convert to a 32-bit integer expression. int64(x); Convert to a 64-bit integer expression. float(x); Convert to a 64-bit floating point expression. float32(x); Convert to a 32-bit floating point expression. float64(x); Convert to a 64-bit floating point expression. floor(x). ceil(x). uniroot(f, min, max, *[, max_iter, epsilon, ...]); Finds a root of the function f within the interval [min, max]. Numeric collection functions. min(*exprs[, filter_missing]); Returns the minimum element of a collection or of given numeric expressions. nanmin(*exprs[, filter_missing]); Returns the minimum value of a collection or of given arguments, excluding NaN. max(*exprs[, filter_missing]); Returns the maximum element of a collection or of given numeric expressions. nanmax(*exprs[, filter_missing]); Returns the maximum value of a collection or of given arguments, exclud",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/index.html:7240,log,logit,7240,docs/0.2/functions/index.html,https://hail.is,https://hail.is/docs/0.2/functions/index.html,1,['log'],['logit']
Testability,"rror of this point estimate. Warning; -------; :func:`.ld_score_regression` considers only the rows for which both row; fields ``weight_expr`` and ``ld_score_expr`` are defined. Rows with missing; values in either field are removed prior to fitting the LD score; regression model. Parameters; ----------; weight_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used to derive; variant weights in the model.; ld_score_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used as covariates; in the model.; chi_sq_exprs : :class:`.Float64Expression` or :obj:`list` of; :class:`.Float64Expression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions for chi-squared; statistics resulting from genome-wide association; studies (GWAS).; n_samples_exprs: :class:`.NumericExpression` or :obj:`list` of; :class:`.NumericExpression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions indicating the number of; samples used in the studies that generated the test; statistics supplied to ``chi_sq_exprs``.; n_blocks : :obj:`int`; The number of blocks used in the jackknife approach to; estimating standard errors.; two_step_threshold : :obj:`int`; Variants with chi-squared statistics greater than this; value are excluded in the first step of the two-step; procedure used to fit the model.; n_reference_panel_variants : :obj:`int`, optional; Number of variants used to estimate the; SNP-heritability :math:`h_g^2`. Returns; -------; :class:`~.Table`; Table keyed by ``phenotype`` with intercept and heritability estimates; for each phenotype passed to the function."""""". chi_sq_exprs = wrap_to_list(chi_sq_exprs); n_samples_exprs = wrap_to_list(n_samples_exprs). assert (len(chi_sq_exprs) == len(n_samples_exprs)) or (len(n_samples_exprs) == 1); __k = 2 # number of covariates, including intercept. ds = chi_sq_exprs[0]._indices.source. analyze('ld_score_regression/weight_expr', weight_expr, d",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:8073,test,test,8073,docs/0.2/_modules/hail/experimental/ld_score_regression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html,2,['test'],['test']
Testability,"rror:; pass. storage_level = enumeration(; 'NONE',; 'DISK_ONLY',; 'DISK_ONLY_2',; 'MEMORY_ONLY',; 'MEMORY_ONLY_2',; 'MEMORY_ONLY_SER',; 'MEMORY_ONLY_SER_2',; 'MEMORY_AND_DISK',; 'MEMORY_AND_DISK_2',; 'MEMORY_AND_DISK_SER',; 'MEMORY_AND_DISK_SER_2',; 'OFF_HEAP',; ). def run_command(args):; import subprocess as sp. try:; sp.check_output(args, stderr=sp.STDOUT); except sp.CalledProcessError as e:; print(e.output); raise e. def hl_plural(orig, n, alternate=None):; if alternate is None:; plural = orig + 's'; else:; plural = alternate; return hl.if_else(n == 1, orig, plural). def plural(orig, n, alternate=None):; if n == 1:; return orig; elif alternate:; return alternate; else:; return orig + 's'. def get_obj_metadata(obj):; from hail.expr.expressions import ArrayStructExpression, SetStructExpression, StructExpression; from hail.matrixtable import GroupedMatrixTable, MatrixTable; from hail.table import GroupedTable, Table; from hail.utils import Struct. def table_error(index_obj):; def fmt_field(field):; assert field in index_obj._fields; inds = index_obj[field]._indices; if inds == index_obj._global_indices:; return ""'{}' [globals]"".format(field); elif inds == index_obj._row_indices:; return ""'{}' [row]"".format(field); elif inds == index_obj._col_indices: # Table will never get here; return ""'{}' [col]"".format(field); else:; assert inds == index_obj._entry_indices; return ""'{}' [entry]"".format(field). return fmt_field. def struct_error(s):; def fmt_field(field):; assert field in s._fields; return ""'{}'"".format(field). return fmt_field. if isinstance(obj, MatrixTable):; return 'MatrixTable', MatrixTable, table_error(obj), True; elif isinstance(obj, GroupedMatrixTable):; return 'GroupedMatrixTable', GroupedMatrixTable, table_error(obj._parent), True; elif isinstance(obj, Table):; return 'Table', Table, table_error(obj), True; elif isinstance(obj, GroupedTable):; return 'GroupedTable', GroupedTable, table_error(obj), False; elif isinstance(obj, Struct):; return 'Struct', Str",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/misc.html:6278,assert,assert,6278,docs/0.2/_modules/hail/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/misc.html,2,['assert'],['assert']
Testability,"rt hailtop.batch_client as bc; from hail.backend.service_backend import ServiceBackend; from hail.expr import Float64Expression; from hail.expr.expressions.expression_typecheck import expr_float64; from hail.expr.functions import numeric_allele_type; from hail.expr.types import tarray, tfloat, tint32, tstr, tstruct; from hail.genetics.allele_type import AlleleType; from hail.ir import TableToTableApply; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import anytype, nullable, numeric, oneof, typecheck; from hail.utils import FatalError; from hail.utils.java import Env, info, warning; from hail.utils.misc import divide_null, guess_cloud_spark_provider, new_temp_file; from hailtop import pip_version, yamlx; from hailtop.config import get_deploy_config; from hailtop.utils import async_to_blocking. from .misc import (; require_alleles_field,; require_biallelic,; require_col_key_str,; require_row_key_variant,; require_table_key_variant,; ). log = logging.getLogger('methods.qc'). HAIL_GENETICS_VEP_GRCH37_85_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH37_85_IMAGE', f'hailgenetics/vep-grch37-85:{pip_version()}'; ); HAIL_GENETICS_VEP_GRCH38_95_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH38_95_IMAGE', f'hailgenetics/vep-grch38-95:{pip_version()}'; ). def _qc_allele_type(ref, alt):; return hl.bind(; lambda at: hl.if_else(; at == AlleleType.SNP,; hl.if_else(hl.is_transition(ref, alt), AlleleType.TRANSITION, AlleleType.TRANSVERSION),; at,; ),; numeric_allele_type(ref, alt),; ). [docs]@typecheck(mt=MatrixTable, name=str); def sample_qc(mt, name='sample_qc') -> MatrixTable:; """"""Compute per-sample metrics useful for quality control. .. include:: ../_templates/req_tvariant.rst. Examples; --------. Compute sample QC metrics and remove low-quality samples:. >>> dataset = hl.sample_qc(dataset, name='sample_qc'); >>> filtered_dataset = dataset.filter_cols((dataset.sample_qc.dp_stats.mean > 20) & (dataset.sample_qc.r_ti_tv > 1.5)). Notes",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/qc.html:1650,log,log,1650,docs/0.2/_modules/hail/methods/qc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html,4,['log'],"['log', 'logging']"
Testability,"rther analyze Firth’s approach in A solution to the problem of separation in logistic regression, 2002.; Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; Phenotype and covariate sample annotations may also be specified using programmatic expressions without identifiers, such as:; if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation sa.fam.isCase added by importing a FAM file with case-control phenotype, case is 1 and control is 0.; Hail’s logistic regression tests correspond to the b.wald, b.lrt, and b.score tests in EPACTS. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes. Parameters:; test (str) – Statistical test, one of: ‘wald’, ‘lrt’, ‘score’, or ‘firth’.; y (str) – Response expression. Must evaluate to Boolean or; numeric with all values 0 or 1.; covariates (list of str) – list of covariate expressions; root (str) – Variant annotation path to store result of logistic regression.; use_dosages (bool) – If true, use genotype dosage rather than hard call. Returns:Variant dataset with logistic regression variant annotations. Return type:VariantDataset. logreg_burden(key_name, variant_keys, single_key, agg_expr, test, y, covariates=[])[source]¶; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Run a gene burden test using the logistic Wald test on the maximum genotype per gene. Here va.genes is; a variant annotation of type Set[String] giving the set of genes containing the variant; (see Extended example in linreg_burd",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:116674,test,test,116674,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,2,['test'],['test']
Testability,"rtype: bool; """""". return self._jrep.isNotCalled(). [docs] def is_called(self):; """"""True if the genotype call is non-missing. :rtype: bool; """""". return self._jrep.isCalled(). [docs] def num_alt_alleles(self):; """"""Returns the count of non-reference alleles. This function returns None if the genotype call is missing. :rtype: int or None; """""". return from_option(self._jrep.nNonRefAlleles()). [docs] @handle_py4j; @typecheck_method(num_alleles=integral); def one_hot_alleles(self, num_alleles):; """"""Returns a list containing the one-hot encoded representation of the called alleles. This one-hot representation is the positional sum of the one-hot; encoding for each called allele. For a biallelic variant, the; one-hot encoding for a reference allele is [1, 0] and the one-hot; encoding for an alternate allele is [0, 1]. Thus, with the; following variables:. .. testcode::. num_alleles = 2; hom_ref = Genotype(0); het = Genotype(1); hom_var = Genotype(2). All the below statements are true:. .. testcode::. hom_ref.one_hot_alleles(num_alleles) == [2, 0]; het.one_hot_alleles(num_alleles) == [1, 1]; hom_var.one_hot_alleles(num_alleles) == [0, 2]. This function returns None if the genotype call is missing. :param int num_alleles: number of possible alternate alleles; :rtype: list of int or None; """"""; return jiterable_to_list(from_option(self._jrep.oneHotAlleles(num_alleles))). [docs] @handle_py4j; @typecheck_method(num_genotypes=integral); def one_hot_genotype(self, num_genotypes):; """"""Returns a list containing the one-hot encoded representation of the genotype call. A one-hot encoding is a vector with one '1' and many '0' values, like; [0, 0, 1, 0] or [1, 0, 0, 0]. This function is useful for transforming; the genotype call (gt) into a one-hot encoded array. With the following; variables:. .. testcode::. num_genotypes = 3; hom_ref = Genotype(0); het = Genotype(1); hom_var = Genotype(2). All the below statements are true:. .. testcode::. hom_ref.one_hot_genotype(num_genotypes) == [1, ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html:5508,test,testcode,5508,docs/0.1/_modules/hail/representation/genotype.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html,1,['test'],['testcode']
Testability,"r}\n""; ). uid = Env.get_uid(); fnames = list(variants.dtype); name, variants = variants._to_table(; uid; ) # This will add back the other key fields of the source, which we don't want; variants = variants.key_by(**{fname: variants[name][fname] for fname in fnames}); variants = variants.select(); elif isinstance(variants, Table):; if len(variants.key) == 0 or not variants.key.dtype._is_prefix_of(expected_vtype):; raise TypeError(; ""'import_bgen' requires the row key type for 'variants' is a non-empty prefix of the BGEN key type: \n""; + f""\tFound: {variants.key.dtype!r}\n""; + f""\tExpected: {expected_vtype!r}\n""; ); variants = variants.select(); else:; assert isinstance(variants, list); try:; if len(variants) == 0:; variants = hl.Table.parallelize(variants, schema=expected_vtype, key=['locus', 'alleles']); else:; first_v = variants[0]; if isinstance(first_v, hl.Locus):; variants = hl.Table.parallelize(; [hl.Struct(locus=v) for v in variants], schema=hl.tstruct(locus=lt), key='locus'; ); else:; assert isinstance(first_v, hl.utils.Struct); if len(first_v) == 1:; variants = hl.Table.parallelize(variants, schema=hl.tstruct(locus=lt), key='locus'); else:; variants = hl.Table.parallelize(variants, schema=expected_vtype, key=['locus', 'alleles']); except Exception:; raise TypeError(; f""'import_bgen' requires all elements in 'variants' are a non-empty prefix of the BGEN key type: {expected_vtype!r}""; ). vir = variants._tir; if (; isinstance(vir, ir.TableRead); and isinstance(vir.reader, ir.TableNativeReader); and vir.reader.intervals is None; and variants.count() == variants.distinct().count(); ):; variants_path = vir.reader.path; else:; variants_path = new_temp_file(prefix='bgen_included_vars', extension='ht'); variants.distinct().write(variants_path); else:; variants_path = None. reader = ir.MatrixBGENReader(path, sample_file, index_file_map, n_partitions, block_size, variants_path). mt = MatrixTable(ir.MatrixRead(reader)).drop(; *[fd for fd in ['GT', 'GP', 'dosage'] if fd n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/impex.html:45891,assert,assert,45891,docs/0.2/_modules/hail/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html,2,['assert'],['assert']
Testability,"s 1 for true (female) and; 0 for false (male). The null model sets :math:`\\beta_1 = 0`. The resulting variant annotations depend on the test statistic; as shown in the tables below. ========== =================== ====== =====; Test Annotation Type Value; ========== =================== ====== =====; Wald ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; Wald ``va.logreg.se`` Double estimated standard error, :math:`\widehat{\mathrm{se}}`; Wald ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`; Wald ``va.logreg.pval`` Double Wald p-value testing :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. ================ =========================== ======= =====; Test Annotation Type Value; ================ =========================== ======= =====; Wald, LRT, Firth ``va.logreg.fit.nIter`` Int number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth); Wald, LRT, Firth ``va.logreg.fit.converged`` Boolean true if iteration converged; Wald, LRT, Firth ``va.logreg.fit.exploded`` Boolean true if iteration exploded; ================ =========================== ======= =====. We consider iteration to hav",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:142286,test,testing,142286,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['testing']
Testability,"s None:; label_by_col = {}; elif isinstance(label, Expression):; label_by_col = {'label': label}; else:; assert isinstance(label, dict); label_by_col = label. if isinstance(colors, ColorMapper):; colors_by_col = {'label': colors}; else:; colors_by_col = colors. label_cols = list(label_by_col.keys()); if isinstance(x, NumericExpression):; _x = ('x', x); else:; _x = x. if isinstance(y, NumericExpression):; _y = ('y', y); else:; _y = y. source_pd = _collect_scatter_plot_data(; _x,; _y,; fields={**hover_fields, **label_by_col},; n_divisions=_downsampling_factor('scatter', n_divisions, collect_all),; missing_label=missing_label,; ); sp = figure(title=title, x_axis_label=xlabel, y_axis_label=ylabel, height=height, width=width); sp, sp_legend_items, sp_legend, sp_color_bar, sp_color_mappers, sp_scatter_renderers = _get_scatter_plot_elements(; sp, source_pd, _x[0], _y[0], label_cols, colors_by_col, size, hover_cols={'x', 'y'} | set(hover_fields); ). if not legend:; assert sp_legend is not None; assert sp_color_bar is not None; sp_legend.visible = False; sp_color_bar.visible = False. # If multiple labels, create JS call back selector; if len(label_cols) > 1:; callback_args: Dict[str, Any]; callback_args = dict(color_mappers=sp_color_mappers, scatter_renderers=sp_scatter_renderers); callback_code = """"""; for (var i = 0; i < scatter_renderers.length; i++){; scatter_renderers[i].glyph.fill_color = {field: cb_obj.value, transform: color_mappers[cb_obj.value]}; scatter_renderers[i].glyph.line_color = {field: cb_obj.value, transform: color_mappers[cb_obj.value]}; scatter_renderers[i].visible = true; }. """""". if legend:; callback_args.update(dict(legend_items=sp_legend_items, legend=sp_legend, color_bar=sp_color_bar)); callback_code += """"""; if (cb_obj.value in legend_items){; legend.items=legend_items[cb_obj.value]; legend.visible=true; color_bar.visible=false; }else{; legend.visible=false; color_bar.visible=true; }. """""". callback = CustomJS(args=callback_args, code=callback_code); s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:34256,assert,assert,34256,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,4,['assert'],['assert']
Testability,"s [0, 1]. Thus, with the; following variables:. .. testcode::. num_alleles = 2; hom_ref = Genotype(0); het = Genotype(1); hom_var = Genotype(2). All the below statements are true:. .. testcode::. hom_ref.one_hot_alleles(num_alleles) == [2, 0]; het.one_hot_alleles(num_alleles) == [1, 1]; hom_var.one_hot_alleles(num_alleles) == [0, 2]. This function returns None if the genotype call is missing. :param int num_alleles: number of possible alternate alleles; :rtype: list of int or None; """"""; return jiterable_to_list(from_option(self._jrep.oneHotAlleles(num_alleles))). [docs] @handle_py4j; @typecheck_method(num_genotypes=integral); def one_hot_genotype(self, num_genotypes):; """"""Returns a list containing the one-hot encoded representation of the genotype call. A one-hot encoding is a vector with one '1' and many '0' values, like; [0, 0, 1, 0] or [1, 0, 0, 0]. This function is useful for transforming; the genotype call (gt) into a one-hot encoded array. With the following; variables:. .. testcode::. num_genotypes = 3; hom_ref = Genotype(0); het = Genotype(1); hom_var = Genotype(2). All the below statements are true:. .. testcode::. hom_ref.one_hot_genotype(num_genotypes) == [1, 0, 0]; het.one_hot_genotype(num_genotypes) == [0, 1, 0]; hom_var.one_hot_genotype(num_genotypes) == [0, 0, 1]. This function returns None if the genotype call is missing. :param int num_genotypes: number of possible genotypes; :rtype: list of int or None; """""". return jiterable_to_list(from_option(self._jrep.oneHotGenotype(num_genotypes))). [docs] @handle_py4j; @typecheck_method(theta=numeric); def p_ab(self, theta=0.5):; """"""Returns the p-value associated with finding the given allele depth ratio. This function uses a one-tailed binomial test. This function returns None if the allelic depth (ad) is missing. :param float theta: null reference probability for binomial model; :rtype: float; """""". return from_option(self._jrep.pAB(theta)). [docs] def fraction_reads_ref(self):; """"""Returns the fraction of re",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html:6319,test,testcode,6319,docs/0.1/_modules/hail/representation/genotype.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html,1,['test'],['testcode']
Testability,"s are mean-imputed across all samples. The resulting **logistic regression key table** has key column of type String given by the ``key_name``; parameter and additional columns corresponding to the fields of the ``va.logreg`` schema given for ``test``; in :py:meth:`.logreg`. :py:meth:`.logreg_burden` returns both the logistic regression key table and the sample key table. :param str key_name: Name to assign to key column of returned key tables. :param str variant_keys: Variant annotation path for the TArray or TSet of keys associated to each variant. :param bool single_key: if true, ``variant_keys`` is interpreted as a single (or missing) key per variant,; rather than as a collection of keys. :param str agg_expr: Sample aggregation expression (per key). :param str test: Statistical test, one of: 'wald', 'lrt', 'score', or 'firth'. :param str y: Response expression. :param covariates: list of covariate expressions.; :type covariates: list of str. :return: Tuple of logistic regression key table and sample aggregation key table.; :rtype: (:py:class:`.KeyTable`, :py:class:`.KeyTable`); """""". r = self._jvdf.logregBurden(key_name, variant_keys, single_key, agg_expr, test, y, jarray(Env.jvm().java.lang.String, covariates)); logreg_kt = KeyTable(self.hc, r._1()); sample_kt = KeyTable(self.hc, r._2()). return logreg_kt, sample_kt. [docs] @handle_py4j; @requireTGenotype; @typecheck_method(pedigree=Pedigree); def mendel_errors(self, pedigree):; """"""Find Mendel errors; count per variant, individual and nuclear; family. .. include:: requireTGenotype.rst. **Examples**. Find all violations of Mendelian inheritance in each (dad,; mom, kid) trio in a pedigree and return four tables:. >>> ped = Pedigree.read('data/trios.fam'); >>> all, per_fam, per_sample, per_variant = vds.mendel_errors(ped); ; Export all mendel errors to a text file:; ; >>> all.export('output/all_mendel_errors.tsv'). Annotate samples with the number of Mendel errors:; ; >>> annotated_vds = vds.annotate_samples_table(",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:153953,log,logistic,153953,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logistic']
Testability,"s four kinds of fields:. global fields; row fields; column fields; entry fields. Row fields are fields that are stored once per row. These can contain information about the rows, or summary data calculated per row.; Column fields are stored once per column. These can contain information about the columns, or summary data calculated per column.; Entry fields are the piece that makes this structure a matrix – there is an entry for each (row, column) pair. Importing and Reading; Like tables, matrix tables can be imported from a variety of formats: VCF, (B)GEN, PLINK, TSV, etc. Matrix tables can also be read from a “native” matrix table format. Let’s read a sample of prepared 1KG data. [1]:. import hail as hl; from bokeh.io import output_notebook, show; output_notebook(). hl.utils.get_1kg('data/'). Loading BokehJS ... Loading BokehJS ... Initializing Hail with default parameters...; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2011-0.2.133-4c60fddb171a.log; 2024-10-04 20:11:52.232 Hail: INFO: 1KG files found. [2]:. mt = hl.read_matrix_table('data/1kg.mt'); mt.describe(). ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 's': str; ----------------------------------------; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'rsid': str; 'qual': float64; 'filters': set<str>; 'info': struct {; AC: array<int32>,; AF: array<float64>,; AN: int32,; BaseQRankSum: float64,; ClippingRankSum: float64,; DP: int32,; DS: bool,; FS: float64,; HaplotypeScore: float64,; InbreedingC",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/07-matrixtable.html:2865,log,logger,2865,docs/0.2/tutorials/07-matrixtable.html,https://hail.is,https://hail.is/docs/0.2/tutorials/07-matrixtable.html,1,['log'],['logger']
Testability,"s genotype probability representation.; Annotations; import_gen() adds the following variant annotations:. va.varid (String) – 2nd column of .gen file if chromosome present, otherwise 1st column.; va.rsid (String) – 3rd column of .gen file if chromosome present, otherwise 2nd column. Parameters:; path (str or list of str) – .gen files to import.; sample_file (str) – The sample file.; tolerance (float) – If the sum of the genotype probabilities for a genotype differ from 1.0 by more than the tolerance, set the genotype to missing.; min_partitions (int or None) – Number of partitions.; chromosome (str or None) – Chromosome if not listed in the .gen file. Returns:Variant dataset imported from .gen and .sample files. Return type:VariantDataset. import_plink(bed, bim, fam, min_partitions=None, delimiter='\\\\s+', missing='NA', quantpheno=False)[source]¶; Import PLINK binary file (BED, BIM, FAM) as variant dataset.; Examples; Import data from a PLINK binary file:; >>> vds = hc.import_plink(bed=""data/test.bed"",; ... bim=""data/test.bim"",; ... fam=""data/test.fam""). Notes; Only binary SNP-major mode files can be read into Hail. To convert your file from individual-major mode to SNP-major mode, use PLINK to read in your fileset and use the --make-bed option.; The centiMorgan position is not currently used in Hail (Column 3 in BIM file).; The ID (s) used by Hail is the individual ID (column 2 in FAM file). Warning; No duplicate individual IDs are allowed. Chromosome names (Column 1) are automatically converted in the following cases:. 23 => “X”; 24 => “Y”; 25 => “X”; 26 => “MT”. Annotations; import_plink() adds the following annotations:. va.rsid (String) – Column 2 in the BIM file.; sa.famID (String) – Column 1 in the FAM file. Set to missing if ID equals “0”.; sa.patID (String) – Column 3 in the FAM file. Set to missing if ID equals “0”.; sa.matID (String) – Column 4 in the FAM file. Set to missing if ID equals “0”.; sa.isFemale (String) – Column 5 in the FAM file. Set to mis",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.HailContext.html:12637,test,test,12637,docs/0.1/hail.HailContext.html,https://hail.is,https://hail.is/docs/0.1/hail.HailContext.html,1,['test'],['test']
Testability,"s import analyze. protected_key = set(indices.protected_key); for k, v in named_exprs.items():; analyze(f'{caller}: field {k!r}', v, indices, agg_axes, broadcast=True); check_keys(caller, k, protected_key); check_collisions(caller, list(named_exprs), indices); return named_exprs. def process_joins(obj, exprs):; all_uids = []; left = obj; used_joins = set(). for e in exprs:; joins = e._ir.search(lambda a: isinstance(a, hail.ir.Join)); for j in sorted(joins, key=lambda j: j.idx): # Make sure joins happen in order; if j.idx not in used_joins:; left = j.join_func(left); all_uids.extend(j.temp_vars); used_joins.add(j.idx). def cleanup(table):; remaining_uids = [uid for uid in all_uids if uid in table._fields]; return table.drop(*remaining_uids). return left, cleanup. def divide_null(num, denom):; from hail.expr import if_else, missing; from hail.expr.expressions.base_expression import unify_types_limited. typ = unify_types_limited(num.dtype, denom.dtype); assert typ is not None; return if_else(denom != 0, num / denom, missing(typ)). def lookup_bit(byte, which_bit):; return (byte >> which_bit) & 1. def timestamp_path(base, suffix=''):; return ''.join([base, '-', datetime.datetime.now().strftime(""%Y%m%d-%H%M""), suffix]). def upper_hex(n, num_digits=None):; if num_digits is None:; return ""{0:X}"".format(n); else:; return ""{0:0{1}X}"".format(n, num_digits). def escape_str(s, backticked=False):; sb = StringIO(). rewrite_dict = {'\b': '\\b', '\n': '\\n', '\t': '\\t', '\f': '\\f', '\r': '\\r'}. for ch in s:; chNum = ord(ch); if chNum > 0x7F:; sb.write(""\\u"" + upper_hex(chNum, 4)); elif chNum < 32:; if ch in rewrite_dict:; sb.write(rewrite_dict[ch]); elif chNum > 0xF:; sb.write(""\\u00"" + upper_hex(chNum)); else:; sb.write(""\\u000"" + upper_hex(chNum)); elif ch == '""':; if backticked:; sb.write('""'); else:; sb.write('\\""'); elif ch == '`':; if backticked:; sb.write(""\\`""); else:; sb.write(""`""); elif ch == '\\':; sb.write('\\\\'); else:; sb.write(ch). escaped = sb.getvalue(); sb.clos",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/misc.html:15191,assert,assert,15191,docs/0.2/_modules/hail/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/misc.html,2,['assert'],['assert']
Testability,"s matrix (GRM). realized_relationship_matrix(call_expr); Computes the realized relationship matrix (RRM). impute_sex(call[, aaf_threshold, ...]); Impute sex of samples by calculating inbreeding coefficient on the X chromosome. ld_matrix(entry_expr, locus_expr, radius[, ...]); Computes the windowed correlation (linkage disequilibrium) matrix between variants. ld_prune(call_expr[, r2, bp_window_size, ...]); Returns a maximal subset of variants that are nearly uncorrelated within each window. compute_charr(ds[, min_af, max_af, min_dp, ...]); Compute CHARR, the DNA sample contamination estimator. mendel_errors(call, pedigree); Find Mendel errors; count per variant, individual and nuclear family. de_novo(mt, pedigree, pop_frequency_prior, *); Call putative de novo events from trio data. nirvana(dataset, config[, block_size, name]); Annotate variants using Nirvana. sample_qc(mt[, name]); Compute per-sample metrics useful for quality control. _logistic_skat(group, weight, y, x, covariates); The logistic sequence kernel association test (SKAT). skat(key_expr, weight_expr, y, x, covariates); Test each keyed group of rows for association by linear or logistic SKAT test. lambda_gc(p_value[, approximate]); Compute genomic inflation factor (lambda GC) from an Expression of p-values. split_multi(ds[, keep_star, left_aligned, ...]); Split multiallelic variants. split_multi_hts(ds[, keep_star, ...]); Split multiallelic variants for datasets that contain one or more fields from a standard high-throughput sequencing entry schema. summarize_variants(mt[, show, handler]); Summarize the variants present in a dataset and print the results. transmission_disequilibrium_test(dataset, ...); Performs the transmission disequilibrium test on trios. trio_matrix(dataset, pedigree[, complete_trios]); Builds and returns a matrix where columns correspond to trios and entries contain genotypes for the trio. variant_qc(mt[, name]); Compute common variant statistics (quality control metrics). vep(datase",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:2660,log,logistic,2660,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"s that don't vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations. Phenotype and covariate sample annotations may also be specified using `programmatic expressions <exprlang.html>`__ without identifiers, such as:. .. code-block:: text. if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation ``sa.fam.isCase`` added by importing a FAM file with case-control phenotype, case is 1 and control is 0. Hail's logistic regression tests correspond to the ``b.wald``, ``b.lrt``, and ``b.score`` tests in `EPACTS <http://genome.sph.umich.edu/wiki/EPACTS#Single_Variant_Tests>`__. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes. :param str test: Statistical test, one of: 'wald', 'lrt', 'score', or 'firth'. :param str y: Response expression. Must evaluate to Boolean or; numeric with all values 0 or 1. :param covariates: list of covariate expressions; :type covariates: list of str. :param str root: Variant annotation path to store result of logistic regression. :param bool use_dosages: If true, use genotype dosage rather than hard call. :return: Variant dataset with logistic regression variant annotations.; :rtype: :py:class:`.VariantDataset`; """""". jvds = self._jvdf.logreg(test, y, jarray(Env.jvm().java.lang.String, covariates), root, use_dosages); return VariantDataset(self.hc, jvds). [docs] @handle_py4j; @typecheck_method(key_name=strlike,; variant_keys=strlike,; single_key=bool,; agg_expr=strlike,; test=strlike,; y=strlike,; covariates=listof(strlike)); def logreg_burden(self, key_name, variant_keys, single_key, agg_expr, test, y, covariates=[]):; r""""""Test each keyed group of variants for association by aggregating (collapsing) genotypes and apply",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:148231,test,test,148231,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,2,['test'],['test']
Testability,"s with very low minor; allele count. The maximum likelihood estimate of \(\beta\) under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests.; Here’s a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. Status; HomRef; Het; HomVar. Case; 1000; 10; 0. Control; 1000; 0; 0. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where x is genotype,; y is phenotype, and logistf is from the logistf package:; x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association.; The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the Jeffrey’s; invariant prior. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full mod",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:12087,log,logistic,12087,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,6,['log'],"['logfit', 'logistf', 'logistic']"
Testability,"s x-axis to be vertically reversed. Parameters:; name (str) – The label to show on x-axis. Returns:; FigureAttribute – The scale to be applied. hail.ggplot.scale_y_continuous(name=None, breaks=None, labels=None, trans='identity')[source]; The default continuous y scale. Parameters:. name (str) – The label to show on y-axis; breaks (list of float) – The locations to draw ticks on the y-axis.; labels (list of str) – The labels of the ticks on the axis.; trans (str) – The transformation to apply to the y-axis. Supports “identity”, “reverse”, “log10”. Returns:; FigureAttribute – The scale to be applied. hail.ggplot.scale_y_discrete(name=None, breaks=None, labels=None)[source]; The default discrete y scale. Parameters:. name (str) – The label to show on y-axis; breaks (list of str) – The locations to draw ticks on the y-axis.; labels (list of str) – The labels of the ticks on the axis. Returns:; FigureAttribute – The scale to be applied. hail.ggplot.scale_y_log10(name=None)[source]; Transforms y-axis to be log base 10 scaled. Parameters:; name (str) – The label to show on y-axis. Returns:; FigureAttribute – The scale to be applied. hail.ggplot.scale_y_reverse(name=None)[source]; Transforms y-axis to be vertically reversed. Parameters:; name (str) – The label to show on y-axis. Returns:; FigureAttribute – The scale to be applied. hail.ggplot.scale_color_continuous()[source]; The default continuous color scale. This linearly interpolates colors between the min and max observed values. Returns:; FigureAttribute – The scale to be applied. hail.ggplot.scale_color_discrete()[source]; The default discrete color scale. This maps each discrete value to a color. Equivalent to scale_color_hue. Returns:; FigureAttribute – The scale to be applied. hail.ggplot.scale_color_hue()[source]; Map discrete colors to evenly placed positions around the color wheel. Returns:; FigureAttribute – The scale to be applied. hail.ggplot.scale_color_manual(*, values)[source]; A color scale that",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/ggplot/index.html:12233,log,log,12233,docs/0.2/ggplot/index.html,https://hail.is,https://hail.is/docs/0.2/ggplot/index.html,1,['log'],['log']
Testability,"s' searching for covariates; axis_field = 'annotation' if axis == 'rows' else 'covariate'; if str_expr is None:; # take all row (or col) fields in mt matching keys in coef_dict; coef_dict = {k: ref_coef_dict[k] for k in ref_coef_dict.keys() if k in fields_to_search}; # if intersect is empty: return error; assert len(coef_dict) > 0, f'None of the keys in ref_coef_dict match any {axis[:-1]} fields'; return coef_dict # return subset of ref_coef_dict; else:; # str_expr search in list of row (or col) fields; fields = [rf for rf in list(fields_to_search) if str_expr in rf]; assert len(fields) > 0, f'No {axis[:-1]} fields matched str_expr search: {str_expr}'; if ref_coef_dict is None:; print(f'Assuming coef = 1 for all {axis_field}s'); return {k: 1 for k in fields}; in_ref_coef_dict = set(fields).intersection(set(ref_coef_dict.keys())) # fields in ref_coef_dict; # if >0 fields returned by search are not in ref_coef_dict; if in_ref_coef_dict != set(fields):; # if none of the fields returned by search are in ref_coef_dict; assert len(in_ref_coef_dict) > 0, f'None of the {axis_field} fields in ref_coef_dict match search results'; fields_to_ignore = set(fields).difference(in_ref_coef_dict); print(f'Ignored fields from {axis_field} search: {fields_to_ignore}'); print('To include ignored fields, change str_expr to match desired fields'); fields = list(in_ref_coef_dict); return {k: ref_coef_dict[k] for k in fields}. [docs]@typecheck(mt=MatrixTable, y=expr_int32, P=oneof(int, float)); def ascertainment_bias(mt, y, P):; r""""""Adds ascertainment bias to a binary phenotype to give it a sample; prevalence of `P` = cases/(cases+controls). Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` containing binary phenotype to be used.; y : :class:`.Expression`; Column field of binary phenotype.; P : :obj:`int` or :obj:`float`; Desired ""sample prevalence"" of phenotype. Returns; -------; :class:`.MatrixTable`; :class:`.MatrixTable` containing binary phenotype with prevalence",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:31637,assert,assert,31637,docs/0.2/_modules/hail/experimental/ldscsim.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html,2,['assert'],['assert']
Testability,"s). [docs] @handle_py4j; @typecheck_method(key_name=strlike,; variant_keys=strlike,; single_key=bool,; agg_expr=strlike,; y=strlike,; covariates=listof(strlike)); def linreg_burden(self, key_name, variant_keys, single_key, agg_expr, y, covariates=[]):; r""""""Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; linear regression model. .. include:: requireTGenotype.rst. **Examples**. Run a gene burden test using linear regression on the maximum genotype per gene. Here ``va.genes`` is a variant; annotation of type Set[String] giving the set of genes containing the variant (see **Extended example** below; for a deep dive):. >>> linreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .linreg_burden(key_name='gene',; ... variant_keys='va.genes',; ... single_key=False,; ... agg_expr='gs.map(g => g.gt).max()',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). Run a gene burden test using linear regression on the weighted sum of genotypes per gene. Here ``va.gene`` is; a variant annotation of type String giving a single gene per variant (or no gene if missing), and ``va.weight``; is a numeric variant annotation:. >>> linreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .linreg_burden(key_name='gene',; ... variant_keys='va.gene',; ... single_key=True,; ... agg_expr='gs.map(g => va.weight * g.gt).sum()',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). To use a weighted sum of genotypes with missing genotypes mean-imputed rather than ignored, set; ``agg_expr='gs.map(g => va.weight * orElse(g.gt.toDouble, 2 * va.qc.AF)).sum()'`` where ``va.qc.AF``; is the allele frequency over those samples that have no missing phenotype or covariates. .. caution::. With ``single_key=False``, ``variant_keys`` expects a variant annotation of Set or Array type, in order to; allow each variant to have zero, one, or more keys (for example, the same variant may appe",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:103222,test,test,103222,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['test']
Testability,"s: Optional[Union[ColorMapper, Dict[str, ColorMapper]]] = None,; width: int = 800,; height: int = 800,; collect_all: Optional[bool] = None,; n_divisions: Optional[int] = 500,; missing_label: str = 'NA',; ) -> Union[figure, Column]:; """"""Create a Quantile-Quantile plot. (https://en.wikipedia.org/wiki/Q-Q_plot). If no label or a single label is provided, then returns :class:`bokeh.plotting.figure`; Otherwise returns a :class:`bokeh.models.layouts.Column` containing:; - a :class:`bokeh.models.widgets.inputs.Select` dropdown selection widget for labels; - a :class:`bokeh.plotting.figure` containing the interactive qq plot. Points will be colored by one of the labels defined in the ``label`` using the color scheme defined in; the corresponding entry of ``colors`` if provided (otherwise a default scheme is used). To specify your color; mapper, check `the bokeh documentation <https://bokeh.pydata.org/en/latest/docs/reference/colors.html>`__; for CategoricalMapper for categorical labels, and for LinearColorMapper and LogColorMapper; for continuous labels.; For categorical labels, clicking on one of the items in the legend will hide/show all points with the corresponding label.; Note that using many different labelling schemes in the same plots, particularly if those labels contain many; different classes could slow down the plot interactions. Hovering on points will display their coordinates, labels and any additional fields specified in ``hover_fields``. Parameters; ----------; pvals : :class:`.NumericExpression`; List of x-values to be plotted.; label : :class:`.Expression` or Dict[str, :class:`.Expression`]]; Either a single expression (if a single label is desired), or a; dictionary of label name -> label value for x and y values.; Used to color each point w.r.t its label.; When multiple labels are given, a dropdown will be displayed with the different options.; Can be used with categorical or continuous expressions.; title : str, optional; Title of the scatterplot.; xla",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:47178,Log,LogColorMapper,47178,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,1,['Log'],['LogColorMapper']
Testability,"s:. Test; Field; Type; Value. Wald, LRT, Firth; fit.n_iterations; int32; number of iterations until; convergence, explosion, or; reaching the max (by default,; 25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; fit.converged; bool; True if iteration converged. Wald, LRT, Firth; fit.exploded; bool; True if iteration exploded. We consider iteration to have converged when every coordinate of; \(\beta\) changes by less than \(10^{-6}\) by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation.; A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of \(\beta\) under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests.; Here’s a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. Status; HomRef; Het; HomVar. Case; 1000; 10; 0. Control; 1000; 0; 0. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where x is genotype,; y is phenotype, and logistf is from t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:11203,test,testing,11203,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['testing']
Testability,"s; adjustment.; The fault flag is an integer indicating whether any issues occurred when; running the Davies algorithm to compute the p-value as the right tail of a; weighted sum of \(\chi^2(1)\) distributions. fault value; Description. 0; no issues. 1; accuracy NOT achieved. 2; round-off error possibly significant. 3; invalid parameters. 4; unable to locate integration parameters. 5; out of memory. Parameters:. key_expr (Expression) – Row-indexed expression for key associated to each row.; weight_expr (Float64Expression) – Row-indexed expression for row weights.; y (Float64Expression) – Column-indexed response expression.; If logistic is True, all non-missing values must evaluate to 0 or; 1. Note that a BooleanExpression will be implicitly converted; to a Float64Expression with this property.; x (Float64Expression) – Entry-indexed expression for input variable.; covariates (list of Float64Expression) – List of column-indexed covariate expressions.; logistic (bool or tuple of int and float) – If false, use the linear test. If true, use the logistic test with no; more than 25 logistic iterations and a convergence tolerance of 1e-6. If; a tuple is given, use the logistic test with the tuple elements as the; maximum nubmer of iterations and convergence tolerance, respectively.; max_size (int) – Maximum size of group on which to run the test.; accuracy (float) – Accuracy achieved by the Davies algorithm if fault value is zero.; iterations (int) – Maximum number of iterations attempted by the Davies algorithm. Returns:; Table – Table of SKAT results. hail.methods.lambda_gc(p_value, approximate=True)[source]; Compute genomic inflation factor (lambda GC) from an Expression of p-values. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. Parameters:. p_value (NumericExpression) – Row-indexed numeric expression of p-values.; approximate (bool) – If False, computes exact lambda GC (slower a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:82075,log,logistic,82075,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"s; else:; raise ValueError(f""'{method}/pass_through': found duplicated field {f!r}""); row_fields[f] = mt[f]; else:; assert isinstance(f, Expression); if not f._ir.is_nested_field:; raise ValueError(f""'{method}/pass_through': expect fields or nested fields, not complex expressions""); if not f._indices == mt._row_indices:; raise ExpressionException(; f""'{method}/pass_through': require row-indexed fields, found indices {f._indices.axes}""; ); name = f._ir.name; if name in row_fields:; # allow silent pass through of key fields; if not (name in mt.row_key and f._ir == mt[name]._ir):; raise ValueError(f""'{method}/pass_through': found duplicated field {name!r}""); row_fields[name] = f; for k in mt.row_key:; del row_fields[k]; return row_fields. [docs]@typecheck(; y=oneof(expr_float64, sequenceof(expr_float64), sequenceof(sequenceof(expr_float64))),; x=expr_float64,; covariates=sequenceof(expr_float64),; block_size=int,; pass_through=sequenceof(oneof(str, Expression)),; weights=nullable(oneof(expr_float64, sequenceof(expr_float64))),; ); def linear_regression_rows(y, x, covariates, block_size=16, pass_through=(), *, weights=None) -> Table:; r""""""For each row, test an input variable for association with; response variables using linear regression. Examples; --------. >>> result_ht = hl.linear_regression_rows(; ... y=dataset.pheno.height,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Warning; -------; As in the example, the intercept covariate ``1`` must be; included **explicitly** if desired. Warning; -------; If `y` is a single value or a list, :func:`.linear_regression_rows`; considers the same set of columns (i.e., samples, points) for every response; variable and row, namely those columns for which **all** response variables; and covariates are defined. If `y` is a list of lists, then each inner list is treated as an; independent group, subsetting columns for missingness separately. Notes; -----; With the default root a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:8322,test,test,8322,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"se ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowere",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:63654,test,test,63654,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,['test'],['test']
Testability,"se exclusive-or x and y.; Examples; >>> hl.eval(hl.bit_xor(5, 3)); 6. Notes; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_lshift(x, y)[source]; Bitwise left-shift x by y.; Examples; >>> hl.eval(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:; >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_rshift(x, y, logical=False)[source]; Bitwise right-shift x by y.; Examples; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With logical=False (default), the sign is preserved:; >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With logical=True, the sign bit is treated as any other:; >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; If logical is False, then the shift is a sign-preserving right shift.; If logical is True, then the shift is logical, with the sign bit; treated as any other bit.; See the Python wiki; for more information about bit operators. Parameters:. x (Int32Expression or Int64Expression); y (Int32Expression or Int64Expression); logical (bool). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_not(x)[source]; Bitwise invert x.; Examples; >>> hl.eval(hl.bit_not(0)); -1. Notes; See the Python wiki; for more information about bit operators. Parameters:; x (Int32Expression or Int64Expression). Returns:; Int32Expression or Int64Expression. hail.expr.functions.bit_count(x)[source];",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/numeric.html:5831,log,logical,5831,docs/0.2/functions/numeric.html,https://hail.is,https://hail.is/docs/0.2/functions/numeric.html,1,['log'],['logical']
Testability,"se,; append=False,; min_block_size=0,; branching_factor=50,; tmp_dir=None,; default_reference='GRCh37',; idempotent=False,; global_seed=None,; spark_conf=None,; skip_logging_configuration=False,; local_tmpdir=None,; _optimizer_iterations=None,; gcs_requester_pays_configuration: Optional[GCSRequesterPaysConfiguration] = None,; copy_log_on_error: bool = False,; ):; from hail.backend.py4j_backend import connect_logger; from hail.backend.spark_backend import SparkBackend. log = _get_log(log); tmpdir = _get_tmpdir(tmp_dir); local_tmpdir = _get_local_tmpdir(local_tmpdir); optimizer_iterations = get_env_or_default(_optimizer_iterations, 'HAIL_OPTIMIZER_ITERATIONS', 3). app_name = app_name or 'Hail'; (; gcs_requester_pays_project,; gcs_requester_pays_buckets,; ) = convert_gcs_requester_pays_configuration_to_hadoop_conf_style(; get_gcs_requester_pays_configuration(; gcs_requester_pays_configuration=gcs_requester_pays_configuration,; ); ); backend = SparkBackend(; idempotent,; sc,; spark_conf,; app_name,; master,; local,; log,; quiet,; append,; min_block_size,; branching_factor,; tmpdir,; local_tmpdir,; skip_logging_configuration,; optimizer_iterations,; gcs_requester_pays_project=gcs_requester_pays_project,; gcs_requester_pays_buckets=gcs_requester_pays_buckets,; copy_log_on_error=copy_log_on_error,; ); if not backend.fs.exists(tmpdir):; backend.fs.mkdir(tmpdir). HailContext.create(log, quiet, append, tmpdir, local_tmpdir, default_reference, global_seed, backend); if not quiet:; connect_logger(backend._utils_package_object, 'localhost', 12888). @typecheck(; billing_project=nullable(str),; remote_tmpdir=nullable(str),; log=nullable(str),; quiet=bool,; append=bool,; tmpdir=nullable(str),; local_tmpdir=nullable(str),; default_reference=enumeration(*BUILTIN_REFERENCES),; global_seed=nullable(int),; disable_progress_bar=nullable(bool),; driver_cores=nullable(oneof(str, int)),; driver_memory=nullable(str),; worker_cores=nullable(oneof(str, int)),; worker_memory=nullable(str),; name",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:15959,log,log,15959,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['log'],['log']
Testability,"se:; raise KeyError(get_nice_field_error(self, item)). def __getattribute__(self, item):; if item in super().__getattribute__('_warn_on_shadowed_name'):; warning(; f'Field {item} is shadowed by another method or attribute. '; f'Use [""{item}""] syntax to access the field.'; ); self._warn_on_shadowed_name.remove(item); return super().__getattribute__(item). def __getattr__(self, item):; raise AttributeError(get_nice_attr_error(self, item)). def __len__(self):; return len(self._fields). def __bool__(self):; return bool(len(self)). [docs] @typecheck_method(item=oneof(str, int, slice)); def __getitem__(self, item):; """"""Access a field of the struct by name or index. Examples; --------. >>> hl.eval(struct['a']); 5. >>> hl.eval(struct[1]); 'Foo'. Parameters; ----------; item : :class:`str`; Field name. Returns; -------; :class:`.Expression`; Struct field.; """"""; if isinstance(item, str):; return self._get_field(item); if isinstance(item, int):; return self._get_field(self.dtype.fields[item]); else:; assert item.start is None or isinstance(item.start, int); assert item.stop is None or isinstance(item.stop, int); assert item.step is None or isinstance(item.step, int); return self.select(*self.dtype.fields[item.start : item.stop : item.step]). def __iter__(self):; return iter(self._fields). def __contains__(self, item):; return item in self._fields. def __hash__(self):; return object.__hash__(self). [docs] def __eq__(self, other):; """"""Check each field for equality. Parameters; ----------; other : :class:`.Expression`; An expression of the same type.; """"""; return Expression.__eq__(self, other). [docs] def __ne__(self, other):; return Expression.__ne__(self, other). def __nonzero__(self):; return Expression.__nonzero__(self). def _annotate_ordered(self, insertions_dict, field_order):; def get_type(field):; e = insertions_dict.get(field); if e is None:; e = self._fields[field]; return e.dtype. new_type = hl.tstruct(**{f: get_type(f) for f in field_order}); indices, aggregations = u",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:45809,assert,assert,45809,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['assert'],['assert']
Testability,"se_zero(sample_id):; if sample_id is None:; return ""0""; return sample_id. line_list = [; sample_id_or_else_zero(self._fam_id),; self._s,; sample_id_or_else_zero(self._pat_id),; sample_id_or_else_zero(self._mat_id),; self._sex_as_numeric_string(),; ""0"",; ]; return ""\t"".join(line_list). [docs]class Pedigree(object):; """"""Class containing a list of trios, with extra functionality. :param trios: list of trio objects to include in pedigree; :type trios: list of :class:`.Trio`; """""". @typecheck_method(trios=sequenceof(Trio)); def __init__(self, trios):; self._trios = tuple(trios). def __eq__(self, other):; return isinstance(other, Pedigree) and self._trios == other._trios. def __hash__(self):; return hash(self._trios). def __iter__(self):; return self._trios.__iter__(). [docs] @classmethod; @typecheck_method(fam_path=str, delimiter=str); def read(cls, fam_path, delimiter='\\s+') -> 'Pedigree':; """"""Read a PLINK .fam file and return a pedigree object. **Examples**. >>> ped = hl.Pedigree.read('data/test.fam'). Notes; -------. See `PLINK .fam file <https://www.cog-genomics.org/plink2/formats#fam>`_ for; the required format. :param str fam_path: path to .fam file. :param str delimiter: Field delimiter. :rtype: :class:`.Pedigree`; """""". trios = []; missing_sex_count = 0; missing_sex_values = set(); with Env.fs().open(fam_path) as file:; for line in file:; split_line = re.split(delimiter, line.strip()); num_fields = len(split_line); if num_fields != 6:; raise FatalError(; ""Require 6 fields per line in .fam, but this line has {}: {}"".format(num_fields, line); ); (fam, kid, dad, mom, sex, _) = tuple(split_line); # 1 is male, 2 is female, 0 is unknown.; is_female = sex == ""2"" if sex in {'1', '2'} else None. if is_female is None:; missing_sex_count += 1; missing_sex_values.add(kid). trio = Trio(; kid,; fam if fam != ""0"" else None,; dad if dad != ""0"" else None,; mom if mom != ""0"" else None,; is_female,; ); trios.append(trio). only_ids = [trio.s for trio in trios]; duplicate_ids = [id fo",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html:4764,test,test,4764,docs/0.2/_modules/hail/genetics/pedigree.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html,2,['test'],['test']
Testability,"self._vdses[current_bin][self._branch_factor :]. remaining = self._branch_factor - len(files_to_merge); while self._num_vdses > 0 and remaining > 0:; current_bin = min(self._vdses); extra = self._vdses[current_bin][-remaining:]; if len(extra) == len(self._vdses[current_bin]):; del self._vdses[current_bin]; else:; self._vdses[current_bin] = self._vdses[current_bin][:-remaining]; files_to_merge = extra + files_to_merge; remaining = self._branch_factor - len(files_to_merge). new_n_samples = sum(f.n_samples for f in files_to_merge); info(f'VDS Combine (job {self._job_id}): merging {len(files_to_merge)} datasets with {new_n_samples} samples'). temp_path = self._temp_out_path(f'vds-combine_job{self._job_id}'); largest_vds = max(files_to_merge, key=lambda vds: vds.n_samples); vds = hl.vds.read_vds(; largest_vds.path,; _assert_reference_type=self._dataset_type.reference_type,; _assert_variant_type=self._dataset_type.variant_type,; _warn_no_ref_block_max_length=False,; ). interval_bin = floor(log(new_n_samples, self._branch_factor)); intervals = self.__intervals_cache.get(interval_bin). if intervals is None:; # we use the reference data since it generally has more rows than the variant data; intervals, _ = calculate_new_intervals(; vds.reference_data, self._target_records, os.path.join(temp_path, 'interval_checkpoint.ht'); ); self.__intervals_cache[interval_bin] = intervals. paths = [f.path for f in files_to_merge]; vdss = self._read_variant_datasets(paths, intervals); combined = combine_variant_datasets(vdss). if self.finished:; self._write_final(combined); return. new_path = os.path.join(temp_path, 'dataset.vds'); combined.write(new_path, overwrite=True, _codec_spec=FAST_CODEC_SPEC); new_bin = floor(log(new_n_samples, self._branch_factor)); # this ensures that we don't somehow stick a vds at the end of; # the same bin, ending up with a weird ordering issue; if new_bin <= original_bin:; new_bin = original_bin + 1; self._vdses[new_bin].append(VDSMetadata(path=new_path, n_sam",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html:16945,log,log,16945,docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,2,['log'],['log']
Testability,"ser_specified_rng_nonce = True; if global_seed is None:; if 'rng_nonce' not in backend.get_flags('rng_nonce'):; backend.set_flags(rng_nonce=hex(Random().randrange(-(2**63), 2**63 - 1))); self._user_specified_rng_nonce = False; else:; backend.set_flags(rng_nonce=hex(global_seed)); Env._hc = self. def initialize_references(self, default_reference):; assert self._backend; self._backend.initialize_references(); if default_reference in BUILTIN_REFERENCES:; self._default_ref = self._backend.get_reference(default_reference); else:; self._default_ref = ReferenceGenome.read(default_reference). @property; def default_reference(self) -> ReferenceGenome:; assert self._default_ref is not None, '_default_ref should have been initialized in HailContext.create'; return self._default_ref. @default_reference.setter; def default_reference(self, value):; if not isinstance(value, ReferenceGenome):; raise TypeError(f'{value} is {type(value)} not a ReferenceGenome'); self._default_ref = value. def stop(self):; assert self._backend; self._backend.stop(); self._backend = None; Env._hc = None; Env._dummy_table = None; Env._seed_generator = None; hail.ir.clear_session_functions(). [docs]@typecheck(; sc=nullable(SparkContext),; app_name=nullable(str),; master=nullable(str),; local=str,; log=nullable(str),; quiet=bool,; append=bool,; min_block_size=int,; branching_factor=int,; tmp_dir=nullable(str),; default_reference=nullable(enumeration(*BUILTIN_REFERENCES)),; idempotent=bool,; global_seed=nullable(int),; spark_conf=nullable(dictof(str, str)),; skip_logging_configuration=bool,; local_tmpdir=nullable(str),; _optimizer_iterations=nullable(int),; backend=nullable(enumeration(*BackendType.__args__)),; driver_cores=nullable(oneof(str, int)),; driver_memory=nullable(str),; worker_cores=nullable(oneof(str, int)),; worker_memory=nullable(str),; gcs_requester_pays_configuration=nullable(oneof(str, sized_tupleof(str, sequenceof(str)))),; regions=nullable(sequenceof(str)),; gcs_bucket_allow_list=nullabl",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:4728,assert,assert,4728,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['assert'],['assert']
Testability,"sert test == 'wald'; return ht.select(test_fit=test_fit, **wald_test(X, test_fit), **ht.pass_through).select_globals('null_fit'). def _poisson_fit(; X: NDArrayNumericExpression, # (N, K); y: NDArrayNumericExpression, # (N,); b: NDArrayNumericExpression, # (K,); mu: NDArrayNumericExpression, # (N,); score: NDArrayNumericExpression, # (K,); fisher: NDArrayNumericExpression, # (K, K); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Poisson(exp(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1; assert mu.ndim == 1; assert score.ndim == 1; assert fisher.ndim == 2. dtype = numerical_regression_fit_dtype; blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}). def fit(recur, iteration, b, mu, score, fisher):; def cont(exploded, delta_b, max_delta_b):; log_lkhd = y @ hl.log(mu) - mu.sum(). next_b = b + delta_b; next_mu = hl.exp(X @ next_b); next_score = X.T @ (y - next_mu); next_fisher = (next_mu * X.T) @ X. return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(; b=b,; score=score,; fisher=fisher,; mu=mu,; n_iterations=iteration,; log_lkhd=log_lkhd,; converged=True,; exploded=False,; ),; ); .when(; iteration == max_iterations,; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b, next_mu, next_score, next_fisher)); ). delta_b_struct = hl.nd.solve(fisher, score, no_crash=True). exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution; max_delta_b = nd_max(delta_b.map(lambda e: hl.abs(e))); return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_struct.select(n_iterations=0,",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:68462,log,log,68462,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['log']
Testability,"silon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid; function, the; genotype \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; \(\mathrm{isFemale}\) is coded as 1 for true (female) and; 0 for false (male). The null model sets \(\beta_1 = 0\).; The resulting variant annotations depend on the test statistic; as shown in the tables below. Test; Annotation; Type; Value. Wald; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). Wald; va.logreg.se; Double; estimated standard error, \(\widehat{\mathrm{se}}\). Wald; va.logreg.zstat; Double; Wald \(z\)-statistic, equal to \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; va.logreg.fit.converged; Boolean; true if iteration converged. Wald, LRT, Firth; va.logreg.fit.exploded; Boolean; true if iteration exploded. We consider iteration to have converged when every coordinate of \(\beta\) changes by less than \(10^{-6}\). For Wald and LRT, up to 25 iterations are attem",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:111575,log,logreg,111575,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logreg']
Testability,"sion of type t. hail.expr.functions.null(t)[source]; Deprecated in favor of missing().; Creates an expression representing a missing value of a specified type.; Examples; >>> hl.eval(hl.null(hl.tarray(hl.tstr))); None. >>> hl.eval(hl.null('array<str>')); None. Notes; This method is useful for constructing an expression that includes missing; values, since None cannot be interpreted as an expression. Parameters:; t (str or HailType) – Type of the missing expression. Returns:; Expression – A missing expression of type t. hail.expr.functions.str(x)[source]; Returns the string representation of x.; Examples; >>> hl.eval(hl.str(hl.struct(a=5, b=7))); '{""a"":5,""b"":7}'. Parameters:; x. Returns:; StringExpression. hail.expr.functions.is_missing(expression)[source]; Returns True if the argument is missing.; Examples; >>> hl.eval(hl.is_missing(5)); False. >>> hl.eval(hl.is_missing(hl.missing(hl.tstr))); True. >>> hl.eval(hl.is_missing(hl.missing(hl.tbool) & True)); True. Parameters:; expression – Expression to test. Returns:; BooleanExpression – True if expression is missing, False otherwise. hail.expr.functions.is_defined(expression)[source]; Returns True if the argument is not missing.; Examples; >>> hl.eval(hl.is_defined(5)); True. >>> hl.eval(hl.is_defined(hl.missing(hl.tstr))); False. >>> hl.eval(hl.is_defined(hl.missing(hl.tbool) & True)); False. Parameters:; expression – Expression to test. Returns:; BooleanExpression – True if expression is not missing, False otherwise. hail.expr.functions.coalesce(*args)[source]; Returns the first non-missing value of args.; Examples; >>> x1 = hl.missing('int'); >>> x2 = 2; >>> hl.eval(hl.coalesce(x1, x2)); 2. Notes; All arguments must have the same type, or must be convertible to a common; type (all numeric, for instance). See also; or_else(). Parameters:; args (variable-length args of Expression). Returns:; Expression. hail.expr.functions.or_else(a, b)[source]; If a is missing, return b.; Examples; >>> hl.eval(hl.or_else(5, 7)",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/core.html:8398,test,test,8398,docs/0.2/functions/core.html,https://hail.is,https://hail.is/docs/0.2/functions/core.html,1,['test'],['test']
Testability,"sion of type tfloat64) – Parameter of the F-distribution; lower_tail (bool or BooleanExpression) – If True, compute the probability of an outcome at or below x,; otherwise greater than x.; log_p (bool or BooleanExpression) – Return the natural logarithm of the probability. Returns:; Expression of type tfloat64. hail.expr.functions.ppois(x, lamb, lower_tail=True, log_p=False)[source]; The cumulative probability function of a Poisson distribution.; Examples; >>> hl.eval(hl.ppois(2, 1)); 0.9196986029286058. Notes; If lower_tail is true, returns Prob(\(X \leq\) x) where \(X\) is a; Poisson random variable with rate parameter lamb. If lower_tail is false,; returns Prob(\(X\) > x). Parameters:. x (float or Expression of type tfloat64); lamb (float or Expression of type tfloat64) – Rate parameter of Poisson distribution.; lower_tail (bool or BooleanExpression) – If True, compute the probability of an outcome at or below x,; otherwise greater than x.; log_p (bool or BooleanExpression) – Return the natural logarithm of the probability. Returns:; Expression of type tfloat64. hail.expr.functions.qchisqtail(p, df, ncp=None, lower_tail=False, log_p=False)[source]; The quantile function of a chi-squared distribution with df degrees of; freedom, inverts pchisqtail().; Examples; >>> hl.eval(hl.qchisqtail(0.05, 2)); 5.991464547107979. >>> hl.eval(hl.qchisqtail(0.05, 2, ncp=2)); 10.838131614372958. >>> hl.eval(hl.qchisqtail(0.05, 2, lower_tail=True)); 0.10258658877510107. >>> hl.eval(hl.qchisqtail(hl.log(0.05), 2, log_p=True)); 5.991464547107979. Notes; Returns right-quantile x for which p = Prob(\(Z^2\) > x) with; \(Z^2\) a chi-squared random variable with degrees of freedom specified; by df. The probability p must satisfy 0 < p < 1. Parameters:. p (float or Expression of type tfloat64) – Probability.; df (float or Expression of type tfloat64) – Degrees of freedom.; ncp (float or Expression of type tfloat64) – Corresponds to ncp parameter in pchisqtail().; lower_tail (bool or Bool",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:24875,log,logarithm,24875,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['log'],['logarithm']
Testability,"sion.; use_dosages (bool) – If true, use genotype dosage rather than hard call. Returns:Variant dataset with logistic regression variant annotations. Return type:VariantDataset. logreg_burden(key_name, variant_keys, single_key, agg_expr, test, y, covariates=[])[source]¶; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Run a gene burden test using the logistic Wald test on the maximum genotype per gene. Here va.genes is; a variant annotation of type Set[String] giving the set of genes containing the variant; (see Extended example in linreg_burden() for a deeper dive in the context of linear regression):; >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.genes',; ... single_key=False,; ... agg_expr='gs.map(g => g.gt).max()',; ... test='wald',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). Run a gene burden test using the logistic score test on the weighted sum of genotypes per gene.; Here va.gene is a variant annotation of type String giving a single gene per variant (or no gene if; missing), and va.weight is a numeric variant annotation:; >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.gene',; ... single_key=True,; ... agg_expr='gs.map(g => va.weight * g.gt).sum()',; ... test='score',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). To use a weighted sum of genotypes with missing genotypes mean-imputed rather than ignored, set; agg_expr='gs.map(g => va.weight * orElse(g.gt.toDouble, 2 * va.qc.AF)).sum()' where va.qc.AF; is the allele frequency over those samples that have no missing phenotype or covariates. Caution; With single_key=False, variant_keys expects a variant annotati",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:117965,test,test,117965,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"sion:; ((xmin, xmax), (ymin, ymax)). All values outside of this range will be considered outliers; and not tallied in the histogram. If this value is None, or either of the inner lists is None,; the range will be computed from the data.; width : int; Plot width (default 600px).; height : int; Plot height (default 600px).; title : str; Title of the plot.; colors : Sequence[str]; List of colors (hex codes, or strings as described; `here <https://bokeh.pydata.org/en/latest/docs/reference/colors.html>`__). Compatible with one of the many; built-in palettes available `here <https://bokeh.pydata.org/en/latest/docs/reference/palettes.html>`__.; log : bool; Plot the log10 of the bin counts. Returns; -------; :class:`bokeh.plotting.figure`; """"""; data = _generate_hist2d_data(x, y, bins, range).to_pandas(). # Use python prettier float -> str function; data['x'] = data['x'].apply(lambda e: str(float(e))); data['y'] = data['y'].apply(lambda e: str(float(e))). mapper: ColorMapper; if log:; mapper = LogColorMapper(palette=colors, low=data.c.min(), high=data.c.max()); else:; mapper = LinearColorMapper(palette=colors, low=data.c.min(), high=data.c.max()). x_axis = sorted(set(data.x), key=lambda z: float(z)); y_axis = sorted(set(data.y), key=lambda z: float(z)); p = figure(; title=title,; x_range=x_axis,; y_range=y_axis,; x_axis_location=""above"",; width=width,; height=height,; tools=""hover,save,pan,box_zoom,reset,wheel_zoom"",; toolbar_location='below',; ). p.grid.grid_line_color = None; p.axis.axis_line_color = None; p.axis.major_tick_line_color = None; p.axis.major_label_standoff = 0; import math. p.xaxis.major_label_orientation = math.pi / 3. p.rect(; x='x', y='y', width=1, height=1, source=data, fill_color={'field': 'c', 'transform': mapper}, line_color=None; ). color_bar = ColorBar(; color_mapper=mapper,; ticker=LogTicker(desired_num_ticks=len(colors)) if log else BasicTicker(desired_num_ticks=len(colors)),; label_standoff=12 if log else 6,; border_line_color=None,; location=(0, ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:19074,log,log,19074,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,3,"['Log', 'log']","['LogColorMapper', 'log']"
Testability,"sources. Hail. Docs »; Python API »; HailContext. View page source. HailContext¶. class hail.HailContext(sc=None, app_name='Hail', master=None, local='local[*]', log='hail.log', quiet=False, append=False, parquet_compression='snappy', min_block_size=1, branching_factor=50, tmp_dir='/tmp')[source]¶; The main entry point for Hail functionality. Warning; Only one Hail context may be running in a Python session at any time. If you; need to reconfigure settings, restart the Python session or use the HailContext.stop() method.; If passing in a Spark context, ensure that the configuration parameters spark.sql.files.openCostInBytes; and spark.sql.files.maxPartitionBytes are set to as least 50GB. Parameters:; sc (pyspark.SparkContext) – Spark context, one will be created if None.; appName – Spark application identifier.; master – Spark cluster master.; local – Local resources to use.; log – Log path.; quiet (bool) – Don’t write logging information to standard error.; append – Write to end of log file instead of overwriting.; parquet_compression – Level of on-disk annotation compression.; min_block_size – Minimum file split size in MB.; branching_factor – Branching factor for tree aggregation.; tmp_dir – Temporary directory for file merging. Variables:sc (pyspark.SparkContext) – Spark context. Attributes. version; Return the version of Hail associated with this HailContext. Methods. __init__; x.__init__(…) initializes x; see help(type(x)) for signature. balding_nichols_model; Simulate a variant dataset using the Balding-Nichols model. eval_expr; Evaluate an expression. eval_expr_typed; Evaluate an expression and return the result as well as its type. get_running; Return the running Hail context in this Python session. grep; Grep big files, like, really fast. import_bgen; Import .bgen file(s) as variant dataset. import_gen; Import .gen file(s) as variant dataset. import_plink; Import PLINK binary file (BED, BIM, FAM) as variant dataset. import_table; Import delimited text file ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.HailContext.html:1323,log,log,1323,docs/0.1/hail.HailContext.html,https://hail.is,https://hail.is/docs/0.1/hail.HailContext.html,1,['log'],['log']
Testability,"specified.; block_size (int, optional) – Block size. Default given by BlockMatrix.default_block_size(). Returns:; Table – Table keyed by locus_expr with LD scores for each variant and; annotation_expr. The function will always return LD scores for; the univariate (all SNPs) annotation. hail.experimental.ld_score_regression(weight_expr, ld_score_expr, chi_sq_exprs, n_samples_exprs, n_blocks=200, two_step_threshold=30, n_reference_panel_variants=None)[source]; Estimate SNP-heritability and level of confounding biases from genome-wide association study; (GWAS) summary statistics.; Given a set or multiple sets of GWAS summary statistics, ld_score_regression() estimates the heritability; of a trait or set of traits and the level of confounding biases present in; the underlying studies by regressing chi-squared statistics on LD scores,; leveraging the model:. \[\mathrm{E}[\chi_j^2] = 1 + Na + \frac{Nh_g^2}{M}l_j\]. \(\mathrm{E}[\chi_j^2]\) is the expected chi-squared statistic; for variant \(j\) resulting from a test of association between; variant \(j\) and a trait.; \(l_j = \sum_{k} r_{jk}^2\) is the LD score of variant; \(j\), calculated as the sum of squared correlation coefficients; between variant \(j\) and nearby variants. See ld_score(); for further details.; \(a\) captures the contribution of confounding biases, such as; cryptic relatedness and uncontrolled population structure, to the; association test statistic.; \(h_g^2\) is the SNP-heritability, or the proportion of variation; in the trait explained by the effects of variants included in the; regression model above.; \(M\) is the number of variants used to estimate \(h_g^2\).; \(N\) is the number of samples in the underlying association study. For more details on the method implemented in this function, see:. LD Score regression distinguishes confounding from polygenicity in genome-wide association studies (Bulik-Sullivan et al, 2015). Examples; Run the method on a matrix table of summary statistics, where th",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/experimental/index.html:8854,test,test,8854,docs/0.2/experimental/index.html,https://hail.is,https://hail.is/docs/0.2/experimental/index.html,1,['test'],['test']
Testability,"ss charges as well as improve latency.; Examples; Require the job to run in ‘us-central1’:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.regions(['us-central1']); ... .command(f'echo ""hello""')). Specify the job can run in any region:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.regions(None); ... .command(f'echo ""hello""')). Parameters:; regions (Optional[List[str]]) – The cloud region(s) to run this job in. Use None to signify; the job can run in any available region. Use py:staticmethod:.ServiceBackend.supported_regions; to list the available regions to choose from. The default is the job can run in; any region. Return type:; Self. Returns:; Same job object with the cloud regions the job can run in set. spot(is_spot); Set whether a job is run on spot instances. By default, all jobs run on spot instances.; Examples; Ensure a job only runs on non-spot instances:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> j = j.spot(False); >>> j = j.command(f'echo ""hello""'). Parameters:; is_spot (bool) – If False, this job will be run on non-spot instances. Return type:; Self. Returns:; Same job object. storage(storage); Set the job’s storage size.; Examples; Set the job’s disk requirements to 10 Gi:; >>> b = Batch(); >>> j = b.new_job(); >>> (j.storage('10Gi'); ... .command(f'echo ""hello""')); >>> b.run(). Notes; The storage expression must be of the form {number}{suffix}; where valid optional suffixes are K, Ki, M, Mi,; G, Gi, T, Ti, P, and Pi. Omitting a suffix means; the value is in bytes.; For the ServiceBackend, jobs requesting one or more cores receive; 5 GiB of storage for the root file system /. Jobs requesting a fraction of a core; receive the same fraction of 5 GiB of storage. If you need additional storage, you; can explicitly request more storage using this method and the extra storage space; will be mounted at /io. Batch automatically writes all ResourceFil",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html:7813,test,test,7813,docs/batch/api/batch/hailtop.batch.job.Job.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html,2,['test'],['test']
Testability,"ss than or equal to `x`. Examples; --------. >>> hl.eval(hl.floor(3.1)); 3.0. Parameters; ----------; x : :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`; """"""; return _func(""floor"", x.dtype, x). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def ceil(x):; """"""The smallest integral value that is greater than or equal to `x`. Examples; --------. >>> hl.eval(hl.ceil(3.1)); 4.0. Parameters; ----------; x : :class:`.Float32Expression`,:class:`.Float64Expression` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`; """"""; return _func(""ceil"", x.dtype, x). [docs]@typecheck(n_hom_ref=expr_int32, n_het=expr_int32, n_hom_var=expr_int32, one_sided=expr_bool); def hardy_weinberg_test(n_hom_ref, n_het, n_hom_var, one_sided=False) -> StructExpression:; """"""Performs test of Hardy-Weinberg equilibrium. Examples; --------. >>> hl.eval(hl.hardy_weinberg_test(250, 500, 250)); Struct(het_freq_hwe=0.5002501250625313, p_value=0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; -----; By default, this method performs a two-sided exact test with mid-p-value correction of; `Hardy-Weinberg equilibrium <https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle>`__; via an efficient implementation of the; `Levene-Haldane distribution <../_static/LeveneHaldane.pdf>`__,; which models the number of heterozygous individuals under equilibrium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:33816,test,test,33816,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"ss:`.Expression` of type :py:data:`.tfloat64`; Poisson rate parameter. Must be non-negative.; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The (log) probability density.; """"""; return _func(""dpois"", tfloat64, x, lamb, log_p). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def exp(x) -> Float64Expression:; """"""Computes `e` raised to the power `x`. Examples; --------. >>> hl.eval(hl.exp(2)); 7.38905609893065. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""exp"", tfloat64, x). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def fisher_exact_test(c1, c2, c3, c4) -> StructExpression:; """"""Calculates the p-value, odds ratio, and 95% confidence interval using; Fisher's exact test for a 2x2 table. Examples; --------. >>> hl.eval(hl.fisher_exact_test(10, 10, 10, 10)); Struct(p_value=1.0000000000000002, odds_ratio=1.0,; ci_95_lower=0.24385796914260355, ci_95_upper=4.100747675033819). >>> hl.eval(hl.fisher_exact_test(51, 43, 22, 92)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967,; ci_95_lower=2.5659373368248444, ci_95_upper=9.677929632035475). Notes; -----; This method is identical to the version implemented in; `R <https://stat.ethz.ch/R-manual/R-devel/library/stats/html/fisher.test.html>`_ with default; parameters (two-sided, alpha = 0.05, null hypothesis that the odds ratio equals 1). Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expre",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:31116,test,test,31116,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"ssed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ------",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:12156,assert,assert,12156,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,4,['assert'],['assert']
Testability,"ssing covariate.; y_residual : tint32, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alone.; s2 : tfloat64, the variance of the residuals, \(\sigma^2\) in the paper.; null_fit:. b : tndarray vector of coefficients.; score : tndarray vector of score statistics.; fisher : tndarray matrix of fisher statistics.; mu : tndarray the expected value under the null model.; n_iterations : tint32 the number of iterations before termination.; log_lkhd : tfloat64 the log-likelihood of the final iteration.; converged : tbool True if the null model converged.; exploded : tbool True if the null model failed to converge due to numerical; explosion. hail.methods.skat(key_expr, weight_expr, y, x, covariates, logistic=False, max_size=46340, accuracy=1e-06, iterations=10000)[source]; Test each keyed group of rows for association by linear or logistic; SKAT test.; Examples; Test each gene for association using the linear sequence kernel association; test:; >>> skat_table = hl.skat(key_expr=burden_ds.gene,; ... weight_expr=burden_ds.weight,; ... y=burden_ds.burden.pheno,; ... x=burden_ds.GT.n_alt_alleles(),; ... covariates=[1, burden_ds.burden.cov1, burden_ds.burden.cov2]). Caution; By default, the Davies algorithm iterates up to 10k times until an; accuracy of 1e-6 is achieved. Hence a reported p-value of zero with no; issues may truly be as large as 1e-6. The accuracy and maximum number of; iterations may be controlled by the corresponding function parameters.; In general, higher accuracy requires more iterations. Caution; To process a group with \(m\) rows, several copies of an; \(m \times m\) matrix of doubles must fit in worker memory. Groups; with tens of thousands of rows may exhaust worker memory causing the; entire job to fail. In this case, use the max_size parameter to skip; groups larger than max_size. Warning; skat() considers the same set of columns (i.e., samples, points) for; every gro",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:78168,test,test,78168,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['test'],['test']
Testability,"ssing: Specify identifier to be treated as missing; ; :param types: Define types of fields in annotations files ; :type types: dict with str keys and :py:class:`.Type` values; ; :return: Key table constructed from text table.; :rtype: :class:`.KeyTable`. :param quote: Quote character; :type quote: str or None; """""". key = wrap_to_list(key); paths = wrap_to_list(paths); jtypes = {k: v._jtype for k, v in types.items()}. jkt = self._jhc.importTable(paths, key, min_partitions, jtypes, comment, delimiter, missing,; no_header, impute, quote); return KeyTable(self, jkt). [docs] @handle_py4j; @typecheck_method(bed=strlike,; bim=strlike,; fam=strlike,; min_partitions=nullable(integral),; delimiter=strlike,; missing=strlike,; quantpheno=bool); def import_plink(self, bed, bim, fam, min_partitions=None, delimiter='\\\\s+', missing='NA', quantpheno=False):; """"""Import PLINK binary file (BED, BIM, FAM) as variant dataset. **Examples**. Import data from a PLINK binary file:. >>> vds = hc.import_plink(bed=""data/test.bed"",; ... bim=""data/test.bim"",; ... fam=""data/test.fam""). **Notes**. Only binary SNP-major mode files can be read into Hail. To convert your file from individual-major mode to SNP-major mode, use PLINK to read in your fileset and use the ``--make-bed`` option. The centiMorgan position is not currently used in Hail (Column 3 in BIM file). The ID (``s``) used by Hail is the individual ID (column 2 in FAM file). .. warning::. No duplicate individual IDs are allowed. Chromosome names (Column 1) are automatically converted in the following cases:. - 23 => ""X""; - 24 => ""Y""; - 25 => ""X""; - 26 => ""MT"". **Annotations**. :py:meth:`~hail.HailContext.import_plink` adds the following annotations:. - **va.rsid** (*String*) -- Column 2 in the BIM file.; - **sa.famID** (*String*) -- Column 1 in the FAM file. Set to missing if ID equals ""0"".; - **sa.patID** (*String*) -- Column 3 in the FAM file. Set to missing if ID equals ""0"".; - **sa.matID** (*String*) -- Column 4 in the FAM file. Set",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/context.html:16536,test,test,16536,docs/0.1/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/context.html,1,['test'],['test']
Testability,"ssion) – Condition to test.; consequent (Expression) – Branch to return if the condition is True.; alternate (Expression) – Branch to return if the condition is False.; missing_false (bool) – If True, treat missing condition as False. See also; case(), switch(), if_else(). Returns:; Expression – One of consequent, alternate, or missing, based on condition. hail.expr.functions.if_else(condition, consequent, alternate, missing_false=False)[source]; Expression for an if/else statement; tests a condition and returns one of two options based on the result.; Examples; >>> x = 5; >>> hl.eval(hl.if_else(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.if_else(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; If condition evaluates to True, returns consequent. If condition; evaluates to False, returns alternate. If predicate is missing, returns; missing. Note; The type of consequent and alternate must be the same. Parameters:. condition (BooleanExpression) – Condition to test.; consequent (Expression) – Branch to return if the condition is True.; alternate (Expression) – Branch to return if the condition is False.; missing_false (bool) – If True, treat missing condition as False. See also; case(), switch(). Returns:; Expression – One of consequent, alternate, or missing, based on condition. hail.expr.functions.switch(expr)[source]; Build a conditional tree on the value of an expression.; Examples; >>> csq = hl.literal('loss of function'); >>> expr = (hl.switch(csq); ... .when('synonymous', 1); ... .when('SYN', 1); ... .when('missense', 2); ... .when('MIS', 2); ... .when('loss of function', 3); ... .when('LOF', 3); ... .or_missing()); >>> hl.eval(expr); 3. See also; SwitchBuilder, case(), cond(). Parameters:; expr (Expression) – Value to match against. Returns:; SwitchBuilder. hail.expr.functions.case(missing_false=False)[source]; Chain multiple if-else statements with a CaseBuilder.; Examples; >>> x = hl.literal('foo bar baz'); >>",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/core.html:4651,test,test,4651,docs/0.2/functions/core.html,https://hail.is,https://hail.is/docs/0.2/functions/core.html,1,['test'],['test']
Testability,"ssion. Returns:; BooleanExpression. – True if f returns True for every element, False otherwise. any(f); Returns True if f returns True for any element.; Examples; >>> hl.eval(a.any(lambda x: x % 2 == 0)); True. >>> hl.eval(s3.any(lambda x: x[0] == 'D')); False. Notes; This method always returns False for empty collections. Parameters:; f (function ( (arg) -> BooleanExpression)) – Function to evaluate for each element of the collection. Must return a; BooleanExpression. Returns:; BooleanExpression. – True if f returns True for any element, False otherwise. collect(_localize=True); Collect all records of an expression into a local list.; Examples; Collect all the values from C1:; >>> table1.C1.collect(); [2, 2, 10, 11]. Warning; Extremely experimental. Warning; The list of records may be very large. Returns:; list. contains(item)[source]; Returns True if item is in the set.; Examples; >>> hl.eval(s1.contains(1)); True. >>> hl.eval(s1.contains(10)); False. Parameters:; item (Expression) – Value for inclusion test. Returns:; BooleanExpression – True if item is in the set. describe(handler=<built-in function print>); Print information about type, index, and dependencies. difference(s)[source]; Return the set of elements in the set that are not present in set s.; Examples; >>> hl.eval(s1.difference(s2)); {2}. >>> hl.eval(s2.difference(s1)); {5}. Parameters:; s (SetExpression) – Set expression of the same type. Returns:; SetExpression – Set of elements not in s. property dtype; The data type of the expression. Returns:; HailType. export(path, delimiter='\t', missing='NA', header=True); Export a field to a text file.; Examples; >>> small_mt.GT.export('output/gt.tsv'); >>> with open('output/gt.tsv', 'r') as f:; ... for line in f:; ... print(line, end=''); locus alleles 0 1 2 3; 1:1 [""A"",""C""] 0/1 0/0 0/1 0/0; 1:2 [""A"",""C""] 1/1 0/1 0/1 0/1; 1:3 [""A"",""C""] 0/0 0/1 0/0 0/0; 1:4 [""A"",""C""] 0/1 1/1 0/1 0/1. >>> small_mt.GT.export('output/gt-no-header.tsv', header=False); >>> ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.SetExpression.html:5802,test,test,5802,docs/0.2/hail.expr.SetExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.SetExpression.html,1,['test'],['test']
Testability,"st of variants.; :rtype: list of Variant; """"""; jvars = self._jldm.variants(); return list(map(lambda jrep: Variant._from_java(jrep), jvars)). [docs] def matrix(self):; """"""; Gets the distributed matrix backing this LD matrix. :return: Matrix of Pearson correlation values.; :rtype: `IndexedRowMatrix <https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.distributed.IndexedRowMatrix>`__; """"""; from pyspark.mllib.linalg.distributed import IndexedRowMatrix. return IndexedRowMatrix(self._jldm.matrix()). [docs] def to_local_matrix(self):; """"""; Converts the LD matrix to a local Spark matrix.; ; .. caution::; ; Only call this method when the LD matrix is small enough to fit in local memory on the driver. ; ; :return: Matrix of Pearson correlation values.; :rtype: `Matrix <https://spark.apache.org/docs/2.1.0/api/python/pyspark.mllib.html#pyspark.mllib.linalg.Matrix>`__; """"""; from pyspark.mllib.linalg import DenseMatrix. j_local_mat = self._jldm.toLocalMatrix(); assert j_local_mat.majorStride() == j_local_mat.rows(); assert j_local_mat.offset() == 0; assert j_local_mat.isTranspose() == False; return DenseMatrix(j_local_mat.rows(), j_local_mat.cols(), list(j_local_mat.data()), False). [docs] def write(self, path):; """"""; Writes the LD matrix to a file. **Examples**. Write an LD matrix to a file. >>> vds.ld_matrix().write('output/ld_matrix'). :param path: the path to which to write the LD matrix; :type path: str; """""". self._jldm.write(path). [docs] @staticmethod; def read(path):; """"""; Reads the LD matrix from a file. **Examples**. Read an LD matrix from a file. >>> ld_matrix = LDMatrix.read('data/ld_matrix'). :param path: the path from which to read the LD matrix; :type path: str; """""". jldm = Env.hail().methods.LDMatrix.read(Env.hc()._jhc, path); return LDMatrix(jldm). [docs] @typecheck_method(path=strlike,; column_delimiter=strlike,; header=nullable(strlike),; parallel_write=bool,; entries=enumeration('full', 'lower', 'strict_lower', 'upper', 'st",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/ldMatrix.html:1792,assert,assert,1792,docs/0.1/_modules/hail/ldMatrix.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/ldMatrix.html,1,['assert'],['assert']
Testability,"st; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; GTEx_sQTL_Pancreas_all_snp_gene_associations. View page source. GTEx_sQTL_Pancreas_all_snp_gene_associations. Versions: v8; Reference genome builds: GRCh38; Type: hail.Table. Schema (v8, GRCh38); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; version: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'phenotype_id': struct {; intron: interval<locus<GRCh38>>,; cluster: str,; gene_id: str; }; 'tss_distance': int32; 'ma_samples': int32; 'ma_count': int32; 'maf': float64; 'pval_nominal': float64; 'slope': float64; 'slope_se': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pancreas_all_snp_gene_associations.html:8810,Log,Log,8810,docs/0.2/datasets/schemas/GTEx_sQTL_Pancreas_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pancreas_all_snp_gene_associations.html,1,['Log'],['Log']
Testability,"st; gnomad_ld_variant_indices_fin; gnomad_ld_variant_indices_nfe; gnomad_ld_variant_indices_nwe; gnomad_ld_variant_indices_seu; gnomad_lof_metrics; gnomad_mnv_genome_d01; gnomad_mnv_genome_d02; gnomad_mnv_genome_d03; gnomad_mnv_genome_d04; gnomad_mnv_genome_d05; gnomad_mnv_genome_d06; gnomad_mnv_genome_d07; gnomad_mnv_genome_d08; gnomad_mnv_genome_d09; gnomad_mnv_genome_d10; gnomad_pca_variant_loadings; gnomad_plof_metrics_gene; gnomad_plof_metrics_transcript; gnomad_variant_co-occurrence; ldsc_baselineLD_annotations; ldsc_baselineLD_ldscores; panukb_ld_scores_AFR; panukb_ld_scores_AMR; panukb_ld_scores_CSA; panukb_ld_scores_EAS; panukb_ld_scores_EUR; panukb_ld_scores_MID; panukb_ld_variant_indices_AFR; panukb_ld_variant_indices_AMR; panukb_ld_variant_indices_CSA; panukb_ld_variant_indices_EAS; panukb_ld_variant_indices_EUR; panukb_ld_variant_indices_MID; panukb_meta_analysis_all_ancestries; panukb_meta_analysis_high_quality; panukb_summary_stats. Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Datasets; Schemas; GTEx_sQTL_Prostate_all_snp_gene_associations. View page source. GTEx_sQTL_Prostate_all_snp_gene_associations. Versions: v8; Reference genome builds: GRCh38; Type: hail.Table. Schema (v8, GRCh38); ----------------------------------------; Global fields:; 'metadata': struct {; name: str,; version: str,; reference_genome: str,; n_rows: int32,; n_partitions: int32; }; ----------------------------------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'phenotype_id': struct {; intron: interval<locus<GRCh38>>,; cluster: str,; gene_id: str; }; 'tss_distance': int32; 'ma_samples': int32; 'ma_count': int32; 'maf': float64; 'pval_nominal': float64; 'slope': float64; 'slope_se': float64; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Prostate_all_snp_gene_associations.html:8810,Log,Log,8810,docs/0.2/datasets/schemas/GTEx_sQTL_Prostate_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Prostate_all_snp_gene_associations.html,1,['Log'],['Log']
Testability,"stderr=sp.STDOUT); except sp.CalledProcessError as e:; print(e.output); raise e. def hl_plural(orig, n, alternate=None):; if alternate is None:; plural = orig + 's'; else:; plural = alternate; return hl.if_else(n == 1, orig, plural). def plural(orig, n, alternate=None):; if n == 1:; return orig; elif alternate:; return alternate; else:; return orig + 's'. def get_obj_metadata(obj):; from hail.expr.expressions import ArrayStructExpression, SetStructExpression, StructExpression; from hail.matrixtable import GroupedMatrixTable, MatrixTable; from hail.table import GroupedTable, Table; from hail.utils import Struct. def table_error(index_obj):; def fmt_field(field):; assert field in index_obj._fields; inds = index_obj[field]._indices; if inds == index_obj._global_indices:; return ""'{}' [globals]"".format(field); elif inds == index_obj._row_indices:; return ""'{}' [row]"".format(field); elif inds == index_obj._col_indices: # Table will never get here; return ""'{}' [col]"".format(field); else:; assert inds == index_obj._entry_indices; return ""'{}' [entry]"".format(field). return fmt_field. def struct_error(s):; def fmt_field(field):; assert field in s._fields; return ""'{}'"".format(field). return fmt_field. if isinstance(obj, MatrixTable):; return 'MatrixTable', MatrixTable, table_error(obj), True; elif isinstance(obj, GroupedMatrixTable):; return 'GroupedMatrixTable', GroupedMatrixTable, table_error(obj._parent), True; elif isinstance(obj, Table):; return 'Table', Table, table_error(obj), True; elif isinstance(obj, GroupedTable):; return 'GroupedTable', GroupedTable, table_error(obj), False; elif isinstance(obj, Struct):; return 'Struct', Struct, struct_error(obj), False; elif isinstance(obj, StructExpression):; return 'StructExpression', StructExpression, struct_error(obj), True; elif isinstance(obj, ArrayStructExpression):; return 'ArrayStructExpression', ArrayStructExpression, struct_error(obj), True; elif isinstance(obj, SetStructExpression):; return 'SetStructExpression', S",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/misc.html:6606,assert,assert,6606,docs/0.2/_modules/hail/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/misc.html,2,['assert'],['assert']
Testability,"step >= 0, 0, -1); if stop is not None:; slice_ir = ir.ArraySlice(self._ir, start._ir, stop._ir, step._ir); else:; slice_ir = ir.ArraySlice(self._ir, start._ir, stop, step._ir). return construct_expr(slice_ir, self.dtype, indices, aggregations). [docs] @typecheck_method(f=func_spec(1, expr_any)); def aggregate(self, f):; """"""Uses the aggregator library to compute a summary from an array. This method is useful for accessing functionality that exists in the aggregator library; but not the basic expression library, for instance, :func:`.call_stats`. Parameters; ----------; f; Aggregation function. Returns; -------; :class:`.Expression`; """"""; return hl.agg._aggregate_local_array(self, f). [docs] @typecheck_method(item=expr_any); def contains(self, item):; """"""Returns a boolean indicating whether `item` is found in the array. Examples; --------. >>> hl.eval(names.contains('Charlie')); True. >>> hl.eval(names.contains('Helen')); False. Parameters; ----------; item : :class:`.Expression`; Item for inclusion test. Warning; -------; This method takes time proportional to the length of the array. If a; pipeline uses this method on the same array several times, it may be; more efficient to convert the array to a set first early in the script; (:func:`~hail.expr.functions.set`). Returns; -------; :class:`.BooleanExpression`; ``True`` if the element is found in the array, ``False`` otherwise.; """"""; return self._method(""contains"", tbool, item). [docs] @deprecated(version=""0.2.58"", reason=""Replaced by first""); def head(self):; """"""Deprecated in favor of :meth:`~.ArrayExpression.first`. Returns the first element of the array, or missing if empty. Returns; -------; :class:`.Expression`; Element. Examples; --------; >>> hl.eval(names.head()); 'Alice'. If the array has no elements, then the result is missing:. >>> hl.eval(names.filter(lambda x: x.startswith('D')).head()); None; """"""; return self.first(). [docs] def first(self):; """"""Returns the first element of the array, or missing if empt",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:13829,test,test,13829,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['test'],['test']
Testability,"stic sequence kernel association test (SKAT).; Logistic SKAT tests if the phenotype, y, is significantly associated with the genotype,; x. For \(N\) samples, in a group of \(M\) variants, with \(K\) covariates, the; model is given by:. \[\begin{align*}; X &: R^{N \times K} \\; G &: \{0, 1, 2\}^{N \times M} \\; \\; Y &\sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_0 X + \beta_1 G)); \end{align*}\]; The usual null hypothesis is \(\beta_1 = 0\). SKAT tests for an association, but does not; provide an effect size or other information about the association.; Wu et al. argue that, under the null hypothesis, a particular value, \(Q\), is distributed; according to a generalized chi-squared distribution with parameters determined by the genotypes,; weights, and residual phenotypes. The SKAT p-value is the probability of drawing even larger; values of \(Q\). If \(\widehat{\beta_\textrm{null}}\) is the best-fit beta under the; null model:. \[Y \sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_\textrm{null} X))\]; Then \(Q\) is defined by Wu et al. as:. \[\begin{align*}; p_i &= \textrm{logit}^{-1}(\widehat{\beta_\textrm{null}} X) \\; r_i &= y_i - p_i \\; W_{ii} &= w_i \\; \\; Q &= r^T G W G^T r; \end{align*}\]; Therefore \(r_i\), the residual phenotype, is the portion of the phenotype unexplained by; the covariates alone. Also notice:. Each sample’s phenotype is Bernoulli distributed with mean \(p_i\) and variance; \(\sigma^2_i = p_i(1 - p_i)\), the binomial variance.; \(G W G^T\), is a symmetric positive-definite matrix when the weights are non-negative. We describe below our interpretation of the mathematics as described in the main body and; appendix of Wu, et al. According to the paper, the distribution of \(Q\) is given by a; generalized chi-squared distribution whose weights are the eigenvalues of a symmetric matrix; which we call \(Z Z^T\):. \[\begin{align*}; V_{ii} &= \sigma^2_i \\; W_{ii} &= w_i \quad\quad \textrm{the weight for variant } i \\; \\; P_0 &= V - V X (X",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:69022,log,logit,69022,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['log'],['logit']
Testability,"stment of genetic correlation parameters; to allow for the joint simulation of up to 100 randomly; correlated phenotypes.; - Methods for binarizing phenotypes to have a certain prevalence; and for adding ascertainment bias to binarized phenotypes. @author: nbaya; """""". import numpy as np; import pandas as pd; from scipy import stats. import hail as hl; from hail.expr.expressions import expr_array, expr_call, expr_float64, expr_int32; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import nullable, oneof, typecheck; from hail.utils.java import Env. [docs]@typecheck(; mt=MatrixTable,; genotype=oneof(expr_int32, expr_float64, expr_call),; h2=(oneof(float, int, list, np.ndarray)),; pi=nullable(oneof(float, int, list, np.ndarray)),; rg=nullable(oneof(float, int, list, np.ndarray)),; annot=nullable(oneof(expr_float64, expr_int32)),; popstrat=nullable(oneof(expr_int32, expr_float64)),; popstrat_var=nullable(oneof(float, int)),; exact_h2=bool,; ); def simulate_phenotypes(; mt, genotype, h2, pi=None, rg=None, annot=None, popstrat=None, popstrat_var=None, exact_h2=False; ):; r""""""Simulate phenotypes for testing LD score regression. Simulates betas (SNP effects) under the infinitesimal, spike & slab, or; annotation-informed models, depending on parameters passed. Optionally adds; population stratification. Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` containing genotypes to be used. Also should contain; variant annotations as row fields if running the annotation-informed; model or covariates as column fields if adding population stratification.; genotype : :class:`.Expression` or :class:`.CallExpression`; Entry field containing genotypes of individuals to be used for the; simulation.; h2 : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`; SNP-based heritability of simulated trait.; pi : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`, optional; Probability of SNP being ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:2044,test,testing,2044,docs/0.2/_modules/hail/experimental/ldscsim.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html,2,['test'],['testing']
Testability,"sts a Python variable or object as an expression.; Examples; >>> table = hl.utils.range_table(8); >>> greetings = hl.literal({1: 'Good morning', 4: 'Good afternoon', 6 : 'Good evening'}); >>> table.annotate(greeting = greetings.get(table.idx)).show(); +-------+------------------+; | idx | greeting |; +-------+------------------+; | int32 | str |; +-------+------------------+; | 0 | NA |; | 1 | ""Good morning"" |; | 2 | NA |; | 3 | NA |; | 4 | ""Good afternoon"" |; | 5 | NA |; | 6 | ""Good evening"" |; | 7 | NA |; +-------+------------------+. Notes; Use this function to capture large Python objects for use in expressions. This; function provides an alternative to adding an object as a global annotation on a; Table or MatrixTable. Parameters:; x – Object to capture and broadcast as an expression. Returns:; Expression. hail.expr.functions.cond(condition, consequent, alternate, missing_false=False)[source]; Deprecated in favor of if_else().; Expression for an if/else statement; tests a condition and returns one of two options based on the result.; Examples; >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; If condition evaluates to True, returns consequent. If condition; evaluates to False, returns alternate. If predicate is missing, returns; missing. Note; The type of consequent and alternate must be the same. Parameters:. condition (BooleanExpression) – Condition to test.; consequent (Expression) – Branch to return if the condition is True.; alternate (Expression) – Branch to return if the condition is False.; missing_false (bool) – If True, treat missing condition as False. See also; case(), switch(), if_else(). Returns:; Expression – One of consequent, alternate, or missing, based on condition. hail.expr.functions.if_else(condition, consequent, alternate, missing_false=False)[source]; Expression for an if/else statement; tests a condition and ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/core.html:3126,test,tests,3126,docs/0.2/functions/core.html,https://hail.is,https://hail.is/docs/0.2/functions/core.html,1,['test'],['tests']
Testability,"supplied phenotype, covariates, and test.; The model and tests are those of :py:meth:`.logreg` with sample genotype ``gt`` replaced by the; score in the sample key table. For each key, missing scores are mean-imputed across all samples. The resulting **logistic regression key table** has key column of type String given by the ``key_name``; parameter and additional columns corresponding to the fields of the ``va.logreg`` schema given for ``test``; in :py:meth:`.logreg`. :py:meth:`.logreg_burden` returns both the logistic regression key table and the sample key table. :param str key_name: Name to assign to key column of returned key tables. :param str variant_keys: Variant annotation path for the TArray or TSet of keys associated to each variant. :param bool single_key: if true, ``variant_keys`` is interpreted as a single (or missing) key per variant,; rather than as a collection of keys. :param str agg_expr: Sample aggregation expression (per key). :param str test: Statistical test, one of: 'wald', 'lrt', 'score', or 'firth'. :param str y: Response expression. :param covariates: list of covariate expressions.; :type covariates: list of str. :return: Tuple of logistic regression key table and sample aggregation key table.; :rtype: (:py:class:`.KeyTable`, :py:class:`.KeyTable`); """""". r = self._jvdf.logregBurden(key_name, variant_keys, single_key, agg_expr, test, y, jarray(Env.jvm().java.lang.String, covariates)); logreg_kt = KeyTable(self.hc, r._1()); sample_kt = KeyTable(self.hc, r._2()). return logreg_kt, sample_kt. [docs] @handle_py4j; @requireTGenotype; @typecheck_method(pedigree=Pedigree); def mendel_errors(self, pedigree):; """"""Find Mendel errors; count per variant, individual and nuclear; family. .. include:: requireTGenotype.rst. **Examples**. Find all violations of Mendelian inheritance in each (dad,; mom, kid) trio in a pedigree and return four tables:. >>> ped = Pedigree.read('data/trios.fam'); >>> all, per_fam, per_sample, per_variant = vds.mendel_errors(ped)",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:153750,test,test,153750,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,2,['test'],['test']
Testability,"symbols are in scope:. - ``s`` (*Sample*): sample; - ``sa``: sample annotations; - ``global``: global annotations; - ``gs`` (*Aggregable[Genotype]*): aggregable of :ref:`genotype` for sample ``s``. Note that ``v``, ``va``, and ``g`` are accessible through; `Aggregable methods <https://hail.is/hail/types.html#aggregable>`_ on ``gs``. The resulting **sample key table** has key column ``key_name`` and a numeric column of scores for each sample; named by the sample ID. 3) For each key, fit the logistic regression model using the supplied phenotype, covariates, and test.; The model and tests are those of :py:meth:`.logreg` with sample genotype ``gt`` replaced by the; score in the sample key table. For each key, missing scores are mean-imputed across all samples. The resulting **logistic regression key table** has key column of type String given by the ``key_name``; parameter and additional columns corresponding to the fields of the ``va.logreg`` schema given for ``test``; in :py:meth:`.logreg`. :py:meth:`.logreg_burden` returns both the logistic regression key table and the sample key table. :param str key_name: Name to assign to key column of returned key tables. :param str variant_keys: Variant annotation path for the TArray or TSet of keys associated to each variant. :param bool single_key: if true, ``variant_keys`` is interpreted as a single (or missing) key per variant,; rather than as a collection of keys. :param str agg_expr: Sample aggregation expression (per key). :param str test: Statistical test, one of: 'wald', 'lrt', 'score', or 'firth'. :param str y: Response expression. :param covariates: list of covariate expressions.; :type covariates: list of str. :return: Tuple of logistic regression key table and sample aggregation key table.; :rtype: (:py:class:`.KeyTable`, :py:class:`.KeyTable`); """""". r = self._jvdf.logregBurden(key_name, variant_keys, single_key, agg_expr, test, y, jarray(Env.jvm().java.lang.String, covariates)); logreg_kt = KeyTable(self.hc, r._1(",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:153242,log,logreg,153242,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"t 6M. See the; `MovieLens website <https://grouplens.org/datasets/movielens/100k/>`__; for more information about this dataset. Parameters; ----------; output_dir; Directory in which to write data.; overwrite; If ``True``, overwrite existing files/directories at those locations.; """"""; fs = Env.fs(). if not _dir_exists(fs, output_dir):; fs.mkdir(output_dir). paths = [os.path.join(output_dir, x) for x in ['movies.ht', 'ratings.ht', 'users.ht']]; if overwrite or any(not _dir_exists(fs, f) for f in paths):; init_temp_dir(); source = resources['movie_lens_100k']; tmp_path = os.path.join(tmp_dir, 'ml-100k.zip'); info(f'downloading MovieLens-100k data ...\n' f' Source: {source}'); sync_retry_transient_errors(urlretrieve, source, tmp_path); with zipfile.ZipFile(tmp_path, 'r') as z:; z.extractall(tmp_dir). user_table_path = os.path.join(tmp_dir, 'ml-100k', 'u.user'); movie_table_path = os.path.join(tmp_dir, 'ml-100k', 'u.item'); ratings_table_path = os.path.join(tmp_dir, 'ml-100k', 'u.data'); assert os.path.exists(user_table_path); assert os.path.exists(movie_table_path); assert os.path.exists(ratings_table_path). user_cluster_readable = _copy_to_tmp(fs, local_path_uri(user_table_path), extension='txt'); movie_cluster_readable = _copy_to_tmp(fs, local_path_uri(movie_table_path), 'txt'); ratings_cluster_readable = _copy_to_tmp(fs, local_path_uri(ratings_table_path), 'txt'). [movies_path, ratings_path, users_path] = paths. genres = [; 'Action',; 'Adventure',; 'Animation',; ""Children's"",; 'Comedy',; 'Crime',; 'Documentary',; 'Drama',; 'Fantasy',; 'Film-Noir',; 'Horror',; 'Musical',; 'Mystery',; 'Romance',; 'Sci-Fi',; 'Thriller',; 'War',; 'Western',; ]. # utility functions for importing movies; def field_to_array(ds, field):; return hl.if_else(ds[field] != 0, hl.array([field]), hl.empty_array(hl.tstr)). def fields_to_array(ds, fields):; return hl.flatten(hl.array([field_to_array(ds, f) for f in fields])). def rename_columns(ht, new_names):; return ht.rename({k: v for k, v in zip",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/tutorial.html:7347,assert,assert,7347,docs/0.2/_modules/hail/utils/tutorial.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/tutorial.html,2,['assert'],['assert']
Testability,"t = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; count response variable using `Poisson regression <https://en.wikipedia.org/wiki/Poisson_regression>`__. Notes; -----; See :func:`.logistic_regression_rows` for more info on statistical tests; of general linear models. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to includ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:60628,assert,assert,60628,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['assert'],['assert']
Testability,"t = table1.drop('C1', 'C2'). Drop fields `C1` and `C2` using field references:. >>> table_result = table1.drop(table1.C1, table1.C2). Drop a list of fields:. >>> fields_to_drop = ['C1', 'C2']; >>> table_result = table1.drop(*fields_to_drop). Notes; -----. This method can be used to drop global or row-indexed fields. The arguments; can be either strings (``'field'``), or top-level field references; (``table.field`` or ``table['field']``). Parameters; ----------; exprs : varargs of :class:`str` or :class:`.Expression`; Names of fields to drop or field reference expressions. Returns; -------; :class:`.Table`; Table without specified fields.; """"""; all_field_exprs = {e: k for k, e in self._fields.items()}; fields_to_drop = set(); for e in exprs:; if isinstance(e, Expression):; if e in all_field_exprs:; fields_to_drop.add(all_field_exprs[e]); else:; raise ExpressionException(; ""method 'drop' expects string field names or top-level field expressions"" "" (e.g. table['foo'])""; ); else:; assert isinstance(e, str); if e not in self._fields:; raise IndexError(""table has no field '{}'"".format(e)); fields_to_drop.add(e). table = self; if any(self._fields[field]._indices == self._global_indices for field in fields_to_drop):; # need to drop globals; table = table._select_globals(; 'drop', self._globals.drop(*[f for f in table.globals if f in fields_to_drop]); ). if any(self._fields[field]._indices == self._row_indices for field in fields_to_drop):; # need to drop row fields; protected_key = set(self._row_indices.protected_key); for f in fields_to_drop:; check_keys('drop', f, protected_key); row_fields = set(table.row); to_drop = [f for f in fields_to_drop if f in row_fields]; table = table._select('drop', table.row.drop(*to_drop)). return table. [docs] @typecheck_method(; output=str, types_file=nullable(str), header=bool, parallel=nullable(ir.ExportType.checker), delimiter=str; ); def export(self, output, types_file=None, header=True, parallel=None, delimiter='\t'):; """"""Export to a t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:51959,assert,assert,51959,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['assert'],['assert']
Testability,"t annotations. Return type:VariantDataset. logreg_burden(key_name, variant_keys, single_key, agg_expr, test, y, covariates=[])[source]¶; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Run a gene burden test using the logistic Wald test on the maximum genotype per gene. Here va.genes is; a variant annotation of type Set[String] giving the set of genes containing the variant; (see Extended example in linreg_burden() for a deeper dive in the context of linear regression):; >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.genes',; ... single_key=False,; ... agg_expr='gs.map(g => g.gt).max()',; ... test='wald',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). Run a gene burden test using the logistic score test on the weighted sum of genotypes per gene.; Here va.gene is a variant annotation of type String giving a single gene per variant (or no gene if; missing), and va.weight is a numeric variant annotation:; >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.gene',; ... single_key=True,; ... agg_expr='gs.map(g => va.weight * g.gt).sum()',; ... test='score',; ... y='sa.burden.pheno',; ... covariates=['sa.burden.cov1', 'sa.burden.cov2'])). To use a weighted sum of genotypes with missing genotypes mean-imputed rather than ignored, set; agg_expr='gs.map(g => va.weight * orElse(g.gt.toDouble, 2 * va.qc.AF)).sum()' where va.qc.AF; is the allele frequency over those samples that have no missing phenotype or covariates. Caution; With single_key=False, variant_keys expects a variant annotation of Set or Array type, in order to; allow each variant to have zero, one, or more keys (for example, the same variant may appear in m",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:118078,test,test,118078,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,3,"['log', 'test']","['logistic', 'test']"
Testability,"t or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""chi_squared_test"", ret_type, c1, c2, c3, c4). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32, min_cell_count=expr_int32); def contingency_table_test(c1, c2, c3, c4, min_cell_count) -> StructExpression:; """"""Performs chi-squared or Fisher's exact test of independence on a 2x2; contingency table. Examples; --------. >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=22)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=23)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967). Notes; -----; If all cell counts are at least `min_cell_count`, the chi-squared test is; used. Otherwise, Fisher's exact test is used. Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4.; min_cell_count : int or :class:`.Expression` of type :py:data:`.tint32`; Minimum count in every cell to use the chi-squared test. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""contingency_table_test"", ret_type, c1, c2, c3, c4, min_cell_count). # We use 64-bit integers.; # It is relatively easy to encounter an integer over",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:20895,test,test,20895,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"t severe to least severe):. Transcript ablation; Splice acceptor variant; Splice donor variant; Stop gained; Frameshift variant; Stop lost; Start lost; Transcript amplification; Inframe insertion; Missense variant; Protein altering variant; Incomplete terminal codon variant; Stop retained variant; Synonymous variant; Splice region variant; Coding sequence variant; Mature miRNA variant; 5’ UTR variant; 3’ UTR variant; Non-coding transcript exon variant; Intron variant; NMD transcript variant; Non-coding transcript variant; Upstream gene variant; Downstream gene variant; TFBS ablation; TFBS amplification; TF binding site variant; Regulatory region ablation; Regulatory region amplification; Feature elongation; Regulatory region variant; Feature truncation; Intergenic variant. If a canonical transcript with the most severe consequence exists, take that gene and transcript. Otherwise, take a non-canonical; transcript with the most severe consequence. Though this is the default logic, you may wish to define gene symbols differently. One way to do so while still using the VEP output; would be to add VEP annotations to your VDS, create a gene symbol variant annotation by parsing through the VEP output however you; wish, and then pass that annotation to annotate_variants_db() using the gene_key parameter.; Here’s an example that uses the gene symbol from the first VEP transcript:; import hail; from pprint import pprint. hc = hail.HailContext(). vds = (; hc; .import_vcf('gs://annotationdb/test/sample.vcf'); .split_multi(); .annotate_variants_db('va.vep'); .annotate_variants_expr('va.my_gene = va.vep.transcript_consequences[0].gene_symbol'); .annotate_variants_db('va.gene.constraint.pli', gene_key='va.my_gene'); ). pprint(vds.variant_schema). This code would return:; Struct{; rsid: String,; qual: Double,; filters: Set[String],; info: Struct{; ...; },; vep: Struct{; ...; },; my_gene: String,; gene: Struct{; constraint: Struct{; pli: Double; }; }; }. Suggest additions or edits¶; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/annotationdb.html:4928,log,logic,4928,docs/0.1/annotationdb.html,https://hail.is,https://hail.is/docs/0.1/annotationdb.html,1,['log'],['logic']
Testability,"t term; if desired. You must provide at least one covariate.; max_size (int) – Maximum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; null_max_iterations (int) – The maximum number of iterations when fitting the logistic null model. Defaults to 25.; null_tolerance (float) – The null model logisitic regression converges when the errors is less than this. Defaults to; 1e-6.; accuracy (float) – The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations (int) – The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns:; Table – One row per-group. The key is group. The row fields are:. group : the group parameter.; size : tint64, the number of variants in this group.; q_stat : tfloat64, the \(Q\) statistic, see Notes for why this differs from the paper.; p_value : tfloat64, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes.; fault : tint32, the fault flag from pgenchisq(). The global fields are:. n_complete_samples : tint32, the number of samples with neither a missing; phenotype nor a missing covariate.; y_residual : tint32, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alone.; s2 : tfloat64, the variance of the residuals, \(\sigma^2\) in the paper.; null_fit:. b : tndarray vector of coefficients.; score : tndarray vector of score statistics.; fisher : tndarray matrix of fisher statistics.; mu : tndarray the expected value under the null model.; n_iterations : tint32 the number of iterations before termination.; log_lkhd : tfloat64 the log-likelihood of the final iteration.; converged : tbool True if the null model converged.; exploded : tbool True if the null model failed to converge due to numerical; explosion. hail.methods.skat(key_expr, weight_expr, ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:76869,test,test,76869,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['test'],['test']
Testability,"t with a phenotype noisily computed from the genotypes:. >>> hl.reset_global_randomness(); >>> mt = hl.balding_nichols_model(1, n_samples=100, n_variants=20); >>> mt = mt.annotate_rows(gene = mt.locus.position // 12); >>> mt = mt.annotate_rows(weight = 1); >>> mt = mt.annotate_cols(phenotype = (hl.agg.sum(mt.GT.n_alt_alleles()) - 20 + hl.rand_norm(0, 1)) > 0.5). Test if the phenotype is significantly associated with the genotype:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 1.78e+02 | 1.68e-04 | 0 |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. The same test, but using the original paper's suggested weights which are derived from the; allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._logistic_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.04e+00 | 3.50e-01 | 0 |; | 1 | 9 | 1.22e+00 | 5.04e-01 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:92297,test,test,92297,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"t with a phenotype noisily computed from the genotypes:; >>> hl.reset_global_randomness(); >>> mt = hl.balding_nichols_model(1, n_samples=100, n_variants=20); >>> mt = mt.annotate_rows(gene = mt.locus.position // 12); >>> mt = mt.annotate_rows(weight = 1); >>> mt = mt.annotate_cols(phenotype = (hl.agg.sum(mt.GT.n_alt_alleles()) - 20 + hl.rand_norm(0, 1)) > 0.5). Test if the phenotype is significantly associated with the genotype:; >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 1.78e+02 | 1.68e-04 | 0 |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. The same test, but using the original paper’s suggested weights which are derived from the; allele frequency.; >>> mt = hl.variant_qc(mt); >>> skat = hl._logistic_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.04e+00 | 3.50e-01 | 0 |; | 1 | 9 | 1.22e+00 | 5.04e-01 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size.; Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:73066,test,test,73066,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['test'],['test']
Testability,"t(collection[, delimiter]); Joins elements of collection into single string delimited by delimiter. entropy(s); Returns the Shannon entropy of the character distribution defined by the string. parse_int(x); Parse a string as a 32-bit integer. parse_int32(x); Parse a string as a 32-bit integer. parse_int64(x); Parse a string as a 64-bit integer. parse_float(x); Parse a string as a 64-bit floating point number. parse_float32(x); Parse a string as a 32-bit floating point number. parse_float64(x); Parse a string as a 64-bit floating point number. Statistical functions. chi_squared_test(c1, c2, c3, c4); Performs chi-squared test of independence on a 2x2 contingency table. fisher_exact_test(c1, c2, c3, c4); Calculates the p-value, odds ratio, and 95% confidence interval using Fisher's exact test for a 2x2 table. contingency_table_test(c1, c2, c3, c4, ...); Performs chi-squared or Fisher's exact test of independence on a 2x2 contingency table. cochran_mantel_haenszel_test(a, b, c, d); Perform the Cochran-Mantel-Haenszel test for association. dbeta(x, a, b); Returns the probability density at x of a beta distribution with parameters a (alpha) and b (beta). dpois(x, lamb[, log_p]); Compute the (log) probability density at x of a Poisson distribution with rate parameter lamb. hardy_weinberg_test(n_hom_ref, n_het, n_hom_var); Performs test of Hardy-Weinberg equilibrium. pchisqtail(x, df[, ncp, lower_tail, log_p]); Returns the probability under the right-tail starting at x for a chi-squared distribution with df degrees of freedom. pnorm(x[, mu, sigma, lower_tail, log_p]); The cumulative probability function of a normal distribution with mean mu and standard deviation sigma. ppois(x, lamb[, lower_tail, log_p]); The cumulative probability function of a Poisson distribution. qchisqtail(p, df[, ncp, lower_tail, log_p]); The quantile function of a chi-squared distribution with df degrees of freedom, inverts pchisqtail(). qnorm(p[, mu, sigma, lower_tail, log_p]); The quantile functio",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/index.html:10327,test,test,10327,docs/0.2/functions/index.html,https://hail.is,https://hail.is/docs/0.2/functions/index.html,1,['test'],['test']
Testability,"t, pass_through, '_lowered_poisson_regression_rows'); mt = mt._select_all(; row_exprs=dict(pass_through=hl.struct(**row_exprs)),; col_exprs=dict(y=y, covariates=covariates),; entry_exprs=dict(x=x),; ); # FIXME: the order of the columns is irrelevant to regression; mt = mt.key_cols_by(). mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])). mt = mt.annotate_globals(; **mt.aggregate_cols(; hl.struct(; yvec=hl.agg.collect(hl.float(mt.y)),; covmat=hl.agg.collect(mt.covariates.map(hl.float)),; n=hl.agg.count(),; ),; _localize=False,; ); ); mt = mt.annotate_globals(; yvec=(; hl.case(); .when(mt.n - k - 1 >= 1, hl.nd.array(mt.yvec)); .or_error(; hl.format(""_lowered_poisson_regression_rows: insufficient degrees of freedom: n=%s, k=%s"", mt.n, k); ); ),; covmat=hl.nd.array(mt.covmat),; n_complete_samples=mt.n,; ); covmat = mt.covmat; yvec = mt.yvec; n = mt.n_complete_samples. logmean = hl.log(yvec.sum() / n); b = hl.nd.array([logmean, *[0 for _ in range(k - 1)]]); mu = hl.exp(covmat @ b); residual = yvec - mu; score = covmat.T @ residual; fisher = (mu * covmat.T) @ covmat; mt = mt.annotate_globals(null_fit=_poisson_fit(covmat, yvec, b, mu, score, fisher, max_iterations, tolerance)); mt = mt.annotate_globals(; null_fit=hl.case(); .when(mt.null_fit.converged, mt.null_fit); .or_error(; hl.format(; '_lowered_poisson_regression_rows: null model did not converge: %s',; mt.null_fit.select('n_iterations', 'log_lkhd', 'converged', 'exploded'),; ); ); ); mt = mt.annotate_rows(mean_x=hl.agg.mean(mt.x)); mt = mt.annotate_rows(xvec=hl.nd.array(hl.agg.collect(hl.coalesce(mt.x, mt.mean_x)))); ht = mt.rows(). covmat = ht.covmat; null_fit = ht.null_fit; # FIXME: we should test a whole block of variants at a time not one-by-one; xvec = ht.xvec; yvec = ht.yvec. if test == 'score':; chi_sq, p = _poisson_score_test(null_fit, covmat, yvec, xvec); return ht.select(chi_sq_stat=chi_sq, p_value=p, **ht.pass_through).select_globals('null_fit'). X = hl.n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:65760,log,logmean,65760,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logmean']
Testability,"t.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female],; ... max_iterations=100,; ... tolerance=1e-8). Warning; -------; :func:`.logistic_regression_rows` considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which **all** response variables and covariates are defined. For each row, missing values of; `x` are mean-imputed over these columns. As in the example, the; intercept covariate ``1`` must be included **explicitly** if desired. Notes; -----; This method performs, for each row, a significance test of the input; variable in predicting a binary (case-control) response variable based; on the logistic regression model. The response variable type must either; be numeric (with all present values 0 or 1) or Boolean, in which case; true and false are coded as 1 and 0, respectively. Hail supports the Wald test ('wald'), likelihood ratio test ('lrt'),; Rao score test ('score'), and Firth test ('firth'). Hail only includes; columns for which the response variable and all covariates are defined.; For each row, Hail imputes missing input values as the mean of the; non-missing values. The example above considers a model of the form. .. math::. \mathrm{Prob}(\mathrm{is\_case}) =; \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt}; + \beta_2 \, \mathrm{age}; + \beta_3 \, \mathrm{is\_female} + \varepsilon),; \quad; \varepsilon \sim \mathrm{N}(0, \sigma^2). where :math:`\mathrm{sigmoid}` is the `sigmoid function`_, the genotype; :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for Het, and 2 for; HomVar, and the Boolean covariate :math:`\mathrm{is\_female}` is coded as; for ``True`` (female) and 0 for ``False`` (male). The null model sets; :math:`\beta_1 = 0`. .. _sigmoid function: https://en.wikipedia.org/wiki/Sigmoid_function. The structure of the emitted row field depends on the test statistic as; shown in the tables below. ======",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:28334,test,test,28334,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,8,['test'],['test']
Testability,"t64) – Number of transversion alternate alleles.; n_star (int64) – Number of star (upstream deletion) alleles.; r_ti_tv (float64) – Transition/Transversion ratio.; r_het_hom_var (float64) – Het/HomVar call ratio.; r_insertion_deletion (float64) – Insertion/Deletion allele ratio. Missing values NA may result from division by zero. Parameters:. mt (MatrixTable) – Dataset.; name (str) – Name for resulting field. Returns:; MatrixTable – Dataset with a new column-indexed field name. hail.methods._logistic_skat(group, weight, y, x, covariates, max_size=46340, null_max_iterations=25, null_tolerance=1e-06, accuracy=1e-06, iterations=10000)[source]; The logistic sequence kernel association test (SKAT).; Logistic SKAT tests if the phenotype, y, is significantly associated with the genotype,; x. For \(N\) samples, in a group of \(M\) variants, with \(K\) covariates, the; model is given by:. \[\begin{align*}; X &: R^{N \times K} \\; G &: \{0, 1, 2\}^{N \times M} \\; \\; Y &\sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_0 X + \beta_1 G)); \end{align*}\]; The usual null hypothesis is \(\beta_1 = 0\). SKAT tests for an association, but does not; provide an effect size or other information about the association.; Wu et al. argue that, under the null hypothesis, a particular value, \(Q\), is distributed; according to a generalized chi-squared distribution with parameters determined by the genotypes,; weights, and residual phenotypes. The SKAT p-value is the probability of drawing even larger; values of \(Q\). If \(\widehat{\beta_\textrm{null}}\) is the best-fit beta under the; null model:. \[Y \sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_\textrm{null} X))\]; Then \(Q\) is defined by Wu et al. as:. \[\begin{align*}; p_i &= \textrm{logit}^{-1}(\widehat{\beta_\textrm{null}} X) \\; r_i &= y_i - p_i \\; W_{ii} &= w_i \\; \\; Q &= r^T G W G^T r; \end{align*}\]; Therefore \(r_i\), the residual phenotype, is the portion of the phenotype unexplained by; the covariates alone. Also no",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:68391,log,logit,68391,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['log'],['logit']
Testability,"t64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions.; logistic : :obj:`bool` or :obj:`tuple` of :obj:`int` and :obj:`float`; If false, use the linear test. If true, use the logistic test with no; more than 25 logistic iterations and a convergence tolerance of 1e-6. If; a tuple is given, use the logistic test with the tuple elements as the; maximum nubmer of iterations and convergence tolerance, respectively.; max_size : :obj:`int`; Maximum size of group on which to run the test.; accuracy : :obj:`float`; Accuracy achieved by the Davies algorithm if fault value is zero.; iterations : :obj:`int`; Maximum number of iterations attempted by the Davies algorithm. Returns; -------; :class:`.Table`; Table of SKAT results. """"""; if hl.current_backend().requires_lowering:; if logistic:; kwargs = {'accuracy': accuracy, 'iterations': iterations}; if logistic is not True:; null_max_iterations, null_tolerance = logistic; kwargs['null_max_iterations'] = null_max_iterations; kwargs['null_tolerance'] = null_tolerance; ht = hl._logistic_skat(key_expr, weight_expr, y, x, covariates, max_size, **kwargs); else:; ht = hl._linear_skat(key_expr, weight_expr, y, x, covariates, max_size, accuracy, iterations); ht = ht.select_globals(); return ht; mt = matrix_table_source('skat/x', x); raise_unless_entry_indexed('skat/x', x). analyze('skat/key_expr', key_expr, mt._row_indices); analyze('skat/weight_expr', weight_expr, mt._row_indices); analyze('skat/y', y, mt._col_indices). all_exprs = [key_expr, weight_expr, y]; for e in covariates:; all_exprs.append(e); analyze('skat/covariates', e, mt._col_indices). _warn_if_no_intercept('skat', covariates). # FIXME: remove this logic when annotation is better optimized; if x in mt._fields_inverse:; x_field_name = mt._fields_inverse[x]; entry_expr = {}; else:; x_field_name = Env.get_uid(); entry_expr = {x_field_name: x}. y_field_name = '__y'; weigh",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:107564,log,logistic,107564,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,6,['log'],['logistic']
Testability,"t:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic, and linear regression models to this data, where ``x`` is genotype, ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085, and 0.0016, respectively. The erroneous value 0.991 is due to quasi-complete separation. Moving one of the 10 hets from case to control eliminates this quasi-complete separation; the p-values from R are then 0.0373, 0.0111, and 0.0116, respectively, as expected for a less significant association. The Firth test reduces bias from small counts and resolves the issue of separation by penalizing maximum likelihood estimation by the `Jeffrey's invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton method is linear rather than quadratic. For Firth, 100 iterations are attempted for the null model and, if that is successful, for the full model as well. In testing we find 20 iterations nearly always suffices. If the null model fails to converge, then the ``sa.lmmreg.fit`` annotations reflect the null model; otherwise, they reflect the full model. See `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__ for an empirical comparison of the logistic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert's notes `Statistical Theory <ht",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:145667,test,test,145667,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['test']
Testability,"t:; """"""Create an interactive scatter plot with marginal densities on the side. ``x`` and ``y`` must both be either:; - a :class:`.NumericExpression` from the same :class:`.Table`.; - a tuple (str, :class:`.NumericExpression`) from the same :class:`.Table`. If passed as a tuple the first element is used as the hover label. This function returns a :class:`bokeh.models.layouts.Column` containing two :class:`figure.Row`:; - The first row contains the X-axis marginal density and a selection widget if multiple entries are specified in the ``label``; - The second row contains the scatter plot and the y-axis marginal density. Points will be colored by one of the labels defined in the ``label`` using the color scheme defined in; the corresponding entry of ``colors`` if provided (otherwise a default scheme is used). To specify your color; mapper, check `the bokeh documentation <https://bokeh.pydata.org/en/latest/docs/reference/colors.html>`__; for CategoricalMapper for categorical labels, and for LinearColorMapper and LogColorMapper; for continuous labels.; For categorical labels, clicking on one of the items in the legend will hide/show all points with the corresponding label in the scatter plot.; Note that using many different labelling schemes in the same plots, particularly if those labels contain many; different classes could slow down the plot interactions. Hovering on points in the scatter plot displays their coordinates, labels and any additional fields specified in ``hover_fields``. Parameters; ----------; ----------; x : :class:`.NumericExpression` or (str, :class:`.NumericExpression`); List of x-values to be plotted.; y : :class:`.NumericExpression` or (str, :class:`.NumericExpression`); List of y-values to be plotted.; label : :class:`.Expression` or Dict[str, :class:`.Expression`]], optional; Either a single expression (if a single label is desired), or a; dictionary of label name -> label value for x and y values.; Used to color each point w.r.t its label.; When",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:37627,Log,LogColorMapper,37627,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,1,['Log'],['LogColorMapper']
Testability,"t; Checkpoint the block matrix. default_block_size; Default block side length. densify; Restore all dropped blocks as explicit blocks of zeros. diagonal; Extracts diagonal elements as a row vector. entries; Returns a table with the indices and value of each block matrix entry. export; Exports a stored block matrix as a delimited text file. export_blocks; Export each block of the block matrix as its own delimited text or binary file. export_rectangles; Export rectangular regions from a block matrix to delimited text or binary files. fill; Creates a block matrix with all elements the same value. filter; Filters matrix rows and columns. filter_cols; Filters matrix columns. filter_rows; Filters matrix rows. floor; Element-wise floor. from_entry_expr; Creates a block matrix using a matrix table entry expression. from_ndarray; Create a BlockMatrix from an ndarray. from_numpy; Distributes a NumPy ndarray as a block matrix. fromfile; Creates a block matrix from a binary file. log; Element-wise natural logarithm. persist; Persists this block matrix in memory or on disk. random; Creates a block matrix with standard normal or uniform random entries. read; Reads a block matrix. rectangles_to_numpy; Instantiates a NumPy ndarray from files of rectangles written out using export_rectangles() or export_blocks(). sparsify_band; Filter to a diagonal band. sparsify_rectangles; Filter to blocks overlapping the union of rectangular regions. sparsify_row_intervals; Creates a block-sparse matrix by filtering to an interval for each row. sparsify_triangle; Filter to the upper or lower triangle. sqrt; Element-wise square root. sum; Sums array elements over one or both axes. svd; Computes the reduced singular value decomposition. to_matrix_table_row_major; Returns a matrix table with row key of row_idx and col key col_idx, whose entries are structs of a single field element. to_ndarray; Collects a BlockMatrix into a local hail ndarray expression on driver. to_numpy; Collects the block matrix ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html:8908,log,log,8908,docs/0.2/linalg/hail.linalg.BlockMatrix.html,https://hail.is,https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html,2,['log'],"['log', 'logarithm']"
Testability,"t; strings may now be optionally terminated with a B for bytes. Bug Fixes. (#13065) In Azure; Query-on-Batch, fix a resource leak that prevented running pipelines; with >500 partitions and created flakiness with >250 partitions.; (#13067) In; Query-on-Batch, driver and worker logs no longer buffer so messages; should arrive in the UI after a fixed delay rather than proportional; to the frequency of log messages.; (#13028) Fix crash; in hl.vds.filter_intervals when using a table to filter a VDS; that stores the max ref block length.; (#13060) Prevent 500; Internal Server Error in Jupyter Notebooks of Dataproc clusters; started by hailctl dataproc.; (#13051) In; Query-on-Batch and hailtop.batch, Azure Blob Storage https; URLs are now supported.; (#13042) In; Query-on-Batch, naive_coalesce no longer performs a full; write/read of the dataset. It now operates identically to the; Query-on-Spark implementation.; (#13031) In; hl.ld_prune, an informative error message is raised when a; dataset does not contain diploid calls instead of an assertion error.; (#13032) In; Query-on-Batch, in Azure, Hail now users a newer version of the Azure; blob storage libraries to reduce the frequency of “Stream is already; closed” errors.; (#13011) In; Query-on-Batch, the driver will use ~1/2 as much memory to read; results as it did in 0.2.115.; (#13013) In; Query-on-Batch, transient errors while streaming from Google Storage; are now automatically retried. Version 0.2.116; Released 2023-05-08. New Features. (#12917) ABS blob; URIs in the format of; https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>; are now supported.; (#12731) Introduced; hailtop.fs that makes public a filesystem module that works for; local fs, gs, s3 and abs. This is now used as the Backend.fs for; hail query but can be used standalone for Hail Batch users by; import hailtop.fs as hfs. Deprecations. (#12929) Hail no; longer officially supports Python 3.7.; (#12917) The; hail-az scheme for referenc",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:33472,assert,assertion,33472,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['assert'],['assertion']
Testability,"tDataset`; """""". jvds = self._jvdf.lmmreg(kinshipMatrix._jkm, y, jarray(Env.jvm().java.lang.String, covariates),; use_ml, global_root, va_root, run_assoc, joption(delta), sparsity_threshold,; use_dosages, joption(n_eigs), joption(dropped_variance_fraction)); return VariantDataset(self.hc, jvds). [docs] @handle_py4j; @requireTGenotype; @typecheck_method(test=strlike,; y=strlike,; covariates=listof(strlike),; root=strlike,; use_dosages=bool); def logreg(self, test, y, covariates=[], root='va.logreg', use_dosages=False):; """"""Test each variant for association using logistic regression. .. include:: requireTGenotype.rst. **Examples**. Run the logistic regression Wald test per variant using a Boolean phenotype and two covariates stored; in sample annotations:. >>> vds_result = vds.logreg('wald', 'sa.pheno.isCase', covariates=['sa.pheno.age', 'sa.pheno.isFemale']). **Notes**. The :py:meth:`~hail.VariantDataset.logreg` method performs,; for each variant, a significance test of the genotype in; predicting a binary (case-control) phenotype based on the; logistic regression model. The phenotype type must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded as 1 and 0, respectively. Hail supports the Wald test ('wald'), likelihood ratio test ('lrt'), Rao score test ('score'),; and Firth test ('firth'). Hail only includes samples for which the phenotype and all covariates are; defined. For each variant, Hail imputes missing genotypes as the mean of called genotypes. By default, genotypes values are given by hard call genotypes (``g.gt``).; If ``use_dosages=True``, then genotype values are defined by the dosage; :math:`\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})`. For Phred-scaled values,; :math:`\mathrm{P}(\mathrm{Het})` and :math:`\mathrm{P}(\mathrm{HomVar})` are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1. The example above considers a model of the form. .. math::.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:139750,log,logreg,139750,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,3,"['log', 'test']","['logistic', 'logreg', 'test']"
Testability,"t['column_ids'])).map(lambda col_idx: hl.struct(col_id=hl_columns[col_idx])); ). if not add_row_id:; ht = ht.drop('row_id'). mt = ht._unlocalize_entries('entries', 'cols', ['col_id']); mt = mt.key_rows_by(*row_key); return mt. [docs]@typecheck(; bed=str,; bim=str,; fam=str,; min_partitions=nullable(int),; delimiter=str,; missing=str,; quant_pheno=bool,; a2_reference=bool,; reference_genome=nullable(reference_genome_type),; contig_recoding=nullable(dictof(str, str)),; skip_invalid_loci=bool,; n_partitions=nullable(int),; block_size=nullable(int),; ); def import_plink(; bed,; bim,; fam,; min_partitions=None,; delimiter='\\\\s+',; missing='NA',; quant_pheno=False,; a2_reference=True,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; n_partitions=None,; block_size=None,; ) -> MatrixTable:; """"""Import a PLINK dataset (BED, BIM, FAM) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_plink(bed='data/test.bed',; ... bim='data/test.bim',; ... fam='data/test.fam',; ... reference_genome='GRCh37'). Notes; -----. Only binary SNP-major mode files can be read into Hail. To convert your; file from individual-major mode to SNP-major mode, use PLINK to read in; your fileset and use the ``--make-bed`` option. Hail uses the individual ID (column 2 in FAM file) as the sample id (`s`).; The individual IDs must be unique. The resulting :class:`.MatrixTable` has the following fields:. * Row fields:. * `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The; chromosome and position. If `reference_genome` is defined, the type; will be :class:`.tlocus` parameterized by `reference_genome`.; Otherwise, the type will be a :class:`.tstruct` with two fields:; `contig` with type :py:data:`.tstr` and `position` with type; :py:data:`.tint32`.; * `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference allele (A2; if `a2_reference` is ``True``) is the first element in the array.; * `",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/impex.html:85995,test,test,85995,docs/0.2/_modules/hail/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html,2,['test'],['test']
Testability,"t_avg = hl.log(avg / (1 - avg)); b = hl.nd.hstack([hl.nd.array([logit_avg]), hl.nd.zeros((hl.int32(m - 1)))]); mu = sigmoid(X @ b); score = X.T @ (y - mu); # Reshape so we do a rowwise multiply; fisher = X.T @ (X * (mu * (1 - mu)).reshape(-1, 1)); else:; # num covs used to fit null model.; m0 = null_fit.b.shape[0]; m_diff = m - m0. X0 = X[:, 0:m0]; X1 = X[:, m0:]. b = hl.nd.hstack([null_fit.b, hl.nd.zeros((m_diff,))]); mu = sigmoid(X @ b); score = hl.nd.hstack([null_fit.score, X1.T @ (y - mu)]). fisher00 = null_fit.fisher; fisher01 = X0.T @ (X1 * (mu * (1 - mu)).reshape(-1, 1)); fisher10 = fisher01.T; fisher11 = X1.T @ (X1 * (mu * (1 - mu)).reshape(-1, 1)). fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). dtype = numerical_regression_fit_dtype; blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}). def search(recur, iteration, b, mu, score, fisher):; def cont(exploded, delta_b, max_delta_b):; log_lkhd = hl.log((y * mu) + (1 - y) * (1 - mu)).sum(). next_b = b + delta_b; next_mu = sigmoid(X @ next_b); next_score = X.T @ (y - next_mu); next_fisher = X.T @ (X * (next_mu * (1 - next_mu)).reshape(-1, 1)). return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(; b=b,; score=score,; fisher=fisher,; mu=mu,; n_iterations=iteration,; log_lkhd=log_lkhd,; converged=True,; exploded=False,; ),; ); .when(; iteration == max_iterations,; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b, next_mu, next_score, next_fisher)); ). delta_b_struct = hl.nd.solve(fisher, score, no_crash=True); exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution; max_delta_b = nd_max(hl.abs(delta_b)); return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:40603,log,log,40603,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['log']
Testability,"t_gen() adds the following variant annotations:. va.varid (String) – 2nd column of .gen file if chromosome present, otherwise 1st column.; va.rsid (String) – 3rd column of .gen file if chromosome present, otherwise 2nd column. Parameters:; path (str or list of str) – .gen files to import.; sample_file (str) – The sample file.; tolerance (float) – If the sum of the genotype probabilities for a genotype differ from 1.0 by more than the tolerance, set the genotype to missing.; min_partitions (int or None) – Number of partitions.; chromosome (str or None) – Chromosome if not listed in the .gen file. Returns:Variant dataset imported from .gen and .sample files. Return type:VariantDataset. import_plink(bed, bim, fam, min_partitions=None, delimiter='\\\\s+', missing='NA', quantpheno=False)[source]¶; Import PLINK binary file (BED, BIM, FAM) as variant dataset.; Examples; Import data from a PLINK binary file:; >>> vds = hc.import_plink(bed=""data/test.bed"",; ... bim=""data/test.bim"",; ... fam=""data/test.fam""). Notes; Only binary SNP-major mode files can be read into Hail. To convert your file from individual-major mode to SNP-major mode, use PLINK to read in your fileset and use the --make-bed option.; The centiMorgan position is not currently used in Hail (Column 3 in BIM file).; The ID (s) used by Hail is the individual ID (column 2 in FAM file). Warning; No duplicate individual IDs are allowed. Chromosome names (Column 1) are automatically converted in the following cases:. 23 => “X”; 24 => “Y”; 25 => “X”; 26 => “MT”. Annotations; import_plink() adds the following annotations:. va.rsid (String) – Column 2 in the BIM file.; sa.famID (String) – Column 1 in the FAM file. Set to missing if ID equals “0”.; sa.patID (String) – Column 3 in the FAM file. Set to missing if ID equals “0”.; sa.matID (String) – Column 4 in the FAM file. Set to missing if ID equals “0”.; sa.isFemale (String) – Column 5 in the FAM file. Set to missing if value equals “-9”, “0”, or “N/A”.; Set to true if ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.HailContext.html:12689,test,test,12689,docs/0.1/hail.HailContext.html,https://hail.is,https://hail.is/docs/0.1/hail.HailContext.html,1,['test'],['test']
Testability,"t_test(c1, c2, c3, c4); Calculates the p-value, odds ratio, and 95% confidence interval using Fisher's exact test for a 2x2 table. contingency_table_test(c1, c2, c3, c4, ...); Performs chi-squared or Fisher's exact test of independence on a 2x2 contingency table. cochran_mantel_haenszel_test(a, b, c, d); Perform the Cochran-Mantel-Haenszel test for association. dbeta(x, a, b); Returns the probability density at x of a beta distribution with parameters a (alpha) and b (beta). dchisq(x, df[, ncp, log_p]); Compute the probability density at x of a chi-squared distribution with df degrees of freedom. dnorm(x[, mu, sigma, log_p]); Compute the probability density at x of a normal distribution with mean mu and standard deviation sigma. dpois(x, lamb[, log_p]); Compute the (log) probability density at x of a Poisson distribution with rate parameter lamb. hardy_weinberg_test(n_hom_ref, n_het, n_hom_var); Performs test of Hardy-Weinberg equilibrium. binom_test(x, n, p, alternative); Performs a binomial test on p given x successes in n trials. pchisqtail(x, df[, ncp, lower_tail, log_p]); Returns the probability under the right-tail starting at x for a chi-squared distribution with df degrees of freedom. pgenchisq(x, w, k, lam, mu, sigma, *[, ...]); The cumulative probability function of a generalized chi-squared distribution. pnorm(x[, mu, sigma, lower_tail, log_p]); The cumulative probability function of a normal distribution with mean mu and standard deviation sigma. pT(x, n[, lower_tail, log_p]); The cumulative probability function of a t-distribution with n degrees of freedom. pF(x, df1, df2[, lower_tail, log_p]); The cumulative probability function of a F-distribution with parameters df1 and df2. ppois(x, lamb[, lower_tail, log_p]); The cumulative probability function of a Poisson distribution. qchisqtail(p, df[, ncp, lower_tail, log_p]); The quantile function of a chi-squared distribution with df degrees of freedom, inverts pchisqtail(). qnorm(p[, mu, sigma, lower_tail, l",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:1852,test,test,1852,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['test'],['test']
Testability,"ta_1 \, \mathrm{gt} + \\beta_2 \, \mathrm{age} + \\beta_3 \, \mathrm{isFemale} + \\varepsilon), \quad \\varepsilon \sim \mathrm{N}(0, \sigma^2). where :math:`\mathrm{sigmoid}` is the `sigmoid; function <https://en.wikipedia.org/wiki/Sigmoid_function>`__, the; genotype :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; :math:`\mathrm{isFemale}` is coded as 1 for true (female) and; 0 for false (male). The null model sets :math:`\\beta_1 = 0`. The resulting variant annotations depend on the test statistic; as shown in the tables below. ========== =================== ====== =====; Test Annotation Type Value; ========== =================== ====== =====; Wald ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; Wald ``va.logreg.se`` Double estimated standard error, :math:`\widehat{\mathrm{se}}`; Wald ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`; Wald ``va.logreg.pval`` Double Wald p-value testing :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. ================ =========================== ======= =====; Test Annotation Type Value; ================ =========================== ======= =",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:141898,log,logreg,141898,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"ta` changes by less than :math:`10^{-6}` by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-val",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:32228,test,testing,32228,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['testing']
Testability,"tabase; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Hail Tutorials; Plotting Tutorial. View page source. Plotting Tutorial; The Hail plot module allows for easy plotting of data. This notebook contains examples of how to use the plotting functions in this module, many of which can also be found in the first tutorial. [1]:. import hail as hl; hl.init(). from bokeh.io import show; from bokeh.layouts import gridplot. Loading BokehJS ... SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2012-0.2.133-4c60fddb171a.log. [2]:. hl.utils.get_1kg('data/'); mt = hl.read_matrix_table('data/1kg.mt'); table = (hl.import_table('data/1kg_annotations.txt', impute=True); .key_by('Sample')); mt = mt.annotate_cols(**table[mt.s]); mt = hl.sample_qc(mt). mt.describe(). SLF4J: Failed to load class ""org.slf4j.impl.StaticMDCBinder"".; SLF4J: Defaulting to no-operation MDCAdapter implementation.; SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details. ----------------------------------------; Global fields:; None; ----------------------------------------; Column fields:; 's': str; 'Population': str; 'SuperPopulation': str; 'isFemale': bool; 'PurpleHair': bool; 'CaffeineConsumption': int32; 'sample_qc': struct {; dp_stats: struct {; mean: float64,; stdev: float64,; min: float64,; max: float64; },; gq_stats: struct {; mean: float64,; stdev: float64,; min: float64,; max: float64; },; call_rate: float64,; n_called: int64,; n_not_called: int64,; n_filtered: int64,; n_hom_ref: int64,; n_het: int6",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/08-plotting.html:1600,log,log,1600,docs/0.2/tutorials/08-plotting.html,https://hail.is,https://hail.is/docs/0.2/tutorials/08-plotting.html,1,['log'],['log']
Testability,"table1.aggregate(hl.agg.count_where(table1.HT > 68)); 2. Parameters; ----------; condition : :class:`.BooleanExpression`; Criteria for inclusion. Returns; -------; :class:`.Expression` of type :py:data:`.tint64`; Total number of records where `condition` is ``True``.; """""". return _agg_func('Sum', [hl.int64(condition)], tint64). [docs]@typecheck(condition=expr_bool); def any(condition) -> BooleanExpression:; """"""Returns ``True`` if `condition` is ``True`` for any record. Examples; --------. >>> (table1.group_by(table1.SEX); ... .aggregate(any_over_70 = hl.agg.any(table1.HT > 70)); ... .show()); +-----+-------------+; | SEX | any_over_70 |; +-----+-------------+; | str | bool |; +-----+-------------+; | ""F"" | False |; | ""M"" | True |; +-----+-------------+. Notes; -----; If there are no records to aggregate, the result is ``False``. Missing records are not considered. If every record is missing,; the result is also ``False``. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test. Returns; -------; :class:`.BooleanExpression`; """"""; return count_where(condition) > 0. [docs]@typecheck(condition=expr_bool); def all(condition) -> BooleanExpression:; """"""Returns ``True`` if `condition` is ``True`` for every record. Examples; --------. >>> (table1.group_by(table1.SEX); ... .aggregate(all_under_70 = hl.agg.all(table1.HT < 70)); ... .show()); +-----+--------------+; | SEX | all_under_70 |; +-----+--------------+; | str | bool |; +-----+--------------+; | ""F"" | False |; | ""M"" | False |; +-----+--------------+. Notes; -----; If there are no records to aggregate, the result is ``True``. Missing records are not considered. If every record is missing,; the result is also ``True``. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test. Returns; -------; :class:`.BooleanExpression`; """"""; return count_where(~condition) == 0. [docs]@typecheck(expr=expr_any, weight=nullable(expr_numeric)); def counter(expr, *, weight=None) -> DictEx",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html:19372,test,test,19372,docs/0.2/_modules/hail/expr/aggregators/aggregators.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html,2,['test'],['test']
Testability,"tart position of interval; endLocus (Locus) – End position of interval. isDefined(a: T): Boolean – Returns true if item is non-missing. Otherwise, false. isMissing(a: T): Boolean – Returns true if item is missing. Otherwise, false. isnan(a: Double): Boolean – Returns true if the argument is NaN (not a number), false if the argument is defined but not NaN. Returns missing if the argument is missing. json(x: T): String – Returns the JSON representation of a data type. Locus(contig: String, pos: Int): Locus. Construct a Locus object.; let l = Locus(""1"", 10040532) in l.position; result: 10040532. Arguments. contig (String) – String representation of contig.; pos (Int) – SNP position or start of an indel. Locus(s: String): Locus. Construct a Locus object.; let l = Locus(""1:10040532"") in l.position; result: 10040532. Arguments. s (String) – String of the form CHR:POS. log(x: Double, b: Double): Double. Returns the base b logarithm of the given value x.; Arguments. x (Double) – the number to take the base b logarithm of.; b (Double) – the base. log(x: Double): Double. Returns the natural logarithm of the given value x.; Arguments. x (Double) – the number to take the natural logarithm of. log10(x: Double): Double. Returns the base 10 logarithm of the given value x.; Arguments. x (Double) – the number to take the base 10 logarithm of. merge(s1: Struct, s2: Struct): Struct. Create a new Struct with all fields in s1 and s2.; let s1 = {gene: ""ACBD"", function: ""LOF""} and s2 = {a: 20, b: ""hello""} in merge(s1, s2); result: {gene: ""ACBD"", function: ""LOF"", a: 20, b: ""hello""}. orElse(a: T, b: T): T. If a is not missing, returns a. Otherwise, returns b.; Examples; Replace missing phenotype values with the mean value:; >>> [mean_height] = vds.query_samples(['samples.map(s => sa.pheno.height).stats()'])['mean']; >>> vds.annotate_samples_expr('sa.pheno.heightImputed = orElse(sa.pheno.height, %d)' % mean_height). orMissing(a: Boolean, b: T): T – If predicate evaluates to true, returns valu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:12042,log,logarithm,12042,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,1,['log'],['logarithm']
Testability,"taset.annotate_rows(hwe = hl.agg.hardy_weinberg_test(dataset.GT)). Test each row on a sub-population:; >>> dataset_result = dataset.annotate_rows(; ... hwe_eas = hl.agg.filter(dataset.pop == 'EAS',; ... hl.agg.hardy_weinberg_test(dataset.GT))). Notes; This method performs the test described in functions.hardy_weinberg_test() based solely on; the counts of homozygous reference, heterozygous, and homozygous variant calls.; The resulting struct expression has two fields:. het_freq_hwe (tfloat64) - Expected frequency; of heterozygous calls under Hardy-Weinberg equilibrium.; p_value (tfloat64) - p-value from test of Hardy-Weinberg; equilibrium. By default, Hail computes the exact p-value with mid-p-value correction, i.e. the; probability of a less-likely outcome plus one-half the probability of an; equally-likely outcome. See this document for; details on the Levene-Haldane distribution and references.; To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set one_sided=True and the p-value returned will be; from the one-sided exact test. Warning; Non-diploid calls (ploidy != 2) are ignored in the counts. While the; counts are defined for multiallelic variants, this test is only statistically; rigorous in the biallelic setting; use split_multi(); to split multiallelic variants beforehand. Parameters:. expr (CallExpression) – Call to test for Hardy-Weinberg equilibrium.; one_sided (bool) – False by default. When True, perform one-sided test for excess heterozygosity. Returns:; StructExpression – Struct expression with fields het_freq_hwe and p_value. hail.expr.aggregators.explode(f, array_agg_expr)[source]; Explode an array or set expression to aggregate the elements of all records.; Examples; Compute the mean of all elements in fields C1, C2, and C3:; >>> table1.aggregate(hl.agg.explode(lambda elt: hl.agg.mean(elt), [table1.C1, table1.C2, table1.C3])); 24.833333333333332. Compute the set of all observed elements in the filters fi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/aggregators.html:16165,test,test,16165,docs/0.2/aggregators.html,https://hail.is,https://hail.is/docs/0.2/aggregators.html,2,['test'],['test']
Testability,"tation=anytype,; annotation_type=Type); def annotate_global(self, path, annotation, annotation_type):; """"""Add global annotations from Python objects. **Examples**. Add populations as a global annotation:; ; >>> vds_result = vds.annotate_global('global.populations',; ... ['EAS', 'AFR', 'EUR', 'SAS', 'AMR'],; ... TArray(TString())). **Notes**. This method registers new global annotations in a VDS. These annotations; can then be accessed through expressions in downstream operations. The; Hail data type must be provided and must match the given ``annotation``; parameter. :param str path: annotation path starting in 'global'. :param annotation: annotation to add to global. :param annotation_type: Hail type of annotation; :type annotation_type: :py:class:`.Type`. :return: Annotated variant dataset.; :rtype: :py:class:`.VariantDataset`; """""". annotation_type._typecheck(annotation). annotated = self._jvds.annotateGlobal(annotation_type._convert_to_j(annotation), annotation_type._jtype, path); assert annotated.globalSignature().typeCheck(annotated.globalAnnotation()), 'error in java type checking'; return VariantDataset(self.hc, annotated). [docs] @handle_py4j; @typecheck_method(expr=oneof(strlike, listof(strlike))); def annotate_samples_expr(self, expr):; """"""Annotate samples with expression. **Examples**. Compute per-sample GQ statistics for hets:. >>> vds_result = (vds.annotate_samples_expr('sa.gqHetStats = gs.filter(g => g.isHet()).map(g => g.gq).stats()'); ... .export_samples('output/samples.txt', 'sample = s, het_gq_mean = sa.gqHetStats.mean')). Compute the list of genes with a singleton LOF per sample:. >>> variant_annotations_table = hc.import_table('data/consequence.tsv', impute=True).key_by('Variant'); >>> vds_result = (vds.annotate_variants_table(variant_annotations_table, root='va.consequence'); ... .annotate_variants_expr('va.isSingleton = gs.map(g => g.nNonRefAlleles()).sum() == 1'); ... .annotate_samples_expr('sa.LOF_genes = gs.filter(g => va.isSingleton && g.is",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:13403,assert,assert,13403,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['assert'],['assert']
Testability,"tations depend on the test statistic; as shown in the tables below. Test; Annotation; Type; Value. Wald; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). Wald; va.logreg.se; Double; estimated standard error, \(\widehat{\mathrm{se}}\). Wald; va.logreg.zstat; Double; Wald \(z\)-statistic, equal to \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; va.logreg.fit.converged; Boolean; true if iteration converged. Wald, LRT, Firth; va.logreg.fit.exploded; Boolean; true if iteration exploded. We consider iteration to have converged when every coordinate of \(\beta\) changes by less than \(10^{-6}\). For Wald and LRT, up to 25 iterations are attempted; in testing we find 4 or 5 iterations nearly always suffice. Convergence may also fail due to explosion, which refers to low-level numerical linear algebra exceptions caused by manipulating ill-conditioned matrices. Explosion may result from (nearly) linearly dependent covariates or complete separation.; A more common situation in genetics ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:111908,test,test,111908,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"tax of; job[‘identifier’]. If an object for that identifier doesn’t exist,; then one will be created automatically (only allowed in the; command() method). The identifier name can be any valid Python; identifier such as ofile5000.; All JobResourceFile are temporary files and must be written to; a permanent location using Batch.write_output() if the output; needs to be saved.; Only resources can be referred to in commands. Referencing a; batch.Batch or Job will result in an error. Parameters:; command (str) – A bash command. Return type:; BashJob. Returns:; Same job object with command appended. declare_resource_group(**mappings); Declare a resource group for a job.; Examples; Declare a resource group:; >>> b = Batch(); >>> input = b.read_input_group(bed='data/example.bed',; ... bim='data/example.bim',; ... fam='data/example.fam'); >>> j = b.new_job(); >>> j.declare_resource_group(tmp1={'bed': '{root}.bed',; ... 'bim': '{root}.bim',; ... 'fam': '{root}.fam',; ... 'log': '{root}.log'}); >>> j.command(f'plink --bfile {input} --make-bed --out {j.tmp1}'); >>> b.run() . Warning; Be careful when specifying the expressions for each file as this is Python; code that is executed with eval!. Parameters:; mappings (Dict[str, Any]) – Keywords (in the above example tmp1) are the name(s) of the; resource group(s). File names may contain arbitrary Python; expressions, which will be evaluated by Python eval. To use the; keyword as the file name, use {root} (in the above example {root}; will be replaced with tmp1). Return type:; BashJob. Returns:; Same job object with resource groups set. image(image); Set the job’s docker image.; Examples; Set the job’s docker image to ubuntu:22.04:; >>> b = Batch(); >>> j = b.new_job(); >>> (j.image('ubuntu:22.04'); ... .command(f'echo ""hello""')); >>> b.run() . Parameters:; image (str) – Docker image to use. Return type:; BashJob. Returns:; Same job object with docker image set. Previous; Next . © Copyright 2024, Hail Team. Built with Sphinx usin",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.BashJob.html:3456,log,log,3456,docs/batch/api/batch/hailtop.batch.job.BashJob.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.BashJob.html,2,['log'],['log']
Testability,"te <https://grouplens.org/datasets/movielens/100k/>`__; for more information about this dataset. Parameters; ----------; output_dir; Directory in which to write data.; overwrite; If ``True``, overwrite existing files/directories at those locations.; """"""; fs = Env.fs(). if not _dir_exists(fs, output_dir):; fs.mkdir(output_dir). paths = [os.path.join(output_dir, x) for x in ['movies.ht', 'ratings.ht', 'users.ht']]; if overwrite or any(not _dir_exists(fs, f) for f in paths):; init_temp_dir(); source = resources['movie_lens_100k']; tmp_path = os.path.join(tmp_dir, 'ml-100k.zip'); info(f'downloading MovieLens-100k data ...\n' f' Source: {source}'); sync_retry_transient_errors(urlretrieve, source, tmp_path); with zipfile.ZipFile(tmp_path, 'r') as z:; z.extractall(tmp_dir). user_table_path = os.path.join(tmp_dir, 'ml-100k', 'u.user'); movie_table_path = os.path.join(tmp_dir, 'ml-100k', 'u.item'); ratings_table_path = os.path.join(tmp_dir, 'ml-100k', 'u.data'); assert os.path.exists(user_table_path); assert os.path.exists(movie_table_path); assert os.path.exists(ratings_table_path). user_cluster_readable = _copy_to_tmp(fs, local_path_uri(user_table_path), extension='txt'); movie_cluster_readable = _copy_to_tmp(fs, local_path_uri(movie_table_path), 'txt'); ratings_cluster_readable = _copy_to_tmp(fs, local_path_uri(ratings_table_path), 'txt'). [movies_path, ratings_path, users_path] = paths. genres = [; 'Action',; 'Adventure',; 'Animation',; ""Children's"",; 'Comedy',; 'Crime',; 'Documentary',; 'Drama',; 'Fantasy',; 'Film-Noir',; 'Horror',; 'Musical',; 'Mystery',; 'Romance',; 'Sci-Fi',; 'Thriller',; 'War',; 'Western',; ]. # utility functions for importing movies; def field_to_array(ds, field):; return hl.if_else(ds[field] != 0, hl.array([field]), hl.empty_array(hl.tstr)). def fields_to_array(ds, fields):; return hl.flatten(hl.array([field_to_array(ds, f) for f in fields])). def rename_columns(ht, new_names):; return ht.rename({k: v for k, v in zip(ht.row, new_names)}). info(f'im",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/tutorial.html:7387,assert,assert,7387,docs/0.2/_modules/hail/utils/tutorial.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/tutorial.html,2,['assert'],['assert']
Testability,"te sample annotations; Query functions and the Hail Expression Language; Quality Control; Let’s do a GWAS!; Confounded!; Rare variant analysis; Eplilogue. Introduction to the expression language; Introduction to the Expression Language; Setup; Hail Expression Language; Hail Types; Primitive Types; Missingness; Let; Conditionals; Compound Types; Numeric Arrays; Exercise; Structs; Genetic Types; Demo variables; Wrangling complex nested types; Learn more!; Exercises. Expression language: query, annotate, and aggregate; Using the expression language to slice, dice, and query genetic data; Check for tutorial data or download if necessary; Types in action; Filtering with expressions; Filtering variants and genotypes; Annotating with expressions; Aggregables; Count; Sum; Fraction; Stats; Counter; FlatMap; Take; Collect; takeBy; Aggregating by key. Expression Language; Python API; Annotation Database; Other Resources. Hail. Docs »; Tutorials. View page source. Tutorials¶; To take Hail for a test drive, go through our tutorials. These can be viewed here in the documentation,; but we recommend instead that you run them yourself with Jupyter.; Download the Hail distribution from our getting started page, and follow; the instructions there to set up the Hail. Inside the unzipped distribution folder, you’ll find; a tutorials/ directory. cd to this directory and run jhail to start the notebook; server, then click a notebook to begin!. Hail Overview¶; This notebook is designed to provide a broad overview of Hail’s functionality, with emphasis on the; functionality to manipulate and query a genetic dataset. We walk through a genome-wide SNP association; test, and demonstrate the need to control for confounding caused by population stratification. Overview; Check for tutorial data or download if necessary; Loading data from disk; Getting to know our data; Integrate sample annotations; Query functions and the Hail Expression Language; Quality Control; Let’s do a GWAS!; Confounded!; Ra",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials-landing.html:1298,test,test,1298,docs/0.1/tutorials-landing.html,https://hail.is,https://hail.is/docs/0.1/tutorials-landing.html,1,['test'],['test']
Testability,"tem': '{}'"".format(self.dtype.element_type, item.dtype); ); return self._method(""add"", self.dtype, self._ec.coerce(item)). [docs] @typecheck_method(item=expr_any); def remove(self, item):; """"""Returns a new set excluding `item`. Examples; --------. >>> hl.eval(s1.remove(1)); {2, 3}. Parameters; ----------; item : :class:`.Expression`; Value to remove. Returns; -------; :class:`.SetExpression`; Set with `item` removed.; """"""; if not self._ec.can_coerce(item.dtype):; raise TypeError(; ""'SetExpression.remove' expects 'item' to be the same type as its elements\n""; "" set element type: '{}'\n""; "" type of arg 'item': '{}'"".format(self.dtype.element_type, item.dtype); ); return self._method(""remove"", self._type, self._ec.coerce(item)). [docs] @typecheck_method(item=expr_any); def contains(self, item):; """"""Returns ``True`` if `item` is in the set. Examples; --------. >>> hl.eval(s1.contains(1)); True. >>> hl.eval(s1.contains(10)); False. Parameters; ----------; item : :class:`.Expression`; Value for inclusion test. Returns; -------; :class:`.BooleanExpression`; ``True`` if `item` is in the set.; """"""; if not self._ec.can_coerce(item.dtype):; raise TypeError(; ""'SetExpression.contains' expects 'item' to be the same type as its elements\n""; "" set element type: '{}'\n""; "" type of arg 'item': '{}'"".format(self.dtype.element_type, item.dtype); ); return self._method(""contains"", tbool, self._ec.coerce(item)). [docs] @typecheck_method(s=expr_set()); def difference(self, s):; """"""Return the set of elements in the set that are not present in set `s`. Examples; --------. >>> hl.eval(s1.difference(s2)); {2}. >>> hl.eval(s2.difference(s1)); {5}. Parameters; ----------; s : :class:`.SetExpression`; Set expression of the same type. Returns; -------; :class:`.SetExpression`; Set of elements not in `s`.; """"""; if not s._type.element_type == self._type.element_type:; raise TypeError(; ""'SetExpression.difference' expects 's' to be the same type\n""; "" set type: '{}'\n""; "" type of 's': '{}'"".format(",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:27820,test,test,27820,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['test'],['test']
Testability,"terable""). def _compare_op(self, op, other):; other = to_expr(other); left, right, success = unify_exprs(self, other); if not success:; raise TypeError(; f""Invalid '{op}' comparison, cannot compare expressions "" f""of type '{self.dtype}' and '{other.dtype}'""; ); res = left._bin_op(op, right, hl.tbool); return res. def _is_scalar(self):; return self._indices.source is None. def _promote_scalar(self, typ):; if typ == tint32:; return hail.int32(self); elif typ == tint64:; return hail.int64(self); elif typ == tfloat32:; return hail.float32(self); else:; assert typ == tfloat64; return hail.float64(self). def _promote_numeric(self, typ):; coercer = expressions.coercer_from_dtype(typ); if isinstance(typ, tarray) and not isinstance(self.dtype, tarray):; return coercer.ec.coerce(self); elif isinstance(typ, tndarray) and not isinstance(self.dtype, tndarray):; return coercer.ec.coerce(self); else:; return coercer.coerce(self). @staticmethod; def _div_ret_type_f(t):; assert is_numeric(t); if t in {tint32, tint64}:; return tfloat64; else:; # Float64 or Float32; return t. def _bin_op_numeric_unify_types(self, name, other):; def numeric_proxy(t):; if t == tbool:; return tint32; else:; return t. def scalar_type(t):; if isinstance(t, tarray):; return numeric_proxy(t.element_type); elif isinstance(t, tndarray):; return numeric_proxy(t.element_type); else:; return numeric_proxy(t). t = unify_types(scalar_type(self.dtype), scalar_type(other.dtype)); if t is None:; raise NotImplementedError(""'{}' {} '{}'"".format(self.dtype, name, other.dtype)). if isinstance(self.dtype, tarray) or isinstance(other.dtype, tarray):; return tarray(t); elif isinstance(self.dtype, tndarray):; return tndarray(t, self.ndim); elif isinstance(other.dtype, tndarray):; return tndarray(t, other.ndim). return t. def _bin_op_numeric(self, name, other, ret_type_f=None):; other = to_expr(other); unified_type = self._bin_op_numeric_unify_types(name, other); me = self._promote_numeric(unified_type); other = other._promote_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html:18592,assert,assert,18592,docs/0.2/_modules/hail/expr/expressions/base_expression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html,2,['assert'],['assert']
Testability,"teration exploded; ================ =================== ======= ===============================. We consider iteration to have converged when every coordinate of; :math:`\beta` changes by less than :math:`10^{-6}` by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:32079,log,logistic,32079,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logistic']
Testability,"ters; ----------; f : function ( (arg) -> :class:`.CollectionExpression`); Function from the element type of the collection to the type of the; collection. For instance, `flatmap` on a ``set<str>`` should take; a ``str`` and return a ``set``. Returns; -------; :class:`.CollectionExpression`; """"""; expected_type, s = (tarray, 'array') if isinstance(self._type, tarray) else (tset, 'set'); value_type = f(construct_variable(Env.get_uid(), self.dtype.element_type)).dtype. if not isinstance(value_type, expected_type):; raise TypeError(; ""'flatmap' expects 'f' to return an expression of type '{}', found '{}'"".format(s, value_type); ). def f2(x):; return hl.array(f(x)) if isinstance(value_type, tset) else f(x). def transform_ir(array, name, body):; return ir.toArray(ir.StreamFlatMap(ir.toStream(array), name, ir.ToStream(body))). array_flatmap = hl.array(self)._ir_lambda_method(transform_ir, f2, self.dtype.element_type, identity). if isinstance(self.dtype, tset):; return hl.set(array_flatmap); assert isinstance(self.dtype, tarray), self.dtype; return array_flatmap. [docs] @typecheck_method(f=func_spec(2, expr_any), zero=expr_any); def fold(self, f, zero):; """"""Reduces the collection with the given function `f`, provided the initial value `zero`. Examples; --------; >>> a = [0, 1, 2]. >>> hl.eval(hl.fold(lambda i, j: i + j, 0, a)); 3. Parameters; ----------; f : function ( (:class:`.Expression`, :class:`.Expression`) -> :class:`.Expression`); Function which takes the cumulative value and the next element, and; returns a new value.; zero : :class:`.Expression`; Initial value to pass in as left argument of `f`. Returns; -------; :class:`.Expression`.; """"""; collection = self; if not isinstance(collection, ArrayExpression):; collection = hl.array(collection); return collection._to_stream().fold(lambda x, y: f(x, y), zero). [docs] @typecheck_method(f=func_spec(1, expr_bool)); def all(self, f):; """"""Returns ``True`` if `f` returns ``True`` for every element. Examples; --------. >>> hl.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:6324,assert,assert,6324,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['assert'],['assert']
Testability,"ters; ----------; group : :class:`.Expression`; Row-indexed expression indicating to which group a variant belongs. This is typically a gene; name or an interval.; weight : :class:`.Float64Expression`; Row-indexed expression for weights. Must be non-negative.; y : :class:`.Float64Expression`; Column-indexed response (dependent variable) expression.; x : :class:`.Float64Expression`; Entry-indexed expression for input (independent variable).; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions. You must explicitly provide an intercept term; if desired. You must provide at least one covariate.; max_size : :obj:`int`; Maximum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; null_max_iterations : :obj:`int`; The maximum number of iterations when fitting the logistic null model. Defaults to 25.; null_tolerance : :obj:`float`; The null model logisitic regression converges when the errors is less than this. Defaults to; 1e-6.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype fr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:95629,log,logisitic,95629,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logisitic']
Testability,"terval_as_struct.includes_end,; point_type=self.point_type,; ). def _convert_to_encoding(self, byte_writer, value):; interval_dict = {; 'start': value.start,; 'end': value.end,; 'includes_start': value.includes_start,; 'includes_end': value.includes_end,; }; self._struct_repr._convert_to_encoding(byte_writer, interval_dict). def unify(self, t):; return isinstance(t, tinterval) and self.point_type.unify(t.point_type). def subst(self):; return tinterval(self.point_type.subst()). def clear(self):; self.point_type.clear(). def _get_context(self):; return self.point_type.get_context(). class Box(object):; named_boxes: ClassVar = {}. @staticmethod; def from_name(name):; if name in Box.named_boxes:; return Box.named_boxes[name]; b = Box(); Box.named_boxes[name] = b; return b. def __init__(self):; pass. def unify(self, v):; if hasattr(self, 'value'):; return self.value == v; self.value = v; return True. def clear(self):; if hasattr(self, 'value'):; del self.value. def get(self):; assert hasattr(self, 'value'); return self.value. tvoid = _tvoid(). tint32 = _tint32(); """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int32Expression`, :func:`.int`, :func:`.int32`; """""". tint64 = _tint64(); """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int64Expression`, :func:`.int64`; """""". tint = tint32; """"""Alias for :py:data:`.tint32`."""""". tfloat32 = _tfloat32(); """"""Hail type for 32-bit floating point numbers. In Python, these are represented as :obj:`float`. See Also; --------; :class:`.Float32Expression`, :func:`.float64`; """""". tfloat64 = _tfloat64(); """"""Hail type for 64-bit floating point numbers. In Python, these are represented as :obj:`float`. See Also; --------; :class:`.Float64Expressio",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:51911,assert,assert,51911,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['assert'],['assert']
Testability,"ter”, “less”, (deprecated: “two.sided”). Returns:; Expression of type tfloat64 – p-value. hail.expr.functions.pchisqtail(x, df, ncp=None, lower_tail=False, log_p=False)[source]; Returns the probability under the right-tail starting at x for a chi-squared; distribution with df degrees of freedom.; Examples; >>> hl.eval(hl.pchisqtail(5, 1)); 0.025347318677468304. >>> hl.eval(hl.pchisqtail(5, 1, ncp=2)); 0.20571085634347097. >>> hl.eval(hl.pchisqtail(5, 1, lower_tail=True)); 0.9746526813225317. >>> hl.eval(hl.pchisqtail(5, 1, log_p=True)); -3.6750823266311876. Parameters:. x (float or Expression of type tfloat64) – The value at which to evaluate the CDF.; df (float or Expression of type tfloat64) – Degrees of freedom.; ncp (float or Expression of type tfloat64) – Noncentrality parameter, defaults to 0 if unspecified.; lower_tail (bool or BooleanExpression) – If True, compute the probability of an outcome at or below x,; otherwise greater than x.; log_p (bool or BooleanExpression) – Return the natural logarithm of the probability. Returns:; Expression of type tfloat64. hail.expr.functions.pgenchisq(x, w, k, lam, mu, sigma, *, max_iterations=None, min_accuracy=None)[source]; The cumulative probability function of a generalized chi-squared distribution.; The generalized chi-squared distribution has many interpretations. We share here four; interpretations of the values of this distribution:. A linear combination of normal variables and squares of normal variables.; A weighted sum of sums of squares of normally distributed values plus a normally distributed; value.; A weighted sum of chi-squared distributed values plus a normally distributed value.; A “quadratic form” in a vector; of uncorrelated standard normal values. The parameters of this function correspond to the parameters of the third interpretation. \[\begin{aligned}; w &: R^n \quad k : Z^n \quad lam : R^n \quad mu : R \quad sigma : R \\; \\; x &\sim N(mu, sigma^2) \\; y_i &\sim \mathrm{NonCentralChiSquared}(k_i",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:15182,log,logarithm,15182,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['log'],['logarithm']
Testability,"tes; -----; Based on the `keep` argument, this method will either restrict to points; in the supplied interval ranges, or remove all rows in those ranges. When ``keep=True``, partitions that don't overlap any supplied interval; will not be loaded at all. This enables :func:`.filter_intervals` to be; used for reasonably low-latency queries of small ranges of the dataset, even; on large datasets. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; Dataset to filter.; intervals : :class:`.ArrayExpression` of type :class:`.tinterval`; Intervals to filter on. The point type of the interval must; be a prefix of the key or equal to the first field of the key.; keep : :obj:`bool`; If ``True``, keep only rows that fall within any interval in `intervals`.; If ``False``, keep only rows that fall outside all intervals in; `intervals`. Returns; -------; :class:`.MatrixTable` or :class:`.Table`. """""". if isinstance(ds, MatrixTable):; k_type = ds.row_key.dtype; else:; assert isinstance(ds, Table); k_type = ds.key.dtype. point_type = intervals.dtype.element_type.point_type. def is_struct_prefix(partial, full):; if list(partial) != list(full)[: len(partial)]:; return False; for k, v in partial.items():; if full[k] != v:; return False; return True. if point_type == k_type[0]:; needs_wrapper = True; k_name = k_type.fields[0]; point_type = hl.tstruct(**{k_name: k_type[k_name]}); elif isinstance(point_type, tstruct) and is_struct_prefix(point_type, k_type):; needs_wrapper = False; else:; raise TypeError(; ""The point type is incompatible with key type of the dataset ('{}', '{}')"".format(; repr(point_type), repr(k_type); ); ). def wrap_input(interval):; if interval is None:; raise TypeError(""'filter_intervals' does not allow missing values in 'intervals'.""); elif needs_wrapper:; return Interval(; Struct(**{k_name: interval.start}),; Struct(**{k_name: interval.end}),; interval.includes_start,; interval.includes_end,; ); else:; return interval. intervals = hl.eval(interval",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/misc.html:13241,assert,assert,13241,docs/0.2/_modules/hail/methods/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html,2,['assert'],['assert']
Testability,"tes; If lower_tail is true, returns Prob(\(X \leq\) x) where \(X\) is a; Poisson random variable with rate parameter lamb. If lower_tail is false,; returns Prob(\(X\) > x). Parameters:. x (float or Expression of type tfloat64); lamb (float or Expression of type tfloat64) – Rate parameter of Poisson distribution.; lower_tail (bool or BooleanExpression) – If True, compute the probability of an outcome at or below x,; otherwise greater than x.; log_p (bool or BooleanExpression) – Return the natural logarithm of the probability. Returns:; Expression of type tfloat64. hail.expr.functions.qchisqtail(p, df, ncp=None, lower_tail=False, log_p=False)[source]; The quantile function of a chi-squared distribution with df degrees of; freedom, inverts pchisqtail().; Examples; >>> hl.eval(hl.qchisqtail(0.05, 2)); 5.991464547107979. >>> hl.eval(hl.qchisqtail(0.05, 2, ncp=2)); 10.838131614372958. >>> hl.eval(hl.qchisqtail(0.05, 2, lower_tail=True)); 0.10258658877510107. >>> hl.eval(hl.qchisqtail(hl.log(0.05), 2, log_p=True)); 5.991464547107979. Notes; Returns right-quantile x for which p = Prob(\(Z^2\) > x) with; \(Z^2\) a chi-squared random variable with degrees of freedom specified; by df. The probability p must satisfy 0 < p < 1. Parameters:. p (float or Expression of type tfloat64) – Probability.; df (float or Expression of type tfloat64) – Degrees of freedom.; ncp (float or Expression of type tfloat64) – Corresponds to ncp parameter in pchisqtail().; lower_tail (bool or BooleanExpression) – Corresponds to lower_tail parameter in pchisqtail().; log_p (bool or BooleanExpression) – Exponentiate p, corresponds to log_p parameter in pchisqtail(). Returns:; Expression of type tfloat64. hail.expr.functions.qnorm(p, mu=0, sigma=1, lower_tail=True, log_p=False)[source]; The quantile function of a normal distribution with mean mu and; standard deviation sigma, inverts pnorm(). Returns quantile of; standard normal distribution by default.; Examples; >>> hl.eval(hl.qnorm(0.90)); 1.2815515",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:25371,log,log,25371,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['log'],['log']
Testability,"th the effects on the remaining covariates fixed; to zero. The returned struct has ten fields:; - `beta` (:class:`.tarray` of :py:data:`.tfloat64`):; Estimated regression coefficient for each covariate.; - `standard_error` (:class:`.tarray` of :py:data:`.tfloat64`):; Estimated standard error for each covariate.; - `t_stat` (:class:`.tarray` of :py:data:`.tfloat64`):; t-statistic for each covariate.; - `p_value` (:class:`.tarray` of :py:data:`.tfloat64`):; p-value for each covariate.; - `multiple_standard_error` (:py:data:`.tfloat64`):; Estimated standard deviation of the random error.; - `multiple_r_squared` (:py:data:`.tfloat64`):; Coefficient of determination for nested models.; - `adjusted_r_squared` (:py:data:`.tfloat64`):; Adjusted `multiple_r_squared` taking into account degrees of; freedom.; - `f_stat` (:py:data:`.tfloat64`):; F-statistic for nested models.; - `multiple_p_value` (:py:data:`.tfloat64`):; p-value for the; `F-test <https://en.wikipedia.org/wiki/F-test#Regression_problems>`__ of; nested models.; - `n` (:py:data:`.tint64`):; Number of samples included in the regression. A sample is included if and; only if `y`, all elements of `x`, and `weight` (if set) are non-missing. All but the last field are missing if `n` is less than or equal to the; number of covariates or if the covariates are linearly dependent. If set, the `weight` parameter generalizes the model to `weighted least; squares <https://en.wikipedia.org/wiki/Weighted_least_squares>`__, useful; for heteroscedastic (diagonal but non-constant) variance. Warning; -------; If any weight is negative, the resulting statistics will be ``nan``. Parameters; ----------; y : :class:`.Float64Expression`; Response (dependent variable).; x : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; Covariates (independent variables).; nested_dim : :obj:`int`; The null model includes the first `nested_dim` covariates.; Must be between 0 and `k` (the length of `x`).; weight : :class:`.Float",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html:52366,test,test,52366,docs/0.2/_modules/hail/expr/aggregators/aggregators.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html,2,['test'],['test']
Testability,"than 1 core, then it receives that fraction of 5 Gi. If you need more storage than this,; you can request more storage explicitly with the Job.storage() method. The minimum storage request is 10 GB; which can be incremented in units of 1 GB maxing out at 64 TB. The additional storage is mounted at /io. Note; If a worker is preempted by google in the middle of running a job, you will be billed for; the time the job was running up until the preemption time. The job will be rescheduled on; a different worker and run again. Therefore, if a job takes 5 minutes to run, but was preempted; after running for 2 minutes and then runs successfully the next time it is scheduled, the; total cost for that job will be 7 minutes. Setup; We assume you’ve already installed Batch and the Google Cloud SDK as described in the Getting; Started section and we have created a user account for you and given you a; billing project.; To authenticate your computer with the Batch service, run the following; command in a terminal window:; gcloud auth application-default login; hailctl auth login. Executing this command will take you to a login page in your browser window where; you can select your google account to authenticate with. If everything works successfully,; you should see a message “hailctl is now authenticated.” in your browser window and no; error messages in the terminal window. Submitting a Batch to the Service. Warning; To avoid substantial network costs, ensure your jobs and data reside in the same region. To execute a batch on the Batch service rather than locally, first; construct a ServiceBackend object with a billing project and; bucket for storing intermediate files. Your service account must have read; and write access to the bucket.; Next, pass the ServiceBackend object to the Batch constructor; with the parameter name backend.; An example of running “Hello World” on the Batch service rather than; locally is shown below. You can open iPython or a Jupyter notebook; and exe",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/service.html:8193,log,login,8193,docs/batch/service.html,https://hail.is,https://hail.is/docs/batch/service.html,2,['log'],['login']
Testability,"that are causal for trait 2 but not trait 1.; rg : :obj:`float` or :obj:`int`; Genetic correlation between traits.; seed : :obj:`int`, optional; Seed for random number generator. If `seed` is ``None``, `seed` is set randomly. Warning; -------; May give inaccurate results if chosen parameters make the covariance matrix; not positive semi-definite. Covariance matrix is likely to not be positive; semi-definite when :math:`p_{TT}` is small and rg is large. Returns; -------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with simulated SNP effects as a row field of arrays.; pi : :obj:`list` or :class:`numpy.ndarray`; List of proportion of SNPs: :math:`p_{TT}`, :math:`p_{TF}`, :math:`p_{FT}`.; Possibly altered if covariance matrix of traits was not positive semi-definite.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix was not positive semi-definite.; """"""; assert sum(pi) <= 1, ""probabilities of being causal must sum to be less than 1""; ptt, ptf, pft, pff = pi[0], pi[1], pi[2], 1 - sum(pi); cov_matrix = np.asarray([[1 / (ptt + ptf), rg / ptt], [rg / ptt, 1 / (ptt + pft)]]); M = mt.count_rows(); # seed random state for replicability; randstate = np.random.RandomState(int(seed)); if np.any(np.linalg.eigvals(cov_matrix) < 0):; print('adjusting parameters to make covariance matrix positive semidefinite'); rg0, ptt0 = rg, ptt; while np.any(np.linalg.eigvals(cov_matrix) < 0): # check positive semidefinite; rg = round(0.99 * rg, 6); ptt = round(ptt + (pff) * 0.001, 6); cov_matrix = np.asarray([[1 / (ptt + ptf), rg / ptt], [rg / ptt, 1 / (ptt + pft)]]); pff0, pff = pff, 1 - sum([ptt, ptf, pft]); print(f'rg: {rg0} -> {rg}\nptt: {ptt0} -> {ptt}\npff: {pff0} -> {pff}'); pi = [ptt, ptf, pft, pff]; beta = randstate.multivariate_normal(; mean=np.zeros(2),; cov=cov_matrix,; size=[; int(M),; ],; ); zeros = np.zeros(shape=int(M)).T; beta_matrix = np.stack(; (beta, np.asarray([beta[:, 0], zeros]).T, np.asarray([zeros, zeros]).T",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:13148,assert,assert,13148,docs/0.2/_modules/hail/experimental/ldscsim.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html,2,['assert'],['assert']
Testability,"the PL likelihoods (converted from the Phred-scale) to sum to 1.; The example above considers a model of the form. \[\mathrm{Prob}(\mathrm{isCase}) = \mathrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt} + \beta_2 \, \mathrm{age} + \beta_3 \, \mathrm{isFemale} + \varepsilon), \quad \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid; function, the; genotype \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; \(\mathrm{isFemale}\) is coded as 1 for true (female) and; 0 for false (male). The null model sets \(\beta_1 = 0\).; The resulting variant annotations depend on the test statistic; as shown in the tables below. Test; Annotation; Type; Value. Wald; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). Wald; va.logreg.se; Double; estimated standard error, \(\widehat{\mathrm{se}}\). Wald; va.logreg.zstat; Double; Wald \(z\)-statistic, equal to \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; va.logreg.fit",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:111290,log,logreg,111290,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logreg']
Testability,"the null model; otherwise,; they reflect the full model. See; `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert's notes; `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__.; Firth introduced his approach in; `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/GibbsFieldEst/BiasReductionMLE.pdf>`__.; Heinze and Schemper further analyze Firth's approach in; `A solution to the problem of separation in logistic regression, 2002 <https://cemsiis.meduniwien.ac.at/fileadmin/msi_akim/CeMSIIS/KB/volltexte/Heinze_Schemper_2002_Statistics_in_Medicine.pdf>`__. Hail's logistic regression tests correspond to the ``b.wald``,; ``b.lrt``, and ``b.score`` tests in `EPACTS`_. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EPACTS results will currently only agree for variants with no; missing genotypes. .. _EPACTS: http://genome.sph.umich.edu/wiki/EPACTS#Single_Variant_Tests. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; test : {'wald', 'lrt', 'score', 'firth'}; Statistical test.; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` w",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:35267,log,logistic,35267,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,"['log', 'test']","['logistic', 'tests']"
Testability,"the null model;; otherwise, they reflect the full model. See; `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert's notes; `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__.; Firth introduced his approach in; `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/GibbsFieldEst/BiasReductionMLE.pdf>`__.; Heinze and Schemper further analyze Firth's approach in; `A solution to the problem of separation in logistic regression, 2002 <https://cemsiis.meduniwien.ac.at/fileadmin/msi_akim/CeMSIIS/KB/volltexte/Heinze_Schemper_2002_Statistics_in_Medicine.pdf>`__. Hail's logistic regression tests correspond to the ``b.wald``,; ``b.lrt``, and ``b.score`` tests in `EPACTS`_. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EPACTS results will currently only agree for variants with no; missing genotypes. .. _EPACTS: http://genome.sph.umich.edu/wiki/EPACTS#Single_Variant_Tests. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; test : {'wald', 'lrt', 'score', 'firth'}; Statistical test.; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` w",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:55712,log,logistic,55712,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,"['log', 'test']","['logistic', 'tests']"
Testability,"the same effect. See also; stop(). Parameters:. sc (pyspark.SparkContext, optional) – Spark Backend only. Spark context. If not specified, the Spark backend will create a new; Spark context.; app_name (str) – A name for this pipeline. In the Spark backend, this becomes the Spark application name. In; the Batch backend, this is a prefix for the name of every Batch.; master (str, optional) – Spark Backend only. URL identifying the Spark leader (master) node or local[N] for local; clusters.; local (str) – Spark Backend only. Local-mode core limit indicator. Must either be local[N] where N is a; positive integer or local[*]. The latter indicates Spark should use all cores; available. local[*] does not respect most containerization CPU limits. This option is only; used if master is unset and spark.master is not set in the Spark configuration.; log (str) – Local path for Hail log file. Does not currently support distributed file systems like; Google Storage, S3, or HDFS.; quiet (bool) – Print fewer log messages.; append (bool) – Append to the end of the log file.; min_block_size (int) – Minimum file block size in MB.; branching_factor (int) – Branching factor for tree aggregation.; tmp_dir (str, optional) – Networked temporary directory. Must be a network-visible file; path. Defaults to /tmp in the default scheme.; default_reference (str) – Deprecated. Please use default_reference() to set the default reference genome; Default reference genome. Either 'GRCh37', 'GRCh38',; 'GRCm38', or 'CanFam3'. idempotent (bool) – If True, calling this function is a no-op if Hail has already been initialized.; global_seed (int, optional) – Global random seed.; spark_conf (dict of str to :class`str`, optional) – Spark backend only. Spark configuration parameters.; skip_logging_configuration (bool) – Spark Backend only. Skip logging configuration in java and python.; local_tmpdir (str, optional) – Local temporary directory. Used on driver and executor nodes.; Must use the file scheme. Defa",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/api.html:4592,log,log,4592,docs/0.2/api.html,https://hail.is,https://hail.is/docs/0.2/api.html,1,['log'],['log']
Testability,"thrm{isFemale} + \varepsilon), \quad \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid; function, the; genotype \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; \(\mathrm{isFemale}\) is coded as 1 for true (female) and; 0 for false (male). The null model sets \(\beta_1 = 0\).; The resulting variant annotations depend on the test statistic; as shown in the tables below. Test; Annotation; Type; Value. Wald; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). Wald; va.logreg.se; Double; estimated standard error, \(\widehat{\mathrm{se}}\). Wald; va.logreg.zstat; Double; Wald \(z\)-statistic, equal to \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; va.logreg.fit.converged; Boolean; true if iteration converged. Wald, LRT, Firth; va.logreg.fit.exploded; Boolean; true if iteration exploded. We consider iteration to have converged when every coordinate of \(\beta\) changes by less than \(10^{-6}\). For",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:111540,test,testing,111540,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['testing']
Testability,"thrm{sigmoid}(\beta_0 + \beta_1 \, \mathrm{gt} + \beta_2 \, \mathrm{age} + \beta_3 \, \mathrm{isFemale} + \varepsilon), \quad \varepsilon \sim \mathrm{N}(0, \sigma^2)\]; where \(\mathrm{sigmoid}\) is the sigmoid; function, the; genotype \(\mathrm{gt}\) is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; \(\mathrm{isFemale}\) is coded as 1 for true (female) and; 0 for false (male). The null model sets \(\beta_1 = 0\).; The resulting variant annotations depend on the test statistic; as shown in the tables below. Test; Annotation; Type; Value. Wald; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). Wald; va.logreg.se; Double; estimated standard error, \(\widehat{\mathrm{se}}\). Wald; va.logreg.zstat; Double; Wald \(z\)-statistic, equal to \(\hat\beta_1 / \widehat{\mathrm{se}}\). Wald; va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; va.logreg.fit.converged; Boolean; true if iteration converged. Wald, LRT, Firth; va.logreg.fit.exploded; Boolean; true if iteration exploded. We consider iteration to",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:111443,log,logreg,111443,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logreg']
Testability,"tic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert’s notes; Statistical Theory.; Firth introduced his approach in; Bias reduction of maximum likelihood estimates, 1993.; Heinze and Schemper further analyze Firth’s approach in; A solution to the problem of separation in logistic regression, 2002.; Hail’s logistic regression tests correspond to the b.wald,; b.lrt, and b.score tests in EPACTS. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EPACTS results will currently only agree for variants with no; missing genotypes. Note; Use the pass_through parameter to include additional row fields from; matrix table underlying x. For example, to include an “rsid” field, set; pass_through=['rsid'] or pass_through=[mt.rsid]. Parameters:. test ({‘wald’, ‘lrt’, ‘score’, ‘firth’}) – Statistical test.; y (Float64Expression or list of Float64Expression) – One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a BooleanExpression will be implicitly converted to; a Float64Expression with this property.; x (Float64Expression) – Entry-indexed expression for input variable.; covariates (list of Float64Expression) – Non-empty list of column-indexed covariate expressions.; pass_through (list of str or Expression) – Additional row fields to include in the resulting table.; max_iterations (int) – The maximum number of iterations.; tolerance (float, optional) – The iterative fit of this model is considered “converged” if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns:; Table. hail.methods.poisson_regression_rows(test, y, x, covariates, pass_through=(), *, max_iterations=25, tolerance=None)[source]; For each row, test an input variable for association wit",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:14561,test,test,14561,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,2,['test'],['test']
Testability,"ticks=""outside""); fig = fig.update_yaxes(title_font_size=18, ticks=""outside""); fig.update_layout(; plot_bgcolor=""white"",; font_family='Arial, ""Open Sans"", verdana, sans-serif',; title_font_size=26,; xaxis=dict(linecolor=""black"", showticklabels=True),; yaxis=dict(linecolor=""black"", showticklabels=True),; # axes for plotly subplots are numbered following the pattern [xaxis, xaxis2, xaxis3, ...]; **{; f""{var}axis{idx}"": {""linecolor"": ""black"", ""showticklabels"": True}; for idx in range(2, n_facet_rows + n_facet_cols + 1); for var in [""x"", ""y""]; },; ). return fig. [docs] def show(self):; """"""Render and show the plot, either in a browser or notebook.""""""; self.to_plotly().show(). [docs] def write_image(self, path):; """"""Write out this plot as an image. This requires you to have installed the python package kaleido from pypi. Parameters; ----------; path: :class:`str`; The path to write the file to.; """"""; self.to_plotly().write_image(path). def _repr_html_(self):; return self.to_plotly()._repr_html_(). def _debug_print(self):; print(""Ggplot Object:""); print(""Aesthetics""); pprint(self.aes); pprint(""Scales:""); pprint(self.scales); print(""Geoms:""); pprint(self.geoms). [docs]def ggplot(table, mapping=aes()):; """"""Create the initial plot object. This function is the beginning of all plots using the ``hail.ggplot`` interface. Plots are constructed; by calling this function, then adding attributes to the plot to get the desired result. Examples; --------. Create a y = x^2 scatter plot. >>> ht = hl.utils.range_table(10); >>> ht = ht.annotate(squared = ht.idx**2); >>> my_plot = hl.ggplot.ggplot(ht, hl.ggplot.aes(x=ht.idx, y=ht.squared)) + hl.ggplot.geom_point(). Parameters; ----------; table; The table containing the data to plot.; mapping; Default list of aesthetic mappings from table data to plot attributes. Returns; -------; :class:`.GGPlot`; """"""; assert isinstance(mapping, Aesthetic); return GGPlot(table, mapping). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:11566,assert,assert,11566,docs/0.2/_modules/hail/ggplot/ggplot.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html,2,['assert'],['assert']
Testability,"til; import string; import tempfile; from collections import Counter, defaultdict; from contextlib import contextmanager; from io import StringIO; from typing import Literal, Optional; from urllib.parse import urlparse. import hail; import hail as hl; from hail.typecheck import enumeration, nullable, typecheck; from hail.utils.java import Env, error. [docs]@typecheck(n_rows=int, n_cols=int, n_partitions=nullable(int)); def range_matrix_table(n_rows, n_cols, n_partitions=None) -> 'hail.MatrixTable':; """"""Construct a matrix table with row and column indices and no entry fields. Examples; --------. >>> range_ds = hl.utils.range_matrix_table(n_rows=100, n_cols=10). >>> range_ds.count_rows(); 100. >>> range_ds.count_cols(); 10. Notes; -----; The resulting matrix table contains the following fields:. - `row_idx` (:py:data:`.tint32`) - Row index (row key).; - `col_idx` (:py:data:`.tint32`) - Column index (column key). It contains no entry fields. This method is meant for testing and learning, and is not optimized for; production performance. Parameters; ----------; n_rows : :obj:`int`; Number of rows.; n_cols : :obj:`int`; Number of columns.; n_partitions : int, optional; Number of partitions (uses Spark default parallelism if None). Returns; -------; :class:`.MatrixTable`; """"""; check_nonnegative_and_in_range('range_matrix_table', 'n_rows', n_rows); check_nonnegative_and_in_range('range_matrix_table', 'n_cols', n_cols); if n_partitions is not None:; check_positive_and_in_range('range_matrix_table', 'n_partitions', n_partitions); return hail.MatrixTable(; hail.ir.MatrixRead(; hail.ir.MatrixRangeReader(n_rows, n_cols, n_partitions),; _assert_type=hl.tmatrix(; hl.tstruct(),; hl.tstruct(col_idx=hl.tint32),; ['col_idx'],; hl.tstruct(row_idx=hl.tint32),; ['row_idx'],; hl.tstruct(),; ),; ); ). [docs]@typecheck(n=int, n_partitions=nullable(int)); def range_table(n, n_partitions=None) -> 'hail.Table':; """"""Construct a table with the row index and no other fields. Examples; --------. >",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/misc.html:1561,test,testing,1561,docs/0.2/_modules/hail/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/misc.html,2,['test'],['testing']
Testability,"ting.figure`; """"""; p.legend.label_text_font_size = font_size; p.xaxis.axis_label_text_font_size = font_size; p.yaxis.axis_label_text_font_size = font_size; p.xaxis.major_label_text_font_size = font_size; p.yaxis.major_label_text_font_size = font_size; if hasattr(p.title, 'text_font_size'):; p.title.text_font_size = font_size; if hasattr(p.xaxis, 'group_text_font_size'):; p.xaxis.group_text_font_size = font_size; return p. [docs]@typecheck(; x=expr_numeric,; y=expr_numeric,; bins=oneof(int, sequenceof(int)),; range=nullable(sized_tupleof(nullable(sized_tupleof(numeric, numeric)), nullable(sized_tupleof(numeric, numeric)))),; title=nullable(str),; width=int,; height=int,; colors=sequenceof(str),; log=bool,; ); def histogram2d(; x: NumericExpression,; y: NumericExpression,; bins: int = 40,; range: Optional[Tuple[int, int]] = None,; title: Optional[str] = None,; width: int = 600,; height: int = 600,; colors: Sequence[str] = bokeh.palettes.all_palettes['Blues'][7][::-1],; log: bool = False,; ) -> figure:; """"""Plot a two-dimensional histogram. ``x`` and ``y`` must both be a :class:`.NumericExpression` from the same :class:`.Table`. If ``x_range`` or ``y_range`` are not provided, the function will do a pass through the data to determine; min and max of each variable. Examples; --------. >>> ht = hail.utils.range_table(1000).annotate(x=hail.rand_norm(), y=hail.rand_norm()); >>> p_hist = hail.plot.histogram2d(ht.x, ht.y). >>> ht = hail.utils.range_table(1000).annotate(x=hail.rand_norm(), y=hail.rand_norm()); >>> p_hist = hail.plot.histogram2d(ht.x, ht.y, bins=10, range=((0, 1), None)). Parameters; ----------; x : :class:`.NumericExpression`; Expression for x-axis (from a Hail table).; y : :class:`.NumericExpression`; Expression for y-axis (from the same Hail table as ``x``).; bins : int or [int, int]; The bin specification:; - If int, the number of bins for the two dimensions (nx = ny = bins).; - If [int, int], the number of bins in each dimension (nx, ny = bins).; The default",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:16944,log,log,16944,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,['log'],['log']
Testability,"tion Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Hail on the Cloud; Hail Query-on-Batch. View page source. Hail Query-on-Batch. Warning; Hail Query-on-Batch (the Batch backend) is currently in beta. This means some functionality is; not yet working. Please contact us if you would like to use missing; functionality on Query-on-Batch!. Hail Query-on-Batch uses Hail Batch instead of Apache Spark to execute jobs. Instead of a Dataproc; cluster, you will need a Hail Batch cluster. For more information on using Hail Batch, see the Hail; Batch docs. For more information on deploying a Hail Batch cluster,; please contact the Hail Team at our discussion forum. Getting Started. Install Hail version 0.2.93 or later:. pip install 'hail>=0.2.93'. Sign up for a Hail Batch account (currently only available to; Broad affiliates).; Authenticate with Hail Batch. hailctl auth login. Specify a bucket for Hail to use for temporary intermediate files. In Google Cloud, we recommend; using a bucket with automatic deletion after a set period of time. hailctl config set batch/remote_tmpdir gs://my-auto-delete-bucket/hail-query-temporaries. Specify a Hail Batch billing project (these are different from Google Cloud projects). Every new; user has a trial billing project loaded with 10 USD. The name is available on the Hail User; account page. hailctl config set batch/billing_project my-billing-project. Set the default Hail Query backend to batch:. hailctl config set query/backend batch. Now you are ready to try Hail! If you want to switch back to; Query-on-Spark, run the previous command again with “spark” in place of “batch”. Variant Effect Predictor (VEP); More information coming very soon. If you want to use VEP with Hail Query-on-Batch, please contact; the Hail Team at our discussion forum. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/cloud/query_on_batch.html:1383,log,login,1383,docs/0.2/cloud/query_on_batch.html,https://hail.is,https://hail.is/docs/0.2/cloud/query_on_batch.html,1,['log'],['login']
Testability,"tion test (SKAT). Logistic SKAT tests if the phenotype, `y`, is significantly associated with the genotype,; `x`. For :math:`N` samples, in a group of :math:`M` variants, with :math:`K` covariates, the; model is given by:. .. math::. \begin{align*}; X &: R^{N \times K} \\; G &: \{0, 1, 2\}^{N \times M} \\; \\; Y &\sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_0 X + \beta_1 G)); \end{align*}. The usual null hypothesis is :math:`\beta_1 = 0`. SKAT tests for an association, but does not; provide an effect size or other information about the association. Wu et al. argue that, under the null hypothesis, a particular value, :math:`Q`, is distributed; according to a generalized chi-squared distribution with parameters determined by the genotypes,; weights, and residual phenotypes. The SKAT p-value is the probability of drawing even larger; values of :math:`Q`. If :math:`\widehat{\beta_\textrm{null}}` is the best-fit beta under the; null model:. .. math::. Y \sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_\textrm{null} X)). Then :math:`Q` is defined by Wu et al. as:. .. math::. \begin{align*}; p_i &= \textrm{logit}^{-1}(\widehat{\beta_\textrm{null}} X) \\; r_i &= y_i - p_i \\; W_{ii} &= w_i \\; \\; Q &= r^T G W G^T r; \end{align*}. Therefore :math:`r_i`, the residual phenotype, is the portion of the phenotype unexplained by; the covariates alone. Also notice:. 1. Each sample's phenotype is Bernoulli distributed with mean :math:`p_i` and variance; :math:`\sigma^2_i = p_i(1 - p_i)`, the binomial variance. 2. :math:`G W G^T`, is a symmetric positive-definite matrix when the weights are non-negative. We describe below our interpretation of the mathematics as described in the main body and; appendix of Wu, et al. According to the paper, the distribution of :math:`Q` is given by a; generalized chi-squared distribution whose weights are the eigenvalues of a symmetric matrix; which we call :math:`Z Z^T`:. .. math::. \begin{align*}; V_{ii} &= \sigma^2_i \\; W_{ii} &= w_i \quad\q",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:88118,log,logit,88118,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['log'],['logit']
Testability,"tly by the user. Use Batch.new_job(),; Batch.new_bash_job(), or Batch.new_python_job() instead.; Methods. always_copy_output; Set the job to always copy output to cloud storage, even if the job failed. always_run; Set the job to always run, even if dependencies fail. cloudfuse; Add a bucket to mount with gcsfuse in GCP or a storage container with blobfuse in Azure. cpu; Set the job's CPU requirements. depends_on; Explicitly set dependencies on other jobs. env. gcsfuse; Add a bucket to mount with gcsfuse. memory; Set the job's memory requirements. regions; Set the cloud regions a job can run in. spot; Set whether a job is run on spot instances. storage; Set the job's storage size. timeout; Set the maximum amount of time this job can run for in seconds. always_copy_output(always_copy_output=True); Set the job to always copy output to cloud storage, even if the job failed.; Notes; Can only be used with the backend.ServiceBackend.; Examples; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.always_copy_output(); ... .command(f'echo ""hello"" > {j.ofile} && false')). Parameters:; always_copy_output (bool) – If True, set job to always copy output to cloud storage regardless; of whether the job succeeded. Return type:; Self. Returns:; Same job object set to always copy output. always_run(always_run=True); Set the job to always run, even if dependencies fail. Warning; Jobs set to always run are not cancellable!. Examples; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.always_run(); ... .command(f'echo ""hello""')). Parameters:; always_run (bool) – If True, set job to always run. Return type:; Self. Returns:; Same job object set to always run. cloudfuse(bucket, mount_point, *, read_only=True); Add a bucket to mount with gcsfuse in GCP or a storage container with blobfuse in Azure.; Notes; Can only be used with the backend.ServiceBackend. This method can; be called more than once. Warning; There are performanc",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html:1573,test,test,1573,docs/batch/api/batch/hailtop.batch.job.Job.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html,2,['test'],['test']
Testability,"tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table3.snp_errors[1],; }),; hl.struct(**{; ck_name: table3.proband[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[2],; 'snp_errors': table3.snp_errors[2],; }),; ]; ); table3 = table3.explode('xs'); table3 = table3.select(**table3.xs); table3 = (; table3.group_by(ck_name, 'fam_id'); .aggregate(errors=hl.agg.sum(table3.errors), snp_errors=hl.agg.sum(table3.snp_errors)); .key_by(ck_name); ). table4 = tm.select_rows(errors=hl.agg.count_where(hl.is_defined(tm.mendel_code))).rows(). return table1, table2, table3, table4. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree); def transmission_disequilibrium_test(dataset, pedigree) -> Table:; r""""""Performs the transmission disequilibrium test on trios. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------; Compute TDT association statistics and show the first two results:. >>> pedigree = hl.Pedigree.read('data/tdt_trios.fam'); >>> tdt_table = hl.transmission_disequilibrium_test(tdt_dataset, pedigree); >>> tdt_table.show(2) # doctest: +SKIP_OUTPUT_CHECK; +---------------+------------+-------+-------+----------+----------+; | locus | alleles | t | u | chi_sq | p_value |; +---------------+------------+-------+-------+----------+----------+; | locus<GRCh37> | array<str> | int64 | int64 | float64 | float64 |; +---------------+------------+-------+-------+----------+----------+; | 1:246714629 | [""C"",""A""] | 0 | 4 | 4.00e+00 | 4.55e-02 |; | 2:167262169 | [""T"",""C""] | NA | NA | NA | NA |; +---------------+------------+-------+-------+----------+---------",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:12937,test,test,12937,docs/0.2/_modules/hail/methods/family_methods.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html,2,['test'],['test']
Testability,"to low-level numerical linear algebra exceptions caused by; manipulating ill-conditioned matrices. Explosion may result from (nearly); linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:52983,log,logistic,52983,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,"['log', 'test']","['logistic', 'tests']"
Testability,"to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:32527,log,logistic,32527,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,"['log', 'test']","['logistic', 'tests']"
Testability,"to store the max reference block length with :func:`.vds.store_ref_block_max_length`. See Also; --------; :func:`.vds.store_ref_block_max_length`. Parameters; ----------; vds : :class:`.VariantDataset` or :class:`.MatrixTable`; max_ref_block_base_pairs; Maximum size of reference blocks, in base pairs.; ref_block_winsorize_fraction; Fraction of reference block length distribution to truncate / winsorize. Returns; -------; :class:`.VariantDataset` or :class:`.MatrixTable`; """"""; if isinstance(ds, VariantDataset):; rd = ds.reference_data; else:; rd = ds. fd_name = hl.vds.VariantDataset.ref_block_max_length_field; if fd_name in rd.globals:; rd = rd.drop(fd_name). if int(ref_block_winsorize_fraction is None) + int(max_ref_block_base_pairs is None) != 1:; raise ValueError(; 'truncate_reference_blocks: require exactly one of ""max_ref_block_base_pairs"", ""ref_block_winsorize_fraction""'; ). if ref_block_winsorize_fraction is not None:; assert (; ref_block_winsorize_fraction > 0 and ref_block_winsorize_fraction < 1; ), 'truncate_reference_blocks: ""ref_block_winsorize_fraction"" must be between 0 and 1 (e.g. 0.01 to truncate the top 1% of reference blocks)'; if ref_block_winsorize_fraction > 0.1:; warning(; f""'truncate_reference_blocks': ref_block_winsorize_fraction of {ref_block_winsorize_fraction} will lead to significant data duplication,""; f"" recommended values are <0.05.""; ); max_ref_block_base_pairs = rd.aggregate_entries(; hl.agg.approx_quantiles(rd.END - rd.locus.position + 1, 1 - ref_block_winsorize_fraction, k=200); ). assert (; max_ref_block_base_pairs > 0; ), 'truncate_reference_blocks: ""max_ref_block_base_pairs"" must be between greater than zero'; info(f""splitting VDS reference blocks at {max_ref_block_base_pairs} base pairs""). rd_under_limit = rd.filter_entries(rd.END - rd.locus.position < max_ref_block_base_pairs).localize_entries(; 'fixed_blocks', 'cols'; ). rd_over_limit = rd.filter_entries(rd.END - rd.locus.position >= max_ref_block_base_pairs).key_cols_by(; col_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/methods.html:34152,assert,assert,34152,docs/0.2/_modules/hail/vds/methods.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/methods.html,2,['assert'],['assert']
Testability,"ton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for ass",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:60257,assert,assert,60257,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,6,"['assert', 'test']","['assert', 'test']"
Testability,"treated as missing; ; :param types: Define types of fields in annotations files ; :type types: dict with str keys and :py:class:`.Type` values; ; :return: Key table constructed from text table.; :rtype: :class:`.KeyTable`. :param quote: Quote character; :type quote: str or None; """""". key = wrap_to_list(key); paths = wrap_to_list(paths); jtypes = {k: v._jtype for k, v in types.items()}. jkt = self._jhc.importTable(paths, key, min_partitions, jtypes, comment, delimiter, missing,; no_header, impute, quote); return KeyTable(self, jkt). [docs] @handle_py4j; @typecheck_method(bed=strlike,; bim=strlike,; fam=strlike,; min_partitions=nullable(integral),; delimiter=strlike,; missing=strlike,; quantpheno=bool); def import_plink(self, bed, bim, fam, min_partitions=None, delimiter='\\\\s+', missing='NA', quantpheno=False):; """"""Import PLINK binary file (BED, BIM, FAM) as variant dataset. **Examples**. Import data from a PLINK binary file:. >>> vds = hc.import_plink(bed=""data/test.bed"",; ... bim=""data/test.bim"",; ... fam=""data/test.fam""). **Notes**. Only binary SNP-major mode files can be read into Hail. To convert your file from individual-major mode to SNP-major mode, use PLINK to read in your fileset and use the ``--make-bed`` option. The centiMorgan position is not currently used in Hail (Column 3 in BIM file). The ID (``s``) used by Hail is the individual ID (column 2 in FAM file). .. warning::. No duplicate individual IDs are allowed. Chromosome names (Column 1) are automatically converted in the following cases:. - 23 => ""X""; - 24 => ""Y""; - 25 => ""X""; - 26 => ""MT"". **Annotations**. :py:meth:`~hail.HailContext.import_plink` adds the following annotations:. - **va.rsid** (*String*) -- Column 2 in the BIM file.; - **sa.famID** (*String*) -- Column 1 in the FAM file. Set to missing if ID equals ""0"".; - **sa.patID** (*String*) -- Column 3 in the FAM file. Set to missing if ID equals ""0"".; - **sa.matID** (*String*) -- Column 4 in the FAM file. Set to missing if ID equals ""0"".; -",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/context.html:16562,test,test,16562,docs/0.1/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/context.html,1,['test'],['test']
Testability,"tured expression. hamming(s1, s2); Returns the Hamming distance between the two strings. delimit(collection[, delimiter]); Joins elements of collection into single string delimited by delimiter. entropy(s); Returns the Shannon entropy of the character distribution defined by the string. parse_int(x); Parse a string as a 32-bit integer. parse_int32(x); Parse a string as a 32-bit integer. parse_int64(x); Parse a string as a 64-bit integer. parse_float(x); Parse a string as a 64-bit floating point number. parse_float32(x); Parse a string as a 32-bit floating point number. parse_float64(x); Parse a string as a 64-bit floating point number. Statistical functions. chi_squared_test(c1, c2, c3, c4); Performs chi-squared test of independence on a 2x2 contingency table. fisher_exact_test(c1, c2, c3, c4); Calculates the p-value, odds ratio, and 95% confidence interval using Fisher's exact test for a 2x2 table. contingency_table_test(c1, c2, c3, c4, ...); Performs chi-squared or Fisher's exact test of independence on a 2x2 contingency table. cochran_mantel_haenszel_test(a, b, c, d); Perform the Cochran-Mantel-Haenszel test for association. dbeta(x, a, b); Returns the probability density at x of a beta distribution with parameters a (alpha) and b (beta). dpois(x, lamb[, log_p]); Compute the (log) probability density at x of a Poisson distribution with rate parameter lamb. hardy_weinberg_test(n_hom_ref, n_het, n_hom_var); Performs test of Hardy-Weinberg equilibrium. pchisqtail(x, df[, ncp, lower_tail, log_p]); Returns the probability under the right-tail starting at x for a chi-squared distribution with df degrees of freedom. pnorm(x[, mu, sigma, lower_tail, log_p]); The cumulative probability function of a normal distribution with mean mu and standard deviation sigma. ppois(x, lamb[, lower_tail, log_p]); The cumulative probability function of a Poisson distribution. qchisqtail(p, df[, ncp, lower_tail, log_p]); The quantile function of a chi-squared distribution with df degrees o",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/index.html:10200,test,test,10200,docs/0.2/functions/index.html,https://hail.is,https://hail.is/docs/0.2/functions/index.html,1,['test'],['test']
Testability,"ual to; :math:`\hat\beta_1 / \widehat{\mathrm{se}}`; Wald `p_value` float64 Wald p-value testing :math:`\beta_1 = 0`; LRT, Firth `beta` float64 fit effect coefficient,; :math:`\hat\beta_1`; LRT, Firth `chi_sq_stat` float64 deviance statistic; LRT, Firth `p_value` float64 LRT / Firth p-value testing; :math:`\beta_1 = 0`; Score `chi_sq_stat` float64 score statistic; Score `p_value` float64 score p-value testing :math:`\beta_1 = 0`; ========== ================== ======= ============================================. For the Wald and likelihood ratio tests, Hail fits the logistic model for; each row using Newton iteration and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. ================ =================== ======= ===============================; Test Field Type Value; ================ =================== ======= ===============================; Wald, LRT, Firth `fit.n_iterations` int32 number of iterations until; convergence, explosion, or; reaching the max (25 for; Wald, LRT; 100 for Firth); Wald, LRT, Firth `fit.converged` bool ``True`` if iteration converged; Wald, LRT, Firth `fit.exploded` bool ``True`` if iteration exploded; ================ =================== ======= ===============================. We consider iteration to have converged when every coordinate of; :math:`\beta` changes by less than :math:`10^{-6}`. For Wald and LRT,; up to 25 iterations are attempted; in testing we find 4 or 5 iterations; nearly always suffice. Convergence may also fail due to explosion,; which refers to low-level numerical linear algebra exceptions caused by; manipulating ill-conditioned matrices. Explosion may result from (nearly); linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:51228,Test,Test,51228,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,1,['Test'],['Test']
Testability,"ual to; :math:`\hat\beta_1 / \widehat{\mathrm{se}}`; Wald `p_value` float64 Wald p-value testing :math:`\beta_1 = 0`; LRT, Firth `beta` float64 fit effect coefficient,; :math:`\hat\beta_1`; LRT, Firth `chi_sq_stat` float64 deviance statistic; LRT, Firth `p_value` float64 LRT / Firth p-value testing; :math:`\beta_1 = 0`; Score `chi_sq_stat` float64 score statistic; Score `p_value` float64 score p-value testing :math:`\beta_1 = 0`; ========== ================== ======= ============================================. For the Wald and likelihood ratio tests, Hail fits the logistic model for; each row using Newton iteration and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. ================ =================== ======= ===============================; Test Field Type Value; ================ =================== ======= ===============================; Wald, LRT, Firth `fit.n_iterations` int32 number of iterations until; convergence, explosion, or; reaching the max (by default,; 25 for Wald, LRT; 100 for Firth); Wald, LRT, Firth `fit.converged` bool ``True`` if iteration converged; Wald, LRT, Firth `fit.exploded` bool ``True`` if iteration exploded; ================ =================== ======= ===============================. We consider iteration to have converged when every coordinate of; :math:`\beta` changes by less than :math:`10^{-6}` by default. For Wald and; LRT, up to 25 iterations are attempted by default; in testing we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:30738,Test,Test,30738,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,1,['Test'],['Test']
Testability,"uced_svd(A: TallSkinnyMatrix, k=10, compute_U=False, iterations=2, iteration_size=None):; # Set Parameters; q = iterations; if iteration_size is None:; L = k + 2; else:; L = iteration_size; assert (q + 1) * L >= k; n = A.ncols. # Generate random matrix G; G = hl.rand_norm(0, 1, size=(n, L)); G = hl.nd.qr(G)[0]._persist(). fact = _krylov_factorization(A, G, q, compute_U); info(""_reduced_svd: Computing local SVD""); return fact.reduced_svd(k). @typecheck(; A=oneof(expr_float64, TallSkinnyMatrix), num_moments=int, p=nullable(int), moment_samples=int, block_size=int; ); def _spectral_moments(A, num_moments, p=None, moment_samples=500, block_size=128):; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_spectral_moments/entry_expr', A); A = _make_tsm(A, block_size). n = A.ncols. if p is None:; p = min(num_moments // 2, 10). # TODO: When moment_samples > n, we should just do a TSQR on A, and compute; # the spectrum of R.; assert moment_samples < n, '_spectral_moments: moment_samples must be smaller than num cols of A'; G = hl.rand_unif(-1, 1, size=(n, moment_samples)).map(lambda x: hl.sign(x)); Q1, R1 = hl.nd.qr(G)._persist(); fact = _krylov_factorization(A, Q1, p, compute_U=False); moments_and_stdevs = hl.eval(fact.spectral_moments(num_moments, R1)); moments = moments_and_stdevs.moments; stdevs = moments_and_stdevs.stdevs; return moments, stdevs. @typecheck(; A=oneof(expr_float64, TallSkinnyMatrix),; k=int,; num_moments=int,; compute_loadings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; moment_samples=int,; ); def _pca_and_moments(; A,; k=10,; num_moments=5,; compute_loadings=False,; q_iterations=10,; oversampling_param=None,; block_size=128,; moment_samples=100,; ):; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_spectral_moments/entry_expr', A); A = _make_tsm(A, block_size). if oversampling_param is None:; oversampling_param = k. # Set Parameters; q = q_iterations; L = k + oversampling_param; n =",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/pca.html:15153,assert,assert,15153,docs/0.2/_modules/hail/methods/pca.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html,2,['assert'],['assert']
Testability,"uces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the `Jeffrey's; invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This; test is slower, as both the null and full model must be fit per variant,; and convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted for the null model; and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the `logreg.fit` fields reflect the null model;; otherwise, they reflect the full model. See; `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert's notes; `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__.; Firth introduced his approach in; `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/GibbsFieldEst/BiasReductionMLE.pdf>`__.; Heinze and Schemper further analyze Firth's approach in; `A solution to the problem of separation in logistic regression, 2002 <https://cemsiis.meduniwien.ac.at/fileadmin/msi_akim/CeMSIIS/KB/volltexte/Heinze_Schemper_2002_Statistics_in_Medicine.pdf>`__. Hail's logistic regression tests correspond to the ``b.wald``,; ``b.lrt``, and ``b.score`` tests in `EPACTS`_. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EPACTS results will currently only agree for variants with no; missing genotypes. .. _EPACTS: http://genome.sph.umich.edu/wiki/EPACTS#Si",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:55117,test,tests,55117,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['tests']
Testability,"ue 0.991 is due to quasi-complete separation. Moving one of the 10 hets from case to control eliminates this quasi-complete separation; the p-values from R are then 0.0373, 0.0111, and 0.0116, respectively, as expected for a less significant association. The Firth test reduces bias from small counts and resolves the issue of separation by penalizing maximum likelihood estimation by the `Jeffrey's invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This test is slower, as both the null and full model must be fit per variant, and convergence of the modified Newton method is linear rather than quadratic. For Firth, 100 iterations are attempted for the null model and, if that is successful, for the full model as well. In testing we find 20 iterations nearly always suffices. If the null model fails to converge, then the ``sa.lmmreg.fit`` annotations reflect the null model; otherwise, they reflect the full model. See `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__ for an empirical comparison of the logistic Wald, LRT, score, and Firth tests. The theoretical foundations of the Wald, likelihood ratio, and score tests may be found in Chapter 3 of Gesine Reinert's notes `Statistical Theory <http://www.stats.ox.ac.uk/~reinert/stattheory/theoryshort09.pdf>`__. Firth introduced his approach in `Bias reduction of maximum likelihood estimates, 1993 <http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/GibbsFieldEst/BiasReductionMLE.pdf>`__. Heinze and Schemper further analyze Firth's approach in `A solution to the problem of separation in logistic regression, 2002 <https://cemsiis.meduniwien.ac.at/fileadmin/msi_akim/CeMSIIS/KB/volltexte/Heinze_Schemper_2002_Statistics_in_Medicine.pdf>`__. Those variants that don't vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations. Phenotype and covariate sample ann",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:146419,test,testing,146419,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['testing']
Testability,"ue for all rows and was mapped to; either the shape or the color aesthetic for geom_point. Version 0.2.114; Released 2023-04-19. New Features. (#12880) Added; hl.vds.store_ref_block_max_len to patch old VDSes to make; interval filtering faster. Bug Fixes. (#12860) Fixed; memory leak in shuffles in Query-on-Batch. Version 0.2.113; Released 2023-04-07. New Features. (#12798); Query-on-Batch now supports; BlockMatrix.write(..., stage_locally=True).; (#12793); Query-on-Batch now supports hl.poisson_regression_rows.; (#12801) Hitting; CTRL-C while interactively using Query-on-Batch cancels the; underlying batch.; (#12810); hl.array can now convert 1-d ndarrays into the equivalent list.; (#12851); hl.variant_qc no longer requires a locus field.; (#12816) In; Query-on-Batch, hl.logistic_regression('firth', ...) is now; supported.; (#12854) In; Query-on-Batch, simple pipelines with large numbers of partitions; should be substantially faster. Bug Fixes. (#12783) Fixed bug; where logs were not properly transmitted to Python.; (#12812) Fixed bug; where Table/MT._calculate_new_partitions returned unbalanced; intervals with whole-stage code generation runtime.; (#12839) Fixed; hailctl dataproc jupyter notebooks to be compatible with Spark; 3.3, which have been broken since 0.2.110.; (#12855) In; Query-on-Batch, allow writing to requester pays buckets, which was; broken before this release. Version 0.2.112; Released 2023-03-15. Bug Fixes. (#12784) Removed an; internal caching mechanism in Query on Batch that caused stalls in; pipelines with large intermediates. Version 0.2.111; Released 2023-03-13. New Features. (#12581) In Query on; Batch, users can specify which regions to have jobs run in. Bug Fixes. (#12772) Fix; hailctl hdinsight submit to pass args to the files. Version 0.2.110; Released 2023-03-08. New Features. (#12643) In Query on; Batch, hl.skat(..., logistic=True) is now supported.; (#12643) In Query on; Batch, hl.liftover is now supported.; (#12629) In Qu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:36757,log,logs,36757,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['log'],['logs']
Testability,"ugh=[mt.rsid]. Parameters:. test ({‘wald’, ‘lrt’, ‘score’, ‘firth’}) – Statistical test.; y (Float64Expression or list of Float64Expression) – One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a BooleanExpression will be implicitly converted to; a Float64Expression with this property.; x (Float64Expression) – Entry-indexed expression for input variable.; covariates (list of Float64Expression) – Non-empty list of column-indexed covariate expressions.; pass_through (list of str or Expression) – Additional row fields to include in the resulting table.; max_iterations (int) – The maximum number of iterations.; tolerance (float, optional) – The iterative fit of this model is considered “converged” if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns:; Table. hail.methods.poisson_regression_rows(test, y, x, covariates, pass_through=(), *, max_iterations=25, tolerance=None)[source]; For each row, test an input variable for association with a; count response variable using Poisson regression.; Notes; See logistic_regression_rows() for more info on statistical tests; of general linear models. Note; Use the pass_through parameter to include additional row fields from; matrix table underlying x. For example, to include an “rsid” field, set; pass_through=['rsid'] or pass_through=[mt.rsid]. Parameters:. y (Float64Expression) – Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x (Float64Expression) – Entry-indexed expression for input variable.; covariates (list of Float64Expression) – Non-empty list of column-indexed covariate expressions.; pass_through (list of str or Expression) – Additional row fields to include in the resulting table.; tolerance (float, optional) – The iterative fit of this model is considered “converged” if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:15446,test,test,15446,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,2,['test'],['test']
Testability,"unction f, provided the initial value zero. array_scan(f, zero, a); Map each element of a to cumulative value of function f, with initial value zero. reversed(x); Reverses the elements of a collection. keyed_intersection(*arrays, key); Compute the intersection of sorted arrays on a given key. keyed_union(*arrays, key); Compute the distinct union of sorted arrays on a given key. Numeric functions. abs(x); Take the absolute value of a numeric value, array or ndarray. approx_equal(x, y[, tolerance, absolute, ...]); Tests whether two numbers are approximately equal. bit_and(x, y); Bitwise and x and y. bit_or(x, y); Bitwise or x and y. bit_xor(x, y); Bitwise exclusive-or x and y. bit_lshift(x, y); Bitwise left-shift x by y. bit_rshift(x, y[, logical]); Bitwise right-shift x by y. bit_not(x); Bitwise invert x. bit_count(x); Count the number of 1s in the in the two's complement binary representation of x. exp(x). expit(x). is_nan(x). is_finite(x). is_infinite(x). log(x[, base]); Take the logarithm of the x with base base. log10(x). logit(x). sign(x); Returns the sign of a numeric value, array or ndarray. sqrt(x). int(x); Convert to a 32-bit integer expression. int32(x); Convert to a 32-bit integer expression. int64(x); Convert to a 64-bit integer expression. float(x); Convert to a 64-bit floating point expression. float32(x); Convert to a 32-bit floating point expression. float64(x); Convert to a 64-bit floating point expression. floor(x). ceil(x). uniroot(f, min, max, *[, max_iter, epsilon, ...]); Finds a root of the function f within the interval [min, max]. Numeric collection functions. min(*exprs[, filter_missing]); Returns the minimum element of a collection or of given numeric expressions. nanmin(*exprs[, filter_missing]); Returns the minimum value of a collection or of given arguments, excluding NaN. max(*exprs[, filter_missing]); Returns the maximum element of a collection or of given numeric expressions. nanmax(*exprs[, filter_missing]); Returns the maximum value ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/index.html:7170,log,log,7170,docs/0.2/functions/index.html,https://hail.is,https://hail.is/docs/0.2/functions/index.html,2,['log'],"['log', 'logarithm']"
Testability,"uple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; -------; :class:`.BooleanExpression`; """""". return _func(""approxEqual"", hl.tbool, x, y, tolerance, absolute, nan_same). def _shift_op(x, y, op):; assert op in ('<<', '>>', '>>>'); t = x.dtype; if t == hl.tint64:; word_size = 64; zero = hl.int64(0); else:; word_size = 32; zero = hl.int32(0). indices, aggregations = unify_all(x, y); return hl.bind(; lambda x, y: (; hl.case(); .when(y >= word_size, hl.sign(x) if op == '>>' else zero); .when(y >= 0, construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations)); .or_error('cannot shift by a negative value: ' + hl.str(x) + f"" {op} "" + hl.str(y)); ),; x,; y,; ). def _bit_op(x, y, op):; if x.dtype == hl.tint32 and y.dtype == hl.tint32:; t = hl.tint32; else:; t = hl.tint64; coercer = coercer_from_dtype(t); x = coercer.coerce(x); y = coercer.coerce(y). indices, aggregations = unify_all(x, y); return construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_oneof(expr_int32, expr_int64)); def bit_and(x, y):; """"""Bitwise and `x` and `y`. Examples; --------; >>> hl.eval(hl.bit_and(5, 3)); 1. Not",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:177671,assert,assert,177671,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['assert'],['assert']
Testability,"ur images in a multi-regional artifact registry, which at time of writing, despite being; “multi-regional”, does not incur network charges in the manner described above. Using the UI; If you have submitted the batch above successfully, then it should open a page in your; browser with a UI page for the batch you submitted. This will show a list of all the jobs; in the batch with the current state, exit code, duration, and cost. The possible job states; are as follows:. Pending - A job is waiting for its dependencies to complete; Ready - All of a job’s dependencies have completed, but the job has not been scheduled to run; Running - A job has been scheduled to run on a worker; Success - A job finished with exit code 0; Failure - A job finished with exit code not equal to 0; Error - The Docker container had an error (ex: out of memory). Clicking on a specific job will take you to a page with the logs for each of the three containers; run per job (see above) as well as a copy of the job spec and detailed; information about the job such as where the job was run, how long it took to pull the image for; each container, and any error messages.; To see all batches you’ve submitted, go to https://batch.hail.is. Each batch will have a current state,; number of jobs total, and the number of pending, succeeded, failed, and cancelled jobs as well as the; running cost of the batch (computed from completed jobs only). The possible batch states are as follows:. open - Not all jobs in the batch have been successfully submitted.; running - All jobs in the batch have been successfully submitted.; success - All jobs in the batch have completed with state “Success”; failure - Any job has completed with state “Failure” or “Error”; cancelled - Any job has been cancelled and no jobs have completed with state “Failure” or “Error”. Note; Jobs can still be running even if the batch has been marked as failure or cancelled. In the case of; ‘failure’, other jobs that do not depend on the failed ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/service.html:12389,log,logs,12389,docs/batch/service.html,https://hail.is,https://hail.is/docs/batch/service.html,1,['log'],['logs']
Testability,"urce mismatch\n""; "" Expected an expression from source {expected}\n""; "" Found expression derived from source {actual}\n""; "" Problematic field(s): {bad_refs}\n\n""; "" This error is commonly caused by chaining methods together:\n""; "" >>> ht.distinct().select(ht.x)\n\n""; "" Correct usage:\n""; "" >>> ht = ht.distinct()\n""; "" >>> ht = ht.select(ht.x)"".format(; caller=caller, expected=expected_source, actual=source, bad_refs=list(bad_refs); ); ); ). # check for stray indices by subtracting expected axes from observed; if broadcast:; unexpected_axes = axes - expected_axes; strictness = ''; else:; unexpected_axes = axes if axes != expected_axes else set(); strictness = 'strictly '. if unexpected_axes:; # one or more out-of-scope fields; refs = get_refs(expr); bad_refs = []; for name, inds in refs.items():; if broadcast:; bad_axes = inds.axes.intersection(unexpected_axes); if bad_axes:; bad_refs.append((name, inds)); elif inds.axes != expected_axes:; bad_refs.append((name, inds)). assert len(bad_refs) > 0; errors.append(; ExpressionException(; ""scope violation: '{caller}' expects an expression {strictness}indexed by {expected}""; ""\n Found indices {axes}, with unexpected indices {stray}. Invalid fields:{fields}{agg}"".format(; caller=caller,; strictness=strictness,; expected=list(expected_axes),; axes=list(indices.axes),; stray=list(unexpected_axes),; fields=''.join(; ""\n '{}' (indices {})"".format(name, list(inds.axes)) for name, inds in bad_refs; ),; agg=''; if (unexpected_axes - aggregation_axes); else ""\n '{}' supports aggregation over axes {}, ""; ""so these fields may appear inside an aggregator function."".format(caller, list(aggregation_axes)),; ); ); ). if aggregations:; if aggregation_axes:; # the expected axes of aggregated expressions are the expected axes + axes aggregated over; expected_agg_axes = expected_axes.union(aggregation_axes). for agg in aggregations:; assert isinstance(agg, Aggregation); refs = get_refs(*agg.exprs); agg_axes = agg.agg_axes(). # check for stray",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html:2461,assert,assert,2461,docs/0.2/_modules/hail/expr/expressions/expression_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html,2,['assert'],['assert']
Testability,"urce]; Create a histogram.; Notes; data can be a Float64Expression, or the result of the hist(); or approx_cdf() aggregators. Parameters:. data (Struct or Float64Expression) – Sequence of data to plot.; range (Tuple[float]) – Range of x values in the histogram.; bins (int) – Number of bins in the histogram.; legend (str) – Label of data on the x-axis.; title (str) – Title of the histogram.; log (bool) – Plot the log10 of the bin counts. Returns:; bokeh.plotting.figure. hail.plot.cumulative_histogram(data, range=None, bins=50, legend=None, title=None, normalize=True, log=False)[source]; Create a cumulative histogram. Parameters:. data (Struct or Float64Expression) – Sequence of data to plot.; range (Tuple[float]) – Range of x values in the histogram.; bins (int) – Number of bins in the histogram.; legend (str) – Label of data on the x-axis.; title (str) – Title of the histogram.; normalize (bool) – Whether or not the cumulative data should be normalized.; log (bool) – Whether or not the y-axis should be of type log. Returns:; bokeh.plotting.figure. hail.plot.histogram2d(x, y, bins=40, range=None, title=None, width=600, height=600, colors=('#eff3ff', '#c6dbef', '#9ecae1', '#6baed6', '#4292c6', '#2171b5', '#084594'), log=False)[source]; Plot a two-dimensional histogram.; x and y must both be a NumericExpression from the same Table.; If x_range or y_range are not provided, the function will do a pass through the data to determine; min and max of each variable.; Examples; >>> ht = hail.utils.range_table(1000).annotate(x=hail.rand_norm(), y=hail.rand_norm()); >>> p_hist = hail.plot.histogram2d(ht.x, ht.y). >>> ht = hail.utils.range_table(1000).annotate(x=hail.rand_norm(), y=hail.rand_norm()); >>> p_hist = hail.plot.histogram2d(ht.x, ht.y, bins=10, range=((0, 1), None)). Parameters:. x (NumericExpression) – Expression for x-axis (from a Hail table).; y (NumericExpression) – Expression for y-axis (from the same Hail table as x).; bins (int or [int, int]) – The bin specifi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/plot.html:4084,log,log,4084,docs/0.2/plot.html,https://hail.is,https://hail.is/docs/0.2/plot.html,2,['log'],['log']
Testability,"urns:; DictExpression – Dictionary with transformed values. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. size()[source]; Returns the size of the dictionary.; Examples; >>> hl.eval(d.size()); 3. Returns:; Expression of type tint32 – Size of the dictionary. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. values()[source]; Returns an array with all values in the dictionary.; Examples; >>> hl.eval(d.values()) ; [33, 44, 43]. Returns:; ArrayExpression – All values in the dictionary. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.DictExpression.html:8535,test,tested,8535,docs/0.2/hail.expr.DictExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.DictExpression.html,1,['test'],['tested']
Testability,"ursively).; Each dict element of the result list contains the following data:. is_dir (bool) – Path is a directory.; size_bytes (int) – Size in bytes.; size (str) – Size as a readable string.; modification_time (str) – Time of last file modification.; owner (str) – Owner.; path (str) – Path. Parameters:; path (str). Returns:; list [dict]. hail.utils.hadoop_scheme_supported(scheme)[source]; Returns True if the Hadoop filesystem supports URLs with the given; scheme.; Examples; >>> hadoop_scheme_supported('gs') . Notes; URLs with the https scheme are only supported if they are specifically; Azure Blob Storage URLs of the form https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>. Parameters:; scheme (str). Returns:; bool. hail.utils.copy_log(path)[source]; Attempt to copy the session log to a hadoop-API-compatible location.; Examples; Specify a manual path:; >>> hl.copy_log('gs://my-bucket/analysis-10-jan19.log') ; INFO: copying log to 'gs://my-bucket/analysis-10-jan19.log'... Copy to a directory:; >>> hl.copy_log('gs://my-bucket/') ; INFO: copying log to 'gs://my-bucket/hail-20180924-2018-devel-46e5fad57524.log'... Notes; Since Hail cannot currently log directly to distributed file systems, this; function is provided as a utility for offloading logs from ephemeral nodes.; If path is a directory, then the log file will be copied using its; base name to the directory (e.g. /home/hail.log would be copied as; gs://my-bucket/hail.log if path is gs://my-bucket. Parameters:; path (str). hail.utils.range_table(n, n_partitions=None)[source]; Construct a table with the row index and no other fields.; Examples; >>> df = hl.utils.range_table(100). >>> df.count(); 100. Notes; The resulting table contains one field:. idx (tint32) - Row index (key). This method is meant for testing and learning, and is not optimized for; production performance. Parameters:. n (int) – Number of rows.; n_partitions (int, optional) – Number of partitions (uses Spark default parallelism",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/utils/index.html:9192,log,log,9192,docs/0.2/utils/index.html,https://hail.is,https://hail.is/docs/0.2/utils/index.html,1,['log'],['log']
Testability,"use in the global model, overrides fitting delta.; :type delta: float or None. :param float sparsity_threshold: Genotype vector sparsity at or below which to use sparse genotype vector in rotation (advanced). :param bool use_dosages: If true, use dosages rather than hard call genotypes. :param int n_eigs: Number of eigenvectors of the kinship matrix used to fit the model. :param float dropped_variance_fraction: Upper bound on fraction of sample variance lost by dropping eigenvectors with small eigenvalues. :return: Variant dataset with linear mixed regression annotations.; :rtype: :py:class:`.VariantDataset`; """""". jvds = self._jvdf.lmmreg(kinshipMatrix._jkm, y, jarray(Env.jvm().java.lang.String, covariates),; use_ml, global_root, va_root, run_assoc, joption(delta), sparsity_threshold,; use_dosages, joption(n_eigs), joption(dropped_variance_fraction)); return VariantDataset(self.hc, jvds). [docs] @handle_py4j; @requireTGenotype; @typecheck_method(test=strlike,; y=strlike,; covariates=listof(strlike),; root=strlike,; use_dosages=bool); def logreg(self, test, y, covariates=[], root='va.logreg', use_dosages=False):; """"""Test each variant for association using logistic regression. .. include:: requireTGenotype.rst. **Examples**. Run the logistic regression Wald test per variant using a Boolean phenotype and two covariates stored; in sample annotations:. >>> vds_result = vds.logreg('wald', 'sa.pheno.isCase', covariates=['sa.pheno.age', 'sa.pheno.isFemale']). **Notes**. The :py:meth:`~hail.VariantDataset.logreg` method performs,; for each variant, a significance test of the genotype in; predicting a binary (case-control) phenotype based on the; logistic regression model. The phenotype type must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded as 1 and 0, respectively. Hail supports the Wald test ('wald'), likelihood ratio test ('lrt'), Rao score test ('score'),; and Firth test ('firth'). Hail only includes samples for whi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:139188,test,test,139188,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,3,"['log', 'test']","['logreg', 'test']"
Testability,"uted. Hail tables can store far more data than can fit on a single computer.; It carries global fields.; It is keyed. A Table has two different kinds of fields:. global fields; row fields. Importing and Reading; Hail can import data from many sources: TSV and CSV files, JSON files, FAM files, databases, Spark, etc. It can also read (and write) a native Hail format.; You can read a dataset with hl.read_table. It take a path and returns a Table. ht stands for Hail Table.; We’ve provided a method to download and import the MovieLens dataset of movie ratings in the Hail native format. Let’s read it!. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages. DOI=https://dx.doi.org/10.1145/2827872. [1]:. import hail as hl; hl.init(). Loading BokehJS ... SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2008-0.2.133-4c60fddb171a.log. [2]:. hl.utils.get_movie_lens('data/'). SLF4J: Failed to load class ""org.slf4j.impl.StaticMDCBinder"".; SLF4J: Defaulting to no-operation MDCAdapter implementation.; SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details.; [Stage 3:> (0 + 1) / 1]. [3]:. users = hl.read_table('data/users.ht'). Exploring Tables; The describe method prints the structure of a table: the fields and their types. [4]:. users.describe(). ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'id': int32; 'age': int32; 'sex",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/03-tables.html:1895,log,logger,1895,docs/0.2/tutorials/03-tables.html,https://hail.is,https://hail.is/docs/0.2/tutorials/03-tables.html,1,['log'],['logger']
Testability,"utput (bool) – If True, set job to always copy output to cloud storage regardless; of whether the job succeeded. Return type:; Self. Returns:; Same job object set to always copy output. always_run(always_run=True); Set the job to always run, even if dependencies fail. Warning; Jobs set to always run are not cancellable!. Examples; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.always_run(); ... .command(f'echo ""hello""')). Parameters:; always_run (bool) – If True, set job to always run. Return type:; Self. Returns:; Same job object set to always run. cloudfuse(bucket, mount_point, *, read_only=True); Add a bucket to mount with gcsfuse in GCP or a storage container with blobfuse in Azure.; Notes; Can only be used with the backend.ServiceBackend. This method can; be called more than once. Warning; There are performance and cost implications of using gcsfuse; or blobfuse. Examples; Google Cloud Platform:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.cloudfuse('my-bucket', '/my-bucket'); ... .command(f'cat /my-bucket/my-blob-object')). Azure:; >>> b = Batch(backend=backend.ServiceBackend('test')); >>> j = b.new_job(); >>> (j.cloudfuse('my-account/my-container', '/dest'); ... .command(f'cat /dest/my-blob-object')). Parameters:. bucket (str) – Name of the google storage bucket to mount or the path to an Azure container in the; format of <account>/<container>.; mount_point (str) – The path at which the cloud blob storage should be mounted to in the Docker; container.; read_only (bool) – If True, mount the cloud blob storage in read-only mode. Return type:; Self. Returns:; Same job object set with a cloud storage path to mount with either gcsfuse or blobfuse. cpu(cores); Set the job’s CPU requirements.; Notes; The string expression must be of the form {number}{suffix}; where the optional suffix is m representing millicpu.; Omitting a suffix means the value is in cpu.; For the ServiceBackend, cores mu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html:2710,test,test,2710,docs/batch/api/batch/hailtop.batch.job.Job.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.Job.html,2,['test'],['test']
Testability,"v._hc. self._log = log. self._tmpdir = tmpdir; self._local_tmpdir = local_tmpdir. self._backend = backend. self._warn_cols_order = True; self._warn_entries_order = True. self._default_ref: Optional[ReferenceGenome] = None. if not quiet:; py_version = version(); sys.stderr.write(; 'Welcome to\n'; ' __ __ <>__\n'; ' / /_/ /__ __/ /\n'; ' / __ / _ `/ / /\n'; ' /_/ /_/\\_,_/_/_/ version {}\n'.format(py_version); ). if py_version.startswith('devel'):; sys.stderr.write(; 'NOTE: This is a beta version. Interfaces may change\n'; ' during the beta period. We recommend pulling\n'; ' the latest changes weekly.\n'; ); sys.stderr.write(f'LOGGING: writing to {log}\n'). self._user_specified_rng_nonce = True; if global_seed is None:; if 'rng_nonce' not in backend.get_flags('rng_nonce'):; backend.set_flags(rng_nonce=hex(Random().randrange(-(2**63), 2**63 - 1))); self._user_specified_rng_nonce = False; else:; backend.set_flags(rng_nonce=hex(global_seed)); Env._hc = self. def initialize_references(self, default_reference):; assert self._backend; self._backend.initialize_references(); if default_reference in BUILTIN_REFERENCES:; self._default_ref = self._backend.get_reference(default_reference); else:; self._default_ref = ReferenceGenome.read(default_reference). @property; def default_reference(self) -> ReferenceGenome:; assert self._default_ref is not None, '_default_ref should have been initialized in HailContext.create'; return self._default_ref. @default_reference.setter; def default_reference(self, value):; if not isinstance(value, ReferenceGenome):; raise TypeError(f'{value} is {type(value)} not a ReferenceGenome'); self._default_ref = value. def stop(self):; assert self._backend; self._backend.stop(); self._backend = None; Env._hc = None; Env._dummy_table = None; Env._seed_generator = None; hail.ir.clear_session_functions(). [docs]@typecheck(; sc=nullable(SparkContext),; app_name=nullable(str),; master=nullable(str),; local=str,; log=nullable(str),; quiet=bool,; append=bool,; mi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:4075,assert,assert,4075,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,['assert'],['assert']
Testability,"v.get_uid(); is_table = isinstance(ds, Table). old_row = ds.row if is_table else ds._rvrow; kept_alleles = hl.range(1, hl.len(old_row.alleles)); if not keep_star:; kept_alleles = kept_alleles.filter(lambda i: old_row.alleles[i] != ""*""). def new_struct(variant, i):; return hl.struct(alleles=variant.alleles, locus=variant.locus, a_index=i, was_split=hl.len(old_row.alleles) > 2). def split_rows(expr, rekey):; if isinstance(ds, MatrixTable):; mt = ds.annotate_rows(**{new_id: expr}).explode_rows(new_id); if rekey:; mt = mt.key_rows_by(); else:; mt = mt.key_rows_by('locus'); new_row_expr = mt._rvrow.annotate(; locus=mt[new_id]['locus'],; alleles=mt[new_id]['alleles'],; a_index=mt[new_id]['a_index'],; was_split=mt[new_id]['was_split'],; old_locus=mt.locus,; old_alleles=mt.alleles,; ).drop(new_id). mt = mt._select_rows('split_multi', new_row_expr); if rekey:; return mt.key_rows_by('locus', 'alleles'); else:; return MatrixTable(ir.MatrixKeyRowsBy(mt._mir, ['locus', 'alleles'], is_sorted=True)); else:; assert isinstance(ds, Table); ht = ds.annotate(**{new_id: expr}).explode(new_id); if rekey:; ht = ht.key_by(); else:; ht = ht.key_by('locus'); new_row_expr = ht.row.annotate(; locus=ht[new_id]['locus'],; alleles=ht[new_id]['alleles'],; a_index=ht[new_id]['a_index'],; was_split=ht[new_id]['was_split'],; old_locus=ht.locus,; old_alleles=ht.alleles,; ).drop(new_id). ht = ht._select('split_multi', new_row_expr); if rekey:; return ht.key_by('locus', 'alleles'); else:; return Table(ir.TableKeyBy(ht._tir, ['locus', 'alleles'], is_sorted=True)). if left_aligned:. def make_struct(i):; def error_on_moved(v):; return (; hl.case(); .when(v.locus == old_row.locus, new_struct(v, i)); .or_error(""Found non-left-aligned variant in split_multi""); ). return hl.bind(error_on_moved, hl.min_rep(old_row.locus, [old_row.alleles[0], old_row.alleles[i]])). return split_rows(hl.sorted(kept_alleles.map(make_struct)), permit_shuffle); else:. def make_struct(i, cond):; def struct_or_empty(v):; return hl.case",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:115532,assert,assert,115532,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['assert'],['assert']
Testability,"va.logreg.pval; Double; Wald p-value testing \(\beta_1 = 0\). LRT, Firth; va.logreg.beta; Double; fit genotype coefficient, \(\hat\beta_1\). LRT, Firth; va.logreg.chi2; Double; deviance statistic. LRT, Firth; va.logreg.pval; Double; LRT / Firth p-value testing \(\beta_1 = 0\). Score; va.logreg.chi2; Double; score statistic. Score; va.logreg.pval; Double; score p-value testing \(\beta_1 = 0\). For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. Test; Annotation; Type; Value. Wald, LRT, Firth; va.logreg.fit.nIter; Int; number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth). Wald, LRT, Firth; va.logreg.fit.converged; Boolean; true if iteration converged. Wald, LRT, Firth; va.logreg.fit.exploded; Boolean; true if iteration exploded. We consider iteration to have converged when every coordinate of \(\beta\) changes by less than \(10^{-6}\). For Wald and LRT, up to 25 iterations are attempted; in testing we find 4 or 5 iterations nearly always suffice. Convergence may also fail due to explosion, which refers to low-level numerical linear algebra exceptions caused by manipulating ill-conditioned matrices. Explosion may result from (nearly) linearly dependent covariates or complete separation.; A more common situation in genetics is quasi-complete seperation, e.g. variants that are observed only in cases (or controls). Such variants inevitably arise when testing millions of variants with very low minor allele count. The maximum likelihood estimate of \(\beta\) under logistic regression is then undefined but convergence may still occur after a large number of iterations due to a very fl",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:112284,log,logreg,112284,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logreg']
Testability,"val(hl.is_missing(hl.missing(hl.tstr))); True. >>> hl.eval(hl.is_missing(hl.missing(hl.tbool) & True)); True. Parameters; ----------; expression; Expression to test. Returns; -------; :class:`.BooleanExpression`; ``True`` if `expression` is missing, ``False`` otherwise.; """"""; return apply_expr(lambda x: ir.IsNA(x), tbool, expression). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def is_nan(x) -> BooleanExpression:; """"""Returns ``True`` if the argument is ``nan`` (not a number). Examples; --------. >>> hl.eval(hl.is_nan(0)); False. >>> hl.eval(hl.is_nan(hl.literal(0) / 0)); True. >>> hl.eval(hl.is_nan(hl.literal(0) / hl.missing(hl.tfloat64))); None. Notes; -----; Note that :func:`~.is_missing` will return ``False`` on ``nan`` since ``nan``; is a defined value. Additionally, this method will return missing if `x` is; missing. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; Expression to test or or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.BooleanExpression`; ``True`` if `x` is ``nan``, ``False`` otherwise or; :class:`.NDArrayNumericExpression` filled with such values; """"""; return _func(""isnan"", tbool, x). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def is_finite(x) -> BooleanExpression:; """"""Returns ``True`` if the argument is a finite floating-point number. Examples; --------; >>> hl.eval(hl.is_finite(0)); True. >>> hl.eval(hl.is_finite(float('nan'))); False. >>> hl.eval(hl.is_finite(float('inf'))); False. >>> hl.eval(hl.is_finite(hl.missing('float32'))); None. Notes; -----; This method will return missing, not ``True``, if `x` is missing. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.BooleanExpression` or :class:`.NDArrayNumericExpression` filled with such expressions; """""";",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:52900,test,test,52900,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"val(s.split('\s+')); ['The', 'quick', 'brown', 'fox']. >>> hl.eval(s.split('\s+', 2)); ['The', 'quick brown fox']. Notes; The delimiter is a regex using the; Java regex syntax; delimiter. To split on special characters, escape them with double; backslash (\\). Parameters:. delim (str or StringExpression) – Delimiter regex.; n (Expression of type tint32, optional) – Maximum number of splits. Returns:; ArrayExpression – Array of split strings. startswith(substr)[source]; Returns whether substr is a prefix of the string.; Examples; >>> hl.eval(s.startswith('The')); True. >>> hl.eval(s.startswith('the')); False. Note; This method is case-sensitive. Parameters:; substr (StringExpression). Returns:; StringExpression. strip()[source]; Returns a copy of the string with whitespace removed from the start; and end.; Examples; >>> s2 = hl.str(' once upon a time\n'); >>> hl.eval(s2.strip()); 'once upon a time'. Returns:; StringExpression. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. translate(mapping)[source]; Translates characters of the string using mapping.; Examples; >>> string = hl.literal('ATTTGCA'); >>> hl.eval(string.translate({'T': 'U'})); 'AUUUGCA'. Parameters:; mapping (DictExpression) – Dictionary of character-character translations. Returns:; StringExpression. See also; replace(). upper()[source]; Returns a copy of the string, but with lower case letters converted; to upper case.; Examples; >>> hl.eval(s.upper()); 'THE QUICK BROWN FOX'. Returns:; StringExpression. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.StringExpression.html:13746,test,tested,13746,docs/0.2/hail.expr.StringExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.StringExpression.html,1,['test'],['tested']
Testability,"value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association.; The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the Jeffrey’s; invariant prior. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the logreg.fit fields reflect the null model; otherwise,; they reflect the full model.; See; Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert’s notes; Statistical Theory.; Firth introduced his approach in; Bias reduction of maximum likelihood estimates, 1993.; Heinze and Schemper further analyze Firth’s approach in; A solution to the problem of separation in logistic regression, 2002.; Hail’s logistic regression tests correspond to the b.wald,; b.lrt, and b.score tests in EPACTS. For each variant, Hail; imputes missing input values as the mean of non-missing input values,; whereas EPACTS subsets to those samples with called genotypes. Hence,; Hail and EPACTS results will currently only agree for variants with no; missing genotypes. Note; Use the pass_through parameter to include additional row fields from; matrix table underlying x. For example, to include an “rsid” field, set; pass_through=['rsid'] or pass_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:13512,test,testing,13512,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,3,"['log', 'test']","['logistic', 'testing', 'tests']"
Testability,"variates for each phenotype.; def fit_null(yvec):; def error_if_not_converged(null_fit):; return (; hl.case(); .when(; ~null_fit.exploded,; (; hl.case(); .when(null_fit.converged, null_fit); .or_error(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:59967,test,test,59967,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"variates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowered_poisson_regression_rows/x', x). row_exprs = _get_regression_row_fields(mt, pass_through, '_lowered_poisson_regression_rows'); mt = mt._select_all(; row_exprs=dict(pass_through=hl.struct(**row_exprs)),; col_exprs=dict(y=y, covariates=covariates),; entry_exprs=dict(x=x),; ); # FIXME: the order of the columns is irrelevant to regression; mt = mt.key_cols_by(). mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covari",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:63952,test,test,63952,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,6,"['assert', 'test']","['assert', 'test']"
Testability,"ve missing annotations.; Phenotype and covariate sample annotations may also be specified using programmatic expressions without identifiers, such as:; if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation sa.fam.isCase added by importing a FAM file with case-control phenotype, case is 1 and control is 0.; Hail’s logistic regression tests correspond to the b.wald, b.lrt, and b.score tests in EPACTS. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes. Parameters:; test (str) – Statistical test, one of: ‘wald’, ‘lrt’, ‘score’, or ‘firth’.; y (str) – Response expression. Must evaluate to Boolean or; numeric with all values 0 or 1.; covariates (list of str) – list of covariate expressions; root (str) – Variant annotation path to store result of logistic regression.; use_dosages (bool) – If true, use genotype dosage rather than hard call. Returns:Variant dataset with logistic regression variant annotations. Return type:VariantDataset. logreg_burden(key_name, variant_keys, single_key, agg_expr, test, y, covariates=[])[source]¶; Test each keyed group of variants for association by aggregating (collapsing) genotypes and applying the; logistic regression model. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Run a gene burden test using the logistic Wald test on the maximum genotype per gene. Here va.genes is; a variant annotation of type Set[String] giving the set of genes containing the variant; (see Extended example in linreg_burden() for a deeper dive in the context of linear regression):; >>> logreg_kt, sample_kt = (hc.read('data/example_burden.vds'); ... .logreg_burden(key_name='gene',; ... variant_keys='va.genes',; ... single_k",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:116957,log,logistic,116957,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logistic']
Testability,"vector; of different i.i.d standard normal variables, so we can interpret :math:`Q` as a weighted sum of; i.i.d. standard normal variables:. .. math::. \begin{align*}; \tilde{h} &= U^T h \\; Q &= \sum_s \Lambda_{ss} \tilde{h}_s^2; \end{align*}. The distribution of such sums (indeed, any quadratic form of i.i.d. standard normal variables); is governed by the generalized chi-squared distribution (the CDF is available in Hail as; :func:`.pgenchisq`):. .. math::. \begin{align*}; \lambda_i &= \Lambda_{ii} \\; Q &\sim \mathrm{GeneralizedChiSquared}(\lambda, \vec{1}, \vec{0}, 0, 0); \end{align*}. Therefore, we can test the null hypothesis by calculating the probability of receiving values; larger than :math:`Q`. If that probability is very small, then the residual phenotypes are; likely not i.i.d. normal variables with variance :math:`\widehat{\sigma}^2`. The SKAT method was originally described in:. Wu MC, Lee S, Cai T, Li Y, Boehnke M, Lin X. *Rare-variant association testing for; sequencing data with the sequence kernel association test.* Am J Hum Genet. 2011 Jul; 15;89(1):82-93. doi: 10.1016/j.ajhg.2011.05.029. Epub 2011 Jul 7. PMID: 21737059; PMCID:; PMC3135811. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3135811/. Examples; --------. Generate a dataset with a phenotype noisily computed from the genotypes:. >>> hl.reset_global_randomness(); >>> mt = hl.balding_nichols_model(1, n_samples=100, n_variants=20); >>> mt = mt.annotate_rows(gene = mt.locus.position // 12); >>> mt = mt.annotate_rows(weight = 1); >>> mt = mt.annotate_cols(phenotype = hl.agg.sum(mt.GT.n_alt_alleles()) - 20 + hl.rand_norm(0, 1)). Test if the phenotype is significantly associated with the genotype:. >>> skat = hl._linear_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:75339,test,testing,75339,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,4,['test'],"['test', 'testing']"
Testability,"vening"" |; | 7 | NA |; +-------+------------------+. Notes; Use this function to capture large Python objects for use in expressions. This; function provides an alternative to adding an object as a global annotation on a; Table or MatrixTable. Parameters:; x – Object to capture and broadcast as an expression. Returns:; Expression. hail.expr.functions.cond(condition, consequent, alternate, missing_false=False)[source]; Deprecated in favor of if_else().; Expression for an if/else statement; tests a condition and returns one of two options based on the result.; Examples; >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; If condition evaluates to True, returns consequent. If condition; evaluates to False, returns alternate. If predicate is missing, returns; missing. Note; The type of consequent and alternate must be the same. Parameters:. condition (BooleanExpression) – Condition to test.; consequent (Expression) – Branch to return if the condition is True.; alternate (Expression) – Branch to return if the condition is False.; missing_false (bool) – If True, treat missing condition as False. See also; case(), switch(), if_else(). Returns:; Expression – One of consequent, alternate, or missing, based on condition. hail.expr.functions.if_else(condition, consequent, alternate, missing_false=False)[source]; Expression for an if/else statement; tests a condition and returns one of two options based on the result.; Examples; >>> x = 5; >>> hl.eval(hl.if_else(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.if_else(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; If condition evaluates to True, returns consequent. If condition; evaluates to False, returns alternate. If predicate is missing, returns; missing. Note; The type of consequent and alternate must be the same. Parameters:. condition (BooleanExpressi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/core.html:3652,test,test,3652,docs/0.2/functions/core.html,https://hail.is,https://hail.is/docs/0.2/functions/core.html,1,['test'],['test']
Testability,"vmat.T) @ xvec).reshape((-1, 1)); fisher10 = fisher01.T; fisher11 = hl.nd.array([[(mu * xvec.T) @ xvec]]); fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). fisher_div_score = hl.nd.solve(fisher, score, no_crash=True); chi_sq = hl.or_missing(~fisher_div_score.failed, score @ fisher_div_score.solution); p = hl.pchisqtail(chi_sq, dof); return chi_sq, p. [docs]def linear_mixed_model(y, x, z_t=None, k=None, p_path=None, overwrite=False, standardize=True, mean_impute=True):; r""""""Initialize a linear mixed model from a matrix table. .. warning::. This functionality is no longer implemented/supported as of Hail 0.2.94.; """"""; raise NotImplementedError(""linear_mixed_model is no longer implemented/supported as of Hail 0.2.94""). [docs]@typecheck(; entry_expr=expr_float64,; model=LinearMixedModel,; pa_t_path=nullable(str),; a_t_path=nullable(str),; mean_impute=bool,; partition_size=nullable(int),; pass_through=sequenceof(oneof(str, Expression)),; ); def linear_mixed_regression_rows(; entry_expr, model, pa_t_path=None, a_t_path=None, mean_impute=True, partition_size=None, pass_through=(); ):; """"""For each row, test an input variable for association using a linear; mixed model. .. warning::. This functionality is no longer implemented/supported as of Hail 0.2.94.; """"""; raise NotImplementedError(""linear_mixed_model is no longer implemented/supported as of Hail 0.2.94""). @typecheck(; group=expr_any,; weight=expr_float64,; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; max_size=int,; accuracy=numeric,; iterations=int,; ); def _linear_skat(; group, weight, y, x, covariates, max_size: int = 46340, accuracy: float = 1e-6, iterations: int = 10000; ):; r""""""The linear sequence kernel association test (SKAT). Linear SKAT tests if the phenotype, `y`, is significantly associated with the genotype, `x`. For; :math:`N` samples, in a group of :math:`M` variants, with :math:`K` covariates, the model is; given by:. .. math::. \",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:71047,test,test,71047,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"with degrees of freedom specified by df. p must satisfy 0 < p <= 1. Inverse of pchisq1tail.; Arguments. p (Double) – Probability; df (Double) – Degrees of freedom. qnorm(p: Double): Double. Returns left-quantile x for which p = Prob(\(Z\) < x) with \(Z\) a standard normal random variable. p must satisfy 0 < p < 1. Inverse of pnorm.; Arguments. p (Double) – Probability. qpois(p: Double, lambda: Double, lowerTail: Boolean, logP: Boolean): Int. If lowerTail equals true, returns the smallest integer \(x\) such that Prob(\(X \leq x\)) \(\geq\) p where \(X\) is a Poisson random variable with rate parameter lambda.; If lowerTail equals false, returns the largest integer \(x\) such that Prob(\(X > x\)) \(\geq\) p. Inverts ppois.; Arguments. p (Double) – Quantile to compute. Must satisfy \(0 \leq p \leq 1\).; lambda (Double) – Poisson rate parameter. Must be non-negative.; lowerTail (Boolean) – If false, returns the right-tail inverse cumulative density function.; logP (Boolean) – If true, input quantiles are given as log(p). qpois(p: Double, lambda: Double): Int. Returns the smallest integer \(x\) such that Prob(\(X \leq x\)) \(\geq\) p where \(X\) is a Poisson random variable with rate parameter lambda. Inverts ppois.; Arguments. p (Double) – Quantile to compute. Must satisfy \(0 \leq p \leq 1\).; lambda (Double) – Poisson rate parameter. Must be non-negative. range(start: Int, stop: Int, step: Int): Array[Int]. Generate an Array with values in the interval [start, stop) in increments of step.; let r = range(0, 5, 2) in r; result: [0, 2, 4]. Arguments. start (Int) – Starting number of the sequence.; stop (Int) – Generate numbers up to, but not including this number.; step (Int) – Difference between each number in the sequence. range(start: Int, stop: Int): Array[Int]. Generate an Array with values in the interval [start, stop).; let r = range(5, 8) in r; result: [5, 6, 7]. Arguments. start (Int) – Starting number of the sequence.; stop (Int) – Generate numbers up to, but n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:15850,log,logP,15850,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,2,['log'],"['log', 'logP']"
Testability,"with input variable the number of alternate alleles as before, and again with input variable the genotype dosage derived from the PL field. [46]:. gwas = hl.linear_regression_rows(; y=mt.pheno.CaffeineConsumption,; x=mt.GT.n_alt_alleles(),; covariates=[1.0, mt.pheno.isFemale, mt.scores[0], mt.scores[1], mt.scores[2]]). [Stage 166:> (0 + 1) / 1]. We’ll first make a Q-Q plot to assess inflation…. [47]:. p = hl.plot.qq(gwas.p_value); show(p). That’s more like it! This shape is indicative of a well-controlled (but not especially well-powered) study. And now for the Manhattan plot:. [48]:. p = hl.plot.manhattan(gwas.p_value); show(p). We have found a caffeine consumption locus! Now simply apply Hail’s Nature paper function to publish the result.; Just kidding, that function won’t land until Hail 1.0!. Rare variant analysis; Here we’ll demonstrate how one can use the expression language to group and count by any arbitrary properties in row and column fields. Hail also implements the sequence kernel association test (SKAT). [49]:. entries = mt.entries(); results = (entries.group_by(pop = entries.pheno.SuperPopulation, chromosome = entries.locus.contig); .aggregate(n_het = hl.agg.count_where(entries.GT.is_het()))). [50]:. results.show(). [Stage 184:> (0 + 1) / 1]. popchromosomen_hetstrstrint64; ""AFR""""1""11039; ""AFR""""10""7123; ""AFR""""11""6777; ""AFR""""12""7016; ""AFR""""13""4650; ""AFR""""14""4262; ""AFR""""15""3847; ""AFR""""16""4564; ""AFR""""17""3607; ""AFR""""18""4133; showing top 10 rows. We use the MatrixTable.entries method to convert our matrix table to a table (with one row for each sample for each variant). In this representation, it is easy to aggregate over any fields we like, which is often the first step of rare variant analysis.; What if we want to group by minor allele frequency bin and hair color, and calculate the mean GQ?. [51]:. entries = entries.annotate(maf_bin = hl.if_else(entries.info.AF[0]<0.01, ""< 1%"",; hl.if_else(entries.info.AF[0]<0.05, ""1%-5%"", "">5%""))). results2 = (entries.g",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html:23693,test,test,23693,docs/0.2/tutorials/01-genome-wide-association-study.html,https://hail.is,https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html,1,['test'],['test']
Testability,"ws(self, caller, row) -> 'MatrixTable':; analyze(caller, row, self._row_indices, {self._col_axis}); base, cleanup = self._process_joins(row); return cleanup(MatrixTable(ir.MatrixMapRows(base._mir, row._ir))). @typecheck_method(caller=str, col=expr_struct(), new_key=nullable(sequenceof(str))); def _select_cols(self, caller, col, new_key=None) -> 'MatrixTable':; analyze(caller, col, self._col_indices, {self._row_axis}); base, cleanup = self._process_joins(col); return cleanup(MatrixTable(ir.MatrixMapCols(base._mir, col._ir, new_key))). @typecheck_method(caller=str, s=expr_struct()); def _select_globals(self, caller, s) -> 'MatrixTable':; base, cleanup = self._process_joins(s); analyze(caller, s, self._global_indices); return cleanup(MatrixTable(ir.MatrixMapGlobals(base._mir, s._ir))). [docs] @typecheck(datasets=matrix_table_type, _check_cols=bool); def union_rows(*datasets: 'MatrixTable', _check_cols=True) -> 'MatrixTable':; """"""Take the union of dataset rows. Examples; --------. .. testsetup::. dataset_to_union_1 = dataset; dataset_to_union_2 = dataset. Union the rows of two datasets:. >>> dataset_result = dataset_to_union_1.union_rows(dataset_to_union_2). Given a list of datasets, take the union of all rows:. >>> all_datasets = [dataset_to_union_1, dataset_to_union_2]. The following three syntaxes are equivalent:. >>> dataset_result = dataset_to_union_1.union_rows(dataset_to_union_2); >>> dataset_result = all_datasets[0].union_rows(*all_datasets[1:]); >>> dataset_result = hl.MatrixTable.union_rows(*all_datasets). Notes; -----. In order to combine two datasets, three requirements must be met:. - The column keys must be identical, both in type, value, and ordering.; - The row key schemas and row schemas must match.; - The entry schemas must match. The column fields in the resulting dataset are the column fields from; the first dataset; the column schemas do not need to match. This method does not deduplicate; if a row exists identically in two; datasets, then it will be",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:116216,test,testsetup,116216,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,['test'],['testsetup']
Testability,"ww2.stat.duke.edu/~scs/Courses/Stat376/Papers/GibbsFieldEst/BiasReductionMLE.pdf>`__. Heinze and Schemper further analyze Firth's approach in `A solution to the problem of separation in logistic regression, 2002 <https://cemsiis.meduniwien.ac.at/fileadmin/msi_akim/CeMSIIS/KB/volltexte/Heinze_Schemper_2002_Statistics_in_Medicine.pdf>`__. Those variants that don't vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations. Phenotype and covariate sample annotations may also be specified using `programmatic expressions <exprlang.html>`__ without identifiers, such as:. .. code-block:: text. if (sa.isFemale) sa.cov.age else (2 * sa.cov.age + 10). For Boolean covariate types, true is coded as 1 and false as 0. In particular, for the sample annotation ``sa.fam.isCase`` added by importing a FAM file with case-control phenotype, case is 1 and control is 0. Hail's logistic regression tests correspond to the ``b.wald``, ``b.lrt``, and ``b.score`` tests in `EPACTS <http://genome.sph.umich.edu/wiki/EPACTS#Single_Variant_Tests>`__. For each variant, Hail imputes missing genotypes as the mean of called genotypes, whereas EPACTS subsets to those samples with called genotypes. Hence, Hail and EPACTS results will currently only agree for variants with no missing genotypes. :param str test: Statistical test, one of: 'wald', 'lrt', 'score', or 'firth'. :param str y: Response expression. Must evaluate to Boolean or; numeric with all values 0 or 1. :param covariates: list of covariate expressions; :type covariates: list of str. :param str root: Variant annotation path to store result of logistic regression. :param bool use_dosages: If true, use genotype dosage rather than hard call. :return: Variant dataset with logistic regression variant annotations.; :rtype: :py:class:`.VariantDataset`; """""". jvds = self._jvdf.logreg(test, y, jarray(Env.jvm().java.lang.String, covariates), root, use_dosages); return VariantDataset(self.hc, jvds). [docs] @handle_py4",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:147894,test,tests,147894,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['test'],['tests']
Testability,"w¶; This notebook is designed to provide a broad overview of Hail’s; functionality, with emphasis on the functionality to manipulate and; query a genetic dataset. We walk through a genome-wide SNP association; test, and demonstrate the need to control for confounding caused by; population stratification.; Each notebook starts the same: we import the hail package and create; a HailContext. This; object is the entry point for most Hail functionality. In [1]:. from hail import *; hc = HailContext(). Running on Apache Spark version 2.0.2; SparkUI available at http://10.56.135.40:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-5a67787. If the above cell ran without error, we’re ready to go!; Before using Hail, we import some standard Python libraries for use; throughout the notebook. In [2]:. import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; import matplotlib.patches as mpatches; from collections import Counter; from math import log, isnan; from pprint import pprint; %matplotlib inline. Installing and importing; seaborn is optional; it; just makes the plots prettier. In [3]:. # optional; import seaborn. Check for tutorial data or download if necessary¶; This cell downloads the necessary data from Google Storage if it isn’t; found in the current working directory. In [4]:. import os; if os.path.isdir('data/1kg.vds') and os.path.isfile('data/1kg_annotations.txt'):; print('All files are present and accounted for!'); else:; import sys; sys.stderr.write('Downloading data (~50M) from Google Storage...\n'); import urllib; import tarfile; urllib.urlretrieve('https://storage.googleapis.com/hail-1kg/tutorial_data.tar',; 'tutorial_data.tar'); sys.stderr.write('Download finished!\n'); sys.stderr.write('Extracting...\n'); tarfile.open('tutorial_data.tar').extractall(); if not (os.path.isdir('data/1kg.vds') and os.path.isfile('data/1kg_annotations.txt')):; raise RuntimeError('Something went wrong!'); else:; sys.stderr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/hail-overview.html:1688,log,log,1688,docs/0.1/tutorials/hail-overview.html,https://hail.is,https://hail.is/docs/0.1/tutorials/hail-overview.html,1,['log'],['log']
Testability,"x (int) - Number of complex alternate alleles.; star (int) - Number of star (upstream deletion) alternate alleles.; max_alleles (int) - The highest number of alleles at any variant. Returns:Object containing summary information. Return type:Summary. tdt(pedigree, root='va.tdt')[source]¶; Find transmitted and untransmitted variants; count per variant and; nuclear family. Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; Compute TDT association results:; >>> pedigree = Pedigree.read('data/trios.fam'); >>> (vds.tdt(pedigree); ... .export_variants(""output/tdt_results.tsv"", ""Variant = v, va.tdt.*"")). Notes; The transmission disequilibrium test tracks the number of times the alternate allele is transmitted (t) or not transmitted (u) from a heterozgyous parent to an affected child under the null that the rate of such transmissions is 0.5. For variants where transmission is guaranteed (i.e., the Y chromosome, mitochondria, and paternal chromosome X variants outside of the PAR), the test cannot be used.; The TDT statistic is given by. \[(t-u)^2 \over (t+u)\]; and follows a 1 degree of freedom chi-squared distribution under the null hypothesis.; The number of transmissions and untransmissions for each possible set of genotypes is determined from the table below. The copy state of a locus with respect to a trio is defined as follows, where PAR is the pseudoautosomal region (PAR). HemiX – in non-PAR of X and child is male; Auto – otherwise (in autosome or PAR, or child is female). Kid; Dad; Mom; Copy State; T; U. HomRef; Het; Het; Auto; 0; 2. HomRef; HomRef; Het; Auto; 0; 1. HomRef; Het; HomRef; Auto; 0; 1. Het; Het; Het; Auto; 1; 1. Het; HomRef; Het; Auto; 1; 0. Het; Het; HomRef; Auto; 1; 0. Het; HomVar; Het; Auto; 0; 1. Het; Het; HomVar; Auto; 0; 1. HomVar; Het; Het; Auto; 2; 0. HomVar; Het; HomVar; Auto; 1; 0. HomVar; HomVar; Het; Auto; 1; 0. HomRef; HomRef; Het; HemiX; 0; 1. HomRef; HomVar; Het; HemiX; 0; 1. HomVar; HomRef; He",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:168322,test,test,168322,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['test'],['test']
Testability,"x(call[, aaf_threshold, ...]); Impute sex of samples by calculating inbreeding coefficient on the X chromosome. ld_matrix(entry_expr, locus_expr, radius[, ...]); Computes the windowed correlation (linkage disequilibrium) matrix between variants. ld_prune(call_expr[, r2, bp_window_size, ...]); Returns a maximal subset of variants that are nearly uncorrelated within each window. compute_charr(ds[, min_af, max_af, min_dp, ...]); Compute CHARR, the DNA sample contamination estimator. mendel_errors(call, pedigree); Find Mendel errors; count per variant, individual and nuclear family. de_novo(mt, pedigree, pop_frequency_prior, *); Call putative de novo events from trio data. nirvana(dataset, config[, block_size, name]); Annotate variants using Nirvana. sample_qc(mt[, name]); Compute per-sample metrics useful for quality control. _logistic_skat(group, weight, y, x, covariates); The logistic sequence kernel association test (SKAT). skat(key_expr, weight_expr, y, x, covariates); Test each keyed group of rows for association by linear or logistic SKAT test. lambda_gc(p_value[, approximate]); Compute genomic inflation factor (lambda GC) from an Expression of p-values. split_multi(ds[, keep_star, left_aligned, ...]); Split multiallelic variants. split_multi_hts(ds[, keep_star, ...]); Split multiallelic variants for datasets that contain one or more fields from a standard high-throughput sequencing entry schema. summarize_variants(mt[, show, handler]); Summarize the variants present in a dataset and print the results. transmission_disequilibrium_test(dataset, ...); Performs the transmission disequilibrium test on trios. trio_matrix(dataset, pedigree[, complete_trios]); Builds and returns a matrix where columns correspond to trios and entries contain genotypes for the trio. variant_qc(mt[, name]); Compute common variant statistics (quality control metrics). vep(dataset[, config, block_size, name, ...]); Annotate variants with VEP. class hail.methods.VEPConfig[source]; Base class",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:2816,log,logistic,2816,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"xed model above is mathematically equivalent to the model. .. math::. U^Ty \\sim \mathrm{N}\\left(U^TX\\beta, \sigma_g^2 (S + \delta I)\\right). for which the covariance is diagonal (e.g., unmixed). That is, rotating the phenotype vector (:math:`y`) and covariate vectors (columns of :math:`X`) in :math:`\mathbb{R}^n` by :math:`U^T` transforms the model to one with independent residuals. For any particular value of :math:`\delta`, the restricted maximum likelihood (REML) solution for the latter model can be solved exactly in time complexity that is linear rather than cubic in :math:`n`. In particular, having rotated, we can run a very efficient 1-dimensional optimization procedure over :math:`\delta` to find the REML estimate :math:`(\hat{\delta}, \\hat{\\beta}, \\hat{\sigma}_g^2)` of the triple :math:`(\delta, \\beta, \sigma_g^2)`, which in turn determines :math:`\\hat{\sigma}_e^2` and :math:`\\hat{h}^2`. We first compute the maximum log likelihood on a :math:`\delta`-grid that is uniform on the log scale, with :math:`\\mathrm{ln}(\delta)` running from -8 to 8 by 0.01, corresponding to :math:`h^2` decreasing from 0.9995 to 0.0005. If :math:`h^2` is maximized at the lower boundary then standard linear regression would be more appropriate and Hail will exit; more generally, consider using standard linear regression when :math:`\\hat{h}^2` is very small. A maximum at the upper boundary is highly suspicious and will also cause Hail to exit. In any case, the log file records the table of grid values for further inspection, beginning under the info line containing ""lmmreg: table of delta"". If the optimal grid point falls in the interior of the grid as expected, we then use `Brent's method <https://en.wikipedia.org/wiki/Brent%27s_method>`__ to find the precise location of the maximum over the same range, with initial guess given by the optimal grid point and a tolerance on :math:`\\mathrm{ln}(\delta)` of 1e-6. If this location differs from the optimal grid point by more th",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:130564,log,log,130564,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,2,['log'],['log']
Testability,"xplosion, which refers to low-level numerical linear algebra exceptions caused by manipulating ill-conditioned matrices. Explosion may result from (nearly) linearly dependent covariates or complete `separation <https://en.wikipedia.org/wiki/Separation_(statistics)>`__. A more common situation in genetics is quasi-complete seperation, e.g. variants that are observed only in cases (or controls). Such variants inevitably arise when testing millions of variants with very low minor allele count. The maximum likelihood estimate of :math:`\\beta` under logistic regression is then undefined but convergence may still occur after a large number of iterations due to a very flat likelihood surface. In testing, we find that such variants produce a secondary bump from 10 to 15 iterations in the histogram of number of iterations per variant. We also find that this faux convergence produces large standard errors and large (insignificant) p-values. To not miss such variants, consider using Firth logistic regression, linear regression, or group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic, and linear regression models to this data, where ``x`` is genotype, ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085, and 0.0016, respectively. The erroneous value 0.991 is due to quasi-complete separation. Moving one of the 10 hets from case to control eliminates this quasi-complete separation; the p-va",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:144540,log,logistic,144540,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,2,"['log', 'test']","['logistic', 'tests']"
Testability,"xpression`; String to parse. Returns; -------; :class:`.CallExpression`; """"""; return _func('Call', tcall, s). [docs]@typecheck(expression=expr_any); def is_defined(expression) -> BooleanExpression:; """"""Returns ``True`` if the argument is not missing. Examples; --------. >>> hl.eval(hl.is_defined(5)); True. >>> hl.eval(hl.is_defined(hl.missing(hl.tstr))); False. >>> hl.eval(hl.is_defined(hl.missing(hl.tbool) & True)); False. Parameters; ----------; expression; Expression to test. Returns; -------; :class:`.BooleanExpression`; ``True`` if `expression` is not missing, ``False`` otherwise.; """"""; return ~apply_expr(lambda x: ir.IsNA(x), tbool, expression). [docs]@typecheck(expression=expr_any); def is_missing(expression) -> BooleanExpression:; """"""Returns ``True`` if the argument is missing. Examples; --------. >>> hl.eval(hl.is_missing(5)); False. >>> hl.eval(hl.is_missing(hl.missing(hl.tstr))); True. >>> hl.eval(hl.is_missing(hl.missing(hl.tbool) & True)); True. Parameters; ----------; expression; Expression to test. Returns; -------; :class:`.BooleanExpression`; ``True`` if `expression` is missing, ``False`` otherwise.; """"""; return apply_expr(lambda x: ir.IsNA(x), tbool, expression). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def is_nan(x) -> BooleanExpression:; """"""Returns ``True`` if the argument is ``nan`` (not a number). Examples; --------. >>> hl.eval(hl.is_nan(0)); False. >>> hl.eval(hl.is_nan(hl.literal(0) / 0)); True. >>> hl.eval(hl.is_nan(hl.literal(0) / hl.missing(hl.tfloat64))); None. Notes; -----; Note that :func:`~.is_missing` will return ``False`` on ``nan`` since ``nan``; is a defined value. Additionally, this method will return missing if `x` is; missing. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; Expression to test or or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.BooleanExpression`; ``True`` if `x` is ``nan``, ``False`` ot",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:52057,test,test,52057,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['test'],['test']
Testability,"xpressions. class Ascending:; def __init__(self, col):; self.col = col. def __eq__(self, other):; return isinstance(other, Ascending) and self.col == other.col. def __ne__(self, other):; return not self == other. class Descending:; def __init__(self, col):; self.col = col. def __eq__(self, other):; return isinstance(other, Descending) and self.col == other.col. def __ne__(self, other):; return not self == other. [docs]@typecheck(col=oneof(Expression, str)); def asc(col):; """"""Sort by `col` ascending."""""". return Ascending(col). [docs]@typecheck(col=oneof(Expression, str)); def desc(col):; """"""Sort by `col` descending."""""". return Descending(col). class ExprContainer:; # this can only grow as big as the object dir, so no need to worry about memory leak; _warned_about: ClassVar = set(). def __init__(self):; self._fields: Dict[str, Expression] = {}; self._fields_inverse: Dict[Expression, str] = {}; self._dir = set(dir(self)); super(ExprContainer, self).__init__(). def _set_field(self, key, value):; assert key not in self._fields_inverse, key; self._fields[key] = value; self._fields_inverse[value] = key. # key is in __dir for methods; # key is in __dict__ for private class fields; if key in self._dir or key in self.__dict__:; if key not in ExprContainer._warned_about:; ExprContainer._warned_about.add(key); warning(; f""Name collision: field {key!r} already in object dict. ""; f""\n This field must be referenced with __getitem__ syntax: obj[{key!r}]""; ); else:; self.__dict__[key] = value. def _get_field(self, item) -> Expression:; if item in self._fields:; return self._fields[item]. raise LookupError(get_nice_field_error(self, item)). def __iter__(self):; raise TypeError(f""'{self.__class__.__name__}' object is not iterable""). def __delattr__(self, item):; if not item[0] == '_':; raise NotImplementedError(f""'{self.__class__.__name__}' object is not mutable""). def __setattr__(self, key, value):; if not key[0] == '_':; raise NotImplementedError(f""'{self.__class__.__name__}' object ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:3105,assert,assert,3105,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['assert'],['assert']
Testability,"xprs, n_samples_exprs, n_blocks=200, two_step_threshold=30, n_reference_panel_variants=None)[source]; Estimate SNP-heritability and level of confounding biases from genome-wide association study; (GWAS) summary statistics.; Given a set or multiple sets of GWAS summary statistics, ld_score_regression() estimates the heritability; of a trait or set of traits and the level of confounding biases present in; the underlying studies by regressing chi-squared statistics on LD scores,; leveraging the model:. \[\mathrm{E}[\chi_j^2] = 1 + Na + \frac{Nh_g^2}{M}l_j\]. \(\mathrm{E}[\chi_j^2]\) is the expected chi-squared statistic; for variant \(j\) resulting from a test of association between; variant \(j\) and a trait.; \(l_j = \sum_{k} r_{jk}^2\) is the LD score of variant; \(j\), calculated as the sum of squared correlation coefficients; between variant \(j\) and nearby variants. See ld_score(); for further details.; \(a\) captures the contribution of confounding biases, such as; cryptic relatedness and uncontrolled population structure, to the; association test statistic.; \(h_g^2\) is the SNP-heritability, or the proportion of variation; in the trait explained by the effects of variants included in the; regression model above.; \(M\) is the number of variants used to estimate \(h_g^2\).; \(N\) is the number of samples in the underlying association study. For more details on the method implemented in this function, see:. LD Score regression distinguishes confounding from polygenicity in genome-wide association studies (Bulik-Sullivan et al, 2015). Examples; Run the method on a matrix table of summary statistics, where the rows; are variants and the columns are different phenotypes:; >>> mt_gwas = ld_score_all_phenos_sumstats; >>> ht_results = hl.experimental.ld_score_regression(; ... weight_expr=mt_gwas['ld_score'],; ... ld_score_expr=mt_gwas['ld_score'],; ... chi_sq_exprs=mt_gwas['chi_squared'],; ... n_samples_exprs=mt_gwas['n']). Run the method on a table with summary sta",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/experimental/index.html:9257,test,test,9257,docs/0.2/experimental/index.html,https://hail.is,https://hail.is/docs/0.2/experimental/index.html,1,['test'],['test']
Testability,"y default, Hail uses pre-compiled native libraries that are compatible with; recent Mac OS X and Debian releases. If you’re not using one of these OSes, set; the environment (or Make) variable HAIL_COMPILE_NATIVES to any value. This; variable tells GNU Make to build the native libraries from source.; Build and install a wheel file from source with local-mode pyspark:; make install HAIL_COMPILE_NATIVES=1. As above, but explicitly specifying the Scala and Spark versions:; make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5. Building the Docs and Website; Install build dependencies listed in the docs style guide.; Build without rendering the notebooks (which is slow):; make hail-docs-do-not-render-notebooks. Build while rendering the notebooks:; make hail-docs. Serve the built website on http://localhost:8000/; (cd build/www && python3 -m http.server). Running the tests; Install development dependencies:; make -C .. install-dev-requirements. A couple Hail tests compare to PLINK 1.9 (not PLINK 2.0 [ignore the confusing; URL]):. PLINK 1.9. Execute every Hail test using at most 8 parallel threads:; make -j8 test. Contributing; Chat with the dev team on our Zulip chatroom or; development forum if you have an idea for a contribution.; We can help you determine if your project is a good candidate for merging.; Keep in mind the following principles when submitting a pull request:. A PR should focus on a single feature. Multiple features should be split into multiple PRs.; Before submitting your PR, you should rebase onto the latest main.; PRs must pass all tests before being merged. See the section above on Running the tests locally.; PRs require a review before being merged. We will assign someone from our dev team to review your PR.; When you make a PR, include a short message that describes the purpose of the; PR and any necessary context for the changes you are making.; For user facing changes (new functions, etc), include “CHANGELOG” in the c",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/getting_started_developing.html:2252,test,tests,2252,docs/0.2/getting_started_developing.html,https://hail.is,https://hail.is/docs/0.2/getting_started_developing.html,1,['test'],['tests']
Testability,"y numpy.tofile; or BlockMatrix.tofile().; Binary files produced and consumed by tofile() and; fromfile() are not platform independent, so should only be used; for inter-operating with NumPy, not storage. Use; BlockMatrix.write() and BlockMatrix.read() to save and load; block matrices, since these methods write and read blocks in parallel; and are platform independent.; A NumPy ndarray must have type float64 for the output of; func:numpy.tofile to be a valid binary input to fromfile().; This is not checked.; The number of entries must be less than \(2^{31}\). Parameters:. uri (str, optional) – URI of binary input file.; n_rows (int) – Number of rows.; n_cols (int) – Number of columns.; block_size (int, optional) – Block size. Default given by default_block_size(). See also; from_numpy(). property is_sparse; Returns True if block-sparse.; Notes; A block matrix is block-sparse if at least of its blocks is dropped,; i.e. implicitly a block of zeros. Returns:; bool. log()[source]; Element-wise natural logarithm. Returns:; BlockMatrix. property n_cols; Number of columns. Returns:; int. property n_rows; Number of rows. Returns:; int. persist(storage_level='MEMORY_AND_DISK')[source]; Persists this block matrix in memory or on disk.; Notes; The BlockMatrix.persist() and BlockMatrix.cache(); methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; BlockMatrix.write(), which stores a permanent file.; Most users should use the “MEMORY_AND_DISK” storage level. See the Spark; documentation; for a more in-depth discussion of persisting data. Parameters:; storage_level (str) – Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns:; BlockMatrix – Persisted block matrix. classmethod ran",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html:25083,log,log,25083,docs/0.2/linalg/hail.linalg.BlockMatrix.html,https://hail.is,https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html,2,['log'],"['log', 'logarithm']"
Testability,"y times does each appear?. We can answer these questions with aggregation. Aggregation combines many values together to create a summary.; To start, we’ll aggregate all the values in a table. (Later, we’ll learn how to aggregate over subsets.); We can do this with the Table.aggregate method.; A call to aggregate has two parts:. The expression to aggregate over (e.g. a field of a Table).; The aggregator to combine the values into the summary. Hail has a large suite of aggregators for summarizing data. Let’s see some in action!. count; Aggregators live in the hl.agg module. The simplest aggregator is count. It takes no arguments and returns the number of values aggregated. [1]:. import hail as hl; from bokeh.io import output_notebook,show; output_notebook(); hl.init(). hl.utils.get_movie_lens('data/'); users = hl.read_table('data/users.ht'). Loading BokehJS ... Loading BokehJS ... SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2008-0.2.133-4c60fddb171a.log; 2024-10-04 20:09:01.799 Hail: INFO: Movie Lens files found!. [2]:. users.aggregate(hl.agg.count()). SLF4J: Failed to load class ""org.slf4j.impl.StaticMDCBinder"".; SLF4J: Defaulting to no-operation MDCAdapter implementation.; SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details. [2]:. 943. [3]:. users.count(). [3]:. 943. stats; stats computes useful statistics about a numeric expression at once. There are also aggregators for mean, min, max, sum, product and array_sum. [4]:. users.show(). idagesexoccupationzipcodeint32int32strstrstr; 124""M""""technician""""85711""",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/04-aggregation.html:2161,log,logger,2161,docs/0.2/tutorials/04-aggregation.html,https://hail.is,https://hail.is/docs/0.2/tutorials/04-aggregation.html,1,['log'],['logger']
Testability,"y to write; a pipeline that runs a random forest for various windows in the genome. The; complete code is provided here for your reference. run_rf_simple.py; from typing import Tuple. import pandas as pd; from sklearn.ensemble import RandomForestRegressor. import hailtop.batch as hb; import hailtop.fs as hfs. def random_forest(df_x_path: str, df_y_path: str, window_name: str, cores: int = 1) -> Tuple[str, float, float]:; # read in data; df_x = pd.read_table(df_x_path, header=0, index_col=0); df_y = pd.read_table(df_y_path, header=0, index_col=0). # split training and testing data for the current window; x_train = df_x[df_x.index != window_name]; x_test = df_x[df_x.index == window_name]. y_train = df_y[df_y.index != window_name]; y_test = df_y[df_y.index == window_name]. # run random forest; max_features = 3 / 4; rf = RandomForestRegressor(n_estimators=100, n_jobs=cores, max_features=max_features, oob_score=True, verbose=False). rf.fit(x_train, y_train). # apply the trained random forest on testing data; y_pred = rf.predict(x_test). # store obs and pred values for this window; obs = y_test[""oe""].to_list()[0]; pred = y_pred[0]. return (window_name, obs, pred). def as_tsv(input: Tuple[str, float, float]) -> str:; return '\t'.join(str(i) for i in input). def main(df_x_path, df_y_path, output_path, python_image):; backend = hb.ServiceBackend(); b = hb.Batch(name='rf-loo', default_python_image=python_image). with hfs.open(df_y_path) as f:; local_df_y = pd.read_table(f, header=0, index_col=0). df_x_input = b.read_input(df_x_path); df_y_input = b.read_input(df_y_path). results = []. for window in local_df_y.index.to_list():; j = b.new_python_job(); result = j.call(random_forest, df_x_input, df_y_input, window); tsv_result = j.call(as_tsv, result); results.append(tsv_result.as_str()). output = hb.concatenate(b, results); b.write_output(output, output_path). b.run(wait=False); backend.close(). run_rf_checkpoint.py; from typing import Tuple. import pandas as pd; from sklearn",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/cookbook/random_forest.html:12453,test,testing,12453,docs/batch/cookbook/random_forest.html,https://hail.is,https://hail.is/docs/batch/cookbook/random_forest.html,2,['test'],['testing']
Testability,"y-indexed expression for input variable.; covariates (list of Float64Expression) – List of column-indexed covariate expressions.; block_size (int) – Number of row regressions to perform simultaneously per core. Larger blocks; require more memory but may improve performance.; pass_through (list of str or Expression) – Additional row fields to include in the resulting table.; weights (Float64Expression or list of Float64Expression) – Optional column-indexed weighting for doing weighted least squares regression. Specify a single weight if a; single y or list of ys is specified. If a list of lists of ys is specified, specify one weight per inner list. Returns:; Table. hail.methods.logistic_regression_rows(test, y, x, covariates, pass_through=(), *, max_iterations=None, tolerance=None)[source]; For each row, test an input variable for association with a; binary response variable using logistic regression.; Examples; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). As above but with at most 100 Newton iterations and a stricter-than-default tolerance of 1e-8:; >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.phe",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:6399,log,logistic,6399,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,2,"['log', 'test']","['logistic', 'test']"
Testability,"y_field_names]). # Fit null models, which means doing a logreg fit with just the covariates for each phenotype.; def fit_null(yvec):; def error_if_not_converged(null_fit):; return (; hl.case(); .when(; ~null_fit.exploded,; (; hl.case(); .when(null_fit.converged, null_fit); .or_error(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:59887,test,test,59887,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['test'],['test']
Testability,"ype :py:data:`.tfloat64`; """"""; return _func(""pF"", tfloat64, x, df1, df2, lower_tail, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def ppois(x, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a Poisson distribution. Examples; --------. >>> hl.eval(hl.ppois(2, 1)); 0.9196986029286058. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is a; Poisson random variable with rate parameter `lamb`. If `lower_tail` is false,; returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; lamb : float or :class:`.Expression` of type :py:data:`.tfloat64`; Rate parameter of Poisson distribution.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""ppois"", tfloat64, x, lamb, lower_tail, log_p). [docs]@typecheck(p=expr_float64, df=expr_float64, ncp=nullable(expr_float64), lower_tail=expr_bool, log_p=expr_bool); def qchisqtail(p, df, ncp=None, lower_tail=False, log_p=False) -> Float64Expression:; """"""The quantile function of a chi-squared distribution with `df` degrees of; freedom, inverts :func:`~.pchisqtail`. Examples; --------. >>> hl.eval(hl.qchisqtail(0.05, 2)); 5.991464547107979. >>> hl.eval(hl.qchisqtail(0.05, 2, ncp=2)); 10.838131614372958. >>> hl.eval(hl.qchisqtail(0.05, 2, lower_tail=True)); 0.10258658877510107. >>> hl.eval(hl.qchisqtail(hl.log(0.05), 2, log_p=True)); 5.991464547107979. Notes; -----; Returns right-quantile `x` for which `p` = Prob(:math:`Z^2` > x) with; :math:`Z^2` a chi-squared random variable with degrees of freedom specified; by `df`. The probability `p` must satisfy 0 < `p` < 1. Pa",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:76868,log,logarithm,76868,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,['log'],['logarithm']
Testability,"ype. Returns; -------; :class:`.BooleanExpression`; ``True`` if every element is contained in set `s`.; """"""; if not s._type.element_type == self._type.element_type:; raise TypeError(; ""'SetExpression.is_subset' expects 's' to be the same type\n""; "" set type: '{}'\n""; "" type of 's': '{}'"".format(self._type, s._type); ); return self._method(""isSubset"", tbool, s). [docs] @typecheck_method(s=expr_set()); def union(self, s):; """"""Return the union of the set and set `s`. Examples; --------. >>> hl.eval(s1.union(s2)); {1, 2, 3, 5}. Parameters; ----------; s : :class:`.SetExpression`; Set expression of the same type. Returns; -------; :class:`.SetExpression`; Set of elements present in either set.; """"""; if not s._type.element_type == self._type.element_type:; raise TypeError(; ""'SetExpression.union' expects 's' to be the same type\n""; "" set type: '{}'\n""; "" type of 's': '{}'"".format(self._type, s._type); ); return self._method(""union"", self._type, s). [docs] def __le__(self, other):; """"""Test whether every element in the set is in `other`. Parameters; ----------; other : :class:`.SetExpression`; Set expression of the same type. Returns; -------; :class:`.BooleanExpression`; ``True`` if every element in the set is in `other`. ``False`` otherwise.; """"""; other = to_expr(other); if isinstance(other.dtype, hl.tset):; return self.is_subset(other). return NotImplemented. [docs] def __lt__(self, other):; """"""Test whether the set is a proper subset of `other` (``set <= other and set != other``). Parameters; ----------; other : :class:`.SetExpression`; Set expression of the same type. Returns; -------; :class:`.BooleanExpression`; ``True`` if the set is a proper subset of `other`. ``False`` otherwise.; """"""; other = to_expr(other); if isinstance(other.dtype, hl.tset):; return self.is_subset(other) & (self != other). return NotImplemented. [docs] def __ge__(self, other):; """"""Test whether every element in `other` is in the set. Parameters; ----------; other : :class:`.SetExpression`; Set ex",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:30802,Test,Test,30802,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,1,['Test'],['Test']
Testability,"ypecheck_method(item=expr_any); def __getitem__(self, item):; """"""Get the value associated with key `item`. Examples; --------. >>> hl.eval(d['Alice']); 43. Notes; -----; Raises an error if `item` is not a key of the dictionary. Use; :meth:`.DictExpression.get` to return missing instead of an error. Parameters; ----------; item : :class:`.Expression`; Key expression. Returns; -------; :class:`.Expression`; Value associated with key `item`.; """"""; if not self._kc.can_coerce(item.dtype):; raise TypeError(; ""dict encountered an invalid key type\n"" "" dict key type: '{}'\n"" "" type of 'item': '{}'"".format(; self.dtype.key_type, item.dtype; ); ); return self._index(self.dtype.value_type, self._kc.coerce(item)). [docs] @typecheck_method(item=expr_any); def contains(self, item):; """"""Returns whether a given key is present in the dictionary. Examples; --------. >>> hl.eval(d.contains('Alice')); True. >>> hl.eval(d.contains('Anne')); False. Parameters; ----------; item : :class:`.Expression`; Key to test for inclusion. Returns; -------; :class:`.BooleanExpression`; ``True`` if `item` is a key of the dictionary, ``False`` otherwise.; """"""; if not self._kc.can_coerce(item.dtype):; raise TypeError(; ""'DictExpression.contains' encountered an invalid key type\n""; "" dict key type: '{}'\n""; "" type of 'item': '{}'"".format(self._type.key_type, item.dtype); ); return self._method(""contains"", tbool, self._kc.coerce(item)). [docs] @typecheck_method(item=expr_any, default=nullable(expr_any)); def get(self, item, default=None):; """"""Returns the value associated with key `k` or a default value if that key is not present. Examples; --------. >>> hl.eval(d.get('Alice')); 43. >>> hl.eval(d.get('Anne')); None. >>> hl.eval(d.get('Anne', 0)); 0. Parameters; ----------; item : :class:`.Expression`; Key.; default : :class:`.Expression`; Default value. Must be same type as dictionary values. Returns; -------; :class:`.Expression`; The value associated with `item`, or `default`.; """"""; if not self._kc.can_co",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:37764,test,test,37764,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,['test'],['test']
Testability,"ython API; Functions; Statistical functions. View page source. Statistical functions. chi_squared_test(c1, c2, c3, c4); Performs chi-squared test of independence on a 2x2 contingency table. fisher_exact_test(c1, c2, c3, c4); Calculates the p-value, odds ratio, and 95% confidence interval using Fisher's exact test for a 2x2 table. contingency_table_test(c1, c2, c3, c4, ...); Performs chi-squared or Fisher's exact test of independence on a 2x2 contingency table. cochran_mantel_haenszel_test(a, b, c, d); Perform the Cochran-Mantel-Haenszel test for association. dbeta(x, a, b); Returns the probability density at x of a beta distribution with parameters a (alpha) and b (beta). dchisq(x, df[, ncp, log_p]); Compute the probability density at x of a chi-squared distribution with df degrees of freedom. dnorm(x[, mu, sigma, log_p]); Compute the probability density at x of a normal distribution with mean mu and standard deviation sigma. dpois(x, lamb[, log_p]); Compute the (log) probability density at x of a Poisson distribution with rate parameter lamb. hardy_weinberg_test(n_hom_ref, n_het, n_hom_var); Performs test of Hardy-Weinberg equilibrium. binom_test(x, n, p, alternative); Performs a binomial test on p given x successes in n trials. pchisqtail(x, df[, ncp, lower_tail, log_p]); Returns the probability under the right-tail starting at x for a chi-squared distribution with df degrees of freedom. pgenchisq(x, w, k, lam, mu, sigma, *[, ...]); The cumulative probability function of a generalized chi-squared distribution. pnorm(x[, mu, sigma, lower_tail, log_p]); The cumulative probability function of a normal distribution with mean mu and standard deviation sigma. pT(x, n[, lower_tail, log_p]); The cumulative probability function of a t-distribution with n degrees of freedom. pF(x, df1, df2[, lower_tail, log_p]); The cumulative probability function of a F-distribution with parameters df1 and df2. ppois(x, lamb[, lower_tail, log_p]); The cumulative probability function of a ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:1621,log,log,1621,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['log'],['log']
Testability,"{\sigma}_g^2\). global.lmmreg.sigmaE2; Double; fit coefficient of environmental variance \(\hat{\sigma}_e^2\). global.lmmreg.delta; Double; fit ratio of variance component coefficients, \(\hat{\delta}\). global.lmmreg.h2; Double; fit narrow-sense heritability, \(\hat{h}^2\). global.lmmreg.nEigs; Int; number of eigenvectors of kinship matrix used to fit model. global.lmmreg.dropped_variance_fraction; Double; specified value of dropped_variance_fraction. global.lmmreg.evals; Array[Double]; all eigenvalues of the kinship matrix in descending order. global.lmmreg.fit.seH2; Double; standard error of \(\hat{h}^2\) under asymptotic normal approximation. global.lmmreg.fit.normLkhdH2; Array[Double]; likelihood function of \(h^2\) normalized on the discrete grid 0.01, 0.02, ..., 0.99. Index i is the likelihood for percentage i. global.lmmreg.fit.maxLogLkhd; Double; (restricted) maximum log likelihood corresponding to \(\hat{\delta}\). global.lmmreg.fit.logDeltaGrid; Array[Double]; values of \(\mathrm{ln}(\delta)\) used in the grid search. global.lmmreg.fit.logLkhdVals; Array[Double]; (restricted) log likelihood of \(y\) given \(X\) and \(\mathrm{ln}(\delta)\) at the (RE)ML fit of \(\beta\) and \(\sigma_g^2\). These global annotations are also added to hail.log, with the ranked evals and \(\delta\) grid with values in .tsv tabular form. Use grep 'lmmreg:' hail.log to find the lines just above each table.; If Step 5 is performed, lmmreg() also adds four linear regression variant annotations. Annotation; Type; Value. va.lmmreg.beta; Double; fit genotype coefficient, \(\hat\beta_0\). va.lmmreg.sigmaG2; Double; fit coefficient of genetic variance component, \(\hat{\sigma}_g^2\). va.lmmreg.chi2; Double; \(\chi^2\) statistic of the likelihood ratio test. va.lmmreg.pval; Double; \(p\)-value. Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; The simplest way to export all resulting annotations is:; >>> lmm_vds.e",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:94623,log,logDeltaGrid,94623,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['log'],['logDeltaGrid']
Testability,"{sigmoid}` is the `sigmoid; function <https://en.wikipedia.org/wiki/Sigmoid_function>`__, the; genotype :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; :math:`\mathrm{isFemale}` is coded as 1 for true (female) and; 0 for false (male). The null model sets :math:`\\beta_1 = 0`. The resulting variant annotations depend on the test statistic; as shown in the tables below. ========== =================== ====== =====; Test Annotation Type Value; ========== =================== ====== =====; Wald ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; Wald ``va.logreg.se`` Double estimated standard error, :math:`\widehat{\mathrm{se}}`; Wald ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`; Wald ``va.logreg.pval`` Double Wald p-value testing :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton iteration. To help diagnose convergence issues, Hail also emits three variant annotations which summarize the iterative fitting process:. ================ =========================== ======= =====; Test Annotation Type Value; ================ =========================== ======= =====; Wald, LRT, Firth ``va.logreg.fit.nIter`` Int number of iterations until convergence, explosion, or reaching the max (25 for Wald, LRT; 100 for Firth); Wald, LR",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:142063,log,logreg,142063,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"| ; Core language functions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); hail; Classes; Modules; expressions; types; functions; aggregators; scans; methods; nd; utils; linalg; stats; genetics; plot; ggplot; vds; experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; Functions; Core language functions. View page source. Core language functions. literal(x[, dtype]); Captures and broadcasts a Python variable or object as an expression. cond(condition, consequent, alternate[, ...]); Deprecated in favor of if_else(). if_else(condition, consequent, alternate[, ...]); Expression for an if/else statement; tests a condition and returns one of two options based on the result. switch(expr); Build a conditional tree on the value of an expression. case([missing_false]); Chain multiple if-else statements with a CaseBuilder. bind(f, *exprs[, _ctx]); Bind a temporary variable and use it in a function. rbind(*exprs[, _ctx]); Bind a temporary variable and use it in a function. missing(t); Creates an expression representing a missing value of a specified type. null(t); Deprecated in favor of missing(). str(x); Returns the string representation of x. is_missing(expression); Returns True if the argument is missing. is_defined(expression); Returns True if the argument is not missing. coalesce(*args); Returns the first non-missing value of args. or_else(a, b); If a is missing, return b. or_missing(predicate, value); Returns value if predicate is True, otherwise returns missing. range(start[, stop, step]); Returns an array of integers from start to stop by step. query_table(path, point_or_interval); Query records fr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/core.html:994,test,tests,994,docs/0.2/functions/core.html,https://hail.is,https://hail.is/docs/0.2/functions/core.html,1,['test'],['tests']
Testability,"| a | b |; +-------+-------+; | int32 | int32 |; +-------+-------+; | 0 | 200 |; | 5 | 10 |; +-------+-------+. You may also specify only a handful of types in partial_type. Hail will automatically; deduce the types of the other fields. Hail _cannot_ deduce the type of a field which only; contains empty arrays (the element type is unspecified), so we specify the type of labels; explicitly.; >>> dictionaries = [; ... {""number"":10038,""state"":""open"",""user"":{""login"":""tpoterba"",""site_admin"":False,""id"":10562794}, ""milestone"":None,""labels"":[]},; ... {""number"":10037,""state"":""open"",""user"":{""login"":""daniel-goldstein"",""site_admin"":False,""id"":24440116},""milestone"":None,""labels"":[]},; ... {""number"":10036,""state"":""open"",""user"":{""login"":""jigold"",""site_admin"":False,""id"":1693348},""milestone"":None,""labels"":[]},; ... {""number"":10035,""state"":""open"",""user"":{""login"":""tpoterba"",""site_admin"":False,""id"":10562794},""milestone"":None,""labels"":[]},; ... {""number"":10033,""state"":""open"",""user"":{""login"":""tpoterba"",""site_admin"":False,""id"":10562794},""milestone"":None,""labels"":[]},; ... ]; >>> t = hl.Table.parallelize(; ... dictionaries,; ... partial_type={""milestone"": hl.tstr, ""labels"": hl.tarray(hl.tstr)}; ... ); >>> t.show(); +--------+--------+--------------------+-----------------+----------+; | number | state | user.login | user.site_admin | user.id |; +--------+--------+--------------------+-----------------+----------+; | int32 | str | str | bool | int32 |; +--------+--------+--------------------+-----------------+----------+; | 10038 | ""open"" | ""tpoterba"" | False | 10562794 |; | 10037 | ""open"" | ""daniel-goldstein"" | False | 24440116 |; | 10036 | ""open"" | ""jigold"" | False | 1693348 |; | 10035 | ""open"" | ""tpoterba"" | False | 10562794 |; | 10033 | ""open"" | ""tpoterba"" | False | 10562794 |; +--------+--------+--------------------+-----------------+----------+; +-----------+------------+; | milestone | labels |; +-----------+------------+; | str | array<str> |; +-----------+------------+; | NA | [] |",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.Table.html:51664,log,login,51664,docs/0.2/hail.Table.html,https://hail.is,https://hail.is/docs/0.2/hail.Table.html,1,['log'],['login']
Testability,"| str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. size(); Returns the size of a collection.; Examples; >>> hl.eval(a.size()); 5. >>> hl.eval(s3.size()); 3. Returns:; Expression of type tint32 – The number of elements in the collection. starmap(f); Transform each element of a collection of tuples.; Examples; >>> hl.eval(hl.array([(1, 2), (2, 3)]).starmap(lambda x, y: x+y)); [3, 5]. Parameters:; f (function ( (*args) -> Expression)) – Function to transform each element of the collection. Returns:; CollectionExpression. – Collection where each element has been transformed according to f. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. union(s)[source]; Return the union of the set and set s.; Examples; >>> hl.eval(s1.union(s2)); {1, 2, 3, 5}. Parameters:; s (SetExpression) – Set expression of the same type. Returns:; SetExpression – Set of elements present in either set. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.SetExpression.html:14289,test,tested,14289,docs/0.2/hail.expr.SetExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.SetExpression.html,1,['test'],['tested']
Testability,"} \\; &= V^{1/2} (I - Q Q^T) V^{1/2} \\; \end{align*}\]; Substitute this simplified expression into \(Z\):. \[\begin{align*}; Z^T Z &= W^{1/2} G^T V^{1/2} (I - Q Q^T) V^{1/2} G W^{1/2} \\; \end{align*}\]; Split this symmetric matrix by observing that \(I - Q Q^T\) is idempotent:. \[\begin{align*}; I - Q Q^T &= (I - Q Q^T)(I - Q Q^T)^T \\; \\; Z &= (I - Q Q^T) V^{1/2} G W^{1/2} \\; Z &= (G - Q Q^T G) V^{1/2} W^{1/2}; \end{align*}\]; Finally, the squared singular values of \(Z\) are the eigenvalues of \(Z^T Z\), so; \(Q\) should be distributed as follows:. \[\begin{align*}; U S V^T &= Z \quad\quad \textrm{the singular value decomposition} \\; \lambda_s &= S_{ss}^2 \\; \\; Q &\sim \textrm{GeneralizedChiSquared}(\lambda, \vec{1}, \vec{0}, 0, 0); \end{align*}\]; The null hypothesis test tests for the probability of observing even larger values of \(Q\).; The SKAT method was originally described in:. Wu MC, Lee S, Cai T, Li Y, Boehnke M, Lin X. Rare-variant association testing for; sequencing data with the sequence kernel association test. Am J Hum Genet. 2011 Jul; 15;89(1):82-93. doi: 10.1016/j.ajhg.2011.05.029. Epub 2011 Jul 7. PMID: 21737059; PMCID:; PMC3135811. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3135811/. Examples; Generate a dataset with a phenotype noisily computed from the genotypes:; >>> hl.reset_global_randomness(); >>> mt = hl.balding_nichols_model(1, n_samples=100, n_variants=20); >>> mt = mt.annotate_rows(gene = mt.locus.position // 12); >>> mt = mt.annotate_rows(weight = 1); >>> mt = mt.annotate_cols(phenotype = (hl.agg.sum(mt.GT.n_alt_alleles()) - 20 + hl.rand_norm(0, 1)) > 0.5). Test if the phenotype is significantly associated with the genotype:; >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:71829,test,testing,71829,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,2,['test'],"['test', 'testing']"
Testability,"} {""s"":2,""family"":""fam1""} {""s"":3,""family"":""fam1""}; 1:1 [""A"",""C""] 0/1 0/0 0/1 0/0; 1:2 [""A"",""C""] 1/1 0/1 0/1 0/1; 1:3 [""A"",""C""] 0/0 0/1 0/0 0/0; 1:4 [""A"",""C""] 0/1 1/1 0/1 0/1. Parameters:. path (str) – The path to which to export.; delimiter (str) – The string for delimiting columns.; missing (str) – The string to output for missing values.; header (bool) – When True include a header line. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None); Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. summarize(handler=None); Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True); Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.BooleanExpression.html:9318,log,logging,9318,docs/0.2/hail.expr.BooleanExpression.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.BooleanExpression.html,12,"['log', 'test']","['logging', 'tested']"
Testability,"} {""s"":3,""family"":""fam1""}; 1:1 [""A"",""C""] 0/1 0/0 0/1 0/0; 1:2 [""A"",""C""] 1/1 0/1 0/1 0/1; 1:3 [""A"",""C""] 0/0 0/1 0/0 0/0; 1:4 [""A"",""C""] 0/1 1/1 0/1 0/1. Parameters:. path (str) – The path to which to export.; delimiter (str) – The string for delimiting columns.; missing (str) – The string to output for missing values.; header (bool) – When True include a header line. show(n=None, width=None, truncate=None, types=True, handler=None, n_rows=None, n_cols=None)[source]; Print the first few records of the expression to the console.; If the expression refers to a value on a keyed axis of a table or matrix; table, then the accompanying keys will be shown along with the records.; Examples; >>> table1.SEX.show(); +-------+-----+; | ID | SEX |; +-------+-----+; | int32 | str |; +-------+-----+; | 1 | ""M"" |; | 2 | ""M"" |; | 3 | ""F"" |; | 4 | ""F"" |; +-------+-----+. >>> hl.literal(123).show(); +--------+; | <expr> |; +--------+; | int32 |; +--------+; | 123 |; +--------+. Notes; The output can be passed piped to another output source using the handler argument:; >>> ht.foo.show(handler=lambda x: logging.info(x)) . Parameters:. n (int) – Maximum number of rows to show.; width (int) – Horizontal width at which to break columns.; truncate (int, optional) – Truncate each field to the given number of characters. If; None, truncate fields to the given width.; types (bool) – Print an extra header line with the type of each field. summarize(handler=None)[source]; Compute and print summary information about the expression. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. take(n, _localize=True)[source]; Collect the first n records of an expression.; Examples; Take the first three rows:; >>> table1.X.take(3); [5, 6, 7]. Warning; Extremely experimental. Parameters:; n (int) – Number of records to take. Returns:; list. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.expr.Expression-1.html:5747,log,logging,5747,docs/0.2/hail.expr.Expression-1.html,https://hail.is,https://hail.is/docs/0.2/hail.expr.Expression-1.html,4,"['log', 'test']","['logging', 'tested']"
Testability,"}(\mathrm{Het})` and :math:`\mathrm{P}(\mathrm{HomVar})` are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1. The example above considers a model of the form. .. math::. \mathrm{Prob}(\mathrm{isCase}) = \mathrm{sigmoid}(\\beta_0 + \\beta_1 \, \mathrm{gt} + \\beta_2 \, \mathrm{age} + \\beta_3 \, \mathrm{isFemale} + \\varepsilon), \quad \\varepsilon \sim \mathrm{N}(0, \sigma^2). where :math:`\mathrm{sigmoid}` is the `sigmoid; function <https://en.wikipedia.org/wiki/Sigmoid_function>`__, the; genotype :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for; Het, and 2 for HomVar, and the Boolean covariate; :math:`\mathrm{isFemale}` is coded as 1 for true (female) and; 0 for false (male). The null model sets :math:`\\beta_1 = 0`. The resulting variant annotations depend on the test statistic; as shown in the tables below. ========== =================== ====== =====; Test Annotation Type Value; ========== =================== ====== =====; Wald ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; Wald ``va.logreg.se`` Double estimated standard error, :math:`\widehat{\mathrm{se}}`; Wald ``va.logreg.zstat`` Double Wald :math:`z`-statistic, equal to :math:`\hat\\beta_1 / \widehat{\mathrm{se}}`; Wald ``va.logreg.pval`` Double Wald p-value testing :math:`\\beta_1 = 0`; LRT, Firth ``va.logreg.beta`` Double fit genotype coefficient, :math:`\hat\\beta_1`; LRT, Firth ``va.logreg.chi2`` Double deviance statistic; LRT, Firth ``va.logreg.pval`` Double LRT / Firth p-value testing :math:`\\beta_1 = 0`; Score ``va.logreg.chi2`` Double score statistic; Score ``va.logreg.pval`` Double score p-value testing :math:`\\beta_1 = 0`; ========== =================== ====== =====. For the Wald and likelihood ratio tests, Hail fits the logistic model for each variant using Newton iteration and only emits the above annotations when the maximum likelihood estimate of the coefficients converges. The Firth test uses a modified form of Newton it",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:141620,log,logreg,141620,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['log'],['logreg']
Testability,"}]"".format(; missing_sex_count, missing_sex_values; ); ). return Pedigree(trios). @property; def trios(self):; """"""List of trio objects in this pedigree. :rtype: list of :class:`.Trio`; """"""; return self._trios. [docs] def complete_trios(self):; """"""List of trio objects that have a defined father and mother. :rtype: list of :class:`.Trio`; """"""; return list(filter(lambda t: t.is_complete(), self.trios)). [docs] @typecheck_method(samples=sequenceof(nullable(str))); def filter_to(self, samples):; """"""Filter the pedigree to a given list of sample IDs. **Notes**. For any trio, the following steps will be applied:. - If the proband is not in the list of samples provided, the trio is removed.; - If the father is not in the list of samples provided, `pat_id` is set to ``None``.; - If the mother is not in the list of samples provided, `mat_id` is set to ``None``. Parameters; ----------; samples: :obj:`list` [:obj:`str`]; Sample IDs to keep. Returns; -------; :class:`.Pedigree`; """"""; sample_set = set(samples). filtered_trios = []; for trio in self._trios:; restricted_trio = trio._restrict_to(sample_set); if restricted_trio is not None:; filtered_trios.append(restricted_trio). return Pedigree(filtered_trios). [docs] @typecheck_method(path=str); def write(self, path):; """"""Write a .fam file to the given path. **Examples**. >>> ped = hl.Pedigree.read('data/test.fam'); >>> ped.write('output/out.fam'). **Notes**. This method writes a `PLINK .fam file <https://www.cog-genomics.org/plink2/formats#fam>`_. .. caution::. Phenotype information is not preserved in the Pedigree data; structure in Hail. Reading and writing a PLINK .fam file will; result in loss of this information. Use :func:`~.import_fam` to; manipulate this information. :param path: output path; :type path: str; """""". lines = [t._to_fam_file_line() for t in self._trios]. with Env.fs().open(path, mode=""w"") as file:; for line in lines:; file.write(line + ""\n""). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html:7409,test,test,7409,docs/0.2/_modules/hail/genetics/pedigree.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html,2,['test'],['test']
Testability," c2, c3, c4); Performs chi-squared test of independence on a 2x2 contingency table. fisher_exact_test(c1, c2, c3, c4); Calculates the p-value, odds ratio, and 95% confidence interval using Fisher's exact test for a 2x2 table. contingency_table_test(c1, c2, c3, c4, ...); Performs chi-squared or Fisher's exact test of independence on a 2x2 contingency table. cochran_mantel_haenszel_test(a, b, c, d); Perform the Cochran-Mantel-Haenszel test for association. dbeta(x, a, b); Returns the probability density at x of a beta distribution with parameters a (alpha) and b (beta). dchisq(x, df[, ncp, log_p]); Compute the probability density at x of a chi-squared distribution with df degrees of freedom. dnorm(x[, mu, sigma, log_p]); Compute the probability density at x of a normal distribution with mean mu and standard deviation sigma. dpois(x, lamb[, log_p]); Compute the (log) probability density at x of a Poisson distribution with rate parameter lamb. hardy_weinberg_test(n_hom_ref, n_het, n_hom_var); Performs test of Hardy-Weinberg equilibrium. binom_test(x, n, p, alternative); Performs a binomial test on p given x successes in n trials. pchisqtail(x, df[, ncp, lower_tail, log_p]); Returns the probability under the right-tail starting at x for a chi-squared distribution with df degrees of freedom. pgenchisq(x, w, k, lam, mu, sigma, *[, ...]); The cumulative probability function of a generalized chi-squared distribution. pnorm(x[, mu, sigma, lower_tail, log_p]); The cumulative probability function of a normal distribution with mean mu and standard deviation sigma. pT(x, n[, lower_tail, log_p]); The cumulative probability function of a t-distribution with n degrees of freedom. pF(x, df1, df2[, lower_tail, log_p]); The cumulative probability function of a F-distribution with parameters df1 and df2. ppois(x, lamb[, lower_tail, log_p]); The cumulative probability function of a Poisson distribution. qchisqtail(p, df[, ncp, lower_tail, log_p]); The quantile function of a chi-squared di",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:1762,test,test,1762,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,1,['test'],['test']
Testability," fam[, ...]); Import a PLINK dataset (BED, BIM, FAM) as a MatrixTable. import_table(paths[, key, min_partitions, ...]); Import delimited text file (text table) as Table. import_vcf(path[, force, force_bgz, ...]); Import VCF file(s) as a MatrixTable. index_bgen(path[, index_file_map, ...]); Index BGEN files as required by import_bgen(). read_matrix_table(path, *[, _intervals, ...]); Read in a MatrixTable written with MatrixTable.write(). read_table(path, *[, _intervals, ...]); Read in a Table written with Table.write(). Statistics. linear_mixed_model(y, x[, z_t, k, p_path, ...]); Initialize a linear mixed model from a matrix table. linear_mixed_regression_rows(entry_expr, model); For each row, test an input variable for association using a linear mixed model. linear_regression_rows(y, x, covariates[, ...]); For each row, test an input variable for association with response variables using linear regression. logistic_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a binary response variable using logistic regression. poisson_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a count response variable using Poisson regression. pca(entry_expr[, k, compute_loadings]); Run principal component analysis (PCA) on numeric columns derived from a matrix table. row_correlation(entry_expr[, block_size]); Computes the correlation matrix between row vectors. Genetics. balding_nichols_model(n_populations, ...[, ...]); Generate a matrix table of variants, samples, and genotypes using the Balding-Nichols or Pritchard-Stephens-Donnelly model. concordance(left, right, *[, ...]); Calculate call concordance with another dataset. filter_intervals(ds, intervals[, keep]); Filter rows with a list of intervals. filter_alleles(mt, f); Filter alternate alleles. filter_alleles_hts(mt, f[, subset]); Filter alternate alleles and update standard GATK entry fields. genetic_relatedness_matrix(call_expr);",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/index.html:3669,test,test,3669,docs/0.2/methods/index.html,https://hail.is,https://hail.is/docs/0.2/methods/index.html,3,"['log', 'test']","['logistic', 'test']"
Testability,". class hail.genetics.Pedigree[source]; Class containing a list of trios, with extra functionality. Parameters:; trios (list of Trio) – list of trio objects to include in pedigree. Attributes. trios; List of trio objects in this pedigree. Methods. complete_trios; List of trio objects that have a defined father and mother. filter_to; Filter the pedigree to a given list of sample IDs. read; Read a PLINK .fam file and return a pedigree object. write; Write a .fam file to the given path. complete_trios()[source]; List of trio objects that have a defined father and mother. Return type:; list of Trio. filter_to(samples)[source]; Filter the pedigree to a given list of sample IDs.; Notes; For any trio, the following steps will be applied:. If the proband is not in the list of samples provided, the trio is removed.; If the father is not in the list of samples provided, pat_id is set to None.; If the mother is not in the list of samples provided, mat_id is set to None. Parameters:; samples (list [str]) – Sample IDs to keep. Returns:; Pedigree. classmethod read(fam_path, delimiter='\\s+')[source]; Read a PLINK .fam file and return a pedigree object.; Examples; >>> ped = hl.Pedigree.read('data/test.fam'). Notes; See PLINK .fam file for; the required format. Parameters:. fam_path (str) – path to .fam file.; delimiter (str) – Field delimiter. Return type:; Pedigree. property trios; List of trio objects in this pedigree. Return type:; list of Trio. write(path)[source]; Write a .fam file to the given path.; Examples; >>> ped = hl.Pedigree.read('data/test.fam'); >>> ped.write('output/out.fam'). Notes; This method writes a PLINK .fam file. Caution; Phenotype information is not preserved in the Pedigree data; structure in Hail. Reading and writing a PLINK .fam file will; result in loss of this information. Use import_fam() to; manipulate this information. Parameters:; path (str) – output path. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/genetics/hail.genetics.Pedigree.html:1892,test,test,1892,docs/0.2/genetics/hail.genetics.Pedigree.html,https://hail.is,https://hail.is/docs/0.2/genetics/hail.genetics.Pedigree.html,2,['test'],['test']
Testability,"﻿. . Contents — Hail. Toggle navigation. HOME. DOCS. 0.2 (Stable); 0.1 (Deprecated). FORUM; CHAT; CODE; JOBS. Hail; . ; . 0.1; . Getting Started; Overview; Tutorials; Expression Language; Python API; Annotation Database; Other Resources. Hail. Docs »; Contents. View page source. Contents¶. Getting Started; Running Hail locally; Building Hail from source; BLAS and LAPACK; Running the tests. Overview; Variant Dataset (VDS); Expressions. Tutorials; Hail Overview; Introduction to the expression language; Expression language: query, annotate, and aggregate. Expression Language; Language Constructs; Operators; Types; Functions. Python API; HailContext; VariantDataset; KeyTable; KinshipMatrix; LDMatrix; representation; expr; utils. Annotation Database; Database Query; Documentation; Important Notes; Suggest additions or edits. Other Resources; Hadoop Glob Patterns; SQL. Indices and tables¶. Index; Search Page. Next . © Copyright 2016, Hail Team. . Built with Sphinx using a theme provided by Read the Docs. . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/index.html:386,test,tests,386,docs/0.1/index.html,https://hail.is,https://hail.is/docs/0.1/index.html,1,['test'],['tests']
Testability,"﻿. . Functions — Hail. Toggle navigation. HOME. DOCS. 0.2 (Stable); 0.1 (Deprecated). FORUM; CHAT; CODE; JOBS. Hail; . ; . 0.1; . Getting Started; Overview; Tutorials; Expression Language; Language Constructs; Operators; Types; Functions. Python API; Annotation Database; Other Resources. Hail. Docs »; Expression Language »; Functions. View page source. Functions¶. binomTest(x: Int, n: Int, p: Double, alternative: String): Double. Returns the p-value from the exact binomial test of the null hypothesis that success has probability p, given x successes in n trials.; Examples; Test each variant for allele balance across all heterozygous genotypes, under the null hypothesis that the two alleles are sampled with equal probability.; >>> (vds.split_multi(); ... .annotate_variants_expr(; ... 'va.ab_binom_test = let all_samples_ad = gs.filter(g => g.isHet).map(g => g.ad).sum() in '; ... 'binomTest(all_samples_ad[1], all_samples_ad.sum(), 0.5, ""two.sided"")')). Arguments. x (Int) – Number of successes; n (Int) – Number of trials; p (Double) – Probability of success under the null hypothesis; alternative (String) – Alternative hypothesis, must be “two.sided”, “greater” or “less”. chisq(c1: Int, c2: Int, c3: Int, c4: Int): Struct{pValue:Double,oddsRatio:Double}. pValue (Double) – p-value; oddsRatio (Double) – odds ratio. Calculates p-value (Chi-square approximation) and odds ratio for 2x2 table; Arguments. c1 (Int) – value for cell 1; c2 (Int) – value for cell 2; c3 (Int) – value for cell 3; c4 (Int) – value for cell 4. combineVariants(left: Variant, right: Variant): Struct{variant:Variant,laIndices:Dict[Int,Int],raIndices:Dict[Int,Int]}. variant (Variant) – Resulting combined variant.; laIndices (Dict[Int, Int]) – Mapping from new to old allele index for the left variant.; raIndices (Dict[Int, Int]) – Mapping from new to old allele index for the right variant. Combines the alleles of two variants at the same locus, making sure that ref and alt alleles are represented uniformely.;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/functions.html:478,test,test,478,docs/0.1/functions.html,https://hail.is,https://hail.is/docs/0.1/functions.html,1,['test'],['test']
Testability,"﻿. . Getting Started — Hail. Toggle navigation. HOME. DOCS. 0.2 (Stable); 0.1 (Deprecated). FORUM; CHAT; CODE; JOBS. Hail; . ; . 0.1; . Getting Started; Running Hail locally; Building Hail from source; Running on a Spark cluster; Running on a Cloudera Cluster; Running in the cloud; Building with other versions of Spark 2. BLAS and LAPACK; Running the tests. Overview; Tutorials; Expression Language; Python API; Annotation Database; Other Resources. Hail. Docs »; Getting Started. View page source. Getting Started¶; You’ll need:. The Java 8 JDK.; Spark 2.0.2. Hail is compatible with Spark 2.0.x and 2.1.x.; Python 2.7 and Jupyter Notebooks. We recommend the free Anaconda distribution. Running Hail locally¶; Hail uploads distributions to Google Storage as part of our continuous integration suite.; You can download a pre-built distribution from the below links. Make sure you download the distribution that matches your Spark version!. Current distribution for Spark 2.0.2; Current distribution for Spark 2.1.0. Unzip the distribution after you download it. Next, edit and copy the below bash commands to set up the Hail; environment variables. You may want to add these to the appropriate dot-file (we recommend ~/.profile); so that you don’t need to rerun these commands in each new session.; Here, fill in the path to the un-tarred Spark package.; export SPARK_HOME=???. Here, fill in the path to the unzipped Hail distribution.; export HAIL_HOME=???; export PATH=$PATH:$HAIL_HOME/bin/. Once you’ve set up Hail, we recommend that you run the Python tutorials to get an overview of Hail; functionality and learn about the powerful query language. To try Hail out, run the below commands; to start a Jupyter Notebook server in the tutorials directory.; cd $HAIL_HOME/tutorials; jhail. You can now click on the “hail-overview” notebook to get started!. Building Hail from source¶. On a Debian-based Linux OS like Ubuntu, run:; $ sudo apt-get install g++ cmake. On Mac OS X, install Xcode, availa",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/getting_started.html:353,test,tests,353,docs/0.1/getting_started.html,https://hail.is,https://hail.is/docs/0.1/getting_started.html,1,['test'],['tests']
Testability,"﻿. . HailContext — Hail. Toggle navigation. HOME. DOCS. 0.2 (Stable); 0.1 (Deprecated). FORUM; CHAT; CODE; JOBS. Hail; . ; . 0.1; . Getting Started; Overview; Tutorials; Expression Language; Python API; HailContext; VariantDataset; KeyTable; KinshipMatrix; LDMatrix; representation; expr; utils. Annotation Database; Other Resources. Hail. Docs »; Python API »; HailContext. View page source. HailContext¶. class hail.HailContext(sc=None, app_name='Hail', master=None, local='local[*]', log='hail.log', quiet=False, append=False, parquet_compression='snappy', min_block_size=1, branching_factor=50, tmp_dir='/tmp')[source]¶; The main entry point for Hail functionality. Warning; Only one Hail context may be running in a Python session at any time. If you; need to reconfigure settings, restart the Python session or use the HailContext.stop() method.; If passing in a Spark context, ensure that the configuration parameters spark.sql.files.openCostInBytes; and spark.sql.files.maxPartitionBytes are set to as least 50GB. Parameters:; sc (pyspark.SparkContext) – Spark context, one will be created if None.; appName – Spark application identifier.; master – Spark cluster master.; local – Local resources to use.; log – Log path.; quiet (bool) – Don’t write logging information to standard error.; append – Write to end of log file instead of overwriting.; parquet_compression – Level of on-disk annotation compression.; min_block_size – Minimum file split size in MB.; branching_factor – Branching factor for tree aggregation.; tmp_dir – Temporary directory for file merging. Variables:sc (pyspark.SparkContext) – Spark context. Attributes. version; Return the version of Hail associated with this HailContext. Methods. __init__; x.__init__(…) initializes x; see help(type(x)) for signature. balding_nichols_model; Simulate a variant dataset using the Balding-Nichols model. eval_expr; Evaluate an expression. eval_expr_typed; Evaluate an expression and return the result as well as its type. get_run",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.HailContext.html:487,log,log,487,docs/0.1/hail.HailContext.html,https://hail.is,https://hail.is/docs/0.1/hail.HailContext.html,2,['log'],['log']
Testability,"﻿. . Overview — Hail. Toggle navigation. HOME. DOCS. 0.2 (Stable); 0.1 (Deprecated). FORUM; CHAT; CODE; JOBS. Hail; . ; . 0.1; . Getting Started; Overview; Tutorials; Hail Overview; Overview; Check for tutorial data or download if necessary; Loading data from disk; Getting to know our data; Integrate sample annotations; Query functions and the Hail Expression Language; Quality Control; Let’s do a GWAS!; Confounded!; Rare variant analysis; Eplilogue. Introduction to the expression language; Expression language: query, annotate, and aggregate. Expression Language; Python API; Annotation Database; Other Resources. Hail. Docs »; Tutorials »; Overview. View page source. Overview¶; This notebook is designed to provide a broad overview of Hail’s; functionality, with emphasis on the functionality to manipulate and; query a genetic dataset. We walk through a genome-wide SNP association; test, and demonstrate the need to control for confounding caused by; population stratification.; Each notebook starts the same: we import the hail package and create; a HailContext. This; object is the entry point for most Hail functionality. In [1]:. from hail import *; hc = HailContext(). Running on Apache Spark version 2.0.2; SparkUI available at http://10.56.135.40:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-5a67787. If the above cell ran without error, we’re ready to go!; Before using Hail, we import some standard Python libraries for use; throughout the notebook. In [2]:. import numpy as np; import pandas as pd; import matplotlib.pyplot as plt; import matplotlib.patches as mpatches; from collections import Counter; from math import log, isnan; from pprint import pprint; %matplotlib inline. Installing and importing; seaborn is optional; it; just makes the plots prettier. In [3]:. # optional; import seaborn. Check for tutorial data or download if necessary¶; This cell downloads the necessary data from Google Storage if it isn’t; found in the",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/hail-overview.html:891,test,test,891,docs/0.1/tutorials/hail-overview.html,https://hail.is,https://hail.is/docs/0.1/tutorials/hail-overview.html,1,['test'],['test']
Testability,"﻿. . hail.representation.genotype — Hail. Toggle navigation. HOME. DOCS. 0.2 (Stable); 0.1 (Deprecated). FORUM; CHAT; CODE; JOBS. Hail; . ; . 0.1; . Getting Started; Overview; Tutorials; Expression Language; Python API; Annotation Database; Other Resources. Hail. Docs »; Module code »; hail.representation.genotype. Source code for hail.representation.genotype; from hail.java import *; from hail.typecheck import *. [docs]class Genotype(object):; """"""; An object that represents an individual's genotype at a genomic locus. .. testsetup::. g = Genotype(0, ad=[9,1], dp=11, gq=20, pl=[0,100,1000]). :param gt: Genotype hard call; :type gt: int or None; :param ad: allelic depth (1 element per allele including reference); :type ad: list of int or None; :param dp: total depth; :type dp: int or None; :param gq: genotype quality; :type gq: int or None; :param pl: phred-scaled posterior genotype likelihoods (1 element per possible genotype); :type pl: list of int or None; """""". @handle_py4j; def __init__(self, gt, ad=None, dp=None, gq=None, pl=None):; """"""Initialize a Genotype object."""""". jvm = Env.jvm(); jgt = joption(gt); if ad:; jad = jsome(jarray(jvm.int, ad)); else:; jad = jnone(); jdp = joption(dp); jgq = joption(gq); if pl:; jpl = jsome(jarray(jvm.int, pl)); else:; jpl = jnone(). jrep = scala_object(Env.hail().variant, 'Genotype').apply(; jgt, jad, jdp, jgq, jpl, False, False); self._gt = gt; self._ad = ad; self._dp = dp; self._gq = gq; self._pl = pl; self._init_from_java(jrep). def __str__(self):; return self._jrep.toString(). def __repr__(self):; fake_ref = 'FakeRef=True' if self._jrep.fakeRef() else ''; if self._jrep.isLinearScale():; return 'Genotype(GT=%s, AD=%s, DP=%s, GQ=%s, GP=%s%s)' %\; (self.gt, self.ad, self.dp, self.gq, self.gp, fake_ref); else:; return 'Genotype(GT=%s, AD=%s, DP=%s, GQ=%s, PL=%s%s)' % \; (self.gt, self.ad, self.dp, self.gq, self.pl, fake_ref). def __eq__(self, other):; return self._jrep.equals(other._jrep). def __hash__(self):; return self._jrep.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html:528,test,testsetup,528,docs/0.1/_modules/hail/representation/genotype.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/representation/genotype.html,1,['test'],['testsetup']
Testability,"﻿. . hail.representation.interval — Hail. Toggle navigation. HOME. DOCS. 0.2 (Stable); 0.1 (Deprecated). FORUM; CHAT; CODE; JOBS. Hail; . ; . 0.1; . Getting Started; Overview; Tutorials; Expression Language; Python API; Annotation Database; Other Resources. Hail. Docs »; Module code »; hail.representation.interval. Source code for hail.representation.interval; from hail.java import *; from hail.representation.variant import Locus; from hail.typecheck import *. interval_type = lazy(). [docs]class Interval(object):; """"""; A genomic interval marked by start and end loci. .. testsetup::. interval1 = Interval.parse('X:100005-X:150020'); interval2 = Interval.parse('16:29500000-30200000'). :param start: inclusive start locus; :type start: :class:`.Locus`; :param end: exclusive end locus; :type end: :class:`.Locus`; """""". @handle_py4j; def __init__(self, start, end):; if not (isinstance(start, Locus) and isinstance(end, Locus)):; raise TypeError('expect arguments of type (Locus, Locus) but found (%s, %s)' %; (str(type(start)), str(type(end)))); jrep = scala_object(Env.hail().variant, 'Locus').makeInterval(start._jrep, end._jrep); self._init_from_java(jrep). def __str__(self):; return self._jrep.toString(). def __repr__(self):; return 'Interval(start=%s, end=%s)' % (repr(self.start), repr(self.end)). def __eq__(self, other):; return self._jrep.equals(other._jrep). def __hash__(self):; return self._jrep.hashCode(). def _init_from_java(self, jrep):; self._jrep = jrep; self._start = Locus._from_java(self._jrep.start()). @classmethod; def _from_java(cls, jrep):; interval = Interval.__new__(cls); interval._init_from_java(jrep); return interval. [docs] @staticmethod; @handle_py4j; @typecheck(string=strlike); def parse(string):; """"""Parses a genomic interval from string representation. **Examples**:. >>> interval_1 = Interval.parse('X:100005-X:150020'); >>> interval_2 = Interval.parse('16:29500000-30200000'); >>> interval_3 = Interval.parse('16:29.5M-30.2M') # same as interval_2; >>> i",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/representation/interval.html:577,test,testsetup,577,docs/0.1/_modules/hail/representation/interval.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/representation/interval.html,1,['test'],['testsetup']
Testability,"﻿. . hail.representation.variant — Hail. Toggle navigation. HOME. DOCS. 0.2 (Stable); 0.1 (Deprecated). FORUM; CHAT; CODE; JOBS. Hail; . ; . 0.1; . Getting Started; Overview; Tutorials; Expression Language; Python API; Annotation Database; Other Resources. Hail. Docs »; Module code »; hail.representation.variant. Source code for hail.representation.variant; from hail.java import scala_object, Env, handle_py4j; from hail.typecheck import *. [docs]class Variant(object):; """"""; An object that represents a genomic polymorphism. .. testsetup::. v_biallelic = Variant.parse('16:20012:A:TT'); v_multiallelic = Variant.parse('16:12311:T:C,TTT,A'). :param contig: chromosome identifier; :type contig: str or int; :param int start: chromosomal position (1-based); :param str ref: reference allele; :param alts: single alternate allele, or list of alternate alleles; :type alts: str or list of str; """""". @handle_py4j; def __init__(self, contig, start, ref, alts):; if isinstance(contig, int):; contig = str(contig); jrep = scala_object(Env.hail().variant, 'Variant').apply(contig, start, ref, alts); self._init_from_java(jrep); self._contig = contig; self._start = start; self._ref = ref. def __str__(self):; return self._jrep.toString(). def __repr__(self):; return 'Variant(contig=%s, start=%s, ref=%s, alts=%s)' % (self.contig, self.start, self.ref, self._alt_alleles). def __eq__(self, other):; return self._jrep.equals(other._jrep). def __hash__(self):; return self._jrep.hashCode(). def _init_from_java(self, jrep):; self._jrep = jrep; self._alt_alleles = map(AltAllele._from_java, [jrep.altAlleles().apply(i) for i in xrange(jrep.nAltAlleles())]). @classmethod; def _from_java(cls, jrep):; v = Variant.__new__(cls); v._init_from_java(jrep); v._contig = jrep.contig(); v._start = jrep.start(); v._ref = jrep.ref(); return v. [docs] @staticmethod; @handle_py4j; @typecheck(string=strlike); def parse(string):; """"""Parses a variant object from a string. There are two acceptable formats: CHR:POS:REF:ALT,",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/representation/variant.html:532,test,testsetup,532,docs/0.1/_modules/hail/representation/variant.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/representation/variant.html,1,['test'],['testsetup']
Testability,"﻿. Clumping GWAS Results — Batch documentation. Batch; . Getting Started; Tutorial; Docker Resources; Batch Service; Cookbooks; Clumping GWAS Results; Introduction; Hail GWAS Script; Docker Image; Batch Script; Functions; Control Code. Synopsis. Random Forest. Reference (Python API); Configuration Reference; Advanced UI Search Help; Python Version Compatibility Policy; Change Log. Batch. Cookbooks; Clumping GWAS Results. View page source. Clumping GWAS Results. Introduction; After performing a genome-wide association study (GWAS) for a given phenotype,; an analyst might want to clump the association results based on the correlation; between variants and p-values. The goal is to get a list of independent; associated loci accounting for linkage disequilibrium between variants.; For example, given a region of the genome with three variants: SNP1, SNP2, and SNP3.; SNP1 has a p-value of 1e-8, SNP2 has a p-value of 1e-7, and SNP3 has a; p-value of 1e-6. The correlation between SNP1 and SNP2 is 0.95, SNP1 and; SNP3 is 0.8, and SNP2 and SNP3 is 0.7. We would want to report SNP1 is the; most associated variant with the phenotype and “clump” SNP2 and SNP3 with the; association for SNP1.; Hail is a highly flexible tool for performing; analyses on genetic datasets in a parallel manner that takes advantage; of a scalable compute cluster. However, LD-based clumping is one example of; many algorithms that are not available in Hail, but are implemented by other; bioinformatics tools such as PLINK.; We use Batch to enable functionality unavailable directly in Hail while still; being able to take advantage of a scalable compute cluster.; To demonstrate how to perform LD-based clumping with Batch, we’ll use the; 1000 Genomes dataset from the Hail GWAS tutorial.; First, we’ll write a Python Hail script that performs a GWAS for caffeine; consumption and exports the results as a binary PLINK file and a TSV; with the association results. Second, we’ll build a docker image containing; the",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/cookbook/clumping.html:379,Log,Log,379,docs/batch/cookbook/clumping.html,https://hail.is,https://hail.is/docs/batch/cookbook/clumping.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; BlockMatrix. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); hail; Classes; Modules; expressions; types; functions; aggregators; scans; methods; nd; utils; linalg; stats; genetics; plot; ggplot; vds; experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; linalg; BlockMatrix. View page source. BlockMatrix. class hail.linalg.BlockMatrix[source]; Hail’s block-distributed matrix of tfloat64 elements. Danger; This functionality is experimental. It may not be tested as; well as other parts of Hail and the interface is subject to; change. A block matrix is a distributed analogue of a two-dimensional; NumPy ndarray with; shape (n_rows, n_cols) and NumPy dtype float64.; Import the class with:; >>> from hail.linalg import BlockMatrix. Under the hood, block matrices are partitioned like a checkerboard into; square blocks with side length a common block size. Blocks in the final row; or column of blocks may be truncated, so block size need not evenly divide; the matrix dimensions. Block size defaults to the value given by; default_block_size().; Operations and broadcasting; The core operations are consistent with NumPy: +, -, *, and; / for element-wise addition, subtraction, multiplication, and division;; @ for matrix multiplication; T for transpose; and ** for; element-wise exponentiation to a scalar power.; For element-wise binary operations, each operand may be a block matrix, an; ndarray, or a scalar (int or float). For matrix; multiplication, each operand may be a block matrix or an ndarray. If either; operand is a block matrix, the result is a block matrix. Binary operations; between block ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html:848,test,tested,848,docs/0.2/linalg/hail.linalg.BlockMatrix.html,https://hail.is,https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html,1,['test'],['tested']
Testability,"﻿. Hail | ; For Software Developers. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Requirements; Building Hail; Building the Docs and Website; Running the tests; Contributing. Other Resources; Change Log And Version Policy. menu; Hail. For Software Developers. View page source. For Software Developers; Hail is an open-source project. We welcome contributions to the repository. Requirements. Java 11 JDK . If you have a Mac, you must use a; compatible architecture (uname -m prints your architecture).; The Python and non-pip installation requirements in Getting Started.; Note: These instructions install the JRE but that is not necessary as the JDK should already; be installed which includes the JRE.; If you are setting HAIL_COMPILE_NATIVES=1, then you need the LZ4 library; header files. On Debian and Ubuntu machines run: apt-get install liblz4-dev. Building Hail; The Hail source code is hosted on GitHub:; git clone https://github.com/hail-is/hail.git; cd hail/hail. By default, Hail uses pre-compiled native libraries that are compatible with; recent Mac OS X and Debian releases. If you’re not using one of these OSes, set; the environment (or Make) variable HAIL_COMPILE_NATIVES to any value. This; variable tells GNU Make to build the native libraries from source.; Build and install a wheel file from source with local-mode pyspark:; make install HAIL_COMPILE_NATIVES=1. As above, but explicitly specifying the Scala and Spark versions:; make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5. Building the Docs and Website; Install build dependencies listed in the docs style guide.; Build without rendering the notebooks (which is slow):; make hail-docs-do-not-render-notebooks. Bu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/getting_started_developing.html:431,test,tests,431,docs/0.2/getting_started_developing.html,https://hail.is,https://hail.is/docs/0.2/getting_started_developing.html,1,['test'],['tests']
Testability,"﻿. Hail | ; Hail Tutorials. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Genome-Wide Association Study (GWAS) Tutorial; Table Tutorial; Aggregation Tutorial; Filtering and Annotation Tutorial; Table Joins Tutorial; MatrixTable Tutorial; Plotting Tutorial; GGPlot Tutorial. Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Hail Tutorials. View page source. Hail Tutorials. To take Hail for a test drive, go through our tutorials. These can be viewed here in the; documentation, but we recommend instead that you run them yourself with Jupyter by; downloading the archive (.tar.gz); and running the following:pip install jupyter; tar xf tutorials.tar.gz; jupyter notebook tutorials/. Genome-Wide Association Study (GWAS) Tutorial; Table Tutorial; Aggregation Tutorial; Filtering and Annotation Tutorial; Table Joins Tutorial; MatrixTable Tutorial; Plotting Tutorial; GGPlot Tutorial. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials-landing.html:680,test,test,680,docs/0.2/tutorials-landing.html,https://hail.is,https://hail.is/docs/0.2/tutorials-landing.html,1,['test'],['test']
Testability,"﻿. Hail | ; Statistical functions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); hail; Classes; Modules; expressions; types; functions; aggregators; scans; methods; nd; utils; linalg; stats; genetics; plot; ggplot; vds; experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; Functions; Statistical functions. View page source. Statistical functions. chi_squared_test(c1, c2, c3, c4); Performs chi-squared test of independence on a 2x2 contingency table. fisher_exact_test(c1, c2, c3, c4); Calculates the p-value, odds ratio, and 95% confidence interval using Fisher's exact test for a 2x2 table. contingency_table_test(c1, c2, c3, c4, ...); Performs chi-squared or Fisher's exact test of independence on a 2x2 contingency table. cochran_mantel_haenszel_test(a, b, c, d); Perform the Cochran-Mantel-Haenszel test for association. dbeta(x, a, b); Returns the probability density at x of a beta distribution with parameters a (alpha) and b (beta). dchisq(x, df[, ncp, log_p]); Compute the probability density at x of a chi-squared distribution with df degrees of freedom. dnorm(x[, mu, sigma, log_p]); Compute the probability density at x of a normal distribution with mean mu and standard deviation sigma. dpois(x, lamb[, log_p]); Compute the (log) probability density at x of a Poisson distribution with rate parameter lamb. hardy_weinberg_test(n_hom_ref, n_het, n_hom_var); Performs test of Hardy-Weinberg equilibrium. binom_test(x, n, p, alternative); Performs a binomial test on p given x successes in n trials. pchisqtail(x, df[, ncp, lower_tail, log_p]); Returns the probability under the right-tail starting at x for ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/stats.html:784,test,test,784,docs/0.2/functions/stats.html,https://hail.is,https://hail.is/docs/0.2/functions/stats.html,2,['test'],['test']
Testability,"﻿. Hail | ; Statistics. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); hail; Classes; Modules; expressions; types; functions; aggregators; scans; methods; nd; utils; linalg; stats; genetics; plot; ggplot; vds; experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; Methods; Statistics. View page source. Statistics. linear_mixed_model(y, x[, z_t, k, p_path, ...]); Initialize a linear mixed model from a matrix table. linear_mixed_regression_rows(entry_expr, model); For each row, test an input variable for association using a linear mixed model. linear_regression_rows(y, x, covariates[, ...]); For each row, test an input variable for association with response variables using linear regression. logistic_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a binary response variable using logistic regression. poisson_regression_rows(test, y, x, covariates); For each row, test an input variable for association with a count response variable using Poisson regression. pca(entry_expr[, k, compute_loadings]); Run principal component analysis (PCA) on numeric columns derived from a matrix table. row_correlation(entry_expr[, block_size]); Computes the correlation matrix between row vectors. hail.methods.linear_mixed_model(y, x, z_t=None, k=None, p_path=None, overwrite=False, standardize=True, mean_impute=True)[source]; Initialize a linear mixed model from a matrix table. Warning; This functionality is no longer implemented/supported as of Hail 0.2.94. hail.methods.linear_mixed_regression_rows(entry_expr, model, pa_t_path=None, a_t_path=None, mean_impute=True, par",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/stats.html:859,test,test,859,docs/0.2/methods/stats.html,https://hail.is,https://hail.is/docs/0.2/methods/stats.html,1,['test'],['test']
Testability,"﻿. Hail | ; hail.context. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.context. Source code for hail.context; import os; import sys; import warnings; from contextlib import contextmanager; from random import Random; from types import TracebackType; from typing import Dict, List, Optional, Tuple, Type, Union; from urllib.parse import urlparse, urlunparse. from pyspark import SparkContext. import hail; from hail.backend import Backend; from hail.genetics.reference_genome import ReferenceGenome, reference_genome_type; from hail.typecheck import dictof, enumeration, nullable, oneof, sequenceof, sized_tupleof, typecheck, typecheck_method; from hail.utils import get_env_or_default; from hail.utils.java import BackendType, Env, choose_backend, warning; from hailtop.aiocloud.aiogoogle import GCSRequesterPaysConfiguration, get_gcs_requester_pays_configuration; from hailtop.fs.fs import FS; from hailtop.hail_event_loop import hail_event_loop; from hailtop.utils import secret_alnum_string. from . import __resource_str; from .backend.backend import local_jar_information; from .builtin_references import BUILTIN_REFERENCES. def _get_tmpdir(tmpdir):; if tmpdir is None:; tmpdir = '/tmp'; return tmpdir. def _get_local_tmpdir(local_tmpdir):; local_tmpdir = get_env_or_default(local_tmpdir, 'TMPDIR', 'file:///tmp'); r = urlparse(local_tmpdir); if not r.scheme:; r = r._replace(scheme='file'); elif r.scheme != 'file':; raise ValueError('invalid local_tmpfile: must use scheme file, got scheme {r.scheme}'); return urlunparse(r). def _get_log(log):; if log is None:; py_version = version(); log_dir = os.environ.get('HAIL_LOG_DIR'); if log_dir i",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:372,Log,Log,372,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.datasets. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.datasets. Source code for hail.experimental.datasets; from typing import Optional, Union. import hail as hl; from hail.matrixtable import MatrixTable; from hail.table import Table. from .datasets_metadata import get_datasets_metadata. def _read_dataset(path: str) -> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; if path.endswith('.ht'):; return hl.read_table(path); elif path.endswith('.mt'):; return hl.read_matrix_table(path); elif path.endswith('.bm'):; return hl.linalg.BlockMatrix.read(path); raise ValueError(f'Invalid path: {path}. Can only load datasets with .ht, .mt, or .bm extensions.'). [docs]def load_dataset(; name: str, version: Optional[str], reference_genome: Optional[str], region: str = 'us-central1', cloud: str = 'gcp'; ) -> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; """"""Load a genetic dataset from Hail's repository. Example; -------; >>> # Load the gnomAD ""HGDP + 1000 Genomes"" dense MatrixTable with GRCh38 coordinates.; >>> mt = hl.experimental.load_dataset(name='gnomad_hgdp_1kg_subset_dense',; ... version='3.1.2',; ... reference_genome='GRCh38',; ... region='us-central1',; ... cloud='gcp'). Parameters; ----------; name : :class:`str`; Name of the dataset to load.; version : :class:`str`, optional; Version of the named dataset to load (see available versions in; documentation). Possibly ``None`` for some datasets.; reference_genome : :class:`str`, optional; Reference genome build, ``'GRCh37'`` or ``'GRCh38'``. Possibly ``None``; for some datasets.; region : :class:`str`; Specify region for bucket, ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:386,Log,Log,386,docs/0.2/_modules/hail/experimental/datasets.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.db. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.db. Source code for hail.experimental.db; import warnings; from typing import ClassVar, Iterable, List, Optional, Set, Tuple, Union. import hail as hl; from hailtop.utils import external_requests_client_session, retry_response_returning_functions. from ..expr import StructExpression; from ..matrixtable import MatrixTable, matrix_table_type; from ..table import Table, table_type; from ..typecheck import oneof, typecheck_method; from ..utils.java import Env, info; from .datasets_metadata import get_datasets_metadata; from .lens import MatrixRows, TableRows. class DatasetVersion:; """""":class:`DatasetVersion` has two constructors: :func:`.from_json` and; :func:`.get_region`. Parameters; ----------; url : :obj:`dict` or :obj:`str`; Nested dictionary of URLs containing key: value pairs, like; ``cloud: {region: url}`` if using :func:`.from_json` constructor,; or a string with the URL from appropriate region if using the; :func:`.get_region` constructor.; version : :obj:`str`, optional; String of dataset version, if not ``None``.; reference_genome : :obj:`str`, optional; String of dataset reference genome, if not ``None``.; """""". @staticmethod; def from_json(doc: dict, cloud: str) -> Optional['DatasetVersion']:; """"""Create :class:`.DatasetVersion` object from dictionary. Parameters; ----------; doc : :obj:`dict`; Dictionary containing url and version keys.; Value for url is a :obj:`dict` containing key: value pairs, like; ``cloud: {region: url}``.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/db.html:380,Log,Log,380,docs/0.2/_modules/hail/experimental/db.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.export_entries_by_col. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.export_entries_by_col. Source code for hail.experimental.export_entries_by_col; import hail as hl; from hail.matrixtable import MatrixTable; from hail.typecheck import typecheck. [docs]@typecheck(; mt=MatrixTable, path=str, batch_size=int, bgzip=bool, header_json_in_file=bool, use_string_key_as_file_name=bool; ); def export_entries_by_col(; mt: MatrixTable,; path: str,; batch_size: int = 256,; bgzip: bool = True,; header_json_in_file: bool = True,; use_string_key_as_file_name: bool = False,; ):; """"""Export entries of the `mt` by column as separate text files. Examples; --------; >>> range_mt = hl.utils.range_matrix_table(10, 10); >>> range_mt = range_mt.annotate_entries(x = hl.rand_unif(0, 1)); >>> hl.experimental.export_entries_by_col(range_mt, 'output/cols_files'). Notes; -----; This function writes a directory with one file per column in `mt`. The; files contain one tab-separated field (with header) for each row field; and entry field in `mt`. The column fields of `mt` are written as JSON; in the first line of each file, prefixed with a ``#``. The above will produce a directory at ``output/cols_files`` with the; following files:. .. code-block:: text. $ ls -l output/cols_files; total 80; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 index.tsv; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-00.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-01.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-02.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-03.tsv.bgz; -rw-r--r-- 1 hail-dev ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/export_entries_by_col.html:399,Log,Log,399,docs/0.2/_modules/hail/experimental/export_entries_by_col.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/export_entries_by_col.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.expressions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.expressions. Source code for hail.experimental.expressions; import hail as hl; from hail.expr.expressions import analyze, expr_any; from hail.expr.table_type import ttable; from hail.expr.types import hail_type; from hail.typecheck import nullable, typecheck. [docs]@typecheck(expr=expr_any, path=str, overwrite=bool); def write_expression(expr, path, overwrite=False):; """"""Write an Expression. In the same vein as Python's pickle, write out an expression; that does not have a source (such as one that comes from; Table.aggregate with _localize=False). Example; -------; >>> ht = hl.utils.range_table(100).annotate(x=hl.rand_norm()); >>> mean_norm = ht.aggregate(hl.agg.mean(ht.x), _localize=False); >>> mean_norm; >>> hl.eval(mean_norm); >>> hl.experimental.write_expression(mean_norm, 'output/expression.he'). Parameters; ----------. expr : :class:`~.Expression`; Expression to write.; path : :class:`str`; Path to which to write expression.; Suggested extension: .he (hail expression).; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination. Returns; -------; None; """"""; source = expr._indices.source; if source is not None:; analyze('write_expression.expr', expr, source._global_indices); source = source.select_globals(__expr=expr); expr = source.index_globals().__expr; hl.utils.range_table(1).filter(False).key_by().drop('idx').annotate_globals(expr=expr).write(; path, overwrite=overwrite; ). [docs]@typecheck(path=str, _assert_type=nullable(hail_type)); def read_expression(path, _assert_type=None):; """"""R",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/expressions.html:389,Log,Log,389,docs/0.2/_modules/hail/experimental/expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/expressions.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.filtering_allele_frequency. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.filtering_allele_frequency. Source code for hail.experimental.filtering_allele_frequency; from hail.expr.expressions import Float64Expression, expr_float64, expr_int32; from hail.expr.functions import _func; from hail.expr.types import tfloat64; from hail.typecheck import typecheck. [docs]@typecheck(ac=expr_int32, an=expr_int32, ci=expr_float64); def filtering_allele_frequency(ac, an, ci) -> Float64Expression:; """"""; Computes a filtering allele frequency (described below); for `ac` and `an` with confidence `ci`. The filtering allele frequency is the highest true population allele frequency; for which the upper bound of the `ci` (confidence interval) of allele count; under a Poisson distribution is still less than the variant's observed; `ac` (allele count) in the reference sample, given an `an` (allele number). This function defines a ""filtering AF"" that represents; the threshold disease-specific ""maximum credible AF"" at or below which; the disease could not plausibly be caused by that variant. A variant with; a filtering AF >= the maximum credible AF for the disease under consideration; should be filtered, while a variant with a filtering AF below the maximum; credible remains a candidate. This filtering AF is not disease-specific:; it can be applied to any disease of interest by comparing with a; user-defined disease-specific maximum credible AF. For more details, see: `Whiffin et al., 2017 <https://www.nature.com/articles/gim201726>`__. Parameters; ----------; ac : int or :class:`.Expression` of type :p",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/filtering_allele_frequency.html:404,Log,Log,404,docs/0.2/_modules/hail/experimental/filtering_allele_frequency.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/filtering_allele_frequency.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.full_outer_join_mt. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.full_outer_join_mt. Source code for hail.experimental.full_outer_join_mt; import hail as hl; from hail.matrixtable import MatrixTable. [docs]def full_outer_join_mt(left: MatrixTable, right: MatrixTable) -> MatrixTable:; """"""Performs a full outer join on `left` and `right`. Replaces row, column, and entry fields with the following:. - `left_row` / `right_row`: structs of row fields from left and right.; - `left_col` / `right_col`: structs of column fields from left and right.; - `left_entry` / `right_entry`: structs of entry fields from left and right. Examples; --------. The following creates and joins two random datasets with disjoint sample ids; but non-disjoint variant sets. We use :func:`.or_else` to attempt to find a; non-missing genotype. If neither genotype is non-missing, then the genotype; is set to missing. In particular, note that Samples `2` and `3` have missing; genotypes for loci 1:1 and 1:2 because those loci are not present in `mt2`; and these samples are not present in `mt1`. >>> hl.reset_global_randomness(); >>> mt1 = hl.balding_nichols_model(1, 2, 3); >>> mt2 = hl.balding_nichols_model(1, 2, 3); >>> mt2 = mt2.key_rows_by(locus=hl.locus(mt2.locus.contig,; ... mt2.locus.position+2),; ... alleles=mt2.alleles); >>> mt2 = mt2.key_cols_by(sample_idx=mt2.sample_idx+2); >>> mt1.show(); +---------------+------------+------+------+; | locus | alleles | 0.GT | 1.GT |; +---------------+------------+------+------+; | locus<GRCh37> | array<str> | call | call |; +---------------+------------+------+------+; | ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html:396,Log,Log,396,docs/0.2/_modules/hail/experimental/full_outer_join_mt.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.import_gtf. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.import_gtf. Source code for hail.experimental.import_gtf; import functools; import operator. import hail as hl; from hail.genetics.reference_genome import reference_genome_type; from hail.table import Table; from hail.typecheck import nullable, sequenceof, typecheck; from hail.utils import new_temp_file; from hail.utils.java import info. [docs]@typecheck(; path=str,; reference_genome=nullable(reference_genome_type),; skip_invalid_contigs=bool,; min_partitions=nullable(int),; force_bgz=bool,; force=bool,; ); def import_gtf(; path, reference_genome=None, skip_invalid_contigs=False, min_partitions=None, force_bgz=False, force=False; ) -> Table:; """"""Import a GTF file. The GTF file format is identical to the GFF version 2 file format,; and so this function can be used to import GFF version 2 files as; well. See https://www.ensembl.org/info/website/upload/gff.html for more; details on the GTF/GFF2 file format. The :class:`.Table` returned by this function will be keyed by the; ``interval`` row field and will include the following row fields:. .. code-block:: text. 'source': str; 'feature': str; 'score': float64; 'strand': str; 'frame': int32; 'interval': interval<>. There will also be corresponding fields for every tag found in the; attribute field of the GTF file. Note; ----. This function will return an ``interval`` field of type :class:`.tinterval`; constructed from the ``seqname``, ``start``, and ``end`` fields in the; GTF file. This interval is inclusive of both the start and end positions; in the GTF file. If the ``refer",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:388,Log,Log,388,docs/0.2/_modules/hail/experimental/import_gtf.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.ld_score_regression. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.ld_score_regression. Source code for hail.experimental.ld_score_regression; import hail as hl; from hail.expr.expressions import analyze, expr_float64, expr_numeric; from hail.table import Table; from hail.typecheck import nullable, oneof, sequenceof, typecheck; from hail.utils import new_temp_file, wrap_to_list. [docs]@typecheck(; weight_expr=expr_float64,; ld_score_expr=expr_numeric,; chi_sq_exprs=oneof(expr_float64, sequenceof(expr_float64)),; n_samples_exprs=oneof(expr_numeric, sequenceof(expr_numeric)),; n_blocks=int,; two_step_threshold=int,; n_reference_panel_variants=nullable(int),; ); def ld_score_regression(; weight_expr,; ld_score_expr,; chi_sq_exprs,; n_samples_exprs,; n_blocks=200,; two_step_threshold=30,; n_reference_panel_variants=None,; ) -> Table:; r""""""Estimate SNP-heritability and level of confounding biases from genome-wide association study; (GWAS) summary statistics. Given a set or multiple sets of GWAS summary statistics, :func:`.ld_score_regression` estimates the heritability; of a trait or set of traits and the level of confounding biases present in; the underlying studies by regressing chi-squared statistics on LD scores,; leveraging the model:. .. math::. \mathrm{E}[\chi_j^2] = 1 + Na + \frac{Nh_g^2}{M}l_j. * :math:`\mathrm{E}[\chi_j^2]` is the expected chi-squared statistic; for variant :math:`j` resulting from a test of association between; variant :math:`j` and a trait.; * :math:`l_j = \sum_{k} r_{jk}^2` is the LD score of variant; :math:`j`, calculated as the sum of squared correlat",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:397,Log,Log,397,docs/0.2/_modules/hail/experimental/ld_score_regression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.ldscore. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.ldscore. Source code for hail.experimental.ldscore; import hail as hl; from hail.expr.expressions import expr_float64, expr_locus, expr_numeric; from hail.linalg import BlockMatrix; from hail.table import Table; from hail.typecheck import nullable, oneof, sequenceof, typecheck; from hail.utils import new_temp_file, wrap_to_list. [docs]@typecheck(; entry_expr=expr_float64,; locus_expr=expr_locus(),; radius=oneof(int, float),; coord_expr=nullable(expr_float64),; annotation_exprs=nullable(oneof(expr_numeric, sequenceof(expr_numeric))),; block_size=nullable(int),; ); def ld_score(entry_expr, locus_expr, radius, coord_expr=None, annotation_exprs=None, block_size=None) -> Table:; """"""Calculate LD scores. Example; -------. >>> # Load genetic data into MatrixTable; >>> mt = hl.import_plink(bed='data/ldsc.bed',; ... bim='data/ldsc.bim',; ... fam='data/ldsc.fam'). >>> # Create locus-keyed Table with numeric variant annotations; >>> ht = hl.import_table('data/ldsc.annot',; ... types={'BP': hl.tint,; ... 'binary': hl.tfloat,; ... 'continuous': hl.tfloat}); >>> ht = ht.annotate(locus=hl.locus(ht.CHR, ht.BP)); >>> ht = ht.key_by('locus'). >>> # Annotate MatrixTable with external annotations; >>> mt = mt.annotate_rows(binary_annotation=ht[mt.locus].binary,; ... continuous_annotation=ht[mt.locus].continuous). >>> # Calculate LD scores using centimorgan coordinates; >>> ht_scores = hl.experimental.ld_score(entry_expr=mt.GT.n_alt_alleles(),; ... locus_expr=mt.locus,; ... radius=1.0,; ... coord_expr=mt.cm_position,; ... annotation_exprs=[mt.bi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html:385,Log,Log,385,docs/0.2/_modules/hail/experimental/ldscore.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.ldscsim. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.ldscsim. Source code for hail.experimental.ldscsim; #!/usr/bin/env python3; # -*- coding: utf-8 -*-; """"""; Simulation framework for testing LDSC. Models for SNP effects:; - Infinitesimal (can simulate n correlated traits); - Spike & slab (can simulate up to 2 correlated traits); - Annotation-informed. Features:; - Field aggregation tools for annotation-informed model and; population stratification with many covariates.; - Automatic adjustment of genetic correlation parameters; to allow for the joint simulation of up to 100 randomly; correlated phenotypes.; - Methods for binarizing phenotypes to have a certain prevalence; and for adding ascertainment bias to binarized phenotypes. @author: nbaya; """""". import numpy as np; import pandas as pd; from scipy import stats. import hail as hl; from hail.expr.expressions import expr_array, expr_call, expr_float64, expr_int32; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import nullable, oneof, typecheck; from hail.utils.java import Env. [docs]@typecheck(; mt=MatrixTable,; genotype=oneof(expr_int32, expr_float64, expr_call),; h2=(oneof(float, int, list, np.ndarray)),; pi=nullable(oneof(float, int, list, np.ndarray)),; rg=nullable(oneof(float, int, list, np.ndarray)),; annot=nullable(oneof(expr_float64, expr_int32)),; popstrat=nullable(oneof(expr_int32, expr_float64)),; popstrat_var=nullable(oneof(float, int)),; exact_h2=bool,; ); def simulate_phenotypes(; mt, genotype, h2, pi=None, rg=None, annot=None, popstrat=None, popstrat_var=None, exact",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:583,test,testing,583,docs/0.2/_modules/hail/experimental/ldscsim.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html,3,"['Log', 'test']","['Log', 'testing']"
Testability,"﻿. Hail | ; hail.experimental.loop. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.loop. Source code for hail.experimental.loop; from typing import Callable. from hail import ir; from hail.expr.expressions import construct_expr, construct_variable, expr_any, to_expr, unify_all; from hail.expr.types import hail_type; from hail.typecheck import anytype, typecheck; from hail.utils.java import Env. [docs]@typecheck(f=anytype, typ=hail_type, args=expr_any); def loop(f: Callable, typ, *args):; r""""""Define and call a tail-recursive function with given arguments. Notes; -----; The argument `f` must be a function where the first argument defines the; recursive call, and the remaining arguments are the arguments to the; recursive function, e.g. to define the recursive function. .. math::. f(x, y) = \begin{cases}; y & \textrm{if } x \equiv 0 \\; f(x - 1, y + x) & \textrm{otherwise}; \end{cases}. we would write:; >>> f = lambda recur, x, y: hl.if_else(x == 0, y, recur(x - 1, y + x)). Full recursion is not supported, and any non-tail-recursive methods will; throw an error when called. This means that the result of any recursive call within the function must; also be the result of the entire function, without modification. Let's; consider two different recursive definitions for the triangle function; :math:`f(x) = 0 + 1 + \dots + x`:. >>> def triangle1(x):; ... if x == 1:; ... return x; ... return x + triangle1(x - 1). >>> def triangle2(x, total):; ... if x == 0:; ... return total; ... return triangle2(x - 1, total + x). The first function definition, `triangle1`, will call itself and then add x.; This is an example of a n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:382,Log,Log,382,docs/0.2/_modules/hail/experimental/loop.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.pca. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.pca. Source code for hail.experimental.pca; import hail as hl; from hail.expr.expressions import (; expr_array,; expr_call,; expr_numeric,; raise_unless_entry_indexed,; raise_unless_row_indexed,; ); from hail.typecheck import typecheck. [docs]@typecheck(call_expr=expr_call, loadings_expr=expr_array(expr_numeric), af_expr=expr_numeric); def pc_project(call_expr, loadings_expr, af_expr):; """"""Projects genotypes onto pre-computed PCs. Requires loadings and; allele-frequency from a reference dataset (see example). Note that; `loadings_expr` must have no missing data and reflect the rows; from the original PCA run for this method to be accurate. Example; -------; >>> # Compute loadings and allele frequency for reference dataset; >>> _, _, loadings_ht = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=True) # doctest: +SKIP; >>> mt = mt.annotate_rows(af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:381,Log,Log,381,docs/0.2/_modules/hail/experimental/pca.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.phase_by_transmission. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.phase_by_transmission. Source code for hail.experimental.phase_by_transmission; from typing import List. import hail as hl; from hail.expr.expressions import expr_array, expr_call, expr_locus, expr_str; from hail.matrixtable import MatrixTable; from hail.typecheck import sequenceof, typecheck. [docs]@typecheck(; locus=expr_locus(),; alleles=expr_array(expr_str),; proband_call=expr_call,; father_call=expr_call,; mother_call=expr_call,; ); def phase_by_transmission(; locus: hl.expr.LocusExpression,; alleles: hl.expr.ArrayExpression,; proband_call: hl.expr.CallExpression,; father_call: hl.expr.CallExpression,; mother_call: hl.expr.CallExpression,; ) -> hl.expr.ArrayExpression:; """"""Phases genotype calls in a trio based allele transmission. Notes; -----; In the phased calls returned, the order is as follows:; - Proband: father_allele | mother_allele; - Parents: transmitted_allele | untransmitted_allele. Phasing of sex chromosomes:; - Sex chromosomes of male individuals should be haploid to be phased correctly.; - If `proband_call` is diploid on non-par regions of the sex chromosomes, it is assumed to be female. Returns `NA` when genotype calls cannot be phased.; The following genotype calls combinations cannot be phased by transmission:; 1. One of the calls in the trio is missing; 2. The proband genotype cannot be obtained from the parents alleles (Mendelian violation); 3. All individuals of the trio are heterozygous for the same two alleles; 4. Father is diploid on non-PAR region of X or Y; 5. Proband is diploid o",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/phase_by_transmission.html:399,Log,Log,399,docs/0.2/_modules/hail/experimental/phase_by_transmission.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/phase_by_transmission.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.plots. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.plots. Source code for hail.experimental.plots; import json. import numpy as np; import pandas as pd; from bokeh.layouts import gridplot; from bokeh.models import ColumnDataSource, Div, HoverTool, TabPanel, Tabs, Title; from bokeh.palettes import Spectral8; from bokeh.plotting import figure; from bokeh.transform import factor_cmap. import hail as hl; from hail.typecheck import typecheck; from hail.utils.hadoop_utils import hadoop_ls, hadoop_open; from hail.utils.java import warning. [docs]def plot_roc_curve(ht, scores, tp_label='tp', fp_label='fp', colors=None, title='ROC Curve', hover_mode='mouse'):; """"""Create ROC curve from Hail Table. One or more `score` fields must be provided, which are assessed against `tp_label` and `fp_label` as truth data. High scores should correspond to true positives. Parameters; ----------; ht : :class:`.Table`; Table with required data; scores : :class:`str` or :obj:`list` of :obj:`.str`; Top-level location of scores in ht against which to generate PR curves.; tp_label : :class:`str`; Top-level location of true positives in ht.; fp_label : :class:`str`; Top-level location of false positives in ht.; colors : :obj:`dict` of :class:`str`; Optional colors to use (score -> desired color).; title : :class:`str`; Title of plot.; hover_mode : :class:`str`; Hover mode; one of 'mouse' (default), 'vline' or 'hline'. Returns; -------; :obj:`tuple` of :class:`bokeh.plotting.figure` and :obj:`list` of :class:`str`; Figure, and list of AUCs corresponding to scores.; """"""; if colors is None:; # Get a palette aut",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/plots.html:383,Log,Log,383,docs/0.2/_modules/hail/experimental/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/plots.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.tidyr. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.tidyr. Source code for hail.experimental.tidyr; import hail as hl; from hail.table import Table; from hail.typecheck import nullable, oneof, sequenceof, typecheck; from hail.utils import new_temp_file, wrap_to_list. [docs]@typecheck(ht=Table, key=str, value=str, fields=str); def gather(ht, key, value, *fields) -> Table:; """"""Collapse fields into key-value pairs. :func:`.gather` mimics the functionality of the `gather()` function found in R's; ``tidyr`` package. This is a way to turn ""wide"" format data into ""long""; format data. Parameters; ----------; ht : :class:`.Table`; A Hail table.; key : :class:`str`; The name of the key field in the gathered table.; value : :class:`str`; The name of the value field in the gathered table.; fields : variable-length args of obj:`str`; Names of fields to gather in ``ht``. Returns; -------; :class:`.Table`; Table with original ``fields`` gathered into ``key`` and ``value`` fields."""""". ht = ht.annotate(_col_val=hl.array([hl.struct(field_name=field, value=ht[field]) for field in fields])); ht = ht.drop(*fields); ht = ht.explode(ht['_col_val']); ht = ht.annotate(**{key: ht['_col_val'][0], value: ht['_col_val'][1]}); ht = ht.drop('_col_val'). ht_tmp = new_temp_file(); ht.write(ht_tmp). return hl.read_table(ht_tmp). [docs]@typecheck(ht=Table, field=str, value=str, key=nullable(oneof(str, sequenceof(str)))); def spread(ht, field, value, key=None) -> Table:; """"""Spread a key-value pair of fields across multiple fields. :func:`.spread` mimics the functionality of the `spread()` function in R's; `tidyr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/tidyr.html:383,Log,Log,383,docs/0.2/_modules/hail/experimental/tidyr.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/tidyr.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.experimental.time. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.time. Source code for hail.experimental.time; import hail as hl; from hail.expr.expressions import expr_int64, expr_str; from hail.expr.functions import _func; from hail.typecheck import typecheck. [docs]@typecheck(format=expr_str, time=expr_int64, zone_id=expr_str); def strftime(format, time, zone_id):; """"""; Convert Unix timestamp to a formatted datetime string. Examples; --------. >>> hl.eval(hl.experimental.strftime(""%Y.%m.%d %H:%M:%S %z"", 1562569201, ""America/New_York"")); '2019.07.08 03:00:01 -04:00'. >>> hl.eval(hl.experimental.strftime(""%A, %B %e, %Y. %r"", 876541523, ""GMT+2"")); 'Saturday, October 11, 1997. 05:45:23 AM'. >>> hl.eval(hl.experimental.strftime(""%A, %B %e, %Y. %r"", 876541523, ""+08:00"")); 'Saturday, October 11, 1997. 11:45:23 AM'. Notes; -----; The following formatting characters are supported in format strings: A a B b D d e F H I j k l M m n p R r S s T t U u V v W Y y z; See documentation here: https://linux.die.net/man/3/strftime. A zone id can take one of three forms. It can be an explicit offset, like ""+01:00"", a relative offset, like ""GMT+2"",; or a IANA timezone database (TZDB) identifier, like ""America/New_York"". Wikipedia maintains a list of TZDB identifiers here: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones. Currently, the formatter implicitly uses the ""en_US"" locale. Parameters; ----------; format : str or :class:`.Expression` of type :py:data:`.tstr`; The format string describing how to render the time.; time : int of :class:`.Expression` of type :py:data:`.tint64`; A long represent",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/time.html:382,Log,Log,382,docs/0.2/_modules/hail/experimental/time.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/time.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.expr.aggregators.aggregators. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.aggregators.aggregators. Source code for hail.expr.aggregators.aggregators; import difflib; from functools import update_wrapper, wraps. import hail as hl; from hail import ir; from hail.expr import (; Aggregation,; ArrayExpression,; BooleanExpression,; DictExpression,; Expression,; ExpressionException,; Float64Expression,; Indices,; Int64Expression,; NDArrayNumericExpression,; NumericExpression,; SetExpression,; StringExpression,; StructExpression,; cast_expr,; construct_expr,; expr_any,; expr_array,; expr_bool,; expr_call,; expr_float64,; expr_int32,; expr_int64,; expr_ndarray,; expr_numeric,; expr_oneof,; expr_set,; expr_str,; to_expr,; unify_all,; unify_types,; ); from hail.expr.expressions.typed_expressions import construct_variable; from hail.expr.functions import _quantile_from_cdf, _result_from_raw_cdf, float32, rbind; from hail.expr.types import (; hail_type,; tarray,; tbool,; tcall,; tdict,; tfloat32,; tfloat64,; tint32,; tint64,; tset,; tstr,; tstruct,; ttuple,; ); from hail.typecheck import TypeChecker, func_spec, identity, nullable, oneof, sequenceof, typecheck, typecheck_method; from hail.utils import wrap_to_list; from hail.utils.java import Env. class AggregableChecker(TypeChecker):; def __init__(self, coercer):; self.coercer = coercer; super(AggregableChecker, self).__init__(). def expects(self):; return self.coercer.expects(). def format(self, arg):; return self.coercer.format(arg). def check(self, x, caller, param):; x = self.coercer.check(x, caller, param); if len(x._ir.search(lambda node: isinstance(nod",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html:393,Log,Log,393,docs/0.2/_modules/hail/expr/aggregators/aggregators.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.expr.builders. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.builders. Source code for hail.expr.builders; import hail as hl; from hail import ir; from hail.expr.expressions import (; ExpressionException,; construct_expr,; expr_any,; expr_bool,; expr_str,; unify_types,; unify_types_limited,; ); from hail.typecheck import typecheck_method. class ConditionalBuilder(object):; def __init__(self):; self._ret_type = None; self._cases = []. def _unify_type(self, t):; if self._ret_type is None:; self._ret_type = t; else:; r = unify_types_limited(self._ret_type, t); if not r:; raise TypeError(""'then' expressions must have same type, found '{}' and '{}'"".format(self._ret_type, t)). [docs]class SwitchBuilder(ConditionalBuilder):; """"""Class for generating conditional trees based on value of an expression. Examples; --------. >>> csq = hl.literal('loss of function'); >>> expr = (hl.switch(csq); ... .when('synonymous', 1); ... .when('SYN', 1); ... .when('missense', 2); ... .when('MIS', 2); ... .when('loss of function', 3); ... .when('LOF', 3); ... .or_missing()); >>> hl.eval(expr); 3. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.SwitchBuilder.when` or; :meth:`~hail.expr.builders.SwitchBuilder.default` method calls must be the; same type. See Also; --------; :func:`.case`, :func:`.cond`, :func:`.switch`. Parameters; ----------; expr : :class:`.Expression`; Value to match against.; """""". @typecheck_method(base=expr_any); def __init__(self, base):; self._base = base; self._when_missing_case = None; super(SwitchBuilder, self).__init__(). def _finish(self, default):; a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/builders.html:378,Log,Log,378,docs/0.2/_modules/hail/expr/builders.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.expr.expressions.base_expression. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.expressions.base_expression. Source code for hail.expr.expressions.base_expression; from typing import Any, List, Mapping, Tuple, overload. import numpy as np; import pandas as pd. import hail; import hail as hl; from hail import ir; from hail.expr import expressions; from hail.expr.types import (; HailType,; from_numpy,; is_compound,; is_numeric,; is_setlike,; summary_type,; tarray,; tbool,; tcall,; tdict,; tfloat32,; tfloat64,; tint32,; tint64,; tinterval,; tlocus,; tndarray,; tset,; tstr,; tstruct,; ttuple,; ); from hail.typecheck import anyfunc, linked_list, nullable, typecheck_method; from hail.utils.java import Env; from hail.utils.linkedlist import LinkedList. from .indices import Aggregation, Indices. class Summary(object):; def __init__(self, type, count, summ_fields, nested, header=None):; self.count = count; self.summ_fields = summ_fields; self.nested = nested; self.type = type; self.header = header. @staticmethod; def pct(x):; return f'{x*100:.2f}%'. @staticmethod; def format(x):; if isinstance(x, float):; return f'{x:.2f}'; else:; return str(x). def __str__(self):; return self._ascii_string(depth=0, prefix=None). def __repr__(self):; return self.__str__(). def _repr_html_(self):; return self._html_string(prefix=None). def _ascii_string(self, depth, prefix):; spacing = ' ' * depth. summary = ''; if self.header:; summary += f'\n{spacing}{self.header}'. if prefix is not None:; summary += f'\n\n{spacing}- {prefix} ({summary_type(self.type)}):'. if len(self.summ_fields) > 0:; max_n_len = max(len(n) for n in self",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html:397,Log,Log,397,docs/0.2/_modules/hail/expr/expressions/base_expression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.expr.expressions.expression_utils. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.expressions.expression_utils. Source code for hail.expr.expressions.expression_utils; from typing import Dict, Set. from hail.typecheck import setof, typecheck. from ...ir import MakeTuple; from ..expressions import Expression, ExpressionException, expr_any; from .indices import Aggregation, Indices. @typecheck(caller=str, expr=Expression, expected_indices=Indices, aggregation_axes=setof(str), broadcast=bool); def analyze(caller: str, expr: Expression, expected_indices: Indices, aggregation_axes: Set = set(), broadcast=True):; from hail.utils import error, warning. indices = expr._indices; source = indices.source; axes = indices.axes; aggregations = expr._aggregations. warnings = []; errors = []. expected_source = expected_indices.source; expected_axes = expected_indices.axes. if source is not None and source is not expected_source:; bad_refs = []; for name, inds in get_refs(expr).items():; if inds.source is not expected_source:; bad_refs.append(name); errors.append(; ExpressionException(; ""'{caller}': source mismatch\n""; "" Expected an expression from source {expected}\n""; "" Found expression derived from source {actual}\n""; "" Problematic field(s): {bad_refs}\n\n""; "" This error is commonly caused by chaining methods together:\n""; "" >>> ht.distinct().select(ht.x)\n\n""; "" Correct usage:\n""; "" >>> ht = ht.distinct()\n""; "" >>> ht = ht.select(ht.x)"".format(; caller=caller, expected=expected_source, actual=source, bad_refs=list(bad_refs); ); ); ). # check for stray indices by subtracting expected axes from observed; if broadc",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html:398,Log,Log,398,docs/0.2/_modules/hail/expr/expressions/expression_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.expr.expressions.typed_expressions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.expressions.typed_expressions. Source code for hail.expr.expressions.typed_expressions; from typing import Dict, Mapping, Optional, Sequence, Union. import numpy as np; from deprecated import deprecated. import hail as hl; from hail import ir; from hail.expr.types import (; HailType,; is_numeric,; tarray,; tbool,; tcall,; tdict,; tfloat32,; tfloat64,; tint32,; tint64,; tinterval,; tlocus,; tndarray,; tset,; tstr,; tstream,; tstruct,; ttuple,; ); from hail.typecheck import (; anyfunc,; dictof,; func_spec,; identity,; nullable,; oneof,; sliceof,; tupleof,; typecheck,; typecheck_method,; ); from hail.utils.java import Env, warning; from hail.utils.linkedlist import LinkedList; from hail.utils.misc import get_nice_attr_error, get_nice_field_error, wrap_to_list, wrap_to_tuple. from .base_expression import Expression, ExpressionException, to_expr, unify_all, unify_types; from .expression_typecheck import (; coercer_from_dtype,; expr_any,; expr_array,; expr_bool,; expr_dict,; expr_int32,; expr_int64,; expr_interval,; expr_ndarray,; expr_numeric,; expr_oneof,; expr_set,; expr_str,; expr_tuple,; ); from .indices import Aggregation, Indices. [docs]class CollectionExpression(Expression):; """"""Expression of type :class:`.tarray` or :class:`.tset`. >>> a = hl.literal([1, 2, 3, 4, 5]). >>> s3 = hl.literal({'Alice', 'Bob', 'Charlie'}); """""". def _filter_missing_method(self, filter_missing: bool, name: str, ret_type: HailType, *args):; collection = self; if filter_missing:; collection = self.filter(hl.is_defined); return collection._me",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:399,Log,Log,399,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.expr.functions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.functions. Source code for hail.expr.functions; import builtins; import functools; import itertools; import operator; from typing import Any, Callable, Iterable, Optional, TypeVar, Union. import numpy as np; import pandas as pd; from deprecated import deprecated. import hail; import hail as hl; from hail import ir; from hail.expr.expressions import (; ArrayExpression,; ArrayNumericExpression,; BooleanExpression,; CallExpression,; DictExpression,; Expression,; ExpressionException,; Float32Expression,; Float64Expression,; Int32Expression,; Int64Expression,; IntervalExpression,; LocusExpression,; NumericExpression,; SetExpression,; StreamExpression,; StringExpression,; StructExpression,; TupleExpression,; apply_expr,; cast_expr,; coercer_from_dtype,; construct_expr,; construct_variable,; expr_any,; expr_array,; expr_bool,; expr_call,; expr_dict,; expr_float32,; expr_float64,; expr_int32,; expr_int64,; expr_interval,; expr_locus,; expr_ndarray,; expr_numeric,; expr_oneof,; expr_set,; expr_str,; expr_stream,; expr_struct,; expr_tuple,; impute_type,; to_expr,; unify_all,; unify_exprs,; unify_types_limited,; ); from hail.expr.types import (; HailType,; hail_type,; is_float32,; is_float64,; is_int32,; is_int64,; is_numeric,; is_primitive,; tarray,; tbool,; tcall,; tdict,; tfloat32,; tfloat64,; tint32,; tint64,; tinterval,; tlocus,; tndarray,; trngstate,; tset,; tstr,; tstream,; tstruct,; ttuple,; ); from hail.genetics.allele_type import AlleleType; from hail.genetics.reference_genome import ReferenceGenome, reference_genome_type; from hail.typec",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:379,Log,Log,379,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.expr.types. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.types. Source code for hail.expr.types; import abc; import builtins; import json; import math; import pprint; from collections.abc import Mapping, Sequence; from typing import ClassVar, Union. import numpy as np; import pandas as pd. import hail as hl; from hailtop.frozendict import frozendict; from hailtop.hail_frozenlist import frozenlist. from .. import genetics; from ..genetics.reference_genome import reference_genome_type; from ..typecheck import nullable, oneof, transformed, typecheck, typecheck_method; from ..utils.byte_reader import ByteReader, ByteWriter; from ..utils.java import escape_parsable; from ..utils.misc import lookup_bit; from ..utils.struct import Struct; from .nat import NatBase, NatLiteral; from .type_parsing import type_grammar, type_grammar_str, type_node_visitor. __all__ = [; 'dtype',; 'dtypes_from_pandas',; 'HailType',; 'hail_type',; 'is_container',; 'is_compound',; 'is_numeric',; 'is_primitive',; 'types_match',; 'tint',; 'tint32',; 'tint64',; 'tfloat',; 'tfloat32',; 'tfloat64',; 'tstr',; 'tbool',; 'tarray',; 'tstream',; 'tndarray',; 'tset',; 'tdict',; 'tstruct',; 'tunion',; 'ttuple',; 'tinterval',; 'tlocus',; 'tcall',; 'tvoid',; 'tvariable',; 'hts_entry_schema',; ]. def summary_type(t):; if isinstance(t, hl.tdict):; return f'dict<{summary_type(t.key_type)}, {summary_type(t.value_type)}>'; elif isinstance(t, hl.tset):; return f'set<{summary_type(t.element_type)}>'; elif isinstance(t, hl.tarray):; return f'array<{summary_type(t.element_type)}>'; elif isinstance(t, hl.tstruct):; return f'struct with {len(t)} fields';",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:375,Log,Log,375,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.genetics.allele_type. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.allele_type. Source code for hail.genetics.allele_type; from enum import IntEnum, auto. _ALLELE_STRS = (; ""Unknown"",; ""SNP"",; ""MNP"",; ""Insertion"",; ""Deletion"",; ""Complex"",; ""Star"",; ""Symbolic"",; ""Transition"",; ""Transversion"",; ). [docs]class AlleleType(IntEnum):; """"""An enumeration for allele type. Notes; -----; The precise values of the enumeration constants are not guarenteed; to be stable and must not be relied upon.; """""". UNKNOWN = 0; """"""Unknown Allele Type""""""; SNP = auto(); """"""Single-nucleotide Polymorphism (SNP)""""""; MNP = auto(); """"""Multi-nucleotide Polymorphism (MNP)""""""; INSERTION = auto(); """"""Insertion""""""; DELETION = auto(); """"""Deletion""""""; COMPLEX = auto(); """"""Complex Polymorphism""""""; STAR = auto(); """"""Star Allele (``alt=*``)""""""; SYMBOLIC = auto(); """"""Symbolic Allele. e.g. ``alt=<INS>``; """"""; TRANSITION = auto(); """"""Transition SNP. e.g. ``ref=A alt=G``. Note; ----; This is only really used internally in :func:`hail.vds.sample_qc` and; :func:`hail.methods.sample_qc`.; """"""; TRANSVERSION = auto(); """"""Transversion SNP. e.g. ``ref=A alt=C``. Note; ----; This is only really used internally in :func:`hail.vds.sample_qc` and; :func:`hail.methods.sample_qc`.; """""". def __str__(self):; return str(self.value). @property; def pretty_name(self):; """"""A formatted (as opposed to uppercase) version of the member's name,; to match :func:`~hail.expr.functions.allele_type`. Examples; --------; >>> AlleleType.INSERTION.pretty_name; 'Insertion'; >>> at = AlleleType(hl.eval(hl.numeric_allele_type('a', 'att'))); >>> at.pretty_name == hl.eval(hl",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/allele_type.html:385,Log,Log,385,docs/0.2/_modules/hail/genetics/allele_type.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/allele_type.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.genetics.call. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.call. Source code for hail.genetics.call; from collections.abc import Sequence. from hail.typecheck import typecheck_method. [docs]class Call(object):; """"""; An object that represents an individual's call at a genomic locus. Parameters; ----------; alleles : :obj:`list` of :obj:`int`; List of alleles that compose the call.; phased : :obj:`bool`; If ``True``, the alleles are phased and the order is specified by; `alleles`. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.GT.take(5`)``. This is rare; it is much; more common to manipulate the :class:`.CallExpression` object, which is; constructed using the following functions:. - :func:`.call`; - :func:`.unphased_diploid_gt_index_call`; - :func:`.parse_call`; """""". def __init__(self, alleles, phased=False):; # Intentionally not using the type check annotations which are too slow.; assert isinstance(alleles, Sequence); assert isinstance(phased, bool). if len(alleles) > 2:; raise NotImplementedError(""Calls with greater than 2 alleles are not supported.""); self._phased = phased; ploidy = len(alleles); if phased or ploidy < 2:; self._alleles = alleles; else:; assert ploidy == 2; a0 = alleles[0]; a1 = alleles[1]; if a1 < a0:; a0, a1 = a1, a0; self._alleles = [a0, a1]. def __str__(self):; n = self.ploidy; if n == 0:; if self._phased:; return '|-'; return '-'. if n == 1:; if self._phased:; return f'|{self._alleles[0]}'; return str(self._alleles[0]). assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; if self._phased:; return",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/call.html:378,Log,Log,378,docs/0.2/_modules/hail/genetics/call.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.genetics.locus. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.locus. Source code for hail.genetics.locus; from typing import Union. import hail as hl; from hail.genetics.reference_genome import ReferenceGenome, reference_genome_type; from hail.typecheck import typecheck_method. [docs]class Locus(object):; """"""An object that represents a location in the genome. Parameters; ----------; contig : :class:`str`; Chromosome identifier.; position : :obj:`int`; Chromosomal position (1-indexed).; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to use. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.locus.take(5)``. This is rare; it is much; more common to manipulate the :class:`.LocusExpression` object, which is; constructed using the following functions:. - :func:`.locus`; - :func:`.parse_locus`; - :func:`.locus_from_global_position`; """""". def __init__(self, contig, position, reference_genome: Union[str, ReferenceGenome] = 'default'):; if isinstance(contig, int):; contig = str(contig). if isinstance(reference_genome, str):; reference_genome = hl.get_reference(reference_genome). assert isinstance(contig, str); assert isinstance(position, int); assert isinstance(reference_genome, ReferenceGenome). self._contig = contig; self._position = position; self._rg = reference_genome. def __str__(self):; return f'{self._contig}:{self._position}'. def __repr__(self):; return 'Locus(contig=%s, position=%s, reference_genome=%s)' % (self.contig, self.position, self._rg). def __eq__(self, other):; return (; (self._contig == ot",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html:379,Log,Log,379,docs/0.2/_modules/hail/genetics/locus.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.genetics.pedigree. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.pedigree. Source code for hail.genetics.pedigree; import re; from collections import Counter. from hail.typecheck import nullable, sequenceof, typecheck_method; from hail.utils.java import Env, FatalError, warning. [docs]class Trio(object):; """"""Class containing information about nuclear family relatedness and sex. :param str s: Sample ID of proband. :param fam_id: Family ID.; :type fam_id: str or None. :param pat_id: Sample ID of father.; :type pat_id: str or None. :param mat_id: Sample ID of mother.; :type mat_id: str or None. :param is_female: Sex of proband.; :type is_female: bool or None; """""". @typecheck_method(s=str, fam_id=nullable(str), pat_id=nullable(str), mat_id=nullable(str), is_female=nullable(bool)); def __init__(self, s, fam_id=None, pat_id=None, mat_id=None, is_female=None):; self._fam_id = fam_id; self._s = s; self._pat_id = pat_id; self._mat_id = mat_id; self._is_female = is_female. def __repr__(self):; return 'Trio(s=%s, fam_id=%s, pat_id=%s, mat_id=%s, is_female=%s)' % (; repr(self.s),; repr(self.fam_id),; repr(self.pat_id),; repr(self.mat_id),; repr(self.is_female),; ). def __str__(self):; return 'Trio(s=%s, fam_id=%s, pat_id=%s, mat_id=%s, is_female=%s)' % (; str(self.s),; str(self.fam_id),; str(self.pat_id),; str(self.mat_id),; str(self.is_female),; ). def __eq__(self, other):; return (; isinstance(other, Trio); and self._s == other._s; and self._mat_id == other._mat_id; and self._pat_id == other._pat_id; and self._fam_id == other._fam_id; and self._is_female == other._is_female; ). def __hash__(self):; retur",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html:382,Log,Log,382,docs/0.2/_modules/hail/genetics/pedigree.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.genetics.reference_genome. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.reference_genome. Source code for hail.genetics.reference_genome; import json; import re; from bisect import bisect_right. import hail as hl; from hail.typecheck import dictof, lazy, nullable, oneof, sequenceof, sized_tupleof, transformed, typecheck_method; from hail.utils.java import Env; from hail.utils.misc import wrap_to_list. rg_type = lazy(); reference_genome_type = oneof(transformed((str, lambda x: hl.get_reference(x))), rg_type). [docs]class ReferenceGenome:; """"""An object that represents a `reference genome <https://en.wikipedia.org/wiki/Reference_genome>`__. Examples; --------. >>> contigs = [""1"", ""X"", ""Y"", ""MT""]; >>> lengths = {""1"": 249250621, ""X"": 155270560, ""Y"": 59373566, ""MT"": 16569}; >>> par = [(""X"", 60001, 2699521)]; >>> my_ref = hl.ReferenceGenome(""my_ref"", contigs, lengths, ""X"", ""Y"", ""MT"", par). Notes; -----; Hail comes with predefined reference genomes (case sensitive!):. - GRCh37, Genome Reference Consortium Human Build 37; - GRCh38, Genome Reference Consortium Human Build 38; - GRCm38, Genome Reference Consortium Mouse Build 38; - CanFam3, Canis lupus familiaris (dog). You can access these reference genome objects using :func:`~hail.get_reference`:. >>> rg = hl.get_reference('GRCh37'); >>> rg = hl.get_reference('GRCh38'); >>> rg = hl.get_reference('GRCm38'); >>> rg = hl.get_reference('CanFam3'). Note that constructing a new reference genome, either by using the class; constructor or by using `read` will add the reference genome to the list of; known references; it is possible to access the reference gen",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:390,Log,Log,390,docs/0.2/_modules/hail/genetics/reference_genome.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.ggplot.aes. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.aes. Source code for hail.ggplot.aes; from collections.abc import Mapping. from hail.expr import Expression, literal. [docs]class Aesthetic(Mapping):; def __init__(self, properties):; self.properties = properties. def __getitem__(self, item):; return self.properties[item]. def __len__(self):; return len(self.properties). def __contains__(self, item):; return item in self.properties. def __iter__(self):; return iter(self.properties). def __repr__(self):; return self.properties.__repr__(). def merge(self, other):; return Aesthetic({**self.properties, **other.properties}). [docs]def aes(**kwargs):; """"""Create an aesthetic mapping. Parameters; ----------; kwargs:; Map aesthetic names to hail expressions based on table's plot. Returns; -------; :class:`.Aesthetic`; The aesthetic mapping to be applied. """"""; hail_field_properties = {}. for k, v in kwargs.items():; _v = v; if not isinstance(v, Expression):; _v = literal(v); hail_field_properties[k] = _v; return Aesthetic(hail_field_properties). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/aes.html:375,Log,Log,375,docs/0.2/_modules/hail/ggplot/aes.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/aes.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.ggplot.coord_cartesian. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.coord_cartesian. Source code for hail.ggplot.coord_cartesian; from .geoms import FigureAttribute. class CoordCartesian(FigureAttribute):; def __init__(self, xlim, ylim):; self.xlim = xlim; self.ylim = ylim. def apply_to_fig(self, fig_so_far):; if self.xlim is not None:; fig_so_far.update_xaxes(range=list(self.xlim)); if self.ylim is not None:; fig_so_far.update_yaxes(range=list(self.ylim)). [docs]def coord_cartesian(xlim=None, ylim=None):; """"""Set the boundaries of the plot. Parameters; ----------; xlim : :obj:`tuple` with two int; The minimum and maximum x value to show on the plot.; ylim : :obj:`tuple` with two int; The minimum and maximum y value to show on the plot. Returns; -------; :class:`.FigureAttribute`; The coordinate attribute to be applied. """"""; return CoordCartesian(xlim, ylim). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/coord_cartesian.html:387,Log,Log,387,docs/0.2/_modules/hail/ggplot/coord_cartesian.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/coord_cartesian.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.ggplot.facets. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.facets. Source code for hail.ggplot.facets; import abc; import math; from typing import ClassVar, Dict, Optional, Tuple. import hail as hl; from hail.expr import Expression, StructExpression. from .geoms import FigureAttribute; from .utils import n_partitions. [docs]def vars(*args: Expression) -> StructExpression:; """""". Parameters; ----------; *args: :class:`hail.expr.Expression`; Fields to facet by. Returns; -------; :class:`hail.expr.StructExpression`; A struct to pass to a faceter. """"""; return hl.struct(**{f""var_{i}"": arg for i, arg in enumerate(args)}). [docs]def facet_wrap(; facets: StructExpression, *, nrow: Optional[int] = None, ncol: Optional[int] = None, scales: str = ""fixed""; ) -> ""FacetWrap"":; """"""Introduce a one dimensional faceting on specified fields. Parameters; ----------; facets: :class:`hail.expr.StructExpression` created by `hl.ggplot.vars` function.; The fields to facet on.; nrow: :class:`int`; The number of rows into which the facets will be spread. Will be ignored if `ncol` is set.; ncol: :class:`int`; The number of columns into which the facets will be spread.; scales: :class:`str`; Whether the scales are the same across facets. For more information and a list of supported options, see `the ggplot documentation <https://ggplot2-book.org/facet.html#controlling-scales>`__. Returns; -------; :class:`FigureAttribute`; The faceter. """"""; return FacetWrap(facets, nrow, ncol, scales). class Faceter(FigureAttribute):; @abc.abstractmethod; def get_expr_to_group_by(self) -> StructExpression:; pass. class FacetWrap(Faceter):; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/facets.html:378,Log,Log,378,docs/0.2/_modules/hail/ggplot/facets.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/facets.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.ggplot.geoms. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.geoms. Source code for hail.ggplot.geoms; import abc; from typing import Any, ClassVar, Dict, Optional. import numpy as np; import plotly.graph_objects as go. from .aes import aes; from .stats import StatBin, StatCDF, StatCount, StatFunction, StatIdentity, StatNone; from .utils import bar_position_plotly_to_gg, linetype_plotly_to_gg. [docs]class FigureAttribute(abc.ABC):; pass. class Geom(FigureAttribute):; def __init__(self, aes):; self.aes = aes. @abc.abstractmethod; def apply_to_fig(; self, agg_result, fig_so_far: go.Figure, precomputed, facet_row, facet_col, legend_cache, is_faceted: bool; ):; """"""Add this geometry to the figure and indicate if this geometry demands a static figure.""""""; pass. @abc.abstractmethod; def get_stat(self):; pass. def _add_aesthetics_to_trace_args(self, trace_args, df):; for aes_name, (plotly_name, default) in self.aes_to_arg.items():; if hasattr(self, aes_name) and getattr(self, aes_name) is not None:; trace_args[plotly_name] = getattr(self, aes_name); elif aes_name in df.attrs:; trace_args[plotly_name] = df.attrs[aes_name]; elif aes_name in df.columns:; trace_args[plotly_name] = df[aes_name]; elif default is not None:; trace_args[plotly_name] = default. def _update_legend_trace_args(self, trace_args, legend_cache):; if ""name"" in trace_args:; trace_args[""legendgroup""] = trace_args[""name""]; if trace_args[""name""] in legend_cache:; trace_args[""showlegend""] = False; else:; trace_args[""showlegend""] = True; legend_cache[trace_args[""name""]] = {}. class GeomLineBasic(Geom):; aes_to_arg: ClassVar = {; ""color"": (""line",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:377,Log,Log,377,docs/0.2/_modules/hail/ggplot/geoms.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.ggplot.ggplot. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.ggplot. Source code for hail.ggplot.ggplot; import itertools; from pprint import pprint. from plotly.subplots import make_subplots. import hail as hl. from .aes import Aesthetic, aes; from .coord_cartesian import CoordCartesian; from .facets import Faceter; from .geoms import FigureAttribute, Geom; from .labels import Labels; from .scale import (; Scale,; ScaleContinuous,; ScaleDiscrete,; scale_color_continuous,; scale_color_discrete,; scale_fill_continuous,; scale_fill_discrete,; scale_shape_auto,; scale_x_continuous,; scale_x_discrete,; scale_x_genomic,; scale_y_continuous,; scale_y_discrete,; ); from .utils import check_scale_continuity, is_continuous_type, is_genomic_type. [docs]class GGPlot:; """"""The class representing a figure created using the ``hail.ggplot`` module. Create one by using :func:`.ggplot`. .. automethod:: to_plotly; .. automethod:: show; .. automethod:: write_image; """""". def __init__(self, ht, aes, geoms=[], labels=Labels(), coord_cartesian=None, scales=None, facet=None):; if scales is None:; scales = {}. self.ht = ht; self.aes = aes; self.geoms = geoms; self.labels = labels; self.coord_cartesian = coord_cartesian; self.scales = scales; self.facet = facet. self.add_default_scales(aes). def __add__(self, other):; assert isinstance(other, (FigureAttribute, Aesthetic)). copied = self.copy(); if isinstance(other, Geom):; copied.geoms.append(other); copied.add_default_scales(other.aes); elif isinstance(other, Labels):; copied.labels = copied.labels.merge(other); elif isinstance(other, CoordCartesian):; copied.coord_cartes",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:378,Log,Log,378,docs/0.2/_modules/hail/ggplot/ggplot.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.ggplot.labels. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.labels. Source code for hail.ggplot.labels; from .geoms import FigureAttribute. class Labels(FigureAttribute):; def __init__(self, title=None, xlabel=None, ylabel=None, group_labels={}, **kwargs):; self.title = title; self.xlabel = xlabel; self.ylabel = ylabel; self.group_labels = group_labels. def apply_to_fig(self, fig_so_far):; layout_updates = {}; if self.title is not None:; layout_updates[""title""] = self.title; if self.xlabel is not None:; layout_updates[""xaxis_title""] = self.xlabel; if self.ylabel is not None:; layout_updates[""yaxis_title""] = self.ylabel. fig_so_far.update_layout(**layout_updates). for legend_group, label in self.group_labels.items():; fig_so_far.update_traces({""legendgrouptitle_text"": label}, {""legendgroup"": legend_group}). def merge(self, other):; new_title = other.title if other.title is not None else self.title; new_xlabel = other.xlabel if other.xlabel is not None else self.xlabel; new_ylabel = other.ylabel if other.ylabel is not None else self.ylabel; new_group_labels = {**self.group_labels, **other.group_labels}. return Labels(title=new_title, xlabel=new_xlabel, ylabel=new_ylabel, group_labels=new_group_labels). [docs]def ggtitle(label):; """"""Sets the title of a plot. Parameters; ----------; label : :class:`str`; The desired title of the plot. Returns; -------; :class:`.FigureAttribute`; Label object to change the title.; """"""; return Labels(title=label). [docs]def xlab(label):; """"""Sets the x-axis label of a plot. Parameters; ----------; label : :class:`str`; The desired x-axis label of the plot. Returns; ---",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/labels.html:378,Log,Log,378,docs/0.2/_modules/hail/ggplot/labels.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/labels.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.ggplot.scale. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.scale. Source code for hail.ggplot.scale; import abc; from collections.abc import Mapping. import plotly; import plotly.express as px. from hail.context import get_reference; from hail.expr.types import tstr. from .geoms import FigureAttribute; from .utils import continuous_nums_to_colors, is_continuous_type, is_discrete_type. class Scale(FigureAttribute):; def __init__(self, aesthetic_name):; self.aesthetic_name = aesthetic_name. @abc.abstractmethod; def transform_data(self, field_expr):; pass. def create_local_transformer(self, groups_of_dfs):; return lambda x: x. @abc.abstractmethod; def is_discrete(self):; pass. @abc.abstractmethod; def is_continuous(self):; pass. def valid_dtype(self, dtype):; pass. class PositionScale(Scale):; def __init__(self, aesthetic_name, name, breaks, labels):; super().__init__(aesthetic_name); self.name = name; self.breaks = breaks; self.labels = labels. def update_axis(self, fig):; if self.aesthetic_name == ""x"":; return fig.update_xaxes; elif self.aesthetic_name == ""y"":; return fig.update_yaxes. # What else do discrete and continuous scales have in common?; def apply_to_fig(self, parent, fig_so_far):; if self.name is not None:; self.update_axis(fig_so_far)(title=self.name). if self.breaks is not None:; self.update_axis(fig_so_far)(tickvals=self.breaks). if self.labels is not None:; self.update_axis(fig_so_far)(ticktext=self.labels). def valid_dtype(self, dtype):; return True. class PositionScaleGenomic(PositionScale):; def __init__(self, aesthetic_name, reference_genome, name=None):; super().__init__(aesth",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:377,Log,Log,377,docs/0.2/_modules/hail/ggplot/scale.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.linalg.blockmatrix. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.linalg.blockmatrix. Source code for hail.linalg.blockmatrix; import itertools; import math; import os; import re. import numpy as np; import scipy.linalg as spla. import hail as hl; import hail.expr.aggregators as agg; from hail.expr import construct_expr, construct_variable; from hail.expr.blockmatrix_type import tblockmatrix; from hail.expr.expressions import (; expr_array,; expr_float64,; expr_int32,; expr_int64,; expr_ndarray,; expr_tuple,; matrix_table_source,; raise_unless_entry_indexed,; ); from hail.ir import (; F64,; ApplyBinaryPrimOp,; ApplyUnaryPrimOp,; BandSparsifier,; BlockMatrixAgg,; BlockMatrixBroadcast,; BlockMatrixCollect,; BlockMatrixDensify,; BlockMatrixDot,; BlockMatrixFilter,; BlockMatrixMap,; BlockMatrixMap2,; BlockMatrixRandom,; BlockMatrixRead,; BlockMatrixSlice,; BlockMatrixSparsify,; BlockMatrixToTable,; BlockMatrixToValueApply,; BlockMatrixWrite,; ExportType,; PerBlockSparsifier,; RectangleSparsifier,; RowIntervalSparsifier,; TableFromBlockMatrixNativeReader,; TableRead,; ValueToBlockMatrix,; tensor_shape_to_matrix_shape,; ); from hail.ir.blockmatrix_reader import BlockMatrixBinaryReader, BlockMatrixNativeReader; from hail.ir.blockmatrix_writer import BlockMatrixBinaryWriter, BlockMatrixNativeWriter, BlockMatrixRectanglesWriter; from hail.table import Table; from hail.typecheck import (; enumeration,; func_spec,; lazy,; nullable,; numeric,; oneof,; sequenceof,; sized_tupleof,; sliceof,; tupleof,; typecheck,; typecheck_method,; ); from hail.utils import local_path_uri, new_local_temp_file, new_temp_file, storage_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:383,Log,Log,383,docs/0.2/_modules/hail/linalg/blockmatrix.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.linalg.utils.misc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.linalg.utils.misc. Source code for hail.linalg.utils.misc; import numpy as np. import hail as hl; from hail.expr.expressions import expr_float64, expr_locus, raise_unless_row_indexed; from hail.typecheck import nullable, oneof, typecheck; from hail.utils.java import Env. [docs]@typecheck(a=np.ndarray, radius=oneof(int, float)); def array_windows(a, radius):; """"""Returns start and stop indices for window around each array value. Examples; --------. >>> hl.linalg.utils.array_windows(np.array([1, 2, 4, 4, 6, 8]), 2); (array([0, 0, 1, 1, 2, 4]), array([2, 4, 5, 5, 6, 6])). >>> hl.linalg.utils.array_windows(np.array([-10.0, -2.5, 0.0, 0.0, 1.2, 2.3, 3.0]), 2.5); (array([0, 1, 1, 1, 2, 2, 4]), array([1, 4, 6, 6, 7, 7, 7])). Notes; -----; For an array ``a`` in ascending order, the resulting ``starts`` and ``stops``; arrays have the same length as ``a`` and the property that, for all indices; ``i``, ``[starts[i], stops[i])`` is the maximal range of indices ``j`` such; that ``a[i] - radius <= a[j] <= a[i] + radius``. Index ranges are start-inclusive and stop-exclusive. This function is; especially useful in conjunction with; :meth:`.BlockMatrix.sparsify_row_intervals`. Parameters; ----------; a: :obj:`numpy.ndarray` of signed integer or float values; 1-dimensional array of values, non-decreasing with respect to index.; radius: :obj:`float`; Non-negative radius of window for values. Returns; -------; (:class:`numpy.ndarray` of :obj:`int`, :class:`numpy.ndarray` of :obj:`int`); Tuple of start indices array and stop indices array.; """"""; if radius < 0:;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/utils/misc.html:382,Log,Log,382,docs/0.2/_modules/hail/linalg/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/utils/misc.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.matrixtable. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.matrixtable. Source code for hail.matrixtable; import itertools; import warnings; from collections import Counter; from typing import Any, Dict, Iterable, List, Optional, Tuple. from deprecated import deprecated. import hail as hl; from hail import ir; from hail.expr.expressions import (; Expression,; ExpressionException,; Indices,; StructExpression,; TupleExpression,; analyze,; construct_expr,; construct_reference,; expr_any,; expr_bool,; expr_struct,; extract_refs_by_indices,; unify_all,; ); from hail.expr.matrix_type import tmatrix; from hail.expr.types import tarray, tset, types_match; from hail.table import ExprContainer, Table, TableIndexKeyError; from hail.typecheck import (; anyfunc,; anytype,; dictof,; enumeration,; lazy,; nullable,; numeric,; oneof,; sequenceof,; typecheck,; typecheck_method,; ); from hail.utils import deduplicate, default_handler, storage_level; from hail.utils.java import Env, info, warning; from hail.utils.misc import check_annotate_exprs, get_key_by_exprs, get_select_exprs, process_joins, wrap_to_tuple. [docs]class GroupedMatrixTable(ExprContainer):; """"""Matrix table grouped by row or column that can be aggregated into a new matrix table."""""". def __init__(; self,; parent: 'MatrixTable',; row_keys=None,; computed_row_key=None,; col_keys=None,; computed_col_key=None,; entry_fields=None,; row_fields=None,; col_fields=None,; partitions=None,; ):; super(GroupedMatrixTable, self).__init__(); self._parent = parent; self._copy_fields_from(parent); self._row_keys = row_keys; self._computed_row_key = computed_row_key; self._c",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:376,Log,Log,376,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.methods.family_methods. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.family_methods. Source code for hail.methods.family_methods; from typing import Tuple. import hail as hl; import hail.expr.aggregators as agg; from hail.expr import expr_call, expr_float64; from hail.genetics.pedigree import Pedigree; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import numeric, typecheck; from hail.utils.java import Env. from .misc import require_biallelic, require_col_key_str. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree, complete_trios=bool); def trio_matrix(dataset, pedigree, complete_trios=False) -> MatrixTable:; """"""Builds and returns a matrix where columns correspond to trios and entries contain genotypes for the trio. .. include:: ../_templates/req_tstring.rst. Examples; --------. Create a trio matrix:. >>> pedigree = hl.Pedigree.read('data/case_control_study.fam'); >>> trio_dataset = hl.trio_matrix(dataset, pedigree, complete_trios=True). Notes; -----. This method builds a new matrix table with one column per trio. If; `complete_trios` is ``True``, then only trios that satisfy; :meth:`.Trio.is_complete` are included. In this new dataset, the column; identifiers are the sample IDs of the trio probands. The column fields and; entries of the matrix are changed in the following ways:. The new column fields consist of three structs (`proband`, `father`,; `mother`), a Boolean field, and a string field:. - **proband** (:class:`.tstruct`) - Column fields on the proband.; - **father** (:class:`.tstruct`) - Column fields on the father.; - **mother** (:clas",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:387,Log,Log,387,docs/0.2/_modules/hail/methods/family_methods.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.methods.impex. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.impex. Source code for hail.methods.impex; import os; import re; from collections import defaultdict. import avro.schema; from avro.datafile import DataFileReader; from avro.io import DatumReader. import hail as hl; from hail import ir; from hail.expr import (; LocusExpression,; StructExpression,; analyze,; expr_array,; expr_bool,; expr_call,; expr_float64,; expr_int32,; expr_numeric,; expr_str,; to_expr,; ); from hail.expr.matrix_type import tmatrix; from hail.expr.table_type import ttable; from hail.expr.types import hail_type, tarray, tbool, tcall, tfloat32, tfloat64, tint32, tint64, tstr, tstruct; from hail.genetics.reference_genome import reference_genome_type; from hail.ir.utils import parse_type; from hail.matrixtable import MatrixTable; from hail.methods.misc import require_biallelic, require_col_key_str, require_row_key_variant; from hail.table import Table; from hail.typecheck import (; anytype,; char,; dictof,; enumeration,; nullable,; numeric,; oneof,; sequenceof,; sized_tupleof,; table_key_type,; typecheck,; ); from hail.utils import new_temp_file; from hail.utils.deduplicate import deduplicate; from hail.utils.java import Env, FatalError, info, jindexed_seq_args, warning; from hail.utils.misc import plural, wrap_to_list. from .import_lines_helpers import should_remove_line, split_lines. def locus_interval_expr(contig, start, end, includes_start, includes_end, reference_genome, skip_invalid_intervals):; includes_start = hl.bool(includes_start); includes_end = hl.bool(includes_end). if reference_genome:; return hl.locus_int",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/impex.html:378,Log,Log,378,docs/0.2/_modules/hail/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.methods.misc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.misc. Source code for hail.methods.misc; from typing import Union. import hail as hl; from hail import ir; from hail.expr import Expression, construct_expr, construct_variable, expr_any, expr_array, expr_interval, expr_numeric; from hail.expr.types import tarray, tlocus, tstr, tstruct, ttuple; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import func_spec, nullable, oneof, typecheck; from hail.utils import Interval, Struct, deduplicate, new_temp_file; from hail.utils.java import Env, info; from hail.utils.misc import plural. [docs]@typecheck(i=Expression, j=Expression, keep=bool, tie_breaker=nullable(func_spec(2, expr_numeric)), keyed=bool); def maximal_independent_set(i, j, keep=True, tie_breaker=None, keyed=True) -> Table:; """"""Return a table containing the vertices in a near; `maximal independent set <https://en.wikipedia.org/wiki/Maximal_independent_set>`_; of an undirected graph whose edges are given by a two-column table. Examples; --------; Run PC-relate and compute pairs of closely related individuals:. >>> pc_rel = hl.pc_relate(dataset.GT, 0.001, k=2, statistics='kin'); >>> pairs = pc_rel.filter(pc_rel['kin'] > 0.125). Starting from the above pairs, prune individuals from a dataset until no; close relationships remain:. >>> related_samples_to_remove = hl.maximal_independent_set(pairs.i, pairs.j, False); >>> result = dataset.filter_cols(; ... hl.is_defined(related_samples_to_remove[dataset.col_key]), keep=False). Starting from the above pairs, prune individuals from a dataset until no",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/misc.html:377,Log,Log,377,docs/0.2/_modules/hail/methods/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.methods.pca. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.pca. Source code for hail.methods.pca; from typing import List, Tuple. import hail as hl; import hail.expr.aggregators as agg; from hail import ir; from hail.experimental import mt_to_table_of_ndarray; from hail.expr import expr_call, expr_float64, matrix_table_source, raise_unless_entry_indexed; from hail.expr.expressions import construct_expr; from hail.table import Table; from hail.typecheck import nullable, oneof, typecheck; from hail.utils import FatalError; from hail.utils.java import Env, info. def hwe_normalize(call_expr):; mt = matrix_table_source('hwe_normalize/call_expr', call_expr); mt = mt.select_entries(__gt=call_expr.n_alt_alleles()); mt = mt.annotate_rows(__AC=agg.sum(mt.__gt), __n_called=agg.count_where(hl.is_defined(mt.__gt))); mt = mt.filter_rows((mt.__AC > 0) & (mt.__AC < 2 * mt.__n_called)). n_variants = mt.count_rows(); if n_variants == 0:; raise FatalError(""hwe_normalize: found 0 variants after filtering out monomorphic sites.""); info(f""hwe_normalize: found {n_variants} variants after filtering out monomorphic sites.""). mt = mt.annotate_rows(__mean_gt=mt.__AC / mt.__n_called); mt = mt.annotate_rows(__hwe_scaled_std_dev=hl.sqrt(mt.__mean_gt * (2 - mt.__mean_gt) * n_variants / 2)); mt = mt.unfilter_entries(). normalized_gt = hl.or_else((mt.__gt - mt.__mean_gt) / mt.__hwe_scaled_std_dev, 0.0); return normalized_gt. [docs]@typecheck(call_expr=expr_call, k=int, compute_loadings=bool); def hwe_normalized_pca(call_expr, k=10, compute_loadings=False) -> Tuple[List[float], Table, Table]:; r""""""Run principal component analysi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/pca.html:376,Log,Log,376,docs/0.2/_modules/hail/methods/pca.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.methods.qc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.qc. Source code for hail.methods.qc; import abc; import logging; import os; from collections import Counter; from shlex import quote as shq; from typing import Dict, List, Optional, Tuple, Union. import hail as hl; import hailtop.batch_client as bc; from hail.backend.service_backend import ServiceBackend; from hail.expr import Float64Expression; from hail.expr.expressions.expression_typecheck import expr_float64; from hail.expr.functions import numeric_allele_type; from hail.expr.types import tarray, tfloat, tint32, tstr, tstruct; from hail.genetics.allele_type import AlleleType; from hail.ir import TableToTableApply; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import anytype, nullable, numeric, oneof, typecheck; from hail.utils import FatalError; from hail.utils.java import Env, info, warning; from hail.utils.misc import divide_null, guess_cloud_spark_provider, new_temp_file; from hailtop import pip_version, yamlx; from hailtop.config import get_deploy_config; from hailtop.utils import async_to_blocking. from .misc import (; require_alleles_field,; require_biallelic,; require_col_key_str,; require_row_key_variant,; require_table_key_variant,; ). log = logging.getLogger('methods.qc'). HAIL_GENETICS_VEP_GRCH37_85_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH37_85_IMAGE', f'hailgenetics/vep-grch37-85:{pip_version()}'; ); HAIL_GENETICS_VEP_GRCH38_95_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH38_95_IMAGE', f'hailgenetics/vep-grch38-95:{pip_version()}'; ). def _qc_allele_type(ref, alt):; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/qc.html:493,log,logging,493,docs/0.2/_modules/hail/methods/qc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html,3,"['Log', 'log']","['Log', 'logging']"
Testability,"﻿. Hail | ; hail.methods.relatedness.identity_by_descent. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.relatedness.identity_by_descent. Source code for hail.methods.relatedness.identity_by_descent; import hail as hl; from hail import ir; from hail.backend.spark_backend import SparkBackend; from hail.expr import analyze; from hail.expr.expressions import expr_float64; from hail.linalg import BlockMatrix; from hail.matrixtable import MatrixTable; from hail.methods.misc import require_biallelic, require_col_key_str; from hail.table import Table; from hail.typecheck import nullable, numeric, typecheck; from hail.utils.java import Env. [docs]@typecheck(dataset=MatrixTable, maf=nullable(expr_float64), bounded=bool, min=nullable(numeric), max=nullable(numeric)); def identity_by_descent(dataset, maf=None, bounded=True, min=None, max=None) -> Table:; """"""Compute matrix of identity-by-descent estimates. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. To calculate a full IBD matrix, using minor allele frequencies computed; from the dataset itself:. >>> hl.identity_by_descent(dataset). To calculate an IBD matrix containing only pairs of samples with; ``PI_HAT`` in :math:`[0.2, 0.9]`, using minor allele frequencies stored in; the row field `panel_maf`:. >>> hl.identity_by_descent(dataset, maf=dataset['panel_maf'], min=0.2, max=0.9). Notes; -----. The dataset must have a column field named `s` which is a :class:`.StringExpression`; and which uniquely identifies a column. The implementation is based on the IBD algorithm d",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/identity_by_descent.html:404,Log,Log,404,docs/0.2/_modules/hail/methods/relatedness/identity_by_descent.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/identity_by_descent.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.methods.relatedness.king. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.relatedness.king. Source code for hail.methods.relatedness.king; import hail as hl; from hail.expr.expressions import expr_call, matrix_table_source; from hail.typecheck import nullable, typecheck; from hail.utils import deduplicate; from hail.utils.java import Env. [docs]@typecheck(call_expr=expr_call, block_size=nullable(int)); def king(call_expr, *, block_size=None):; r""""""Compute relatedness estimates between individuals using a KING variant. .. include:: ../_templates/req_diploid_gt.rst. Examples; --------; Estimate the kinship coefficient for every pair of samples. >>> kinship = hl.king(dataset.GT). Notes; -----. The following presentation summarizes the methods section of `Manichaikul,; et. al. <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025716/>`__, but; adopts a more consistent notation for matrices. Let. - :math:`i` and :math:`j` be two individuals in the dataset. - :math:`N^{Aa}_{i}` be the number of heterozygote genotypes for individual; :math:`i`. - :math:`N^{Aa,Aa}_{i,j}` be the number of variants at which a pair of; individuals both have heterozygote genotypes. - :math:`N^{AA,aa}_{i,j}` be the number of variants at which a pair of; individuals have opposing homozygote genotypes. - :math:`S_{i,j}` be the set of single-nucleotide variants for which both; individuals :math:`i` and :math:`j` have a non-missing genotype. - :math:`X_{i,s}` be the genotype score matrix. Each entry corresponds to; the genotype of individual :math:`i` at variant; :math:`s`. Homozygous-reference genotypes are represented as 0,; hetero",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/king.html:389,Log,Log,389,docs/0.2/_modules/hail/methods/relatedness/king.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/king.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.methods.relatedness.mating_simulation. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.relatedness.mating_simulation. Source code for hail.methods.relatedness.mating_simulation; import hail as hl; from hail.matrixtable import MatrixTable; from hail.typecheck import numeric, typecheck. [docs]@typecheck(mt=MatrixTable, n_rounds=int, generation_size_multiplier=numeric, keep_founders=bool); def simulate_random_mating(mt, n_rounds=1, generation_size_multiplier=1.0, keep_founders=True):; """"""Simulate random diploid mating to produce new individuals. Parameters; ----------; mt; n_rounds : :obj:`int`; Number of rounds of mating.; generation_size_multiplier : :obj:`float`; Ratio of number of offspring to current population for each round of mating.; keep_founders :obj:`bool`; If true, keep all founders and intermediate generations in the final sample list. If; false, keep only offspring in the last generation. Returns; -------; :class:`.MatrixTable`; """"""; if generation_size_multiplier <= 0:; raise ValueError(; f""simulate_random_mating: 'generation_size_multiplier' must be greater than zero: got {generation_size_multiplier}""; ); if n_rounds < 1:; raise ValueError(f""simulate_random_mating: 'n_rounds' must be positive: got {n_rounds}""). ck = next(iter(mt.col_key)). mt = mt.select_entries('GT'). ht = mt.localize_entries('__entries', '__cols'). ht = ht.annotate_globals(; generation_0=hl.range(hl.len(ht.__cols)).map(; lambda i: hl.struct(; s=hl.str('generation_0_idx_') + hl.str(i),; original=hl.str(ht.__cols[i][ck]),; mother=hl.missing('int32'),; father=hl.missing('int32'),; ); ); ). def make_new_generation(prev_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/mating_simulation.html:402,Log,Log,402,docs/0.2/_modules/hail/methods/relatedness/mating_simulation.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/mating_simulation.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.methods.relatedness.pc_relate. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.relatedness.pc_relate. Source code for hail.methods.relatedness.pc_relate; from typing import Optional. import hail as hl; import hail.expr.aggregators as agg; from hail import ir; from hail.backend.spark_backend import SparkBackend; from hail.expr import (; ArrayNumericExpression,; BooleanExpression,; CallExpression,; Float64Expression,; analyze,; expr_array,; expr_call,; expr_float64,; matrix_table_source,; ); from hail.expr.types import tarray; from hail.linalg import BlockMatrix; from hail.table import Table; from hail.typecheck import enumeration, nullable, numeric, typecheck; from hail.utils import new_temp_file; from hail.utils.java import Env. from ..pca import _hwe_normalized_blanczos, hwe_normalized_pca. [docs]@typecheck(; call_expr=expr_call,; min_individual_maf=numeric,; k=nullable(int),; scores_expr=nullable(expr_array(expr_float64)),; min_kinship=nullable(numeric),; statistics=enumeration('kin', 'kin2', 'kin20', 'all'),; block_size=nullable(int),; include_self_kinship=bool,; ); def pc_relate(; call_expr: CallExpression,; min_individual_maf: float,; *,; k: Optional[int] = None,; scores_expr: Optional[ArrayNumericExpression] = None,; min_kinship: Optional[float] = None,; statistics: str = 'all',; block_size: Optional[int] = None,; include_self_kinship: bool = False,; ) -> Table:; r""""""Compute relatedness estimates between individuals using a variant of the; PC-Relate method. .. include:: ../_templates/req_diploid_gt.rst. Examples; --------; Estimate kinship, identity-by-descent two, identity-by-descent one, a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/pc_relate.html:394,Log,Log,394,docs/0.2/_modules/hail/methods/relatedness/pc_relate.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/pc_relate.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.methods.statgen. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.statgen. Source code for hail.methods.statgen; import builtins; import itertools; import math; from typing import Callable, Dict, List, Optional, Tuple, Union. import hail as hl; import hail.expr.aggregators as agg; from hail import ir; from hail.expr import (; Expression,; ExpressionException,; NDArrayNumericExpression,; StructExpression,; analyze,; expr_any,; expr_call,; expr_float64,; expr_locus,; expr_numeric,; matrix_table_source,; raise_unless_column_indexed,; raise_unless_entry_indexed,; raise_unless_row_indexed,; table_source,; ); from hail.expr.functions import expit; from hail.expr.types import tarray, tbool, tfloat64, tint32, tndarray, tstruct; from hail.genetics.reference_genome import reference_genome_type; from hail.linalg import BlockMatrix; from hail.matrixtable import MatrixTable; from hail.methods.misc import require_biallelic, require_row_key_variant; from hail.stats import LinearMixedModel; from hail.table import Table; from hail.typecheck import anytype, enumeration, nullable, numeric, oneof, sequenceof, sized_tupleof, typecheck; from hail.utils import FatalError, new_temp_file, wrap_to_list; from hail.utils.java import Env, info, warning. from ..backend.spark_backend import SparkBackend; from . import pca, relatedness. pc_relate = relatedness.pc_relate; identity_by_descent = relatedness.identity_by_descent; _blanczos_pca = pca._blanczos_pca; _hwe_normalized_blanczos = pca._hwe_normalized_blanczos; _spectral_moments = pca._spectral_moments; _pca_and_moments = pca._pca_and_moments; hwe_normalized_pca = pca.hwe_nor",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:380,Log,Log,380,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.nd.nd. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.nd.nd. Source code for hail.nd.nd; from functools import reduce. import hail as hl; from hail.expr.expressions import (; Int64Expression,; cast_expr,; construct_expr,; expr_any,; expr_array,; expr_bool,; expr_int32,; expr_int64,; expr_ndarray,; expr_numeric,; expr_tuple,; unify_all,; ); from hail.expr.expressions.typed_expressions import NDArrayNumericExpression; from hail.expr.functions import _ndarray; from hail.expr.functions import array as aarray; from hail.expr.types import HailType, tfloat32, tfloat64, tndarray, ttuple; from hail.ir import Apply, NDArrayConcat, NDArrayEigh, NDArrayInv, NDArrayQR, NDArraySVD; from hail.typecheck import nullable, oneof, sequenceof, tupleof, typecheck. tsequenceof_nd = oneof(sequenceof(expr_ndarray()), expr_array(expr_ndarray())); shape_type = oneof(expr_int64, tupleof(expr_int64), expr_tuple()). [docs]def array(input_array, dtype=None):; """"""Construct an :class:`.NDArrayExpression`. Examples; --------. >>> hl.eval(hl.nd.array([1, 2, 3, 4])); array([1, 2, 3, 4], dtype=int32). >>> hl.eval(hl.nd.array([[1, 2, 3], [4, 5, 6]])); array([[1, 2, 3],; [4, 5, 6]], dtype=int32). >>> hl.eval(hl.nd.array(np.identity(3))); array([[1., 0., 0.],; [0., 1., 0.],; [0., 0., 1.]]). >>> hl.eval(hl.nd.array(hl.range(10, 20))); array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype=int32). Parameters; ----------; input_array : :class:`.ArrayExpression`, numpy ndarray, or nested python lists/tuples; The array to convert to a Hail ndarray.; dtype : :class:`.HailType`; Desired hail type. Default: `float64`. Returns; -------; :class:`.NDArray",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/nd/nd.html:370,Log,Log,370,docs/0.2/_modules/hail/nd/nd.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/nd/nd.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.plot.plots. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.plot.plots. Source code for hail.plot.plots; import collections; import math; import warnings; from typing import Any, Callable, Dict, List, Optional, Sequence, Set, Tuple, Union. import bokeh; import bokeh.io; import bokeh.models; import bokeh.palettes; import bokeh.plotting; import numpy as np; import pandas as pd; from bokeh.layouts import gridplot; from bokeh.models import (; BasicTicker,; CategoricalColorMapper,; CDSView,; ColorBar,; ColorMapper,; Column,; ColumnDataSource,; CustomJS,; DataRange1d,; GridPlot,; GroupFilter,; HoverTool,; IntersectionFilter,; Label,; Legend,; LegendItem,; LinearColorMapper,; LogColorMapper,; LogTicker,; Plot,; Renderer,; Select,; Slope,; Span,; ); from bokeh.plotting import figure; from bokeh.transform import transform. import hail; from hail.expr import aggregators; from hail.expr.expressions import (; Expression,; Float32Expression,; Float64Expression,; Int32Expression,; Int64Expression,; LocusExpression,; NumericExpression,; StringExpression,; expr_any,; expr_float64,; expr_locus,; expr_numeric,; expr_str,; raise_unless_row_indexed,; ); from hail.expr.functions import _error_from_cdf_python; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import dictof, nullable, numeric, oneof, sequenceof, sized_tupleof, typecheck; from hail.utils.java import warning; from hail.utils.struct import Struct. palette = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']. [docs]def output_notebook():; """"""Configure the Bokeh out",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:375,Log,Log,375,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,3,['Log'],"['Log', 'LogColorMapper', 'LogTicker']"
Testability,"﻿. Hail | ; hail.stats.linear_mixed_model. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.stats.linear_mixed_model. Source code for hail.stats.linear_mixed_model; [docs]class LinearMixedModel(object):; r""""""Class representing a linear mixed model. .. warning::. This functionality is no longer implemented/supported as of Hail 0.2.94. """""". def __init__(self, py, px, s, y=None, x=None, p_path=None):; raise NotImplementedError(""LinearMixedModel is no longer implemented/supported as of Hail 0.2.94""). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/stats/linear_mixed_model.html:389,Log,Log,389,docs/0.2/_modules/hail/stats/linear_mixed_model.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/stats/linear_mixed_model.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.table. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.table. Source code for hail.table; import collections; import itertools; import pprint; import shutil; from typing import Callable, ClassVar, Dict, List, Optional, Sequence, Union, overload. import numpy as np; import pandas; import pyspark. import hail as hl; from hail import ir; from hail.expr.expressions import (; ArrayExpression,; BooleanExpression,; CallExpression,; CollectionExpression,; DictExpression,; Expression,; ExpressionException,; Indices,; IntervalExpression,; LocusExpression,; NDArrayExpression,; NumericExpression,; StringExpression,; StructExpression,; TupleExpression,; analyze,; construct_expr,; construct_reference,; expr_any,; expr_array,; expr_bool,; expr_stream,; expr_struct,; extract_refs_by_indices,; to_expr,; unify_all,; ); from hail.expr.table_type import ttable; from hail.expr.types import dtypes_from_pandas, hail_type, tarray, tset, tstruct, types_match; from hail.typecheck import (; anyfunc,; anytype,; dictof,; enumeration,; func_spec,; lazy,; nullable,; numeric,; oneof,; sequenceof,; table_key_type,; typecheck,; typecheck_method,; ); from hail.utils import deduplicate; from hail.utils.interval import Interval; from hail.utils.java import Env, info, warning; from hail.utils.misc import (; check_annotate_exprs,; check_collisions,; check_keys,; get_key_by_exprs,; get_nice_attr_error,; get_nice_field_error,; get_select_exprs,; plural,; process_joins,; storage_level,; wrap_to_tuple,; ); from hail.utils.placement_tree import PlacementTree. table_type = lazy(). class TableIndexKeyError(Exception):; def __init__(self, key_type, in",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:370,Log,Log,370,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.utils.hadoop_utils. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.hadoop_utils. Source code for hail.utils.hadoop_utils; import gzip; import io; import os.path; import sys; from typing import Any, Dict, List. from hail.fs.hadoop_fs import HadoopFS; from hail.typecheck import enumeration, typecheck; from hail.utils.java import Env, info. [docs]@typecheck(path=str, mode=enumeration('r', 'w', 'x', 'rb', 'wb', 'xb'), buffer_size=int); def hadoop_open(path: str, mode: str = 'r', buffer_size: int = 8192):; """"""Open a file through the Hadoop filesystem API. Supports distributed; file systems like hdfs, gs, and s3. Warning; -------; Due to an implementation limitation, :func:`hadoop_open` may be quite; slow for large data sets (anything larger than 50 MB). Examples; --------; Write a Pandas DataFrame as a CSV directly into Google Cloud Storage:. >>> with hadoop_open('gs://my-bucket/df.csv', 'w') as f: # doctest: +SKIP; ... pandas_df.to_csv(f). Read and print the lines of a text file stored in Google Cloud Storage:. >>> with hadoop_open('gs://my-bucket/notes.txt') as f: # doctest: +SKIP; ... for line in f:; ... print(line.strip()). Write two lines directly to a file in Google Cloud Storage:. >>> with hadoop_open('gs://my-bucket/notes.txt', 'w') as f: # doctest: +SKIP; ... f.write('result1: %s\\n' % result1); ... f.write('result2: %s\\n' % result2). Unpack a packed Python struct directly from a file in Google Cloud Storage:. >>> from struct import unpack; >>> with hadoop_open('gs://my-bucket/notes.txt', 'rb') as f: # doctest: +SKIP; ... print(unpack('<f', bytearray(f.read()))). Notes; -----; The supported mo",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html:383,Log,Log,383,docs/0.2/_modules/hail/utils/hadoop_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.utils.interval. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.interval. Source code for hail.utils.interval; import hail as hl; from hail.typecheck import anytype, lazy, nullable, typecheck_method. interval_type = lazy(). [docs]class Interval(object):; """"""; An object representing a range of values between `start` and `end`. >>> interval2 = hl.Interval(3, 6). Parameters; ----------; start : any type; Object with type `point_type`.; end : any type; Object with type `point_type`.; includes_start : :obj:`bool`; Interval includes start.; includes_end : :obj:`bool`; Interval includes end. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.interval.take(5)``. This is rare; it is much; more common to manipulate the :class:`.IntervalExpression` object, which is; constructed using the following functions:. - :func:`.interval`; - :func:`.locus_interval`; - :func:`.parse_locus_interval`; """""". @typecheck_method(; start=anytype,; end=anytype,; includes_start=bool,; includes_end=bool,; point_type=nullable(lambda: hl.expr.types.hail_type),; ); def __init__(self, start, end, includes_start=True, includes_end=False, point_type=None):; if point_type is None:; from hail.expr.expressions import impute_type, unify_types_limited. start_type = impute_type(start); end_type = impute_type(end); point_type = unify_types_limited(start_type, end_type); if point_type is None:; raise TypeError(""'start' and 'end' have incompatible types: '{}', '{}'."".format(start_type, end_type)). self._point_type = point_type; self._start = start; self._end = end; self._includes_start",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/interval.html:379,Log,Log,379,docs/0.2/_modules/hail/utils/interval.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/interval.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.utils.misc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.misc. Source code for hail.utils.misc; import atexit; import datetime; import difflib; import json; import os; import re; import secrets; import shutil; import string; import tempfile; from collections import Counter, defaultdict; from contextlib import contextmanager; from io import StringIO; from typing import Literal, Optional; from urllib.parse import urlparse. import hail; import hail as hl; from hail.typecheck import enumeration, nullable, typecheck; from hail.utils.java import Env, error. [docs]@typecheck(n_rows=int, n_cols=int, n_partitions=nullable(int)); def range_matrix_table(n_rows, n_cols, n_partitions=None) -> 'hail.MatrixTable':; """"""Construct a matrix table with row and column indices and no entry fields. Examples; --------. >>> range_ds = hl.utils.range_matrix_table(n_rows=100, n_cols=10). >>> range_ds.count_rows(); 100. >>> range_ds.count_cols(); 10. Notes; -----; The resulting matrix table contains the following fields:. - `row_idx` (:py:data:`.tint32`) - Row index (row key).; - `col_idx` (:py:data:`.tint32`) - Column index (column key). It contains no entry fields. This method is meant for testing and learning, and is not optimized for; production performance. Parameters; ----------; n_rows : :obj:`int`; Number of rows.; n_cols : :obj:`int`; Number of columns.; n_partitions : int, optional; Number of partitions (uses Spark default parallelism if None). Returns; -------; :class:`.MatrixTable`; """"""; check_nonnegative_and_in_range('range_matrix_table', 'n_rows', n_rows); check_nonnegative_and_in_range('range_matrix_table', '",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/misc.html:375,Log,Log,375,docs/0.2/_modules/hail/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/misc.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.utils.struct. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.struct. Source code for hail.utils.struct; import pprint; from collections import OrderedDict; from collections.abc import Mapping; from typing import Any, Dict. from hail.typecheck import anytype, typecheck, typecheck_method; from hail.utils.misc import get_nice_attr_error, get_nice_field_error. [docs]class Struct(Mapping):; """"""; Nested annotation structure. >>> bar = hl.Struct(**{'foo': 5, '1kg': 10}). Struct elements are treated as both 'items' and 'attributes', which; allows either syntax for accessing the element ""foo"" of struct ""bar"":. >>> bar.foo; >>> bar['foo']. Field names that are not valid Python identifiers, such as fields that; start with numbers or contain spaces, must be accessed with the latter; syntax:. >>> bar['1kg']. The ``pprint`` module can be used to print nested Structs in a more; human-readable fashion:. >>> from pprint import pprint; >>> pprint(bar). Parameters; ----------; attributes; Field names and values. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.info.take(5)``. This is rare; it is much; more common to manipulate the :class:`.StructExpression` object, which is; constructed using the :func:`.struct` function.; """""". def __init__(self, **kwargs):; # Set this way to avoid an infinite recursion in `__getattr__`.; self.__dict__[""_fields""] = kwargs. def __contains__(self, item):; return item in self._fields. def __getstate__(self) -> Dict[str, Any]:; return self._fields. def __setstate__(self, state: Dict[str, Any]):; self.__dict__[""_fields""] = st",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/struct.html:377,Log,Log,377,docs/0.2/_modules/hail/utils/struct.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/struct.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.utils.tutorial. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.tutorial. Source code for hail.utils.tutorial; import os; import zipfile; from urllib.request import urlretrieve. import hail as hl; from hailtop.utils import sync_retry_transient_errors. from .java import Env, info; from .misc import local_path_uri, new_local_temp_dir, new_temp_file. __all__ = ['get_1kg', 'get_hgdp', 'get_movie_lens']. resources = {; '1kg_annotations': 'https://storage.googleapis.com/hail-tutorial/1kg_annotations.txt',; '1kg_matrix_table': 'https://storage.googleapis.com/hail-tutorial/1kg.vcf.bgz',; '1kg_ensembl_gene_annotations': 'https://storage.googleapis.com/hail-tutorial/ensembl_gene_annotations.txt',; 'HGDP_annotations': 'https://storage.googleapis.com/hail-tutorial/hgdp/hgdp_pop_and_sex_annotations.tsv',; 'HGDP_matrix_table': 'https://storage.googleapis.com/hail-tutorial/hgdp/hgdp_subset.vcf.bgz',; 'HGDP_ensembl_gene_annotations': 'https://storage.googleapis.com/hail-tutorial/hgdp/hgdp_gene_annotations.tsv',; 'movie_lens_100k': 'https://files.grouplens.org/datasets/movielens/ml-100k.zip',; }. tmp_dir: str = None. def init_temp_dir():; global tmp_dir; if tmp_dir is None:; tmp_dir = new_local_temp_dir(). def _dir_exists(fs, path):; return fs.exists(path) and fs.is_dir(path). def _file_exists(fs, path):; return fs.exists(path) and fs.is_file(path). def _copy_to_tmp(fs, src, extension=None):; dst = new_temp_file(extension=extension); fs.copy(src, dst); return dst. [docs]def get_1kg(output_dir, overwrite: bool = False):; """"""Download subset of the `1000 Genomes <http://www.internationalgenome.org/>`__; dataset and sam",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/tutorial.html:379,Log,Log,379,docs/0.2/_modules/hail/utils/tutorial.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/tutorial.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.vds.combiner.variant_dataset_combiner. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.combiner.variant_dataset_combiner. Source code for hail.vds.combiner.variant_dataset_combiner; import collections; import hashlib; import json; import os; import sys; import uuid; from itertools import chain; from math import floor, log; from typing import ClassVar, Collection, Dict, List, NamedTuple, Optional, Union. import hail as hl; from hail.expr import HailType, tmatrix; from hail.genetics.reference_genome import ReferenceGenome; from hail.utils import FatalError, Interval; from hail.utils.java import info, warning. from ..variant_dataset import VariantDataset; from .combine import (; calculate_even_genome_partitioning,; calculate_new_intervals,; combine,; combine_r,; combine_variant_datasets,; defined_entry_fields,; make_reference_stream,; make_variant_stream,; transform_gvcf,; ). [docs]class VDSMetadata(NamedTuple):; """"""The path to a Variant Dataset and the number of samples within. Parameters; ----------; path : :class:`str`; Path to the variant dataset.; n_samples : :class:`int`; Number of samples contained within the Variant Dataset at `path`. """""". path: str; n_samples: int. class CombinerOutType(NamedTuple):; """"""A container for the types of a VDS"""""". reference_type: tmatrix; variant_type: tmatrix. FAST_CODEC_SPEC = """"""{; ""name"": ""LEB128BufferSpec"",; ""child"": {; ""name"": ""BlockingBufferSpec"",; ""blockSize"": 65536,; ""child"": {; ""name"": ""ZstdBlockBufferSpec"",; ""blockSize"": 65536,; ""child"": {; ""name"": ""StreamBlockBufferSpec""; }; }; }; }"""""". [docs]class VariantDatasetCombiner: # pylint: disable=too-many-instanc",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html:693,log,log,693,docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,3,"['Log', 'log']","['Log', 'log']"
Testability,"﻿. Hail | ; hail.vds.functions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.functions. Source code for hail.vds.functions; import hail as hl; from hail.expr.expressions import expr_any, expr_array, expr_call, expr_int32; from hail.expr.functions import _func; from hail.typecheck import enumeration, typecheck. [docs]@typecheck(lgt=expr_call, la=expr_array(expr_int32)); def lgt_to_gt(lgt, la):; """"""Transform LGT into GT using local alleles array. Parameters; ----------; lgt : :class:`.CallExpression`; LGT value.; la : :class:`.ArrayExpression`; Local alleles array. Returns; -------; :class:`.CallExpression`; """"""; return hl.rbind(lgt, lambda lgt: hl.if_else(lgt.is_non_ref(), _func(""lgt_to_gt"", hl.tcall, lgt, la), lgt)). [docs]@typecheck(; array=expr_array(),; local_alleles=expr_array(expr_int32),; n_alleles=expr_int32,; fill_value=expr_any,; number=enumeration('A', 'R', 'G'),; ); def local_to_global(array, local_alleles, n_alleles, fill_value, number):; """"""Reindex a locally-indexed array to globally-indexed. Examples; --------; >>> local_alleles = hl.array([0, 2]); >>> local_ad = hl.array([9, 10]); >>> local_pl = hl.array([94, 0, 123]). >>> hl.eval(local_to_global(local_ad, local_alleles, n_alleles=3, fill_value=0, number='R')); [9, 0, 10]. >>> hl.eval(local_to_global(local_pl, local_alleles, n_alleles=3, fill_value=999, number='G')); [94, 999, 999, 0, 999, 123]. Notes; -----; The `number` parameter matches the `VCF specification <https://samtools.github.io/hts-specs/VCFv4.3.pdf>`__; number definitions:. - ``A`` indicates one value per allele, excluding the reference.; - ``R`` indicates one value per allele, including",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/functions.html:378,Log,Log,378,docs/0.2/_modules/hail/vds/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/functions.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.vds.methods. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.methods. Source code for hail.vds.methods; import hail as hl; from hail import ir; from hail.expr import expr_any, expr_array, expr_bool, expr_interval, expr_locus, expr_str; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import dictof, enumeration, func_spec, nullable, oneof, sequenceof, typecheck; from hail.utils.java import Env, info, warning; from hail.utils.misc import new_temp_file, wrap_to_list; from hail.vds.variant_dataset import VariantDataset. def write_variant_datasets(vdss, paths, *, overwrite=False, stage_locally=False, codec_spec=None):; """"""Write many `vdses` to their corresponding path in `paths`.""""""; ref_writer = ir.MatrixNativeMultiWriter(; [f""{p}/reference_data"" for p in paths], overwrite, stage_locally, codec_spec; ); var_writer = ir.MatrixNativeMultiWriter([f""{p}/variant_data"" for p in paths], overwrite, stage_locally, codec_spec); Env.backend().execute(ir.MatrixMultiWrite([vds.reference_data._mir for vds in vdss], ref_writer)); Env.backend().execute(ir.MatrixMultiWrite([vds.variant_data._mir for vds in vdss], var_writer)). [docs]@typecheck(vds=VariantDataset); def to_dense_mt(vds: 'VariantDataset') -> 'MatrixTable':; """"""Creates a single, dense :class:`.MatrixTable` from the split; :class:`.VariantDataset` representation. Parameters; ----------; vds : :class:`.VariantDataset`; Dataset in VariantDataset representation. Returns; -------; :class:`.MatrixTable`; Dataset in dense MatrixTable representation.; """"""; ref = vds.reference_data; # FIXME(chrisvittal) consider changing END ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/methods.html:376,Log,Log,376,docs/0.2/_modules/hail/vds/methods.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/methods.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.vds.sample_qc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.sample_qc. Source code for hail.vds.sample_qc; from collections.abc import Sequence; from typing import Optional. import hail as hl; from hail.expr.expressions import Expression; from hail.expr.expressions.typed_expressions import (; ArrayExpression,; CallExpression,; LocusExpression,; NumericExpression,; StructExpression,; ); from hail.genetics.allele_type import AlleleType; from hail.methods.misc import require_first_key_field_locus; from hail.methods.qc import _qc_allele_type; from hail.table import Table; from hail.typecheck import nullable, sequenceof, typecheck; from hail.utils.java import Env; from hail.utils.misc import divide_null; from hail.vds.variant_dataset import VariantDataset. @typecheck(global_gt=Expression, alleles=ArrayExpression); def vmt_sample_qc_variant_annotations(; *,; global_gt: 'Expression',; alleles: 'ArrayExpression',; ) -> tuple['Expression', 'Expression']:; """"""Compute the necessary variant annotations for :func:`.vmt_sample_qc`, that is,; allele count (AC) and an integer representation of allele type. Parameters; ----------; global_gt : :class:`.Expression`; Call expression of the global GT of a variants matrix table usually generated; by :func:`..lgt_to_gt`; alleles : :class:`.ArrayExpression`; Array expression of the alleles of a variants matrix table; (generally ``vds.variant_data.alleles``). Returns; -------; :class:`tuple`; Tuple of expressions representing the AC (first element) and allele type; (second element).; """""". return (hl.agg.call_stats(global_gt, alleles).AC, alleles[1:].map(lambda alt: _qc_all",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/sample_qc.html:378,Log,Log,378,docs/0.2/_modules/hail/vds/sample_qc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/sample_qc.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hail.vds.variant_dataset. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.variant_dataset. Source code for hail.vds.variant_dataset; import json; import os. import hail as hl; from hail.genetics import ReferenceGenome; from hail.matrixtable import MatrixTable; from hail.typecheck import typecheck_method; from hail.utils.java import info, warning. extra_ref_globals_file = 'extra_reference_globals.json'. [docs]def read_vds(; path,; *,; intervals=None,; n_partitions=None,; _assert_reference_type=None,; _assert_variant_type=None,; _warn_no_ref_block_max_length=True,; ) -> 'VariantDataset':; """"""Read in a :class:`.VariantDataset` written with :meth:`.VariantDataset.write`. Parameters; ----------; path: :obj:`str`. Returns; -------; :class:`.VariantDataset`; """"""; if intervals or not n_partitions:; reference_data = hl.read_matrix_table(VariantDataset._reference_path(path), _intervals=intervals); variant_data = hl.read_matrix_table(VariantDataset._variants_path(path), _intervals=intervals); else:; assert n_partitions is not None; reference_data = hl.read_matrix_table(VariantDataset._reference_path(path)); intervals = reference_data._calculate_new_partitions(n_partitions); assert len(intervals) > 0; reference_data = hl.read_matrix_table(VariantDataset._reference_path(path), _intervals=intervals); variant_data = hl.read_matrix_table(VariantDataset._variants_path(path), _intervals=intervals). vds = VariantDataset(reference_data, variant_data); if VariantDataset.ref_block_max_length_field not in vds.reference_data.globals:; fs = hl.current_backend().fs; metadata_file = os.path.join(path, extra_ref_globals_file); if fs.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/variant_dataset.html:384,Log,Log,384,docs/0.2/_modules/hail/vds/variant_dataset.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/variant_dataset.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hailtop.frozendict. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hailtop.frozendict. Source code for hailtop.frozendict; from collections.abc import Mapping; from typing import Dict, Generic, TypeVar. T = TypeVar(""T""); U = TypeVar(""U""). [docs]class frozendict(Mapping, Generic[T, U]):; """"""; An object representing an immutable dictionary. >>> my_frozen_dict = hl.utils.frozendict({1:2, 7:5}). To get a normal python dictionary with the same elements from a `frozendict`:. >>> dict(frozendict({'a': 1, 'b': 2})). Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.my_dict.take(5)``. This is rare; it is much; more common to manipulate the :class:`.DictExpression` object, which is; constructed using :func:`.dict`. This class is necessary because hail; supports using dicts as keys to other dicts or as elements in sets, while; python does not. """""". def __init__(self, d: Dict[T, U]):; self.d = d.copy(). def __getitem__(self, k: T) -> U:; return self.d[k]. def __hash__(self) -> int:; return hash(frozenset(self.items())). def __len__(self) -> int:; return len(self.d). def __iter__(self):; return iter(self.d). def __repr__(self):; return f'frozendict({self.d!r})'. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hailtop/frozendict.html:378,Log,Log,378,docs/0.2/_modules/hailtop/frozendict.html,https://hail.is,https://hail.is/docs/0.2/_modules/hailtop/frozendict.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; hailtop.fs.fs_utils. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hailtop.fs.fs_utils. Source code for hailtop.fs.fs_utils; import io; from typing import List, Optional. from hailtop.aiocloud.aiogoogle import GCSRequesterPaysConfiguration; from hailtop.utils.gcs_requester_pays import GCSRequesterPaysFSCache. from .router_fs import RouterFS; from .stat_result import FileListEntry. _fses = GCSRequesterPaysFSCache(fs_constructor=RouterFS). [docs]def open(; path: str,; mode: str = 'r',; buffer_size: int = 8192,; *,; requester_pays_config: Optional[GCSRequesterPaysConfiguration] = None,; ) -> io.IOBase:; """"""Open a file from the local filesystem of from blob storage. Supported; blob storage providers are GCS, S3 and ABS. Examples; --------; Write a Pandas DataFrame as a CSV directly into Google Cloud Storage:. >>> with hfs.open('gs://my-bucket/df.csv', 'w') as f: # doctest: +SKIP; ... pandas_df.to_csv(f). Read and print the lines of a text file stored in Google Cloud Storage:. >>> with hfs.open('gs://my-bucket/notes.txt') as f: # doctest: +SKIP; ... for line in f:; ... print(line.strip()). Access a text file stored in a Requester Pays Bucket in Google Cloud Storage:. >>> with hfs.open( # doctest: +SKIP; ... 'gs://my-bucket/notes.txt',; ... requester_pays_config='my-project'; ... ) as f:; ... for line in f:; ... print(line.strip()). Specify multiple Requester Pays Buckets within a project that are acceptable; to access:. >>> with hfs.open( # doctest: +SKIP; ... 'gs://my-bucket/notes.txt',; ... requester_pays_config=('my-project', ['my-bucket', 'bucket-2']); ... ) as f:; ... for line in f:; ... print(line.strip()). Writ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hailtop/fs/fs_utils.html:379,Log,Log,379,docs/0.2/_modules/hailtop/fs/fs_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hailtop/fs/fs_utils.html,1,['Log'],['Log']
Testability,"﻿. Hail | ; linalg/utils. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); hail; Classes; Modules; expressions; types; functions; aggregators; scans; methods; nd; utils; linalg; stats; genetics; plot; ggplot; vds; experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; linalg; linalg/utils. View page source. linalg/utils. array_windows(a, radius); Returns start and stop indices for window around each array value. locus_windows(locus_expr, radius[, ...]); Returns start and stop indices for window around each locus. hail.linalg.utils.array_windows(a, radius)[source]; Returns start and stop indices for window around each array value.; Examples; >>> hl.linalg.utils.array_windows(np.array([1, 2, 4, 4, 6, 8]), 2); (array([0, 0, 1, 1, 2, 4]), array([2, 4, 5, 5, 6, 6])). >>> hl.linalg.utils.array_windows(np.array([-10.0, -2.5, 0.0, 0.0, 1.2, 2.3, 3.0]), 2.5); (array([0, 1, 1, 1, 2, 2, 4]), array([1, 4, 6, 6, 7, 7, 7])). Notes; For an array a in ascending order, the resulting starts and stops; arrays have the same length as a and the property that, for all indices; i, [starts[i], stops[i]) is the maximal range of indices j such; that a[i] - radius <= a[j] <= a[i] + radius.; Index ranges are start-inclusive and stop-exclusive. This function is; especially useful in conjunction with; BlockMatrix.sparsify_row_intervals(). Parameters:. a (numpy.ndarray of signed integer or float values) – 1-dimensional array of values, non-decreasing with respect to index.; radius (float) – Non-negative radius of window for values. Returns:; (numpy.ndarray of int, numpy.ndarray of int) – Tuple of start indices array and stop in",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/linalg/utils/index.html:573,Log,Log,573,docs/0.2/linalg/utils/index.html,https://hail.is,https://hail.is/docs/0.2/linalg/utils/index.html,1,['Log'],['Log']
Usability," Added; hail.query_table function for reading tables with indices from; Python.; (#12139) Random; number generation has been updated, but shouldn’t affect most users.; If you need to manually set seeds, see; https://hail.is/docs/0.2/functions/random.html for details.; (#11884) Added; Job.always_copy_output when using the ServiceBackend. The; default behavior is False, which is a breaking change from the; previous behavior to always copy output files regardless of the job’s; completion state.; (#12139) Brand new; random number generation, shouldn’t affect most users. If you need to; manually set seeds, see; https://hail.is/docs/0.2/functions/random.html for details. Bug Fixes. (#12487) Fixed a bug; causing rare but deterministic job failures deserializing data in; Query-on-Batch.; (#12535) QoB will; now error if the user reads from and writes to the same path. QoB; also now respects the user’s configuration of; disable_progress_bar. When disable_progress_bar is; unspecified, QoB only disables the progress bar for non-interactive; sessions.; (#12517) Fix a; performance regression that appears when using hl.split_multi_hts; among other methods. Version 0.2.105; Released 2022-10-31 🎃. New Features. (#12293) Added; support for hail.MatrixTables to hail.ggplot. Bug Fixes. (#12384) Fixed a; critical bug that disabled tree aggregation and scan executions in; 0.2.104, leading to out-of-memory errors.; (#12265) Fix; long-standing bug wherein hl.agg.collect_as_set and; hl.agg.counter error when applied to types which, in Python, are; unhashable. For example, hl.agg.counter(t.list_of_genes) will not; error when t.list_of_genes is a list. Instead, the counter; dictionary will use FrozenList keys from the frozenlist; package. Version 0.2.104; Release 2022-10-19. New Features. (#12346): Introduced; new progress bars which include total time elapsed and look cool. Version 0.2.103; Release 2022-10-18. Bug Fixes. (#12305): Fixed a; rare crash reading tables/matrixtables with _",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:43159,progress bar,progress bar,43159,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['progress bar'],['progress bar']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_C,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Gastroesophageal_Junction_all_snp_gene_associations.html:319,Guid,Guides,319,docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Gastroesophageal_Junction_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Gastroesophageal_Junction_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cel,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Cells_EBV-transformed_lymphocytes_all_snp_gene_associations.html:317,Guid,Guides,317,docs/0.2/datasets/schemas/GTEx_sQTL_Cells_EBV-transformed_lymphocytes_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Cells_EBV-transformed_lymphocytes_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Not_Sun_Exposed_Suprapubic_all_snp_gene_associations.html:315,Guid,Guides,315,docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Not_Sun_Exposed_Suprapubic_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Not_Sun_Exposed_Suprapubic_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Small_Intestine_Terminal_Ileum_all_snp_gene_associations.html:314,Guid,Guides,314,docs/0.2/datasets/schemas/GTEx_sQTL_Small_Intestine_Terminal_Ileum_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Small_Intestine_Terminal_Ileum_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cult,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Sun_Exposed_Lower_leg_all_snp_gene_associations.html:310,Guid,Guides,310,docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Sun_Exposed_Lower_leg_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Sun_Exposed_Lower_leg_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Heart_Atrial_Appendage_all_snp_gene_associations.html:306,Guid,Guides,306,docs/0.2/datasets/schemas/GTEx_sQTL_Heart_Atrial_Appendage_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Heart_Atrial_Appendage_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_f,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Muscularis_all_snp_gene_associations.html:304,Guid,Guides,304,docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Muscularis_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Muscularis_all_snp_gene_associations.html,3,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibro,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Transverse_all_snp_gene_associations.html:300,Guid,Guides,300,docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Transverse_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Transverse_all_snp_gene_associations.html,2,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibrob,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Muscle_Skeletal_all_snp_gene_associations.html:299,Guid,Guides,299,docs/0.2/datasets/schemas/GTEx_sQTL_Muscle_Skeletal_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Muscle_Skeletal_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibrobla,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Sigmoid_all_snp_gene_associations.html:297,Guid,Guides,297,docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Sigmoid_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Sigmoid_all_snp_gene_associations.html,2,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblas,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Nerve_Tibial_all_snp_gene_associations.html:296,Guid,Guides,296,docs/0.2/datasets/schemas/GTEx_sQTL_Nerve_Tibial_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Nerve_Tibial_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblast,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Whole_Blood_all_snp_gene_associations.html:295,Guid,Guides,295,docs/0.2/datasets/schemas/GTEx_sQTL_Whole_Blood_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Whole_Blood_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pituitary_all_snp_gene_associations.html:293,Guid,Guides,293,docs/0.2/datasets/schemas/GTEx_sQTL_Pituitary_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pituitary_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_a,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pancreas_all_snp_gene_associations.html:292,Guid,Guides,292,docs/0.2/datasets/schemas/GTEx_sQTL_Pancreas_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pancreas_all_snp_gene_associations.html,2,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_al,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Stomach_all_snp_gene_associations.html:291,Guid,Guides,291,docs/0.2/datasets/schemas/GTEx_sQTL_Stomach_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Stomach_all_snp_gene_associations.html,2,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Spleen_all_snp_gene_associations.html:290,Guid,Guides,290,docs/0.2/datasets/schemas/GTEx_sQTL_Spleen_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Spleen_all_snp_gene_associations.html,4,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Liver_all_snp_gene_associations.html:289,Guid,Guides,289,docs/0.2/datasets/schemas/GTEx_sQTL_Liver_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Liver_all_snp_gene_associations.html,2,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_s,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Lung_all_snp_gene_associations.html:288,Guid,Guides,288,docs/0.2/datasets/schemas/GTEx_sQTL_Lung_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Lung_all_snp_gene_associations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_ge,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_all_ancestries.html:283,Guid,Guides,283,docs/0.2/datasets/schemas/panukb_meta_analysis_all_ancestries.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_all_ancestries.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_high_quality.html:281,Guid,Guides,281,docs/0.2/datasets/schemas/panukb_meta_analysis_high_quality.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_high_quality.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_both_sexes.html:280,Guid,Guides,280,docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_both_sexes.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_both_sexes.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_ass,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AFR.html:277,Guid,Guides,277,docs/0.2/datasets/schemas/panukb_ld_variant_indices_AFR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AFR.html,6,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_asso,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_female.html:276,Guid,Guides,276,docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_female.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_female.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_assoc,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_annotations.html:275,Guid,Guides,275,docs/0.2/datasets/schemas/ldsc_baselineLD_annotations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_annotations.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associ,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_male.html:274,Guid,Guides,274,docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_male.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_male.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associat,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_ldscores.html:272,Guid,Guides,272,docs/0.2/datasets/schemas/ldsc_baselineLD_ldscores.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_ldscores.html,1,['Guid'],['Guides']
Usability, Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associations,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AFR.html:268,Guid,Guides,268,docs/0.2/datasets/schemas/panukb_ld_scores_AFR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AFR.html,7,['Guid'],['Guides']
Usability," MXL| AMR| false| false| 8| true|; |NA19102| YRI| AFR| true| false| 6| false|; |HG00141| GBR| EUR| false| false| 6| false|; |HG01890| ACB| AFR| false| false| 8| false|; |HG00263| GBR| EUR| true| true| 6| false|; +-------+----------+---------------+--------+----------+-------------------+-----------+; only showing top 5 rows. Aggregables¶; We’ve now seen how it’s possible to use the Hail expression language to; manipulate various things like numbers and arrays. We can compute the; mean of an array of numbers with .mean(), find their max with; .max(), and so on.; But what if we wanted to compute the mean of 5 trillion numbers?; That’s a lot of data, and turns out to be the rough number of genotypes; in the preprocessed gnomAD VCF,; which contained about 20 thousand samples and 250 million variants. Hail; is designed to handle datasets of this size and larger, and does so by; computing in parallel on many computers using Apache; Spark.; But we still want a simple programming model that allows us to query and; transform such distributed data. That is where the Aggregable comes; in. First, an example:. In [24]:. vds.query_genotypes('gs.map(g => g.gq).stats()').mean. Out[24]:. 30.682263230349086. The above statement computes the mean GQ of all genotypes in a dataset.; This code can compute the mean GQ of a megabyte-scale thousand genomes; subset on a laptop, or compute the mean GQ of a 300 TB .vcf on a massive; cloud cluster. Hail is scalable!; An Aggregable[T] is distributed collection of elements of type; T. The interface is modeled on Array[T], but aggregables can be; arbitrarily large and they are unordered, so they don’t support; operations like indexing.; Aggregables support map and filter. Like sum, max, etc. on arrays,; aggregables support operations which we call “aggregators” that operate; on the entire aggregable collection and produce a summary or derived; statistic. See the; documentation for a; complete list of aggregators.; Aggregables are available in expr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/expression-language-part-2.html:10455,simpl,simple,10455,docs/0.1/tutorials/expression-language-part-2.html,https://hail.is,https://hail.is/docs/0.1/tutorials/expression-language-part-2.html,1,['simpl'],['simple']
Usability," True) -> 'MatrixTable':; """"""Change the number of partitions. Examples; --------. Repartition to 500 partitions:. >>> dataset_result = dataset.repartition(500). Notes; -----. Check the current number of partitions with :meth:`.n_partitions`. The data in a dataset is divided into chunks called partitions, which; may be stored together or across a network, so that each partition may; be read and processed in parallel by available cores. When a matrix with; :math:`M` rows is first imported, each of the :math:`k` partitions will; contain about :math:`M/k` of the rows. Since each partition has some; computational overhead, decreasing the number of partitions can improve; performance after significant filtering. Since it's recommended to have; at least 2 - 4 partitions per core, increasing the number of partitions; can allow one to take advantage of more cores. Partitions are a core; concept of distributed computation in Spark, see `their documentation; <http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds>`__; for details. When ``shuffle=True``, Hail does a full shuffle of the data; and creates equal sized partitions. When ``shuffle=False``,; Hail combines existing partitions to avoid a full; shuffle. These algorithms correspond to the `repartition` and; `coalesce` commands in Spark, respectively. In particular,; when ``shuffle=False``, ``n_partitions`` cannot exceed current; number of partitions. Parameters; ----------; n_partitions : int; Desired number of partitions.; shuffle : bool; If ``True``, use full shuffle to repartition. Returns; -------; :class:`.MatrixTable`; Repartitioned dataset.; """"""; if hl.current_backend().requires_lowering:; tmp = hl.utils.new_temp_file(). if len(self.row_key) == 0:; uid = Env.get_uid(); tmp2 = hl.utils.new_temp_file(); self.checkpoint(tmp2); ht = hl.read_matrix_table(tmp2).add_row_index(uid).key_rows_by(uid); ht.checkpoint(tmp); return hl.read_matrix_table(tmp, _n_partitions=n_partitions).drop",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:107994,guid,guide,107994,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,['guid'],['guide']
Usability," ``True``, use full shuffle to repartition. Returns; -------; :class:`.Table`; Repartitioned table.; """"""; if hl.current_backend().requires_lowering:; tmp = hl.utils.new_temp_file(). if len(self.key) == 0:; uid = Env.get_uid(); tmp2 = hl.utils.new_temp_file(); self.checkpoint(tmp2); ht = hl.read_table(tmp2).add_index(uid).key_by(uid); ht.checkpoint(tmp); return hl.read_table(tmp, _n_partitions=n).key_by().drop(uid); else:; # checkpoint rather than write to use fast codec; self.checkpoint(tmp); return hl.read_table(tmp, _n_partitions=n). return Table(; ir.TableRepartition(; self._tir, n, ir.RepartitionStrategy.SHUFFLE if shuffle else ir.RepartitionStrategy.COALESCE; ); ). [docs] @typecheck_method(max_partitions=int); def naive_coalesce(self, max_partitions: int) -> 'Table':; """"""Naively decrease the number of partitions. Example; -------; Naively repartition to 10 partitions:. >>> table_result = table1.naive_coalesce(10). Warning; -------; :meth:`.naive_coalesce` simply combines adjacent partitions to achieve; the desired number. It does not attempt to rebalance, unlike; :meth:`.repartition`, so it can produce a heavily unbalanced dataset. An; unbalanced dataset can be inefficient to operate on because the work is; not evenly distributed across partitions. Parameters; ----------; max_partitions : int; Desired number of partitions. If the current number of partitions is; less than or equal to `max_partitions`, do nothing. Returns; -------; :class:`.Table`; Table with at most `max_partitions` partitions.; """"""; return Table(ir.TableRepartition(self._tir, max_partitions, ir.RepartitionStrategy.NAIVE_COALESCE)). [docs] @typecheck_method(other=table_type); def semi_join(self, other: 'Table') -> 'Table':; """"""Filters the table to rows whose key appears in `other`. Parameters; ----------; other : :class:`.Table`; Table with compatible key field(s). Returns; -------; :class:`.Table`. Notes; -----; The key type of the table must match the key type of `other`. This method does not ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:94537,simpl,simply,94537,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['simpl'],['simply']
Usability," `sum_x` are of type; ``array<float64>``, and the last five fields are of type; ``array<array<float64>>``. Index into these arrays with; ``a[index_in_outer_list, index_in_inner_list]``. For example, if; ``y=[[a], [b, c]]`` then the p-value for ``b`` is ``p_value[1][0]``. In the statistical genetics example above, the input variable `x` encodes; genotype as the number of alternate alleles (0, 1, or 2). For each variant; (row), genotype is tested for association with height controlling for age; and sex, by fitting the linear regression model:. .. math::. \mathrm{height} = \beta_0 + \beta_1 \, \mathrm{genotype}; + \beta_2 \, \mathrm{age}; + \beta_3 \, \mathrm{is\_female}; + \varepsilon,; \quad; \varepsilon \sim \mathrm{N}(0, \sigma^2). Boolean covariates like :math:`\mathrm{is\_female}` are encoded as 1 for; ``True`` and 0 for ``False``. The null model sets :math:`\beta_1 = 0`. The standard least-squares linear regression model is derived in Section; 3.2 of `The Elements of Statistical Learning, 2nd Edition; <http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf>`__.; See equation 3.12 for the t-statistic which follows the t-distribution with; :math:`n - k - 1` degrees of freedom, under the null hypothesis of no; effect, with :math:`n` samples and :math:`k` covariates in addition to; ``x``. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions.; block_size : :obj:`int`; Number of row regressions to perform simultaneously per core. Larger blocks; require more m",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:11185,Learn,Learning,11185,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,1,['Learn'],['Learning']
Usability," bug; in hail.ggplot where all legend entries would have the same text; if one column had exactly one value for all rows and was mapped to; either the shape or the color aesthetic for geom_point. Version 0.2.114; Released 2023-04-19. New Features. (#12880) Added; hl.vds.store_ref_block_max_len to patch old VDSes to make; interval filtering faster. Bug Fixes. (#12860) Fixed; memory leak in shuffles in Query-on-Batch. Version 0.2.113; Released 2023-04-07. New Features. (#12798); Query-on-Batch now supports; BlockMatrix.write(..., stage_locally=True).; (#12793); Query-on-Batch now supports hl.poisson_regression_rows.; (#12801) Hitting; CTRL-C while interactively using Query-on-Batch cancels the; underlying batch.; (#12810); hl.array can now convert 1-d ndarrays into the equivalent list.; (#12851); hl.variant_qc no longer requires a locus field.; (#12816) In; Query-on-Batch, hl.logistic_regression('firth', ...) is now; supported.; (#12854) In; Query-on-Batch, simple pipelines with large numbers of partitions; should be substantially faster. Bug Fixes. (#12783) Fixed bug; where logs were not properly transmitted to Python.; (#12812) Fixed bug; where Table/MT._calculate_new_partitions returned unbalanced; intervals with whole-stage code generation runtime.; (#12839) Fixed; hailctl dataproc jupyter notebooks to be compatible with Spark; 3.3, which have been broken since 0.2.110.; (#12855) In; Query-on-Batch, allow writing to requester pays buckets, which was; broken before this release. Version 0.2.112; Released 2023-03-15. Bug Fixes. (#12784) Removed an; internal caching mechanism in Query on Batch that caused stalls in; pipelines with large intermediates. Version 0.2.111; Released 2023-03-13. New Features. (#12581) In Query on; Batch, users can specify which regions to have jobs run in. Bug Fixes. (#12772) Fix; hailctl hdinsight submit to pass args to the files. Version 0.2.110; Released 2023-03-08. New Features. (#12643) In Query on; Batch, hl.skat(..., logi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:36636,simpl,simple,36636,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['simpl'],['simple']
Usability," def __str__(self):; return ""stream<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other, tstream) and self.element_type == other.element_type. def _pretty(self, b, indent, increment):; b.append('stream<'); self.element_type._pretty(b, indent, increment); b.append('>'). def _parsable_string(self):; return ""Stream["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[list, frozenlist]:; ls = [self.element_type._convert_from_json_na(elt, _should_freeze) for elt in x]; if _should_freeze:; return frozenlist(ls); return ls. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tstream) and self.element_type.unify(t.element_type). def subst(self):; return tstream(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). def is_setlike(maybe_setlike):; return isinstance(maybe_setlike, (set, frozenset)). [docs]class tset(HailType):; """"""Hail type for collections of distinct elements. In Python, these are represented as :obj:`set`. Notes; -----; Sets contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of set. See Also; --------; :class:`.SetExpression`, :class:`.CollectionExpression`,; :func:`.set`, :ref:`sec-collection-functions`; """""". @typecheck_method(element_type=hail_type); def __init__(self, element_type):; self._element_type = element_type; self._array_repr = tarray(element_type); super(tset, self).__init__(). @property; def element_type(self):; """"""Set element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. def _traverse(self, obj, f):; if f(self, obj):; for elt in obj:; self.element_type._t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:22939,clear,clear,22939,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability," experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; Expressions. View page source. Expressions. eval(expression); Evaluate a Hail expression, returning the result. Expression; Base class for Hail expressions. ArrayExpression; Expression of type tarray. ArrayNumericExpression; Expression of type tarray with a numeric type. BooleanExpression; Expression of type tbool. CallExpression; Expression of type tcall. CollectionExpression; Expression of type tarray or tset. DictExpression; Expression of type tdict. IntervalExpression; Expression of type tinterval. LocusExpression; Expression of type tlocus. NumericExpression; Expression of numeric type. Int32Expression; Expression of type tint32. Int64Expression; Expression of type tint64. Float32Expression; Expression of type tfloat32. Float64Expression; Expression of type tfloat64. SetExpression; Expression of type tset. StringExpression; Expression of type tstr. StructExpression; Expression of type tstruct. TupleExpression; Expression of type ttuple. NDArrayExpression; Expression of type tndarray. NDArrayNumericExpression; Expression of type tndarray with a numeric element type. hail.expr.eval(expression)[source]; Evaluate a Hail expression, returning the result.; This method is extremely useful for learning about Hail expressions and; understanding how to compose them.; The expression must have no indices, but can refer to the globals; of a Table or MatrixTable.; Examples; Evaluate a conditional:; >>> x = 6; >>> hl.eval(hl.if_else(x % 2 == 0, 'Even', 'Odd')); 'Even'. Parameters:; expression (Expression) – Any expression, or a Python value that can be implicitly interpreted as an expression. Returns:; Any. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/expressions.html:1855,learn,learning,1855,docs/0.2/expressions.html,https://hail.is,https://hail.is/docs/0.2/expressions.html,1,['learn'],['learning']
Usability," interval_as_struct.end,; interval_as_struct.includes_start,; interval_as_struct.includes_end,; point_type=self.point_type,; ). def _convert_to_encoding(self, byte_writer, value):; interval_dict = {; 'start': value.start,; 'end': value.end,; 'includes_start': value.includes_start,; 'includes_end': value.includes_end,; }; self._struct_repr._convert_to_encoding(byte_writer, interval_dict). def unify(self, t):; return isinstance(t, tinterval) and self.point_type.unify(t.point_type). def subst(self):; return tinterval(self.point_type.subst()). def clear(self):; self.point_type.clear(). def _get_context(self):; return self.point_type.get_context(). class Box(object):; named_boxes: ClassVar = {}. @staticmethod; def from_name(name):; if name in Box.named_boxes:; return Box.named_boxes[name]; b = Box(); Box.named_boxes[name] = b; return b. def __init__(self):; pass. def unify(self, v):; if hasattr(self, 'value'):; return self.value == v; self.value = v; return True. def clear(self):; if hasattr(self, 'value'):; del self.value. def get(self):; assert hasattr(self, 'value'); return self.value. tvoid = _tvoid(). tint32 = _tint32(); """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int32Expression`, :func:`.int`, :func:`.int32`; """""". tint64 = _tint64(); """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int64Expression`, :func:`.int64`; """""". tint = tint32; """"""Alias for :py:data:`.tint32`."""""". tfloat32 = _tfloat32(); """"""Hail type for 32-bit floating point numbers. In Python, these are represented as :obj:`float`. See Also; --------; :class:`.Float32Expression`, :func:`.float64`; """""". tfloat64 = _tfloat64(); """"""Hail type for 64-bit floating point numbers. In Python, these are represente",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:51837,clear,clear,51837,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability," other.ndim. def _pretty(self, b, indent, increment):; b.append('ndarray<'); self._element_type._pretty(b, indent, increment); b.append(', '); b.append(str(self.ndim)); b.append('>'). def _parsable_string(self):; return f'NDArray[{self._element_type._parsable_string()},{self.ndim}]'. def _convert_from_json(self, x, _should_freeze: bool = False) -> np.ndarray:; if is_numeric(self._element_type):; np_type = self.element_type.to_numpy(); return np.ndarray(shape=x['shape'], buffer=np.array(x['data'], dtype=np_type), dtype=np_type); else:; raise TypeError(""Hail cannot currently return ndarrays of non-numeric or boolean type.""). def _convert_to_json(self, x):; data = x.flatten(""C"").tolist(). strides = []; axis_one_step_byte_size = x.itemsize; for dimension_size in x.shape:; strides.append(axis_one_step_byte_size); axis_one_step_byte_size *= dimension_size if dimension_size > 0 else 1. json_dict = {""shape"": x.shape, ""data"": data}; return json_dict. def clear(self):; self._element_type.clear(); self._ndim.clear(). def unify(self, t):; return isinstance(t, tndarray) and self._element_type.unify(t._element_type) and self._ndim.unify(t._ndim). def subst(self):; return tndarray(self._element_type.subst(), self._ndim.subst()). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> np.ndarray:; shape = [byte_reader.read_int64() for i in range(self.ndim)]; total_num_elements = np.product(shape, dtype=np.int64). if self.element_type in _numeric_types:; element_byte_size = self.element_type._byte_size; bytes_to_read = element_byte_size * total_num_elements; buffer = byte_reader.read_bytes_view(bytes_to_read); return np.frombuffer(buffer, self.element_type.to_numpy, count=total_num_elements).reshape(shape); else:; elements = [; self.element_type._convert_from_encoding(byte_reader, _should_freeze) for i in range(total_num_elements); ]; np_type = self.element_type.to_numpy(); return np.ndarray(shap",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:16831,clear,clear,16831,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability," stage in the evaluation process. Parameters; ----------; expression : :class:`.Expression`; Any expression, or a Python value that can be implicitly interpreted as an expression. Returns; -------; (Any, dict); Result of evaluating `expression` and a dictionary of the timings; """""". from hail.utils.java import Env. analyze('eval', expression, Indices(expression._indices.source)); if expression._indices.source is None:; ir_type = expression._ir.typ; expression_type = expression.dtype; if ir_type != expression.dtype:; raise ExpressionException(f'Expression type and IR type differed: \n{ir_type}\n vs \n{expression_type}'); ir = expression._ir; else:; uid = Env.get_uid(); ir = expression._indices.source.select_globals(**{uid: expression}).index_globals()[uid]._ir. return Env.backend().execute(MakeTuple([ir]), timed=True)[0]. [docs]@typecheck(expression=expr_any); def eval(expression):; """"""Evaluate a Hail expression, returning the result. This method is extremely useful for learning about Hail expressions and; understanding how to compose them. The expression must have no indices, but can refer to the globals; of a :class:`.Table` or :class:`.MatrixTable`. Examples; --------; Evaluate a conditional:. >>> x = 6; >>> hl.eval(hl.if_else(x % 2 == 0, 'Even', 'Odd')); 'Even'. Parameters; ----------; expression : :class:`.Expression`; Any expression, or a Python value that can be implicitly interpreted as an expression. Returns; -------; Any; """"""; return eval_timed(expression)[0]. @typecheck(expression=expr_any); def eval_typed(expression):; """"""Evaluate a Hail expression, returning the result and the type of the result. This method is extremely useful for learning about Hail expressions and understanding; how to compose them. The expression must have no indices, but can refer to the globals; of a :class:`.hail.Table` or :class:`.hail.MatrixTable`. Examples; --------; Evaluate a conditional:. >>> x = 6; >>> hl.eval_typed(hl.if_else(x % 2 == 0, 'Even', 'Odd')); ('Even', dtype('str",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html:5543,learn,learning,5543,docs/0.2/_modules/hail/expr/expressions/expression_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html,2,['learn'],['learning']
Usability," that can be attached to a variant annotation field. The following attributes are read from the VCF header when importing a VCF and written; to the VCF header when exporting a VCF:. - INFO fields attributes (attached to (`va.info.*`)):. - 'Number': The arity of the field. Can take values. - `0` (Boolean flag),; - `1` (single value),; - `R` (one value per allele, including the reference),; - `A` (one value per non-reference allele),; - `G` (one value per genotype), and; - `.` (any number of values). - When importing: The value in read from the VCF INFO field definition; - When exporting: The default value is `0` for **Boolean**, `.` for **Arrays** and 1 for all other types. - 'Description' (default is ''). - FILTER entries in the VCF header are generated based on the attributes; of `va.filters`. Each key/value pair in the attributes will generate; a FILTER entry in the VCF with ID = key and Description = value. **Examples**. Consider the following command which adds a filter and an annotation to the VDS (we're assuming a split VDS for simplicity):. 1) an INFO field `AC_HC`, which stores the allele count of high; confidence genotypes (DP >= 10, GQ >= 20) for each non-reference allele,. 2) a filter `HardFilter` that filters all sites with the `GATK suggested hard filters <http://gatkforums.broadinstitute.org/gatk/discussion/2806/howto-apply-hard-filters-to-a-call-set>`__:. - For SNVs: QD < 2.0 || FS < 60 || MQ < 40 || MQRankSum < -12.5 || ReadPosRankSum < -8.0. - For Indels (and other complex): QD < 2.0 || FS < 200.0 || ReadPosRankSum < 20.0. >>> annotated_vds = vds.annotate_variants_expr([; ... 'va.info.AC_HC = gs.filter(g => g.dp >= 10 && g.gq >= 20).callStats(g => v).AC[1:]',; ... 'va.filters = if((v.altAllele.isSNP && (va.info.QD < 2.0 || va.info.FS < 60 || va.info.MQ < 40 || ' +; ... 'va.info.MQRankSum < -12.5 || va.info.ReadPosRankSum < -8.0)) || ' +; ... '(va.info.QD < 2.0 || va.info.FS < 200.0 || va.info.ReadPosRankSum < 20.0)) va.filters.add(""HardFilter"") else",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:204222,simpl,simplicity,204222,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simplicity']
Usability," with mean \(p_i\) and variance; \(\sigma^2_i = p_i(1 - p_i)\), the binomial variance.; \(G W G^T\), is a symmetric positive-definite matrix when the weights are non-negative. We describe below our interpretation of the mathematics as described in the main body and; appendix of Wu, et al. According to the paper, the distribution of \(Q\) is given by a; generalized chi-squared distribution whose weights are the eigenvalues of a symmetric matrix; which we call \(Z Z^T\):. \[\begin{align*}; V_{ii} &= \sigma^2_i \\; W_{ii} &= w_i \quad\quad \textrm{the weight for variant } i \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2}; \end{align*}\]; The eigenvalues of \(Z Z^T\) and \(Z^T Z\) are the squared singular values of \(Z\);; therefore, we instead focus on \(Z^T Z\). In the expressions below, we elide transpositions; of symmetric matrices:. \[\begin{align*}; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2} \\; Z &= P_0^{1/2} G W^{1/2} \\; Z^T Z &= W^{1/2} G^T P_0 G W^{1/2}; \end{align*}\]; Before substituting the definition of \(P_0\), simplify it using the reduced QR; decomposition:. \[\begin{align*}; Q R &= V^{1/2} X \\; R^T Q^T &= X^T V^{1/2} \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; &= V - V X (R^T Q^T Q R)^{-1} X^T V \\; &= V - V X (R^T R)^{-1} X^T V \\; &= V - V X R^{-1} (R^T)^{-1} X^T V \\; &= V - V^{1/2} Q (R^T)^{-1} X^T V^{1/2} \\; &= V - V^{1/2} Q Q^T V^{1/2} \\; &= V^{1/2} (I - Q Q^T) V^{1/2} \\; \end{align*}\]; Substitute this simplified expression into \(Z\):. \[\begin{align*}; Z^T Z &= W^{1/2} G^T V^{1/2} (I - Q Q^T) V^{1/2} G W^{1/2} \\; \end{align*}\]; Split this symmetric matrix by observing that \(I - Q Q^T\) is idempotent:. \[\begin{align*}; I - Q Q^T &= (I - Q Q^T)(I - Q Q^T)^T \\; \\; Z &= (I - Q Q^T) V^{1/2} G W^{1/2} \\; Z &= (G - Q Q^T G) V^{1/2} W^{1/2}; \end{align*}\]; Finally, the squared singular values of \(Z\) are the eigenvalues of \(Z^T Z\), so; \(Q\) should be distributed as follows:. \[\begin{align*}; U S V^T ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:70507,simpl,simplify,70507,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['simpl'],['simplify']
Usability," zeros. Returns; -------; :class:`.BlockMatrix`; """"""; return BlockMatrix(BlockMatrixDensify(self._bmir)). [docs] def cache(self):; """"""Persist this block matrix in memory. Notes; -----; This method is an alias for :meth:`persist(""MEMORY_ONLY"") <hail.linalg.BlockMatrix.persist>`. Returns; -------; :class:`.BlockMatrix`; Cached block matrix.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK'):; """"""Persists this block matrix in memory or on disk. Notes; -----; The :meth:`.BlockMatrix.persist` and :meth:`.BlockMatrix.cache`; methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; :meth:`.BlockMatrix.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.BlockMatrix`; Persisted block matrix.; """"""; return Env.backend().persist_blockmatrix(self). [docs] def unpersist(self):; """"""Unpersists this block matrix from memory/disk. Notes; -----; This function will have no effect on a block matrix that was not previously; persisted. Returns; -------; :class:`.BlockMatrix`; Unpersisted block matrix.; """"""; return Env.backend().unpersist_blockmatrix(self). def __pos__(self):; return self. def __neg__(self):; """"""Negation: -a. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda x: construct_expr(ApplyUnaryPrimOp('-', x._ir), hl.tfloat64), needs_dense=False). ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:42713,guid,guide,42713,docs/0.2/_modules/hail/linalg/blockmatrix.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html,2,['guid'],['guide']
Usability,"(other, tunion) and self._cases == other._cases and all(self[c] == other[c] for c in self._cases); ). def _pretty(self, b, indent, increment):; if not self._cases:; b.append('union {}'); return. pre_indent = indent; indent += increment; b.append('union {'); for i, (f, t) in enumerate(self.items()):; if i > 0:; b.append(', '); b.append('\n'); b.append(' ' * indent); b.append('{}: '.format(escape_parsable(f))); t._pretty(b, indent, increment); b.append('\n'); b.append(' ' * pre_indent); b.append('}'). def _parsable_string(self):; return ""Union{{{}}}"".format(; ','.join('{}:{}'.format(escape_parsable(f), t._parsable_string()) for f, t in self.items()); ). def unify(self, t):; if not (isinstance(t, tunion) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tunion(**{f: t.subst() for f, t in self.items()}). def clear(self):; for f, t in self.items():; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.values()). [docs]class ttuple(HailType, Sequence):; """"""Hail type for tuples. In Python, these are represented as :obj:`tuple`. Parameters; ----------; types: varargs of :class:`.HailType`; Element types. See Also; --------; :class:`.TupleExpression`; """""". @typecheck_method(types=hail_type); def __init__(self, *types):; self._types = types; super(ttuple, self).__init__(). @property; def types(self):; """"""Tuple element types. Returns; -------; :obj:`tuple` of :class:`.HailType`; """"""; return self._types. def _traverse(self, obj, f):; if f(self, obj):; for t, elt in zip(self.types, obj):; t._traverse(elt, f). def _typecheck_one_level(self, annotation):; if annotation:; if not isinstance(annotation, tuple):; raise TypeError(""type 'tuple' expected Python tuple, but found '%s'"" % type(annotation)); if len(annotation) != len(self.types):; raise TypeError(""%s expected tuple of size '%i', but found '%s'"" % (self, len(self.types), an",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:38316,clear,clear,38316,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"(self, x):; return {; 'start': self.point_type._convert_to_json_na(x.start),; 'end': self.point_type._convert_to_json_na(x.end),; 'includeStart': x.includes_start,; 'includeEnd': x.includes_end,; }. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; interval_as_struct = self._struct_repr._convert_from_encoding(byte_reader, _should_freeze); return hl.Interval(; interval_as_struct.start,; interval_as_struct.end,; interval_as_struct.includes_start,; interval_as_struct.includes_end,; point_type=self.point_type,; ). def _convert_to_encoding(self, byte_writer, value):; interval_dict = {; 'start': value.start,; 'end': value.end,; 'includes_start': value.includes_start,; 'includes_end': value.includes_end,; }; self._struct_repr._convert_to_encoding(byte_writer, interval_dict). def unify(self, t):; return isinstance(t, tinterval) and self.point_type.unify(t.point_type). def subst(self):; return tinterval(self.point_type.subst()). def clear(self):; self.point_type.clear(). def _get_context(self):; return self.point_type.get_context(). class Box(object):; named_boxes: ClassVar = {}. @staticmethod; def from_name(name):; if name in Box.named_boxes:; return Box.named_boxes[name]; b = Box(); Box.named_boxes[name] = b; return b. def __init__(self):; pass. def unify(self, v):; if hasattr(self, 'value'):; return self.value == v; self.value = v; return True. def clear(self):; if hasattr(self, 'value'):; del self.value. def get(self):; assert hasattr(self, 'value'); return self.value. tvoid = _tvoid(). tint32 = _tint32(); """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int32Expression`, :func:`.int`, :func:`.int32`; """""". tint64 = _tint64(); """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`. S",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:51440,clear,clear,51440,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"):; if annotation is not None and not isinstance(annotation, bool):; raise TypeError(""type 'bool' expected Python 'bool', but found type '%s'"" % type(annotation)). def __str__(self):; return ""bool"". def _eq(self, other):; return isinstance(other, _tbool). def _parsable_string(self):; return ""Boolean"". def unify(self, t):; return t == tbool. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return bool. def _byte_size(self):; return 1. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> bool:; return byte_reader.read_bool(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_bool(value). class _trngstate(HailType):; def __init__(self):; super(_trngstate, self).__init__(). def __str__(self):; return ""rng_state"". def _eq(self, other):; return isinstance(other, _trngstate). def _parsable_string(self):; return ""RNGState"". def unify(self, t):; return t == trngstate. def subst(self):; return self. def clear(self):; pass. [docs]class tndarray(HailType):; """"""Hail type for n-dimensional arrays. .. include:: _templates/experimental.rst. In Python, these are represented as NumPy :obj:`numpy.ndarray`. Notes; -----. NDArrays contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of array.; ndim : int32; Number of dimensions. See Also; --------; :class:`.NDArrayExpression`, :obj:`.nd.array`; """""". @typecheck_method(element_type=hail_type, ndim=oneof(NatBase, int)); def __init__(self, element_type, ndim):; self._element_type = element_type; self._ndim = NatLiteral(ndim) if isinstance(ndim, int) else ndim; super(tndarray, self).__init__(). @property; def element_type(self):; """"""NDArray element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. @property; def ndim(self):; """"""NDArray number of dimensions. Returns; -------; :obj:`int`; Number of dimensions.; """"""; assert ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:14147,clear,clear,14147,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"); new_field_types.update(new_fields); return tstruct(**new_field_types). def _drop_fields(self, fields):; return tstruct(**{f: t for f, t in self.items() if f not in fields}). def _select_fields(self, fields):; return tstruct(**{f: self[f] for f in fields}). def _index_path(self, path):; t = self; for p in path:; t = t[p]; return t. def _rename(self, map):; seen = {}; new_field_types = {}. for f0, t in self.items():; f = map.get(f0, f0); if f in seen:; raise ValueError(; ""Cannot rename two fields to the same name: attempted to rename {} and {} both to {}"".format(; repr(seen[f]), repr(f0), repr(f); ); ); else:; seen[f] = f0; new_field_types[f] = t. return tstruct(**new_field_types). def unify(self, t):; if not (isinstance(t, tstruct) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tstruct(**{f: t.subst() for f, t in self.items()}). def clear(self):; for f, t in self.items():; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.values()). class tunion(HailType, Mapping):; @typecheck_method(case_types=hail_type); def __init__(self, **case_types):; """"""Tagged union type. Values of type union represent one of several; heterogenous, named cases. Parameters; ----------; cases : keyword args of :class:`.HailType`; The union cases. """""". super(tunion, self).__init__(); self._case_types = case_types; self._cases = tuple(case_types). @property; def cases(self):; """"""Return union case names. Returns; -------; :obj:`tuple` of :class:`str`; Tuple of union case names; """"""; return self._cases. @typecheck_method(item=oneof(int, str)); def __getitem__(self, item):; if isinstance(item, int):; item = self._cases[item]; return self._case_types[item]. def __iter__(self):; return iter(self._case_types). def __len__(self):; return len(self._cases). def __str__(self):; return ""union{{{}}}"".format(', '.join('{}: {}'.format(escape_parsable",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:36223,clear,clear,36223,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"----------------+--------+----------------------------------------------------------+; | ``gqStDev`` | Double | Genotype quality standard deviation across all genotypes |; +---------------------------+--------+----------------------------------------------------------+. Missing values ``NA`` may result (for example, due to division by zero) and are handled properly in filtering and written as ""NA"" in export modules. The empirical standard deviation is computed with zero degrees of freedom. :param str root: Sample annotation root for the computed struct.; :param bool keep_star: Count star alleles as non-reference alleles; ; :return: Annotated variant dataset with new sample qc annotations.; :rtype: :class:`.VariantDataset`; """""". return VariantDataset(self.hc, self._jvdf.sampleQC(root, keep_star)). [docs] @handle_py4j; def storage_level(self):; """"""Returns the storage (persistence) level of the variant dataset. **Notes**. See the `Spark documentation <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__ for details on persistence levels. :rtype: str; """""". return self._jvds.storageLevel(). [docs] @handle_py4j; @requireTGenotype; def summarize(self):; """"""Returns a summary of useful information about the dataset.; ; .. include:: requireTGenotype.rst. ; **Examples**; ; >>> s = vds.summarize(); >>> print(s.contigs); >>> print('call rate is %.2f' % s.call_rate); >>> s.report(); ; The following information is contained in the summary:; ; - **samples** (*int*) - Number of samples.; - **variants** (*int*) - Number of variants.; - **call_rate** (*float*) - Fraction of all genotypes called.; - **contigs** (*list of str*) - List of all unique contigs found in the dataset.; - **multiallelics** (*int*) - Number of multiallelic variants.; - **snps** (*int*) - Number of SNP alternate alleles.; - **mnps** (*int*) - Number of MNP alternate alleles.; - **insertions** (*int*) - Number of insertion alternate alleles.; - **deletions** (*int*) - Number of deletions ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:201572,guid,guide,201572,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['guid'],['guide']
Usability,"---. >>> rrm = hl.realized_relationship_matrix(dataset.GT). Notes; -----; The realized relationship matrix (RRM) is defined as follows. Consider the; :math:`n \times m` matrix :math:`C` of raw genotypes, with rows indexed by; :math:`n` samples and columns indexed by the :math:`m` bialellic autosomal; variants; :math:`C_{ij}` is the number of alternate alleles of variant; :math:`j` carried by sample :math:`i`, which can be 0, 1, 2, or missing. For; each variant :math:`j`, the sample alternate allele frequency :math:`p_j` is; computed as half the mean of the non-missing entries of column :math:`j`.; Entries of :math:`M` are then mean-centered and variance-normalized as. .. math::. M_{ij} =; \frac{C_{ij}-2p_j}; {\sqrt{\frac{m}{n} \sum_{k=1}^n (C_{ij}-2p_j)^2}},. with :math:`M_{ij} = 0` for :math:`C_{ij}` missing (i.e. mean genotype; imputation). This scaling normalizes each variant column to have empirical; variance :math:`1/m`, which gives each sample row approximately unit total; variance (assuming linkage equilibrium) and yields the :math:`n \times n`; sample correlation or realized relationship matrix (RRM) :math:`K` as simply. .. math::. K = MM^T. Note that the only difference between the realized relationship matrix and; the genetic relatedness matrix (GRM) used in; :func:`.realized_relationship_matrix` is the variant (column) normalization:; where RRM uses empirical variance, GRM uses expected variance under; Hardy-Weinberg Equilibrium. This method drops variants with zero variance before computing kinship. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression on matrix table with columns corresponding; to samples. Returns; -------; :class:`.BlockMatrix`; Realized relationship matrix for all samples. Row and column indices; correspond to matrix table column index.; """"""; mt = matrix_table_source('realized_relationship_matrix/call_expr', call_expr); raise_unless_entry_indexed('realized_relationship_matrix/call_expr', call_expr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:129927,simpl,simply,129927,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['simpl'],['simply']
Usability,"-compatible location.; Examples; Specify a manual path:; >>> hl.copy_log('gs://my-bucket/analysis-10-jan19.log') ; INFO: copying log to 'gs://my-bucket/analysis-10-jan19.log'... Copy to a directory:; >>> hl.copy_log('gs://my-bucket/') ; INFO: copying log to 'gs://my-bucket/hail-20180924-2018-devel-46e5fad57524.log'... Notes; Since Hail cannot currently log directly to distributed file systems, this; function is provided as a utility for offloading logs from ephemeral nodes.; If path is a directory, then the log file will be copied using its; base name to the directory (e.g. /home/hail.log would be copied as; gs://my-bucket/hail.log if path is gs://my-bucket. Parameters:; path (str). hail.utils.range_table(n, n_partitions=None)[source]; Construct a table with the row index and no other fields.; Examples; >>> df = hl.utils.range_table(100). >>> df.count(); 100. Notes; The resulting table contains one field:. idx (tint32) - Row index (key). This method is meant for testing and learning, and is not optimized for; production performance. Parameters:. n (int) – Number of rows.; n_partitions (int, optional) – Number of partitions (uses Spark default parallelism if None). Returns:; Table. hail.utils.range_matrix_table(n_rows, n_cols, n_partitions=None)[source]; Construct a matrix table with row and column indices and no entry fields.; Examples; >>> range_ds = hl.utils.range_matrix_table(n_rows=100, n_cols=10). >>> range_ds.count_rows(); 100. >>> range_ds.count_cols(); 10. Notes; The resulting matrix table contains the following fields:. row_idx (tint32) - Row index (row key).; col_idx (tint32) - Column index (column key). It contains no entry fields.; This method is meant for testing and learning, and is not optimized for; production performance. Parameters:. n_rows (int) – Number of rows.; n_cols (int) – Number of columns.; n_partitions (int, optional) – Number of partitions (uses Spark default parallelism if None). Returns:; MatrixTable. hail.utils.get_1kg(output_dir, ov",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/utils/index.html:10012,learn,learning,10012,docs/0.2/utils/index.html,https://hail.is,https://hail.is/docs/0.2/utils/index.html,1,['learn'],['learning']
Usability,". rrm(force_block=False, force_gramian=False)[source]¶; Computes the Realized Relationship Matrix (RRM).; Examples; >>> kinship_matrix = vds.rrm(). Notes; The Realized Relationship Matrix is defined as follows. Consider the \(n \times m\) matrix \(C\) of raw genotypes, with rows indexed by \(n\) samples and; columns indexed by the \(m\) bialellic autosomal variants; \(C_{ij}\) is the number of alternate alleles of variant \(j\) carried by sample \(i\), which; can be 0, 1, 2, or missing. For each variant \(j\), the sample alternate allele frequency \(p_j\) is computed as half the mean of the non-missing entries of column; \(j\). Entries of \(M\) are then mean-centered and variance-normalized as. \[M_{ij} = \frac{C_{ij}-2p_j}{\sqrt{\frac{m}{n} \sum_{k=1}^n (C_{ij}-2p_j)^2}},\]; with \(M_{ij} = 0\) for \(C_{ij}\) missing (i.e. mean genotype imputation). This scaling normalizes each variant column to have empirical variance \(1/m\), which gives each sample row approximately unit total variance (assuming linkage equilibrium) and yields the \(n \times n\) sample correlation or realized relationship matrix (RRM) \(K\) as simply. \[K = MM^T\]; Note that the only difference between the Realized Relationship Matrix and the Genetic Relationship Matrix (GRM) used in grm() is the variant (column) normalization: where RRM uses empirical variance, GRM uses expected variance under Hardy-Weinberg Equilibrium. Parameters:; force_block (bool) – Force using Spark’s BlockMatrix to compute kinship (advanced).; force_gramian (bool) – Force using Spark’s RowMatrix.computeGramian to compute kinship (advanced). Returns:Realized Relationship Matrix for all samples. Return type:KinshipMatrix. same(other, tolerance=1e-06)[source]¶; True if the two variant datasets have the same variants, samples, genotypes, and annotation schemata and values.; Examples; This will return True:; >>> vds.same(vds). Notes; The tolerance parameter sets the tolerance for equality when comparing floating-point fields. ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:154547,simpl,simply,154547,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simply']
Usability,".; (#14062) Fix; (#14052) which; caused incorrect results for identity by descent in Query-on-Batch.; (#14122) Ensure that; stack traces are transmitted from workers to the driver to the; client.; (#14105) When a VCF; contains missing values in array fields, Hail now suggests using; array_elements_required=False. Deprecations. (#13987) Deprecate; default_reference parameter to hl.init, users should use; hl.default_reference with an argument to set new default; references usually shortly after hl.init. Version 0.2.126; Released 2023-10-30. Bug Fixes. (#13939) Fix a bug; introduced in 0.2.125 which could cause dict literals created in; python to be decoded incorrectly, causing runtime errors or,; potentially, incorrect results.; (#13751) Correct the; broadcasting of ndarrays containing at least one dimension of length; zero. This previously produced incorrect results. Version 0.2.125; Released 2023-10-26. New Features. (#13682); hl.export_vcf now clearly reports all Table or Matrix Table; fields which cannot be represented in a VCF.; (#13355) Improve the; Hail compiler to more reliably rewrite Table.filter and; MatrixTable.filter_rows to use hl.filter_intervals. Before; this change some queries required reading all partitions even though; only a small number of partitions match the filter.; (#13787) Improve; speed of reading hail format datasets from disk. Simple pipelines may; see as much as a halving in latency.; (#13849) Fix; (#13788), improving; the error message when hl.logistic_regression_rows is provided; row or entry annotations for the dependent variable.; (#13888); hl.default_reference can now be passed an argument to change the; default reference genome. Bug Fixes. (#13702) Fix; (#13699) and; (#13693). Since; 0.2.96, pipelines that combined random functions; (e.g. hl.rand_unif) with index(..., all_matches=True) could; fail with a ClassCastException.; (#13707) Fix; (#13633).; hl.maximum_independent_set now accepts strings as the names of; individuals. ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:20889,clear,clearly,20889,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['clear'],['clearly']
Usability,"0.1 (Deprecated). FORUM; CHAT; CODE; JOBS. Hail; . ; . 0.1; . Getting Started; Overview; Tutorials; Expression Language; Python API; Annotation Database; Database Query; Documentation; Important Notes; Multiallelic variants; VEP annotations; Gene-level annotations. Suggest additions or edits. Other Resources. Hail. Docs »; Annotation Database. View page source. Annotation Database¶; This database contains a curated collection of variant annotations in Hail-friendly format, for use in Hail analysis pipelines.; Currently, the annotate_variants_db() VDS method associated with this database works only if you are running Hail on the; Google Cloud Platform.; To incorporate these annotations in your own Hail analysis pipeline, select which annotations you would like to query from the; documentation below and then copy-and-paste the Hail code generated into your own analysis script.; For example, a simple Hail script to load a VCF into a VDS, annotate the VDS with CADD raw and PHRED scores using this database,; and inspect the schema could look something like this:; import hail; from pprint import pprint. hc = hail.HailContext(). vds = (; hc; .import_vcf('gs://annotationdb/test/sample.vcf'); .split_multi(); .annotate_variants_db([; 'va.cadd'; ]); ). pprint(vds.variant_schema). This code would return the following schema:; Struct{; rsid: String,; qual: Double,; filters: Set[String],; info: Struct{; ...; },; cadd: Struct{; RawScore: Double,; PHRED: Double; }; }. Database Query¶; Select annotations by clicking on the checkboxes in the documentation, and the appropriate Hail command will be generated; in the panel below.; Use the “Copy to clipboard” button to copy the generated Hail code, and paste the command into your; own Hail script. Database Query. Copy to clipboard. vds = ( hc .read('my.vds') .split_multi(); .annotate_variants_db([ ... ]); ). Documentation¶; These annotations have been collected from a variety of publications and their accompanying datasets (usually text f",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/annotationdb.html:982,simpl,simple,982,docs/0.1/annotationdb.html,https://hail.is,https://hail.is/docs/0.1/annotationdb.html,1,['simpl'],['simple']
Usability,"2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Genome-Wide Association Study (GWAS) Tutorial; Table Tutorial; Aggregation Tutorial; Filtering and Annotation Tutorial; Table Joins Tutorial; MatrixTable Tutorial; MatrixTable Anatomy; Importing and Reading; MatrixTable operations; Exercise: GQ vs DP. Plotting Tutorial; GGPlot Tutorial. Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Hail Tutorials; MatrixTable Tutorial. View page source. MatrixTable Tutorial; If you’ve gotten this far, you’re probably thinking:. “Can’t I do all of this in pandas or R?”; “What does this have to do with biology?”. The two crucial features that Hail adds are scalability and the domain-specific primitives needed to work easily with biological data. Fear not! You’ve learned most of the basic concepts of Hail and now are ready for the bit that makes it possible to represent and compute on genetic matrices: the MatrixTable.; In the last example of the Table Joins Tutorial, the ratings table had a compound key: movie_id and user_id. The ratings were secretly a movie-by-user matrix!; However, since this matrix is very sparse, it is reasonably represented in a so-called “coordinate form” Table, where each row of the table is an entry of the sparse matrix. For large and dense matrices (like sequencing data), the per-row overhead of coordinate reresentations is untenable. That’s why we built MatrixTable, a 2-dimensional generalization of Table. MatrixTable Anatomy; Recall that Table has two kinds of fields:. global fields; row fields. MatrixTable has four kinds of fields:. global fields; row fields; column fields; entry fields. Row fields are fields that are stored once per row. These can contain information about the rows, or summary data calculated per row.; Column fields are stored once per column. These can contain in",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/07-matrixtable.html:1074,learn,learned,1074,docs/0.2/tutorials/07-matrixtable.html,https://hail.is,https://hail.is/docs/0.2/tutorials/07-matrixtable.html,1,['learn'],['learned']
Usability,":; which_missing_bit = i % 8; if which_missing_bit == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; answer.append(None); else:; field_decoded = t._convert_from_encoding(byte_reader, _should_freeze); answer.append(field_decoded). return tuple(answer). def _convert_to_encoding(self, byte_writer, value):; length = len(self); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8; for i, t in enumerate(self.types):; if not HailType._missing(value[i]):; t._convert_to_encoding(byte_writer, value[i]). def unify(self, t):; if not (isinstance(t, ttuple) and len(self.types) == len(t.types)):; return False; for t1, t2 in zip(self.types, t.types):; if not t1.unify(t2):; return False; return True. def subst(self):; return ttuple(*[t.subst() for t in self.types]). def clear(self):; for t in self.types:; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.types). def allele_pair(j: int, k: int):; assert j >= 0 and j <= 0xFFFF; assert k >= 0 and k <= 0xFFFF; return j | (k << 16). def allele_pair_sqrt(i):; k = int(math.sqrt(8 * float(i) + 1) / 2 - 0.5); assert k * (k + 1) // 2 <= i; j = i - k * (k + 1) // 2; # TODO another assert; return allele_pair(j, k). small_allele_pair = [; allele_pair(0, 0),; allele_pair(0, 1),; allele_pair(1, 1),; allele_pair(0, 2),; allele_pair(1, 2),; allele_pair(2, 2),; allele_pair(0, 3),; allele_pair(1, 3),; allele_pair(2, 3),; allele_pair(3, 3),; allele_pair(0, 4),; allele_pair(1, 4),; allele_pair(2, 4),; allele_pair(3, 4),; allele_pair(4, 4),; allele_pair(0, 5),; allele_pair(1, 5),; allele_pair(2, 5),; allele_pair(3, 5),; allele_pair(4, 5),; allele_pair(5, 5),; allele_pair(0, 6),; allele_pair(1, 6),; allele_pair(2, 6),; allele_pair(3, 6),; allele_pair(4, 6),; allele_pair(5, 6),; allele_pair(6, 6),; allele_pair(0, 7),; allele_pair(1, 7),; allele_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:41754,clear,clear,41754,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,":math:`C_{ij}` is the number of alternate alleles of variant :math:`j` carried by sample :math:`i`, which can be 0, 1, 2, or missing. For each variant :math:`j`, the sample alternate allele frequency :math:`p_j` is computed as half the mean of the non-missing entries of column :math:`j`. Entries of :math:`M` are then mean-centered and variance-normalized as. .. math::. M_{ij} = \\frac{C_{ij}-2p_j}{\sqrt{2p_j(1-p_j)m}},. with :math:`M_{ij} = 0` for :math:`C_{ij}` missing (i.e. mean genotype imputation). This scaling normalizes genotype variances to a common value :math:`1/m` for variants in Hardy-Weinberg equilibrium and is further motivated in the paper cited above. (The resulting amplification of signal from the low end of the allele frequency spectrum will also introduce noise for rare variants; common practice is to filter out variants with minor allele frequency below some cutoff.) The factor :math:`1/m` gives each sample row approximately unit total variance (assuming linkage equilibrium) and yields the sample correlation or genetic relationship matrix (GRM) as simply :math:`MM^T`. PCA then computes the SVD. .. math::. M = USV^T. where columns of :math:`U` are left singular vectors (orthonormal in :math:`\mathbb{R}^n`), columns of :math:`V` are right singular vectors (orthonormal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2, \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`. Typically one computes only the first :math:`k` singular vectors and values, yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are :math:`n \\times k`, :math:`k \\times k` and :math:`m \\times k` respectively. From the perspective of the samples or rows of :math:`M` as data, :math:`V_k` contains the variant loadings for the first :math:`k` PCs while :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each sample. The loadings represent a new basis ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:164241,simpl,simply,164241,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simply']
Usability,"; ----------------------------------------; Row fields:; 'id': int32; 'age': int32; 'sex': str; 'occupation': str; 'zipcode': str; ----------------------------------------; Key: ['id']; ----------------------------------------. key is a struct expression of all of the key fields, so we can refer to the key of a table without explicitly specifying the names of the key fields. [3]:. users.key.describe(). --------------------------------------------------------; Type:; struct {; id: int32; }; --------------------------------------------------------; Source:; <hail.table.Table object at 0x7f5beee034f0>; Index:; ['row']; --------------------------------------------------------. Keys need not be unique or non-missing, although in many applications they will be both.; When tables are joined in Hail, they are joined based on their keys. In order to join two tables, they must share the same number of keys, same key types (i.e. string vs integer), and the same order of keys.; Let’s look at a simple example of a join. We’ll use the Table.parallelize() method to create two small tables, t1 and t2. [4]:. t1 = hl.Table.parallelize([; {'a': 'foo', 'b': 1},; {'a': 'bar', 'b': 2},; {'a': 'bar', 'b': 2}],; hl.tstruct(a=hl.tstr, b=hl.tint32),; key='a'); t2 = hl.Table.parallelize([; {'t': 'foo', 'x': 3.14},; {'t': 'bar', 'x': 2.78},; {'t': 'bar', 'x': -1},; {'t': 'quam', 'x': 0}],; hl.tstruct(t=hl.tstr, x=hl.tfloat64),; key='t'). [5]:. t1.show(). SLF4J: Failed to load class ""org.slf4j.impl.StaticMDCBinder"".; SLF4J: Defaulting to no-operation MDCAdapter implementation.; SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details. abstrint32; ""bar""2; ""bar""2; ""foo""1. [6]:. t2.show(). txstrfloat64; ""bar""2.78e+00; ""bar""-1.00e+00; ""foo""3.14e+00; ""quam""0.00e+00. Now, we can join the tables. [7]:. j = t1.annotate(t2_x = t2[t1.a].x); j.show(). [Stage 3:==========================================> (12 + 4) / 16]. abt2_xstrint32float64; ""bar""22.78e+00; ""bar""22.78e+00; ""foo""1",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/06-joins.html:3498,simpl,simple,3498,docs/0.2/tutorials/06-joins.html,https://hail.is,https://hail.is/docs/0.2/tutorials/06-joins.html,1,['simpl'],['simple']
Usability,"; .aggregate(mean_gq = hl.agg.stats(entries.GQ).mean,; mean_dp = hl.agg.stats(entries.DP).mean)). [52]:. results2.show(). [Stage 193:> (0 + 1) / 1]. af_binpurple_hairmean_gqmean_dpstrboolfloat64float64; ""1%-5%""False2.48e+017.43e+00; ""1%-5%""True2.46e+017.47e+00; ""< 1%""False2.35e+017.55e+00; ""< 1%""True2.35e+017.53e+00; "">5%""False3.70e+017.65e+00; "">5%""True3.73e+017.70e+00. We’ve shown that it’s easy to aggregate by a couple of arbitrary statistics. This specific examples may not provide especially useful pieces of information, but this same pattern can be used to detect effects of rare variation:. Count the number of heterozygous genotypes per gene by functional category (synonymous, missense, or loss-of-function) to estimate per-gene functional constraint; Count the number of singleton loss-of-function mutations per gene in cases and controls to detect genes involved in disease. Epilogue; Congrats! You’ve reached the end of the first tutorial. To learn more about Hail’s API and functionality, take a look at the other tutorials. You can check out the Python API for documentation on additional Hail functions. If you use Hail for your own science, we’d love to hear from you on Zulip chat or the discussion forum.; For reference, here’s the full workflow to all tutorial endpoints combined into one cell. [53]:. table = hl.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample'). mt = hl.read_matrix_table('data/1kg.mt'); mt = mt.annotate_cols(pheno = table[mt.s]); mt = hl.sample_qc(mt); mt = mt.filter_cols((mt.sample_qc.dp_stats.mean >= 4) & (mt.sample_qc.call_rate >= 0.97)); ab = mt.AD[1] / hl.sum(mt.AD); filter_condition_ab = ((mt.GT.is_hom_ref() & (ab <= 0.1)) |; (mt.GT.is_het() & (ab >= 0.25) & (ab <= 0.75)) |; (mt.GT.is_hom_var() & (ab >= 0.9))); mt = mt.filter_entries(filter_condition_ab); mt = hl.variant_qc(mt); mt = mt.filter_rows(mt.variant_qc.AF[1] > 0.01). eigenvalues, pcs, _ = hl.hwe_normalized_pca(mt.GT). mt = mt.annotate_cols(scores = pcs[mt.s].",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html:25706,learn,learn,25706,docs/0.2/tutorials/01-genome-wide-association-study.html,https://hail.is,https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html,1,['learn'],['learn']
Usability,; Hail | panukb_ld_variant_indices_MID; Hail | panukb_meta_analysis_all_ancestries; Hail | panukb_meta_analysis_high_quality; Hail | panukb_summary_stats; Hail | UK_Biobank_Rapid_GWAS_both_sexes; Hail | UK_Biobank_Rapid_GWAS_female; Hail | UK_Biobank_Rapid_GWAS_male. Hail | Schemas. Hail | Datasets. /experimental; ; Hail | DB; Hail | Experimental; Hail | ldscsim. Hail | Expressions; Hail | hailtop.fs Python API. /functions; ; Hail | Collection functions; Hail | Constructor functions; Hail | Core language functions; Hail | Genetics functions; Hail | CaseBuilder; Hail | SwitchBuilder; Hail | Functions; Hail | Numeric functions; Hail | Random functions; Hail | Statistical functions; Hail | String functions. /genetics; ; Hail | AlleleType; Hail | Call; Hail | Locus; Hail | Pedigree; Hail | ReferenceGenome; Hail | Trio; Hail | genetics. Hail | Index; Hail | Installing Hail; Hail | For Software Developers. /ggplot; ; Hail | Plotting With hail.ggplot Overview. /guides; ; Hail | Aggregation; Hail | Annotation; Hail | Genetics. Hail | How-To Guides; Hail | Hadoop Glob Patterns; Hail | ArrayExpression; Hail | ArrayNumericExpression; Hail | BooleanExpression; Hail | CallExpression; Hail | CollectionExpression; Hail | DictExpression. Hail | Expression. Hail | Expression; Hail | Expression. Hail | Float32Expression; Hail | Float64Expression; Hail | Int32Expression; Hail | Int64Expression; Hail | IntervalExpression; Hail | LocusExpression; Hail | NDArrayExpression; Hail | NDArrayNumericExpression; Hail | NumericExpression; Hail | SetExpression; Hail | StringExpression; Hail | StructExpression; Hail | TupleExpression; Hail | GroupedMatrixTable; Hail | GroupedTable; Hail | MatrixTable; Hail | Table; Hail | Hail on the Cloud; Hail | Hail 0.2. /install; ; Hail | Use Hail on Azure HDInsight; Hail | Use Hail on Google Dataproc; Hail | Install Hail on GNU/Linux; Hail | Install Hail on Mac OS X; Hail | Install Hail on a Spark Cluster; Hail | Your First Hail Query. Hail | Libraries. /linal,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/index-wcopy.html:32603,guid,guides,32603,index-wcopy.html,https://hail.is,https://hail.is/index-wcopy.html,1,['guid'],['guides']
Usability,"; prior is the maximum of the `pop_frequency_prior` and ``1 / 3e7``.; - `proband` (``struct``) -- Proband column fields from `mt`.; - `father` (``struct``) -- Father column fields from `mt`.; - `mother` (``struct``) -- Mother column fields from `mt`.; - `proband_entry` (``struct``) -- Proband entry fields from `mt`.; - `father_entry` (``struct``) -- Father entry fields from `mt`.; - `proband_entry` (``struct``) -- Mother entry fields from `mt`.; - `is_female` (``bool``) -- ``True`` if proband is female.; - `p_de_novo` (``float64``) -- Unfiltered posterior probability; that the event is *de novo* rather than a missed heterozygous; event in a parent.; - `confidence` (``str``) Validation confidence. One of: ``'HIGH'``,; ``'MEDIUM'``, ``'LOW'``. The key of the table is ``['locus', 'alleles', 'id']``. The model looks for de novo events in which both parents are homozygous; reference and the proband is a heterozygous. The model makes the simplifying; assumption that when this configuration ``x = (AA, AA, AB)`` of calls; occurs, exactly one of the following is true:. - ``d``: a de novo mutation occurred in the proband and all calls are; accurate.; - ``m``: at least one parental allele is actually heterozygous and; the proband call is accurate. We can then estimate the posterior probability of a de novo mutation as:. .. math::. \mathrm{P_{\text{de novo}}} = \frac{\mathrm{P}(d \mid x)}{\mathrm{P}(d \mid x) + \mathrm{P}(m \mid x)}. Applying Bayes rule to the numerator and denominator yields. .. math::. \frac{\mathrm{P}(x \mid d)\,\mathrm{P}(d)}{\mathrm{P}(x \mid d)\,\mathrm{P}(d) +; \mathrm{P}(x \mid m)\,\mathrm{P}(m)}. The prior on de novo mutation is estimated from the rate in the literature:. .. math::. \mathrm{P}(d) = \frac{1 \, \text{mutation}}{30{,}000{,}000 \, \text{bases}}. The prior used for at least one alternate allele between the parents; depends on the alternate allele frequency:. .. math::. \mathrm{P}(m) = 1 - (1 - AF)^4. The likelihoods :math:`\mathrm{P}(x \mid ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:22347,simpl,simplifying,22347,docs/0.2/_modules/hail/methods/family_methods.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html,2,['simpl'],['simplifying']
Usability,"; rep = allele_repr(i); return gt_allele_pair(rep). if ploidy == 0:; alleles = []; elif ploidy == 1:; alleles = [allele_repr(int_rep)]; elif ploidy == 2:; p = call_allele_pair(int_rep); alleles = [ap_j(p), ap_k(p)]; else:; raise ValueError(""Unsupported Ploidy""). return genetics.Call(alleles, phased). def _convert_to_encoding(self, byte_writer, value: genetics.Call):; int_rep = 0. int_rep |= value.ploidy << 1; if value.phased:; int_rep |= 1. def diploid_gt_index(j: int, k: int):; assert j <= k; return k * (k + 1) // 2 + j. def allele_pair_rep(c: genetics.Call):; [j, k] = c.alleles; if c.phased:; return diploid_gt_index(j, j + k); return diploid_gt_index(j, k). assert value.ploidy <= 2; if value.ploidy == 1:; int_rep |= value.alleles[0] << 3; elif value.ploidy == 2:; int_rep |= allele_pair_rep(value) << 3; int_rep = int_rep if 0 <= int_rep < 2**31 - 1 else int_rep - 2**32. byte_writer.write_int32(int_rep). def unify(self, t):; return t == tcall. def subst(self):; return self. def clear(self):; pass. [docs]class tlocus(HailType):; """"""Hail type for a genomic coordinate with a contig and a position. In Python, these are represented by :class:`.Locus`. Parameters; ----------; reference_genome: :class:`.ReferenceGenome` or :class:`str`; Reference genome to use. See Also; --------; :class:`.LocusExpression`, :func:`.locus`, :func:`.parse_locus`,; :class:`.Locus`; """""". struct_repr = tstruct(contig=_tstr(), pos=_tint32()). @classmethod; @typecheck_method(reference_genome=nullable(reference_genome_type)); def _schema_from_rg(cls, reference_genome='default'):; # must match TLocus.schemaFromRG; if reference_genome is None:; return hl.tstruct(contig=hl.tstr, position=hl.tint32); return cls(reference_genome). @typecheck_method(reference_genome=reference_genome_type); def __init__(self, reference_genome='default'):; self._rg = reference_genome; super(tlocus, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not isinstance(annotation, gene",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:45551,clear,clear,45551,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"; return False; return True. @property; def finished(self) -> bool:; """"""Have all GVCFs and input Variant Datasets been combined?""""""; return not self._gvcfs and not self._vdses. [docs] def save(self):; """"""Save a :class:`.VariantDatasetCombiner` to its `save_path`.""""""; fs = hl.current_backend().fs; try:; backup_path = self._save_path + '.bak'; if fs.exists(self._save_path):; fs.copy(self._save_path, backup_path); with fs.open(self._save_path, 'w') as out:; json.dump(self, out, indent=2, cls=Encoder); if fs.exists(backup_path):; fs.remove(backup_path); except OSError as e:; # these messages get printed, because there is absolutely no guarantee; # that the hail context is in a sane state if any of the above operations; # fail; print(f'Failed saving {self.__class__.__name__} state at {self._save_path}'); print(f'An attempt was made to copy {self._save_path} to {backup_path}'); print('An old version of this state may be there.'); print(; 'Dumping current state as json to standard output, you may wish '; 'to save this output in order to resume the combiner.'; ); json.dump(self, sys.stdout, indent=2, cls=Encoder); print(); raise e. [docs] def run(self):; """"""Combine the specified GVCFs and Variant Datasets.""""""; flagname = 'no_ir_logging'; prev_flag_value = hl._get_flags(flagname).get(flagname); hl._set_flags(**{flagname: '1'}). vds_samples = sum(vds.n_samples for vdses in self._vdses.values() for vds in vdses); info(; 'Running VDS combiner:\n'; f' VDS arguments: {self._num_vdses} datasets with {vds_samples} samples\n'; f' GVCF arguments: {len(self._gvcfs)} inputs/samples\n'; f' Branch factor: {self._branch_factor}\n'; f' GVCF merge batch size: {self._gvcf_batch_size}'; ); while not self.finished:; self.save(); self.step(); self.save(); info('Finished VDS combiner!'); hl._set_flags(**{flagname: prev_flag_value}). [docs] @staticmethod; def load(path) -> 'VariantDatasetCombiner':; """"""Load a :class:`.VariantDatasetCombiner` from `path`.""""""; fs = hl.current_backend().fs; with fs.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html:12111,resume,resume,12111,docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,2,['resume'],['resume']
Usability,"=====================================================================+; | ``va.lmmreg.beta`` | Double | fit genotype coefficient, :math:`\hat\\beta_0` |; +------------------------+--------+-------------------------------------------------------------------------+; | ``va.lmmreg.sigmaG2`` | Double | fit coefficient of genetic variance component, :math:`\hat{\sigma}_g^2` |; +------------------------+--------+-------------------------------------------------------------------------+; | ``va.lmmreg.chi2`` | Double | :math:`\chi^2` statistic of the likelihood ratio test |; +------------------------+--------+-------------------------------------------------------------------------+; | ``va.lmmreg.pval`` | Double | :math:`p`-value |; +------------------------+--------+-------------------------------------------------------------------------+. Those variants that don't vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations. The simplest way to export all resulting annotations is:. >>> lmm_vds.export_variants('output/lmmreg.tsv.bgz', 'variant = v, va.lmmreg.*'); >>> lmmreg_results = lmm_vds.globals['lmmreg']; ; By default, genotypes values are given by hard call genotypes (``g.gt``).; If ``use_dosages=True``, then genotype values for per-variant association are defined by the dosage; :math:`\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})`. For Phred-scaled values,; :math:`\mathrm{P}(\mathrm{Het})` and :math:`\mathrm{P}(\mathrm{HomVar})` are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1. **Performance**. Hail's initial version of :py:meth:`.lmmreg` scales beyond 15k samples and to an essentially unbounded number of variants, making it particularly well-suited to modern sequencing studies and complementary to tools designed for SNP arrays. Analysts have used :py:meth:`.lmmreg` in research to compute kinship from 100k common variants and test 32 million non-rare variants on 8k ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:123675,simpl,simplest,123675,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simplest']
Usability,"> Union[dict, frozendict]:; # NB: We ensure the key is always frozen with a wrapper on the key_type in the _array_repr.; d = {}; length = byte_reader.read_int32(); for _ in range(length):; element = self._array_repr.element_type._convert_from_encoding(byte_reader, _should_freeze); d[element.key] = element.value. if _should_freeze:; return frozendict(d); return d. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); for k, v in value.items():; self._array_repr.element_type._convert_to_encoding(byte_writer, {'key': k, 'value': v}). def _propagate_jtypes(self, jtype):; self._key_type._add_jtype(jtype.keyType()); self._value_type._add_jtype(jtype.valueType()). def unify(self, t):; return isinstance(t, tdict) and self.key_type.unify(t.key_type) and self.value_type.unify(t.value_type). def subst(self):; return tdict(self._key_type.subst(), self._value_type.subst()). def clear(self):; self.key_type.clear(); self.value_type.clear(). def _get_context(self):; return HailTypeContext.union(self.key_type, self.value_type). [docs]class tstruct(HailType, Mapping):; """"""Hail type for structured groups of heterogeneous fields. In Python, these are represented as :class:`.Struct`. Hail's :class:`.tstruct` type is commonly used to compose types together to form nested; structures. Structs can contain any combination of types, and are ordered mappings; from field name to field type. Each field name must be unique. Structs are very common in Hail. Each component of a :class:`.Table` and :class:`.MatrixTable`; is a struct:. - :meth:`.Table.row`; - :meth:`.Table.globals`; - :meth:`.MatrixTable.row`; - :meth:`.MatrixTable.col`; - :meth:`.MatrixTable.entry`; - :meth:`.MatrixTable.globals`. Structs appear below the top-level component types as well. Consider the following join:. >>> new_table = table1.annotate(table2_fields = table2.index(table1.key)). This snippet adds a field to ``table1`` called ``table2_fields``. In the new",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:29524,clear,clear,29524,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,AMR.rst.txt; panukb_ld_variant_indices_CSA.rst.txt; panukb_ld_variant_indices_EAS.rst.txt; panukb_ld_variant_indices_EUR.rst.txt; panukb_ld_variant_indices_MID.rst.txt; panukb_meta_analysis_all_ancestries.rst.txt; panukb_meta_analysis_high_quality.rst.txt; panukb_summary_stats.rst.txt; UK_Biobank_Rapid_GWAS_both_sexes.rst.txt; UK_Biobank_Rapid_GWAS_female.rst.txt; UK_Biobank_Rapid_GWAS_male.rst.txt. schemas.rst.txt. /experimental; ; hail.experimental.DB.rst.txt; index.rst.txt; ldscsim.rst.txt. /functions; ; collections.rst.txt; constructors.rst.txt; core.rst.txt; genetics.rst.txt; hail.expr.builders.CaseBuilder.rst.txt; hail.expr.builders.SwitchBuilder.rst.txt; index.rst.txt; numeric.rst.txt; random.rst.txt; stats.rst.txt; string.rst.txt. /genetics; ; hail.genetics.AlleleType.rst.txt; hail.genetics.Call.rst.txt; hail.genetics.Locus.rst.txt; hail.genetics.Pedigree.rst.txt; hail.genetics.ReferenceGenome.rst.txt; hail.genetics.Trio.rst.txt; index.rst.txt. /ggplot; ; index.rst.txt. /guides; ; agg.rst.txt; annotation.rst.txt; genetics.rst.txt. /install; ; azure.rst.txt; dataproc.rst.txt; linux.rst.txt; macosx.rst.txt; other-cluster.rst.txt; try.rst.txt. /linalg; . /utils; ; index.rst.txt. hail.linalg.BlockMatrix.rst.txt; index.rst.txt. /methods; ; genetics.rst.txt; impex.rst.txt; index.rst.txt; misc.rst.txt; relatedness.rst.txt; stats.rst.txt. /nd; ; index.rst.txt. /overview; ; expressions.rst.txt; index.rst.txt; matrix_table.rst.txt; table.rst.txt. /stats; ; hail.stats.LinearMixedModel.rst.txt; index.rst.txt. /tutorials; ; 01-genome-wide-association-study.ipynb.txt; 03-tables.ipynb.txt; 04-aggregation.ipynb.txt; 05-filter-annotate.ipynb.txt; 06-joins.ipynb.txt; 07-matrixtable.ipynb.txt; 08-plotting.ipynb.txt; 09-ggplot.ipynb.txt. /utils; ; index.rst.txt. /vds; ; hail.vds.combiner.load_combiner.rst.txt; hail.vds.combiner.new_combiner.rst.txt; hail.vds.combiner.VariantDatasetCombiner.rst.txt; hail.vds.combiner.VDSMetadata.rst.txt; hail.vds.filter_chromosomes.rst.txt; hail,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/index-wcopy.html:17724,guid,guides,17724,index-wcopy.html,https://hail.is,https://hail.is/index-wcopy.html,1,['guid'],['guides']
Usability,"Exclusive writable binary file (io.BufferedWriter).; Throws an error if a file already exists at the path. The provided destination file path must be a URI (uniform resource identifier). Caution; These file handles are slower than standard Python file handles. If you; are writing a large file (larger than ~50M), it will be faster to write; to a local file using standard Python I/O and use hadoop_copy(); to move your file to a distributed file system. Parameters:. path (str) – Path to file.; mode (str) – File access mode.; buffer_size (int) – Buffer size, in bytes. Returns:; Readable or writable file handle. hail.utils.hadoop_copy(src, dest)[source]; Copy a file through the Hadoop filesystem API.; Supports distributed file systems like hdfs, gs, and s3.; Examples; Copy a file from Google Cloud Storage to a local file:; >>> hadoop_copy('gs://hail-common/LCR.interval_list',; ... 'file:///mnt/data/LCR.interval_list') . Notes; Try using hadoop_open() first, it’s simpler, but not great; for large data! For example:; >>> with hadoop_open('gs://my_bucket/results.csv', 'r') as f: ; ... pandas_df.to_csv(f). The provided source and destination file paths must be URIs; (uniform resource identifiers). Parameters:. src (str) – Source file URI.; dest (str) – Destination file URI. hail.utils.hadoop_exists(path)[source]; Returns True if path exists. Parameters:; path (str). Returns:; bool. hail.utils.hadoop_is_file(path)[source]; Returns True if path both exists and is a file. Parameters:; path (str). Returns:; bool. hail.utils.hadoop_is_dir(path)[source]; Returns True if path both exists and is a directory. Parameters:; path (str). Returns:; bool. hail.utils.hadoop_stat(path)[source]; Returns information about the file or directory at a given path.; Notes; Raises an error if path does not exist.; The resulting dictionary contains the following data:. is_dir (bool) – Path is a directory.; size_bytes (int) – Size in bytes.; size (str) – Size as a readable string.; modification_ti",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/utils/index.html:6764,simpl,simpler,6764,docs/0.2/utils/index.html,https://hail.is,https://hail.is/docs/0.2/utils/index.html,1,['simpl'],['simpler']
Usability,"PUT_CHECK; +-------+-------+-----+-------+-------+-------+-------+-------+-------+; | ID | HT | SEX | X | Z | C1 | C2 | C3 | idx |; +-------+-------+-----+-------+-------+-------+-------+-------+-------+; | int32 | int32 | str | int32 | int32 | int32 | int32 | int32 | int64 |; +-------+-------+-----+-------+-------+-------+-------+-------+-------+; | 1 | 65 | M | 5 | 4 | 2 | 50 | 5 | 0 |; | 2 | 72 | M | 6 | 3 | 2 | 61 | 1 | 1 |; | 3 | 70 | F | 7 | 3 | 10 | 81 | -5 | 2 |; | 4 | 60 | F | 8 | 2 | 11 | 90 | -10 | 3 |; +-------+-------+-----+-------+-------+-------+-------+-------+-------+. Notes; -----. This method returns a table with a new field whose name is given by; the `name` parameter, with type :py:data:`.tint64`. The value of this field; is the integer index of each row, starting from 0. Methods that respect; ordering (like :meth:`.Table.take` or :meth:`.Table.export`) will; return rows in order. This method is also helpful for creating a unique integer index for; rows of a table so that more complex types can be encoded as a simple; number for performance reasons. Parameters; ----------; name : str; Name of index field. Returns; -------; :class:`.Table`; Table with a new index field.; """""". return self.annotate(**{name: hl.scan.count()}). [docs] @typecheck_method(tables=table_type, unify=bool); def union(self, *tables, unify: bool = False) -> 'Table':; """"""Union the rows of multiple tables. Examples; --------. Take the union of rows from two tables:. >>> union_table = table1.union(other_table). Notes; -----; If a row appears in more than one table identically, it is duplicated; in the result. All tables must have the same key names and types. They; must also have the same row types, unless the `unify` parameter is; ``True``, in which case a field appearing in any table will be included; in the result, with missing values for tables that do not contain the; field. If a field appears in multiple tables with incompatible types,; like arrays and strings, then an err",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:84704,simpl,simple,84704,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['simpl'],['simple']
Usability,"The arms of; the conditional must have the same type. The predicate must be of type; Boolean. If the predicate is missing, the value of the entire; conditional is missing. Here are some simple examples. In [24]:. hc.eval_expr_typed('if (true) 1 else 2'). Out[24]:. (1, Int). In [25]:. hc.eval_expr_typed('if (false) 1 else 2'). Out[25]:. (2, Int). In [26]:. hc.eval_expr_typed('if (NA: Boolean) 1 else 2'). Out[26]:. (None, Int). The if and else branches need to return the same type. The below; expression is invalid. In [27]:. # Uncomment and run the below code to see the error message. # hc.eval_expr_typed('if (true) 1 else ""two""'). Compound Types¶; Hail has several compound types: -; Array[T] -; Set[T] - Dict[K,; V] -; Aggregable[T] -; Struct; T, K and V here mean any type, including other compound; types. Hail’s Array[T] objects are similar to Python’s lists, except; they must be homogenous: that is, each element must be of the same type.; Arrays are 0-indexed. Here are some examples of simple array; expressions.; Array literals are constructed with square brackets. In [28]:. hc.eval_expr_typed('[1, 2, 3, 4, 5]'). Out[28]:. ([1, 2, 3, 4, 5], Array[Int]). Arrays are indexed with square brackets and support Python’s slice; syntax. In [29]:. hc.eval_expr_typed('let a = [1, 2, 3, 4, 5] in a[0]'). Out[29]:. (1, Int). In [30]:. hc.eval_expr_typed('let a = [1, 2, 3, 4, 5] in a[1:3]'). Out[30]:. ([2, 3], Array[Int]). In [31]:. hc.eval_expr_typed('let a = [1, 2, 3, 4, 5] in a[1:]'). Out[31]:. ([2, 3, 4, 5], Array[Int]). In [32]:. hc.eval_expr_typed('let a = [1, 2, 3, 4, 5] in a.length()'). Out[32]:. (5, Int). Arrays can be transformed with functional operators filter and; map. These operations return a new array, never modify the original. In [33]:. # keep the elements that are less than 10; hc.eval_expr_typed('let a = [1, 2, 22, 7, 10, 11] in a.filter(x => x < 10)'). Out[33]:. ([1, 2, 7], Array[Int]). In [34]:. # square the elements of an array; hc.eval_expr_typed('let a = [1",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/introduction-to-the-expression-language.html:7587,simpl,simple,7587,docs/0.1/tutorials/introduction-to-the-expression-language.html,https://hail.is,https://hail.is/docs/0.1/tutorials/introduction-to-the-expression-language.html,1,['simpl'],['simple']
Usability,"Then the result of; make_table():; >>> ht = mt.make_table() . has the original row fields along with 6 additional fields,; one for each sample and entry field:; Global fields:; 'batch': str; Row fields:; 'locus': locus<GRCh37>; 'alleles': array<str>; 'A.GT': call; 'A.GQ': int32; 'B.GT': call; 'B.GQ': int32; 'C.GT': call; 'C.GQ': int32; Key:; 'locus': locus<GRCh37>; 'alleles': array<str>. n_partitions()[source]; Number of partitions.; Notes; The data in a dataset is divided into chunks called partitions, which; may be stored together or across a network, so that each partition may; be read and processed in parallel by available cores. Partitions are a; core concept of distributed computation in Spark, see here; for details. Returns:; int – Number of partitions. naive_coalesce(max_partitions)[source]; Naively decrease the number of partitions.; Example; Naively repartition to 10 partitions:; >>> dataset_result = dataset.naive_coalesce(10). Warning; naive_coalesce() simply combines adjacent partitions to achieve; the desired number. It does not attempt to rebalance, unlike; repartition(), so it can produce a heavily unbalanced dataset. An; unbalanced dataset can be inefficient to operate on because the work is; not evenly distributed across partitions. Parameters:; max_partitions (int) – Desired number of partitions. If the current number of partitions is; less than or equal to max_partitions, do nothing. Returns:; MatrixTable – Matrix table with at most max_partitions partitions. persist(storage_level='MEMORY_AND_DISK')[source]; Persist this table in memory or on disk.; Examples; Persist the dataset to both memory and disk:; >>> dataset = dataset.persist() . Notes; The MatrixTable.persist() and MatrixTable.cache(); methods store the current dataset on disk or in memory temporarily to; avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for Table.write(),; which stores a permanent file.; Most users should use",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.MatrixTable.html:48966,simpl,simply,48966,docs/0.2/hail.MatrixTable.html,https://hail.is,https://hail.is/docs/0.2/hail.MatrixTable.html,1,['simpl'],['simply']
Usability,"True, delete temporary directories with intermediate files.; backend_kwargs (Any) – See Backend._run() for backend-specific arguments. Return type:; Optional[Batch]. select_jobs(pattern); Select all jobs in the batch whose name matches pattern.; Examples; Select jobs in batch matching qc:; >>> b = Batch(); >>> j = b.new_job(name='qc'); >>> qc_jobs = b.select_jobs('qc'); >>> assert qc_jobs == [j]. Parameters:; pattern (str) – Regex pattern matching job names. Return type:; List[Job]. write_output(resource, dest); Write resource file or resource file group to an output destination.; Examples; Write a single job intermediate to a local file:; >>> b = Batch(); >>> j = b.new_job(); >>> j.command(f'echo ""hello"" > {j.ofile}'); >>> b.write_output(j.ofile, 'output/hello.txt'); >>> b.run(). Write a single job intermediate to a permanent location in GCS:; b = Batch(); j = b.new_job(); j.command(f'echo ""hello"" > {j.ofile}'); b.write_output(j.ofile, 'gs://mybucket/output/hello.txt'); b.run(). Write a single job intermediate to a permanent location in Azure:; b = Batch(); j = b.new_job(); j.command(f'echo ""hello"" > {j.ofile}'); b.write_output(j.ofile, 'https://my-account.blob.core.windows.net/my-container/output/hello.txt'); b.run() # doctest: +SKIP. Warning; To avoid expensive egress charges, output files should be located in buckets; that are in the same region in which your Batch jobs run. Notes; All JobResourceFile are temporary files and must be written; to a permanent location using write_output() if the output needs; to be saved. Parameters:. resource (Resource) – Resource to be written to a file.; dest (str) – Destination file path. For a single ResourceFile, this will; simply be dest. For a ResourceGroup, dest is the file; root and each resource file will be written to {root}.identifier; where identifier is the identifier of the file in the; ResourceGroup map. Previous; Next . © Copyright 2024, Hail Team. Built with Sphinx using a; theme; provided by Read the Docs.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.batch.Batch.html:12380,simpl,simply,12380,docs/batch/api/batch/hailtop.batch.batch.Batch.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.batch.Batch.html,2,['simpl'],['simply']
Usability,"\(v = n \times 1\) vector of genotypes, with missing genotypes imputed as the mean of called genotypes; \(X_v = \left[v | X \right] = n \times (1 + c)\) matrix concatenating \(v\) and \(X\); \(\beta_v = (\beta^0_v, \beta^1_v, \ldots, \beta^c_v) = (1 + c) \times 1\) vector of covariate coefficients. Fixing \(\delta\) at the global REML estimate \(\hat{\delta}\), we find the REML estimate \((\hat{\beta}_v, \hat{\sigma}_{g,v}^2)\) via rotation of the model. \[y \sim \mathrm{N}\left(X_v\beta_v, \sigma_{g,v}^2 (K + \hat{\delta} I)\right)\]; Note that the only new rotation to compute here is \(U^T v\).; To test the null hypothesis that the genotype coefficient \(\beta^0_v\) is zero, we consider the restricted model with parameters \(((0, \beta^1_v, \ldots, \beta^c_v), \sigma_{g,v}^2)\) within the full model with parameters \((\beta^0_v, \beta^1_v, \ldots, \beta^c_v), \sigma_{g_v}^2)\), with \(\delta\) fixed at \(\hat\delta\) in both. The latter fit is simply that of the global model, \(((0, \hat{\beta}^1, \ldots, \hat{\beta}^c), \hat{\sigma}_g^2)\). The likelihood ratio test statistic is given by. \[\chi^2 = n \, \mathrm{ln}\left(\frac{\hat{\sigma}^2_g}{\hat{\sigma}_{g,v}^2}\right)\]; and follows a chi-squared distribution with one degree of freedom. Here the ratio \(\hat{\sigma}^2_g / \hat{\sigma}_{g,v}^2\) captures the degree to which adding the variant \(v\) to the global model reduces the residual phenotypic variance.; Kinship Matrix; FastLMM uses the Realized Relationship Matrix (RRM) for kinship. This can be computed with rrm(). However, any instance of KinshipMatrix may be used, so long as sample_list contains the complete samples of the caller variant dataset in the same order.; Low-rank approximation of kinship for improved performance; lmmreg() can implicitly use a low-rank approximation of the kinship matrix to more rapidly fit delta and the statistics for each variant. The computational complexity per variant is proportional to the number of eigenvectors used.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:105852,simpl,simply,105852,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simply']
Usability,"_expr)[source]; Computes the realized relationship matrix (RRM).; Examples; >>> rrm = hl.realized_relationship_matrix(dataset.GT). Notes; The realized relationship matrix (RRM) is defined as follows. Consider the; \(n \times m\) matrix \(C\) of raw genotypes, with rows indexed by; \(n\) samples and columns indexed by the \(m\) bialellic autosomal; variants; \(C_{ij}\) is the number of alternate alleles of variant; \(j\) carried by sample \(i\), which can be 0, 1, 2, or missing. For; each variant \(j\), the sample alternate allele frequency \(p_j\) is; computed as half the mean of the non-missing entries of column \(j\).; Entries of \(M\) are then mean-centered and variance-normalized as. \[M_{ij} =; \frac{C_{ij}-2p_j}; {\sqrt{\frac{m}{n} \sum_{k=1}^n (C_{ij}-2p_j)^2}},\]; with \(M_{ij} = 0\) for \(C_{ij}\) missing (i.e. mean genotype; imputation). This scaling normalizes each variant column to have empirical; variance \(1/m\), which gives each sample row approximately unit total; variance (assuming linkage equilibrium) and yields the \(n \times n\); sample correlation or realized relationship matrix (RRM) \(K\) as simply. \[K = MM^T\]; Note that the only difference between the realized relationship matrix and; the genetic relatedness matrix (GRM) used in; realized_relationship_matrix() is the variant (column) normalization:; where RRM uses empirical variance, GRM uses expected variance under; Hardy-Weinberg Equilibrium.; This method drops variants with zero variance before computing kinship. Parameters:; call_expr (CallExpression) – Entry-indexed call expression on matrix table with columns corresponding; to samples. Returns:; BlockMatrix – Realized relationship matrix for all samples. Row and column indices; correspond to matrix table column index. hail.methods.impute_sex(call, aaf_threshold=0.0, include_par=False, female_threshold=0.2, male_threshold=0.8, aaf=None)[source]; Impute sex of samples by calculating inbreeding coefficient on the; X chromosome. Note; R",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:33960,simpl,simply,33960,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['simpl'],['simply']
Usability,"_i \quad\quad \textrm{the weight for variant } i \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2}; \end{align*}. The eigenvalues of :math:`Z Z^T` and :math:`Z^T Z` are the squared singular values of :math:`Z`;; therefore, we instead focus on :math:`Z^T Z`. In the expressions below, we elide transpositions; of symmetric matrices:. .. math::. \begin{align*}; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2} \\; Z &= P_0^{1/2} G W^{1/2} \\; Z^T Z &= W^{1/2} G^T P_0 G W^{1/2}; \end{align*}. Before substituting the definition of :math:`P_0`, simplify it using the reduced QR; decomposition:. .. math::. \begin{align*}; Q R &= V^{1/2} X \\; R^T Q^T &= X^T V^{1/2} \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; &= V - V X (R^T Q^T Q R)^{-1} X^T V \\; &= V - V X (R^T R)^{-1} X^T V \\; &= V - V X R^{-1} (R^T)^{-1} X^T V \\; &= V - V^{1/2} Q (R^T)^{-1} X^T V^{1/2} \\; &= V - V^{1/2} Q Q^T V^{1/2} \\; &= V^{1/2} (I - Q Q^T) V^{1/2} \\; \end{align*}. Substitute this simplified expression into :math:`Z`:. .. math::. \begin{align*}; Z^T Z &= W^{1/2} G^T V^{1/2} (I - Q Q^T) V^{1/2} G W^{1/2} \\; \end{align*}. Split this symmetric matrix by observing that :math:`I - Q Q^T` is idempotent:. .. math::. \begin{align*}; I - Q Q^T &= (I - Q Q^T)(I - Q Q^T)^T \\; \\; Z &= (I - Q Q^T) V^{1/2} G W^{1/2} \\; Z &= (G - Q Q^T G) V^{1/2} W^{1/2}; \end{align*}. Finally, the squared singular values of :math:`Z` are the eigenvalues of :math:`Z^T Z`, so; :math:`Q` should be distributed as follows:. .. math::. \begin{align*}; U S V^T &= Z \quad\quad \textrm{the singular value decomposition} \\; \lambda_s &= S_{ss}^2 \\; \\; Q &\sim \textrm{GeneralizedChiSquared}(\lambda, \vec{1}, \vec{0}, 0, 0); \end{align*}. The null hypothesis test tests for the probability of observing even larger values of :math:`Q`. The SKAT method was originally described in:. Wu MC, Lee S, Cai T, Li Y, Boehnke M, Lin X. *Rare-variant association testing for; sequencing data with the sequence kernel associa",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:90099,simpl,simplified,90099,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['simpl'],['simplified']
Usability,"_pretty(self, b, indent, increment):; b.append('ndarray<'); self._element_type._pretty(b, indent, increment); b.append(', '); b.append(str(self.ndim)); b.append('>'). def _parsable_string(self):; return f'NDArray[{self._element_type._parsable_string()},{self.ndim}]'. def _convert_from_json(self, x, _should_freeze: bool = False) -> np.ndarray:; if is_numeric(self._element_type):; np_type = self.element_type.to_numpy(); return np.ndarray(shape=x['shape'], buffer=np.array(x['data'], dtype=np_type), dtype=np_type); else:; raise TypeError(""Hail cannot currently return ndarrays of non-numeric or boolean type.""). def _convert_to_json(self, x):; data = x.flatten(""C"").tolist(). strides = []; axis_one_step_byte_size = x.itemsize; for dimension_size in x.shape:; strides.append(axis_one_step_byte_size); axis_one_step_byte_size *= dimension_size if dimension_size > 0 else 1. json_dict = {""shape"": x.shape, ""data"": data}; return json_dict. def clear(self):; self._element_type.clear(); self._ndim.clear(). def unify(self, t):; return isinstance(t, tndarray) and self._element_type.unify(t._element_type) and self._ndim.unify(t._ndim). def subst(self):; return tndarray(self._element_type.subst(), self._ndim.subst()). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> np.ndarray:; shape = [byte_reader.read_int64() for i in range(self.ndim)]; total_num_elements = np.product(shape, dtype=np.int64). if self.element_type in _numeric_types:; element_byte_size = self.element_type._byte_size; bytes_to_read = element_byte_size * total_num_elements; buffer = byte_reader.read_bytes_view(bytes_to_read); return np.frombuffer(buffer, self.element_type.to_numpy, count=total_num_elements).reshape(shape); else:; elements = [; self.element_type._convert_from_encoding(byte_reader, _should_freeze) for i in range(total_num_elements); ]; np_type = self.element_type.to_numpy(); return np.ndarray(shape=shape, buffer=n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:16851,clear,clear,16851,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"`; Repartitioned dataset.; """"""; if hl.current_backend().requires_lowering:; tmp = hl.utils.new_temp_file(). if len(self.row_key) == 0:; uid = Env.get_uid(); tmp2 = hl.utils.new_temp_file(); self.checkpoint(tmp2); ht = hl.read_matrix_table(tmp2).add_row_index(uid).key_rows_by(uid); ht.checkpoint(tmp); return hl.read_matrix_table(tmp, _n_partitions=n_partitions).drop(uid); else:; # checkpoint rather than write to use fast codec; self.checkpoint(tmp); return hl.read_matrix_table(tmp, _n_partitions=n_partitions). return MatrixTable(; ir.MatrixRepartition(; self._mir, n_partitions, ir.RepartitionStrategy.SHUFFLE if shuffle else ir.RepartitionStrategy.COALESCE; ); ). [docs] @typecheck_method(max_partitions=int); def naive_coalesce(self, max_partitions: int) -> 'MatrixTable':; """"""Naively decrease the number of partitions. Example; -------; Naively repartition to 10 partitions:. >>> dataset_result = dataset.naive_coalesce(10). Warning; -------; :meth:`.naive_coalesce` simply combines adjacent partitions to achieve; the desired number. It does not attempt to rebalance, unlike; :meth:`.repartition`, so it can produce a heavily unbalanced dataset. An; unbalanced dataset can be inefficient to operate on because the work is; not evenly distributed across partitions. Parameters; ----------; max_partitions : int; Desired number of partitions. If the current number of partitions is; less than or equal to `max_partitions`, do nothing. Returns; -------; :class:`.MatrixTable`; Matrix table with at most `max_partitions` partitions.; """"""; return MatrixTable(ir.MatrixRepartition(self._mir, max_partitions, ir.RepartitionStrategy.NAIVE_COALESCE)). [docs] def cache(self) -> 'MatrixTable':; """"""Persist the dataset in memory. Examples; --------; Persist the dataset in memory:. >>> dataset = dataset.cache() # doctest: +SKIP. Notes; -----. This method is an alias for :func:`persist(""MEMORY_ONLY"") <hail.MatrixTable.persist>`. Returns; -------; :class:`.MatrixTable`; Cached dataset.; """"""; return se",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:109591,simpl,simply,109591,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,['simpl'],['simply']
Usability,"aGrid; Array[Double]; values of \(\mathrm{ln}(\delta)\) used in the grid search. global.lmmreg.fit.logLkhdVals; Array[Double]; (restricted) log likelihood of \(y\) given \(X\) and \(\mathrm{ln}(\delta)\) at the (RE)ML fit of \(\beta\) and \(\sigma_g^2\). These global annotations are also added to hail.log, with the ranked evals and \(\delta\) grid with values in .tsv tabular form. Use grep 'lmmreg:' hail.log to find the lines just above each table.; If Step 5 is performed, lmmreg() also adds four linear regression variant annotations. Annotation; Type; Value. va.lmmreg.beta; Double; fit genotype coefficient, \(\hat\beta_0\). va.lmmreg.sigmaG2; Double; fit coefficient of genetic variance component, \(\hat{\sigma}_g^2\). va.lmmreg.chi2; Double; \(\chi^2\) statistic of the likelihood ratio test. va.lmmreg.pval; Double; \(p\)-value. Those variants that don’t vary across the included samples (e.g., all genotypes; are HomRef) will have missing annotations.; The simplest way to export all resulting annotations is:; >>> lmm_vds.export_variants('output/lmmreg.tsv.bgz', 'variant = v, va.lmmreg.*'); >>> lmmreg_results = lmm_vds.globals['lmmreg']. By default, genotypes values are given by hard call genotypes (g.gt).; If use_dosages=True, then genotype values for per-variant association are defined by the dosage; \(\mathrm{P}(\mathrm{Het}) + 2 \cdot \mathrm{P}(\mathrm{HomVar})\). For Phred-scaled values,; \(\mathrm{P}(\mathrm{Het})\) and \(\mathrm{P}(\mathrm{HomVar})\) are; calculated by normalizing the PL likelihoods (converted from the Phred-scale) to sum to 1.; Performance; Hail’s initial version of lmmreg() scales beyond 15k samples and to an essentially unbounded number of variants, making it particularly well-suited to modern sequencing studies and complementary to tools designed for SNP arrays. Analysts have used lmmreg() in research to compute kinship from 100k common variants and test 32 million non-rare variants on 8k whole genomes in about 10 minutes on Google cloud.;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:95600,simpl,simplest,95600,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simplest']
Usability,"able Joins Tutorial; MatrixTable Tutorial; Plotting Tutorial; GGPlot Tutorial. Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Hail Tutorials; Aggregation Tutorial. View page source. Aggregation Tutorial; In the last section, we inspected the structure of the data and displayed a few example values.; How do we get a deeper feel for the data? One of the most natural things to do is to create a summary of a large number of values. For example, you could ask:. How many women are in the dataset? How many men?; What is the average age? Youngest age? Oldest age?; What are all the occupations that appear, and how many times does each appear?. We can answer these questions with aggregation. Aggregation combines many values together to create a summary.; To start, we’ll aggregate all the values in a table. (Later, we’ll learn how to aggregate over subsets.); We can do this with the Table.aggregate method.; A call to aggregate has two parts:. The expression to aggregate over (e.g. a field of a Table).; The aggregator to combine the values into the summary. Hail has a large suite of aggregators for summarizing data. Let’s see some in action!. count; Aggregators live in the hl.agg module. The simplest aggregator is count. It takes no arguments and returns the number of values aggregated. [1]:. import hail as hl; from bokeh.io import output_notebook,show; output_notebook(); hl.init(). hl.utils.get_movie_lens('data/'); users = hl.read_table('data/users.ht'). Loading BokehJS ... Loading BokehJS ... SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/04-aggregation.html:1368,learn,learn,1368,docs/0.2/tutorials/04-aggregation.html,https://hail.is,https://hail.is/docs/0.2/tutorials/04-aggregation.html,1,['learn'],['learn']
Usability,"able in memory. Examples; --------; Persist the table in memory:. >>> table = table.cache() # doctest: +SKIP. Notes; -----. This method is an alias for :func:`persist(""MEMORY_ONLY"") <hail.Table.persist>`. Returns; -------; :class:`.Table`; Cached table.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK') -> 'Table':; """"""Persist this table in memory or on disk. Examples; --------; Persist the table to both memory and disk:. >>> table = table.persist() # doctest: +SKIP. Notes; -----. The :meth:`.Table.persist` and :meth:`.Table.cache` methods store the; current table on disk or in memory temporarily to avoid redundant computation; and improve the performance of Hail pipelines. This method is not a substitution; for :meth:`.Table.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.Table`; Persisted table.; """"""; return Env.backend().persist(self). [docs] def unpersist(self) -> 'Table':; """"""; Unpersists this table from memory/disk. Notes; -----; This function will have no effect on a table that was not previously; persisted. Returns; -------; :class:`.Table`; Unpersisted table.; """"""; return Env.backend().unpersist(self). @overload; def collect(self) -> List[hl.Struct]: ... @overload; def collect(self, _localize=False) -> ArrayExpression: ... [docs] @typecheck_method(_localize=bool, _timed=bool); def collect(self, _localize=True, *, _timed=False):; """"""Collect the rows of the table into a local li",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:80411,guid,guide,80411,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['guid'],['guide']
Usability,"ackends; Utilities. Configuration Reference; Advanced UI Search Help; Python Version Compatibility Policy; Change Log. Batch. Python API; BashJob. View page source. BashJob. class hailtop.batch.job.BashJob(batch, token, *, name=None, attributes=None, shell=None); Bases: Job; Object representing a single bash job to execute.; Examples; Create a batch object:; >>> b = Batch(). Create a new bash job that prints hello to a temporary file t.ofile:; >>> j = b.new_job(); >>> j.command(f'echo ""hello"" > {j.ofile}'). Write the temporary file t.ofile to a permanent location; >>> b.write_output(j.ofile, 'hello.txt'). Execute the DAG:; >>> b.run(). Notes; This class should never be created directly by the user. Use Batch.new_job(); or Batch.new_bash_job() instead.; Methods. command; Set the job's command to execute. declare_resource_group; Declare a resource group for a job. image; Set the job's docker image. command(command); Set the job’s command to execute.; Examples; Simple job with no output files:; >>> b = Batch(); >>> j = b.new_job(); >>> j.command(f'echo ""hello""'); >>> b.run(). Simple job with one temporary file j.ofile that is written to a; permanent location:; >>> b = Batch(); >>> j = b.new_job(); >>> j.command(f'echo ""hello world"" > {j.ofile}'); >>> b.write_output(j.ofile, 'output/hello.txt'); >>> b.run(). Two jobs with a file interdependency:; >>> b = Batch(); >>> j1 = b.new_job(); >>> j1.command(f'echo ""hello"" > {j1.ofile}'); >>> j2 = b.new_bash_job(); >>> j2.command(f'cat {j1.ofile} > {j2.ofile}'); >>> b.write_output(j2.ofile, 'output/cat_output.txt'); >>> b.run(). Specify multiple commands in the same job:; >>> b = Batch(); >>> t = b.new_job(); >>> j.command(f'echo ""hello"" > {j.tmp1}'); >>> j.command(f'echo ""world"" > {j.tmp2}'); >>> j.command(f'echo ""!"" > {j.tmp3}'); >>> j.command(f'cat {j.tmp1} {j.tmp2} {j.tmp3} > {j.ofile}'); >>> b.write_output(j.ofile, 'output/concatenated.txt'); >>> b.run(). Notes; This method can be called more than once. It’s behavior is t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.BashJob.html:1196,Simpl,Simple,1196,docs/batch/api/batch/hailtop.batch.job.BashJob.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.BashJob.html,1,['Simpl'],['Simple']
Usability,"alue). def _byte_size(self):; return 4. class _tint64(HailType):; """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`.; """""". def __init__(self):; super(_tint64, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not is_int64(annotation):; raise TypeError(""type 'int64' expected Python 'int', but found type '%s'"" % type(annotation)); if not self.min_value <= annotation <= self.max_value:; raise TypeError(; f""Value out of range for 64-bit integer: ""; f""expected [{self.min_value}, {self.max_value}], found {annotation}""; ). def __str__(self):; return ""int64"". def _eq(self, other):; return isinstance(other, _tint64). def _parsable_string(self):; return ""Int64"". @property; def min_value(self):; return -(1 << 63). @property; def max_value(self):; return (1 << 63) - 1. def unify(self, t):; return t == tint64. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.int64. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> int:; return byte_reader.read_int64(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_int64(value). def _byte_size(self):; return 8. class _tfloat32(HailType):; """"""Hail type for 32-bit floating point numbers. In Python, these are represented as :obj:`float`.; """""". def __init__(self):; super(_tfloat32, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not is_float32(annotation):; raise TypeError(""type 'float32' expected Python 'float', but found type '%s'"" % type(annotation)). def __str__(self):; return ""float32"". def _eq(self, other):; return isinstance(other, _tfloat32). def _parsable_string(self):; return ""Float32"". def _convert_from_json(self, x, _should_freeze: bool = False):; return float(x). def _convert_to_json(self, x):; if math.isfinite(x):; return x; else:; return str(x)",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:9464,clear,clear,9464,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"alueError(; ""'gvcf_sample_names' and 'gvcf_paths' must have the same length ""; f'{len(gvcf_sample_names)} != {len(gvcf_paths)}'; ). if batch_size is None:; if gvcf_batch_size is None:; gvcf_batch_size = VariantDatasetCombiner._default_gvcf_batch_size; else:; pass; elif gvcf_batch_size is None:; warning(; 'The batch_size parameter is deprecated. '; 'The batch_size parameter will be removed in a future version of Hail. '; 'Please use gvcf_batch_size instead.'; ); gvcf_batch_size = batch_size; else:; raise ValueError(; 'Specify only one of batch_size and gvcf_batch_size. ' f'Received {batch_size} and {gvcf_batch_size}.'; ); del batch_size. def maybe_load_from_saved_path(save_path: str) -> Optional[VariantDatasetCombiner]:; if force:; return None; fs = hl.current_backend().fs; if fs.exists(save_path):; try:; combiner = load_combiner(save_path); warning(f'found existing combiner plan at {save_path}, using it'); # we overwrite these values as they are serialized, but not part of the; # hash for an autogenerated name and we want users to be able to overwrite; # these when resuming a combine (a common reason to need to resume a combine; # is a failure due to branch factor being too large); combiner._branch_factor = branch_factor; combiner._target_records = target_records; combiner._gvcf_batch_size = gvcf_batch_size; return combiner; except (ValueError, TypeError, OSError, KeyError) as e:; warning(; f'file exists at {save_path}, but it is not a valid combiner plan, overwriting\n'; f' caused by: {e}'; ); return None. # We do the first save_path check now after validating the arguments; if save_path is not None:; saved_combiner = maybe_load_from_saved_path(save_path); if saved_combiner is not None:; return saved_combiner. if len(gvcf_paths) > 0:; n_partition_args = (; int(intervals is not None); + int(import_interval_size is not None); + int(use_genome_default_intervals); + int(use_exome_default_intervals); ). if n_partition_args == 0:; raise ValueError(; ""'new_combiner': requ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html:26168,resume,resume,26168,docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,2,['resume'],['resume']
Usability,"alues to be downsampled.; label (StringExpression or ArrayExpression) – Additional data for each (x, y) coordinate. Can pass in multiple fields in an ArrayExpression.; n_divisions (int) – Factor by which to downsample (default value = 500). A lower input results in fewer output datapoints. Returns:; ArrayExpression – Expression for downsampled coordinate points (x, y). The element type of the array is; ttuple of tfloat64, tfloat64, and tarray of tstr. hail.expr.aggregators.approx_cdf(expr, k=100, *, _raw=False)[source]; Produce a summary of the distribution of values.; Notes; This method returns a struct containing two arrays: values and ranks.; The values array contains an ordered sample of values seen. The ranks; array is one longer, and contains the approximate ranks for the; corresponding values.; These represent a summary of the CDF of the distribution of values. In; particular, for any value x = values(i) in the summary, we estimate that; there are ranks(i) values strictly less than x, and that there are; ranks(i+1) values less than or equal to x. For any value y (not; necessarily in the summary), we estimate CDF(y) to be ranks(i), where i; is such that values(i-1) < y ≤ values(i).; An alternative intuition is that the summary encodes a compressed; approximation to the sorted list of values. For example, values=[0,2,5,6,9]; and ranks=[0,3,4,5,8,10] represents the approximation [0,0,0,2,5,6,6,6,9,9],; with the value values(i) occupying indices ranks(i) (inclusive) to; ranks(i+1) (exclusive).; The returned struct also contains an array _compaction_counts, which is; used internally to support downstream error estimation. Warning; This is an approximate and nondeterministic method. Parameters:. expr (Expression) – Expression to collect.; k (int) – Parameter controlling the accuracy vs. memory usage tradeoff. Returns:; StructExpression – Struct containing values and ranks arrays. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/aggregators.html:34547,intuit,intuition,34547,docs/0.2/aggregators.html,https://hail.is,https://hail.is/docs/0.2/aggregators.html,1,['intuit'],['intuition']
Usability,"amed_exprs.items():; analyze(f'{caller}: ({name!r})', expr, self._parent._global_indices, {self._parent._row_axis}); check_collisions(caller, list(named_exprs), self._parent._row_indices); if not named_exprs.keys().isdisjoint(set(self._key_expr)):; intersection = set(named_exprs.keys()) & set(self._key_expr); raise ValueError(; f'GroupedTable.aggregate: Group names and aggregration expression names overlap: {intersection}'; ). base, _ = self._parent._process_joins(self._key_expr, *named_exprs.values()). key_struct = self._key_expr; return Table(; ir.TableKeyByAndAggregate(; base._tir, hl.struct(**named_exprs)._ir, key_struct._ir, self._npartitions, self._buffer_size; ); ). [docs]class Table(ExprContainer):; """"""Hail's distributed implementation of a dataframe or SQL table. Use :func:`.read_table` to read a table that was written with; :meth:`.Table.write`. Use :meth:`.to_spark` and :meth:`.Table.from_spark`; to inter-operate with PySpark's; `SQL <https://spark.apache.org/docs/latest/sql-programming-guide.html>`__ and; `machine learning <https://spark.apache.org/docs/latest/ml-guide.html>`__; functionality. Examples; --------. The examples below use ``table1`` and ``table2``, which are imported; from text files using :func:`.import_table`. >>> table1 = hl.import_table('data/kt_example1.tsv', impute=True, key='ID'); >>> table1.show(). .. code-block:: text. +-------+-------+-----+-------+-------+-------+-------+-------+; | ID | HT | SEX | X | Z | C1 | C2 | C3 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | int32 | int32 | str | int32 | int32 | int32 | int32 | int32 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | 1 | 65 | M | 5 | 4 | 2 | 50 | 5 |; | 2 | 72 | M | 6 | 3 | 2 | 61 | 1 |; | 3 | 70 | F | 7 | 3 | 10 | 81 | -5 |; | 4 | 60 | F | 8 | 2 | 11 | 90 | -10 |; +-------+-------+-----+-------+-------+-------+-------+-------+. >>> table2 = hl.import_table('data/kt_example2.tsv', impute=True, key='ID'); >>> table2.show(). .. code-",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:8171,guid,guide,8171,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['guid'],['guide']
Usability,"ample_allele_frequency parameter is True,; then the computed allele frequency is not included in the calculation, and the; prior is the maximum of the pop_frequency_prior and 1 / 3e7.; proband (struct) – Proband column fields from mt.; father (struct) – Father column fields from mt.; mother (struct) – Mother column fields from mt.; proband_entry (struct) – Proband entry fields from mt.; father_entry (struct) – Father entry fields from mt.; proband_entry (struct) – Mother entry fields from mt.; is_female (bool) – True if proband is female.; p_de_novo (float64) – Unfiltered posterior probability; that the event is de novo rather than a missed heterozygous; event in a parent.; confidence (str) Validation confidence. One of: 'HIGH',; 'MEDIUM', 'LOW'. The key of the table is ['locus', 'alleles', 'id'].; The model looks for de novo events in which both parents are homozygous; reference and the proband is a heterozygous. The model makes the simplifying; assumption that when this configuration x = (AA, AA, AB) of calls; occurs, exactly one of the following is true:. d: a de novo mutation occurred in the proband and all calls are; accurate.; m: at least one parental allele is actually heterozygous and; the proband call is accurate. We can then estimate the posterior probability of a de novo mutation as:. \[\mathrm{P_{\text{de novo}}} = \frac{\mathrm{P}(d \mid x)}{\mathrm{P}(d \mid x) + \mathrm{P}(m \mid x)}\]; Applying Bayes rule to the numerator and denominator yields. \[\frac{\mathrm{P}(x \mid d)\,\mathrm{P}(d)}{\mathrm{P}(x \mid d)\,\mathrm{P}(d) +; \mathrm{P}(x \mid m)\,\mathrm{P}(m)}\]; The prior on de novo mutation is estimated from the rate in the literature:. \[\mathrm{P}(d) = \frac{1 \, \text{mutation}}{30{,}000{,}000 \, \text{bases}}\]; The prior used for at least one alternate allele between the parents; depends on the alternate allele frequency:. \[\mathrm{P}(m) = 1 - (1 - AF)^4\]; The likelihoods \(\mathrm{P}(x \mid d)\) and \(\mathrm{P}(x \mid m)\); are computed",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:54360,simpl,simplifying,54360,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['simpl'],['simplifying']
Usability,"ark version 2.0.2; SparkUI available at http://10.56.135.40:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-5a67787. Hail Expression Language¶; The Hail expression language is used everywhere in Hail: filtering; conditions, describing covariates and phenotypes, storing summary; statistics about variants and samples, generating synthetic data,; plotting, exporting, and more. The Hail expression language takes the; form of Python strings passed into various Hail methods like; filter_variants_expr; and linear; regression.; The expression language is a programming language just like Python or R; or Scala. While the syntax is different, programming experience will; certainly translate. We have built the expression language with the hope; that even people new to programming are able to use it to explore; genetic data, even if this means copying motifs and expressions found on; places like Hail discussion forum.; For learning purposes, HailContext contains the method; eval_expr_typed.; This method takes a Python string of Hail expr code, evaluates it, and; returns a tuple with the result and the type. We’ll be using this method; throughout the expression language tutorial. Hail Types¶; The Hail expression language is strongly typed, meaning that every; expression has an associated type.; Hail defines the following types:; Primitives: - Int -; Double -; Float -; Long -; Boolean -; String; Compound Types: - Array[T] -; Set[T] - Dict[K,; V] -; Aggregable[T] -; Struct; Genetic Types: - Variant -; Locus -; AltAllele -; Interval -; Genotype -; Call. Primitive Types¶; Let’s start with simple primitive types. Primitive types are a basic; building block for any programming language - these are things like; numbers and strings and boolean values.; Hail expressions are passed as Python strings to Hail methods. In [2]:. # the Boolean literals are 'true' and 'false'; hc.eval_expr_typed('true'). Out[2]:. (True, Boolean). The return value is T",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/introduction-to-the-expression-language.html:2648,learn,learning,2648,docs/0.1/tutorials/introduction-to-the-expression-language.html,https://hail.is,https://hail.is/docs/0.1/tutorials/introduction-to-the-expression-language.html,1,['learn'],['learning']
Usability,"artitions=None)[source]; Construct a table with the row index and no other fields.; Examples; >>> df = hl.utils.range_table(100). >>> df.count(); 100. Notes; The resulting table contains one field:. idx (tint32) - Row index (key). This method is meant for testing and learning, and is not optimized for; production performance. Parameters:. n (int) – Number of rows.; n_partitions (int, optional) – Number of partitions (uses Spark default parallelism if None). Returns:; Table. hail.utils.range_matrix_table(n_rows, n_cols, n_partitions=None)[source]; Construct a matrix table with row and column indices and no entry fields.; Examples; >>> range_ds = hl.utils.range_matrix_table(n_rows=100, n_cols=10). >>> range_ds.count_rows(); 100. >>> range_ds.count_cols(); 10. Notes; The resulting matrix table contains the following fields:. row_idx (tint32) - Row index (row key).; col_idx (tint32) - Column index (column key). It contains no entry fields.; This method is meant for testing and learning, and is not optimized for; production performance. Parameters:. n_rows (int) – Number of rows.; n_cols (int) – Number of columns.; n_partitions (int, optional) – Number of partitions (uses Spark default parallelism if None). Returns:; MatrixTable. hail.utils.get_1kg(output_dir, overwrite=False)[source]; Download subset of the 1000 Genomes; dataset and sample annotations.; Notes; The download is about 15M. Parameters:. output_dir – Directory in which to write data.; overwrite – If True, overwrite any existing files/directories at output_dir. hail.utils.get_hgdp(output_dir, overwrite=False)[source]; Download subset of the Human Genome Diversity Panel; dataset and sample annotations.; Notes; The download is about 30MB. Parameters:. output_dir – Directory in which to write data.; overwrite – If True, overwrite any existing files/directories at output_dir. hail.utils.get_movie_lens(output_dir, overwrite=False)[source]; Download public Movie Lens dataset.; Notes; The download is about 6M.;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/utils/index.html:10733,learn,learning,10733,docs/0.2/utils/index.html,https://hail.is,https://hail.is/docs/0.2/utils/index.html,1,['learn'],['learning']
Usability,"ast section, we inspected the structure of the data and displayed a few example values.; How do we get a deeper feel for the data? One of the most natural things to do is to create a summary of a large number of values. For example, you could ask:. How many women are in the dataset? How many men?; What is the average age? Youngest age? Oldest age?; What are all the occupations that appear, and how many times does each appear?. We can answer these questions with aggregation. Aggregation combines many values together to create a summary.; To start, we’ll aggregate all the values in a table. (Later, we’ll learn how to aggregate over subsets.); We can do this with the Table.aggregate method.; A call to aggregate has two parts:. The expression to aggregate over (e.g. a field of a Table).; The aggregator to combine the values into the summary. Hail has a large suite of aggregators for summarizing data. Let’s see some in action!. count; Aggregators live in the hl.agg module. The simplest aggregator is count. It takes no arguments and returns the number of values aggregated. [1]:. import hail as hl; from bokeh.io import output_notebook,show; output_notebook(); hl.init(). hl.utils.get_movie_lens('data/'); users = hl.read_table('data/users.ht'). Loading BokehJS ... Loading BokehJS ... SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-20241004-2008-0.2.133-4c60fddb171a.log; 2024-10-04 20:09:01.799 Hail: INFO: Movie Lens files found!. [2]:. users.aggregate(hl.agg.count()). SLF4J: Failed to load class ""org.slf4j.impl.StaticMDCBinder"".; SLF4J: Defaulting to no-oper",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/04-aggregation.html:1746,simpl,simplest,1746,docs/0.2/tutorials/04-aggregation.html,https://hail.is,https://hail.is/docs/0.2/tutorials/04-aggregation.html,1,['simpl'],['simplest']
Usability,"best rank :math:`k` approximation :math:`U_k S_k V_k^T` of :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are :math:`n \\times k`, :math:`k \\times k` and :math:`m \\times k` respectively. From the perspective of the samples or rows of :math:`M` as data, :math:`V_k` contains the variant loadings for the first :math:`k` PCs while :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each sample. The loadings represent a new basis of features while the scores represent the projected data on those features. The eigenvalues of the GRM :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2, \ldots`, which represent the variances carried by the respective PCs. By default, Hail only computes the loadings if the ``loadings`` parameter is specified. *Note:* In PLINK/GCTA the GRM is taken as the starting point and it is computed slightly differently with regard to missing data. Here the :math:`ij` entry of :math:`MM^T` is simply the dot product of rows :math:`i` and :math:`j` of :math:`M`; in terms of :math:`C` it is. .. math::. \\frac{1}{m}\sum_{l\in\mathcal{C}_i\cap\mathcal{C}_j}\\frac{(C_{il}-2p_l)(C_{jl} - 2p_l)}{2p_l(1-p_l)}. where :math:`\mathcal{C}_i = \{l \mid C_{il} \\text{ is non-missing}\}`. In PLINK/GCTA the denominator :math:`m` is replaced with the number of terms in the sum :math:`\\lvert\mathcal{C}_i\cap\\mathcal{C}_j\\rvert`, i.e. the number of variants where both samples have non-missing genotypes. While this is arguably a better estimator of the true GRM (trading shrinkage for noise), it has the drawback that one loses the clean interpretation of the loadings and scores as features and projections. Separately, for the PCs PLINK/GCTA output the eigenvectors of the GRM; even ignoring the above discrepancy that means the left singular vectors :math:`U_k` instead of the component scores :math:`U_k S_k`. While this is just a matter of the scale on each PC, the scores have the advantage of representing true projecti",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:165668,simpl,simply,165668,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simply']
Usability,"ces, {self._parent._row_axis}); check_collisions(caller, list(named_exprs), self._parent._row_indices); if not named_exprs.keys().isdisjoint(set(self._key_expr)):; intersection = set(named_exprs.keys()) & set(self._key_expr); raise ValueError(; f'GroupedTable.aggregate: Group names and aggregration expression names overlap: {intersection}'; ). base, _ = self._parent._process_joins(self._key_expr, *named_exprs.values()). key_struct = self._key_expr; return Table(; ir.TableKeyByAndAggregate(; base._tir, hl.struct(**named_exprs)._ir, key_struct._ir, self._npartitions, self._buffer_size; ); ). [docs]class Table(ExprContainer):; """"""Hail's distributed implementation of a dataframe or SQL table. Use :func:`.read_table` to read a table that was written with; :meth:`.Table.write`. Use :meth:`.to_spark` and :meth:`.Table.from_spark`; to inter-operate with PySpark's; `SQL <https://spark.apache.org/docs/latest/sql-programming-guide.html>`__ and; `machine learning <https://spark.apache.org/docs/latest/ml-guide.html>`__; functionality. Examples; --------. The examples below use ``table1`` and ``table2``, which are imported; from text files using :func:`.import_table`. >>> table1 = hl.import_table('data/kt_example1.tsv', impute=True, key='ID'); >>> table1.show(). .. code-block:: text. +-------+-------+-----+-------+-------+-------+-------+-------+; | ID | HT | SEX | X | Z | C1 | C2 | C3 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | int32 | int32 | str | int32 | int32 | int32 | int32 | int32 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | 1 | 65 | M | 5 | 4 | 2 | 50 | 5 |; | 2 | 72 | M | 6 | 3 | 2 | 61 | 1 |; | 3 | 70 | F | 7 | 3 | 10 | 81 | -5 |; | 4 | 60 | F | 8 | 2 | 11 | 90 | -10 |; +-------+-------+-----+-------+-------+-------+-------+-------+. >>> table2 = hl.import_table('data/kt_example2.tsv', impute=True, key='ID'); >>> table2.show(). .. code-block:: text. +-------+-------+--------+; | ID | A | B |; +-------+-------+--------+; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:8250,guid,guide,8250,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['guid'],['guide']
Usability,"column order:. >>> import random; >>> indices = list(range(dataset.count_cols())); >>> random.shuffle(indices); >>> dataset_reordered = dataset.choose_cols(indices). Take the first ten columns:. >>> dataset_result = dataset.choose_cols(list(range(10))). Parameters; ----------; indices : :obj:`list` of :obj:`int`; List of old column indices. Returns; -------; :class:`.MatrixTable`; """"""; n_cols = self.count_cols(); for i in indices:; if not 0 <= i < n_cols:; raise ValueError(f""'choose_cols': expect indices between 0 and {n_cols}, found {i}""); return MatrixTable(ir.MatrixChooseCols(self._mir, indices)). [docs] def n_partitions(self) -> int:; """"""Number of partitions. Notes; -----. The data in a dataset is divided into chunks called partitions, which; may be stored together or across a network, so that each partition may; be read and processed in parallel by available cores. Partitions are a; core concept of distributed computation in Spark, see `here; <http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds>`__; for details. Returns; -------; int; Number of partitions.; """"""; return Env.backend().execute(ir.MatrixToValueApply(self._mir, {'name': 'NPartitionsMatrixTable'})). [docs] @typecheck_method(n_partitions=int, shuffle=bool); def repartition(self, n_partitions: int, shuffle: bool = True) -> 'MatrixTable':; """"""Change the number of partitions. Examples; --------. Repartition to 500 partitions:. >>> dataset_result = dataset.repartition(500). Notes; -----. Check the current number of partitions with :meth:`.n_partitions`. The data in a dataset is divided into chunks called partitions, which; may be stored together or across a network, so that each partition may; be read and processed in parallel by available cores. When a matrix with; :math:`M` rows is first imported, each of the :math:`k` partitions will; contain about :math:`M/k` of the rows. Since each partition has some; computational overhead, decreasing the number of partitio",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:106653,guid,guide,106653,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,['guid'],['guide']
Usability,"cs[mt.s].scores). [45]:. p = hl.plot.scatter(mt.scores[0],; mt.scores[1],; label=mt.pheno.SuperPopulation,; title='PCA', xlabel='PC1', ylabel='PC2'); show(p). [Stage 161:> (0 + 1) / 1]. Now we can rerun our linear regression, controlling for sample sex and the first few principal components. We’ll do this with input variable the number of alternate alleles as before, and again with input variable the genotype dosage derived from the PL field. [46]:. gwas = hl.linear_regression_rows(; y=mt.pheno.CaffeineConsumption,; x=mt.GT.n_alt_alleles(),; covariates=[1.0, mt.pheno.isFemale, mt.scores[0], mt.scores[1], mt.scores[2]]). [Stage 166:> (0 + 1) / 1]. We’ll first make a Q-Q plot to assess inflation…. [47]:. p = hl.plot.qq(gwas.p_value); show(p). That’s more like it! This shape is indicative of a well-controlled (but not especially well-powered) study. And now for the Manhattan plot:. [48]:. p = hl.plot.manhattan(gwas.p_value); show(p). We have found a caffeine consumption locus! Now simply apply Hail’s Nature paper function to publish the result.; Just kidding, that function won’t land until Hail 1.0!. Rare variant analysis; Here we’ll demonstrate how one can use the expression language to group and count by any arbitrary properties in row and column fields. Hail also implements the sequence kernel association test (SKAT). [49]:. entries = mt.entries(); results = (entries.group_by(pop = entries.pheno.SuperPopulation, chromosome = entries.locus.contig); .aggregate(n_het = hl.agg.count_where(entries.GT.is_het()))). [50]:. results.show(). [Stage 184:> (0 + 1) / 1]. popchromosomen_hetstrstrint64; ""AFR""""1""11039; ""AFR""""10""7123; ""AFR""""11""6777; ""AFR""""12""7016; ""AFR""""13""4650; ""AFR""""14""4262; ""AFR""""15""3847; ""AFR""""16""4564; ""AFR""""17""3607; ""AFR""""18""4133; showing top 10 rows. We use the MatrixTable.entries method to convert our matrix table to a table (with one row for each sample for each variant). In this representation, it is easy to aggregate over any fields we like, which is often ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html:23358,simpl,simply,23358,docs/0.2/tutorials/01-genome-wide-association-study.html,https://hail.is,https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html,1,['simpl'],['simply']
Usability,"d Relationship Matrix (RRM). **Examples**. >>> kinship_matrix = vds.rrm(). **Notes**. The Realized Relationship Matrix is defined as follows. Consider the :math:`n \\times m` matrix :math:`C` of raw genotypes, with rows indexed by :math:`n` samples and; columns indexed by the :math:`m` bialellic autosomal variants; :math:`C_{ij}` is the number of alternate alleles of variant :math:`j` carried by sample :math:`i`, which; can be 0, 1, 2, or missing. For each variant :math:`j`, the sample alternate allele frequency :math:`p_j` is computed as half the mean of the non-missing entries of column; :math:`j`. Entries of :math:`M` are then mean-centered and variance-normalized as. .. math::. M_{ij} = \\frac{C_{ij}-2p_j}{\sqrt{\\frac{m}{n} \sum_{k=1}^n (C_{ij}-2p_j)^2}},. with :math:`M_{ij} = 0` for :math:`C_{ij}` missing (i.e. mean genotype imputation). This scaling normalizes each variant column to have empirical variance :math:`1/m`, which gives each sample row approximately unit total variance (assuming linkage equilibrium) and yields the :math:`n \\times n` sample correlation or realized relationship matrix (RRM) :math:`K` as simply. .. math::. K = MM^T. Note that the only difference between the Realized Relationship Matrix and the Genetic Relationship Matrix (GRM) used in :py:meth:`~hail.VariantDataset.grm` is the variant (column) normalization: where RRM uses empirical variance, GRM uses expected variance under Hardy-Weinberg Equilibrium. :param bool force_block: Force using Spark's BlockMatrix to compute kinship (advanced). :param bool force_gramian: Force using Spark's RowMatrix.computeGramian to compute kinship (advanced). :return: Realized Relationship Matrix for all samples.; :rtype: :py:class:`KinshipMatrix`; """"""; return KinshipMatrix(self._jvdf.rrm(force_block, force_gramian)). [docs] @handle_py4j; @typecheck_method(other=vds_type,; tolerance=numeric); def same(self, other, tolerance=1e-6):; """"""True if the two variant datasets have the same variants, samples, gen",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:195440,simpl,simply,195440,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simply']
Usability,"d identity-by-descent zero, one, and two.; :rtype: :py:class:`.KeyTable`. """""". intstatistics = { ""phi"" : 0, ""phik2"" : 1, ""phik2k0"" : 2, ""all"" : 3 }[statistics]. return KeyTable(self.hc, self._jvdf.pcRelate(k, maf, block_size, min_kinship, intstatistics)). [docs] @handle_py4j; @typecheck_method(storage_level=strlike); def persist(self, storage_level=""MEMORY_AND_DISK""):; """"""Persist this variant dataset to memory and/or disk. **Examples**. Persist the variant dataset to both memory and disk:. >>> vds_result = vds.persist(). **Notes**. The :py:meth:`~hail.VariantDataset.persist` and :py:meth:`~hail.VariantDataset.cache` methods ; allow you to store the current dataset on disk or in memory to avoid redundant computation and ; improve the performance of Hail pipelines. :py:meth:`~hail.VariantDataset.cache` is an alias for ; :func:`persist(""MEMORY_ONLY"") <hail.VariantDataset.persist>`. Most users will want ""MEMORY_AND_DISK"".; See the `Spark documentation <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__ ; for a more in-depth discussion of persisting data.; ; .. warning ::; ; Persist, like all other :class:`.VariantDataset` functions, is functional.; Its output must be captured. This is wrong:; ; >>> vds = vds.linreg('sa.phenotype') # doctest: +SKIP; >>> vds.persist() # doctest: +SKIP; ; The above code does NOT persist ``vds``. Instead, it copies ``vds`` and persists that result. ; The proper usage is this:; ; >>> vds = vds.pca().persist() # doctest: +SKIP. :param storage_level: Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP; ; :rtype: :class:`.VariantDataset`; """""". return VariantDataset(self.hc, self._jvdf.persist(storage_level)). [docs] def unpersist(self):; """"""; Unpersists this VDS from memory/disk.; ; **Notes**; This function will have no effect on a VDS that was not previously per",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:178449,guid,guide,178449,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['guid'],['guide']
Usability,"d with respect to reference; GRCh37:. X: 60001 - 2699520, 154931044 - 155260560; Y: 10001 - 2649520, 59034050 - 59363566. Parameters:pedigree (Pedigree) – Sample pedigree. Returns:Four tables with Mendel error statistics. Return type:(KeyTable, KeyTable, KeyTable, KeyTable). min_rep(max_shift=100)[source]¶; Gives minimal, left-aligned representation of alleles. Note that this can change the variant position.; Examples; 1. Simple trimming of a multi-allelic site, no change in variant position; 1:10000:TAA:TAA,AA => 1:10000:TA:T,A; 2. Trimming of a bi-allelic site leading to a change in position; 1:10000:AATAA,AAGAA => 1:10002:T:G. Parameters:max_shift (int) – maximum number of base pairs by which; a split variant can move. Affects memory usage, and will; cause Hail to throw an error if a variant that moves further; is encountered. Return type:VariantDataset. naive_coalesce(max_partitions)[source]¶; Naively descrease the number of partitions. Warning; naive_coalesce() simply combines adjacent partitions to achieve the desired number. It does not attempt to rebalance, unlike repartition(), so it can produce a heavily unbalanced dataset. An unbalanced dataset can be inefficient to operate on because the work is not evenly distributed across partitions. Parameters:max_partitions (int) – Desired number of partitions. If the current number of partitions is less than max_partitions, do nothing. Returns:Variant dataset with the number of partitions equal to at most max_partitions. Return type:VariantDataset. num_partitions()[source]¶; Number of partitions.; Notes; The data in a variant dataset is divided into chunks called partitions, which may be stored together or across a network, so that each partition may be read and processed in parallel by available cores. Partitions are a core concept of distributed computation in Spark, see here for details. Return type:int. num_samples¶; Number of samples. Return type:int. pc_relate(k, maf, block_size=512, min_kinship=-inf, statisti",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:128432,simpl,simply,128432,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simply']
Usability,"digree (Pedigree) – Sample pedigree.; root – Variant annotation root to store TDT result. Returns:Variant dataset with TDT association results added to variant annotations. Return type:VariantDataset. union()[source]¶; Take the union of datasets vertically (include all variants).; Examples; Union two datasets:; >>> vds_union = vds_autosomal.union(vds_chromX). Given a list of datasets, union them all:; >>> all_vds = [vds_autosomal, vds_chromX, vds_chromY]. The following three syntaxes are equivalent:; >>> vds_union1 = vds_autosomal.union(vds_chromX, vds_chromY); >>> vds_union2 = all_vds[0].union(*all_vds[1:]); >>> vds_union3 = VariantDataset.union(*all_vds). Notes. In order to combine two datasets, these requirements must be met:. the samples must match; the variant annotation schemas must match (field order within structs matters).; the cell (genotype) schemas must match (field order within structs matters). The column annotations in the resulting dataset are simply the column annotations; from the first dataset; the column annotation schemas do not need to match.; This method can trigger a shuffle, if partitions from two datasets overlap. Parameters:vds_type (tuple of VariantDataset) – Datasets to combine. Returns:Dataset with variants from all datasets. Return type:VariantDataset. unpersist()[source]¶; Unpersists this VDS from memory/disk.; Notes; This function will have no effect on a VDS that was not previously persisted.; There’s nothing stopping you from continuing to use a VDS that has been unpersisted, but doing so will result in; all previous steps taken to compute the VDS being performed again since the VDS must be recomputed. Only unpersist; a VDS when you are done with it. variant_qc(root='va.qc')[source]¶; Compute common variant statistics (quality control metrics). Important; The genotype_schema() must be of type TGenotype in order to use this method. Examples; >>> vds_result = vds.variant_qc(). Annotations; variant_qc() computes 18 variant statistics f",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:170926,simpl,simply,170926,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simply']
Usability,"ds); return tstruct(**new_field_types). def _drop_fields(self, fields):; return tstruct(**{f: t for f, t in self.items() if f not in fields}). def _select_fields(self, fields):; return tstruct(**{f: self[f] for f in fields}). def _index_path(self, path):; t = self; for p in path:; t = t[p]; return t. def _rename(self, map):; seen = {}; new_field_types = {}. for f0, t in self.items():; f = map.get(f0, f0); if f in seen:; raise ValueError(; ""Cannot rename two fields to the same name: attempted to rename {} and {} both to {}"".format(; repr(seen[f]), repr(f0), repr(f); ); ); else:; seen[f] = f0; new_field_types[f] = t. return tstruct(**new_field_types). def unify(self, t):; if not (isinstance(t, tstruct) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tstruct(**{f: t.subst() for f, t in self.items()}). def clear(self):; for f, t in self.items():; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.values()). class tunion(HailType, Mapping):; @typecheck_method(case_types=hail_type); def __init__(self, **case_types):; """"""Tagged union type. Values of type union represent one of several; heterogenous, named cases. Parameters; ----------; cases : keyword args of :class:`.HailType`; The union cases. """""". super(tunion, self).__init__(); self._case_types = case_types; self._cases = tuple(case_types). @property; def cases(self):; """"""Return union case names. Returns; -------; :obj:`tuple` of :class:`str`; Tuple of union case names; """"""; return self._cases. @typecheck_method(item=oneof(int, str)); def __getitem__(self, item):; if isinstance(item, int):; item = self._cases[item]; return self._case_types[item]. def __iter__(self):; return iter(self._case_types). def __len__(self):; return len(self._cases). def __str__(self):; return ""union{{{}}}"".format(', '.join('{}: {}'.format(escape_parsable(f), str(t)) for f, t in self.item",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:36266,clear,clear,36266,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"ds.filter_variants_expr('va.qc.AF > 0.1', keep=True).count_variants(). Out[16]:. 7993L. In [17]:. # Filter on allele frequency and GQ mean; vds.filter_variants_expr('va.qc.AF > 0.1 && va.qc.gqMean > 20').count_variants(). Out[17]:. 7879L. In [18]:. # Genotype call rate across the entire dataset; vds.summarize().call_rate. Out[18]:. 0.9831634887327798. As we can see in the previous cell, the overall call rate of this; dataset is 98.7%. In [19]:. vds.filter_genotypes('g.gq >= 20', keep=True).summarize().call_rate. Out[19]:. 0.5495507709150625. However, 40% of those called genotypes are called with GQ 20 or less!; This corresponds to less than 99% confidence in the call. Annotating with expressions¶; It is also possible to produce new annotations with the expression; language. These take an expression of the form:; <new annotation name> = <expression>. To annotate samples, the new annotation name must also start with; sa. To annotate variants, it must always begin with va.; Here are some simple examples. In [20]:. (vds.annotate_samples_expr('sa.keepThisSample = sa.qc.callRate > 0.95 && sa.qc.dpMean > 5'); .filter_samples_expr('sa.keepThisSample', keep=True).num_samples). Out[20]:. 696. In [21]:. (vds.annotate_variants_expr('va.keepThisVariant = va.qc.AF > 0.1 && va.qc.gqMean > 20'); .filter_variants_expr('va.keepThisVariant').count_variants()). Out[21]:. 7879L. Key tables also have an; annotate; method. We can use this to produce new columns or redefine old ones:. In [22]:. kt.to_dataframe().show(5). +-------+----------+---------------+--------+----------+-------------------+; | Sample|Population|SuperPopulation|isFemale|PurpleHair|CaffeineConsumption|; +-------+----------+---------------+--------+----------+-------------------+; |NA19784| MXL| AMR| false| false| 8|; |NA19102| YRI| AFR| true| false| 6|; |HG00141| GBR| EUR| false| false| 6|; |HG01890| ACB| AFR| false| false| 8|; |HG00263| GBR| EUR| true| true| 6|; +-------+----------+---------------+--------+----------+",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/expression-language-part-2.html:8073,simpl,simple,8073,docs/0.1/tutorials/expression-language-part-2.html,https://hail.is,https://hail.is/docs/0.1/tutorials/expression-language-part-2.html,1,['simpl'],['simple']
Usability,"e joined (their; rows will be joined where table1.a == table2.c and table1.b ==; table2.d).; The key fields and order from the left table are preserved,; while the key fields from the right table are not present in; the result. Note; These join methods implement a traditional Cartesian product join, and; the number of records in the resulting table can be larger than; the number of records on the left or right if duplicate keys are; present. Parameters:. right (Table) – Table to join.; how (str) – Join type. One of “inner”, “left”, “right”, “outer”. Returns:; Table – Joined table. property key; Row key struct.; Examples; List of key field names:; >>> list(table1.key); ['ID']. Number of key fields:; >>> len(table1.key); 1. Returns:; StructExpression. key_by(*keys, **named_keys)[source]; Key table by a new set of fields.; Table keys control both the order of the rows in the table and the ability to join or; annotate one table with the information in another table.; Examples; Consider a simple unkeyed table. Its rows appear are guaranteed to appear in the same order; as they were in the source text file.; >>> ht = hl.import_table('data/kt_example1.tsv', impute=True); >>> ht.show(); +-------+-------+-----+-------+-------+-------+-------+-------+; | ID | HT | SEX | X | Z | C1 | C2 | C3 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | int32 | int32 | str | int32 | int32 | int32 | int32 | int32 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | 1 | 65 | ""M"" | 5 | 4 | 2 | 50 | 5 |; | 2 | 72 | ""M"" | 6 | 3 | 2 | 61 | 1 |; | 3 | 70 | ""F"" | 7 | 3 | 10 | 81 | -5 |; | 4 | 60 | ""F"" | 8 | 2 | 11 | 90 | -10 |; +-------+-------+-----+-------+-------+-------+-------+-------+. Changing the key forces the rows to appear in ascending order. For this reason,; key_by() is a relatively expensive operation. It must sort the entire dataset.; >>> ht = ht.key_by('HT'); >>> ht.show(); +-------+-------+-----+-------+-------+-------+-------+-------+; | ID ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.Table.html:39256,simpl,simple,39256,docs/0.2/hail.Table.html,https://hail.is,https://hail.is/docs/0.2/hail.Table.html,1,['simpl'],['simple']
Usability,"e, in bytes. Returns; -------; Readable or writable file handle.; """"""; # pile of hacks to preserve some legacy behavior, like auto gzip; fs = Env.fs(); if isinstance(fs, HadoopFS):; return fs.legacy_open(path, mode, buffer_size); _, ext = os.path.splitext(path); if ext in ('.gz', '.bgz'):; binary_mode = 'wb' if mode[0] == 'w' else 'rb'; file = fs.open(path, binary_mode, buffer_size); file = gzip.GzipFile(fileobj=file, mode=mode); if 'b' not in mode:; file = io.TextIOWrapper(file, encoding='utf-8'); else:; file = fs.open(path, mode, buffer_size); return file. [docs]@typecheck(src=str, dest=str); def hadoop_copy(src, dest):; """"""Copy a file through the Hadoop filesystem API.; Supports distributed file systems like hdfs, gs, and s3. Examples; --------; Copy a file from Google Cloud Storage to a local file:. >>> hadoop_copy('gs://hail-common/LCR.interval_list',; ... 'file:///mnt/data/LCR.interval_list') # doctest: +SKIP. Notes; ----. Try using :func:`.hadoop_open` first, it's simpler, but not great; for large data! For example:. >>> with hadoop_open('gs://my_bucket/results.csv', 'r') as f: #doctest: +SKIP; ... pandas_df.to_csv(f). The provided source and destination file paths must be URIs; (uniform resource identifiers). Parameters; ----------; src: :class:`str`; Source file URI.; dest: :class:`str`; Destination file URI.; """"""; return Env.fs().copy(src, dest). [docs]def hadoop_exists(path: str) -> bool:; """"""Returns ``True`` if `path` exists. Parameters; ----------; path : :class:`str`. Returns; -------; :obj:`.bool`; """"""; return Env.fs().exists(path). [docs]def hadoop_is_file(path: str) -> bool:; """"""Returns ``True`` if `path` both exists and is a file. Parameters; ----------; path : :class:`str`. Returns; -------; :obj:`.bool`; """"""; return Env.fs().is_file(path). [docs]def hadoop_is_dir(path: str) -> bool:; """"""Returns ``True`` if `path` both exists and is a directory. Parameters; ----------; path : :class:`str`. Returns; -------; :obj:`.bool`; """"""; return Env.fs().is_di",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html:4024,simpl,simpler,4024,docs/0.2/_modules/hail/utils/hadoop_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html,2,['simpl'],['simpler']
Usability,"e,; ). def _convert_to_json(self, x):; return {; 'start': self.point_type._convert_to_json_na(x.start),; 'end': self.point_type._convert_to_json_na(x.end),; 'includeStart': x.includes_start,; 'includeEnd': x.includes_end,; }. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; interval_as_struct = self._struct_repr._convert_from_encoding(byte_reader, _should_freeze); return hl.Interval(; interval_as_struct.start,; interval_as_struct.end,; interval_as_struct.includes_start,; interval_as_struct.includes_end,; point_type=self.point_type,; ). def _convert_to_encoding(self, byte_writer, value):; interval_dict = {; 'start': value.start,; 'end': value.end,; 'includes_start': value.includes_start,; 'includes_end': value.includes_end,; }; self._struct_repr._convert_to_encoding(byte_writer, interval_dict). def unify(self, t):; return isinstance(t, tinterval) and self.point_type.unify(t.point_type). def subst(self):; return tinterval(self.point_type.subst()). def clear(self):; self.point_type.clear(). def _get_context(self):; return self.point_type.get_context(). class Box(object):; named_boxes: ClassVar = {}. @staticmethod; def from_name(name):; if name in Box.named_boxes:; return Box.named_boxes[name]; b = Box(); Box.named_boxes[name] = b; return b. def __init__(self):; pass. def unify(self, v):; if hasattr(self, 'value'):; return self.value == v; self.value = v; return True. def clear(self):; if hasattr(self, 'value'):; del self.value. def get(self):; assert hasattr(self, 'value'); return self.value. tvoid = _tvoid(). tint32 = _tint32(); """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int32Expression`, :func:`.int`, :func:`.int32`; """""". tint64 = _tint64(); """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are r",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:51410,clear,clear,51410,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"e._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[set, frozenset]:; s = {self.element_type._convert_from_json_na(elt, _should_freeze=True) for elt in x}; if _should_freeze:; return frozenset(s); return s. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> Union[set, frozenset]:; s = self._array_repr._convert_from_encoding(byte_reader, _should_freeze=True); if _should_freeze:; return frozenset(s); return set(s). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; self._array_repr._convert_to_encoding(byte_writer, list(value)). def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tset) and self.element_type.unify(t.element_type). def subst(self):; return tset(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). class _freeze_this_type(HailType):; def __init__(self, t):; self.t = t. def _convert_from_json_na(self, x, _should_freeze: bool = False):; return self.t._convert_from_json_na(x, _should_freeze=True). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; return self.t._convert_from_encoding(byte_reader, _should_freeze=True). def _convert_to_encoding(self, byte_writer, x):; return self.t._convert_to_encoding(byte_writer, x). [docs]class tdict(HailType):; """"""Hail type for key-value maps. In Python, these are represented as :obj:`dict`. Notes; -----; Dicts parameterize the type of both their keys and values with; `key_type` and `value_type`. Parameters; ----------; key_type: :class:`.HailType`; Key type.; value_type: :class:`.HailType`; Value type. See Also; --------; :class:`.DictExpression`, :func:`.dict`, :ref:`sec-collection-functions`; """""". @typecheck_method(key_type=hail_type, value_type=hai",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:25502,clear,clear,25502,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"ead tables or matrix tables written by this; version of Hail. Version 0.2.24; Released 2019-10-03. hailctl dataproc. (#7185) Resolve issue; in dependencies that led to a Jupyter update breaking cluster; creation. New features. (#7071) Add; permit_shuffle flag to hl.{split_multi, split_multi_hts} to; allow processing of datasets with both multiallelics and duplciate; loci.; (#7121) Add; hl.contig_length function.; (#7130) Add; window method on LocusExpression, which creates an interval; around a locus.; (#7172) Permit; hl.init(sc=sc) with pip-installed packages, given the right; configuration options. Bug fixes. (#7070) Fix; unintentionally strict type error in MatrixTable.union_rows.; (#7170) Fix issues; created downstream of BlockMatrix.T.; (#7146) Fix bad; handling of edge cases in BlockMatrix.filter.; (#7182) Fix problem; parsing VCFs where lines end in an INFO field of type flag. Version 0.2.23; Released 2019-09-23. hailctl dataproc. (#7087) Added back; progress bar to notebooks, with links to the correct Spark UI url.; (#7104) Increased; disk requested when using --vep to address the “colony collapse”; cluster error mode. Bug fixes. (#7066) Fixed; generated code when methods from multiple reference genomes appear; together.; (#7077) Fixed crash; in hl.agg.group_by. New features. (#7009) Introduced; analysis pass in Python that mostly obviates the hl.bind and; hl.rbind operators; idiomatic Python that generates Hail; expressions will perform much better.; (#7076) Improved; memory management in generated code, add additional log statements; about allocated memory to improve debugging.; (#7085) Warn only; once about schema mismatches during JSON import (used in VEP,; Nirvana, and sometimes import_table.; (#7106); hl.agg.call_stats can now accept a number of alleles for its; alleles parameter, useful when dealing with biallelic calls; without the alleles array at hand. Performance. (#7086) Improved; performance of JSON import.; (#6981) Improved; performance",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:84997,progress bar,progress bar,84997,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['progress bar'],['progress bar']
Usability,"ecrease the number of variant dataset partitions. **Examples**. Repartition the variant dataset to have 500 partitions:. >>> vds_result = vds.repartition(500). **Notes**. Check the current number of partitions with :py:meth:`.num_partitions`. The data in a variant dataset is divided into chunks called partitions, which may be stored together or across a network, so that each partition may be read and processed in parallel by available cores. When a variant dataset with :math:`M` variants is first imported, each of the :math:`k` partition will contain about :math:`M/k` of the variants. Since each partition has some computational overhead, decreasing the number of partitions can improve performance after significant filtering. Since it's recommended to have at least 2 - 4 partitions per core, increasing the number of partitions can allow one to take advantage of more cores. Partitions are a core concept of distributed computation in Spark, see `here <http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds>`__ for details. With ``shuffle=True``, Hail does a full shuffle of the data and creates equal sized partitions. With ``shuffle=False``, Hail combines existing partitions to avoid a full shuffle. These algorithms correspond to the ``repartition`` and ``coalesce`` commands in Spark, respectively. In particular, when ``shuffle=False``, ``num_partitions`` cannot exceed current number of partitions. :param int num_partitions: Desired number of partitions, must be less than the current number if ``shuffle=False``. :param bool shuffle: If true, use full shuffle to repartition. :return: Variant dataset with the number of partitions equal to at most ``num_partitions``; :rtype: :class:`.VariantDataset`; """""". jvds = self._jvdf.coalesce(num_partitions, shuffle); return VariantDataset(self.hc, jvds). [docs] @handle_py4j; @typecheck_method(max_partitions=integral); def naive_coalesce(self, max_partitions):; """"""Naively descrease the number of",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:192404,guid,guide,192404,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['guid'],['guide']
Usability,"ect(B = table2.index(table1.ID).B); >>> table_result.B.show(); +-------+----------+; | ID | B |; +-------+----------+; | int32 | str |; +-------+----------+; | 1 | ""cat"" |; | 2 | ""dog"" |; | 3 | ""mouse"" |; | 4 | ""rabbit"" |; +-------+----------+. Using `key` as the sole index expression is equivalent to passing all; key fields individually:. >>> table_result = table1.select(B = table2.index(table1.key).B). It is also possible to use non-key fields or expressions as the index; expressions:. >>> table_result = table1.select(B = table2.index(table1.C1 % 4).B); >>> table_result.show(); +-------+---------+; | ID | B |; +-------+---------+; | int32 | str |; +-------+---------+; | 1 | ""dog"" |; | 2 | ""dog"" |; | 3 | ""dog"" |; | 4 | ""mouse"" |; +-------+---------+. Notes; -----; :meth:`.Table.index` is used to expose one table's fields for use in; expressions involving the another table or matrix table's fields. The; result of the method call is a struct expression that is usable in the; same scope as `exprs`, just as if `exprs` were used to look up values of; the table in a dictionary. The type of the struct expression is the same as the indexed table's; :meth:`.row_value` (the key fields are removed, as they are available; in the form of the index expressions). Note; ----; There is a shorthand syntax for :meth:`.Table.index` using square; brackets (the Python ``__getitem__`` syntax). This syntax is preferred. >>> table_result = table1.select(B = table2[table1.ID].B). Parameters; ----------; exprs : variable-length args of :class:`.Expression`; Index expressions.; all_matches : bool; Experimental. If ``True``, value of expression is array of all matches. Returns; -------; :class:`.Expression`; """"""; try:; return self._index(*exprs, all_matches=all_matches); except TableIndexKeyError as err:; raise ExpressionException(; f""Key type mismatch: cannot index table with given expressions:\n""; f"" Table key: {', '.join(str(t) for t in err.key_type.values()) or '<<<empty key>>>'}\n""; f"" In",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:71334,usab,usable,71334,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['usab'],['usable']
Usability,"ef _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> str:; length = byte_reader.read_int32(); str_literal = byte_reader.read_bytes(length).decode('utf-8'). return str_literal. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; value_bytes = value.encode('utf-8'); byte_writer.write_int32(len(value_bytes)); byte_writer.write_bytes(value_bytes). class _tbool(HailType):; """"""Hail type for Boolean (``True`` or ``False``) values. In Python, these are represented as :obj:`bool`.; """""". def __init__(self):; super(_tbool, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not isinstance(annotation, bool):; raise TypeError(""type 'bool' expected Python 'bool', but found type '%s'"" % type(annotation)). def __str__(self):; return ""bool"". def _eq(self, other):; return isinstance(other, _tbool). def _parsable_string(self):; return ""Boolean"". def unify(self, t):; return t == tbool. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return bool. def _byte_size(self):; return 1. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> bool:; return byte_reader.read_bool(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_bool(value). class _trngstate(HailType):; def __init__(self):; super(_trngstate, self).__init__(). def __str__(self):; return ""rng_state"". def _eq(self, other):; return isinstance(other, _trngstate). def _parsable_string(self):; return ""RNGState"". def unify(self, t):; return t == trngstate. def subst(self):; return self. def clear(self):; pass. [docs]class tndarray(HailType):; """"""Hail type for n-dimensional arrays. .. include:: _templates/experimental.rst. In Python, these are represented as NumPy :obj:`numpy.ndarray`. Notes; -----. NDArrays contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of array.; ndim : int",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:13532,clear,clear,13532,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"elf, other):; return (; isinstance(other, tunion) and self._cases == other._cases and all(self[c] == other[c] for c in self._cases); ). def _pretty(self, b, indent, increment):; if not self._cases:; b.append('union {}'); return. pre_indent = indent; indent += increment; b.append('union {'); for i, (f, t) in enumerate(self.items()):; if i > 0:; b.append(', '); b.append('\n'); b.append(' ' * indent); b.append('{}: '.format(escape_parsable(f))); t._pretty(b, indent, increment); b.append('\n'); b.append(' ' * pre_indent); b.append('}'). def _parsable_string(self):; return ""Union{{{}}}"".format(; ','.join('{}:{}'.format(escape_parsable(f), t._parsable_string()) for f, t in self.items()); ). def unify(self, t):; if not (isinstance(t, tunion) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tunion(**{f: t.subst() for f, t in self.items()}). def clear(self):; for f, t in self.items():; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.values()). [docs]class ttuple(HailType, Sequence):; """"""Hail type for tuples. In Python, these are represented as :obj:`tuple`. Parameters; ----------; types: varargs of :class:`.HailType`; Element types. See Also; --------; :class:`.TupleExpression`; """""". @typecheck_method(types=hail_type); def __init__(self, *types):; self._types = types; super(ttuple, self).__init__(). @property; def types(self):; """"""Tuple element types. Returns; -------; :obj:`tuple` of :class:`.HailType`; """"""; return self._types. def _traverse(self, obj, f):; if f(self, obj):; for t, elt in zip(self.types, obj):; t._traverse(elt, f). def _typecheck_one_level(self, annotation):; if annotation:; if not isinstance(annotation, tuple):; raise TypeError(""type 'tuple' expected Python tuple, but found '%s'"" % type(annotation)); if len(annotation) != len(self.types):; raise TypeError(""%s expected tuple of size '%i', but found ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:38273,clear,clear,38273,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"enotypes; - :math:`X_v = \\left[v | X \\right] = n \\times (1 + c)` matrix concatenating :math:`v` and :math:`X`; - :math:`\\beta_v = (\\beta^0_v, \\beta^1_v, \\ldots, \\beta^c_v) = (1 + c) \\times 1` vector of covariate coefficients. Fixing :math:`\delta` at the global REML estimate :math:`\\hat{\delta}`, we find the REML estimate :math:`(\\hat{\\beta}_v, \\hat{\sigma}_{g,v}^2)` via rotation of the model. .. math::. y \\sim \\mathrm{N}\\left(X_v\\beta_v, \sigma_{g,v}^2 (K + \\hat{\delta} I)\\right). Note that the only new rotation to compute here is :math:`U^T v`. To test the null hypothesis that the genotype coefficient :math:`\\beta^0_v` is zero, we consider the restricted model with parameters :math:`((0, \\beta^1_v, \ldots, \\beta^c_v), \sigma_{g,v}^2)` within the full model with parameters :math:`(\\beta^0_v, \\beta^1_v, \\ldots, \\beta^c_v), \sigma_{g_v}^2)`, with :math:`\delta` fixed at :math:`\\hat\delta` in both. The latter fit is simply that of the global model, :math:`((0, \\hat{\\beta}^1, \\ldots, \\hat{\\beta}^c), \\hat{\sigma}_g^2)`. The likelihood ratio test statistic is given by. .. math::. \chi^2 = n \\, \\mathrm{ln}\left(\\frac{\hat{\sigma}^2_g}{\\hat{\sigma}_{g,v}^2}\\right). and follows a chi-squared distribution with one degree of freedom. Here the ratio :math:`\\hat{\sigma}^2_g / \\hat{\sigma}_{g,v}^2` captures the degree to which adding the variant :math:`v` to the global model reduces the residual phenotypic variance. **Kinship Matrix**. FastLMM uses the Realized Relationship Matrix (RRM) for kinship. This can be computed with :py:meth:`~hail.VariantDataset.rrm`. However, any instance of :py:class:`KinshipMatrix` may be used, so long as ``sample_list`` contains the complete samples of the caller variant dataset in the same order. **Low-rank approximation of kinship for improved performance**. :py:meth:`.lmmreg` can implicitly use a low-rank approximation of the kinship matrix to more rapidly fit delta and the statistics for each variant. The",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:135358,simpl,simply,135358,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simply']
Usability,"er. Association testing (Step 5) is fully distributed by variant with per-variant time complexity that is completely independent of the number of sample covariates and dominated by multiplication of the genotype vector \(v\) by the matrix of eigenvectors \(U^T\) as described below, which we accelerate with a sparse representation of \(v\). The matrix \(U^T\) has size about \(8n^2\) bytes and is currently broadcast to each Spark executor. For example, with 15k samples, storing \(U^T\) consumes about 3.6GB of memory on a 16-core worker node with two 8-core executors. So for large \(n\), we recommend using a high-memory configuration such as highmem workers.; Linear mixed model; lmmreg() estimates the genetic proportion of residual phenotypic variance (narrow-sense heritability) under a kinship-based linear mixed model, and then optionally tests each variant for association using the likelihood ratio test. Inference is exact.; We first describe the sample-covariates-only model used to estimate heritability, which we simply refer to as the global model. With \(n\) samples and \(c\) sample covariates, we define:. \(y = n \times 1\) vector of phenotypes; \(X = n \times c\) matrix of sample covariates and intercept column of ones; \(K = n \times n\) kinship matrix; \(I = n \times n\) identity matrix; \(\beta = c \times 1\) vector of covariate coefficients; \(\sigma_g^2 =\) coefficient of genetic variance component \(K\); \(\sigma_e^2 =\) coefficient of environmental variance component \(I\); \(\delta = \frac{\sigma_e^2}{\sigma_g^2} =\) ratio of environmental and genetic variance component coefficients; \(h^2 = \frac{\sigma_g^2}{\sigma_g^2 + \sigma_e^2} = \frac{1}{1 + \delta} =\) genetic proportion of residual phenotypic variance. Under a linear mixed model, \(y\) is sampled from the \(n\)-dimensional multivariate normal distribution with mean \(X \beta\) and variance components that are scalar multiples of \(K\) and \(I\):. \[y \sim \mathrm{N}\left(X\beta, \sigma_g^2 K + \s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:98375,simpl,simply,98375,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simply']
Usability,"es Spark default parallelism if None). Returns; -------; :class:`.MatrixTable`; """"""; check_nonnegative_and_in_range('range_matrix_table', 'n_rows', n_rows); check_nonnegative_and_in_range('range_matrix_table', 'n_cols', n_cols); if n_partitions is not None:; check_positive_and_in_range('range_matrix_table', 'n_partitions', n_partitions); return hail.MatrixTable(; hail.ir.MatrixRead(; hail.ir.MatrixRangeReader(n_rows, n_cols, n_partitions),; _assert_type=hl.tmatrix(; hl.tstruct(),; hl.tstruct(col_idx=hl.tint32),; ['col_idx'],; hl.tstruct(row_idx=hl.tint32),; ['row_idx'],; hl.tstruct(),; ),; ); ). [docs]@typecheck(n=int, n_partitions=nullable(int)); def range_table(n, n_partitions=None) -> 'hail.Table':; """"""Construct a table with the row index and no other fields. Examples; --------. >>> df = hl.utils.range_table(100). >>> df.count(); 100. Notes; -----; The resulting table contains one field:. - `idx` (:py:data:`.tint32`) - Row index (key). This method is meant for testing and learning, and is not optimized for; production performance. Parameters; ----------; n : int; Number of rows.; n_partitions : int, optional; Number of partitions (uses Spark default parallelism if None). Returns; -------; :class:`.Table`; """"""; check_nonnegative_and_in_range('range_table', 'n', n); if n_partitions is not None:; check_positive_and_in_range('range_table', 'n_partitions', n_partitions). return hail.Table(hail.ir.TableRange(n, n_partitions)). def check_positive_and_in_range(caller, name, value):; if value <= 0:; raise ValueError(f""'{caller}': parameter '{name}' must be positive, found {value}""); elif value > hail.tint32.max_value:; raise ValueError(; f""'{caller}': parameter '{name}' must be less than or equal to {hail.tint32.max_value}, "" f""found {value}""; ). def check_nonnegative_and_in_range(caller, name, value):; if value < 0:; raise ValueError(f""'{caller}': parameter '{name}' must be non-negative, found {value}""); elif value > hail.tint32.max_value:; raise ValueError(; f""'{caller}'",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/misc.html:2780,learn,learning,2780,docs/0.2/_modules/hail/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/misc.html,2,['learn'],['learning']
Usability,"es for a variant annotation.; Attributes are key/value pairs that can be attached to a variant annotation field.; The following attributes are read from the VCF header when importing a VCF and written; to the VCF header when exporting a VCF:. INFO fields attributes (attached to (va.info.*)):; ‘Number’: The arity of the field. Can take values; 0 (Boolean flag),; 1 (single value),; R (one value per allele, including the reference),; A (one value per non-reference allele),; G (one value per genotype), and; . (any number of values); When importing: The value in read from the VCF INFO field definition; When exporting: The default value is 0 for Boolean, . for Arrays and 1 for all other types. ‘Description’ (default is ‘’). FILTER entries in the VCF header are generated based on the attributes; of va.filters. Each key/value pair in the attributes will generate; a FILTER entry in the VCF with ID = key and Description = value. Examples; Consider the following command which adds a filter and an annotation to the VDS (we’re assuming a split VDS for simplicity):. an INFO field AC_HC, which stores the allele count of high; confidence genotypes (DP >= 10, GQ >= 20) for each non-reference allele,; a filter HardFilter that filters all sites with the GATK suggested hard filters:; For SNVs: QD < 2.0 || FS < 60 || MQ < 40 || MQRankSum < -12.5 || ReadPosRankSum < -8.0; For Indels (and other complex): QD < 2.0 || FS < 200.0 || ReadPosRankSum < 20.0. >>> annotated_vds = vds.annotate_variants_expr([; ... 'va.info.AC_HC = gs.filter(g => g.dp >= 10 && g.gq >= 20).callStats(g => v).AC[1:]',; ... 'va.filters = if((v.altAllele.isSNP && (va.info.QD < 2.0 || va.info.FS < 60 || va.info.MQ < 40 || ' +; ... 'va.info.MQRankSum < -12.5 || va.info.ReadPosRankSum < -8.0)) || ' +; ... '(va.info.QD < 2.0 || va.info.FS < 200.0 || va.info.ReadPosRankSum < 20.0)) va.filters.add(""HardFilter"") else va.filters']). If we now export this VDS as VCF, it would produce the following header (for these new fields):;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:159950,simpl,simplicity,159950,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simplicity']
Usability,"esult = table1.select(B = table2.index(table1.ID).B); >>> table_result.B.show(); +-------+----------+; | ID | B |; +-------+----------+; | int32 | str |; +-------+----------+; | 1 | ""cat"" |; | 2 | ""dog"" |; | 3 | ""mouse"" |; | 4 | ""rabbit"" |; +-------+----------+. Using key as the sole index expression is equivalent to passing all; key fields individually:; >>> table_result = table1.select(B = table2.index(table1.key).B). It is also possible to use non-key fields or expressions as the index; expressions:; >>> table_result = table1.select(B = table2.index(table1.C1 % 4).B); >>> table_result.show(); +-------+---------+; | ID | B |; +-------+---------+; | int32 | str |; +-------+---------+; | 1 | ""dog"" |; | 2 | ""dog"" |; | 3 | ""dog"" |; | 4 | ""mouse"" |; +-------+---------+. Notes; Table.index() is used to expose one table’s fields for use in; expressions involving the another table or matrix table’s fields. The; result of the method call is a struct expression that is usable in the; same scope as exprs, just as if exprs were used to look up values of; the table in a dictionary.; The type of the struct expression is the same as the indexed table’s; row_value() (the key fields are removed, as they are available; in the form of the index expressions). Note; There is a shorthand syntax for Table.index() using square; brackets (the Python __getitem__ syntax). This syntax is preferred.; >>> table_result = table1.select(B = table2[table1.ID].B). Parameters:. exprs (variable-length args of Expression) – Index expressions.; all_matches (bool) – Experimental. If True, value of expression is array of all matches. Returns:; Expression. index_globals()[source]; Return this table’s global variables for use in another; expression context.; Examples; >>> table_result = table2.annotate(C = table2.A * table1.index_globals().global_field_1). Returns:; StructExpression. join(right, how='inner', _mangle=<function Table.<lambda>>, _join_key=None)[source]; Join two tables together.; Examples; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.Table.html:35816,usab,usable,35816,docs/0.2/hail.Table.html,https://hail.is,https://hail.is/docs/0.2/hail.Table.html,1,['usab'],['usable']
Usability,"etric positive-definite matrix when the weights are non-negative. We describe below our interpretation of the mathematics as described in the main body and; appendix of Wu, et al. According to the paper, the distribution of :math:`Q` is given by a; generalized chi-squared distribution whose weights are the eigenvalues of a symmetric matrix; which we call :math:`Z Z^T`:. .. math::. \begin{align*}; V_{ii} &= \sigma^2_i \\; W_{ii} &= w_i \quad\quad \textrm{the weight for variant } i \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2}; \end{align*}. The eigenvalues of :math:`Z Z^T` and :math:`Z^T Z` are the squared singular values of :math:`Z`;; therefore, we instead focus on :math:`Z^T Z`. In the expressions below, we elide transpositions; of symmetric matrices:. .. math::. \begin{align*}; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2} \\; Z &= P_0^{1/2} G W^{1/2} \\; Z^T Z &= W^{1/2} G^T P_0 G W^{1/2}; \end{align*}. Before substituting the definition of :math:`P_0`, simplify it using the reduced QR; decomposition:. .. math::. \begin{align*}; Q R &= V^{1/2} X \\; R^T Q^T &= X^T V^{1/2} \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; &= V - V X (R^T Q^T Q R)^{-1} X^T V \\; &= V - V X (R^T R)^{-1} X^T V \\; &= V - V X R^{-1} (R^T)^{-1} X^T V \\; &= V - V^{1/2} Q (R^T)^{-1} X^T V^{1/2} \\; &= V - V^{1/2} Q Q^T V^{1/2} \\; &= V^{1/2} (I - Q Q^T) V^{1/2} \\; \end{align*}. Substitute this simplified expression into :math:`Z`:. .. math::. \begin{align*}; Z^T Z &= W^{1/2} G^T V^{1/2} (I - Q Q^T) V^{1/2} G W^{1/2} \\; \end{align*}. Split this symmetric matrix by observing that :math:`I - Q Q^T` is idempotent:. .. math::. \begin{align*}; I - Q Q^T &= (I - Q Q^T)(I - Q Q^T)^T \\; \\; Z &= (I - Q Q^T) V^{1/2} G W^{1/2} \\; Z &= (G - Q Q^T G) V^{1/2} W^{1/2}; \end{align*}. Finally, the squared singular values of :math:`Z` are the eigenvalues of :math:`Z^T Z`, so; :math:`Q` should be distributed as follows:. .. math::. \begin{align*}; U S V^T &= Z \quad\quad \t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:89675,simpl,simplify,89675,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,['simpl'],['simplify']
Usability,"f, obj, f):; """"""Traverse a nested type and object. Parameters; ----------; obj : Any; f : Callable[[HailType, Any], bool]; Function to evaluate on the type and object. Traverse children if; the function returns ``True``.; """"""; f(self, obj). @abc.abstractmethod; def unify(self, t):; raise NotImplementedError. @abc.abstractmethod; def subst(self):; raise NotImplementedError. @abc.abstractmethod; def clear(self):; raise NotImplementedError. def _get_context(self):; return _empty_context. def get_context(self):; if self._context is None:; self._context = self._get_context(); return self._context. def to_numpy(self):; return object. hail_type = oneof(HailType, transformed((str, dtype)), type(None)). class _tvoid(HailType):; def __init__(self):; super(_tvoid, self).__init__(). def __str__(self):; return ""void"". def _eq(self, other):; return isinstance(other, _tvoid). def _parsable_string(self):; return ""Void"". def unify(self, t):; return t == tvoid. def subst(self):; return self. def clear(self):; pass. def _convert_from_encoding(self, *_):; raise ValueError(""Cannot decode void type""). def _convert_to_encoding(self, *_):; raise ValueError(""Cannot encode void type""). class _tint32(HailType):; """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`.; """""". def __init__(self):; super(_tint32, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not is_int32(annotation):; raise TypeError(""type 'tint32' expected Python 'int', but found type '%s'"" % type(annotation)); elif not self.min_value <= annotation <= self.max_value:; raise TypeError(; f""Value out of range for 32-bit integer: ""; f""expected [{self.min_value}, {self.max_value}], found {annotation}""; ). def __str__(self):; return ""int32"". def _eq(self, other):; return isinstance(other, _tint32). def _parsable_string(self):; return ""Int32"". @property; def min",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:7033,clear,clear,7033,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"foo and rg.bar will not have the .txt file extension and; instead will be {root}.foo and {root}.bar where {root} is a random; identifier.; Notes; The identifier is used to refer to a specific resource file. For example,; given the resource group rg, you can use the attribute notation; rg.identifier or the get item notation rg[identifier].; The file extensions for each file are derived from the identifier. This; is equivalent to “{root}.identifier” from; BashJob.declare_resource_group(). We are planning on adding; flexibility to incorporate more complicated extensions in the future; such as .vcf.bgz. For now, use JobResourceFile.add_extension(); to add an extension to a resource file. Parameters:; kwargs (Union[str, PathLike]) – Key word arguments where the name/key is the identifier and the value; is the file path. Return type:; ResourceGroup. run(dry_run=False, verbose=False, delete_scratch_on_exit=True, **backend_kwargs); Execute a batch.; Examples; Create a simple batch with one job and execute it:; >>> b = Batch(); >>> j = b.new_job(); >>> j.command('echo ""hello world""'); >>> b.run(). Parameters:. dry_run (bool) – If True, don’t execute code.; verbose (bool) – If True, print debugging output.; delete_scratch_on_exit (bool) – If True, delete temporary directories with intermediate files.; backend_kwargs (Any) – See Backend._run() for backend-specific arguments. Return type:; Optional[Batch]. select_jobs(pattern); Select all jobs in the batch whose name matches pattern.; Examples; Select jobs in batch matching qc:; >>> b = Batch(); >>> j = b.new_job(name='qc'); >>> qc_jobs = b.select_jobs('qc'); >>> assert qc_jobs == [j]. Parameters:; pattern (str) – Regex pattern matching job names. Return type:; List[Job]. write_output(resource, dest); Write resource file or resource file group to an output destination.; Examples; Write a single job intermediate to a local file:; >>> b = Batch(); >>> j = b.new_job(); >>> j.command(f'echo ""hello"" > {j.ofile}'); >>> b.write_outp",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.batch.Batch.html:10408,simpl,simple,10408,docs/batch/api/batch/hailtop.batch.batch.Batch.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.batch.Batch.html,2,['simpl'],['simple']
Usability,"ge Log. Batch. Python API; BashJob. View page source. BashJob. class hailtop.batch.job.BashJob(batch, token, *, name=None, attributes=None, shell=None); Bases: Job; Object representing a single bash job to execute.; Examples; Create a batch object:; >>> b = Batch(). Create a new bash job that prints hello to a temporary file t.ofile:; >>> j = b.new_job(); >>> j.command(f'echo ""hello"" > {j.ofile}'). Write the temporary file t.ofile to a permanent location; >>> b.write_output(j.ofile, 'hello.txt'). Execute the DAG:; >>> b.run(). Notes; This class should never be created directly by the user. Use Batch.new_job(); or Batch.new_bash_job() instead.; Methods. command; Set the job's command to execute. declare_resource_group; Declare a resource group for a job. image; Set the job's docker image. command(command); Set the job’s command to execute.; Examples; Simple job with no output files:; >>> b = Batch(); >>> j = b.new_job(); >>> j.command(f'echo ""hello""'); >>> b.run(). Simple job with one temporary file j.ofile that is written to a; permanent location:; >>> b = Batch(); >>> j = b.new_job(); >>> j.command(f'echo ""hello world"" > {j.ofile}'); >>> b.write_output(j.ofile, 'output/hello.txt'); >>> b.run(). Two jobs with a file interdependency:; >>> b = Batch(); >>> j1 = b.new_job(); >>> j1.command(f'echo ""hello"" > {j1.ofile}'); >>> j2 = b.new_bash_job(); >>> j2.command(f'cat {j1.ofile} > {j2.ofile}'); >>> b.write_output(j2.ofile, 'output/cat_output.txt'); >>> b.run(). Specify multiple commands in the same job:; >>> b = Batch(); >>> t = b.new_job(); >>> j.command(f'echo ""hello"" > {j.tmp1}'); >>> j.command(f'echo ""world"" > {j.tmp2}'); >>> j.command(f'echo ""!"" > {j.tmp3}'); >>> j.command(f'cat {j.tmp1} {j.tmp2} {j.tmp3} > {j.ofile}'); >>> b.write_output(j.ofile, 'output/concatenated.txt'); >>> b.run(). Notes; This method can be called more than once. It’s behavior is to append; commands to run to the set of previously defined commands rather than; overriding an existing comman",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/batch/hailtop.batch.job.BashJob.html:1313,Simpl,Simple,1313,docs/batch/api/batch/hailtop.batch.job.BashJob.html,https://hail.is,https://hail.is/docs/batch/api/batch/hailtop.batch.job.BashJob.html,1,['Simpl'],['Simple']
Usability,"her.element_type and self.ndim == other.ndim. def _pretty(self, b, indent, increment):; b.append('ndarray<'); self._element_type._pretty(b, indent, increment); b.append(', '); b.append(str(self.ndim)); b.append('>'). def _parsable_string(self):; return f'NDArray[{self._element_type._parsable_string()},{self.ndim}]'. def _convert_from_json(self, x, _should_freeze: bool = False) -> np.ndarray:; if is_numeric(self._element_type):; np_type = self.element_type.to_numpy(); return np.ndarray(shape=x['shape'], buffer=np.array(x['data'], dtype=np_type), dtype=np_type); else:; raise TypeError(""Hail cannot currently return ndarrays of non-numeric or boolean type.""). def _convert_to_json(self, x):; data = x.flatten(""C"").tolist(). strides = []; axis_one_step_byte_size = x.itemsize; for dimension_size in x.shape:; strides.append(axis_one_step_byte_size); axis_one_step_byte_size *= dimension_size if dimension_size > 0 else 1. json_dict = {""shape"": x.shape, ""data"": data}; return json_dict. def clear(self):; self._element_type.clear(); self._ndim.clear(). def unify(self, t):; return isinstance(t, tndarray) and self._element_type.unify(t._element_type) and self._ndim.unify(t._ndim). def subst(self):; return tndarray(self._element_type.subst(), self._ndim.subst()). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> np.ndarray:; shape = [byte_reader.read_int64() for i in range(self.ndim)]; total_num_elements = np.product(shape, dtype=np.int64). if self.element_type in _numeric_types:; element_byte_size = self.element_type._byte_size; bytes_to_read = element_byte_size * total_num_elements; buffer = byte_reader.read_bytes_view(bytes_to_read); return np.frombuffer(buffer, self.element_type.to_numpy, count=total_num_elements).reshape(shape); else:; elements = [; self.element_type._convert_from_encoding(byte_reader, _should_freeze) for i in range(total_num_elements); ]; np_type = self.element_type.t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:16798,clear,clear,16798,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"hip=0.1) . Notes; The traditional estimator for kinship between a pair of individuals; \(i\) and \(j\), sharing the set \(S_{ij}\) of; single-nucleotide variants, from a population with estimated allele; frequencies \(\widehat{p}_{s}\) at SNP \(s\), is given by:. \[\widehat{\psi}_{ij} \coloneqq; \frac{1}{\left|\mathcal{S}_{ij}\right|}; \sum_{s \in \mathcal{S}_{ij}}; \frac{\left(g_{is} - 2\hat{p}_{s}\right)\left(g_{js} - 2\widehat{p}_{s}\right)}; {4 \widehat{p}_{s}\left(1-\widehat{p}_{s}\right)}\]; This estimator is true under the model that the sharing of common; (relative to the population) alleles is not very informative to; relatedness (because they’re common) and the sharing of rare alleles; suggests a recent common ancestor from which the allele was inherited by; descent.; When multiple ancestry groups are mixed in a sample, this model breaks; down. Alleles that are rare in all but one ancestry group are treated as; very informative to relatedness. However, these alleles are simply; markers of the ancestry group. The PC-Relate method corrects for this; situation and the related situation of admixed individuals.; PC-Relate slightly modifies the usual estimator for relatedness:; occurrences of population allele frequency are replaced with an; “individual-specific allele frequency”. This modification allows the; method to correctly weight an allele according to an individual’s unique; ancestry profile.; The “individual-specific allele frequency” at a given genetic locus is; modeled by PC-Relate as a linear function of a sample’s first k; principal component coordinates. As such, the efficacy of this method; rests on two assumptions:. an individual’s first k principal component coordinates fully; describe their allele-frequency-relevant ancestry, and; the relationship between ancestry (as described by principal; component coordinates) and population allele frequency is linear. The estimators for kinship, and identity-by-descent zero, one, and two; follow. Let:. \(S",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/relatedness.html:14149,simpl,simply,14149,docs/0.2/methods/relatedness.html,https://hail.is,https://hail.is/docs/0.2/methods/relatedness.html,1,['simpl'],['simply']
Usability,"his is more efficient than producing the full key table and; filtering using filter().; >>> rel = vds.pc_relate(5, 0.01, min_kinship=0.1). Method; The traditional estimator for kinship between a pair of individuals; \(i\) and \(j\), sharing the set \(S_{ij}\) of; single-nucleotide variants, from a population with allele frequencies; \(p_s\), is given by:. \[\widehat{\phi_{ij}} := \frac{1}{|S_{ij}|}\sum_{s \in S_{ij}}\frac{(g_{is} - 2 p_s) (g_{js} - 2 p_s)}{4 * \sum_{s \in S_{ij} p_s (1 - p_s)}}\]; This estimator is true under the model that the sharing of common; (relative to the population) alleles is not very informative to; relatedness (because they’re common) and the sharing of rare alleles; suggests a recent common ancestor from which the allele was inherited by; descent.; When multiple ancestry groups are mixed in a sample, this model breaks; down. Alleles that are rare in all but one ancestry group are treated as; very informative to relatedness. However, these alleles are simply; markers of the ancestry group. The PC-Relate method corrects for this; situation and the related situation of admixed individuals.; PC-Relate slightly modifies the usual estimator for relatedness:; occurences of population allele frequency are replaced with an; “individual-specific allele frequency”. This modification allows the; method to correctly weight an allele according to an individual’s unique; ancestry profile.; The “individual-specific allele frequency” at a given genetic locus is; modeled by PC-Relate as a linear function of their first k principal; component coordinates. As such, the efficacy of this method rests on two; assumptions:. an individual’s first k principal component coordinates fully; describe their allele-frequency-relevant ancestry, and; the relationship between ancestry (as described by principal; component coordinates) and population allele frequency is linear. The estimators for kinship, and identity-by-descent zero, one, and two; follow. Let:. \(S_{ij}\",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:131231,simpl,simply,131231,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simply']
Usability,"iants(); summary.call_rate = jrep.callRate().get() if jrep.callRate().isDefined() else float('nan'); summary.contigs = [str(x) for x in jiterable_to_list(jrep.contigs())]; summary.multiallelics = jrep.multiallelics(); summary.snps = jrep.snps(); summary.mnps = jrep.mnps(); summary.insertions = jrep.insertions(); summary.deletions = jrep.deletions(); summary.complex = jrep.complex(); summary.star = jrep.star(); summary.max_alleles = jrep.maxAlleles(); return summary. def __repr__(self):; return 'Summary(samples=%d, variants=%d, call_rate=%f, contigs=%s, multiallelics=%d, snps=%d, ' \; 'mnps=%d, insertions=%d, deletions=%d, complex=%d, star=%d, max_alleles=%d)' % (; self.samples, self.variants, self.call_rate,; self.contigs, self.multiallelics, self.snps,; self.mnps, self.insertions, self.deletions,; self.complex, self.star, self.max_alleles). def __str__(self):; return repr(self). [docs] def report(self):; """"""Print the summary information.""""""; print('') # clear out pesky progress bar if necessary; print('%16s: %d' % ('Samples', self.samples)); print('%16s: %d' % ('Variants', self.variants)); print('%16s: %f' % ('Call Rate', self.call_rate)); print('%16s: %s' % ('Contigs', self.contigs)); print('%16s: %d' % ('Multiallelics', self.multiallelics)); print('%16s: %d' % ('SNPs', self.snps)); print('%16s: %d' % ('MNPs', self.mnps)); print('%16s: %d' % ('Insertions', self.insertions)); print('%16s: %d' % ('Deletions', self.deletions)); print('%16s: %d' % ('Complex Alleles', self.complex)); print('%16s: %d' % ('Star Alleles', self.star)); print('%16s: %d' % ('Max Alleles', self.max_alleles)). class FunctionDocumentation(object):; @handle_py4j; def types_rst(self, file_name):; Env.hail().utils.FunctionDocumentation.makeTypesDocs(file_name). @handle_py4j; def functions_rst(self, file_name):; Env.hail().utils.FunctionDocumentation.makeFunctionsDocs(file_name). [docs]@handle_py4j; @typecheck(path=strlike,; buffer_size=integral); def hadoop_read(path, buffer_size=8192):; """"""Open a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/utils.html:2317,clear,clear,2317,docs/0.1/_modules/hail/utils.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/utils.html,2,"['clear', 'progress bar']","['clear', 'progress bar']"
Usability,"ically one computes only the first \(k\) singular vectors and values, yielding the best rank \(k\) approximation \(U_k S_k V_k^T\) of \(M\); the truncations \(U_k\), \(S_k\) and \(V_k\) are \(n \times k\), \(k \times k\) and \(m \times k\) respectively.; From the perspective of the samples or rows of \(M\) as data, \(V_k\) contains the variant loadings for the first \(k\) PCs while \(MV_k = U_k S_k\) contains the first \(k\) PC scores of each sample. The loadings represent a new basis of features while the scores represent the projected data on those features. The eigenvalues of the GRM \(MM^T\) are the squares of the singular values \(s_1^2, s_2^2, \ldots\), which represent the variances carried by the respective PCs. By default, Hail only computes the loadings if the loadings parameter is specified.; Note: In PLINK/GCTA the GRM is taken as the starting point and it is computed slightly differently with regard to missing data. Here the \(ij\) entry of \(MM^T\) is simply the dot product of rows \(i\) and \(j\) of \(M\); in terms of \(C\) it is. \[\frac{1}{m}\sum_{l\in\mathcal{C}_i\cap\mathcal{C}_j}\frac{(C_{il}-2p_l)(C_{jl} - 2p_l)}{2p_l(1-p_l)}\]; where \(\mathcal{C}_i = \{l \mid C_{il} \text{ is non-missing}\}\). In PLINK/GCTA the denominator \(m\) is replaced with the number of terms in the sum \(\lvert\mathcal{C}_i\cap\mathcal{C}_j\rvert\), i.e. the number of variants where both samples have non-missing genotypes. While this is arguably a better estimator of the true GRM (trading shrinkage for noise), it has the drawback that one loses the clean interpretation of the loadings and scores as features and projections.; Separately, for the PCs PLINK/GCTA output the eigenvectors of the GRM; even ignoring the above discrepancy that means the left singular vectors \(U_k\) instead of the component scores \(U_k S_k\). While this is just a matter of the scale on each PC, the scores have the advantage of representing true projections of the data onto features with the varia",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:141604,simpl,simply,141604,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simply']
Usability,"il does a full shuffle of the data and creates equal sized partitions. With ``shuffle=False``, Hail combines existing partitions to avoid a full shuffle. These algorithms correspond to the ``repartition`` and ``coalesce`` commands in Spark, respectively. In particular, when ``shuffle=False``, ``num_partitions`` cannot exceed current number of partitions. :param int num_partitions: Desired number of partitions, must be less than the current number if ``shuffle=False``. :param bool shuffle: If true, use full shuffle to repartition. :return: Variant dataset with the number of partitions equal to at most ``num_partitions``; :rtype: :class:`.VariantDataset`; """""". jvds = self._jvdf.coalesce(num_partitions, shuffle); return VariantDataset(self.hc, jvds). [docs] @handle_py4j; @typecheck_method(max_partitions=integral); def naive_coalesce(self, max_partitions):; """"""Naively descrease the number of partitions. .. warning ::. :py:meth:`~hail.VariantDataset.naive_coalesce` simply combines adjacent partitions to achieve the desired number. It does not attempt to rebalance, unlike :py:meth:`~hail.VariantDataset.repartition`, so it can produce a heavily unbalanced dataset. An unbalanced dataset can be inefficient to operate on because the work is not evenly distributed across partitions. :param int max_partitions: Desired number of partitions. If the current number of partitions is less than ``max_partitions``, do nothing. :return: Variant dataset with the number of partitions equal to at most ``max_partitions``; :rtype: :class:`.VariantDataset`; """""". jvds = self._jvds.naiveCoalesce(max_partitions); return VariantDataset(self.hc, jvds); ; [docs] @handle_py4j; @typecheck_method(force_block=bool,; force_gramian=bool); def rrm(self, force_block=False, force_gramian=False):; """"""Computes the Realized Relationship Matrix (RRM). **Examples**. >>> kinship_matrix = vds.rrm(). **Notes**. The Realized Relationship Matrix is defined as follows. Consider the :math:`n \\times m` matrix :math:`C`",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:193468,simpl,simply,193468,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simply']
Usability,"ilarly, a Hail JAR compatible with Cloudera Spark version 2.1.0 is built by executing:; ./gradlew shadowJar -Dspark.version=2.1.0.cloudera1. On a Cloudera cluster, SPARK_HOME should be set as:; SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2,. On Cloudera, you can create an interactive Python shell using pyspark2:; $ pyspark2 --jars build/libs/hail-all-spark.jar \; --py-files build/distributions/hail-python.zip \; --conf spark.sql.files.openCostInBytes=1099511627776 \; --conf spark.sql.files.maxPartitionBytes=1099511627776 \; --conf spark.hadoop.parquet.block.size=1099511627776. Cloudera’s version of spark-submit is called spark2-submit. Running in the cloud¶; Google and Amazon offer optimized Spark performance; and exceptional scalability to many thousands of cores without the overhead; of installing and managing an on-prem cluster.; Hail publishes pre-built JARs for Google Cloud Platform’s Dataproc Spark; clusters. If you would prefer to avoid building Hail from source, learn how to; get started on Google Cloud Platform by reading this forum post. You; can use cloudtools to simplify using; Hail on GCP even further, including via interactive Jupyter notebooks (also discussed here). Building with other versions of Spark 2¶; Hail is compatible with Spark 2.0.x and 2.1.x. To build against Spark 2.1.0,; modify the above instructions as follows:. Set the Spark version in the gradle command; $ ./gradlew -Dspark.version=2.1.0 shadowJar. SPARK_HOME should point to an installation of the desired version of Spark, such as spark-2.1.0-bin-hadoop2.7. The version of the Py4J ZIP file in the hail alias must match the version in $SPARK_HOME/python/lib in your version of Spark. BLAS and LAPACK¶; Hail uses BLAS and LAPACK optimized linear algebra libraries. These should load automatically on recent versions of Mac OS X and Google Dataproc. On Linux, these must be explicitly installed; on Ubuntu 14.04, run; $ apt-get install libatlas-base-dev. If natives are not found, hail.log wi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/getting_started.html:6960,learn,learn,6960,docs/0.1/getting_started.html,https://hail.is,https://hail.is/docs/0.1/getting_started.html,1,['learn'],['learn']
Usability,"ing about it. Luckily, it’s easy to not be that person!; Always start small. For Hail, this means using a two worker Spark cluster and experimenting on a small; fraction of the data. For genetic data, make sure your scripts work on chromosome 22 (the 2nd smallest autosomal chromosome) before; you try running on the entire genome! If you have a matrix table you can limit to chromosome 22 with filter_rows.; Hail will make sure not to load data for other chromosomes.; import hail as hl. mt = hl.read_matrix_table('gs://....'); mt = mt.filter_rows(mt.locus.contig == '22'). Hail’s hl.balding_nichols_model creates a random genotype dataset with configurable numbers of rows and columns.; You can use these datasets for experimentation.; As you’ll see later, the smallest Hail cluster (on GCP) costs about 3 dollars per hour. Each time you think you need to double; the size of your cluster ask yourself: am I prepared to spend twice as much money per hour?. Estimating time; Estimating the time and cost of a Hail operation is often simple. Start a small cluster and use filter_rows to read a small fraction of the data:; test_mt = mt.filter_rows(mt.locus.contig == '22'); print(mt.count_rows() / test_mt.count_rows()). Multiply the time spent computing results on this smaller dataset by the number printed. This yields a reasonable expectation of the time; to compute results on the full dataset using a cluster of the same size. However, not all operations will scale this way. Certain complicated operations; like pca or BlockMatrix multiplies do not scale linearly. When doing small time estimates, it can sometimes be helpful to get a few datapoints as; you gradually increase the size of your small dataset to see if it’s scaling linearly. Estimating cost; Costs vary between cloud providers. This cost estimate is based on Google Cloud, but the same principles often apply to other providers.; Google charges by the core-hour, so we can convert so-called “wall clock time” (time elapsed fr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/cloud/general_advice.html:1820,simpl,simple,1820,docs/0.2/cloud/general_advice.html,https://hail.is,https://hail.is/docs/0.2/cloud/general_advice.html,1,['simpl'],['simple']
Usability,"inite(x):; return x; else:; return str(x). def unify(self, t):; return t == tfloat64. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float64. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> float:; return byte_reader.read_float64(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_float64(value). def _byte_size(self):; return 8. class _tstr(HailType):; """"""Hail type for text strings. In Python, these are represented as strings.; """""". def __init__(self):; super(_tstr, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation and not isinstance(annotation, str):; raise TypeError(""type 'str' expected Python 'str', but found type '%s'"" % type(annotation)). def __str__(self):; return ""str"". def _eq(self, other):; return isinstance(other, _tstr). def _parsable_string(self):; return ""String"". def unify(self, t):; return t == tstr. def subst(self):; return self. def clear(self):; pass. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> str:; length = byte_reader.read_int32(); str_literal = byte_reader.read_bytes(length).decode('utf-8'). return str_literal. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; value_bytes = value.encode('utf-8'); byte_writer.write_int32(len(value_bytes)); byte_writer.write_bytes(value_bytes). class _tbool(HailType):; """"""Hail type for Boolean (``True`` or ``False``) values. In Python, these are represented as :obj:`bool`.; """""". def __init__(self):; super(_tbool, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not isinstance(annotation, bool):; raise TypeError(""type 'bool' expected Python 'bool', but found type '%s'"" % type(annotation)). def __str__(self):; return ""bool"". def _eq(self, other):; return isinstance(other, _tbool). def _parsable_string(self):; return ""Boolean"". def unify(self, t):; return t == tbool. def subst(self):; return sel",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:12518,clear,clear,12518,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"ion)). def __str__(self):; return ""array<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other, tarray) and self.element_type == other.element_type. def _pretty(self, b, indent, increment):; b.append('array<'); self.element_type._pretty(b, indent, increment); b.append('>'). def _parsable_string(self):; return ""Array["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[list, frozenlist]:; ls = [self.element_type._convert_from_json_na(elt, _should_freeze) for elt in x]; if _should_freeze:; return frozenlist(ls); return ls. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tarray) and self.element_type.unify(t.element_type). def subst(self):; return tarray(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> Union[list, frozenlist]:; length = byte_reader.read_int32(). num_missing_bytes = math.ceil(length / 8); missing_bytes = byte_reader.read_bytes_view(num_missing_bytes). decoded = []; i = 0; current_missing_byte = None; while i < length:; which_missing_bit = i % 8; if which_missing_bit == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; decoded.append(None); else:; element_decoded = self.element_type._convert_from_encoding(byte_reader, _should_freeze); decoded.append(element_decoded); i += 1; if _should_freeze:; return frozenlist(decoded); return decoded. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:20301,clear,clear,20301,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"ion, allele_index:; Int32Expression) to BooleanExpression; subset (bool) – Subset PL field if True, otherwise downcode PL field. The; calculation of GT and GQ also depend on whether one subsets or; downcodes the PL. Returns:; MatrixTable. hail.methods.hwe_normalized_pca(call_expr, k=10, compute_loadings=False)[source]; Run principal component analysis (PCA) on the Hardy-Weinberg-normalized; genotype call matrix.; Examples; >>> eigenvalues, scores, loadings = hl.hwe_normalized_pca(dataset.GT, k=5). Notes; This method specializes pca() for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate are unnormalizable and removed before; evaluation. See pca() for more details.; Users of PLINK/GCTA should be aware that Hail computes the GRM slightly; differently with regard to missing data. In Hail, the; \(ij\) entry of the GRM \(MM^T\) is simply the dot product of rows; \(i\) and \(j\) of \(M\); in terms of \(C\) it is. \[\frac{1}{m}\sum_{l\in\mathcal{C}_i\cap\mathcal{C}_j}\frac{(C_{il}-2p_l)(C_{jl} - 2p_l)}{2p_l(1-p_l)}\]; where \(\mathcal{C}_i = \{l \mid C_{il} \text{ is non-missing}\}\). In; PLINK/GCTA the denominator \(m\) is replaced with the number of terms in; the sum \(\lvert\mathcal{C}_i\cap\mathcal{C}_j\rvert\), i.e. the; number of variants where both samples have non-missing genotypes. While this; is arguably a better estimator of the true GRM (trading shrinkage for; noise), it has the drawback that one loses the clean interpretation of the; loadings and scores as features and projections; Separately, for the PCs PLINK/GCTA output the eigenvectors of the GRM, i.e.; the left singular vectors \(U_k\) instead of the component scores; \(U_k S_k\). The scores have the advantage of representing true; projections of the data onto features with the variance of a score; reflecting the variance explained by the corresponding feature. ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:29298,simpl,simply,29298,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['simpl'],['simply']
Usability,"ion._indices.source.select_globals(**{uid: expression}).index_globals()[uid]._ir. return Env.backend().execute(MakeTuple([ir]), timed=True)[0]. [docs]@typecheck(expression=expr_any); def eval(expression):; """"""Evaluate a Hail expression, returning the result. This method is extremely useful for learning about Hail expressions and; understanding how to compose them. The expression must have no indices, but can refer to the globals; of a :class:`.Table` or :class:`.MatrixTable`. Examples; --------; Evaluate a conditional:. >>> x = 6; >>> hl.eval(hl.if_else(x % 2 == 0, 'Even', 'Odd')); 'Even'. Parameters; ----------; expression : :class:`.Expression`; Any expression, or a Python value that can be implicitly interpreted as an expression. Returns; -------; Any; """"""; return eval_timed(expression)[0]. @typecheck(expression=expr_any); def eval_typed(expression):; """"""Evaluate a Hail expression, returning the result and the type of the result. This method is extremely useful for learning about Hail expressions and understanding; how to compose them. The expression must have no indices, but can refer to the globals; of a :class:`.hail.Table` or :class:`.hail.MatrixTable`. Examples; --------; Evaluate a conditional:. >>> x = 6; >>> hl.eval_typed(hl.if_else(x % 2 == 0, 'Even', 'Odd')); ('Even', dtype('str')). Parameters; ----------; expression : :class:`.Expression`; Any expression, or a Python value that can be implicitly interpreted as an expression. Returns; -------; (any, :class:`.HailType`); Result of evaluating `expression`, and its type. """"""; return eval(expression), expression.dtype. def _get_refs(expr: Expression, builder: Dict[str, Indices]) -> None:; from hail.ir import GetField, TopLevelReference. for ir in expr._ir.search(; lambda a: (isinstance(a, GetField) and not a.name.startswith('__uid') and isinstance(a.o, TopLevelReference)); ):; src = expr._indices.source; builder[ir.name] = src._indices_from_ref[ir.o.name]. def extract_refs_by_indices(exprs, indices):; """"""Re",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html:6231,learn,learning,6231,docs/0.2/_modules/hail/expr/expressions/expression_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html,2,['learn'],['learning']
Usability,"itional estimator for kinship between a pair of individuals; :math:`i` and :math:`j`, sharing the set :math:`S_{ij}` of; single-nucleotide variants, from a population with estimated allele; frequencies :math:`\widehat{p}_{s}` at SNP :math:`s`, is given by:. .. math::. \widehat{\psi}_{ij} \coloneqq; \frac{1}{\left|\mathcal{S}_{ij}\right|}; \sum_{s \in \mathcal{S}_{ij}}; \frac{\left(g_{is} - 2\hat{p}_{s}\right)\left(g_{js} - 2\widehat{p}_{s}\right)}; {4 \widehat{p}_{s}\left(1-\widehat{p}_{s}\right)}. This estimator is true under the model that the sharing of common; (relative to the population) alleles is not very informative to; relatedness (because they're common) and the sharing of rare alleles; suggests a recent common ancestor from which the allele was inherited by; descent. When multiple ancestry groups are mixed in a sample, this model breaks; down. Alleles that are rare in all but one ancestry group are treated as; very informative to relatedness. However, these alleles are simply; markers of the ancestry group. The PC-Relate method corrects for this; situation and the related situation of admixed individuals. PC-Relate slightly modifies the usual estimator for relatedness:; occurrences of population allele frequency are replaced with an; ""individual-specific allele frequency"". This modification allows the; method to correctly weight an allele according to an individual's unique; ancestry profile. The ""individual-specific allele frequency"" at a given genetic locus is; modeled by PC-Relate as a linear function of a sample's first ``k``; principal component coordinates. As such, the efficacy of this method; rests on two assumptions:. - an individual's first ``k`` principal component coordinates fully; describe their allele-frequency-relevant ancestry, and. - the relationship between ancestry (as described by principal; component coordinates) and population allele frequency is linear. The estimators for kinship, and identity-by-descent zero, one, and two; follow.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/pc_relate.html:4055,simpl,simply,4055,docs/0.2/_modules/hail/methods/relatedness/pc_relate.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/pc_relate.html,2,['simpl'],['simply']
Usability,"ive of the end position. Note; Hail uses the following ordering for contigs: 1-22 sorted numerically, then X, Y, MT,; then alphabetically for any contig not matching the standard human chromosomes. Caution; The interval parser for these files does not support the full range of formats supported; by the python parser parse(). ‘k’, ‘m’, ‘start’, and ‘end’ are all; invalid motifs in the contig:start-end format here. Parameters:filename (str) – Path to file. Returns:Interval-keyed table. Return type:KeyTable. indexed(name='index')[source]¶; Add the numerical index of each row as a new column.; Examples; >>> ind_kt = kt1.indexed(). Notes; This method returns a table with a new column whose name is; given by the name parameter, with type Long. The value; of this column is the numerical index of each row, starting; from 0. Methods that respect ordering (like KeyTable.take(); or KeyTable.export() will return rows in order.; This method is helpful for creating a unique integer index for rows; of a table, so that more complex types can be encoded as a simple; number. Parameters:name (str) – Name of index column. Returns:Table with a new index column. Return type:KeyTable. join(right, how='inner')[source]¶; Join two key tables together.; Examples; Join kt1 to kt2 to produce kt_joined:; >>> kt_result = kt1.key_by('ID').join(kt2.key_by('ID')). Notes:; Hail supports four types of joins specified by how:. inner – Key must be present in both kt1 and kt2.; outer – Key present in kt1 or kt2. For keys only in kt1, the value of non-key columns from kt2 is set to missing.; Likewise, for keys only in kt2, the value of non-key columns from kt1 is set to missing.; left – Key present in kt1. For keys only in kt1, the value of non-key columns from kt2 is set to missing.; right – Key present in kt2. For keys only in kt2, the value of non-key columns from kt1 is set to missing. The non-key fields in kt2 must have non-overlapping column names with kt1.; Both key tables must have the same number ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.KeyTable.html:16382,simpl,simple,16382,docs/0.1/hail.KeyTable.html,https://hail.is,https://hail.is/docs/0.1/hail.KeyTable.html,1,['simpl'],['simple']
Usability,"l field. n_partitions()[source]; Returns the number of partitions in the table.; Examples; Range tables can be constructed with an explicit number of partitions:; >>> ht = hl.utils.range_table(100, n_partitions=10); >>> ht.n_partitions(); 10. Small files are often imported with one partition:; >>> ht2 = hl.import_table('data/coordinate_matrix.tsv', impute=True); >>> ht2.n_partitions(); 1. The min_partitions argument to import_table() forces more partitions, but it can; produce empty partitions. Empty partitions do not affect correctness but introduce; unnecessary extra bookkeeping that slows down the pipeline.; >>> ht2 = hl.import_table('data/coordinate_matrix.tsv', impute=True, min_partitions=10); >>> ht2.n_partitions(); 10. Returns:; int – Number of partitions. naive_coalesce(max_partitions)[source]; Naively decrease the number of partitions.; Example; Naively repartition to 10 partitions:; >>> table_result = table1.naive_coalesce(10). Warning; naive_coalesce() simply combines adjacent partitions to achieve; the desired number. It does not attempt to rebalance, unlike; repartition(), so it can produce a heavily unbalanced dataset. An; unbalanced dataset can be inefficient to operate on because the work is; not evenly distributed across partitions. Parameters:; max_partitions (int) – Desired number of partitions. If the current number of partitions is; less than or equal to max_partitions, do nothing. Returns:; Table – Table with at most max_partitions partitions. order_by(*exprs)[source]; Sort by the specified fields, defaulting to ascending order. Will unkey the table if it is keyed.; Examples; Let’s assume we have a field called HT in our table.; By default, ascending order is used:; >>> sorted_table = table1.order_by(table1.HT). >>> sorted_table = table1.order_by('HT'). You can sort in ascending order explicitly:; >>> sorted_table = table1.order_by(hl.asc(table1.HT)). >>> sorted_table = table1.order_by(hl.asc('HT')). Tables can be sorted by field descending ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.Table.html:47703,simpl,simply,47703,docs/0.2/hail.Table.html,https://hail.is,https://hail.is/docs/0.2/hail.Table.html,1,['simpl'],['simply']
Usability,"lation(v1, v2) >= r2):; keep = False; if keep:; pruned_set.append(v1). The parameter ``window`` defines the maximum distance in base pairs between two variants to check whether; the variants are independent (:math:`R^2` < ``r2``) where ``r2`` is the maximum :math:`R^2` allowed.; :math:`R^2` is defined as the square of `Pearson's correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`__; :math:`{\\rho}_{x,y}` between the two genotype vectors :math:`{\\mathbf{x}}` and :math:`{\\mathbf{y}}`. .. math::. {\\rho}_{x,y} = \\frac{\\mathrm{Cov}(X,Y)}{\\sigma_X \\sigma_Y}. :py:meth:`.ld_prune` with default arguments is equivalent to ``plink --indep-pairwise 1000kb 1 0.2``.; The list of pruned variants returned by Hail and PLINK will differ because Hail mean-imputes missing values and tests pairs of variants in a different order than PLINK. Be sure to provide enough disk space per worker because :py:meth:`.ld_prune` `persists <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__ up to 3 copies of the data to both memory and disk.; The amount of disk space required will depend on the size and minor allele frequency of the input data and the prune parameters ``r2`` and ``window``. The number of bytes stored in memory per variant is about ``nSamples / 4 + 50``. .. warning::. The variants in the pruned set are not guaranteed to be identical each time :py:meth:`.ld_prune` is run. We recommend running :py:meth:`.ld_prune` once and exporting the list of LD pruned variants using; :py:meth:`.export_variants` for future use. :param float r2: Maximum :math:`R^2` threshold between two variants in the pruned set within a given window. :param int window: Width of window in base-pairs for computing pair-wise :math:`R^2` values. :param int memory_per_core: Total amount of memory available for each core in MB. If unsure, use the default value. :param int num_cores: The number of cores available. Equivalent to the total number of worker",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:94479,guid,guide,94479,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['guid'],['guide']
Usability,"le and; filtering using :py:meth:`~hail.KeyTable.filter`. >>> rel = vds.pc_relate(5, 0.01, min_kinship=0.1). **Method**. The traditional estimator for kinship between a pair of individuals; :math:`i` and :math:`j`, sharing the set :math:`S_{ij}` of; single-nucleotide variants, from a population with allele frequencies; :math:`p_s`, is given by:. .. math::. \\widehat{\phi_{ij}} := \\frac{1}{|S_{ij}|}\\sum_{s \in S_{ij}}\\frac{(g_{is} - 2 p_s) (g_{js} - 2 p_s)}{4 * \sum_{s \in S_{ij} p_s (1 - p_s)}}. This estimator is true under the model that the sharing of common; (relative to the population) alleles is not very informative to; relatedness (because they're common) and the sharing of rare alleles; suggests a recent common ancestor from which the allele was inherited by; descent. When multiple ancestry groups are mixed in a sample, this model breaks; down. Alleles that are rare in all but one ancestry group are treated as; very informative to relatedness. However, these alleles are simply; markers of the ancestry group. The PC-Relate method corrects for this; situation and the related situation of admixed individuals. PC-Relate slightly modifies the usual estimator for relatedness:; occurences of population allele frequency are replaced with an; ""individual-specific allele frequency"". This modification allows the; method to correctly weight an allele according to an individual's unique; ancestry profile. The ""individual-specific allele frequency"" at a given genetic locus is; modeled by PC-Relate as a linear function of their first ``k`` principal; component coordinates. As such, the efficacy of this method rests on two; assumptions:. - an individual's first ``k`` principal component coordinates fully; describe their allele-frequency-relevant ancestry, and. - the relationship between ancestry (as described by principal; component coordinates) and population allele frequency is linear. The estimators for kinship, and identity-by-descent zero, one, and two; follow. Let:.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:170514,simpl,simply,170514,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simply']
Usability,"le.; ; **Examples**; ; Take the first ten rows:; ; >>> first10 = kt1.take(10); ; **Notes**; ; This method does not need to look at all the data, and ; allows for fast queries of the start of the table.; ; :param int n: Number of rows to take.; ; :return: Rows from the start of the table.; :rtype: list of :class:`.~hail.representation.Struct`; """""". return [self.schema._convert_to_py(r) for r in self._jkt.take(n)]. [docs] @handle_py4j; @typecheck_method(name=strlike); def indexed(self, name='index'):; """"""Add the numerical index of each row as a new column. **Examples**. >>> ind_kt = kt1.indexed(). **Notes**. This method returns a table with a new column whose name is; given by the ``name`` parameter, with type ``Long``. The value; of this column is the numerical index of each row, starting; from 0. Methods that respect ordering (like :py:meth:`.KeyTable.take`; or :py:meth:`.KeyTable.export` will return rows in order. This method is helpful for creating a unique integer index for rows; of a table, so that more complex types can be encoded as a simple; number. :param str name: Name of index column. :return: Table with a new index column.; :rtype: :class:`.KeyTable`; """""". return KeyTable(self.hc, self._jkt.indexed(name)). [docs] @typecheck_method(n=integral,; truncate_to=nullable(integral),; print_types=bool); def show(self, n=10, truncate_to=None, print_types=True):; """"""Show the first few rows of the table in human-readable format. **Examples**. Show, with default parameters (10 rows, no truncation, and column types):. >>> kt1.show(). Truncate long columns to 25 characters and only write 5 rows:. >>> kt1.show(5, truncate_to=25). **Notes**. If the ``truncate_to`` argument is ``None``, then no truncation will; occur. This is the default behavior. An integer argument will truncate; each cell to the specified number of characters. :param int n: Number of rows to show. :param truncate_to: Truncate columns to the desired number of characters.; :type truncate_to: int or None. ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/keytable.html:35330,simpl,simple,35330,docs/0.1/_modules/hail/keytable.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/keytable.html,1,['simpl'],['simple']
Usability,"le.filter_cols(); MatrixTable.filter_entries(). Filter methods take a BooleanExpression argument. These expressions; are generated by applying computations to the fields of the matrix table:; >>> filt_mt = mt.filter_rows(hl.len(mt.alleles) == 2). >>> filt_mt = mt.filter_cols(hl.agg.mean(mt.GQ) < 20). >>> filt_mt = mt.filter_entries(mt.DP < 5). These expressions can compute arbitrarily over the data: the MatrixTable.filter_cols(); example above aggregates entries per column of the matrix table to compute the; mean of the GQ field, and removes columns where the result is smaller than 20.; Annotate; MatrixTable has four methods to add new fields or update existing fields:. MatrixTable.annotate_globals(); MatrixTable.annotate_rows(); MatrixTable.annotate_cols(); MatrixTable.annotate_entries(). Annotate methods take keyword arguments where the key is the name of the new; field to add and the value is an expression specifying what should be added.; The simplest example is adding a new global field foo that just contains the constant; 5.; >>> mt_new = mt.annotate_globals(foo = 5); >>> print(mt_new.globals.dtype.pretty()); struct {; foo: int32; }. Another example is adding a new row field call_rate which computes the fraction; of non-missing entries GT per row:; >>> mt_new = mt.annotate_rows(call_rate = hl.agg.fraction(hl.is_defined(mt.GT))). Annotate methods are also useful for updating values. For example, to update the; GT entry field to be missing if GQ is less than 20, we can do the following:; >>> mt_new = mt.annotate_entries(GT = hl.or_missing(mt.GQ >= 20, mt.GT)). Select; Select is used to create a new schema for a dimension of the matrix table. Key; fields are always preserved even when not selected. For example, following the; matrix table schemas from importing a VCF file (shown above),; to create a hard calls dataset where each entry only contains the GT field; we can do the following:; >>> mt_new = mt.select_entries('GT'); >>> print(mt_new.entry.dtype.pretty());",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/overview/matrix_table-1.html:6441,simpl,simplest,6441,docs/0.2/overview/matrix_table-1.html,https://hail.is,https://hail.is/docs/0.2/overview/matrix_table-1.html,2,['simpl'],['simplest']
Usability,"lf._rg is None:; self._rg = hl.default_reference(); return self._rg. def _pretty(self, b, indent, increment):; b.append('locus<{}>'.format(escape_parsable(self.reference_genome.name))). def _convert_from_json(self, x, _should_freeze: bool = False) -> genetics.Locus:; return genetics.Locus(x['contig'], x['position'], reference_genome=self.reference_genome). def _convert_to_json(self, x):; return {'contig': x.contig, 'position': x.position}. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> genetics.Locus:; as_struct = tlocus.struct_repr._convert_from_encoding(byte_reader); return genetics.Locus(as_struct.contig, as_struct.pos, self.reference_genome). def _convert_to_encoding(self, byte_writer, value: genetics.Locus):; tlocus.struct_repr._convert_to_encoding(byte_writer, {'contig': value.contig, 'pos': value.position}). def unify(self, t):; return isinstance(t, tlocus) and self.reference_genome == t.reference_genome. def subst(self):; return self. def clear(self):; pass. def _get_context(self):; return HailTypeContext(references={self.reference_genome.name}). [docs]class tinterval(HailType):; """"""Hail type for intervals of ordered values. In Python, these are represented by :class:`.Interval`. Parameters; ----------; point_type: :class:`.HailType`; Interval point type. See Also; --------; :class:`.IntervalExpression`, :class:`.Interval`, :func:`.interval`,; :func:`.parse_locus_interval`; """""". @typecheck_method(point_type=hail_type); def __init__(self, point_type):; self._point_type = point_type; self._struct_repr = tstruct(start=point_type, end=point_type, includes_start=hl.tbool, includes_end=hl.tbool); super(tinterval, self).__init__(). @property; def point_type(self):; """"""Interval point type. Returns; -------; :class:`.HailType`; Interval point type.; """"""; return self._point_type. def _traverse(self, obj, f):; if f(self, obj):; self.point_type._traverse(obj.start, f); self.point_type._traverse(obj.end, f). def _typecheck_one_level(self, ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:48310,clear,clear,48310,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"like indexing.; Aggregables support map and filter. Like sum, max, etc. on arrays,; aggregables support operations which we call “aggregators” that operate; on the entire aggregable collection and produce a summary or derived; statistic. See the; documentation for a; complete list of aggregators.; Aggregables are available in expressions on various methods on; VariantDataset.; Above,; query_genotypes; exposes the aggregable gs: Aggregable[Genotype] which is the; collection of all the genotypes in the dataset.; First, we map the genotypes to their GQ values. Then, we use the; stats() aggregator to compute a struct with information like mean; and standard deviation. We can see the other values in the struct; produced as well:. In [25]:. pprint(vds.query_genotypes('gs.map(g => g.gq).stats()')). {u'max': 99.0,; u'mean': 30.682263230349086,; u'min': 0.0,; u'nNotMissing': 10776455L,; u'stdev': 26.544770565260993,; u'sum': 330646029.00001156}. Count¶; The count aggregator is pretty simple - it counts the number of; elements in the aggregable. In [26]:. vds.query_genotypes('gs.count()'). Out[26]:. 10961000L. In [27]:. vds.num_samples * vds.count_variants(). Out[27]:. 10961000L. There’s one genotype per sample per variant, so the count of gs is; equal to the number of samples times the number of variants, or about 11; million. How can we make this more useful? With filter!. In [28]:. vds.query_genotypes('gs.filter(g => g.isHet()).count()'). Out[28]:. 2583309L. Of the 11 million genotypes in the dataset, about 2.5M are heterozygous.; What about combining sample annotations with genotype information? How; many heterozygote genotypes are found in the American samples? A simple; way to implement this is by filtering to American samples first and then; running the same query. In [29]:. (vds.filter_samples_expr('sa.metadata.SuperPopulation == ""AMR""'); .query_genotypes('gs.filter(g => g.isHet()).count()')). Out[29]:. 754850L. The next cell is a bit tricky - aggregables have an extra",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/expression-language-part-2.html:12145,simpl,simple,12145,docs/0.1/tutorials/expression-language-part-2.html,https://hail.is,https://hail.is/docs/0.1/tutorials/expression-language-part-2.html,1,['simpl'],['simple']
Usability,"llion rows and twenty partitions:; >>> range_kt = KeyTable.range(1000000, num_partitions=20). Notes; The resulting table has one column:. index (Int) – Unique row index from 0 until n. Parameters:; n (int) – Number of rows.; num_partitions (int or None) – Number of partitions. Return type:KeyTable. rename(column_names)[source]¶; Rename columns of key table.; column_names can be either a list of new names or a dict; mapping old names to new names. If column_names is a list,; its length must be the number of columns in this KeyTable.; Examples; Rename using a list:; >>> kt2.rename(['newColumn1', 'newColumn2', 'newColumn3']). Rename using a dict:; >>> kt2.rename({'A' : 'C1'}). Parameters:column_names – list of new column names or a dict mapping old names to new names. Returns:Key table with renamed columns. Return type:KeyTable. repartition(n, shuffle=True)[source]¶; Change the number of distributed partitions. Warning; When shuffle is False, repartition can only decrease the number of partitions and simply combines adjacent partitions to achieve the desired number. It does not attempt to rebalance and so can produce a heavily unbalanced dataset. An unbalanced dataset can be inefficient to operate on because the work is not evenly distributed across partitions. Parameters:; n (int) – Desired number of partitions.; shuffle (bool) – Whether to shuffle or naively coalesce. Return type:KeyTable. same(other)[source]¶; Test whether two key tables are identical.; Examples; >>> if kt1.same(kt2):; ... print(""KeyTables are the same!""). Parameters:other (KeyTable) – key table to compare against. Return type:bool. schema¶; Table schema.; Examples; >>> print(kt1.schema). The pprint module can be used to print the schema in a more human-readable format:; >>> from pprint import pprint; >>> pprint(kt1.schema). Return type:TStruct. select(column_names)[source]¶; Select a subset of columns.; Examples; Assume kt1 is a KeyTable with three columns: C1, C2 and; C3.; Select/drop columns:; >>",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.KeyTable.html:25906,simpl,simply,25906,docs/0.1/hail.KeyTable.html,https://hail.is,https://hail.is/docs/0.1/hail.KeyTable.html,1,['simpl'],['simply']
Usability,"loat32(HailType):; """"""Hail type for 32-bit floating point numbers. In Python, these are represented as :obj:`float`.; """""". def __init__(self):; super(_tfloat32, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not is_float32(annotation):; raise TypeError(""type 'float32' expected Python 'float', but found type '%s'"" % type(annotation)). def __str__(self):; return ""float32"". def _eq(self, other):; return isinstance(other, _tfloat32). def _parsable_string(self):; return ""Float32"". def _convert_from_json(self, x, _should_freeze: bool = False):; return float(x). def _convert_to_json(self, x):; if math.isfinite(x):; return x; else:; return str(x). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> float:; return byte_reader.read_float32(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_float32(value). def unify(self, t):; return t == tfloat32. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float32. def _byte_size(self):; return 4. class _tfloat64(HailType):; """"""Hail type for 64-bit floating point numbers. In Python, these are represented as :obj:`float`.; """""". def __init__(self):; super(_tfloat64, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not is_float64(annotation):; raise TypeError(""type 'float64' expected Python 'float', but found type '%s'"" % type(annotation)). def __str__(self):; return ""float64"". def _eq(self, other):; return isinstance(other, _tfloat64). def _parsable_string(self):; return ""Float64"". def _convert_from_json(self, x, _should_freeze: bool = False):; return float(x). def _convert_to_json(self, x):; if math.isfinite(x):; return x; else:; return str(x). def unify(self, t):; return t == tfloat64. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float64. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = Fals",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:10772,clear,clear,10772,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"lue):; byte_writer.write_float32(value). def unify(self, t):; return t == tfloat32. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float32. def _byte_size(self):; return 4. class _tfloat64(HailType):; """"""Hail type for 64-bit floating point numbers. In Python, these are represented as :obj:`float`.; """""". def __init__(self):; super(_tfloat64, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not is_float64(annotation):; raise TypeError(""type 'float64' expected Python 'float', but found type '%s'"" % type(annotation)). def __str__(self):; return ""float64"". def _eq(self, other):; return isinstance(other, _tfloat64). def _parsable_string(self):; return ""Float64"". def _convert_from_json(self, x, _should_freeze: bool = False):; return float(x). def _convert_to_json(self, x):; if math.isfinite(x):; return x; else:; return str(x). def unify(self, t):; return t == tfloat64. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float64. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> float:; return byte_reader.read_float64(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_float64(value). def _byte_size(self):; return 8. class _tstr(HailType):; """"""Hail type for text strings. In Python, these are represented as strings.; """""". def __init__(self):; super(_tstr, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation and not isinstance(annotation, str):; raise TypeError(""type 'str' expected Python 'str', but found type '%s'"" % type(annotation)). def __str__(self):; return ""str"". def _eq(self, other):; return isinstance(other, _tstr). def _parsable_string(self):; return ""String"". def unify(self, t):; return t == tstr. def subst(self):; return self. def clear(self):; pass. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> str:; length = byte_reader.read_int3",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:11646,clear,clear,11646,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"m and writes to the same path. QoB; also now respects the user’s configuration of; disable_progress_bar. When disable_progress_bar is; unspecified, QoB only disables the progress bar for non-interactive; sessions.; (#12517) Fix a; performance regression that appears when using hl.split_multi_hts; among other methods. Version 0.2.105; Released 2022-10-31 🎃. New Features. (#12293) Added; support for hail.MatrixTables to hail.ggplot. Bug Fixes. (#12384) Fixed a; critical bug that disabled tree aggregation and scan executions in; 0.2.104, leading to out-of-memory errors.; (#12265) Fix; long-standing bug wherein hl.agg.collect_as_set and; hl.agg.counter error when applied to types which, in Python, are; unhashable. For example, hl.agg.counter(t.list_of_genes) will not; error when t.list_of_genes is a list. Instead, the counter; dictionary will use FrozenList keys from the frozenlist; package. Version 0.2.104; Release 2022-10-19. New Features. (#12346): Introduced; new progress bars which include total time elapsed and look cool. Version 0.2.103; Release 2022-10-18. Bug Fixes. (#12305): Fixed a; rare crash reading tables/matrixtables with _intervals. Version 0.2.102; Released 2022-10-06. New Features. (#12218) Missing; values are now supported in primitive columns in Table.to_pandas.; (#12254); Cross-product-style legends for data groups have been replaced with; factored ones (consistent with ggplot2’s implementation) for; hail.ggplot.geom_point, and support has been added for custom; legend group labels.; (#12268); VariantDataset now implements union_rows for combining; datasets with the same samples but disjoint variants. Bug Fixes. (#12278) Fixed bug; made more likely by 0.2.101 in which Hail errors when interacting; with a NumPy integer or floating point type.; (#12277) Fixed bug; in reading tables/matrixtables with partition intervals that led to; error or segfault. Version 0.2.101; Released 2022-10-04. New Features. (#12218) Support; missing values in pr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:43972,progress bar,progress bars,43972,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['progress bar'],['progress bars']
Usability,"me to key table. **Examples**. >>> kt = KeyTable.from_dataframe(df) # doctest: +SKIP. **Notes**. Spark SQL data types are converted to Hail types as follows:. .. code-block:: text. BooleanType => Boolean; IntegerType => Int; LongType => Long; FloatType => Float; DoubleType => Double; StringType => String; BinaryType => Binary; ArrayType => Array; StructType => Struct. Unlisted Spark SQL data types are currently unsupported.; ; :param df: PySpark DataFrame.; :type df: ``DataFrame``; ; :param key: Key column(s).; :type key: str or list of str. :return: Key table constructed from the Spark SQL DataFrame.; :rtype: :class:`.KeyTable`; """""". return KeyTable(Env.hc(), Env.hail().keytable.KeyTable.fromDF(Env.hc()._jhc, df._jdf, wrap_to_list(key))). [docs] @handle_py4j; @typecheck_method(n=integral,; shuffle=bool); def repartition(self, n, shuffle=True):; """"""Change the number of distributed partitions.; ; .. warning ::. When `shuffle` is `False`, `repartition` can only decrease the number of partitions and simply combines adjacent partitions to achieve the desired number. It does not attempt to rebalance and so can produce a heavily unbalanced dataset. An unbalanced dataset can be inefficient to operate on because the work is not evenly distributed across partitions.; ; :param int n: Desired number of partitions. :param bool shuffle: Whether to shuffle or naively coalesce.; ; :rtype: :class:`.KeyTable` ; """""". return KeyTable(self.hc, self._jkt.repartition(n, shuffle)). [docs] @staticmethod; @handle_py4j; @typecheck(path=strlike,; quantitative=bool,; delimiter=strlike,; missing=strlike); def import_fam(path, quantitative=False, delimiter='\\\\s+', missing='NA'):; """"""Import PLINK .fam file into a key table. **Examples**. Import case-control phenotype data from a tab-separated `PLINK .fam; <https://www.cog-genomics.org/plink2/formats#fam>`_ file into sample; annotations:. >>> fam_kt = KeyTable.import_fam('data/myStudy.fam'). In Hail, unlike PLINK, the user must *explicitly* disti",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/keytable.html:31090,simpl,simply,31090,docs/0.1/_modules/hail/keytable.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/keytable.html,1,['simpl'],['simply']
Usability,"mple_ids = jiterable_to_list(self._jvds.sampleIds()); return self._sample_ids. @property; @handle_py4j; def sample_annotations(self):; """"""Return a dict of sample annotations. The keys of this dictionary are the sample IDs (strings).; The values are sample annotations. :return: dict; """""". if self._sample_annotations is None:; zipped_annotations = Env.jutils().iterableToArrayList(; self._jvds.sampleIdsAndAnnotations(); ); r = {}; for element in zipped_annotations:; r[element._1()] = self.sample_schema._convert_to_py(element._2()); self._sample_annotations = r; return self._sample_annotations. [docs] @handle_py4j; def num_partitions(self):; """"""Number of partitions. **Notes**. The data in a variant dataset is divided into chunks called partitions, which may be stored together or across a network, so that each partition may be read and processed in parallel by available cores. Partitions are a core concept of distributed computation in Spark, see `here <http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds>`__ for details. :rtype: int; """""". return self._jvds.nPartitions(). @property; @handle_py4j; def num_samples(self):; """"""Number of samples. :rtype: int; """""". if self._num_samples is None:; self._num_samples = self._jvds.nSamples(); return self._num_samples. [docs] @handle_py4j; def count_variants(self):; """"""Count number of variants in variant dataset. :rtype: long; """""". return self._jvds.countVariants(). [docs] @handle_py4j; def was_split(self):; """"""True if multiallelic variants have been split into multiple biallelic variants. Result is True if :py:meth:`~hail.VariantDataset.split_multi` or :py:meth:`~hail.VariantDataset.filter_multi` has been called on this variant dataset,; or if the variant dataset was imported with :py:meth:`~hail.HailContext.import_plink`, :py:meth:`~hail.HailContext.import_gen`,; or :py:meth:`~hail.HailContext.import_bgen`, or if the variant dataset was simulated with :py:meth:`~hail.HailContext.balding_ni",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:5001,guid,guide,5001,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['guid'],['guide']
Usability,"n or R; or Scala. While the syntax is different, programming experience will; certainly translate. We have built the expression language with the hope; that even people new to programming are able to use it to explore; genetic data, even if this means copying motifs and expressions found on; places like Hail discussion forum.; For learning purposes, HailContext contains the method; eval_expr_typed.; This method takes a Python string of Hail expr code, evaluates it, and; returns a tuple with the result and the type. We’ll be using this method; throughout the expression language tutorial. Hail Types¶; The Hail expression language is strongly typed, meaning that every; expression has an associated type.; Hail defines the following types:; Primitives: - Int -; Double -; Float -; Long -; Boolean -; String; Compound Types: - Array[T] -; Set[T] - Dict[K,; V] -; Aggregable[T] -; Struct; Genetic Types: - Variant -; Locus -; AltAllele -; Interval -; Genotype -; Call. Primitive Types¶; Let’s start with simple primitive types. Primitive types are a basic; building block for any programming language - these are things like; numbers and strings and boolean values.; Hail expressions are passed as Python strings to Hail methods. In [2]:. # the Boolean literals are 'true' and 'false'; hc.eval_expr_typed('true'). Out[2]:. (True, Boolean). The return value is True, not true. Why? When values are; returned by Hail methods, they are returned as the corresponding Python; value. In [3]:. hc.eval_expr_typed('123'). Out[3]:. (123, Int). In [4]:. hc.eval_expr_typed('123.45'). Out[4]:. (123.45, Double). String literals are denoted with double-quotes. The ‘u’ preceding the; printed result denotes a unicode string, and is safe to ignore. In [5]:. hc.eval_expr_typed('""Hello, world""'). Out[5]:. (u'Hello, world', String). Primitive types support all the usual operations you’d expect. For; details, refer to the documentation on; operators and; types. Here are some examples. In [6]:. hc.eval_expr_typ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/introduction-to-the-expression-language.html:3322,simpl,simple,3322,docs/0.1/tutorials/introduction-to-the-expression-language.html,https://hail.is,https://hail.is/docs/0.1/tutorials/introduction-to-the-expression-language.html,1,['simpl'],['simple']
Usability,"n, shuffle=True) -> 'Table':; """"""Change the number of partitions. Examples; --------. Repartition to 500 partitions:. >>> table_result = table1.repartition(500). Notes; -----. Check the current number of partitions with :meth:`.n_partitions`. The data in a dataset is divided into chunks called partitions, which; may be stored together or across a network, so that each partition may; be read and processed in parallel by available cores. When a table with; :math:`M` rows is first imported, each of the :math:`k` partitions will; contain about :math:`M/k` of the rows. Since each partition has some; computational overhead, decreasing the number of partitions can improve; performance after significant filtering. Since it's recommended to have; at least 2 - 4 partitions per core, increasing the number of partitions; can allow one to take advantage of more cores. Partitions are a core; concept of distributed computation in Spark, see `their documentation; <http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds>`__; for details. When ``shuffle=True``, Hail does a full shuffle of the data; and creates equal sized partitions. When ``shuffle=False``,; Hail combines existing partitions to avoid a full shuffle.; These algorithms correspond to the `repartition` and; `coalesce` commands in Spark, respectively. In particular,; when ``shuffle=False``, ``n_partitions`` cannot exceed current; number of partitions. Parameters; ----------; n : int; Desired number of partitions.; shuffle : bool; If ``True``, use full shuffle to repartition. Returns; -------; :class:`.Table`; Repartitioned table.; """"""; if hl.current_backend().requires_lowering:; tmp = hl.utils.new_temp_file(). if len(self.key) == 0:; uid = Env.get_uid(); tmp2 = hl.utils.new_temp_file(); self.checkpoint(tmp2); ht = hl.read_table(tmp2).add_index(uid).key_by(uid); ht.checkpoint(tmp); return hl.read_table(tmp, _n_partitions=n).key_by().drop(uid); else:; # checkpoint rather than write to ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:93033,guid,guide,93033,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['guid'],['guide']
Usability,"n. We can see the other values in the struct; produced as well:. In [25]:. pprint(vds.query_genotypes('gs.map(g => g.gq).stats()')). {u'max': 99.0,; u'mean': 30.682263230349086,; u'min': 0.0,; u'nNotMissing': 10776455L,; u'stdev': 26.544770565260993,; u'sum': 330646029.00001156}. Count¶; The count aggregator is pretty simple - it counts the number of; elements in the aggregable. In [26]:. vds.query_genotypes('gs.count()'). Out[26]:. 10961000L. In [27]:. vds.num_samples * vds.count_variants(). Out[27]:. 10961000L. There’s one genotype per sample per variant, so the count of gs is; equal to the number of samples times the number of variants, or about 11; million. How can we make this more useful? With filter!. In [28]:. vds.query_genotypes('gs.filter(g => g.isHet()).count()'). Out[28]:. 2583309L. Of the 11 million genotypes in the dataset, about 2.5M are heterozygous.; What about combining sample annotations with genotype information? How; many heterozygote genotypes are found in the American samples? A simple; way to implement this is by filtering to American samples first and then; running the same query. In [29]:. (vds.filter_samples_expr('sa.metadata.SuperPopulation == ""AMR""'); .query_genotypes('gs.filter(g => g.isHet()).count()')). Out[29]:. 754850L. The next cell is a bit tricky - aggregables have an extra “context” that; they carry around. We can actually access the sample, sample; annotations, variant, and variant annotations inside of operations on; gs. We don’t need to filter samples first, we can do it inside the; query:. In [30]:. vds.query_genotypes('gs.filter(g => g.isHet() && sa.metadata.SuperPopulation == ""AMR"").count()'). Out[30]:. 754850L. Here’s an example where we use the variant annotations to count the; number of heterozygous genotypes in Americans at rare loci. In [31]:. vds.query_genotypes('''gs.filter(g => g.isHet(); && sa.metadata.SuperPopulation == ""AMR""; && va.qc.AF < 0.01).count()'''). Out[31]:. 1879L. Sum¶; The sum aggregator can be used ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/expression-language-part-2.html:12842,simpl,simple,12842,docs/0.1/tutorials/expression-language-part-2.html,https://hail.is,https://hail.is/docs/0.1/tutorials/expression-language-part-2.html,1,['simpl'],['simple']
Usability,"ng a public 1000 genomes VCF to; about 50 MB. In [5]:. vds = hc.read('data/1kg.vds'). Getting to know our data¶; It’s important to have easy ways to slice, dice, query, and summarize a; dataset. Some of these methods are demonstrated below.; The; summarize; method is useful for providing a broad overview of the data contained in; a dataset. In [6]:. vds.summarize().report(). Samples: 1000; Variants: 10961; Call Rate: 0.983163; Contigs: ['X', '12', '8', '19', '4', '15', '11', '9', '22', '13', '16', '5', '10', '21', '6', '1', '17', '14', '20', '2', '18', '7', '3']; Multiallelics: 0; SNPs: 10961; MNPs: 0; Insertions: 0; Deletions: 0; Complex Alleles: 0; Star Alleles: 0; Max Alleles: 2. The; query_variants; method is the first time we’ll see the Hail expression; language. The expression; language allows for a variety of incredibly expressive queries and; computations, but is probably the most complex part of Hail. See the; pair of tutorials on the expression language to learn more!; Here, we can use query_variants to pull out 5 variants to see what; they look like. In [7]:. vds.query_variants('variants.take(5)'). Out[7]:. [Variant(contig=1, start=904165, ref=G, alts=[AltAllele(ref=G, alt=A)]),; Variant(contig=1, start=909917, ref=G, alts=[AltAllele(ref=G, alt=A)]),; Variant(contig=1, start=986963, ref=C, alts=[AltAllele(ref=C, alt=T)]),; Variant(contig=1, start=1563691, ref=T, alts=[AltAllele(ref=T, alt=G)]),; Variant(contig=1, start=1707740, ref=T, alts=[AltAllele(ref=T, alt=G)])]. There are often several ways to do something in Hail. Here are two ways; to peek at the first few sample IDs:. In [8]:. vds.query_samples('samples.take(5)'). Out[8]:. [u'HG00096', u'HG00097', u'HG00099', u'HG00100', u'HG00101']. In [9]:. vds.sample_ids[:5]. Out[9]:. [u'HG00096', u'HG00097', u'HG00099', u'HG00100', u'HG00101']. There’s a similar interface for looking at the genotypes in a dataset.; We use; query_genotypes; to look at the first few genotype calls. In [10]:. vds.query_genotypes",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/hail-overview.html:3998,learn,learn,3998,docs/0.1/tutorials/hail-overview.html,https://hail.is,https://hail.is/docs/0.1/tutorials/hail-overview.html,1,['learn'],['learn']
Usability,"nge_table(5, 5).annotate(x=hl.rand_unif(0, 1, seed=0)); >>> table.x.collect(); [0.5820244750020055,; 0.33150686392731943,; 0.20526631289173847,; 0.6964416913998893,; 0.6092952493383876]. However, moving it to a sufficiently different context will produce different; results:; >>> table = hl.utils.range_table(7, 1); >>> table = table.filter(table.idx >= 2).annotate(x=hl.rand_unif(0, 1, seed=0)); >>> table.x.collect(); [0.20526631289173847,; 0.6964416913998893,; 0.6092952493383876,; 0.6404026938964441,; 0.5550464170615771]. In fact, in this case we are getting the tail of; >>> table = hl.utils.range_table(7, 1).annotate(x=hl.rand_unif(0, 1, seed=0)); >>> table.x.collect(); [0.5820244750020055,; 0.33150686392731943,; 0.20526631289173847,; 0.6964416913998893,; 0.6092952493383876,; 0.6404026938964441,; 0.5550464170615771]. Reproducibility across sessions; The values of a random function are fully determined by three things:. The seed set on the function itself. If not specified, these are simply; generated sequentially.; Some data uniquely identifying the current position within a larger context,; e.g. Table, MatrixTable, or array. For instance, in a range_table(),; this data is simply the row id, as suggested by the previous examples.; The global seed. This is fixed for the entire session, and can only be set; using the global_seed argument to init(). To ensure reproducibility within a single hail session, it suffices to either; manually set the seed on every random function call, or to call; reset_global_randomness() at the start of a pipeline, which resets the; counter used to generate seeds.; >>> hl.reset_global_randomness(); >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])); [0.9828239225846387, 0.49094525115847415]. >>> hl.reset_global_randomness(); >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])); [0.9828239225846387, 0.49094525115847415]. To ensure reproducibility across sessions, one must in addition specify the; global_seed in init(",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/random.html:4219,simpl,simply,4219,docs/0.2/functions/random.html,https://hail.is,https://hail.is/docs/0.2/functions/random.html,1,['simpl'],['simply']
Usability,"np_dtype} could not be converted to a hail type.""). def dtypes_from_pandas(pd_dtype):; if type(pd_dtype) == pd.StringDtype:; return hl.tstr; elif pd_dtype == np.int64:; return hl.tint64; elif pd_dtype == np.uint64:; # Hail does *not* support unsigned integers but the next condition,; # pd.api.types.is_integer_dtype(pd_dtype) would return true on unsigned 64-bit ints; return None; # For some reason pandas doesn't have `is_int32_dtype`, so we use `is_integer_dtype` if first branch failed.; elif pd.api.types.is_integer_dtype(pd_dtype):; return hl.tint32; elif pd_dtype == np.float32:; return hl.tfloat32; elif pd_dtype == np.float64:; return hl.tfloat64; elif pd_dtype == bool:; return hl.tbool; return None. class tvariable(HailType):; _cond_map: ClassVar = {; 'numeric': is_numeric,; 'int32': lambda x: x == tint32,; 'int64': lambda x: x == tint64,; 'float32': lambda x: x == tfloat32,; 'float64': lambda x: x == tfloat64,; 'locus': lambda x: isinstance(x, tlocus),; 'struct': lambda x: isinstance(x, tstruct),; 'union': lambda x: isinstance(x, tunion),; 'tuple': lambda x: isinstance(x, ttuple),; }. def __init__(self, name, cond):; self.name = name; self.cond = cond; self.condf = tvariable._cond_map[cond] if cond else None; self.box = Box.from_name(name). def unify(self, t):; if self.condf and not self.condf(t):; return False; return self.box.unify(t). def clear(self):; self.box.clear(). def subst(self):; return self.box.get(). def __str__(self):; s = '?' + self.name; if self.cond:; s = s + ':' + self.cond; return s. _old_printer = pprint.PrettyPrinter. class TypePrettyPrinter(pprint.PrettyPrinter):; def _format(self, object, stream, indent, allowance, context, level):; if isinstance(object, HailType):; stream.write(object.pretty(self._indent_per_level)); else:; return _old_printer._format(self, object, stream, indent, allowance, context, level). pprint.PrettyPrinter = TypePrettyPrinter # monkey-patch pprint. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:56434,clear,clear,56434,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,4,['clear'],['clear']
Usability,"ormalized_gt = hl.or_else((mt.__gt - mt.__mean_gt) / mt.__hwe_scaled_std_dev, 0.0); return normalized_gt. [docs]@typecheck(call_expr=expr_call, k=int, compute_loadings=bool); def hwe_normalized_pca(call_expr, k=10, compute_loadings=False) -> Tuple[List[float], Table, Table]:; r""""""Run principal component analysis (PCA) on the Hardy-Weinberg-normalized; genotype call matrix. Examples; --------. >>> eigenvalues, scores, loadings = hl.hwe_normalized_pca(dataset.GT, k=5). Notes; -----; This method specializes :func:`.pca` for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate are unnormalizable and removed before; evaluation. See :func:`.pca` for more details. Users of PLINK/GCTA should be aware that Hail computes the GRM slightly; differently with regard to missing data. In Hail, the; :math:`ij` entry of the GRM :math:`MM^T` is simply the dot product of rows; :math:`i` and :math:`j` of :math:`M`; in terms of :math:`C` it is. .. math::. \frac{1}{m}\sum_{l\in\mathcal{C}_i\cap\mathcal{C}_j}\frac{(C_{il}-2p_l)(C_{jl} - 2p_l)}{2p_l(1-p_l)}. where :math:`\mathcal{C}_i = \{l \mid C_{il} \text{ is non-missing}\}`. In; PLINK/GCTA the denominator :math:`m` is replaced with the number of terms in; the sum :math:`\lvert\mathcal{C}_i\cap\mathcal{C}_j\rvert`, i.e. the; number of variants where both samples have non-missing genotypes. While this; is arguably a better estimator of the true GRM (trading shrinkage for; noise), it has the drawback that one loses the clean interpretation of the; loadings and scores as features and projections. Separately, for the PCs PLINK/GCTA output the eigenvectors of the GRM, i.e.; the left singular vectors :math:`U_k` instead of the component scores; :math:`U_k S_k`. The scores have the advantage of representing true; projections of the data onto features with the variance of a score; reflecting the variance e",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/pca.html:2670,simpl,simply,2670,docs/0.2/_modules/hail/methods/pca.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html,2,['simpl'],['simply']
Usability,"ou mind.; """"""; context_name = f""context_{Env.get_uid()}""; ctype = contexts.dtype.element_type; cexpr = construct_expr(ir.Ref(context_name, ctype), ctype). globals_name = f""globals_{Env.get_uid()}""; globals = globals or hl.struct(); gexpr = construct_expr(ir.Ref(globals_name, globals.dtype), globals.dtype). body = ir.toStream(rowfn(cexpr, gexpr)._ir). if isinstance(partitions, int):; partitions = [Interval(hl.Struct(), hl.Struct(), True, True) for _ in range(partitions)]. partitioner = ir.Partitioner(partitions[0].point_type, partitions). return Table(ir.TableGen(ir.toStream(contexts._ir), globals._ir, context_name, globals_name, body, partitioner)). [docs] @typecheck_method(keys=oneof(str, expr_any), named_keys=expr_any); def key_by(self, *keys, **named_keys) -> 'Table':; """"""Key table by a new set of fields. Table keys control both the order of the rows in the table and the ability to join or; annotate one table with the information in another table. Examples; --------. Consider a simple unkeyed table. Its rows appear are guaranteed to appear in the same order; as they were in the source text file. >>> ht = hl.import_table('data/kt_example1.tsv', impute=True); >>> ht.show(); +-------+-------+-----+-------+-------+-------+-------+-------+; | ID | HT | SEX | X | Z | C1 | C2 | C3 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | int32 | int32 | str | int32 | int32 | int32 | int32 | int32 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | 1 | 65 | ""M"" | 5 | 4 | 2 | 50 | 5 |; | 2 | 72 | ""M"" | 6 | 3 | 2 | 61 | 1 |; | 3 | 70 | ""F"" | 7 | 3 | 10 | 81 | -5 |; | 4 | 60 | ""F"" | 8 | 2 | 11 | 90 | -10 |; +-------+-------+-----+-------+-------+-------+-------+-------+. Changing the key forces the rows to appear in ascending order. For this reason,; :meth:`.key_by` is a relatively expensive operation. It must sort the entire dataset. >>> ht = ht.key_by('HT'); >>> ht.show(); +-------+-------+-----+-------+-------+-------+-------+-------+; | ID |",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:21498,simpl,simple,21498,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['simpl'],['simple']
Usability,"oving it to a sufficiently different context will produce different; results:; >>> table = hl.utils.range_table(7, 1); >>> table = table.filter(table.idx >= 2).annotate(x=hl.rand_unif(0, 1, seed=0)); >>> table.x.collect(); [0.20526631289173847,; 0.6964416913998893,; 0.6092952493383876,; 0.6404026938964441,; 0.5550464170615771]. In fact, in this case we are getting the tail of; >>> table = hl.utils.range_table(7, 1).annotate(x=hl.rand_unif(0, 1, seed=0)); >>> table.x.collect(); [0.5820244750020055,; 0.33150686392731943,; 0.20526631289173847,; 0.6964416913998893,; 0.6092952493383876,; 0.6404026938964441,; 0.5550464170615771]. Reproducibility across sessions; The values of a random function are fully determined by three things:. The seed set on the function itself. If not specified, these are simply; generated sequentially.; Some data uniquely identifying the current position within a larger context,; e.g. Table, MatrixTable, or array. For instance, in a range_table(),; this data is simply the row id, as suggested by the previous examples.; The global seed. This is fixed for the entire session, and can only be set; using the global_seed argument to init(). To ensure reproducibility within a single hail session, it suffices to either; manually set the seed on every random function call, or to call; reset_global_randomness() at the start of a pipeline, which resets the; counter used to generate seeds.; >>> hl.reset_global_randomness(); >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])); [0.9828239225846387, 0.49094525115847415]. >>> hl.reset_global_randomness(); >>> hl.eval(hl.array([hl.rand_unif(0, 1), hl.rand_unif(0, 1)])); [0.9828239225846387, 0.49094525115847415]. To ensure reproducibility across sessions, one must in addition specify the; global_seed in init(). If not specified, the global seed is chosen; randomly. All documentation examples were computed using global_seed=0.; >>> hl.stop() ; >>> hl.init(global_seed=0) ; >>> hl.eval(hl.array([hl.rand_u",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/functions/random.html:4413,simpl,simply,4413,docs/0.2/functions/random.html,https://hail.is,https://hail.is/docs/0.2/functions/random.html,1,['simpl'],['simply']
Usability,"patible with Spark 2.0.x and 2.1.x.; Python 2.7 and Jupyter Notebooks. We recommend the free Anaconda distribution. Running Hail locally¶; Hail uploads distributions to Google Storage as part of our continuous integration suite.; You can download a pre-built distribution from the below links. Make sure you download the distribution that matches your Spark version!. Current distribution for Spark 2.0.2; Current distribution for Spark 2.1.0. Unzip the distribution after you download it. Next, edit and copy the below bash commands to set up the Hail; environment variables. You may want to add these to the appropriate dot-file (we recommend ~/.profile); so that you don’t need to rerun these commands in each new session.; Here, fill in the path to the un-tarred Spark package.; export SPARK_HOME=???. Here, fill in the path to the unzipped Hail distribution.; export HAIL_HOME=???; export PATH=$PATH:$HAIL_HOME/bin/. Once you’ve set up Hail, we recommend that you run the Python tutorials to get an overview of Hail; functionality and learn about the powerful query language. To try Hail out, run the below commands; to start a Jupyter Notebook server in the tutorials directory.; cd $HAIL_HOME/tutorials; jhail. You can now click on the “hail-overview” notebook to get started!. Building Hail from source¶. On a Debian-based Linux OS like Ubuntu, run:; $ sudo apt-get install g++ cmake. On Mac OS X, install Xcode, available through the App Store, for the C++ compiler. CMake can be downloaded from the CMake website or through Homebrew. To install with Homebrew, run; $ brew install cmake. The Hail source code. To clone the Hail repository using Git, run; $ git clone --branch 0.1 https://github.com/broadinstitute/hail.git; $ cd hail. You can also download the source code directly from Github.; You may also want to install Seaborn, a Python library for statistical data visualization, using conda install seaborn or pip install seaborn. While not technically necessary, Seaborn is used in t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/getting_started.html:1614,learn,learn,1614,docs/0.1/getting_started.html,https://hail.is,https://hail.is/docs/0.1/getting_started.html,1,['learn'],['learn']
Usability,"pieces of information, but this same pattern can be used to detect; effects of rare variation:. Count the number of heterozygous genotypes per gene by functional; category (synonymous, missense, or loss-of-function) to estimate; per-gene functional constraint; Count the number of singleton loss-of-function mutations per gene in; cases and controls to detect genes involved in disease. Eplilogue¶; Congrats! If you’ve made it this far, you’re perfectly primed to read; the Overview, look through the; Hail objects representing many; core concepts in genetics, and check out the many Hail functions defined; in the Python API. If you use Hail; for your own science, we’d love to hear from you on Gitter; chat or the discussion; forum.; There’s also a lot of functionality inside Hail that we didn’t get to in; this broad overview. Things like:. Flexible import and export to a variety of data and annotation; formats (VCF, BGEN, PLINK, JSON, TSV, …); Simulation; Burden tests; Kinship and pruning (IBD, GRM, RRM); Family-based tests and utilities; Distributed file system utilities; Interoperability with Python and Spark machine learning libraries; More!. For reference, here’s the full workflow to all tutorial endpoints; combined into one cell. It may take a minute! It’s doing a lot of work. In [60]:. table = hc.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample'); common_vds = (hc.read('data/1kg.vds'); .annotate_samples_table(table, root='sa'); .sample_qc(); .filter_samples_expr('sa.qc.dpMean >= 4 && sa.qc.callRate >= 0.97'); .filter_genotypes('''let ab = g.ad[1] / g.ad.sum() in; ((g.isHomRef && ab <= 0.1) ||; (g.isHet && ab >= 0.25 && ab <= 0.75) ||; (g.isHomVar && ab >= 0.9))'''); .variant_qc(); .filter_variants_expr('va.qc.AF > 0.01'); .ld_prune(memory_per_core=512, num_cores=4)). pca = common_vds.pca('sa.pca', k=5, eigenvalues='global.eigen'); pvals = (common_vds; .annotate_samples_table(pca.samples_table(), expr='sa.pca = table.pca'); .linreg('sa.CaffeineCons",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/hail-overview.html:30501,learn,learning,30501,docs/0.1/tutorials/hail-overview.html,https://hail.is,https://hail.is/docs/0.1/tutorials/hail-overview.html,1,['learn'],['learning']
Usability,"ps to 0/0; and 0/1. The genotype 1/2 maps to 0/1 and 0/1. The biallelic alt AD entry is just the multiallelic AD entry; corresponding to the alternate allele. The ref AD entry is the; sum of the other multiallelic entries. The biallelic DP is the same as the multiallelic DP. The biallelic PL entry for for a genotype g is the minimum; over PL entries for multiallelic genotypes that downcode to; g. For example, the PL for (A, T) at 0/1 is the minimum of the; PLs for 0/1 (50) and 1/2 (45), and thus 45. Fixing an alternate allele and biallelic variant, downcoding; gives a map from multiallelic to biallelic alleles and; genotypes. The biallelic AD entry for an allele is just the; sum of the multiallelic AD entries for alleles that map to; that allele. Similarly, the biallelic PL entry for a genotype; is the minimum over multiallelic PL entries for genotypes that; map to that genotype. By default, GQ is recomputed from PL. If ``propagate_gq=True``; is passed, the biallelic GQ field is simply the multiallelic; GQ field, that is, genotype qualities are unchanged. Here is a second example for a het non-ref. .. code-block:: text. A C,T 1/2:2,8,6:16:45:99,50,99,45,0,99. splits as. .. code-block:: text. A C 0/1:8,8:16:45:45,0,99; A T 0/1:10,6:16:50:50,0,99. **VCF Info Fields**. Hail does not split annotations in the info field. This means; that if a multiallelic site with ``info.AC`` value ``[10, 2]`` is; split, each split site will contain the same array ``[10,; 2]``. The provided allele index annotation ``va.aIndex`` can be used; to select the value corresponding to the split allele's; position:. >>> vds_result = (vds.split_multi(); ... .filter_variants_expr('va.info.AC[va.aIndex - 1] < 10', keep = False)). VCFs split by Hail and exported to new VCFs may be; incompatible with other tools, if action is not taken; first. Since the ""Number"" of the arrays in split multiallelic; sites no longer matches the structure on import (""A"" for 1 per; allele, for example), Hail will export t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:210023,simpl,simply,210023,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simply']
Usability,"r None, the batch/regions Hail configuration; variable is consulted. See examples above. If none of these variables are set, then jobs may; run in any region. ServiceBackend.supported_regions() lists the available regions.; gcs_bucket_allow_list (Optional[List[str]]) – A list of buckets that the ServiceBackend should be permitted to read from or write to, even if their; default policy is to use “cold” storage. Attributes. ANY_REGION; A special value that indicates a job may run in any region. Methods. _async_run; Execute a batch. supported_regions; Get the supported cloud regions. ANY_REGION: ClassVar[List[str]] = ['any_region']; A special value that indicates a job may run in any region. async _async_run(batch, dry_run, verbose, delete_scratch_on_exit, wait=True, open=False, disable_progress_bar=False, callback=None, token=None, **backend_kwargs); Execute a batch. Warning; This method should not be called directly. Instead, use batch.Batch.run(); and pass ServiceBackend specific arguments as key-word arguments. Parameters:. batch (Batch) – Batch to execute.; dry_run (bool) – If True, don’t execute code.; verbose (bool) – If True, print debugging output.; delete_scratch_on_exit (bool) – If True, delete temporary directories with intermediate files.; wait (bool) – If True, wait for the batch to finish executing before returning.; open (bool) – If True, open the UI page for the batch.; disable_progress_bar (bool) – If True, disable the progress bar.; callback (Optional[str]) – If not None, a URL that will receive at most one POST request; after the entire batch completes.; token (Optional[str]) – If not None, a string used for idempotency of batch submission. Return type:; Optional[Batch]. static supported_regions(); Get the supported cloud regions; Examples; >>> regions = ServiceBackend.supported_regions(). Returns:; A list of the supported cloud regions. Previous; Next . © Copyright 2024, Hail Team. Built with Sphinx using a; theme; provided by Read the Docs.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/api/backend/hailtop.batch.backend.ServiceBackend.html:5726,progress bar,progress bar,5726,docs/batch/api/backend/hailtop.batch.backend.ServiceBackend.html,https://hail.is,https://hail.is/docs/batch/api/backend/hailtop.batch.backend.ServiceBackend.html,2,['progress bar'],['progress bar']
Usability,"r i, t in enumerate(self.types):; which_missing_bit = i % 8; if which_missing_bit == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; answer.append(None); else:; field_decoded = t._convert_from_encoding(byte_reader, _should_freeze); answer.append(field_decoded). return tuple(answer). def _convert_to_encoding(self, byte_writer, value):; length = len(self); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8; for i, t in enumerate(self.types):; if not HailType._missing(value[i]):; t._convert_to_encoding(byte_writer, value[i]). def unify(self, t):; if not (isinstance(t, ttuple) and len(self.types) == len(t.types)):; return False; for t1, t2 in zip(self.types, t.types):; if not t1.unify(t2):; return False; return True. def subst(self):; return ttuple(*[t.subst() for t in self.types]). def clear(self):; for t in self.types:; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.types). def allele_pair(j: int, k: int):; assert j >= 0 and j <= 0xFFFF; assert k >= 0 and k <= 0xFFFF; return j | (k << 16). def allele_pair_sqrt(i):; k = int(math.sqrt(8 * float(i) + 1) / 2 - 0.5); assert k * (k + 1) // 2 <= i; j = i - k * (k + 1) // 2; # TODO another assert; return allele_pair(j, k). small_allele_pair = [; allele_pair(0, 0),; allele_pair(0, 1),; allele_pair(1, 1),; allele_pair(0, 2),; allele_pair(1, 2),; allele_pair(2, 2),; allele_pair(0, 3),; allele_pair(1, 3),; allele_pair(2, 3),; allele_pair(3, 3),; allele_pair(0, 4),; allele_pair(1, 4),; allele_pair(2, 4),; allele_pair(3, 4),; allele_pair(4, 4),; allele_pair(0, 5),; allele_pair(1, 5),; allele_pair(2, 5),; allele_pair(3, 5),; allele_pair(4, 5),; allele_pair(5, 5),; allele_pair(0, 6),; allele_pair(1, 6),; allele_pair(2, 6),; allele_pair(3, 6),; allele_pair(4, 6),; allele_pair(5, 6),; allele_pair(6, 6),; allele_pair(0, 7)",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:41716,clear,clear,41716,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"rElse(NA: Int, 2)'). Out[19]:. (2, Int). In [20]:. hc.eval_expr_typed('orMissing(true, 5)'). Out[20]:. (5, Int). In [21]:. hc.eval_expr_typed('orMissing(false, 5)'). Out[21]:. (None, Int). Let¶; You can assign a value to a variable with a let expression. Here is; an example. In [22]:. hc.eval_expr_typed('let a = 5 in a + 1'). Out[22]:. (6, Int). The variable, here a is only visible in the body of the let, the; expression following in. You can assign multiple variables. Variable; assignments are separated by and. Each variable is visible in the; right hand side of the following variables as well as the body of the; let. For example:. In [23]:. hc.eval_expr_typed('''; let a = 5; and b = a + 1; in a * b; '''). Out[23]:. (30, Int). Conditionals¶; Unlike other languages, conditionals in Hail return a value. The arms of; the conditional must have the same type. The predicate must be of type; Boolean. If the predicate is missing, the value of the entire; conditional is missing. Here are some simple examples. In [24]:. hc.eval_expr_typed('if (true) 1 else 2'). Out[24]:. (1, Int). In [25]:. hc.eval_expr_typed('if (false) 1 else 2'). Out[25]:. (2, Int). In [26]:. hc.eval_expr_typed('if (NA: Boolean) 1 else 2'). Out[26]:. (None, Int). The if and else branches need to return the same type. The below; expression is invalid. In [27]:. # Uncomment and run the below code to see the error message. # hc.eval_expr_typed('if (true) 1 else ""two""'). Compound Types¶; Hail has several compound types: -; Array[T] -; Set[T] - Dict[K,; V] -; Aggregable[T] -; Struct; T, K and V here mean any type, including other compound; types. Hail’s Array[T] objects are similar to Python’s lists, except; they must be homogenous: that is, each element must be of the same type.; Arrays are 0-indexed. Here are some examples of simple array; expressions.; Array literals are constructed with square brackets. In [28]:. hc.eval_expr_typed('[1, 2, 3, 4, 5]'). Out[28]:. ([1, 2, 3, 4, 5], Array[Int]). Arrays are inde",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/tutorials/introduction-to-the-expression-language.html:6772,simpl,simple,6772,docs/0.1/tutorials/introduction-to-the-expression-language.html,https://hail.is,https://hail.is/docs/0.1/tutorials/introduction-to-the-expression-language.html,1,['simpl'],['simple']
Usability,"ra1. On a Cloudera cluster, SPARK_HOME should be set as:; SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2,. On Cloudera, you can create an interactive Python shell using pyspark2:; $ pyspark2 --jars build/libs/hail-all-spark.jar \; --py-files build/distributions/hail-python.zip \; --conf spark.sql.files.openCostInBytes=1099511627776 \; --conf spark.sql.files.maxPartitionBytes=1099511627776 \; --conf spark.hadoop.parquet.block.size=1099511627776. Cloudera’s version of spark-submit is called spark2-submit. Running in the cloud¶; Google and Amazon offer optimized Spark performance; and exceptional scalability to many thousands of cores without the overhead; of installing and managing an on-prem cluster.; Hail publishes pre-built JARs for Google Cloud Platform’s Dataproc Spark; clusters. If you would prefer to avoid building Hail from source, learn how to; get started on Google Cloud Platform by reading this forum post. You; can use cloudtools to simplify using; Hail on GCP even further, including via interactive Jupyter notebooks (also discussed here). Building with other versions of Spark 2¶; Hail is compatible with Spark 2.0.x and 2.1.x. To build against Spark 2.1.0,; modify the above instructions as follows:. Set the Spark version in the gradle command; $ ./gradlew -Dspark.version=2.1.0 shadowJar. SPARK_HOME should point to an installation of the desired version of Spark, such as spark-2.1.0-bin-hadoop2.7. The version of the Py4J ZIP file in the hail alias must match the version in $SPARK_HOME/python/lib in your version of Spark. BLAS and LAPACK¶; Hail uses BLAS and LAPACK optimized linear algebra libraries. These should load automatically on recent versions of Mac OS X and Google Dataproc. On Linux, these must be explicitly installed; on Ubuntu 14.04, run; $ apt-get install libatlas-base-dev. If natives are not found, hail.log will contain the warnings; Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK; Failed to load implementation",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/getting_started.html:7066,simpl,simplify,7066,docs/0.1/getting_started.html,https://hail.is,https://hail.is/docs/0.1/getting_started.html,1,['simpl'],['simplify']
Usability,"rance.; (#11835) Add; hl.ggplot.geom_density which renders a plot of an approximation; of the probability density function of its argument. Bug fixes. (#11815) Fix; incorrectly missing entries in to_dense_mt at the position of ref; block END.; (#11828) Fix; hl.init to not ignore its sc argument. This bug was; introduced in 0.2.94.; (#11830) Fix an; error and relax a timeout which caused hailtop.aiotools.copy to; hang.; (#11778) Fix a; (different) error which could cause hangs in; hailtop.aiotools.copy. Version 0.2.94; Released 2022-04-26. Deprecation. (#11765) Deprecated; and removed linear mixed model functionality. Beta features. (#11782); hl.import_table is up to twice as fast for small tables. New features. (#11428); hailtop.batch.build_python_image now accepts a; show_docker_output argument to toggle printing docker’s output to; the terminal while building container images; (#11725); hl.ggplot now supports facet_wrap; (#11776); hailtop.aiotools.copy will always show a progress bar when; --verbose is passed. hailctl dataproc. (#11710) support; pass-through arguments to connect. Bug fixes. (#11792) Resolved; issue where corrupted tables could be created with whole-stage code; generation enabled. Version 0.2.93; Release 2022-03-27. Beta features. Several issues with the beta version of Hail Query on Hail Batch are; addressed in this release. Version 0.2.92; Release 2022-03-25. New features. (#11613) Add; hl.ggplot support for scale_fill_hue, scale_color_hue,; and scale_fill_manual, scale_color_manual. This allows for an; infinite number of discrete colors.; (#11608) Add all; remaining and all versions of extant public gnomAD datasets to the; Hail Annotation Database and Datasets API. Current as of March 23rd; 2022.; (#11662) Add the; weight aesthetic geom_bar. Beta features. This version of Hail includes all the necessary client-side; infrastructure to execute Hail Query pipelines on a Hail Batch; cluster. This effectively enables a “serverless” version",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/change_log.html:50081,progress bar,progress bar,50081,docs/0.2/change_log.html,https://hail.is,https://hail.is/docs/0.2/change_log.html,1,['progress bar'],['progress bar']
Usability,"reeze: bool = False) -> Union[dict, frozendict]:; # NB: We ensure the key is always frozen with a wrapper on the key_type in the _array_repr.; d = {}; length = byte_reader.read_int32(); for _ in range(length):; element = self._array_repr.element_type._convert_from_encoding(byte_reader, _should_freeze); d[element.key] = element.value. if _should_freeze:; return frozendict(d); return d. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); for k, v in value.items():; self._array_repr.element_type._convert_to_encoding(byte_writer, {'key': k, 'value': v}). def _propagate_jtypes(self, jtype):; self._key_type._add_jtype(jtype.keyType()); self._value_type._add_jtype(jtype.valueType()). def unify(self, t):; return isinstance(t, tdict) and self.key_type.unify(t.key_type) and self.value_type.unify(t.value_type). def subst(self):; return tdict(self._key_type.subst(), self._value_type.subst()). def clear(self):; self.key_type.clear(); self.value_type.clear(). def _get_context(self):; return HailTypeContext.union(self.key_type, self.value_type). [docs]class tstruct(HailType, Mapping):; """"""Hail type for structured groups of heterogeneous fields. In Python, these are represented as :class:`.Struct`. Hail's :class:`.tstruct` type is commonly used to compose types together to form nested; structures. Structs can contain any combination of types, and are ordered mappings; from field name to field type. Each field name must be unique. Structs are very common in Hail. Each component of a :class:`.Table` and :class:`.MatrixTable`; is a struct:. - :meth:`.Table.row`; - :meth:`.Table.globals`; - :meth:`.MatrixTable.row`; - :meth:`.MatrixTable.col`; - :meth:`.MatrixTable.entry`; - :meth:`.MatrixTable.globals`. Structs appear below the top-level component types as well. Consider the following join:. >>> new_table = table1.annotate(table2_fields = table2.index(table1.key)). This snippet adds a field to ``table1`` called ``table",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:29499,clear,clear,29499,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"ributed by variant with per-variant time complexity that is completely independent of the number of sample covariates and dominated by multiplication of the genotype vector :math:`v` by the matrix of eigenvectors :math:`U^T` as described below, which we accelerate with a sparse representation of :math:`v`. The matrix :math:`U^T` has size about :math:`8n^2` bytes and is currently broadcast to each Spark executor. For example, with 15k samples, storing :math:`U^T` consumes about 3.6GB of memory on a 16-core worker node with two 8-core executors. So for large :math:`n`, we recommend using a high-memory configuration such as ``highmem`` workers. **Linear mixed model**. :py:meth:`.lmmreg` estimates the genetic proportion of residual phenotypic variance (narrow-sense heritability) under a kinship-based linear mixed model, and then optionally tests each variant for association using the likelihood ratio test. Inference is exact. We first describe the sample-covariates-only model used to estimate heritability, which we simply refer to as the *global model*. With :math:`n` samples and :math:`c` sample covariates, we define:. - :math:`y = n \\times 1` vector of phenotypes; - :math:`X = n \\times c` matrix of sample covariates and intercept column of ones; - :math:`K = n \\times n` kinship matrix; - :math:`I = n \\times n` identity matrix; - :math:`\\beta = c \\times 1` vector of covariate coefficients; - :math:`\sigma_g^2 =` coefficient of genetic variance component :math:`K`; - :math:`\sigma_e^2 =` coefficient of environmental variance component :math:`I`; - :math:`\delta = \\frac{\sigma_e^2}{\sigma_g^2} =` ratio of environmental and genetic variance component coefficients; - :math:`h^2 = \\frac{\sigma_g^2}{\sigma_g^2 + \sigma_e^2} = \\frac{1}{1 + \delta} =` genetic proportion of residual phenotypic variance. Under a linear mixed model, :math:`y` is sampled from the :math:`n`-dimensional `multivariate normal distribution <https://en.wikipedia.org/wiki/Multivariate_normal_dis",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:126861,simpl,simply,126861,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simply']
Usability,"rix.read(path, _assert_type=self._bmir._type). [docs] @staticmethod; @typecheck(; entry_expr=expr_float64,; path=str,; overwrite=bool,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def write_from_entry_expr(; entry_expr,; path,; overwrite=False,; mean_impute=False,; center=False,; normalize=False,; axis='rows',; block_size=None,; ):; """"""Writes a block matrix from a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> BlockMatrix.write_from_entry_expr(mt.GT.n_alt_alleles(),; ... 'output/model.bm'). Notes; -----; The resulting file can be loaded with :meth:`BlockMatrix.read`.; Blocks are stored row-major. If a pipelined transformation significantly downsamples the rows of the; underlying matrix table, then repartitioning the matrix table ahead of; this method will greatly improve its performance. By default, this method will fail if any values are missing (to be clear,; special float values like ``nan`` are not missing values). - Set `mean_impute` to replace missing values with the row mean before; possibly centering or normalizing. If all values are missing, the row; mean is ``nan``. - Set `center` to shift each row to have mean zero before possibly; normalizing. - Set `normalize` to normalize each row to have unit length. To standardize each row, regarded as an empirical distribution, to have; mean 0 and variance 1, set `center` and `normalize` and then multiply; the result by ``sqrt(n_cols)``. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.bu",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:22673,clear,clear,22673,docs/0.2/_modules/hail/linalg/blockmatrix.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html,2,['clear'],['clear']
Usability,"s not realizable in Python""). def __str__(self):; return ""stream<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other, tstream) and self.element_type == other.element_type. def _pretty(self, b, indent, increment):; b.append('stream<'); self.element_type._pretty(b, indent, increment); b.append('>'). def _parsable_string(self):; return ""Stream["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[list, frozenlist]:; ls = [self.element_type._convert_from_json_na(elt, _should_freeze) for elt in x]; if _should_freeze:; return frozenlist(ls); return ls. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tstream) and self.element_type.unify(t.element_type). def subst(self):; return tstream(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). def is_setlike(maybe_setlike):; return isinstance(maybe_setlike, (set, frozenset)). [docs]class tset(HailType):; """"""Hail type for collections of distinct elements. In Python, these are represented as :obj:`set`. Notes; -----; Sets contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of set. See Also; --------; :class:`.SetExpression`, :class:`.CollectionExpression`,; :func:`.set`, :ref:`sec-collection-functions`; """""". @typecheck_method(element_type=hail_type); def __init__(self, element_type):; self._element_type = element_type; self._array_repr = tarray(element_type); super(tset, self).__init__(). @property; def element_type(self):; """"""Set element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. def _traverse(self, obj, f):; if f(self, obj):; for elt ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:22907,clear,clear,22907,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"s:; raise ExpressionException(; ""dynamic variables created by 'hl.bind' or lambda methods like 'hl.map' may not be aggregated""; ). [docs]@typecheck(expr=expr_numeric, k=int, _raw=bool); def approx_cdf(expr, k=100, *, _raw=False):; """"""Produce a summary of the distribution of values. Notes; -----; This method returns a struct containing two arrays: `values` and `ranks`.; The `values` array contains an ordered sample of values seen. The `ranks`; array is one longer, and contains the approximate ranks for the; corresponding values. These represent a summary of the CDF of the distribution of values. In; particular, for any value `x = values(i)` in the summary, we estimate that; there are `ranks(i)` values strictly less than `x`, and that there are; `ranks(i+1)` values less than or equal to `x`. For any value `y` (not; necessarily in the summary), we estimate CDF(y) to be `ranks(i)`, where `i`; is such that `values(i-1) < y ≤ values(i)`. An alternative intuition is that the summary encodes a compressed; approximation to the sorted list of values. For example, values=[0,2,5,6,9]; and ranks=[0,3,4,5,8,10] represents the approximation [0,0,0,2,5,6,6,6,9,9],; with the value `values(i)` occupying indices `ranks(i)` (inclusive) to; `ranks(i+1)` (exclusive). The returned struct also contains an array `_compaction_counts`, which is; used internally to support downstream error estimation. Warning; -------; This is an approximate and nondeterministic method. Parameters; ----------; expr : :class:`.Expression`; Expression to collect.; k : :obj:`int`; Parameter controlling the accuracy vs. memory usage tradeoff. Returns; -------; :class:`.StructExpression`; Struct containing `values` and `ranks` arrays.; """"""; raw_res = _agg_func(; 'ApproxCDF',; [hl.float64(expr)],; tstruct(levels=tarray(tint32), items=tarray(tfloat64), _compaction_counts=tarray(tint32)),; init_op_args=[k],; ); conv = {; tint32: lambda x: x.map(hl.int),; tint64: lambda x: x.map(hl.int64),; tfloat32: lambda x: x.map(hl.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html:12464,intuit,intuition,12464,docs/0.2/_modules/hail/expr/aggregators/aggregators.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html,2,['intuit'],['intuition']
Usability,"self, byte_reader, _should_freeze: bool = False) -> Union[dict, frozendict]:; # NB: We ensure the key is always frozen with a wrapper on the key_type in the _array_repr.; d = {}; length = byte_reader.read_int32(); for _ in range(length):; element = self._array_repr.element_type._convert_from_encoding(byte_reader, _should_freeze); d[element.key] = element.value. if _should_freeze:; return frozendict(d); return d. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); for k, v in value.items():; self._array_repr.element_type._convert_to_encoding(byte_writer, {'key': k, 'value': v}). def _propagate_jtypes(self, jtype):; self._key_type._add_jtype(jtype.keyType()); self._value_type._add_jtype(jtype.valueType()). def unify(self, t):; return isinstance(t, tdict) and self.key_type.unify(t.key_type) and self.value_type.unify(t.value_type). def subst(self):; return tdict(self._key_type.subst(), self._value_type.subst()). def clear(self):; self.key_type.clear(); self.value_type.clear(). def _get_context(self):; return HailTypeContext.union(self.key_type, self.value_type). [docs]class tstruct(HailType, Mapping):; """"""Hail type for structured groups of heterogeneous fields. In Python, these are represented as :class:`.Struct`. Hail's :class:`.tstruct` type is commonly used to compose types together to form nested; structures. Structs can contain any combination of types, and are ordered mappings; from field name to field type. Each field name must be unique. Structs are very common in Hail. Each component of a :class:`.Table` and :class:`.MatrixTable`; is a struct:. - :meth:`.Table.row`; - :meth:`.Table.globals`; - :meth:`.MatrixTable.row`; - :meth:`.MatrixTable.col`; - :meth:`.MatrixTable.entry`; - :meth:`.MatrixTable.globals`. Structs appear below the top-level component types as well. Consider the following join:. >>> new_table = table1.annotate(table2_fields = table2.index(table1.key)). This snippet adds a field ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:29471,clear,clear,29471,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"stribution of \(Q\) is given by a; generalized chi-squared distribution whose weights are the eigenvalues of a symmetric matrix; which we call \(Z Z^T\):. \[\begin{align*}; V_{ii} &= \sigma^2_i \\; W_{ii} &= w_i \quad\quad \textrm{the weight for variant } i \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2}; \end{align*}\]; The eigenvalues of \(Z Z^T\) and \(Z^T Z\) are the squared singular values of \(Z\);; therefore, we instead focus on \(Z^T Z\). In the expressions below, we elide transpositions; of symmetric matrices:. \[\begin{align*}; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2} \\; Z &= P_0^{1/2} G W^{1/2} \\; Z^T Z &= W^{1/2} G^T P_0 G W^{1/2}; \end{align*}\]; Before substituting the definition of \(P_0\), simplify it using the reduced QR; decomposition:. \[\begin{align*}; Q R &= V^{1/2} X \\; R^T Q^T &= X^T V^{1/2} \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; &= V - V X (R^T Q^T Q R)^{-1} X^T V \\; &= V - V X (R^T R)^{-1} X^T V \\; &= V - V X R^{-1} (R^T)^{-1} X^T V \\; &= V - V^{1/2} Q (R^T)^{-1} X^T V^{1/2} \\; &= V - V^{1/2} Q Q^T V^{1/2} \\; &= V^{1/2} (I - Q Q^T) V^{1/2} \\; \end{align*}\]; Substitute this simplified expression into \(Z\):. \[\begin{align*}; Z^T Z &= W^{1/2} G^T V^{1/2} (I - Q Q^T) V^{1/2} G W^{1/2} \\; \end{align*}\]; Split this symmetric matrix by observing that \(I - Q Q^T\) is idempotent:. \[\begin{align*}; I - Q Q^T &= (I - Q Q^T)(I - Q Q^T)^T \\; \\; Z &= (I - Q Q^T) V^{1/2} G W^{1/2} \\; Z &= (G - Q Q^T G) V^{1/2} W^{1/2}; \end{align*}\]; Finally, the squared singular values of \(Z\) are the eigenvalues of \(Z^T Z\), so; \(Q\) should be distributed as follows:. \[\begin{align*}; U S V^T &= Z \quad\quad \textrm{the singular value decomposition} \\; \lambda_s &= S_{ss}^2 \\; \\; Q &\sim \textrm{GeneralizedChiSquared}(\lambda, \vec{1}, \vec{0}, 0, 0); \end{align*}\]; The null hypothesis test tests for the probability of observing even larger values of \(Q\).; The SKAT method was originally described in:",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/methods/genetics.html:70924,simpl,simplified,70924,docs/0.2/methods/genetics.html,https://hail.is,https://hail.is/docs/0.2/methods/genetics.html,1,['simpl'],['simplified']
Usability,"t in memory:. >>> dataset = dataset.cache() # doctest: +SKIP. Notes; -----. This method is an alias for :func:`persist(""MEMORY_ONLY"") <hail.MatrixTable.persist>`. Returns; -------; :class:`.MatrixTable`; Cached dataset.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level: str = 'MEMORY_AND_DISK') -> 'MatrixTable':; """"""Persist this table in memory or on disk. Examples; --------; Persist the dataset to both memory and disk:. >>> dataset = dataset.persist() # doctest: +SKIP. Notes; -----. The :meth:`.MatrixTable.persist` and :meth:`.MatrixTable.cache`; methods store the current dataset on disk or in memory temporarily to; avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for :meth:`.Table.write`,; which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.MatrixTable`; Persisted dataset.; """"""; return Env.backend().persist(self). [docs] def unpersist(self) -> 'MatrixTable':; """"""; Unpersists this dataset from memory/disk. Notes; -----; This function will have no effect on a dataset that was not previously; persisted. Returns; -------; :class:`.MatrixTable`; Unpersisted dataset.; """"""; return Env.backend().unpersist(self). [docs] @typecheck_method(name=str); def add_row_index(self, name: str = 'row_idx') -> 'MatrixTable':; """"""Add the integer index of each row as a new row field. Examples; --------. >>> dataset_result = dataset.add_row_index(). Notes; -----; The field adde",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:111393,guid,guide,111393,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,['guid'],['guide']
Usability,t.txt; hail.vds.combiner.VDSMetadata.rst.txt; hail.vds.filter_chromosomes.rst.txt; hail.vds.filter_intervals.rst.txt; hail.vds.filter_samples.rst.txt; hail.vds.filter_variants.rst.txt; hail.vds.impute_sex_chr_ploidy_from_interval_coverage.rst.txt; hail.vds.impute_sex_chromosome_ploidy.rst.txt; hail.vds.interval_coverage.rst.txt; hail.vds.lgt_to_gt.rst.txt; hail.vds.local_to_global.rst.txt; hail.vds.merge_reference_blocks.rst.txt; hail.vds.read_vds.rst.txt; hail.vds.sample_qc.rst.txt; hail.vds.split_multi.rst.txt; hail.vds.store_ref_block_max_length.rst.txt; hail.vds.to_dense_mt.rst.txt; hail.vds.to_merged_sparse_mt.rst.txt; hail.vds.truncate_reference_blocks.rst.txt; hail.vds.VariantDataset.rst.txt; index.rst.txt. aggregators.rst.txt; annotation_database_ui.rst.txt; api.rst.txt; batch_api.rst.txt; change_log.rst.txt; cheatsheets.rst.txt; configuration_reference.rst.txt; datasets.rst.txt; expressions.rst.txt; fs_api.rst.txt; getting_started.rst.txt; getting_started_developing.rst.txt; guides.rst.txt; hadoop_glob_patterns.rst.txt; hail.expr.ArrayExpression.rst.txt; hail.expr.ArrayNumericExpression.rst.txt; hail.expr.BooleanExpression.rst.txt; hail.expr.CallExpression.rst.txt; hail.expr.CollectionExpression.rst.txt; hail.expr.DictExpression.rst.txt; hail.expr.Expression.rst.txt; hail.expr.Float32Expression.rst.txt; hail.expr.Float64Expression.rst.txt; hail.expr.Int32Expression.rst.txt; hail.expr.Int64Expression.rst.txt; hail.expr.IntervalExpression.rst.txt; hail.expr.LocusExpression.rst.txt; hail.expr.NDArrayExpression.rst.txt; hail.expr.NDArrayNumericExpression.rst.txt; hail.expr.NumericExpression.rst.txt; hail.expr.SetExpression.rst.txt; hail.expr.StringExpression.rst.txt; hail.expr.StructExpression.rst.txt; hail.expr.TupleExpression.rst.txt; hail.GroupedMatrixTable.rst.txt; hail.GroupedTable.rst.txt; hail.MatrixTable.rst.txt; hail.Table.rst.txt; hail_on_the_cloud.rst.txt; index.rst.txt; libraries.rst.txt; other_resources.rst.txt; plot.rst.txt; root_api.rst.txt; scan,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/index-wcopy.html:19642,guid,guides,19642,index-wcopy.html,https://hail.is,https://hail.is/index-wcopy.html,1,['guid'],['guides']
Usability,"table1.add_index(); >>> table_result.show() ; +-------+-------+-----+-------+-------+-------+-------+-------+-------+; | ID | HT | SEX | X | Z | C1 | C2 | C3 | idx |; +-------+-------+-----+-------+-------+-------+-------+-------+-------+; | int32 | int32 | str | int32 | int32 | int32 | int32 | int32 | int64 |; +-------+-------+-----+-------+-------+-------+-------+-------+-------+; | 1 | 65 | M | 5 | 4 | 2 | 50 | 5 | 0 |; | 2 | 72 | M | 6 | 3 | 2 | 61 | 1 | 1 |; | 3 | 70 | F | 7 | 3 | 10 | 81 | -5 | 2 |; | 4 | 60 | F | 8 | 2 | 11 | 90 | -10 | 3 |; +-------+-------+-----+-------+-------+-------+-------+-------+-------+. Notes; This method returns a table with a new field whose name is given by; the name parameter, with type tint64. The value of this field; is the integer index of each row, starting from 0. Methods that respect; ordering (like Table.take() or Table.export()) will; return rows in order.; This method is also helpful for creating a unique integer index for; rows of a table so that more complex types can be encoded as a simple; number for performance reasons. Parameters:; name (str) – Name of index field. Returns:; Table – Table with a new index field. aggregate(expr, _localize=True)[source]; Aggregate over rows into a local value.; Examples; Aggregate over rows:; >>> table1.aggregate(hl.struct(fraction_male=hl.agg.fraction(table1.SEX == 'M'),; ... mean_x=hl.agg.mean(table1.X))); Struct(fraction_male=0.5, mean_x=6.5). Note; This method supports (and expects!) aggregation over rows. Parameters:; expr (Expression) – Aggregation expression. Returns:; any – Aggregated value dependent on expr. all(expr)[source]; Evaluate whether a boolean expression is true for all rows.; Examples; Test whether C1 is greater than 5 in all rows of the table:; >>> if table1.all(table1.C1 == 5):; ... print(""All rows have C1 equal 5.""). Parameters:; expr (BooleanExpression) – Expression to test. Returns:; bool. annotate(**named_exprs)[source]; Add new fields.; New Table fields ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.Table.html:7571,simpl,simple,7571,docs/0.2/hail.Table.html,https://hail.is,https://hail.is/docs/0.2/hail.Table.html,1,['simpl'],['simple']
Usability,"taset(self.hc, self._jvds.join(right._jvds)). [docs] @handle_py4j; @typecheck(datasets=tupleof(vds_type)); def union(*datasets):; """"""Take the union of datasets vertically (include all variants). **Examples**. .. testsetup::. vds_autosomal = vds; vds_chromX = vds; vds_chromY = vds. Union two datasets:. >>> vds_union = vds_autosomal.union(vds_chromX). Given a list of datasets, union them all:. >>> all_vds = [vds_autosomal, vds_chromX, vds_chromY]. The following three syntaxes are equivalent:. >>> vds_union1 = vds_autosomal.union(vds_chromX, vds_chromY); >>> vds_union2 = all_vds[0].union(*all_vds[1:]); >>> vds_union3 = VariantDataset.union(*all_vds). **Notes**. In order to combine two datasets, these requirements must be met:; - the samples must match; - the variant annotation schemas must match (field order within structs matters).; - the cell (genotype) schemas must match (field order within structs matters). The column annotations in the resulting dataset are simply the column annotations; from the first dataset; the column annotation schemas do not need to match. This method can trigger a shuffle, if partitions from two datasets overlap. :param vds_type: Datasets to combine.; :type vds_type: tuple of :class:`.VariantDataset`. :return: Dataset with variants from all datasets.; :rtype: :class:`.VariantDataset`; """"""; if len(datasets) == 0:; raise ValueError('Expected at least one argument'); elif len(datasets) == 1:; return datasets[0]; else:; return VariantDataset(Env.hc(), Env.hail().variant.VariantSampleMatrix.union([d._jvds for d in datasets])). [docs] @handle_py4j; @requireTGenotype; @typecheck_method(r2=numeric,; window=integral,; memory_per_core=integral,; num_cores=integral); def ld_prune(self, r2=0.2, window=1000000, memory_per_core=256, num_cores=1):; """"""Prune variants in linkage disequilibrium (LD). .. include:: requireTGenotype.rst. Requires :py:class:`~hail.VariantDataset.was_split` equals True. **Examples**. Export the set of common LD pruned variants to ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/dataset.html:91981,simpl,simply,91981,docs/0.1/_modules/hail/dataset.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/dataset.html,1,['simpl'],['simply']
Usability,"te: These instructions install the JRE but that is not necessary as the JDK should already; be installed which includes the JRE.; If you are setting HAIL_COMPILE_NATIVES=1, then you need the LZ4 library; header files. On Debian and Ubuntu machines run: apt-get install liblz4-dev. Building Hail; The Hail source code is hosted on GitHub:; git clone https://github.com/hail-is/hail.git; cd hail/hail. By default, Hail uses pre-compiled native libraries that are compatible with; recent Mac OS X and Debian releases. If you’re not using one of these OSes, set; the environment (or Make) variable HAIL_COMPILE_NATIVES to any value. This; variable tells GNU Make to build the native libraries from source.; Build and install a wheel file from source with local-mode pyspark:; make install HAIL_COMPILE_NATIVES=1. As above, but explicitly specifying the Scala and Spark versions:; make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5. Building the Docs and Website; Install build dependencies listed in the docs style guide.; Build without rendering the notebooks (which is slow):; make hail-docs-do-not-render-notebooks. Build while rendering the notebooks:; make hail-docs. Serve the built website on http://localhost:8000/; (cd build/www && python3 -m http.server). Running the tests; Install development dependencies:; make -C .. install-dev-requirements. A couple Hail tests compare to PLINK 1.9 (not PLINK 2.0 [ignore the confusing; URL]):. PLINK 1.9. Execute every Hail test using at most 8 parallel threads:; make -j8 test. Contributing; Chat with the dev team on our Zulip chatroom or; development forum if you have an idea for a contribution.; We can help you determine if your project is a good candidate for merging.; Keep in mind the following principles when submitting a pull request:. A PR should focus on a single feature. Multiple features should be split into multiple PRs.; Before submitting your PR, you should rebase onto the latest main.; PRs must pass a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/getting_started_developing.html:1895,guid,guide,1895,docs/0.2/getting_started_developing.html,https://hail.is,https://hail.is/docs/0.2/getting_started_developing.html,1,['guid'],['guide']
Usability,"tem nonresponse behaviour to; 	 survey questionnaires are systematic and associated with genetic loci. Nat Hum Behav 7,; 	 1371–1387; 	 (2023). https://doi.org/10.1038/s41562-023-01632-7 https://www.nature.com/articles/s41562-023-01632-7. 	 Josefine U Melchiorsen, Kimmie V Sørensen, Jette Bork-Jensen, Hüsün S Kizilkaya, Lærke S; 	 Gasbjerg, Alexander S Hauser, Jørgen Rungby, Henrik T Sørensen, Allan Vaag, Jens S; 	 Nielsen, Oluf Pedersen, Allan Linneberg, Bolette Hartmann, Anette P Gjesing, Jens J; 	 Holst, Torben Hansen, Mette M Rosenkilde, Niels Grarup, Rare Heterozygous; 	 Loss-of-Function Variants in the Human GLP-1 Receptor Are Not Associated With; 	 Cardiometabolic Phenotypes, The Journal of Clinical Endocrinology & Metabolism, Volume; 	 108, Issue 11, November 2023, Pages; 	 2821–2833, https://doi.org/10.1210/clinem/dgad290. https://academic.oup.com/jcem/article/108/11/2821/7180819. 	 Vukadinovic, Milos et al. Deep learning-enabled analysis of medical images identifies; 	 cardiac sphericity as an early marker of cardiomyopathy and related outcomes. Med,; 	 Volume 4, Issue 4, 252 - 262.e3. https://www.cell.com/med/fulltext/S2666-6340(23)00069-7. 	 Epi25 Collaborative; Chen S, Neale BM, Berkovic SF. Shared and distinct ultra-rare; 	 genetic risk for diverse epilepsies: A whole-exome sequencing study of 54,423; 	 individuals across multiple genetic ancestries. medRxiv [Preprint]. 2023 Feb; 	 24:2023.02.22.23286310. doi: 10.1101/2023.02.22.23286310. PMID: 36865150; PMCID:; 	 PMC9980234. https://pubmed.ncbi.nlm.nih.gov/36865150/. 	 Kurki, M.I., Karjalainen, J., Palta, P. et al. FinnGen provides genetic insights from a; 	 well-phenotyped isolated population. Nature 613, 508–518; 	 (2023). https://doi.org/10.1038/s41586-022-05473-8 https://www.nature.com/articles/s41586-022-05473-8. 	 Mortensen, Ó., Thomsen, E., Lydersen, L.N. et al. FarGen: Elucidating the distribution; 	 of coding variants in the isolated population of the Faroe Islands. Eur J Hum Genet 31,; 	 329–",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/references.html:5085,learn,learning-enabled,5085,references.html,https://hail.is,https://hail.is/references.html,1,['learn'],['learning-enabled']
Usability,"til; import string; import tempfile; from collections import Counter, defaultdict; from contextlib import contextmanager; from io import StringIO; from typing import Literal, Optional; from urllib.parse import urlparse. import hail; import hail as hl; from hail.typecheck import enumeration, nullable, typecheck; from hail.utils.java import Env, error. [docs]@typecheck(n_rows=int, n_cols=int, n_partitions=nullable(int)); def range_matrix_table(n_rows, n_cols, n_partitions=None) -> 'hail.MatrixTable':; """"""Construct a matrix table with row and column indices and no entry fields. Examples; --------. >>> range_ds = hl.utils.range_matrix_table(n_rows=100, n_cols=10). >>> range_ds.count_rows(); 100. >>> range_ds.count_cols(); 10. Notes; -----; The resulting matrix table contains the following fields:. - `row_idx` (:py:data:`.tint32`) - Row index (row key).; - `col_idx` (:py:data:`.tint32`) - Column index (column key). It contains no entry fields. This method is meant for testing and learning, and is not optimized for; production performance. Parameters; ----------; n_rows : :obj:`int`; Number of rows.; n_cols : :obj:`int`; Number of columns.; n_partitions : int, optional; Number of partitions (uses Spark default parallelism if None). Returns; -------; :class:`.MatrixTable`; """"""; check_nonnegative_and_in_range('range_matrix_table', 'n_rows', n_rows); check_nonnegative_and_in_range('range_matrix_table', 'n_cols', n_cols); if n_partitions is not None:; check_positive_and_in_range('range_matrix_table', 'n_partitions', n_partitions); return hail.MatrixTable(; hail.ir.MatrixRead(; hail.ir.MatrixRangeReader(n_rows, n_cols, n_partitions),; _assert_type=hl.tmatrix(; hl.tstruct(),; hl.tstruct(col_idx=hl.tint32),; ['col_idx'],; hl.tstruct(row_idx=hl.tint32),; ['row_idx'],; hl.tstruct(),; ),; ); ). [docs]@typecheck(n=int, n_partitions=nullable(int)); def range_table(n, n_partitions=None) -> 'hail.Table':; """"""Construct a table with the row index and no other fields. Examples; --------. >",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/misc.html:1573,learn,learning,1573,docs/0.2/_modules/hail/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/misc.html,2,['learn'],['learning']
Usability,"tion.; force_row_major (bool) – If True, transform blocks in column-major format; to row-major format before writing.; If False, write blocks in their current format.; stage_locally (bool) – If True, major output will be written to temporary local storage; before being copied to output. static write_from_entry_expr(entry_expr, path, overwrite=False, mean_impute=False, center=False, normalize=False, axis='rows', block_size=None)[source]; Writes a block matrix from a matrix table entry expression.; Examples; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> BlockMatrix.write_from_entry_expr(mt.GT.n_alt_alleles(),; ... 'output/model.bm'). Notes; The resulting file can be loaded with BlockMatrix.read().; Blocks are stored row-major.; If a pipelined transformation significantly downsamples the rows of the; underlying matrix table, then repartitioning the matrix table ahead of; this method will greatly improve its performance.; By default, this method will fail if any values are missing (to be clear,; special float values like nan are not missing values). Set mean_impute to replace missing values with the row mean before; possibly centering or normalizing. If all values are missing, the row; mean is nan.; Set center to shift each row to have mean zero before possibly; normalizing.; Set normalize to normalize each row to have unit length. To standardize each row, regarded as an empirical distribution, to have; mean 0 and variance 1, set center and normalize and then multiply; the result by sqrt(n_cols). Warning; If the rows of the matrix table have been filtered to a small fraction,; then MatrixTable.repartition() before this method to improve; performance.; This method opens n_cols / block_size files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; --properties 'core:fs.gs.io.buffersize.write=1048576. Parameters:. entry_ex",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html:46074,clear,clear,46074,docs/0.2/linalg/hail.linalg.BlockMatrix.html,https://hail.is,https://hail.is/docs/0.2/linalg/hail.linalg.BlockMatrix.html,1,['clear'],['clear']
Usability,"titions:; intervals = ht._calculate_new_partitions(_n_partitions); return read_table(; path,; _intervals=intervals,; _assert_type=ht._type,; _load_refs=_load_refs,; _create_row_uids=_create_row_uids,; ); return ht. [docs]@typecheck(; t=Table,; host=str,; port=int,; index=str,; index_type=str,; block_size=int,; config=nullable(dictof(str, str)),; verbose=bool,; ); def export_elasticsearch(t, host, port, index, index_type, block_size, config=None, verbose=True):; """"""Export a :class:`.Table` to Elasticsearch. By default, this method supports Elasticsearch versions 6.8.x - 7.x.x. Older versions of elasticsearch will require; recompiling hail. .. warning::; :func:`.export_elasticsearch` is EXPERIMENTAL. .. note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), intervals=nullable(sequenceof(anytype))); def import_avro(paths, *, key=None, intervals=None):; if not paths:; raise ValueError('import_avro requires at least one path'); if (key is None) != (intervals is None):; raise ValueError('key and intervals must either be both defined or both undefined'). with hl.current_backend().fs.open(paths[0], 'rb') as avro_file:; # monkey patch DataFileReader.determine_file_length to account for bug in Google HadoopFS. def patched_determine_file_length(self) -> int:; remember_pos = self.reader.tell(); self.reader.seek(-1, 2); file_length = self.reader.tell() + 1; self.reader.seek(remember_pos); return file_length.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/impex.html:112101,guid,guide,112101,docs/0.2/_modules/hail/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html,2,['guid'],['guide']
Usability,"to 0/0; and 0/1. The genotype 1/2 maps to 0/1 and 0/1.; The biallelic alt AD entry is just the multiallelic AD entry; corresponding to the alternate allele. The ref AD entry is the; sum of the other multiallelic entries.; The biallelic DP is the same as the multiallelic DP.; The biallelic PL entry for for a genotype g is the minimum; over PL entries for multiallelic genotypes that downcode to; g. For example, the PL for (A, T) at 0/1 is the minimum of the; PLs for 0/1 (50) and 1/2 (45), and thus 45.; Fixing an alternate allele and biallelic variant, downcoding; gives a map from multiallelic to biallelic alleles and; genotypes. The biallelic AD entry for an allele is just the; sum of the multiallelic AD entries for alleles that map to; that allele. Similarly, the biallelic PL entry for a genotype; is the minimum over multiallelic PL entries for genotypes that; map to that genotype.; By default, GQ is recomputed from PL. If propagate_gq=True; is passed, the biallelic GQ field is simply the multiallelic; GQ field, that is, genotype qualities are unchanged.; Here is a second example for a het non-ref; A C,T 1/2:2,8,6:16:45:99,50,99,45,0,99. splits as; A C 0/1:8,8:16:45:45,0,99; A T 0/1:10,6:16:50:50,0,99. VCF Info Fields; Hail does not split annotations in the info field. This means; that if a multiallelic site with info.AC value [10, 2] is; split, each split site will contain the same array [10,; 2]. The provided allele index annotation va.aIndex can be used; to select the value corresponding to the split allele’s; position:; >>> vds_result = (vds.split_multi(); ... .filter_variants_expr('va.info.AC[va.aIndex - 1] < 10', keep = False)). VCFs split by Hail and exported to new VCFs may be; incompatible with other tools, if action is not taken; first. Since the “Number” of the arrays in split multiallelic; sites no longer matches the structure on import (“A” for 1 per; allele, for example), Hail will export these fields with; number “.”.; If the desired output is one value",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:163847,simpl,simply,163847,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simply']
Usability,"umns indexed by \(m\) bialellic autosomal variants; \(C_{ij}\) is the number of alternate alleles of variant \(j\) carried by sample \(i\), which can be 0, 1, 2, or missing. For each variant \(j\), the sample alternate allele frequency \(p_j\) is computed as half the mean of the non-missing entries of column \(j\). Entries of \(M\) are then mean-centered and variance-normalized as. \[M_{ij} = \frac{C_{ij}-2p_j}{\sqrt{2p_j(1-p_j)m}},\]; with \(M_{ij} = 0\) for \(C_{ij}\) missing (i.e. mean genotype imputation). This scaling normalizes genotype variances to a common value \(1/m\) for variants in Hardy-Weinberg equilibrium and is further motivated in the paper cited above. (The resulting amplification of signal from the low end of the allele frequency spectrum will also introduce noise for rare variants; common practice is to filter out variants with minor allele frequency below some cutoff.) The factor \(1/m\) gives each sample row approximately unit total variance (assuming linkage equilibrium) and yields the sample correlation or genetic relationship matrix (GRM) as simply \(MM^T\).; PCA then computes the SVD. \[M = USV^T\]; where columns of \(U\) are left singular vectors (orthonormal in \(\mathbb{R}^n\)), columns of \(V\) are right singular vectors (orthonormal in \(\mathbb{R}^m\)), and \(S=\mathrm{diag}(s_1, s_2, \ldots)\) with ordered singular values \(s_1 \ge s_2 \ge \cdots \ge 0\). Typically one computes only the first \(k\) singular vectors and values, yielding the best rank \(k\) approximation \(U_k S_k V_k^T\) of \(M\); the truncations \(U_k\), \(S_k\) and \(V_k\) are \(n \times k\), \(k \times k\) and \(m \times k\) respectively.; From the perspective of the samples or rows of \(M\) as data, \(V_k\) contains the variant loadings for the first \(k\) PCs while \(MV_k = U_k S_k\) contains the first \(k\) PC scores of each sample. The loadings represent a new basis of features while the scores represent the projected data on those features. The eigenvalues of ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/hail.VariantDataset.html:140294,simpl,simply,140294,docs/0.1/hail.VariantDataset.html,https://hail.is,https://hail.is/docs/0.1/hail.VariantDataset.html,1,['simpl'],['simply']
Usability,"und type '%s'"" % type(annotation)). def __str__(self):; return ""array<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other, tarray) and self.element_type == other.element_type. def _pretty(self, b, indent, increment):; b.append('array<'); self.element_type._pretty(b, indent, increment); b.append('>'). def _parsable_string(self):; return ""Array["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[list, frozenlist]:; ls = [self.element_type._convert_from_json_na(elt, _should_freeze) for elt in x]; if _should_freeze:; return frozenlist(ls); return ls. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tarray) and self.element_type.unify(t.element_type). def subst(self):; return tarray(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> Union[list, frozenlist]:; length = byte_reader.read_int32(). num_missing_bytes = math.ceil(length / 8); missing_bytes = byte_reader.read_bytes_view(num_missing_bytes). decoded = []; i = 0; current_missing_byte = None; while i < length:; which_missing_bit = i % 8; if which_missing_bit == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; decoded.append(None); else:; element_decoded = self.element_type._convert_from_encoding(byte_reader, _should_freeze); decoded.append(element_decoded); i += 1; if _should_freeze:; return frozenlist(decoded); return decoded. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if H",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:20269,clear,clear,20269,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"urn ""Set["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[set, frozenset]:; s = {self.element_type._convert_from_json_na(elt, _should_freeze=True) for elt in x}; if _should_freeze:; return frozenset(s); return s. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> Union[set, frozenset]:; s = self._array_repr._convert_from_encoding(byte_reader, _should_freeze=True); if _should_freeze:; return frozenset(s); return set(s). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; self._array_repr._convert_to_encoding(byte_writer, list(value)). def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tset) and self.element_type.unify(t.element_type). def subst(self):; return tset(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). class _freeze_this_type(HailType):; def __init__(self, t):; self.t = t. def _convert_from_json_na(self, x, _should_freeze: bool = False):; return self.t._convert_from_json_na(x, _should_freeze=True). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; return self.t._convert_from_encoding(byte_reader, _should_freeze=True). def _convert_to_encoding(self, byte_writer, x):; return self.t._convert_to_encoding(byte_writer, x). [docs]class tdict(HailType):; """"""Hail type for key-value maps. In Python, these are represented as :obj:`dict`. Notes; -----; Dicts parameterize the type of both their keys and values with; `key_type` and `value_type`. Parameters; ----------; key_type: :class:`.HailType`; Key type.; value_type: :class:`.HailType`; Value type. See Also; --------; :class:`.DictExpression`, :func:`.dict`, :ref:`sec-collection-functions`; """""". @typecheck_method(key_t",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:25470,clear,clear,25470,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"utput, overwrite). [docs] @handle_py4j; def cache(self):; """"""Mark this key table to be cached in memory. :py:meth:`~hail.KeyTable.cache` is the same as :func:`persist(""MEMORY_ONLY"") <hail.KeyTable.persist>`. :rtype: :class:`.KeyTable`. """"""; return KeyTable(self.hc, self._jkt.cache()). [docs] @handle_py4j; @typecheck_method(storage_level=strlike); def persist(self, storage_level=""MEMORY_AND_DISK""):; """"""Persist this key table to memory and/or disk. **Examples**. Persist the key table to both memory and disk:. >>> kt = kt.persist() # doctest: +SKIP. **Notes**. The :py:meth:`~hail.KeyTable.persist` and :py:meth:`~hail.KeyTable.cache` methods ; allow you to store the current table on disk or in memory to avoid redundant computation and ; improve the performance of Hail pipelines. :py:meth:`~hail.KeyTable.cache` is an alias for ; :func:`persist(""MEMORY_ONLY"") <hail.KeyTable.persist>`. Most users will want ""MEMORY_AND_DISK"".; See the `Spark documentation <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__ ; for a more in-depth discussion of persisting data. :param storage_level: Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP; ; :rtype: :class:`.KeyTable`; """""". return KeyTable(self.hc, self._jkt.persist(storage_level)). [docs] @handle_py4j; def unpersist(self):; """"""; Unpersists this table from memory/disk.; ; **Notes**; This function will have no effect on a table that was not previously persisted.; ; There's nothing stopping you from continuing to use a table that has been unpersisted, but doing so will result in; all previous steps taken to compute the table being performed again since the table must be recomputed. Only unpersist; a table when you are done with it.; """"""; self._jkt.unpersist(). [docs] @handle_py4j; @typecheck_method(cols=tupleof(oneof(strlike, Ascending, Descending))); ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.1/_modules/hail/keytable.html:24126,guid,guide,24126,docs/0.1/_modules/hail/keytable.html,https://hail.is,https://hail.is/docs/0.1/_modules/hail/keytable.html,1,['guid'],['guide']
Usability,"x, _should_freeze: bool = False):; return x. def _from_encoding(self, encoding):; return self._convert_from_encoding(ByteReader(memoryview(encoding))). def _to_encoding(self, value) -> bytes:; buf = bytearray(); self._convert_to_encoding(ByteWriter(buf), value); return bytes(buf). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; raise ValueError(""Not implemented yet""). def _convert_to_encoding(self, byte_writer, value):; raise ValueError(""Not implemented yet""). @staticmethod; def _missing(value):; return value is None or value is pd.NA. def _traverse(self, obj, f):; """"""Traverse a nested type and object. Parameters; ----------; obj : Any; f : Callable[[HailType, Any], bool]; Function to evaluate on the type and object. Traverse children if; the function returns ``True``.; """"""; f(self, obj). @abc.abstractmethod; def unify(self, t):; raise NotImplementedError. @abc.abstractmethod; def subst(self):; raise NotImplementedError. @abc.abstractmethod; def clear(self):; raise NotImplementedError. def _get_context(self):; return _empty_context. def get_context(self):; if self._context is None:; self._context = self._get_context(); return self._context. def to_numpy(self):; return object. hail_type = oneof(HailType, transformed((str, dtype)), type(None)). class _tvoid(HailType):; def __init__(self):; super(_tvoid, self).__init__(). def __str__(self):; return ""void"". def _eq(self, other):; return isinstance(other, _tvoid). def _parsable_string(self):; return ""Void"". def unify(self, t):; return t == tvoid. def subst(self):; return self. def clear(self):; pass. def _convert_from_encoding(self, *_):; raise ValueError(""Cannot decode void type""). def _convert_to_encoding(self, *_):; raise ValueError(""Cannot encode void type""). class _tint32(HailType):; """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`.; """""". def __init__(s",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:6441,clear,clear,6441,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"ype""). class _tint32(HailType):; """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`.; """""". def __init__(self):; super(_tint32, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not is_int32(annotation):; raise TypeError(""type 'tint32' expected Python 'int', but found type '%s'"" % type(annotation)); elif not self.min_value <= annotation <= self.max_value:; raise TypeError(; f""Value out of range for 32-bit integer: ""; f""expected [{self.min_value}, {self.max_value}], found {annotation}""; ). def __str__(self):; return ""int32"". def _eq(self, other):; return isinstance(other, _tint32). def _parsable_string(self):; return ""Int32"". @property; def min_value(self):; return -(1 << 31). @property; def max_value(self):; return (1 << 31) - 1. def unify(self, t):; return t == tint32. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.int32. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> int:; return byte_reader.read_int32(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_int32(value). def _byte_size(self):; return 4. class _tint64(HailType):; """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`.; """""". def __init__(self):; super(_tint64, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not is_int64(annotation):; raise TypeError(""type 'int64' expected Python 'int', but found type '%s'"" % type(annotation)); if not self.min_value <= annotation <= self.max_value:; raise TypeError(; f""Value out of range for 64-bit integer: ""; f""expected [{self.min_value}, {self.max_value}], found {annotation}""; ). def __str__(self):; return ""int64"". def _eq(self, other):; return isin",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:8205,clear,clear,8205,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,['clear'],['clear']
Usability,"{name!r})', expr, self._parent._global_indices, {self._parent._row_axis}); check_collisions(caller, list(named_exprs), self._parent._row_indices); if not named_exprs.keys().isdisjoint(set(self._key_expr)):; intersection = set(named_exprs.keys()) & set(self._key_expr); raise ValueError(; f'GroupedTable.aggregate: Group names and aggregration expression names overlap: {intersection}'; ). base, _ = self._parent._process_joins(self._key_expr, *named_exprs.values()). key_struct = self._key_expr; return Table(; ir.TableKeyByAndAggregate(; base._tir, hl.struct(**named_exprs)._ir, key_struct._ir, self._npartitions, self._buffer_size; ); ). [docs]class Table(ExprContainer):; """"""Hail's distributed implementation of a dataframe or SQL table. Use :func:`.read_table` to read a table that was written with; :meth:`.Table.write`. Use :meth:`.to_spark` and :meth:`.Table.from_spark`; to inter-operate with PySpark's; `SQL <https://spark.apache.org/docs/latest/sql-programming-guide.html>`__ and; `machine learning <https://spark.apache.org/docs/latest/ml-guide.html>`__; functionality. Examples; --------. The examples below use ``table1`` and ``table2``, which are imported; from text files using :func:`.import_table`. >>> table1 = hl.import_table('data/kt_example1.tsv', impute=True, key='ID'); >>> table1.show(). .. code-block:: text. +-------+-------+-----+-------+-------+-------+-------+-------+; | ID | HT | SEX | X | Z | C1 | C2 | C3 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | int32 | int32 | str | int32 | int32 | int32 | int32 | int32 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | 1 | 65 | M | 5 | 4 | 2 | 50 | 5 |; | 2 | 72 | M | 6 | 3 | 2 | 61 | 1 |; | 3 | 70 | F | 7 | 3 | 10 | 81 | -5 |; | 4 | 60 | F | 8 | 2 | 11 | 90 | -10 |; +-------+-------+-----+-------+-------+-------+-------+-------+. >>> table2 = hl.import_table('data/kt_example2.tsv', impute=True, key='ID'); >>> table2.show(). .. code-block:: text. +-------+-------+--------+; |",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:8200,learn,learning,8200,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,['learn'],['learning']
Usability,"‘f’ character; before a string literal. When creating the string, Python evaluates any expressions; in single curly braces {…} using the current variable scope. When Python compiles; the example below, the string ‘Alice’ is substituted for {name} because the variable; name is set to ‘Alice’ in the line above.; >>> name = 'Alice'; >>> print(f'hello {name}'); hello Alice. You can put any arbitrary Python code inside the curly braces and Python will evaluate; the expression correctly. For example, below we evaluate x + 1 first before compiling; the string. Therefore, we get ‘x = 6’ as the resulting string.; >>> x = 5; >>> print(f'x = {x + 1}'); x = 6. To use an f-string and output a single curly brace in the output string, escape the curly; brace by duplicating the character. For example, { becomes {{ in the string definition,; but will print as {. Likewise, } becomes }}, but will print as }.; >>> x = 5; >>> print(f'x = {{x + 1}} plus {x}'); x = {x + 1} plus 5. To learn more about f-strings, check out this tutorial. Hello World; A Batch consists of a set of Job to execute. There can be; an arbitrary number of jobs in the batch that are executed in order of their dependencies.; A dependency between two jobs states that the dependent job should not run until; the previous job completes. Thus, under the covers a batch is a directed acyclic graph (DAG); of jobs.; In the example below, we have defined a Batch b with the name ‘hello’.; We use the method Batch.new_job() to create a job object which we call j and then; use the method BashJob.command() to tell Batch that we want to execute echo “hello world”.; However, at this point, Batch hasn’t actually run the job to print “hello world”. All we have; done is specified the jobs and the order in which they should be run. To actually execute the; Batch, we call Batch.run(). The name arguments to both Batch and; Job are used in the Batch Service UI.; >>> b = hb.Batch(name='hello'); >>> j = b.new_job(name='j1'); >>> j.command('e",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/batch/tutorial.html:1744,learn,learn,1744,docs/batch/tutorial.html,https://hail.is,https://hail.is/docs/batch/tutorial.html,1,['learn'],['learn']
Usability,"﻿. Hail | ; Cheat Sheets. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Cheat Sheets. View page source. Cheat Sheets. Note; Hail’s cheat sheets are relatively new. We welcome suggestions; for additional cheatsheets, as well as feedback about our documentation. If; you’d like to add a cheatsheet to the documentation, make a pull request!. Hail Tables Cheat Sheet; Hail MatrixTables Cheat Sheet. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/cheatsheets.html:564,feedback,feedback,564,docs/0.2/cheatsheets.html,https://hail.is,https://hail.is/docs/0.2/cheatsheets.html,1,['feedback'],['feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Cells_EBV-transformed_lymphocytes_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cel,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Cells_EBV-transformed_lymphocytes_all_snp_gene_associations.html:107,Feedback,Feedback,107,docs/0.2/datasets/schemas/GTEx_sQTL_Cells_EBV-transformed_lymphocytes_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Cells_EBV-transformed_lymphocytes_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Colon_Sigmoid_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibrobla,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Sigmoid_all_snp_gene_associations.html:87,Feedback,Feedback,87,docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Sigmoid_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Sigmoid_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Colon_Transverse_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibro,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Transverse_all_snp_gene_associations.html:90,Feedback,Feedback,90,docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Transverse_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Colon_Transverse_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Esophagus_Gastroesophageal_Junction_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_C,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Gastroesophageal_Junction_all_snp_gene_associations.html:109,Feedback,Feedback,109,docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Gastroesophageal_Junction_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Gastroesophageal_Junction_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Esophagus_Mucosa_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibro,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Mucosa_all_snp_gene_associations.html:90,Feedback,Feedback,90,docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Mucosa_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Mucosa_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Esophagus_Muscularis_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_f,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Muscularis_all_snp_gene_associations.html:94,Feedback,Feedback,94,docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Muscularis_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Esophagus_Muscularis_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Heart_Atrial_Appendage_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Heart_Atrial_Appendage_all_snp_gene_associations.html:96,Feedback,Feedback,96,docs/0.2/datasets/schemas/GTEx_sQTL_Heart_Atrial_Appendage_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Heart_Atrial_Appendage_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Heart_Left_Ventricle_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_f,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Heart_Left_Ventricle_all_snp_gene_associations.html:94,Feedback,Feedback,94,docs/0.2/datasets/schemas/GTEx_sQTL_Heart_Left_Ventricle_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Heart_Left_Ventricle_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Kidney_Cortex_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibrobla,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Kidney_Cortex_all_snp_gene_associations.html:87,Feedback,Feedback,87,docs/0.2/datasets/schemas/GTEx_sQTL_Kidney_Cortex_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Kidney_Cortex_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Liver_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Liver_all_snp_gene_associations.html:79,Feedback,Feedback,79,docs/0.2/datasets/schemas/GTEx_sQTL_Liver_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Liver_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Lung_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_s,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Lung_all_snp_gene_associations.html:78,Feedback,Feedback,78,docs/0.2/datasets/schemas/GTEx_sQTL_Lung_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Lung_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Minor_Salivary_Gland_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_f,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Minor_Salivary_Gland_all_snp_gene_associations.html:94,Feedback,Feedback,94,docs/0.2/datasets/schemas/GTEx_sQTL_Minor_Salivary_Gland_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Minor_Salivary_Gland_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Muscle_Skeletal_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibrob,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Muscle_Skeletal_all_snp_gene_associations.html:89,Feedback,Feedback,89,docs/0.2/datasets/schemas/GTEx_sQTL_Muscle_Skeletal_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Muscle_Skeletal_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Nerve_Tibial_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblas,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Nerve_Tibial_all_snp_gene_associations.html:86,Feedback,Feedback,86,docs/0.2/datasets/schemas/GTEx_sQTL_Nerve_Tibial_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Nerve_Tibial_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Ovary_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Ovary_all_snp_gene_associations.html:79,Feedback,Feedback,79,docs/0.2/datasets/schemas/GTEx_sQTL_Ovary_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Ovary_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Pancreas_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_a,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pancreas_all_snp_gene_associations.html:82,Feedback,Feedback,82,docs/0.2/datasets/schemas/GTEx_sQTL_Pancreas_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pancreas_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Pituitary_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pituitary_all_snp_gene_associations.html:83,Feedback,Feedback,83,docs/0.2/datasets/schemas/GTEx_sQTL_Pituitary_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Pituitary_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Prostate_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_a,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Prostate_all_snp_gene_associations.html:82,Feedback,Feedback,82,docs/0.2/datasets/schemas/GTEx_sQTL_Prostate_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Prostate_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Skin_Not_Sun_Exposed_Suprapubic_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Not_Sun_Exposed_Suprapubic_all_snp_gene_associations.html:105,Feedback,Feedback,105,docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Not_Sun_Exposed_Suprapubic_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Not_Sun_Exposed_Suprapubic_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Skin_Sun_Exposed_Lower_leg_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cult,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Sun_Exposed_Lower_leg_all_snp_gene_associations.html:100,Feedback,Feedback,100,docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Sun_Exposed_Lower_leg_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Skin_Sun_Exposed_Lower_leg_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Small_Intestine_Terminal_Ileum_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Small_Intestine_Terminal_Ileum_all_snp_gene_associations.html:104,Feedback,Feedback,104,docs/0.2/datasets/schemas/GTEx_sQTL_Small_Intestine_Terminal_Ileum_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Small_Intestine_Terminal_Ileum_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Spleen_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Spleen_all_snp_gene_associations.html:80,Feedback,Feedback,80,docs/0.2/datasets/schemas/GTEx_sQTL_Spleen_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Spleen_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Stomach_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_al,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Stomach_all_snp_gene_associations.html:81,Feedback,Feedback,81,docs/0.2/datasets/schemas/GTEx_sQTL_Stomach_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Stomach_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Testis_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Testis_all_snp_gene_associations.html:80,Feedback,Feedback,80,docs/0.2/datasets/schemas/GTEx_sQTL_Testis_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Testis_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Thyroid_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_al,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Thyroid_all_snp_gene_associations.html:81,Feedback,Feedback,81,docs/0.2/datasets/schemas/GTEx_sQTL_Thyroid_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Thyroid_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Uterus_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Uterus_all_snp_gene_associations.html:80,Feedback,Feedback,80,docs/0.2/datasets/schemas/GTEx_sQTL_Uterus_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Uterus_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Vagina_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Vagina_all_snp_gene_associations.html:80,Feedback,Feedback,80,docs/0.2/datasets/schemas/GTEx_sQTL_Vagina_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Vagina_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; GTEx_sQTL_Whole_Blood_all_snp_gene_associations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblast,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Whole_Blood_all_snp_gene_associations.html:85,Feedback,Feedback,85,docs/0.2/datasets/schemas/GTEx_sQTL_Whole_Blood_all_snp_gene_associations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/GTEx_sQTL_Whole_Blood_all_snp_gene_associations.html,1,['Feedback'],['Feedback']
Usability,"﻿. Hail | ; Genetics. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Aggregation; Annotation (Adding Fields); Genetics; Formatting; Convert variants in string format to separate locus and allele fields; Liftover variants from one coordinate system to another. Filtering and Pruning; Remove related individuals from a dataset; Filter loci by a list of locus intervals; Pruning Variants in Linkage Disequilibrium. Analysis; Linear Regression. PLINK Conversions; Polygenic Score Calculation. Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. How-To Guides; Genetics. View page source. Genetics; This page tailored how-to guides for small but commonly-used patterns; appearing in genetics pipelines. For documentation on the suite of; genetics functions built into Hail, see the genetics methods page. Formatting. Convert variants in string format to separate locus and allele fields. code:; >>> ht = ht.key_by(**hl.parse_variant(ht.variant)). dependencies:; parse_variant(), key_by(). understanding:. If your variants are strings of the format ‘chr:pos:ref:alt’, you may want; to convert them to separate locus and allele fields. This is useful if; you have imported a table with variants in string format and you would like to; join this table with other Hail tables that are keyed by locus and; alleles.; hl.parse_variant(ht.variant) constructs a StructExpression; containing two nested fields for the locus and alleles. The ** syntax unpacks; this struct so that the resulting table has two new fields, locus and; alleles. Liftover variants from one coordinate system to another. tags:; liftover. description:; Liftover a Table or MatrixTable from one reference genome to another. code:; First, we need to set up",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/guides/genetics.html:904,guid,guides,904,docs/0.2/guides/genetics.html,https://hail.is,https://hail.is/docs/0.2/guides/genetics.html,1,['guid'],['guides']
Usability,"﻿. Hail | ; Hail 0.2. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Hail 0.2. View page source. Hail 0.2; Hail is an open-source library for scalable data exploration and analysis, with; a particular emphasis on genomics. See the overview for; a high-level walkthrough of the library, the GWAS tutorial for a simple; example of conducting a genome-wide association study, and the installation page to get started; using Hail. Contents. Installation; Mac OS X; Linux; Google Dataproc; Azure HDInsight; Other Spark Clusters; After installation, try your first Hail query. Hail on the Cloud; General Advice; Query-on-Batch; Google Cloud; Microsoft Azure; Amazon Web Services; Databricks. Tutorials; Genome-Wide Association Study (GWAS) Tutorial; Table Tutorial; Aggregation Tutorial; Filtering and Annotation Tutorial; Table Joins Tutorial; MatrixTable Tutorial; Plotting Tutorial; GGPlot Tutorial. Reference (Python API); hail; hailtop.fs; hailtop.batch. Configuration Reference; Supported Configuration Variables. Overview; Expressions; Tables; MatrixTables. How-To Guides; Aggregation; Annotation (Adding Fields); Genetics. Cheatsheets; Datasets; Schemas. Annotation Database; Database Query. Libraries; gnomad (Hail Utilities for gnomAD). For Software Developers; Requirements; Building Hail; Building the Docs and Website; Running the tests; Contributing. Other Resources; Hadoop Glob Patterns. Change Log And Version Policy; Python Version Compatibility Policy; Frequently Asked Questions; Version 0.2.133; Version 0.2.132; Version 0.2.131; Version 0.2.130; Version 0.2.129; Version 0.2.128; Version 0.2.127; Version 0.2.126; Version 0.2.125; Version 0.2.124; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/index.html:646,simpl,simple,646,docs/0.2/index.html,https://hail.is,https://hail.is/docs/0.2/index.html,1,['simpl'],['simple']
Usability,"﻿. Hail | ; How-To Guides. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Aggregation; Annotation (Adding Fields); Genetics. Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. How-To Guides. View page source. How-To Guides. Note; Hail’s How-To Guides are in their early stages. We welcome suggestions; for additional guides, as well as feedback about our documentation. If; you’d like to add a guide to the documentation, make a pull request!. These guides are short, goal-oriented explanations of how to use Hail. Aggregation; Table Aggregations; Aggregate Over Rows Into A Local Value; One aggregation; Multiple aggregations. Aggregate Per Group. Matrix Table Aggregations; Aggregate Entries Per Row (Over Columns); Aggregate Entries Per Column (Over Rows); Aggregate Column Values Into a Local Value; One aggregation; Multiple aggregations. Aggregate Row Values Into a Local Value; One aggregation; Multiple aggregations. Aggregate Entry Values Into A Local Value; Aggregate Per Column Group; Aggregate Per Row Group. Annotation (Adding Fields); Create a nested annotation; Remove a nested annotation. Genetics; Formatting; Convert variants in string format to separate locus and allele fields; Liftover variants from one coordinate system to another. Filtering and Pruning; Remove related individuals from a dataset; Filter loci by a list of locus intervals; From a table of intervals; From a UCSC BED file; Using hl.filter_intervals; Declaring intervals with hl.parse_locus_interval. Pruning Variants in Linkage Disequilibrium. Analysis; Linear Regression; Single Phenotype; Multiple Phenotypes; Using Variants (SNPs) as Covariates; Stratified by Group. PLINK Conversions; Polygenic Score Calculation. Previous;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/guides.html:602,guid,guides,602,docs/0.2/guides.html,https://hail.is,https://hail.is/docs/0.2/guides.html,4,"['feedback', 'guid']","['feedback', 'guide', 'guides']"
Usability,"﻿. Hail | ; Install Hail on a Spark Cluster. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Mac OS X; Linux; Google Dataproc; Azure HDInsight; Other Spark Clusters; Next Steps. After installation, try your first Hail query. Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Installing Hail; Install Hail on a Spark Cluster. View page source. Install Hail on a Spark Cluster; If you are using Google Dataproc, please see these simpler instructions. If you; are using Azure HDInsight please see these simpler instructions.; Hail should work with any Spark 3.5.x cluster built with Scala 2.12.; Hail needs to be built from source on the leader node. Building Hail from source; requires:. Java 11 JDK.; Python 3.9 or later.; A recent C and a C++ compiler, GCC 5.0, LLVM 3.4, or later versions of either; suffice.; The LZ4 library.; BLAS and LAPACK. On a Debian-like system, the following should suffice:; apt-get update; apt-get install \; openjdk-11-jdk-headless \; g++ \; python3 python3-pip \; libopenblas-dev liblapack-dev \; liblz4-dev. The next block of commands downloads, builds, and installs Hail from source.; git clone https://github.com/hail-is/hail.git; cd hail/hail; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.18 SPARK_VERSION=3.5.0. If you forget to install any of the requirements before running make install-on-cluster, it’s possible; to get into a bad state where make insists you don’t have a requirement that you have in fact installed.; Try doing make clean and then a fresh invocation of the make install-on-cluster line if this happens.; On every worker node of the cluster, you must install a BLAS and LAPACK library; such as the Intel MKL or OpenBLAS. On a Debian-like sy",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/install/other-cluster.html:712,simpl,simpler,712,docs/0.2/install/other-cluster.html,https://hail.is,https://hail.is/docs/0.2/install/other-cluster.html,2,['simpl'],['simpler']
Usability,"﻿. Hail | ; Table Joins Tutorial. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Genome-Wide Association Study (GWAS) Tutorial; Table Tutorial; Aggregation Tutorial; Filtering and Annotation Tutorial; Table Joins Tutorial; The Key to Understanding Joins; Joining Tables; Exercises. MatrixTable Tutorial; Plotting Tutorial; GGPlot Tutorial. Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Hail Tutorials; Table Joins Tutorial. View page source. Table Joins Tutorial; This tutorial walks through some ways to join Hail tables. We’ll use a simple movie dataset to illustrate. The movie dataset comes in multiple parts. Here are a few questions we might naturally ask about the dataset:. What is the mean rating per genre?; What is the favorite movie for each occupation?; What genres are most preferred by women vs men?. We’ll use joins to combine datasets in order to answer these questions.; Let’s initialize Hail, fetch the tutorial data, and load three tables: users, movies, and ratings. [1]:. import hail as hl. hl.utils.get_movie_lens('data/'). users = hl.read_table('data/users.ht'); movies = hl.read_table('data/movies.ht'); ratings = hl.read_table('data/ratings.ht'). Loading BokehJS ... Initializing Hail with default parameters...; SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.5.0; SparkUI available at http://hostname-09f2439d4b:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.133-4c60fddb171a; LOGGING: writing to /io/hail/python/hail/docs/tutorials/hail-",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/tutorials/06-joins.html:825,simpl,simple,825,docs/0.2/tutorials/06-joins.html,https://hail.is,https://hail.is/docs/0.2/tutorials/06-joins.html,1,['simpl'],['simple']
Usability,"﻿. Hail | ; Table. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); hail; Classes; Table; GroupedTable; MatrixTable; GroupedMatrixTable. Modules; Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; Table. View page source. Table. class hail.Table[source]; Hail’s distributed implementation of a dataframe or SQL table.; Use read_table() to read a table that was written with; Table.write(). Use to_spark() and Table.from_spark(); to inter-operate with PySpark’s; SQL and; machine learning; functionality.; Examples; The examples below use table1 and table2, which are imported; from text files using import_table().; >>> table1 = hl.import_table('data/kt_example1.tsv', impute=True, key='ID'); >>> table1.show(). +-------+-------+-----+-------+-------+-------+-------+-------+; | ID | HT | SEX | X | Z | C1 | C2 | C3 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | int32 | int32 | str | int32 | int32 | int32 | int32 | int32 |; +-------+-------+-----+-------+-------+-------+-------+-------+; | 1 | 65 | M | 5 | 4 | 2 | 50 | 5 |; | 2 | 72 | M | 6 | 3 | 2 | 61 | 1 |; | 3 | 70 | F | 7 | 3 | 10 | 81 | -5 |; | 4 | 60 | F | 8 | 2 | 11 | 90 | -10 |; +-------+-------+-----+-------+-------+-------+-------+-------+. >>> table2 = hl.import_table('data/kt_example2.tsv', impute=True, key='ID'); >>> table2.show(). +-------+-------+--------+; | ID | A | B |; +-------+-------+--------+; | int32 | int32 | str |; +-------+-------+--------+; | 1 | 65 | cat |; | 2 | 72 | dog |; | 3 | 70 | mouse |; | 4 | 60 | rabbit |; +-------+-------+--------+. Define new annotations:; >>> height_mean_m = 68; >>> height_sd_m = 3; >>> he",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/hail.Table.html:846,learn,learning,846,docs/0.2/hail.Table.html,https://hail.is,https://hail.is/docs/0.2/hail.Table.html,1,['learn'],['learning']
Usability,﻿. Hail | ; UK_Biobank_Rapid_GWAS_both_sexes. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_both_sexes.html:70,Feedback,Feedback,70,docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_both_sexes.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_both_sexes.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; UK_Biobank_Rapid_GWAS_female. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_asso,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_female.html:66,Feedback,Feedback,66,docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_female.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_female.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; UK_Biobank_Rapid_GWAS_male. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associ,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_male.html:64,Feedback,Feedback,64,docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_male.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/UK_Biobank_Rapid_GWAS_male.html,1,['Feedback'],['Feedback']
Usability,"﻿. Hail | ; hail.context. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.context. Source code for hail.context; import os; import sys; import warnings; from contextlib import contextmanager; from random import Random; from types import TracebackType; from typing import Dict, List, Optional, Tuple, Type, Union; from urllib.parse import urlparse, urlunparse. from pyspark import SparkContext. import hail; from hail.backend import Backend; from hail.genetics.reference_genome import ReferenceGenome, reference_genome_type; from hail.typecheck import dictof, enumeration, nullable, oneof, sequenceof, sized_tupleof, typecheck, typecheck_method; from hail.utils import get_env_or_default; from hail.utils.java import BackendType, Env, choose_backend, warning; from hailtop.aiocloud.aiogoogle import GCSRequesterPaysConfiguration, get_gcs_requester_pays_configuration; from hailtop.fs.fs import FS; from hailtop.hail_event_loop import hail_event_loop; from hailtop.utils import secret_alnum_string. from . import __resource_str; from .backend.backend import local_jar_information; from .builtin_references import BUILTIN_REFERENCES. def _get_tmpdir(tmpdir):; if tmpdir is None:; tmpdir = '/tmp'; return tmpdir. def _get_local_tmpdir(local_tmpdir):; local_tmpdir = get_env_or_default(local_tmpdir, 'TMPDIR', 'file:///tmp'); r = urlparse(local_tmpdir); if not r.scheme:; r = r._replace(scheme='file'); elif r.scheme != 'file':; raise ValueError('invalid local_tmpfile: must use scheme file, got scheme {r.scheme}'); return urlunparse(r). def _get_log(log):; if log is None:; py_version = version(); log_dir = os.environ.get('HAIL_LOG_DIR'); if log_dir i",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/context.html:50,Feedback,Feedback,50,docs/0.2/_modules/hail/context.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/context.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.datasets. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.datasets. Source code for hail.experimental.datasets; from typing import Optional, Union. import hail as hl; from hail.matrixtable import MatrixTable; from hail.table import Table. from .datasets_metadata import get_datasets_metadata. def _read_dataset(path: str) -> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; if path.endswith('.ht'):; return hl.read_table(path); elif path.endswith('.mt'):; return hl.read_matrix_table(path); elif path.endswith('.bm'):; return hl.linalg.BlockMatrix.read(path); raise ValueError(f'Invalid path: {path}. Can only load datasets with .ht, .mt, or .bm extensions.'). [docs]def load_dataset(; name: str, version: Optional[str], reference_genome: Optional[str], region: str = 'us-central1', cloud: str = 'gcp'; ) -> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; """"""Load a genetic dataset from Hail's repository. Example; -------; >>> # Load the gnomAD ""HGDP + 1000 Genomes"" dense MatrixTable with GRCh38 coordinates.; >>> mt = hl.experimental.load_dataset(name='gnomad_hgdp_1kg_subset_dense',; ... version='3.1.2',; ... reference_genome='GRCh38',; ... region='us-central1',; ... cloud='gcp'). Parameters; ----------; name : :class:`str`; Name of the dataset to load.; version : :class:`str`, optional; Version of the named dataset to load (see available versions in; documentation). Possibly ``None`` for some datasets.; reference_genome : :class:`str`, optional; Reference genome build, ``'GRCh37'`` or ``'GRCh38'``. Possibly ``None``; for some datasets.; region : :class:`str`; Specify region for bucket, ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:64,Feedback,Feedback,64,docs/0.2/_modules/hail/experimental/datasets.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.db. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.db. Source code for hail.experimental.db; import warnings; from typing import ClassVar, Iterable, List, Optional, Set, Tuple, Union. import hail as hl; from hailtop.utils import external_requests_client_session, retry_response_returning_functions. from ..expr import StructExpression; from ..matrixtable import MatrixTable, matrix_table_type; from ..table import Table, table_type; from ..typecheck import oneof, typecheck_method; from ..utils.java import Env, info; from .datasets_metadata import get_datasets_metadata; from .lens import MatrixRows, TableRows. class DatasetVersion:; """""":class:`DatasetVersion` has two constructors: :func:`.from_json` and; :func:`.get_region`. Parameters; ----------; url : :obj:`dict` or :obj:`str`; Nested dictionary of URLs containing key: value pairs, like; ``cloud: {region: url}`` if using :func:`.from_json` constructor,; or a string with the URL from appropriate region if using the; :func:`.get_region` constructor.; version : :obj:`str`, optional; String of dataset version, if not ``None``.; reference_genome : :obj:`str`, optional; String of dataset reference genome, if not ``None``.; """""". @staticmethod; def from_json(doc: dict, cloud: str) -> Optional['DatasetVersion']:; """"""Create :class:`.DatasetVersion` object from dictionary. Parameters; ----------; doc : :obj:`dict`; Dictionary containing url and version keys.; Value for url is a :obj:`dict` containing key: value pairs, like; ``cloud: {region: url}``.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/db.html:58,Feedback,Feedback,58,docs/0.2/_modules/hail/experimental/db.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.export_entries_by_col. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.export_entries_by_col. Source code for hail.experimental.export_entries_by_col; import hail as hl; from hail.matrixtable import MatrixTable; from hail.typecheck import typecheck. [docs]@typecheck(; mt=MatrixTable, path=str, batch_size=int, bgzip=bool, header_json_in_file=bool, use_string_key_as_file_name=bool; ); def export_entries_by_col(; mt: MatrixTable,; path: str,; batch_size: int = 256,; bgzip: bool = True,; header_json_in_file: bool = True,; use_string_key_as_file_name: bool = False,; ):; """"""Export entries of the `mt` by column as separate text files. Examples; --------; >>> range_mt = hl.utils.range_matrix_table(10, 10); >>> range_mt = range_mt.annotate_entries(x = hl.rand_unif(0, 1)); >>> hl.experimental.export_entries_by_col(range_mt, 'output/cols_files'). Notes; -----; This function writes a directory with one file per column in `mt`. The; files contain one tab-separated field (with header) for each row field; and entry field in `mt`. The column fields of `mt` are written as JSON; in the first line of each file, prefixed with a ``#``. The above will produce a directory at ``output/cols_files`` with the; following files:. .. code-block:: text. $ ls -l output/cols_files; total 80; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 index.tsv; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-00.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-01.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-02.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-03.tsv.bgz; -rw-r--r-- 1 hail-dev ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/export_entries_by_col.html:77,Feedback,Feedback,77,docs/0.2/_modules/hail/experimental/export_entries_by_col.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/export_entries_by_col.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.expressions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.expressions. Source code for hail.experimental.expressions; import hail as hl; from hail.expr.expressions import analyze, expr_any; from hail.expr.table_type import ttable; from hail.expr.types import hail_type; from hail.typecheck import nullable, typecheck. [docs]@typecheck(expr=expr_any, path=str, overwrite=bool); def write_expression(expr, path, overwrite=False):; """"""Write an Expression. In the same vein as Python's pickle, write out an expression; that does not have a source (such as one that comes from; Table.aggregate with _localize=False). Example; -------; >>> ht = hl.utils.range_table(100).annotate(x=hl.rand_norm()); >>> mean_norm = ht.aggregate(hl.agg.mean(ht.x), _localize=False); >>> mean_norm; >>> hl.eval(mean_norm); >>> hl.experimental.write_expression(mean_norm, 'output/expression.he'). Parameters; ----------. expr : :class:`~.Expression`; Expression to write.; path : :class:`str`; Path to which to write expression.; Suggested extension: .he (hail expression).; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination. Returns; -------; None; """"""; source = expr._indices.source; if source is not None:; analyze('write_expression.expr', expr, source._global_indices); source = source.select_globals(__expr=expr); expr = source.index_globals().__expr; hl.utils.range_table(1).filter(False).key_by().drop('idx').annotate_globals(expr=expr).write(; path, overwrite=overwrite; ). [docs]@typecheck(path=str, _assert_type=nullable(hail_type)); def read_expression(path, _assert_type=None):; """"""R",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/expressions.html:67,Feedback,Feedback,67,docs/0.2/_modules/hail/experimental/expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/expressions.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.filtering_allele_frequency. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.filtering_allele_frequency. Source code for hail.experimental.filtering_allele_frequency; from hail.expr.expressions import Float64Expression, expr_float64, expr_int32; from hail.expr.functions import _func; from hail.expr.types import tfloat64; from hail.typecheck import typecheck. [docs]@typecheck(ac=expr_int32, an=expr_int32, ci=expr_float64); def filtering_allele_frequency(ac, an, ci) -> Float64Expression:; """"""; Computes a filtering allele frequency (described below); for `ac` and `an` with confidence `ci`. The filtering allele frequency is the highest true population allele frequency; for which the upper bound of the `ci` (confidence interval) of allele count; under a Poisson distribution is still less than the variant's observed; `ac` (allele count) in the reference sample, given an `an` (allele number). This function defines a ""filtering AF"" that represents; the threshold disease-specific ""maximum credible AF"" at or below which; the disease could not plausibly be caused by that variant. A variant with; a filtering AF >= the maximum credible AF for the disease under consideration; should be filtered, while a variant with a filtering AF below the maximum; credible remains a candidate. This filtering AF is not disease-specific:; it can be applied to any disease of interest by comparing with a; user-defined disease-specific maximum credible AF. For more details, see: `Whiffin et al., 2017 <https://www.nature.com/articles/gim201726>`__. Parameters; ----------; ac : int or :class:`.Expression` of type :p",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/filtering_allele_frequency.html:82,Feedback,Feedback,82,docs/0.2/_modules/hail/experimental/filtering_allele_frequency.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/filtering_allele_frequency.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.full_outer_join_mt. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.full_outer_join_mt. Source code for hail.experimental.full_outer_join_mt; import hail as hl; from hail.matrixtable import MatrixTable. [docs]def full_outer_join_mt(left: MatrixTable, right: MatrixTable) -> MatrixTable:; """"""Performs a full outer join on `left` and `right`. Replaces row, column, and entry fields with the following:. - `left_row` / `right_row`: structs of row fields from left and right.; - `left_col` / `right_col`: structs of column fields from left and right.; - `left_entry` / `right_entry`: structs of entry fields from left and right. Examples; --------. The following creates and joins two random datasets with disjoint sample ids; but non-disjoint variant sets. We use :func:`.or_else` to attempt to find a; non-missing genotype. If neither genotype is non-missing, then the genotype; is set to missing. In particular, note that Samples `2` and `3` have missing; genotypes for loci 1:1 and 1:2 because those loci are not present in `mt2`; and these samples are not present in `mt1`. >>> hl.reset_global_randomness(); >>> mt1 = hl.balding_nichols_model(1, 2, 3); >>> mt2 = hl.balding_nichols_model(1, 2, 3); >>> mt2 = mt2.key_rows_by(locus=hl.locus(mt2.locus.contig,; ... mt2.locus.position+2),; ... alleles=mt2.alleles); >>> mt2 = mt2.key_cols_by(sample_idx=mt2.sample_idx+2); >>> mt1.show(); +---------------+------------+------+------+; | locus | alleles | 0.GT | 1.GT |; +---------------+------------+------+------+; | locus<GRCh37> | array<str> | call | call |; +---------------+------------+------+------+; | ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html:74,Feedback,Feedback,74,docs/0.2/_modules/hail/experimental/full_outer_join_mt.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.import_gtf. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.import_gtf. Source code for hail.experimental.import_gtf; import functools; import operator. import hail as hl; from hail.genetics.reference_genome import reference_genome_type; from hail.table import Table; from hail.typecheck import nullable, sequenceof, typecheck; from hail.utils import new_temp_file; from hail.utils.java import info. [docs]@typecheck(; path=str,; reference_genome=nullable(reference_genome_type),; skip_invalid_contigs=bool,; min_partitions=nullable(int),; force_bgz=bool,; force=bool,; ); def import_gtf(; path, reference_genome=None, skip_invalid_contigs=False, min_partitions=None, force_bgz=False, force=False; ) -> Table:; """"""Import a GTF file. The GTF file format is identical to the GFF version 2 file format,; and so this function can be used to import GFF version 2 files as; well. See https://www.ensembl.org/info/website/upload/gff.html for more; details on the GTF/GFF2 file format. The :class:`.Table` returned by this function will be keyed by the; ``interval`` row field and will include the following row fields:. .. code-block:: text. 'source': str; 'feature': str; 'score': float64; 'strand': str; 'frame': int32; 'interval': interval<>. There will also be corresponding fields for every tag found in the; attribute field of the GTF file. Note; ----. This function will return an ``interval`` field of type :class:`.tinterval`; constructed from the ``seqname``, ``start``, and ``end`` fields in the; GTF file. This interval is inclusive of both the start and end positions; in the GTF file. If the ``refer",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:66,Feedback,Feedback,66,docs/0.2/_modules/hail/experimental/import_gtf.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.ld_score_regression. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.ld_score_regression. Source code for hail.experimental.ld_score_regression; import hail as hl; from hail.expr.expressions import analyze, expr_float64, expr_numeric; from hail.table import Table; from hail.typecheck import nullable, oneof, sequenceof, typecheck; from hail.utils import new_temp_file, wrap_to_list. [docs]@typecheck(; weight_expr=expr_float64,; ld_score_expr=expr_numeric,; chi_sq_exprs=oneof(expr_float64, sequenceof(expr_float64)),; n_samples_exprs=oneof(expr_numeric, sequenceof(expr_numeric)),; n_blocks=int,; two_step_threshold=int,; n_reference_panel_variants=nullable(int),; ); def ld_score_regression(; weight_expr,; ld_score_expr,; chi_sq_exprs,; n_samples_exprs,; n_blocks=200,; two_step_threshold=30,; n_reference_panel_variants=None,; ) -> Table:; r""""""Estimate SNP-heritability and level of confounding biases from genome-wide association study; (GWAS) summary statistics. Given a set or multiple sets of GWAS summary statistics, :func:`.ld_score_regression` estimates the heritability; of a trait or set of traits and the level of confounding biases present in; the underlying studies by regressing chi-squared statistics on LD scores,; leveraging the model:. .. math::. \mathrm{E}[\chi_j^2] = 1 + Na + \frac{Nh_g^2}{M}l_j. * :math:`\mathrm{E}[\chi_j^2]` is the expected chi-squared statistic; for variant :math:`j` resulting from a test of association between; variant :math:`j` and a trait.; * :math:`l_j = \sum_{k} r_{jk}^2` is the LD score of variant; :math:`j`, calculated as the sum of squared correlat",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:75,Feedback,Feedback,75,docs/0.2/_modules/hail/experimental/ld_score_regression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.ldscore. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.ldscore. Source code for hail.experimental.ldscore; import hail as hl; from hail.expr.expressions import expr_float64, expr_locus, expr_numeric; from hail.linalg import BlockMatrix; from hail.table import Table; from hail.typecheck import nullable, oneof, sequenceof, typecheck; from hail.utils import new_temp_file, wrap_to_list. [docs]@typecheck(; entry_expr=expr_float64,; locus_expr=expr_locus(),; radius=oneof(int, float),; coord_expr=nullable(expr_float64),; annotation_exprs=nullable(oneof(expr_numeric, sequenceof(expr_numeric))),; block_size=nullable(int),; ); def ld_score(entry_expr, locus_expr, radius, coord_expr=None, annotation_exprs=None, block_size=None) -> Table:; """"""Calculate LD scores. Example; -------. >>> # Load genetic data into MatrixTable; >>> mt = hl.import_plink(bed='data/ldsc.bed',; ... bim='data/ldsc.bim',; ... fam='data/ldsc.fam'). >>> # Create locus-keyed Table with numeric variant annotations; >>> ht = hl.import_table('data/ldsc.annot',; ... types={'BP': hl.tint,; ... 'binary': hl.tfloat,; ... 'continuous': hl.tfloat}); >>> ht = ht.annotate(locus=hl.locus(ht.CHR, ht.BP)); >>> ht = ht.key_by('locus'). >>> # Annotate MatrixTable with external annotations; >>> mt = mt.annotate_rows(binary_annotation=ht[mt.locus].binary,; ... continuous_annotation=ht[mt.locus].continuous). >>> # Calculate LD scores using centimorgan coordinates; >>> ht_scores = hl.experimental.ld_score(entry_expr=mt.GT.n_alt_alleles(),; ... locus_expr=mt.locus,; ... radius=1.0,; ... coord_expr=mt.cm_position,; ... annotation_exprs=[mt.bi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html:63,Feedback,Feedback,63,docs/0.2/_modules/hail/experimental/ldscore.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.ldscsim. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.ldscsim. Source code for hail.experimental.ldscsim; #!/usr/bin/env python3; # -*- coding: utf-8 -*-; """"""; Simulation framework for testing LDSC. Models for SNP effects:; - Infinitesimal (can simulate n correlated traits); - Spike & slab (can simulate up to 2 correlated traits); - Annotation-informed. Features:; - Field aggregation tools for annotation-informed model and; population stratification with many covariates.; - Automatic adjustment of genetic correlation parameters; to allow for the joint simulation of up to 100 randomly; correlated phenotypes.; - Methods for binarizing phenotypes to have a certain prevalence; and for adding ascertainment bias to binarized phenotypes. @author: nbaya; """""". import numpy as np; import pandas as pd; from scipy import stats. import hail as hl; from hail.expr.expressions import expr_array, expr_call, expr_float64, expr_int32; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import nullable, oneof, typecheck; from hail.utils.java import Env. [docs]@typecheck(; mt=MatrixTable,; genotype=oneof(expr_int32, expr_float64, expr_call),; h2=(oneof(float, int, list, np.ndarray)),; pi=nullable(oneof(float, int, list, np.ndarray)),; rg=nullable(oneof(float, int, list, np.ndarray)),; annot=nullable(oneof(expr_float64, expr_int32)),; popstrat=nullable(oneof(expr_int32, expr_float64)),; popstrat_var=nullable(oneof(float, int)),; exact_h2=bool,; ); def simulate_phenotypes(; mt, genotype, h2, pi=None, rg=None, annot=None, popstrat=None, popstrat_var=None, exact",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:63,Feedback,Feedback,63,docs/0.2/_modules/hail/experimental/ldscsim.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.loop. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.loop. Source code for hail.experimental.loop; from typing import Callable. from hail import ir; from hail.expr.expressions import construct_expr, construct_variable, expr_any, to_expr, unify_all; from hail.expr.types import hail_type; from hail.typecheck import anytype, typecheck; from hail.utils.java import Env. [docs]@typecheck(f=anytype, typ=hail_type, args=expr_any); def loop(f: Callable, typ, *args):; r""""""Define and call a tail-recursive function with given arguments. Notes; -----; The argument `f` must be a function where the first argument defines the; recursive call, and the remaining arguments are the arguments to the; recursive function, e.g. to define the recursive function. .. math::. f(x, y) = \begin{cases}; y & \textrm{if } x \equiv 0 \\; f(x - 1, y + x) & \textrm{otherwise}; \end{cases}. we would write:; >>> f = lambda recur, x, y: hl.if_else(x == 0, y, recur(x - 1, y + x)). Full recursion is not supported, and any non-tail-recursive methods will; throw an error when called. This means that the result of any recursive call within the function must; also be the result of the entire function, without modification. Let's; consider two different recursive definitions for the triangle function; :math:`f(x) = 0 + 1 + \dots + x`:. >>> def triangle1(x):; ... if x == 1:; ... return x; ... return x + triangle1(x - 1). >>> def triangle2(x, total):; ... if x == 0:; ... return total; ... return triangle2(x - 1, total + x). The first function definition, `triangle1`, will call itself and then add x.; This is an example of a n",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:60,Feedback,Feedback,60,docs/0.2/_modules/hail/experimental/loop.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.pca. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.pca. Source code for hail.experimental.pca; import hail as hl; from hail.expr.expressions import (; expr_array,; expr_call,; expr_numeric,; raise_unless_entry_indexed,; raise_unless_row_indexed,; ); from hail.typecheck import typecheck. [docs]@typecheck(call_expr=expr_call, loadings_expr=expr_array(expr_numeric), af_expr=expr_numeric); def pc_project(call_expr, loadings_expr, af_expr):; """"""Projects genotypes onto pre-computed PCs. Requires loadings and; allele-frequency from a reference dataset (see example). Note that; `loadings_expr` must have no missing data and reflect the rows; from the original PCA run for this method to be accurate. Example; -------; >>> # Compute loadings and allele frequency for reference dataset; >>> _, _, loadings_ht = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=True) # doctest: +SKIP; >>> mt = mt.annotate_rows(af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:59,Feedback,Feedback,59,docs/0.2/_modules/hail/experimental/pca.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.phase_by_transmission. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.phase_by_transmission. Source code for hail.experimental.phase_by_transmission; from typing import List. import hail as hl; from hail.expr.expressions import expr_array, expr_call, expr_locus, expr_str; from hail.matrixtable import MatrixTable; from hail.typecheck import sequenceof, typecheck. [docs]@typecheck(; locus=expr_locus(),; alleles=expr_array(expr_str),; proband_call=expr_call,; father_call=expr_call,; mother_call=expr_call,; ); def phase_by_transmission(; locus: hl.expr.LocusExpression,; alleles: hl.expr.ArrayExpression,; proband_call: hl.expr.CallExpression,; father_call: hl.expr.CallExpression,; mother_call: hl.expr.CallExpression,; ) -> hl.expr.ArrayExpression:; """"""Phases genotype calls in a trio based allele transmission. Notes; -----; In the phased calls returned, the order is as follows:; - Proband: father_allele | mother_allele; - Parents: transmitted_allele | untransmitted_allele. Phasing of sex chromosomes:; - Sex chromosomes of male individuals should be haploid to be phased correctly.; - If `proband_call` is diploid on non-par regions of the sex chromosomes, it is assumed to be female. Returns `NA` when genotype calls cannot be phased.; The following genotype calls combinations cannot be phased by transmission:; 1. One of the calls in the trio is missing; 2. The proband genotype cannot be obtained from the parents alleles (Mendelian violation); 3. All individuals of the trio are heterozygous for the same two alleles; 4. Father is diploid on non-PAR region of X or Y; 5. Proband is diploid o",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/phase_by_transmission.html:77,Feedback,Feedback,77,docs/0.2/_modules/hail/experimental/phase_by_transmission.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/phase_by_transmission.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.plots. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.plots. Source code for hail.experimental.plots; import json. import numpy as np; import pandas as pd; from bokeh.layouts import gridplot; from bokeh.models import ColumnDataSource, Div, HoverTool, TabPanel, Tabs, Title; from bokeh.palettes import Spectral8; from bokeh.plotting import figure; from bokeh.transform import factor_cmap. import hail as hl; from hail.typecheck import typecheck; from hail.utils.hadoop_utils import hadoop_ls, hadoop_open; from hail.utils.java import warning. [docs]def plot_roc_curve(ht, scores, tp_label='tp', fp_label='fp', colors=None, title='ROC Curve', hover_mode='mouse'):; """"""Create ROC curve from Hail Table. One or more `score` fields must be provided, which are assessed against `tp_label` and `fp_label` as truth data. High scores should correspond to true positives. Parameters; ----------; ht : :class:`.Table`; Table with required data; scores : :class:`str` or :obj:`list` of :obj:`.str`; Top-level location of scores in ht against which to generate PR curves.; tp_label : :class:`str`; Top-level location of true positives in ht.; fp_label : :class:`str`; Top-level location of false positives in ht.; colors : :obj:`dict` of :class:`str`; Optional colors to use (score -> desired color).; title : :class:`str`; Title of plot.; hover_mode : :class:`str`; Hover mode; one of 'mouse' (default), 'vline' or 'hline'. Returns; -------; :obj:`tuple` of :class:`bokeh.plotting.figure` and :obj:`list` of :class:`str`; Figure, and list of AUCs corresponding to scores.; """"""; if colors is None:; # Get a palette aut",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/plots.html:61,Feedback,Feedback,61,docs/0.2/_modules/hail/experimental/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/plots.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.tidyr. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.tidyr. Source code for hail.experimental.tidyr; import hail as hl; from hail.table import Table; from hail.typecheck import nullable, oneof, sequenceof, typecheck; from hail.utils import new_temp_file, wrap_to_list. [docs]@typecheck(ht=Table, key=str, value=str, fields=str); def gather(ht, key, value, *fields) -> Table:; """"""Collapse fields into key-value pairs. :func:`.gather` mimics the functionality of the `gather()` function found in R's; ``tidyr`` package. This is a way to turn ""wide"" format data into ""long""; format data. Parameters; ----------; ht : :class:`.Table`; A Hail table.; key : :class:`str`; The name of the key field in the gathered table.; value : :class:`str`; The name of the value field in the gathered table.; fields : variable-length args of obj:`str`; Names of fields to gather in ``ht``. Returns; -------; :class:`.Table`; Table with original ``fields`` gathered into ``key`` and ``value`` fields."""""". ht = ht.annotate(_col_val=hl.array([hl.struct(field_name=field, value=ht[field]) for field in fields])); ht = ht.drop(*fields); ht = ht.explode(ht['_col_val']); ht = ht.annotate(**{key: ht['_col_val'][0], value: ht['_col_val'][1]}); ht = ht.drop('_col_val'). ht_tmp = new_temp_file(); ht.write(ht_tmp). return hl.read_table(ht_tmp). [docs]@typecheck(ht=Table, field=str, value=str, key=nullable(oneof(str, sequenceof(str)))); def spread(ht, field, value, key=None) -> Table:; """"""Spread a key-value pair of fields across multiple fields. :func:`.spread` mimics the functionality of the `spread()` function in R's; `tidyr",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/tidyr.html:61,Feedback,Feedback,61,docs/0.2/_modules/hail/experimental/tidyr.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/tidyr.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.experimental.time. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.time. Source code for hail.experimental.time; import hail as hl; from hail.expr.expressions import expr_int64, expr_str; from hail.expr.functions import _func; from hail.typecheck import typecheck. [docs]@typecheck(format=expr_str, time=expr_int64, zone_id=expr_str); def strftime(format, time, zone_id):; """"""; Convert Unix timestamp to a formatted datetime string. Examples; --------. >>> hl.eval(hl.experimental.strftime(""%Y.%m.%d %H:%M:%S %z"", 1562569201, ""America/New_York"")); '2019.07.08 03:00:01 -04:00'. >>> hl.eval(hl.experimental.strftime(""%A, %B %e, %Y. %r"", 876541523, ""GMT+2"")); 'Saturday, October 11, 1997. 05:45:23 AM'. >>> hl.eval(hl.experimental.strftime(""%A, %B %e, %Y. %r"", 876541523, ""+08:00"")); 'Saturday, October 11, 1997. 11:45:23 AM'. Notes; -----; The following formatting characters are supported in format strings: A a B b D d e F H I j k l M m n p R r S s T t U u V v W Y y z; See documentation here: https://linux.die.net/man/3/strftime. A zone id can take one of three forms. It can be an explicit offset, like ""+01:00"", a relative offset, like ""GMT+2"",; or a IANA timezone database (TZDB) identifier, like ""America/New_York"". Wikipedia maintains a list of TZDB identifiers here: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones. Currently, the formatter implicitly uses the ""en_US"" locale. Parameters; ----------; format : str or :class:`.Expression` of type :py:data:`.tstr`; The format string describing how to render the time.; time : int of :class:`.Expression` of type :py:data:`.tint64`; A long represent",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/experimental/time.html:60,Feedback,Feedback,60,docs/0.2/_modules/hail/experimental/time.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/time.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.expr.aggregators.aggregators. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.aggregators.aggregators. Source code for hail.expr.aggregators.aggregators; import difflib; from functools import update_wrapper, wraps. import hail as hl; from hail import ir; from hail.expr import (; Aggregation,; ArrayExpression,; BooleanExpression,; DictExpression,; Expression,; ExpressionException,; Float64Expression,; Indices,; Int64Expression,; NDArrayNumericExpression,; NumericExpression,; SetExpression,; StringExpression,; StructExpression,; cast_expr,; construct_expr,; expr_any,; expr_array,; expr_bool,; expr_call,; expr_float64,; expr_int32,; expr_int64,; expr_ndarray,; expr_numeric,; expr_oneof,; expr_set,; expr_str,; to_expr,; unify_all,; unify_types,; ); from hail.expr.expressions.typed_expressions import construct_variable; from hail.expr.functions import _quantile_from_cdf, _result_from_raw_cdf, float32, rbind; from hail.expr.types import (; hail_type,; tarray,; tbool,; tcall,; tdict,; tfloat32,; tfloat64,; tint32,; tint64,; tset,; tstr,; tstruct,; ttuple,; ); from hail.typecheck import TypeChecker, func_spec, identity, nullable, oneof, sequenceof, typecheck, typecheck_method; from hail.utils import wrap_to_list; from hail.utils.java import Env. class AggregableChecker(TypeChecker):; def __init__(self, coercer):; self.coercer = coercer; super(AggregableChecker, self).__init__(). def expects(self):; return self.coercer.expects(). def format(self, arg):; return self.coercer.format(arg). def check(self, x, caller, param):; x = self.coercer.check(x, caller, param); if len(x._ir.search(lambda node: isinstance(nod",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html:71,Feedback,Feedback,71,docs/0.2/_modules/hail/expr/aggregators/aggregators.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/aggregators/aggregators.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.expr.builders. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.builders. Source code for hail.expr.builders; import hail as hl; from hail import ir; from hail.expr.expressions import (; ExpressionException,; construct_expr,; expr_any,; expr_bool,; expr_str,; unify_types,; unify_types_limited,; ); from hail.typecheck import typecheck_method. class ConditionalBuilder(object):; def __init__(self):; self._ret_type = None; self._cases = []. def _unify_type(self, t):; if self._ret_type is None:; self._ret_type = t; else:; r = unify_types_limited(self._ret_type, t); if not r:; raise TypeError(""'then' expressions must have same type, found '{}' and '{}'"".format(self._ret_type, t)). [docs]class SwitchBuilder(ConditionalBuilder):; """"""Class for generating conditional trees based on value of an expression. Examples; --------. >>> csq = hl.literal('loss of function'); >>> expr = (hl.switch(csq); ... .when('synonymous', 1); ... .when('SYN', 1); ... .when('missense', 2); ... .when('MIS', 2); ... .when('loss of function', 3); ... .when('LOF', 3); ... .or_missing()); >>> hl.eval(expr); 3. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.SwitchBuilder.when` or; :meth:`~hail.expr.builders.SwitchBuilder.default` method calls must be the; same type. See Also; --------; :func:`.case`, :func:`.cond`, :func:`.switch`. Parameters; ----------; expr : :class:`.Expression`; Value to match against.; """""". @typecheck_method(base=expr_any); def __init__(self, base):; self._base = base; self._when_missing_case = None; super(SwitchBuilder, self).__init__(). def _finish(self, default):; a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/builders.html:56,Feedback,Feedback,56,docs/0.2/_modules/hail/expr/builders.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.expr.expressions.base_expression. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.expressions.base_expression. Source code for hail.expr.expressions.base_expression; from typing import Any, List, Mapping, Tuple, overload. import numpy as np; import pandas as pd. import hail; import hail as hl; from hail import ir; from hail.expr import expressions; from hail.expr.types import (; HailType,; from_numpy,; is_compound,; is_numeric,; is_setlike,; summary_type,; tarray,; tbool,; tcall,; tdict,; tfloat32,; tfloat64,; tint32,; tint64,; tinterval,; tlocus,; tndarray,; tset,; tstr,; tstruct,; ttuple,; ); from hail.typecheck import anyfunc, linked_list, nullable, typecheck_method; from hail.utils.java import Env; from hail.utils.linkedlist import LinkedList. from .indices import Aggregation, Indices. class Summary(object):; def __init__(self, type, count, summ_fields, nested, header=None):; self.count = count; self.summ_fields = summ_fields; self.nested = nested; self.type = type; self.header = header. @staticmethod; def pct(x):; return f'{x*100:.2f}%'. @staticmethod; def format(x):; if isinstance(x, float):; return f'{x:.2f}'; else:; return str(x). def __str__(self):; return self._ascii_string(depth=0, prefix=None). def __repr__(self):; return self.__str__(). def _repr_html_(self):; return self._html_string(prefix=None). def _ascii_string(self, depth, prefix):; spacing = ' ' * depth. summary = ''; if self.header:; summary += f'\n{spacing}{self.header}'. if prefix is not None:; summary += f'\n\n{spacing}- {prefix} ({summary_type(self.type)}):'. if len(self.summ_fields) > 0:; max_n_len = max(len(n) for n in self",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html:75,Feedback,Feedback,75,docs/0.2/_modules/hail/expr/expressions/base_expression.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/base_expression.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.expr.expressions.expression_utils. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.expressions.expression_utils. Source code for hail.expr.expressions.expression_utils; from typing import Dict, Set. from hail.typecheck import setof, typecheck. from ...ir import MakeTuple; from ..expressions import Expression, ExpressionException, expr_any; from .indices import Aggregation, Indices. @typecheck(caller=str, expr=Expression, expected_indices=Indices, aggregation_axes=setof(str), broadcast=bool); def analyze(caller: str, expr: Expression, expected_indices: Indices, aggregation_axes: Set = set(), broadcast=True):; from hail.utils import error, warning. indices = expr._indices; source = indices.source; axes = indices.axes; aggregations = expr._aggregations. warnings = []; errors = []. expected_source = expected_indices.source; expected_axes = expected_indices.axes. if source is not None and source is not expected_source:; bad_refs = []; for name, inds in get_refs(expr).items():; if inds.source is not expected_source:; bad_refs.append(name); errors.append(; ExpressionException(; ""'{caller}': source mismatch\n""; "" Expected an expression from source {expected}\n""; "" Found expression derived from source {actual}\n""; "" Problematic field(s): {bad_refs}\n\n""; "" This error is commonly caused by chaining methods together:\n""; "" >>> ht.distinct().select(ht.x)\n\n""; "" Correct usage:\n""; "" >>> ht = ht.distinct()\n""; "" >>> ht = ht.select(ht.x)"".format(; caller=caller, expected=expected_source, actual=source, bad_refs=list(bad_refs); ); ); ). # check for stray indices by subtracting expected axes from observed; if broadc",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html:76,Feedback,Feedback,76,docs/0.2/_modules/hail/expr/expressions/expression_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/expression_utils.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.expr.expressions.typed_expressions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.expressions.typed_expressions. Source code for hail.expr.expressions.typed_expressions; from typing import Dict, Mapping, Optional, Sequence, Union. import numpy as np; from deprecated import deprecated. import hail as hl; from hail import ir; from hail.expr.types import (; HailType,; is_numeric,; tarray,; tbool,; tcall,; tdict,; tfloat32,; tfloat64,; tint32,; tint64,; tinterval,; tlocus,; tndarray,; tset,; tstr,; tstream,; tstruct,; ttuple,; ); from hail.typecheck import (; anyfunc,; dictof,; func_spec,; identity,; nullable,; oneof,; sliceof,; tupleof,; typecheck,; typecheck_method,; ); from hail.utils.java import Env, warning; from hail.utils.linkedlist import LinkedList; from hail.utils.misc import get_nice_attr_error, get_nice_field_error, wrap_to_list, wrap_to_tuple. from .base_expression import Expression, ExpressionException, to_expr, unify_all, unify_types; from .expression_typecheck import (; coercer_from_dtype,; expr_any,; expr_array,; expr_bool,; expr_dict,; expr_int32,; expr_int64,; expr_interval,; expr_ndarray,; expr_numeric,; expr_oneof,; expr_set,; expr_str,; expr_tuple,; ); from .indices import Aggregation, Indices. [docs]class CollectionExpression(Expression):; """"""Expression of type :class:`.tarray` or :class:`.tset`. >>> a = hl.literal([1, 2, 3, 4, 5]). >>> s3 = hl.literal({'Alice', 'Bob', 'Charlie'}); """""". def _filter_missing_method(self, filter_missing: bool, name: str, ret_type: HailType, *args):; collection = self; if filter_missing:; collection = self.filter(hl.is_defined); return collection._me",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html:77,Feedback,Feedback,77,docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/expressions/typed_expressions.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.expr.functions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.functions. Source code for hail.expr.functions; import builtins; import functools; import itertools; import operator; from typing import Any, Callable, Iterable, Optional, TypeVar, Union. import numpy as np; import pandas as pd; from deprecated import deprecated. import hail; import hail as hl; from hail import ir; from hail.expr.expressions import (; ArrayExpression,; ArrayNumericExpression,; BooleanExpression,; CallExpression,; DictExpression,; Expression,; ExpressionException,; Float32Expression,; Float64Expression,; Int32Expression,; Int64Expression,; IntervalExpression,; LocusExpression,; NumericExpression,; SetExpression,; StreamExpression,; StringExpression,; StructExpression,; TupleExpression,; apply_expr,; cast_expr,; coercer_from_dtype,; construct_expr,; construct_variable,; expr_any,; expr_array,; expr_bool,; expr_call,; expr_dict,; expr_float32,; expr_float64,; expr_int32,; expr_int64,; expr_interval,; expr_locus,; expr_ndarray,; expr_numeric,; expr_oneof,; expr_set,; expr_str,; expr_stream,; expr_struct,; expr_tuple,; impute_type,; to_expr,; unify_all,; unify_exprs,; unify_types_limited,; ); from hail.expr.types import (; HailType,; hail_type,; is_float32,; is_float64,; is_int32,; is_int64,; is_numeric,; is_primitive,; tarray,; tbool,; tcall,; tdict,; tfloat32,; tfloat64,; tint32,; tint64,; tinterval,; tlocus,; tndarray,; trngstate,; tset,; tstr,; tstream,; tstruct,; ttuple,; ); from hail.genetics.allele_type import AlleleType; from hail.genetics.reference_genome import ReferenceGenome, reference_genome_type; from hail.typec",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/functions.html:57,Feedback,Feedback,57,docs/0.2/_modules/hail/expr/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.expr.types. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.expr.types. Source code for hail.expr.types; import abc; import builtins; import json; import math; import pprint; from collections.abc import Mapping, Sequence; from typing import ClassVar, Union. import numpy as np; import pandas as pd. import hail as hl; from hailtop.frozendict import frozendict; from hailtop.hail_frozenlist import frozenlist. from .. import genetics; from ..genetics.reference_genome import reference_genome_type; from ..typecheck import nullable, oneof, transformed, typecheck, typecheck_method; from ..utils.byte_reader import ByteReader, ByteWriter; from ..utils.java import escape_parsable; from ..utils.misc import lookup_bit; from ..utils.struct import Struct; from .nat import NatBase, NatLiteral; from .type_parsing import type_grammar, type_grammar_str, type_node_visitor. __all__ = [; 'dtype',; 'dtypes_from_pandas',; 'HailType',; 'hail_type',; 'is_container',; 'is_compound',; 'is_numeric',; 'is_primitive',; 'types_match',; 'tint',; 'tint32',; 'tint64',; 'tfloat',; 'tfloat32',; 'tfloat64',; 'tstr',; 'tbool',; 'tarray',; 'tstream',; 'tndarray',; 'tset',; 'tdict',; 'tstruct',; 'tunion',; 'ttuple',; 'tinterval',; 'tlocus',; 'tcall',; 'tvoid',; 'tvariable',; 'hts_entry_schema',; ]. def summary_type(t):; if isinstance(t, hl.tdict):; return f'dict<{summary_type(t.key_type)}, {summary_type(t.value_type)}>'; elif isinstance(t, hl.tset):; return f'set<{summary_type(t.element_type)}>'; elif isinstance(t, hl.tarray):; return f'array<{summary_type(t.element_type)}>'; elif isinstance(t, hl.tstruct):; return f'struct with {len(t)} fields';",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/expr/types.html:53,Feedback,Feedback,53,docs/0.2/_modules/hail/expr/types.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.genetics.allele_type. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.allele_type. Source code for hail.genetics.allele_type; from enum import IntEnum, auto. _ALLELE_STRS = (; ""Unknown"",; ""SNP"",; ""MNP"",; ""Insertion"",; ""Deletion"",; ""Complex"",; ""Star"",; ""Symbolic"",; ""Transition"",; ""Transversion"",; ). [docs]class AlleleType(IntEnum):; """"""An enumeration for allele type. Notes; -----; The precise values of the enumeration constants are not guarenteed; to be stable and must not be relied upon.; """""". UNKNOWN = 0; """"""Unknown Allele Type""""""; SNP = auto(); """"""Single-nucleotide Polymorphism (SNP)""""""; MNP = auto(); """"""Multi-nucleotide Polymorphism (MNP)""""""; INSERTION = auto(); """"""Insertion""""""; DELETION = auto(); """"""Deletion""""""; COMPLEX = auto(); """"""Complex Polymorphism""""""; STAR = auto(); """"""Star Allele (``alt=*``)""""""; SYMBOLIC = auto(); """"""Symbolic Allele. e.g. ``alt=<INS>``; """"""; TRANSITION = auto(); """"""Transition SNP. e.g. ``ref=A alt=G``. Note; ----; This is only really used internally in :func:`hail.vds.sample_qc` and; :func:`hail.methods.sample_qc`.; """"""; TRANSVERSION = auto(); """"""Transversion SNP. e.g. ``ref=A alt=C``. Note; ----; This is only really used internally in :func:`hail.vds.sample_qc` and; :func:`hail.methods.sample_qc`.; """""". def __str__(self):; return str(self.value). @property; def pretty_name(self):; """"""A formatted (as opposed to uppercase) version of the member's name,; to match :func:`~hail.expr.functions.allele_type`. Examples; --------; >>> AlleleType.INSERTION.pretty_name; 'Insertion'; >>> at = AlleleType(hl.eval(hl.numeric_allele_type('a', 'att'))); >>> at.pretty_name == hl.eval(hl",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/allele_type.html:63,Feedback,Feedback,63,docs/0.2/_modules/hail/genetics/allele_type.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/allele_type.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.genetics.call. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.call. Source code for hail.genetics.call; from collections.abc import Sequence. from hail.typecheck import typecheck_method. [docs]class Call(object):; """"""; An object that represents an individual's call at a genomic locus. Parameters; ----------; alleles : :obj:`list` of :obj:`int`; List of alleles that compose the call.; phased : :obj:`bool`; If ``True``, the alleles are phased and the order is specified by; `alleles`. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.GT.take(5`)``. This is rare; it is much; more common to manipulate the :class:`.CallExpression` object, which is; constructed using the following functions:. - :func:`.call`; - :func:`.unphased_diploid_gt_index_call`; - :func:`.parse_call`; """""". def __init__(self, alleles, phased=False):; # Intentionally not using the type check annotations which are too slow.; assert isinstance(alleles, Sequence); assert isinstance(phased, bool). if len(alleles) > 2:; raise NotImplementedError(""Calls with greater than 2 alleles are not supported.""); self._phased = phased; ploidy = len(alleles); if phased or ploidy < 2:; self._alleles = alleles; else:; assert ploidy == 2; a0 = alleles[0]; a1 = alleles[1]; if a1 < a0:; a0, a1 = a1, a0; self._alleles = [a0, a1]. def __str__(self):; n = self.ploidy; if n == 0:; if self._phased:; return '|-'; return '-'. if n == 1:; if self._phased:; return f'|{self._alleles[0]}'; return str(self._alleles[0]). assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; if self._phased:; return",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/call.html:56,Feedback,Feedback,56,docs/0.2/_modules/hail/genetics/call.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.genetics.locus. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.locus. Source code for hail.genetics.locus; from typing import Union. import hail as hl; from hail.genetics.reference_genome import ReferenceGenome, reference_genome_type; from hail.typecheck import typecheck_method. [docs]class Locus(object):; """"""An object that represents a location in the genome. Parameters; ----------; contig : :class:`str`; Chromosome identifier.; position : :obj:`int`; Chromosomal position (1-indexed).; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to use. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.locus.take(5)``. This is rare; it is much; more common to manipulate the :class:`.LocusExpression` object, which is; constructed using the following functions:. - :func:`.locus`; - :func:`.parse_locus`; - :func:`.locus_from_global_position`; """""". def __init__(self, contig, position, reference_genome: Union[str, ReferenceGenome] = 'default'):; if isinstance(contig, int):; contig = str(contig). if isinstance(reference_genome, str):; reference_genome = hl.get_reference(reference_genome). assert isinstance(contig, str); assert isinstance(position, int); assert isinstance(reference_genome, ReferenceGenome). self._contig = contig; self._position = position; self._rg = reference_genome. def __str__(self):; return f'{self._contig}:{self._position}'. def __repr__(self):; return 'Locus(contig=%s, position=%s, reference_genome=%s)' % (self.contig, self.position, self._rg). def __eq__(self, other):; return (; (self._contig == ot",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html:57,Feedback,Feedback,57,docs/0.2/_modules/hail/genetics/locus.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.genetics.pedigree. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.pedigree. Source code for hail.genetics.pedigree; import re; from collections import Counter. from hail.typecheck import nullable, sequenceof, typecheck_method; from hail.utils.java import Env, FatalError, warning. [docs]class Trio(object):; """"""Class containing information about nuclear family relatedness and sex. :param str s: Sample ID of proband. :param fam_id: Family ID.; :type fam_id: str or None. :param pat_id: Sample ID of father.; :type pat_id: str or None. :param mat_id: Sample ID of mother.; :type mat_id: str or None. :param is_female: Sex of proband.; :type is_female: bool or None; """""". @typecheck_method(s=str, fam_id=nullable(str), pat_id=nullable(str), mat_id=nullable(str), is_female=nullable(bool)); def __init__(self, s, fam_id=None, pat_id=None, mat_id=None, is_female=None):; self._fam_id = fam_id; self._s = s; self._pat_id = pat_id; self._mat_id = mat_id; self._is_female = is_female. def __repr__(self):; return 'Trio(s=%s, fam_id=%s, pat_id=%s, mat_id=%s, is_female=%s)' % (; repr(self.s),; repr(self.fam_id),; repr(self.pat_id),; repr(self.mat_id),; repr(self.is_female),; ). def __str__(self):; return 'Trio(s=%s, fam_id=%s, pat_id=%s, mat_id=%s, is_female=%s)' % (; str(self.s),; str(self.fam_id),; str(self.pat_id),; str(self.mat_id),; str(self.is_female),; ). def __eq__(self, other):; return (; isinstance(other, Trio); and self._s == other._s; and self._mat_id == other._mat_id; and self._pat_id == other._pat_id; and self._fam_id == other._fam_id; and self._is_female == other._is_female; ). def __hash__(self):; retur",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html:60,Feedback,Feedback,60,docs/0.2/_modules/hail/genetics/pedigree.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.genetics.reference_genome. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.genetics.reference_genome. Source code for hail.genetics.reference_genome; import json; import re; from bisect import bisect_right. import hail as hl; from hail.typecheck import dictof, lazy, nullable, oneof, sequenceof, sized_tupleof, transformed, typecheck_method; from hail.utils.java import Env; from hail.utils.misc import wrap_to_list. rg_type = lazy(); reference_genome_type = oneof(transformed((str, lambda x: hl.get_reference(x))), rg_type). [docs]class ReferenceGenome:; """"""An object that represents a `reference genome <https://en.wikipedia.org/wiki/Reference_genome>`__. Examples; --------. >>> contigs = [""1"", ""X"", ""Y"", ""MT""]; >>> lengths = {""1"": 249250621, ""X"": 155270560, ""Y"": 59373566, ""MT"": 16569}; >>> par = [(""X"", 60001, 2699521)]; >>> my_ref = hl.ReferenceGenome(""my_ref"", contigs, lengths, ""X"", ""Y"", ""MT"", par). Notes; -----; Hail comes with predefined reference genomes (case sensitive!):. - GRCh37, Genome Reference Consortium Human Build 37; - GRCh38, Genome Reference Consortium Human Build 38; - GRCm38, Genome Reference Consortium Mouse Build 38; - CanFam3, Canis lupus familiaris (dog). You can access these reference genome objects using :func:`~hail.get_reference`:. >>> rg = hl.get_reference('GRCh37'); >>> rg = hl.get_reference('GRCh38'); >>> rg = hl.get_reference('GRCm38'); >>> rg = hl.get_reference('CanFam3'). Note that constructing a new reference genome, either by using the class; constructor or by using `read` will add the reference genome to the list of; known references; it is possible to access the reference gen",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:68,Feedback,Feedback,68,docs/0.2/_modules/hail/genetics/reference_genome.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.ggplot.aes. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.aes. Source code for hail.ggplot.aes; from collections.abc import Mapping. from hail.expr import Expression, literal. [docs]class Aesthetic(Mapping):; def __init__(self, properties):; self.properties = properties. def __getitem__(self, item):; return self.properties[item]. def __len__(self):; return len(self.properties). def __contains__(self, item):; return item in self.properties. def __iter__(self):; return iter(self.properties). def __repr__(self):; return self.properties.__repr__(). def merge(self, other):; return Aesthetic({**self.properties, **other.properties}). [docs]def aes(**kwargs):; """"""Create an aesthetic mapping. Parameters; ----------; kwargs:; Map aesthetic names to hail expressions based on table's plot. Returns; -------; :class:`.Aesthetic`; The aesthetic mapping to be applied. """"""; hail_field_properties = {}. for k, v in kwargs.items():; _v = v; if not isinstance(v, Expression):; _v = literal(v); hail_field_properties[k] = _v; return Aesthetic(hail_field_properties). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/aes.html:53,Feedback,Feedback,53,docs/0.2/_modules/hail/ggplot/aes.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/aes.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.ggplot.coord_cartesian. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.coord_cartesian. Source code for hail.ggplot.coord_cartesian; from .geoms import FigureAttribute. class CoordCartesian(FigureAttribute):; def __init__(self, xlim, ylim):; self.xlim = xlim; self.ylim = ylim. def apply_to_fig(self, fig_so_far):; if self.xlim is not None:; fig_so_far.update_xaxes(range=list(self.xlim)); if self.ylim is not None:; fig_so_far.update_yaxes(range=list(self.ylim)). [docs]def coord_cartesian(xlim=None, ylim=None):; """"""Set the boundaries of the plot. Parameters; ----------; xlim : :obj:`tuple` with two int; The minimum and maximum x value to show on the plot.; ylim : :obj:`tuple` with two int; The minimum and maximum y value to show on the plot. Returns; -------; :class:`.FigureAttribute`; The coordinate attribute to be applied. """"""; return CoordCartesian(xlim, ylim). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/coord_cartesian.html:65,Feedback,Feedback,65,docs/0.2/_modules/hail/ggplot/coord_cartesian.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/coord_cartesian.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.ggplot.facets. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.facets. Source code for hail.ggplot.facets; import abc; import math; from typing import ClassVar, Dict, Optional, Tuple. import hail as hl; from hail.expr import Expression, StructExpression. from .geoms import FigureAttribute; from .utils import n_partitions. [docs]def vars(*args: Expression) -> StructExpression:; """""". Parameters; ----------; *args: :class:`hail.expr.Expression`; Fields to facet by. Returns; -------; :class:`hail.expr.StructExpression`; A struct to pass to a faceter. """"""; return hl.struct(**{f""var_{i}"": arg for i, arg in enumerate(args)}). [docs]def facet_wrap(; facets: StructExpression, *, nrow: Optional[int] = None, ncol: Optional[int] = None, scales: str = ""fixed""; ) -> ""FacetWrap"":; """"""Introduce a one dimensional faceting on specified fields. Parameters; ----------; facets: :class:`hail.expr.StructExpression` created by `hl.ggplot.vars` function.; The fields to facet on.; nrow: :class:`int`; The number of rows into which the facets will be spread. Will be ignored if `ncol` is set.; ncol: :class:`int`; The number of columns into which the facets will be spread.; scales: :class:`str`; Whether the scales are the same across facets. For more information and a list of supported options, see `the ggplot documentation <https://ggplot2-book.org/facet.html#controlling-scales>`__. Returns; -------; :class:`FigureAttribute`; The faceter. """"""; return FacetWrap(facets, nrow, ncol, scales). class Faceter(FigureAttribute):; @abc.abstractmethod; def get_expr_to_group_by(self) -> StructExpression:; pass. class FacetWrap(Faceter):; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/facets.html:56,Feedback,Feedback,56,docs/0.2/_modules/hail/ggplot/facets.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/facets.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.ggplot.geoms. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.geoms. Source code for hail.ggplot.geoms; import abc; from typing import Any, ClassVar, Dict, Optional. import numpy as np; import plotly.graph_objects as go. from .aes import aes; from .stats import StatBin, StatCDF, StatCount, StatFunction, StatIdentity, StatNone; from .utils import bar_position_plotly_to_gg, linetype_plotly_to_gg. [docs]class FigureAttribute(abc.ABC):; pass. class Geom(FigureAttribute):; def __init__(self, aes):; self.aes = aes. @abc.abstractmethod; def apply_to_fig(; self, agg_result, fig_so_far: go.Figure, precomputed, facet_row, facet_col, legend_cache, is_faceted: bool; ):; """"""Add this geometry to the figure and indicate if this geometry demands a static figure.""""""; pass. @abc.abstractmethod; def get_stat(self):; pass. def _add_aesthetics_to_trace_args(self, trace_args, df):; for aes_name, (plotly_name, default) in self.aes_to_arg.items():; if hasattr(self, aes_name) and getattr(self, aes_name) is not None:; trace_args[plotly_name] = getattr(self, aes_name); elif aes_name in df.attrs:; trace_args[plotly_name] = df.attrs[aes_name]; elif aes_name in df.columns:; trace_args[plotly_name] = df[aes_name]; elif default is not None:; trace_args[plotly_name] = default. def _update_legend_trace_args(self, trace_args, legend_cache):; if ""name"" in trace_args:; trace_args[""legendgroup""] = trace_args[""name""]; if trace_args[""name""] in legend_cache:; trace_args[""showlegend""] = False; else:; trace_args[""showlegend""] = True; legend_cache[trace_args[""name""]] = {}. class GeomLineBasic(Geom):; aes_to_arg: ClassVar = {; ""color"": (""line",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:55,Feedback,Feedback,55,docs/0.2/_modules/hail/ggplot/geoms.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.ggplot.ggplot. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.ggplot. Source code for hail.ggplot.ggplot; import itertools; from pprint import pprint. from plotly.subplots import make_subplots. import hail as hl. from .aes import Aesthetic, aes; from .coord_cartesian import CoordCartesian; from .facets import Faceter; from .geoms import FigureAttribute, Geom; from .labels import Labels; from .scale import (; Scale,; ScaleContinuous,; ScaleDiscrete,; scale_color_continuous,; scale_color_discrete,; scale_fill_continuous,; scale_fill_discrete,; scale_shape_auto,; scale_x_continuous,; scale_x_discrete,; scale_x_genomic,; scale_y_continuous,; scale_y_discrete,; ); from .utils import check_scale_continuity, is_continuous_type, is_genomic_type. [docs]class GGPlot:; """"""The class representing a figure created using the ``hail.ggplot`` module. Create one by using :func:`.ggplot`. .. automethod:: to_plotly; .. automethod:: show; .. automethod:: write_image; """""". def __init__(self, ht, aes, geoms=[], labels=Labels(), coord_cartesian=None, scales=None, facet=None):; if scales is None:; scales = {}. self.ht = ht; self.aes = aes; self.geoms = geoms; self.labels = labels; self.coord_cartesian = coord_cartesian; self.scales = scales; self.facet = facet. self.add_default_scales(aes). def __add__(self, other):; assert isinstance(other, (FigureAttribute, Aesthetic)). copied = self.copy(); if isinstance(other, Geom):; copied.geoms.append(other); copied.add_default_scales(other.aes); elif isinstance(other, Labels):; copied.labels = copied.labels.merge(other); elif isinstance(other, CoordCartesian):; copied.coord_cartes",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:56,Feedback,Feedback,56,docs/0.2/_modules/hail/ggplot/ggplot.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.ggplot.labels. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.labels. Source code for hail.ggplot.labels; from .geoms import FigureAttribute. class Labels(FigureAttribute):; def __init__(self, title=None, xlabel=None, ylabel=None, group_labels={}, **kwargs):; self.title = title; self.xlabel = xlabel; self.ylabel = ylabel; self.group_labels = group_labels. def apply_to_fig(self, fig_so_far):; layout_updates = {}; if self.title is not None:; layout_updates[""title""] = self.title; if self.xlabel is not None:; layout_updates[""xaxis_title""] = self.xlabel; if self.ylabel is not None:; layout_updates[""yaxis_title""] = self.ylabel. fig_so_far.update_layout(**layout_updates). for legend_group, label in self.group_labels.items():; fig_so_far.update_traces({""legendgrouptitle_text"": label}, {""legendgroup"": legend_group}). def merge(self, other):; new_title = other.title if other.title is not None else self.title; new_xlabel = other.xlabel if other.xlabel is not None else self.xlabel; new_ylabel = other.ylabel if other.ylabel is not None else self.ylabel; new_group_labels = {**self.group_labels, **other.group_labels}. return Labels(title=new_title, xlabel=new_xlabel, ylabel=new_ylabel, group_labels=new_group_labels). [docs]def ggtitle(label):; """"""Sets the title of a plot. Parameters; ----------; label : :class:`str`; The desired title of the plot. Returns; -------; :class:`.FigureAttribute`; Label object to change the title.; """"""; return Labels(title=label). [docs]def xlab(label):; """"""Sets the x-axis label of a plot. Parameters; ----------; label : :class:`str`; The desired x-axis label of the plot. Returns; ---",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/labels.html:56,Feedback,Feedback,56,docs/0.2/_modules/hail/ggplot/labels.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/labels.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.ggplot.scale. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.scale. Source code for hail.ggplot.scale; import abc; from collections.abc import Mapping. import plotly; import plotly.express as px. from hail.context import get_reference; from hail.expr.types import tstr. from .geoms import FigureAttribute; from .utils import continuous_nums_to_colors, is_continuous_type, is_discrete_type. class Scale(FigureAttribute):; def __init__(self, aesthetic_name):; self.aesthetic_name = aesthetic_name. @abc.abstractmethod; def transform_data(self, field_expr):; pass. def create_local_transformer(self, groups_of_dfs):; return lambda x: x. @abc.abstractmethod; def is_discrete(self):; pass. @abc.abstractmethod; def is_continuous(self):; pass. def valid_dtype(self, dtype):; pass. class PositionScale(Scale):; def __init__(self, aesthetic_name, name, breaks, labels):; super().__init__(aesthetic_name); self.name = name; self.breaks = breaks; self.labels = labels. def update_axis(self, fig):; if self.aesthetic_name == ""x"":; return fig.update_xaxes; elif self.aesthetic_name == ""y"":; return fig.update_yaxes. # What else do discrete and continuous scales have in common?; def apply_to_fig(self, parent, fig_so_far):; if self.name is not None:; self.update_axis(fig_so_far)(title=self.name). if self.breaks is not None:; self.update_axis(fig_so_far)(tickvals=self.breaks). if self.labels is not None:; self.update_axis(fig_so_far)(ticktext=self.labels). def valid_dtype(self, dtype):; return True. class PositionScaleGenomic(PositionScale):; def __init__(self, aesthetic_name, reference_genome, name=None):; super().__init__(aesth",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:55,Feedback,Feedback,55,docs/0.2/_modules/hail/ggplot/scale.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.linalg.blockmatrix. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.linalg.blockmatrix. Source code for hail.linalg.blockmatrix; import itertools; import math; import os; import re. import numpy as np; import scipy.linalg as spla. import hail as hl; import hail.expr.aggregators as agg; from hail.expr import construct_expr, construct_variable; from hail.expr.blockmatrix_type import tblockmatrix; from hail.expr.expressions import (; expr_array,; expr_float64,; expr_int32,; expr_int64,; expr_ndarray,; expr_tuple,; matrix_table_source,; raise_unless_entry_indexed,; ); from hail.ir import (; F64,; ApplyBinaryPrimOp,; ApplyUnaryPrimOp,; BandSparsifier,; BlockMatrixAgg,; BlockMatrixBroadcast,; BlockMatrixCollect,; BlockMatrixDensify,; BlockMatrixDot,; BlockMatrixFilter,; BlockMatrixMap,; BlockMatrixMap2,; BlockMatrixRandom,; BlockMatrixRead,; BlockMatrixSlice,; BlockMatrixSparsify,; BlockMatrixToTable,; BlockMatrixToValueApply,; BlockMatrixWrite,; ExportType,; PerBlockSparsifier,; RectangleSparsifier,; RowIntervalSparsifier,; TableFromBlockMatrixNativeReader,; TableRead,; ValueToBlockMatrix,; tensor_shape_to_matrix_shape,; ); from hail.ir.blockmatrix_reader import BlockMatrixBinaryReader, BlockMatrixNativeReader; from hail.ir.blockmatrix_writer import BlockMatrixBinaryWriter, BlockMatrixNativeWriter, BlockMatrixRectanglesWriter; from hail.table import Table; from hail.typecheck import (; enumeration,; func_spec,; lazy,; nullable,; numeric,; oneof,; sequenceof,; sized_tupleof,; sliceof,; tupleof,; typecheck,; typecheck_method,; ); from hail.utils import local_path_uri, new_local_temp_file, new_temp_file, storage_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:61,Feedback,Feedback,61,docs/0.2/_modules/hail/linalg/blockmatrix.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.linalg.utils.misc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.linalg.utils.misc. Source code for hail.linalg.utils.misc; import numpy as np. import hail as hl; from hail.expr.expressions import expr_float64, expr_locus, raise_unless_row_indexed; from hail.typecheck import nullable, oneof, typecheck; from hail.utils.java import Env. [docs]@typecheck(a=np.ndarray, radius=oneof(int, float)); def array_windows(a, radius):; """"""Returns start and stop indices for window around each array value. Examples; --------. >>> hl.linalg.utils.array_windows(np.array([1, 2, 4, 4, 6, 8]), 2); (array([0, 0, 1, 1, 2, 4]), array([2, 4, 5, 5, 6, 6])). >>> hl.linalg.utils.array_windows(np.array([-10.0, -2.5, 0.0, 0.0, 1.2, 2.3, 3.0]), 2.5); (array([0, 1, 1, 1, 2, 2, 4]), array([1, 4, 6, 6, 7, 7, 7])). Notes; -----; For an array ``a`` in ascending order, the resulting ``starts`` and ``stops``; arrays have the same length as ``a`` and the property that, for all indices; ``i``, ``[starts[i], stops[i])`` is the maximal range of indices ``j`` such; that ``a[i] - radius <= a[j] <= a[i] + radius``. Index ranges are start-inclusive and stop-exclusive. This function is; especially useful in conjunction with; :meth:`.BlockMatrix.sparsify_row_intervals`. Parameters; ----------; a: :obj:`numpy.ndarray` of signed integer or float values; 1-dimensional array of values, non-decreasing with respect to index.; radius: :obj:`float`; Non-negative radius of window for values. Returns; -------; (:class:`numpy.ndarray` of :obj:`int`, :class:`numpy.ndarray` of :obj:`int`); Tuple of start indices array and stop indices array.; """"""; if radius < 0:;",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/linalg/utils/misc.html:60,Feedback,Feedback,60,docs/0.2/_modules/hail/linalg/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/utils/misc.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.matrixtable. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.matrixtable. Source code for hail.matrixtable; import itertools; import warnings; from collections import Counter; from typing import Any, Dict, Iterable, List, Optional, Tuple. from deprecated import deprecated. import hail as hl; from hail import ir; from hail.expr.expressions import (; Expression,; ExpressionException,; Indices,; StructExpression,; TupleExpression,; analyze,; construct_expr,; construct_reference,; expr_any,; expr_bool,; expr_struct,; extract_refs_by_indices,; unify_all,; ); from hail.expr.matrix_type import tmatrix; from hail.expr.types import tarray, tset, types_match; from hail.table import ExprContainer, Table, TableIndexKeyError; from hail.typecheck import (; anyfunc,; anytype,; dictof,; enumeration,; lazy,; nullable,; numeric,; oneof,; sequenceof,; typecheck,; typecheck_method,; ); from hail.utils import deduplicate, default_handler, storage_level; from hail.utils.java import Env, info, warning; from hail.utils.misc import check_annotate_exprs, get_key_by_exprs, get_select_exprs, process_joins, wrap_to_tuple. [docs]class GroupedMatrixTable(ExprContainer):; """"""Matrix table grouped by row or column that can be aggregated into a new matrix table."""""". def __init__(; self,; parent: 'MatrixTable',; row_keys=None,; computed_row_key=None,; col_keys=None,; computed_col_key=None,; entry_fields=None,; row_fields=None,; col_fields=None,; partitions=None,; ):; super(GroupedMatrixTable, self).__init__(); self._parent = parent; self._copy_fields_from(parent); self._row_keys = row_keys; self._computed_row_key = computed_row_key; self._c",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/matrixtable.html:54,Feedback,Feedback,54,docs/0.2/_modules/hail/matrixtable.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/matrixtable.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.family_methods. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.family_methods. Source code for hail.methods.family_methods; from typing import Tuple. import hail as hl; import hail.expr.aggregators as agg; from hail.expr import expr_call, expr_float64; from hail.genetics.pedigree import Pedigree; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import numeric, typecheck; from hail.utils.java import Env. from .misc import require_biallelic, require_col_key_str. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree, complete_trios=bool); def trio_matrix(dataset, pedigree, complete_trios=False) -> MatrixTable:; """"""Builds and returns a matrix where columns correspond to trios and entries contain genotypes for the trio. .. include:: ../_templates/req_tstring.rst. Examples; --------. Create a trio matrix:. >>> pedigree = hl.Pedigree.read('data/case_control_study.fam'); >>> trio_dataset = hl.trio_matrix(dataset, pedigree, complete_trios=True). Notes; -----. This method builds a new matrix table with one column per trio. If; `complete_trios` is ``True``, then only trios that satisfy; :meth:`.Trio.is_complete` are included. In this new dataset, the column; identifiers are the sample IDs of the trio probands. The column fields and; entries of the matrix are changed in the following ways:. The new column fields consist of three structs (`proband`, `father`,; `mother`), a Boolean field, and a string field:. - **proband** (:class:`.tstruct`) - Column fields on the proband.; - **father** (:class:`.tstruct`) - Column fields on the father.; - **mother** (:clas",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:65,Feedback,Feedback,65,docs/0.2/_modules/hail/methods/family_methods.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.impex. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.impex. Source code for hail.methods.impex; import os; import re; from collections import defaultdict. import avro.schema; from avro.datafile import DataFileReader; from avro.io import DatumReader. import hail as hl; from hail import ir; from hail.expr import (; LocusExpression,; StructExpression,; analyze,; expr_array,; expr_bool,; expr_call,; expr_float64,; expr_int32,; expr_numeric,; expr_str,; to_expr,; ); from hail.expr.matrix_type import tmatrix; from hail.expr.table_type import ttable; from hail.expr.types import hail_type, tarray, tbool, tcall, tfloat32, tfloat64, tint32, tint64, tstr, tstruct; from hail.genetics.reference_genome import reference_genome_type; from hail.ir.utils import parse_type; from hail.matrixtable import MatrixTable; from hail.methods.misc import require_biallelic, require_col_key_str, require_row_key_variant; from hail.table import Table; from hail.typecheck import (; anytype,; char,; dictof,; enumeration,; nullable,; numeric,; oneof,; sequenceof,; sized_tupleof,; table_key_type,; typecheck,; ); from hail.utils import new_temp_file; from hail.utils.deduplicate import deduplicate; from hail.utils.java import Env, FatalError, info, jindexed_seq_args, warning; from hail.utils.misc import plural, wrap_to_list. from .import_lines_helpers import should_remove_line, split_lines. def locus_interval_expr(contig, start, end, includes_start, includes_end, reference_genome, skip_invalid_intervals):; includes_start = hl.bool(includes_start); includes_end = hl.bool(includes_end). if reference_genome:; return hl.locus_int",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/impex.html:56,Feedback,Feedback,56,docs/0.2/_modules/hail/methods/impex.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.misc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.misc. Source code for hail.methods.misc; from typing import Union. import hail as hl; from hail import ir; from hail.expr import Expression, construct_expr, construct_variable, expr_any, expr_array, expr_interval, expr_numeric; from hail.expr.types import tarray, tlocus, tstr, tstruct, ttuple; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import func_spec, nullable, oneof, typecheck; from hail.utils import Interval, Struct, deduplicate, new_temp_file; from hail.utils.java import Env, info; from hail.utils.misc import plural. [docs]@typecheck(i=Expression, j=Expression, keep=bool, tie_breaker=nullable(func_spec(2, expr_numeric)), keyed=bool); def maximal_independent_set(i, j, keep=True, tie_breaker=None, keyed=True) -> Table:; """"""Return a table containing the vertices in a near; `maximal independent set <https://en.wikipedia.org/wiki/Maximal_independent_set>`_; of an undirected graph whose edges are given by a two-column table. Examples; --------; Run PC-relate and compute pairs of closely related individuals:. >>> pc_rel = hl.pc_relate(dataset.GT, 0.001, k=2, statistics='kin'); >>> pairs = pc_rel.filter(pc_rel['kin'] > 0.125). Starting from the above pairs, prune individuals from a dataset until no; close relationships remain:. >>> related_samples_to_remove = hl.maximal_independent_set(pairs.i, pairs.j, False); >>> result = dataset.filter_cols(; ... hl.is_defined(related_samples_to_remove[dataset.col_key]), keep=False). Starting from the above pairs, prune individuals from a dataset until no",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/misc.html:55,Feedback,Feedback,55,docs/0.2/_modules/hail/methods/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.pca. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.pca. Source code for hail.methods.pca; from typing import List, Tuple. import hail as hl; import hail.expr.aggregators as agg; from hail import ir; from hail.experimental import mt_to_table_of_ndarray; from hail.expr import expr_call, expr_float64, matrix_table_source, raise_unless_entry_indexed; from hail.expr.expressions import construct_expr; from hail.table import Table; from hail.typecheck import nullable, oneof, typecheck; from hail.utils import FatalError; from hail.utils.java import Env, info. def hwe_normalize(call_expr):; mt = matrix_table_source('hwe_normalize/call_expr', call_expr); mt = mt.select_entries(__gt=call_expr.n_alt_alleles()); mt = mt.annotate_rows(__AC=agg.sum(mt.__gt), __n_called=agg.count_where(hl.is_defined(mt.__gt))); mt = mt.filter_rows((mt.__AC > 0) & (mt.__AC < 2 * mt.__n_called)). n_variants = mt.count_rows(); if n_variants == 0:; raise FatalError(""hwe_normalize: found 0 variants after filtering out monomorphic sites.""); info(f""hwe_normalize: found {n_variants} variants after filtering out monomorphic sites.""). mt = mt.annotate_rows(__mean_gt=mt.__AC / mt.__n_called); mt = mt.annotate_rows(__hwe_scaled_std_dev=hl.sqrt(mt.__mean_gt * (2 - mt.__mean_gt) * n_variants / 2)); mt = mt.unfilter_entries(). normalized_gt = hl.or_else((mt.__gt - mt.__mean_gt) / mt.__hwe_scaled_std_dev, 0.0); return normalized_gt. [docs]@typecheck(call_expr=expr_call, k=int, compute_loadings=bool); def hwe_normalized_pca(call_expr, k=10, compute_loadings=False) -> Tuple[List[float], Table, Table]:; r""""""Run principal component analysi",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/pca.html:54,Feedback,Feedback,54,docs/0.2/_modules/hail/methods/pca.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.qc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.qc. Source code for hail.methods.qc; import abc; import logging; import os; from collections import Counter; from shlex import quote as shq; from typing import Dict, List, Optional, Tuple, Union. import hail as hl; import hailtop.batch_client as bc; from hail.backend.service_backend import ServiceBackend; from hail.expr import Float64Expression; from hail.expr.expressions.expression_typecheck import expr_float64; from hail.expr.functions import numeric_allele_type; from hail.expr.types import tarray, tfloat, tint32, tstr, tstruct; from hail.genetics.allele_type import AlleleType; from hail.ir import TableToTableApply; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import anytype, nullable, numeric, oneof, typecheck; from hail.utils import FatalError; from hail.utils.java import Env, info, warning; from hail.utils.misc import divide_null, guess_cloud_spark_provider, new_temp_file; from hailtop import pip_version, yamlx; from hailtop.config import get_deploy_config; from hailtop.utils import async_to_blocking. from .misc import (; require_alleles_field,; require_biallelic,; require_col_key_str,; require_row_key_variant,; require_table_key_variant,; ). log = logging.getLogger('methods.qc'). HAIL_GENETICS_VEP_GRCH37_85_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH37_85_IMAGE', f'hailgenetics/vep-grch37-85:{pip_version()}'; ); HAIL_GENETICS_VEP_GRCH38_95_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH38_95_IMAGE', f'hailgenetics/vep-grch38-95:{pip_version()}'; ). def _qc_allele_type(ref, alt):; ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/qc.html:53,Feedback,Feedback,53,docs/0.2/_modules/hail/methods/qc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.relatedness.identity_by_descent. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.relatedness.identity_by_descent. Source code for hail.methods.relatedness.identity_by_descent; import hail as hl; from hail import ir; from hail.backend.spark_backend import SparkBackend; from hail.expr import analyze; from hail.expr.expressions import expr_float64; from hail.linalg import BlockMatrix; from hail.matrixtable import MatrixTable; from hail.methods.misc import require_biallelic, require_col_key_str; from hail.table import Table; from hail.typecheck import nullable, numeric, typecheck; from hail.utils.java import Env. [docs]@typecheck(dataset=MatrixTable, maf=nullable(expr_float64), bounded=bool, min=nullable(numeric), max=nullable(numeric)); def identity_by_descent(dataset, maf=None, bounded=True, min=None, max=None) -> Table:; """"""Compute matrix of identity-by-descent estimates. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. To calculate a full IBD matrix, using minor allele frequencies computed; from the dataset itself:. >>> hl.identity_by_descent(dataset). To calculate an IBD matrix containing only pairs of samples with; ``PI_HAT`` in :math:`[0.2, 0.9]`, using minor allele frequencies stored in; the row field `panel_maf`:. >>> hl.identity_by_descent(dataset, maf=dataset['panel_maf'], min=0.2, max=0.9). Notes; -----. The dataset must have a column field named `s` which is a :class:`.StringExpression`; and which uniquely identifies a column. The implementation is based on the IBD algorithm d",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/identity_by_descent.html:82,Feedback,Feedback,82,docs/0.2/_modules/hail/methods/relatedness/identity_by_descent.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/identity_by_descent.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.relatedness.king. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.relatedness.king. Source code for hail.methods.relatedness.king; import hail as hl; from hail.expr.expressions import expr_call, matrix_table_source; from hail.typecheck import nullable, typecheck; from hail.utils import deduplicate; from hail.utils.java import Env. [docs]@typecheck(call_expr=expr_call, block_size=nullable(int)); def king(call_expr, *, block_size=None):; r""""""Compute relatedness estimates between individuals using a KING variant. .. include:: ../_templates/req_diploid_gt.rst. Examples; --------; Estimate the kinship coefficient for every pair of samples. >>> kinship = hl.king(dataset.GT). Notes; -----. The following presentation summarizes the methods section of `Manichaikul,; et. al. <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3025716/>`__, but; adopts a more consistent notation for matrices. Let. - :math:`i` and :math:`j` be two individuals in the dataset. - :math:`N^{Aa}_{i}` be the number of heterozygote genotypes for individual; :math:`i`. - :math:`N^{Aa,Aa}_{i,j}` be the number of variants at which a pair of; individuals both have heterozygote genotypes. - :math:`N^{AA,aa}_{i,j}` be the number of variants at which a pair of; individuals have opposing homozygote genotypes. - :math:`S_{i,j}` be the set of single-nucleotide variants for which both; individuals :math:`i` and :math:`j` have a non-missing genotype. - :math:`X_{i,s}` be the genotype score matrix. Each entry corresponds to; the genotype of individual :math:`i` at variant; :math:`s`. Homozygous-reference genotypes are represented as 0,; hetero",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/king.html:67,Feedback,Feedback,67,docs/0.2/_modules/hail/methods/relatedness/king.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/king.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.relatedness.mating_simulation. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.relatedness.mating_simulation. Source code for hail.methods.relatedness.mating_simulation; import hail as hl; from hail.matrixtable import MatrixTable; from hail.typecheck import numeric, typecheck. [docs]@typecheck(mt=MatrixTable, n_rounds=int, generation_size_multiplier=numeric, keep_founders=bool); def simulate_random_mating(mt, n_rounds=1, generation_size_multiplier=1.0, keep_founders=True):; """"""Simulate random diploid mating to produce new individuals. Parameters; ----------; mt; n_rounds : :obj:`int`; Number of rounds of mating.; generation_size_multiplier : :obj:`float`; Ratio of number of offspring to current population for each round of mating.; keep_founders :obj:`bool`; If true, keep all founders and intermediate generations in the final sample list. If; false, keep only offspring in the last generation. Returns; -------; :class:`.MatrixTable`; """"""; if generation_size_multiplier <= 0:; raise ValueError(; f""simulate_random_mating: 'generation_size_multiplier' must be greater than zero: got {generation_size_multiplier}""; ); if n_rounds < 1:; raise ValueError(f""simulate_random_mating: 'n_rounds' must be positive: got {n_rounds}""). ck = next(iter(mt.col_key)). mt = mt.select_entries('GT'). ht = mt.localize_entries('__entries', '__cols'). ht = ht.annotate_globals(; generation_0=hl.range(hl.len(ht.__cols)).map(; lambda i: hl.struct(; s=hl.str('generation_0_idx_') + hl.str(i),; original=hl.str(ht.__cols[i][ck]),; mother=hl.missing('int32'),; father=hl.missing('int32'),; ); ); ). def make_new_generation(prev_",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/mating_simulation.html:80,Feedback,Feedback,80,docs/0.2/_modules/hail/methods/relatedness/mating_simulation.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/mating_simulation.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.relatedness.pc_relate. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.relatedness.pc_relate. Source code for hail.methods.relatedness.pc_relate; from typing import Optional. import hail as hl; import hail.expr.aggregators as agg; from hail import ir; from hail.backend.spark_backend import SparkBackend; from hail.expr import (; ArrayNumericExpression,; BooleanExpression,; CallExpression,; Float64Expression,; analyze,; expr_array,; expr_call,; expr_float64,; matrix_table_source,; ); from hail.expr.types import tarray; from hail.linalg import BlockMatrix; from hail.table import Table; from hail.typecheck import enumeration, nullable, numeric, typecheck; from hail.utils import new_temp_file; from hail.utils.java import Env. from ..pca import _hwe_normalized_blanczos, hwe_normalized_pca. [docs]@typecheck(; call_expr=expr_call,; min_individual_maf=numeric,; k=nullable(int),; scores_expr=nullable(expr_array(expr_float64)),; min_kinship=nullable(numeric),; statistics=enumeration('kin', 'kin2', 'kin20', 'all'),; block_size=nullable(int),; include_self_kinship=bool,; ); def pc_relate(; call_expr: CallExpression,; min_individual_maf: float,; *,; k: Optional[int] = None,; scores_expr: Optional[ArrayNumericExpression] = None,; min_kinship: Optional[float] = None,; statistics: str = 'all',; block_size: Optional[int] = None,; include_self_kinship: bool = False,; ) -> Table:; r""""""Compute relatedness estimates between individuals using a variant of the; PC-Relate method. .. include:: ../_templates/req_diploid_gt.rst. Examples; --------; Estimate kinship, identity-by-descent two, identity-by-descent one, a",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/pc_relate.html:72,Feedback,Feedback,72,docs/0.2/_modules/hail/methods/relatedness/pc_relate.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/relatedness/pc_relate.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.methods.statgen. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.statgen. Source code for hail.methods.statgen; import builtins; import itertools; import math; from typing import Callable, Dict, List, Optional, Tuple, Union. import hail as hl; import hail.expr.aggregators as agg; from hail import ir; from hail.expr import (; Expression,; ExpressionException,; NDArrayNumericExpression,; StructExpression,; analyze,; expr_any,; expr_call,; expr_float64,; expr_locus,; expr_numeric,; matrix_table_source,; raise_unless_column_indexed,; raise_unless_entry_indexed,; raise_unless_row_indexed,; table_source,; ); from hail.expr.functions import expit; from hail.expr.types import tarray, tbool, tfloat64, tint32, tndarray, tstruct; from hail.genetics.reference_genome import reference_genome_type; from hail.linalg import BlockMatrix; from hail.matrixtable import MatrixTable; from hail.methods.misc import require_biallelic, require_row_key_variant; from hail.stats import LinearMixedModel; from hail.table import Table; from hail.typecheck import anytype, enumeration, nullable, numeric, oneof, sequenceof, sized_tupleof, typecheck; from hail.utils import FatalError, new_temp_file, wrap_to_list; from hail.utils.java import Env, info, warning. from ..backend.spark_backend import SparkBackend; from . import pca, relatedness. pc_relate = relatedness.pc_relate; identity_by_descent = relatedness.identity_by_descent; _blanczos_pca = pca._blanczos_pca; _hwe_normalized_blanczos = pca._hwe_normalized_blanczos; _spectral_moments = pca._spectral_moments; _pca_and_moments = pca._pca_and_moments; hwe_normalized_pca = pca.hwe_nor",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:58,Feedback,Feedback,58,docs/0.2/_modules/hail/methods/statgen.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.nd.nd. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.nd.nd. Source code for hail.nd.nd; from functools import reduce. import hail as hl; from hail.expr.expressions import (; Int64Expression,; cast_expr,; construct_expr,; expr_any,; expr_array,; expr_bool,; expr_int32,; expr_int64,; expr_ndarray,; expr_numeric,; expr_tuple,; unify_all,; ); from hail.expr.expressions.typed_expressions import NDArrayNumericExpression; from hail.expr.functions import _ndarray; from hail.expr.functions import array as aarray; from hail.expr.types import HailType, tfloat32, tfloat64, tndarray, ttuple; from hail.ir import Apply, NDArrayConcat, NDArrayEigh, NDArrayInv, NDArrayQR, NDArraySVD; from hail.typecheck import nullable, oneof, sequenceof, tupleof, typecheck. tsequenceof_nd = oneof(sequenceof(expr_ndarray()), expr_array(expr_ndarray())); shape_type = oneof(expr_int64, tupleof(expr_int64), expr_tuple()). [docs]def array(input_array, dtype=None):; """"""Construct an :class:`.NDArrayExpression`. Examples; --------. >>> hl.eval(hl.nd.array([1, 2, 3, 4])); array([1, 2, 3, 4], dtype=int32). >>> hl.eval(hl.nd.array([[1, 2, 3], [4, 5, 6]])); array([[1, 2, 3],; [4, 5, 6]], dtype=int32). >>> hl.eval(hl.nd.array(np.identity(3))); array([[1., 0., 0.],; [0., 1., 0.],; [0., 0., 1.]]). >>> hl.eval(hl.nd.array(hl.range(10, 20))); array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19], dtype=int32). Parameters; ----------; input_array : :class:`.ArrayExpression`, numpy ndarray, or nested python lists/tuples; The array to convert to a Hail ndarray.; dtype : :class:`.HailType`; Desired hail type. Default: `float64`. Returns; -------; :class:`.NDArray",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/nd/nd.html:48,Feedback,Feedback,48,docs/0.2/_modules/hail/nd/nd.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/nd/nd.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.plot.plots. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.plot.plots. Source code for hail.plot.plots; import collections; import math; import warnings; from typing import Any, Callable, Dict, List, Optional, Sequence, Set, Tuple, Union. import bokeh; import bokeh.io; import bokeh.models; import bokeh.palettes; import bokeh.plotting; import numpy as np; import pandas as pd; from bokeh.layouts import gridplot; from bokeh.models import (; BasicTicker,; CategoricalColorMapper,; CDSView,; ColorBar,; ColorMapper,; Column,; ColumnDataSource,; CustomJS,; DataRange1d,; GridPlot,; GroupFilter,; HoverTool,; IntersectionFilter,; Label,; Legend,; LegendItem,; LinearColorMapper,; LogColorMapper,; LogTicker,; Plot,; Renderer,; Select,; Slope,; Span,; ); from bokeh.plotting import figure; from bokeh.transform import transform. import hail; from hail.expr import aggregators; from hail.expr.expressions import (; Expression,; Float32Expression,; Float64Expression,; Int32Expression,; Int64Expression,; LocusExpression,; NumericExpression,; StringExpression,; expr_any,; expr_float64,; expr_locus,; expr_numeric,; expr_str,; raise_unless_row_indexed,; ); from hail.expr.functions import _error_from_cdf_python; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import dictof, nullable, numeric, oneof, sequenceof, sized_tupleof, typecheck; from hail.utils.java import warning; from hail.utils.struct import Struct. palette = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']. [docs]def output_notebook():; """"""Configure the Bokeh out",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/plot/plots.html:53,Feedback,Feedback,53,docs/0.2/_modules/hail/plot/plots.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/plot/plots.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.stats.linear_mixed_model. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.stats.linear_mixed_model. Source code for hail.stats.linear_mixed_model; [docs]class LinearMixedModel(object):; r""""""Class representing a linear mixed model. .. warning::. This functionality is no longer implemented/supported as of Hail 0.2.94. """""". def __init__(self, py, px, s, y=None, x=None, p_path=None):; raise NotImplementedError(""LinearMixedModel is no longer implemented/supported as of Hail 0.2.94""). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/stats/linear_mixed_model.html:67,Feedback,Feedback,67,docs/0.2/_modules/hail/stats/linear_mixed_model.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/stats/linear_mixed_model.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.table. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.table. Source code for hail.table; import collections; import itertools; import pprint; import shutil; from typing import Callable, ClassVar, Dict, List, Optional, Sequence, Union, overload. import numpy as np; import pandas; import pyspark. import hail as hl; from hail import ir; from hail.expr.expressions import (; ArrayExpression,; BooleanExpression,; CallExpression,; CollectionExpression,; DictExpression,; Expression,; ExpressionException,; Indices,; IntervalExpression,; LocusExpression,; NDArrayExpression,; NumericExpression,; StringExpression,; StructExpression,; TupleExpression,; analyze,; construct_expr,; construct_reference,; expr_any,; expr_array,; expr_bool,; expr_stream,; expr_struct,; extract_refs_by_indices,; to_expr,; unify_all,; ); from hail.expr.table_type import ttable; from hail.expr.types import dtypes_from_pandas, hail_type, tarray, tset, tstruct, types_match; from hail.typecheck import (; anyfunc,; anytype,; dictof,; enumeration,; func_spec,; lazy,; nullable,; numeric,; oneof,; sequenceof,; table_key_type,; typecheck,; typecheck_method,; ); from hail.utils import deduplicate; from hail.utils.interval import Interval; from hail.utils.java import Env, info, warning; from hail.utils.misc import (; check_annotate_exprs,; check_collisions,; check_keys,; get_key_by_exprs,; get_nice_attr_error,; get_nice_field_error,; get_select_exprs,; plural,; process_joins,; storage_level,; wrap_to_tuple,; ); from hail.utils.placement_tree import PlacementTree. table_type = lazy(). class TableIndexKeyError(Exception):; def __init__(self, key_type, in",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/table.html:48,Feedback,Feedback,48,docs/0.2/_modules/hail/table.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/table.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.utils.hadoop_utils. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.hadoop_utils. Source code for hail.utils.hadoop_utils; import gzip; import io; import os.path; import sys; from typing import Any, Dict, List. from hail.fs.hadoop_fs import HadoopFS; from hail.typecheck import enumeration, typecheck; from hail.utils.java import Env, info. [docs]@typecheck(path=str, mode=enumeration('r', 'w', 'x', 'rb', 'wb', 'xb'), buffer_size=int); def hadoop_open(path: str, mode: str = 'r', buffer_size: int = 8192):; """"""Open a file through the Hadoop filesystem API. Supports distributed; file systems like hdfs, gs, and s3. Warning; -------; Due to an implementation limitation, :func:`hadoop_open` may be quite; slow for large data sets (anything larger than 50 MB). Examples; --------; Write a Pandas DataFrame as a CSV directly into Google Cloud Storage:. >>> with hadoop_open('gs://my-bucket/df.csv', 'w') as f: # doctest: +SKIP; ... pandas_df.to_csv(f). Read and print the lines of a text file stored in Google Cloud Storage:. >>> with hadoop_open('gs://my-bucket/notes.txt') as f: # doctest: +SKIP; ... for line in f:; ... print(line.strip()). Write two lines directly to a file in Google Cloud Storage:. >>> with hadoop_open('gs://my-bucket/notes.txt', 'w') as f: # doctest: +SKIP; ... f.write('result1: %s\\n' % result1); ... f.write('result2: %s\\n' % result2). Unpack a packed Python struct directly from a file in Google Cloud Storage:. >>> from struct import unpack; >>> with hadoop_open('gs://my-bucket/notes.txt', 'rb') as f: # doctest: +SKIP; ... print(unpack('<f', bytearray(f.read()))). Notes; -----; The supported mo",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html:61,Feedback,Feedback,61,docs/0.2/_modules/hail/utils/hadoop_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/hadoop_utils.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.utils.interval. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.interval. Source code for hail.utils.interval; import hail as hl; from hail.typecheck import anytype, lazy, nullable, typecheck_method. interval_type = lazy(). [docs]class Interval(object):; """"""; An object representing a range of values between `start` and `end`. >>> interval2 = hl.Interval(3, 6). Parameters; ----------; start : any type; Object with type `point_type`.; end : any type; Object with type `point_type`.; includes_start : :obj:`bool`; Interval includes start.; includes_end : :obj:`bool`; Interval includes end. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.interval.take(5)``. This is rare; it is much; more common to manipulate the :class:`.IntervalExpression` object, which is; constructed using the following functions:. - :func:`.interval`; - :func:`.locus_interval`; - :func:`.parse_locus_interval`; """""". @typecheck_method(; start=anytype,; end=anytype,; includes_start=bool,; includes_end=bool,; point_type=nullable(lambda: hl.expr.types.hail_type),; ); def __init__(self, start, end, includes_start=True, includes_end=False, point_type=None):; if point_type is None:; from hail.expr.expressions import impute_type, unify_types_limited. start_type = impute_type(start); end_type = impute_type(end); point_type = unify_types_limited(start_type, end_type); if point_type is None:; raise TypeError(""'start' and 'end' have incompatible types: '{}', '{}'."".format(start_type, end_type)). self._point_type = point_type; self._start = start; self._end = end; self._includes_start",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/interval.html:57,Feedback,Feedback,57,docs/0.2/_modules/hail/utils/interval.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/interval.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.utils.misc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.misc. Source code for hail.utils.misc; import atexit; import datetime; import difflib; import json; import os; import re; import secrets; import shutil; import string; import tempfile; from collections import Counter, defaultdict; from contextlib import contextmanager; from io import StringIO; from typing import Literal, Optional; from urllib.parse import urlparse. import hail; import hail as hl; from hail.typecheck import enumeration, nullable, typecheck; from hail.utils.java import Env, error. [docs]@typecheck(n_rows=int, n_cols=int, n_partitions=nullable(int)); def range_matrix_table(n_rows, n_cols, n_partitions=None) -> 'hail.MatrixTable':; """"""Construct a matrix table with row and column indices and no entry fields. Examples; --------. >>> range_ds = hl.utils.range_matrix_table(n_rows=100, n_cols=10). >>> range_ds.count_rows(); 100. >>> range_ds.count_cols(); 10. Notes; -----; The resulting matrix table contains the following fields:. - `row_idx` (:py:data:`.tint32`) - Row index (row key).; - `col_idx` (:py:data:`.tint32`) - Column index (column key). It contains no entry fields. This method is meant for testing and learning, and is not optimized for; production performance. Parameters; ----------; n_rows : :obj:`int`; Number of rows.; n_cols : :obj:`int`; Number of columns.; n_partitions : int, optional; Number of partitions (uses Spark default parallelism if None). Returns; -------; :class:`.MatrixTable`; """"""; check_nonnegative_and_in_range('range_matrix_table', 'n_rows', n_rows); check_nonnegative_and_in_range('range_matrix_table', '",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/misc.html:53,Feedback,Feedback,53,docs/0.2/_modules/hail/utils/misc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/misc.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.utils.struct. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.struct. Source code for hail.utils.struct; import pprint; from collections import OrderedDict; from collections.abc import Mapping; from typing import Any, Dict. from hail.typecheck import anytype, typecheck, typecheck_method; from hail.utils.misc import get_nice_attr_error, get_nice_field_error. [docs]class Struct(Mapping):; """"""; Nested annotation structure. >>> bar = hl.Struct(**{'foo': 5, '1kg': 10}). Struct elements are treated as both 'items' and 'attributes', which; allows either syntax for accessing the element ""foo"" of struct ""bar"":. >>> bar.foo; >>> bar['foo']. Field names that are not valid Python identifiers, such as fields that; start with numbers or contain spaces, must be accessed with the latter; syntax:. >>> bar['1kg']. The ``pprint`` module can be used to print nested Structs in a more; human-readable fashion:. >>> from pprint import pprint; >>> pprint(bar). Parameters; ----------; attributes; Field names and values. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.info.take(5)``. This is rare; it is much; more common to manipulate the :class:`.StructExpression` object, which is; constructed using the :func:`.struct` function.; """""". def __init__(self, **kwargs):; # Set this way to avoid an infinite recursion in `__getattr__`.; self.__dict__[""_fields""] = kwargs. def __contains__(self, item):; return item in self._fields. def __getstate__(self) -> Dict[str, Any]:; return self._fields. def __setstate__(self, state: Dict[str, Any]):; self.__dict__[""_fields""] = st",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/struct.html:55,Feedback,Feedback,55,docs/0.2/_modules/hail/utils/struct.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/struct.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.utils.tutorial. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.utils.tutorial. Source code for hail.utils.tutorial; import os; import zipfile; from urllib.request import urlretrieve. import hail as hl; from hailtop.utils import sync_retry_transient_errors. from .java import Env, info; from .misc import local_path_uri, new_local_temp_dir, new_temp_file. __all__ = ['get_1kg', 'get_hgdp', 'get_movie_lens']. resources = {; '1kg_annotations': 'https://storage.googleapis.com/hail-tutorial/1kg_annotations.txt',; '1kg_matrix_table': 'https://storage.googleapis.com/hail-tutorial/1kg.vcf.bgz',; '1kg_ensembl_gene_annotations': 'https://storage.googleapis.com/hail-tutorial/ensembl_gene_annotations.txt',; 'HGDP_annotations': 'https://storage.googleapis.com/hail-tutorial/hgdp/hgdp_pop_and_sex_annotations.tsv',; 'HGDP_matrix_table': 'https://storage.googleapis.com/hail-tutorial/hgdp/hgdp_subset.vcf.bgz',; 'HGDP_ensembl_gene_annotations': 'https://storage.googleapis.com/hail-tutorial/hgdp/hgdp_gene_annotations.tsv',; 'movie_lens_100k': 'https://files.grouplens.org/datasets/movielens/ml-100k.zip',; }. tmp_dir: str = None. def init_temp_dir():; global tmp_dir; if tmp_dir is None:; tmp_dir = new_local_temp_dir(). def _dir_exists(fs, path):; return fs.exists(path) and fs.is_dir(path). def _file_exists(fs, path):; return fs.exists(path) and fs.is_file(path). def _copy_to_tmp(fs, src, extension=None):; dst = new_temp_file(extension=extension); fs.copy(src, dst); return dst. [docs]def get_1kg(output_dir, overwrite: bool = False):; """"""Download subset of the `1000 Genomes <http://www.internationalgenome.org/>`__; dataset and sam",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/utils/tutorial.html:57,Feedback,Feedback,57,docs/0.2/_modules/hail/utils/tutorial.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/utils/tutorial.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.vds.combiner.variant_dataset_combiner. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.combiner.variant_dataset_combiner. Source code for hail.vds.combiner.variant_dataset_combiner; import collections; import hashlib; import json; import os; import sys; import uuid; from itertools import chain; from math import floor, log; from typing import ClassVar, Collection, Dict, List, NamedTuple, Optional, Union. import hail as hl; from hail.expr import HailType, tmatrix; from hail.genetics.reference_genome import ReferenceGenome; from hail.utils import FatalError, Interval; from hail.utils.java import info, warning. from ..variant_dataset import VariantDataset; from .combine import (; calculate_even_genome_partitioning,; calculate_new_intervals,; combine,; combine_r,; combine_variant_datasets,; defined_entry_fields,; make_reference_stream,; make_variant_stream,; transform_gvcf,; ). [docs]class VDSMetadata(NamedTuple):; """"""The path to a Variant Dataset and the number of samples within. Parameters; ----------; path : :class:`str`; Path to the variant dataset.; n_samples : :class:`int`; Number of samples contained within the Variant Dataset at `path`. """""". path: str; n_samples: int. class CombinerOutType(NamedTuple):; """"""A container for the types of a VDS"""""". reference_type: tmatrix; variant_type: tmatrix. FAST_CODEC_SPEC = """"""{; ""name"": ""LEB128BufferSpec"",; ""child"": {; ""name"": ""BlockingBufferSpec"",; ""blockSize"": 65536,; ""child"": {; ""name"": ""ZstdBlockBufferSpec"",; ""blockSize"": 65536,; ""child"": {; ""name"": ""StreamBlockBufferSpec""; }; }; }; }"""""". [docs]class VariantDatasetCombiner: # pylint: disable=too-many-instanc",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html:80,Feedback,Feedback,80,docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/combiner/variant_dataset_combiner.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.vds.functions. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.functions. Source code for hail.vds.functions; import hail as hl; from hail.expr.expressions import expr_any, expr_array, expr_call, expr_int32; from hail.expr.functions import _func; from hail.typecheck import enumeration, typecheck. [docs]@typecheck(lgt=expr_call, la=expr_array(expr_int32)); def lgt_to_gt(lgt, la):; """"""Transform LGT into GT using local alleles array. Parameters; ----------; lgt : :class:`.CallExpression`; LGT value.; la : :class:`.ArrayExpression`; Local alleles array. Returns; -------; :class:`.CallExpression`; """"""; return hl.rbind(lgt, lambda lgt: hl.if_else(lgt.is_non_ref(), _func(""lgt_to_gt"", hl.tcall, lgt, la), lgt)). [docs]@typecheck(; array=expr_array(),; local_alleles=expr_array(expr_int32),; n_alleles=expr_int32,; fill_value=expr_any,; number=enumeration('A', 'R', 'G'),; ); def local_to_global(array, local_alleles, n_alleles, fill_value, number):; """"""Reindex a locally-indexed array to globally-indexed. Examples; --------; >>> local_alleles = hl.array([0, 2]); >>> local_ad = hl.array([9, 10]); >>> local_pl = hl.array([94, 0, 123]). >>> hl.eval(local_to_global(local_ad, local_alleles, n_alleles=3, fill_value=0, number='R')); [9, 0, 10]. >>> hl.eval(local_to_global(local_pl, local_alleles, n_alleles=3, fill_value=999, number='G')); [94, 999, 999, 0, 999, 123]. Notes; -----; The `number` parameter matches the `VCF specification <https://samtools.github.io/hts-specs/VCFv4.3.pdf>`__; number definitions:. - ``A`` indicates one value per allele, excluding the reference.; - ``R`` indicates one value per allele, including",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/functions.html:56,Feedback,Feedback,56,docs/0.2/_modules/hail/vds/functions.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/functions.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.vds.methods. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.methods. Source code for hail.vds.methods; import hail as hl; from hail import ir; from hail.expr import expr_any, expr_array, expr_bool, expr_interval, expr_locus, expr_str; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import dictof, enumeration, func_spec, nullable, oneof, sequenceof, typecheck; from hail.utils.java import Env, info, warning; from hail.utils.misc import new_temp_file, wrap_to_list; from hail.vds.variant_dataset import VariantDataset. def write_variant_datasets(vdss, paths, *, overwrite=False, stage_locally=False, codec_spec=None):; """"""Write many `vdses` to their corresponding path in `paths`.""""""; ref_writer = ir.MatrixNativeMultiWriter(; [f""{p}/reference_data"" for p in paths], overwrite, stage_locally, codec_spec; ); var_writer = ir.MatrixNativeMultiWriter([f""{p}/variant_data"" for p in paths], overwrite, stage_locally, codec_spec); Env.backend().execute(ir.MatrixMultiWrite([vds.reference_data._mir for vds in vdss], ref_writer)); Env.backend().execute(ir.MatrixMultiWrite([vds.variant_data._mir for vds in vdss], var_writer)). [docs]@typecheck(vds=VariantDataset); def to_dense_mt(vds: 'VariantDataset') -> 'MatrixTable':; """"""Creates a single, dense :class:`.MatrixTable` from the split; :class:`.VariantDataset` representation. Parameters; ----------; vds : :class:`.VariantDataset`; Dataset in VariantDataset representation. Returns; -------; :class:`.MatrixTable`; Dataset in dense MatrixTable representation.; """"""; ref = vds.reference_data; # FIXME(chrisvittal) consider changing END ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/methods.html:54,Feedback,Feedback,54,docs/0.2/_modules/hail/vds/methods.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/methods.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.vds.sample_qc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.sample_qc. Source code for hail.vds.sample_qc; from collections.abc import Sequence; from typing import Optional. import hail as hl; from hail.expr.expressions import Expression; from hail.expr.expressions.typed_expressions import (; ArrayExpression,; CallExpression,; LocusExpression,; NumericExpression,; StructExpression,; ); from hail.genetics.allele_type import AlleleType; from hail.methods.misc import require_first_key_field_locus; from hail.methods.qc import _qc_allele_type; from hail.table import Table; from hail.typecheck import nullable, sequenceof, typecheck; from hail.utils.java import Env; from hail.utils.misc import divide_null; from hail.vds.variant_dataset import VariantDataset. @typecheck(global_gt=Expression, alleles=ArrayExpression); def vmt_sample_qc_variant_annotations(; *,; global_gt: 'Expression',; alleles: 'ArrayExpression',; ) -> tuple['Expression', 'Expression']:; """"""Compute the necessary variant annotations for :func:`.vmt_sample_qc`, that is,; allele count (AC) and an integer representation of allele type. Parameters; ----------; global_gt : :class:`.Expression`; Call expression of the global GT of a variants matrix table usually generated; by :func:`..lgt_to_gt`; alleles : :class:`.ArrayExpression`; Array expression of the alleles of a variants matrix table; (generally ``vds.variant_data.alleles``). Returns; -------; :class:`tuple`; Tuple of expressions representing the AC (first element) and allele type; (second element).; """""". return (hl.agg.call_stats(global_gt, alleles).AC, alleles[1:].map(lambda alt: _qc_all",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/sample_qc.html:56,Feedback,Feedback,56,docs/0.2/_modules/hail/vds/sample_qc.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/sample_qc.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hail.vds.variant_dataset. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.vds.variant_dataset. Source code for hail.vds.variant_dataset; import json; import os. import hail as hl; from hail.genetics import ReferenceGenome; from hail.matrixtable import MatrixTable; from hail.typecheck import typecheck_method; from hail.utils.java import info, warning. extra_ref_globals_file = 'extra_reference_globals.json'. [docs]def read_vds(; path,; *,; intervals=None,; n_partitions=None,; _assert_reference_type=None,; _assert_variant_type=None,; _warn_no_ref_block_max_length=True,; ) -> 'VariantDataset':; """"""Read in a :class:`.VariantDataset` written with :meth:`.VariantDataset.write`. Parameters; ----------; path: :obj:`str`. Returns; -------; :class:`.VariantDataset`; """"""; if intervals or not n_partitions:; reference_data = hl.read_matrix_table(VariantDataset._reference_path(path), _intervals=intervals); variant_data = hl.read_matrix_table(VariantDataset._variants_path(path), _intervals=intervals); else:; assert n_partitions is not None; reference_data = hl.read_matrix_table(VariantDataset._reference_path(path)); intervals = reference_data._calculate_new_partitions(n_partitions); assert len(intervals) > 0; reference_data = hl.read_matrix_table(VariantDataset._reference_path(path), _intervals=intervals); variant_data = hl.read_matrix_table(VariantDataset._variants_path(path), _intervals=intervals). vds = VariantDataset(reference_data, variant_data); if VariantDataset.ref_block_max_length_field not in vds.reference_data.globals:; fs = hl.current_backend().fs; metadata_file = os.path.join(path, extra_ref_globals_file); if fs.",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hail/vds/variant_dataset.html:62,Feedback,Feedback,62,docs/0.2/_modules/hail/vds/variant_dataset.html,https://hail.is,https://hail.is/docs/0.2/_modules/hail/vds/variant_dataset.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hailtop.batch Python API. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); hail; hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; hailtop.batch Python API. View page source. hailtop.batch Python API; The Hail Batch Service is a multi-tenant elastic compute cluster for analyzing datasets in the cloud. It; is available in both Microsoft Azure and Google Cloud Platform. At this time, the; Hail-maintained Batch Service is only available for users with a Broad Institute affiliation. However, there are; instructions available for how to deploy the Hail Batch Service in your own projects in our GitHub repository.; To learn more about the Hail Batch Service, take a look at our documentation.; The Python library hailtop.batch is a client library for defining workflows for the Hail Batch Service to execute.; To learn more about the Python client library, there is a tutorial and; cookbooks with detailed examples. The API documentation is available here. Previous; Next . © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/batch_api.html:954,learn,learn,954,docs/0.2/batch_api.html,https://hail.is,https://hail.is/docs/0.2/batch_api.html,2,['learn'],['learn']
Usability,"﻿. Hail | ; hailtop.frozendict. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hailtop.frozendict. Source code for hailtop.frozendict; from collections.abc import Mapping; from typing import Dict, Generic, TypeVar. T = TypeVar(""T""); U = TypeVar(""U""). [docs]class frozendict(Mapping, Generic[T, U]):; """"""; An object representing an immutable dictionary. >>> my_frozen_dict = hl.utils.frozendict({1:2, 7:5}). To get a normal python dictionary with the same elements from a `frozendict`:. >>> dict(frozendict({'a': 1, 'b': 2})). Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.my_dict.take(5)``. This is rare; it is much; more common to manipulate the :class:`.DictExpression` object, which is; constructed using :func:`.dict`. This class is necessary because hail; supports using dicts as keys to other dicts or as elements in sets, while; python does not. """""". def __init__(self, d: Dict[T, U]):; self.d = d.copy(). def __getitem__(self, k: T) -> U:; return self.d[k]. def __hash__(self) -> int:; return hash(frozenset(self.items())). def __len__(self) -> int:; return len(self.d). def __iter__(self):; return iter(self.d). def __repr__(self):; return f'frozendict({self.d!r})'. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hailtop/frozendict.html:56,Feedback,Feedback,56,docs/0.2/_modules/hailtop/frozendict.html,https://hail.is,https://hail.is/docs/0.2/_modules/hailtop/frozendict.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,"﻿. Hail | ; hailtop.fs.fs_utils. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hailtop.fs.fs_utils. Source code for hailtop.fs.fs_utils; import io; from typing import List, Optional. from hailtop.aiocloud.aiogoogle import GCSRequesterPaysConfiguration; from hailtop.utils.gcs_requester_pays import GCSRequesterPaysFSCache. from .router_fs import RouterFS; from .stat_result import FileListEntry. _fses = GCSRequesterPaysFSCache(fs_constructor=RouterFS). [docs]def open(; path: str,; mode: str = 'r',; buffer_size: int = 8192,; *,; requester_pays_config: Optional[GCSRequesterPaysConfiguration] = None,; ) -> io.IOBase:; """"""Open a file from the local filesystem of from blob storage. Supported; blob storage providers are GCS, S3 and ABS. Examples; --------; Write a Pandas DataFrame as a CSV directly into Google Cloud Storage:. >>> with hfs.open('gs://my-bucket/df.csv', 'w') as f: # doctest: +SKIP; ... pandas_df.to_csv(f). Read and print the lines of a text file stored in Google Cloud Storage:. >>> with hfs.open('gs://my-bucket/notes.txt') as f: # doctest: +SKIP; ... for line in f:; ... print(line.strip()). Access a text file stored in a Requester Pays Bucket in Google Cloud Storage:. >>> with hfs.open( # doctest: +SKIP; ... 'gs://my-bucket/notes.txt',; ... requester_pays_config='my-project'; ... ) as f:; ... for line in f:; ... print(line.strip()). Specify multiple Requester Pays Buckets within a project that are acceptable; to access:. >>> with hfs.open( # doctest: +SKIP; ... 'gs://my-bucket/notes.txt',; ... requester_pays_config=('my-project', ['my-bucket', 'bucket-2']); ... ) as f:; ... for line in f:; ... print(line.strip()). Writ",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/_modules/hailtop/fs/fs_utils.html:57,Feedback,Feedback,57,docs/0.2/_modules/hailtop/fs/fs_utils.html,https://hail.is,https://hail.is/docs/0.2/_modules/hailtop/fs/fs_utils.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,﻿. Hail | ; ldsc_baselineLD_annotations. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_assoc,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_annotations.html:65,Feedback,Feedback,65,docs/0.2/datasets/schemas/ldsc_baselineLD_annotations.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_annotations.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; ldsc_baselineLD_ldscores. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associat,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_ldscores.html:62,Feedback,Feedback,62,docs/0.2/datasets/schemas/ldsc_baselineLD_ldscores.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/ldsc_baselineLD_ldscores.html,1,['Feedback'],['Feedback']
Usability,"﻿. Hail | ; linalg/utils. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); hail; Classes; Modules; expressions; types; functions; aggregators; scans; methods; nd; utils; linalg; stats; genetics; plot; ggplot; vds; experimental. Top-Level Functions. hailtop.fs; hailtop.batch. Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Python API; Hail Query Python API; linalg; linalg/utils. View page source. linalg/utils. array_windows(a, radius); Returns start and stop indices for window around each array value. locus_windows(locus_expr, radius[, ...]); Returns start and stop indices for window around each locus. hail.linalg.utils.array_windows(a, radius)[source]; Returns start and stop indices for window around each array value.; Examples; >>> hl.linalg.utils.array_windows(np.array([1, 2, 4, 4, 6, 8]), 2); (array([0, 0, 1, 1, 2, 4]), array([2, 4, 5, 5, 6, 6])). >>> hl.linalg.utils.array_windows(np.array([-10.0, -2.5, 0.0, 0.0, 1.2, 2.3, 3.0]), 2.5); (array([0, 1, 1, 1, 2, 2, 4]), array([1, 4, 6, 6, 7, 7, 7])). Notes; For an array a in ascending order, the resulting starts and stops; arrays have the same length as a and the property that, for all indices; i, [starts[i], stops[i]) is the maximal range of indices j such; that a[i] - radius <= a[j] <= a[i] + radius.; Index ranges are start-inclusive and stop-exclusive. This function is; especially useful in conjunction with; BlockMatrix.sparsify_row_intervals(). Parameters:. a (numpy.ndarray of signed integer or float values) – 1-dimensional array of values, non-decreasing with respect to index.; radius (float) – Non-negative radius of window for values. Returns:; (numpy.ndarray of int, numpy.ndarray of int) – Tuple of start indices array and stop in",MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/linalg/utils/index.html:50,Feedback,Feedback,50,docs/0.2/linalg/utils/index.html,https://hail.is,https://hail.is/docs/0.2/linalg/utils/index.html,2,"['Feedback', 'Guid']","['Feedback', 'Guides']"
Usability,﻿. Hail | ; panukb_ld_scores_AFR. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associations,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AFR.html:58,Feedback,Feedback,58,docs/0.2/datasets/schemas/panukb_ld_scores_AFR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AFR.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_scores_AMR. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associations,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AMR.html:58,Feedback,Feedback,58,docs/0.2/datasets/schemas/panukb_ld_scores_AMR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_AMR.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_scores_CSA. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associations,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_CSA.html:58,Feedback,Feedback,58,docs/0.2/datasets/schemas/panukb_ld_scores_CSA.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_CSA.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_scores_EAS. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associations,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_EAS.html:58,Feedback,Feedback,58,docs/0.2/datasets/schemas/panukb_ld_scores_EAS.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_EAS.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_scores_EUR. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associations,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_EUR.html:58,Feedback,Feedback,58,docs/0.2/datasets/schemas/panukb_ld_scores_EUR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_EUR.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_scores_MID. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associations,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_MID.html:58,Feedback,Feedback,58,docs/0.2/datasets/schemas/panukb_ld_scores_MID.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_scores_MID.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_variant_indices_AFR. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_ass,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AFR.html:67,Feedback,Feedback,67,docs/0.2/datasets/schemas/panukb_ld_variant_indices_AFR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AFR.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_variant_indices_AMR. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_ass,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AMR.html:67,Feedback,Feedback,67,docs/0.2/datasets/schemas/panukb_ld_variant_indices_AMR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_AMR.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_variant_indices_CSA. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_ass,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_CSA.html:67,Feedback,Feedback,67,docs/0.2/datasets/schemas/panukb_ld_variant_indices_CSA.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_CSA.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_variant_indices_EAS. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_ass,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_EAS.html:67,Feedback,Feedback,67,docs/0.2/datasets/schemas/panukb_ld_variant_indices_EAS.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_EAS.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_variant_indices_EUR. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_ass,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_EUR.html:67,Feedback,Feedback,67,docs/0.2/datasets/schemas/panukb_ld_variant_indices_EUR.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_EUR.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_ld_variant_indices_MID. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_ass,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_MID.html:67,Feedback,Feedback,67,docs/0.2/datasets/schemas/panukb_ld_variant_indices_MID.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_ld_variant_indices_MID.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_meta_analysis_all_ancestries. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_ge,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_all_ancestries.html:73,Feedback,Feedback,73,docs/0.2/datasets/schemas/panukb_meta_analysis_all_ancestries.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_all_ancestries.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_meta_analysis_high_quality. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_high_quality.html:71,Feedback,Feedback,71,docs/0.2/datasets/schemas/panukb_meta_analysis_high_quality.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_meta_analysis_high_quality.html,1,['Feedback'],['Feedback']
Usability,﻿. Hail | ; panukb_summary_stats. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Schemas; 1000_Genomes_HighCov_autosomes; 1000_Genomes_HighCov_chrX; 1000_Genomes_HighCov_chrY; 1000_Genomes_Retracted_autosomes; 1000_Genomes_Retracted_chrX; 1000_Genomes_Retracted_chrY; 1000_Genomes_autosomes; 1000_Genomes_chrMT; 1000_Genomes_chrX; 1000_Genomes_chrY; CADD; DANN; Ensembl_homo_sapiens_low_complexity_regions; Ensembl_homo_sapiens_reference_genome; GTEx_RNA_seq_gene_TPMs; GTEx_RNA_seq_gene_read_counts; GTEx_RNA_seq_junction_read_counts; GTEx_eQTL_Adipose_Subcutaneous_all_snp_gene_associations; GTEx_eQTL_Adipose_Visceral_Omentum_all_snp_gene_associations; GTEx_eQTL_Adrenal_Gland_all_snp_gene_associations; GTEx_eQTL_Artery_Aorta_all_snp_gene_associations; GTEx_eQTL_Artery_Coronary_all_snp_gene_associations; GTEx_eQTL_Artery_Tibial_all_snp_gene_associations; GTEx_eQTL_Brain_Amygdala_all_snp_gene_associations; GTEx_eQTL_Brain_Anterior_cingulate_cortex_BA24_all_snp_gene_associations; GTEx_eQTL_Brain_Caudate_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellar_Hemisphere_all_snp_gene_associations; GTEx_eQTL_Brain_Cerebellum_all_snp_gene_associations; GTEx_eQTL_Brain_Cortex_all_snp_gene_associations; GTEx_eQTL_Brain_Frontal_Cortex_BA9_all_snp_gene_associations; GTEx_eQTL_Brain_Hippocampus_all_snp_gene_associations; GTEx_eQTL_Brain_Hypothalamus_all_snp_gene_associations; GTEx_eQTL_Brain_Nucleus_accumbens_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Putamen_basal_ganglia_all_snp_gene_associations; GTEx_eQTL_Brain_Spinal_cord_cervical_c-1_all_snp_gene_associations; GTEx_eQTL_Brain_Substantia_nigra_all_snp_gene_associations; GTEx_eQTL_Breast_Mammary_Tissue_all_snp_gene_associations; GTEx_eQTL_Cells_Cultured_fibroblasts_all_snp_gene_associations,MatchSource.WIKI,hail-is,hail,0.2.133,https://hail.is/docs/0.2/datasets/schemas/panukb_summary_stats.html:58,Feedback,Feedback,58,docs/0.2/datasets/schemas/panukb_summary_stats.html,https://hail.is,https://hail.is/docs/0.2/datasets/schemas/panukb_summary_stats.html,1,['Feedback'],['Feedback']
